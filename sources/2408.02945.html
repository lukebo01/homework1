<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.02945] Self-Supervised Learning for Multi-Channel Neural Transducer</title><meta property="og:description" content="Self-supervised learning, such as with the wav2vec 2.0 framework significantly improves the accuracy of end-to-end automatic speech recognition (ASR). Wav2vec 2.0 has been applied to single-channel end-to-end ASR modelâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Self-Supervised Learning for Multi-Channel Neural Transducer">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Self-Supervised Learning for Multi-Channel Neural Transducer">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.02945">

<!--Generated on Thu Sep  5 16:03:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="font-size:90%;">Self-Supervised Learning for Multi-Channel Neural Transducer</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text" style="font-size:90%;">Self-supervised</span><span id="id1.id1.2" class="ltx_text" style="font-size:90%;"> learning, such as with the wav2vec 2.0 framework significantly improves the accuracy of </span><span id="id1.id1.3" class="ltx_text" style="font-size:90%;">end-to-end</span><span id="id1.id1.4" class="ltx_text" style="font-size:90%;"> automatic speech recognition (ASR). Wav2vec 2.0 has been applied to </span><span id="id1.id1.5" class="ltx_text" style="font-size:90%;">single-channel</span><span id="id1.id1.6" class="ltx_text" style="font-size:90%;"> </span><span id="id1.id1.7" class="ltx_text" style="font-size:90%;">end-to-end</span><span id="id1.id1.8" class="ltx_text" style="font-size:90%;"> ASR models. In this work, we explored a </span><span id="id1.id1.9" class="ltx_text" style="font-size:90%;">self-supervised</span><span id="id1.id1.10" class="ltx_text" style="font-size:90%;"> learning method for a </span><span id="id1.id1.11" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="id1.id1.12" class="ltx_text" style="font-size:90%;"> </span><span id="id1.id1.13" class="ltx_text" style="font-size:90%;">end-to-end</span><span id="id1.id1.14" class="ltx_text" style="font-size:90%;"> ASR model based on the wav2vec 2.0 framework. As the </span><span id="id1.id1.15" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="id1.id1.16" class="ltx_text" style="font-size:90%;"> </span><span id="id1.id1.17" class="ltx_text" style="font-size:90%;">end-to-end</span><span id="id1.id1.18" class="ltx_text" style="font-size:90%;"> ASR model, we focused on a </span><span id="id1.id1.19" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="id1.id1.20" class="ltx_text" style="font-size:90%;"> neural transducer. In </span><span id="id1.id1.21" class="ltx_text" style="font-size:90%;">pre-training</span><span id="id1.id1.22" class="ltx_text" style="font-size:90%;">, we compared three different methods for feature quantization to train a </span><span id="id1.id1.23" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="id1.id1.24" class="ltx_text" style="font-size:90%;"> conformer audio encoder: joint quantization, </span><span id="id1.id1.25" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="id1.id1.26" class="ltx_text" style="font-size:90%;"> quantization and </span><span id="id1.id1.27" class="ltx_text" style="font-size:90%;">channel-wise</span><span id="id1.id1.28" class="ltx_text" style="font-size:90%;"> quantization. In </span><span id="id1.id1.29" class="ltx_text" style="font-size:90%;">fine-tuning</span><span id="id1.id1.30" class="ltx_text" style="font-size:90%;">, we trained the </span><span id="id1.id1.31" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="id1.id1.32" class="ltx_text" style="font-size:90%;"> </span><span id="id1.id1.33" class="ltx_text" style="font-size:90%;">conformerâ€“transducer</span><span id="id1.id1.34" class="ltx_text" style="font-size:90%;">. All experiments were conducted using the </span><span id="id1.id1.35" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="id1.id1.36" class="ltx_text" style="font-size:90%;"> and </span><span id="id1.id1.37" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="id1.id1.38" class="ltx_text" style="font-size:90%;"> datasets. The results of the experiments showed that </span><span id="id1.id1.39" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="id1.id1.40" class="ltx_text" style="font-size:90%;"> quantization was the most effective among the methods. We observed a 66% relative reduction in character error rate compared with the model without any </span><span id="id1.id1.41" class="ltx_text" style="font-size:90%;">pre-training</span><span id="id1.id1.42" class="ltx_text" style="font-size:90%;"> for the </span><span id="id1.id1.43" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="id1.id1.44" class="ltx_text" style="font-size:90%;"> dataset.</span></p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Index Terms</span><span id="p1.1.2" class="ltx_text" style="font-size:90%;">:
</span><span id="p1.1.3" class="ltx_text" style="font-size:90%;">Self-supervised</span><span id="p1.1.4" class="ltx_text" style="font-size:90%;"> learning, wav2vec 2.0, Multi-channel end-to-end speech recognition, Neural transducer, Conformer</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text" style="font-size:90%;">Self-supervised</span><span id="S1.p1.1.2" class="ltx_text" style="font-size:90%;"> learning significantly improves the accuracy of </span><span id="S1.p1.1.3" class="ltx_text" style="font-size:90%;">end-to-end</span><span id="S1.p1.1.4" class="ltx_text" style="font-size:90%;"> automatic speech recognition (ASR) models such as the </span><span id="S1.p1.1.5" class="ltx_text" style="font-size:90%;">attention-based</span><span id="S1.p1.1.6" class="ltx_text" style="font-size:90%;"> </span><span id="S1.p1.1.7" class="ltx_text" style="font-size:90%;">encoder-decoder</span><span id="S1.p1.1.8" class="ltx_text" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.9.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib1" title="" class="ltx_ref">1</a><span id="S1.p1.1.10.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.11" class="ltx_text" style="font-size:90%;">, connectionist temporal classification (CTC) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.12.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S1.p1.1.13.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.14" class="ltx_text" style="font-size:90%;"> and neural transducers </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.15.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S1.p1.1.16.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.17" class="ltx_text" style="font-size:90%;">. The most popular framework for </span><span id="S1.p1.1.18" class="ltx_text" style="font-size:90%;">self-supervised</span><span id="S1.p1.1.19" class="ltx_text" style="font-size:90%;"> learning is wav2vec 2.0 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.20.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S1.p1.1.21.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.22" class="ltx_text" style="font-size:90%;">.
In wav2vec 2.0 pre-training, the model is trained similarly to that in masked language modeling </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.23.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S1.p1.1.24.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.25" class="ltx_text" style="font-size:90%;">. In </span><span id="S1.p1.1.26" class="ltx_text" style="font-size:90%;">fine-tuning</span><span id="S1.p1.1.27" class="ltx_text" style="font-size:90%;">, the model is trained using the ASR loss function. Wav2vec 2.0 has been mainly applied to </span><span id="S1.p1.1.28" class="ltx_text" style="font-size:90%;">single-channel end-to-end</span><span id="S1.p1.1.29" class="ltx_text" style="font-size:90%;"> ASR models </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.30.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S1.p1.1.31.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.32" class="ltx_text" style="font-size:90%;">. In this work, we train a </span><span id="S1.p1.1.33" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S1.p1.1.34" class="ltx_text" style="font-size:90%;"> </span><span id="S1.p1.1.35" class="ltx_text" style="font-size:90%;">end-to-end</span><span id="S1.p1.1.36" class="ltx_text" style="font-size:90%;"> ASR model based on the wav2vec 2.0 framework.</span></p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text" style="font-size:90%;">Multi-channel </span><span id="S1.p2.1.2" class="ltx_text" style="font-size:90%;">end-to-end</span><span id="S1.p2.1.3" class="ltx_text" style="font-size:90%;"> ASR models can improve the robustness of </span><span id="S1.p2.1.4" class="ltx_text" style="font-size:90%;">far-field</span><span id="S1.p2.1.5" class="ltx_text" style="font-size:90%;"> ASR in noisy environments, because the models can capture not only spectral information but also spatial information of the target and interference signals captured from different microphones </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S1.p2.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.8" class="ltx_text" style="font-size:90%;">. In many </span><span id="S1.p2.1.9" class="ltx_text" style="font-size:90%;">end-to-end multi-channel</span><span id="S1.p2.1.10" class="ltx_text" style="font-size:90%;"> ASR architectures </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S1.p2.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.13" class="ltx_text" style="font-size:90%;">, a </span><span id="S1.p2.1.14" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S1.p2.1.15" class="ltx_text" style="font-size:90%;"> neural transducer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.16.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S1.p2.1.17.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.18" class="ltx_text" style="font-size:90%;"> is promising in terms of efficiency and accuracy.</span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text" style="font-size:90%;">Multi-channel</span><span id="S1.p3.1.2" class="ltx_text" style="font-size:90%;"> neural transducers are based on neural transducers such as </span><span id="S1.p3.1.3" class="ltx_text" style="font-size:90%;">Transformerâ€“Transducer</span><span id="S1.p3.1.4" class="ltx_text" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="S1.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.7" class="ltx_text" style="font-size:90%;"> and </span><span id="S1.p3.1.8" class="ltx_text" style="font-size:90%;">Conformerâ€“Transducer</span><span id="S1.p3.1.9" class="ltx_text" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.10.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S1.p3.1.11.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.12" class="ltx_text" style="font-size:90%;">. </span><span id="S1.p3.1.13" class="ltx_text" style="font-size:90%;">Multi-channel</span><span id="S1.p3.1.14" class="ltx_text" style="font-size:90%;"> neural transducers can learn the contextual relationship across channels using </span><span id="S1.p3.1.15" class="ltx_text" style="font-size:90%;">channel-wise</span><span id="S1.p3.1.16" class="ltx_text" style="font-size:90%;"> and </span><span id="S1.p3.1.17" class="ltx_text" style="font-size:90%;">cross-channel</span><span id="S1.p3.1.18" class="ltx_text" style="font-size:90%;"> </span><span id="S1.p3.1.19" class="ltx_text" style="font-size:90%;">self-attention</span><span id="S1.p3.1.20" class="ltx_text" style="font-size:90%;"> layers without beamforming </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.21.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S1.p3.1.22.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.23" class="ltx_text" style="font-size:90%;">. </span><span id="S1.p3.1.24" class="ltx_text" style="font-size:90%;">Multi-channel</span><span id="S1.p3.1.25" class="ltx_text" style="font-size:90%;"> neural transducers outperform typical </span><span id="S1.p3.1.26" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S1.p3.1.27" class="ltx_text" style="font-size:90%;"> </span><span id="S1.p3.1.28" class="ltx_text" style="font-size:90%;">end-to-end</span><span id="S1.p3.1.29" class="ltx_text" style="font-size:90%;"> ASR models, which are cascaded with neural beamforming </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.30.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S1.p3.1.31.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.32" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text" style="font-size:90%;">In this work, we train a </span><span id="S1.p4.1.2" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S1.p4.1.3" class="ltx_text" style="font-size:90%;"> neural transducer based on wav2vec 2.0 </span><span id="S1.p4.1.4" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S1.p4.1.5" class="ltx_text" style="font-size:90%;">.
For training, we explore three quantization methods: joint quantization, </span><span id="S1.p4.1.6" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S1.p4.1.7" class="ltx_text" style="font-size:90%;"> quantization and </span><span id="S1.p4.1.8" class="ltx_text" style="font-size:90%;">channel-wise quantization</span><span id="S1.p4.1.9" class="ltx_text" style="font-size:90%;">.
We report the results of experiments using the </span><span id="S1.p4.1.10" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S1.p4.1.11" class="ltx_text" style="font-size:90%;"> and public </span><span id="S1.p4.1.12" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="S1.p4.1.13" class="ltx_text" style="font-size:90%;"> datasets </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S1.p4.1.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.16" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text" style="font-size:90%;">In the experiments, we show that </span><span id="S1.p5.1.2" class="ltx_text" style="font-size:90%;">feature-wise quantization</span><span id="S1.p5.1.3" class="ltx_text" style="font-size:90%;"> has the best performance among the quantization methods. We observe 66% and 4.2% relative reductions in character error rate compared with the model without any </span><span id="S1.p5.1.4" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S1.p5.1.5" class="ltx_text" style="font-size:90%;"> for the </span><span id="S1.p5.1.6" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S1.p5.1.7" class="ltx_text" style="font-size:90%;"> and </span><span id="S1.p5.1.8" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="S1.p5.1.9" class="ltx_text" style="font-size:90%;"> datasets, respectively.</span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Multi-channel neural transducer</h3>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2408.02945/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="182" height="75" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Architecture of multi-channel neural transducer in the case of two channels.</figcaption>
</figure>
<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.6" class="ltx_p"><span id="S2.SS1.p1.6.1" class="ltx_text" style="font-size:90%;">We first describe the architecture of a </span><span id="S2.SS1.p1.6.2" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S2.SS1.p1.6.3" class="ltx_text" style="font-size:90%;"> neural transducer. FigureÂ </span><a href="#S2.F1" title="Figure 1 â€£ 2.1 Multi-channel neural transducer â€£ 2 Background â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S2.SS1.p1.6.4" class="ltx_text" style="font-size:90%;"> shows an overview of a </span><span id="S2.SS1.p1.6.5" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S2.SS1.p1.6.6" class="ltx_text" style="font-size:90%;"> neural transducer in the case of two channels. Given acoustic feature </span><math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="\bm{x}" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi mathsize="90%" id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">ğ’™</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">ğ’™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\bm{x}</annotation></semantics></math><span id="S2.SS1.p1.6.7" class="ltx_text" style="font-size:90%;"> and previous tokens </span><math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="\bm{y}_{u-1}" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><msub id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml">ğ’š</mi><mrow id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml"><mi mathsize="90%" id="S2.SS1.p1.2.m2.1.1.3.2" xref="S2.SS1.p1.2.m2.1.1.3.2.cmml">u</mi><mo mathsize="90%" id="S2.SS1.p1.2.m2.1.1.3.1" xref="S2.SS1.p1.2.m2.1.1.3.1.cmml">âˆ’</mo><mn mathsize="90%" id="S2.SS1.p1.2.m2.1.1.3.3" xref="S2.SS1.p1.2.m2.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">ğ’š</ci><apply id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3"><minus id="S2.SS1.p1.2.m2.1.1.3.1.cmml" xref="S2.SS1.p1.2.m2.1.1.3.1"></minus><ci id="S2.SS1.p1.2.m2.1.1.3.2.cmml" xref="S2.SS1.p1.2.m2.1.1.3.2">ğ‘¢</ci><cn type="integer" id="S2.SS1.p1.2.m2.1.1.3.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">\bm{y}_{u-1}</annotation></semantics></math><span id="S2.SS1.p1.6.8" class="ltx_text" style="font-size:90%;">, the </span><span id="S2.SS1.p1.6.9" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S2.SS1.p1.6.10" class="ltx_text" style="font-size:90%;"> audio encoder converts acoustic feature </span><math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="\bm{x}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi mathsize="90%" id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">ğ’™</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">ğ’™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\bm{x}</annotation></semantics></math><span id="S2.SS1.p1.6.11" class="ltx_text" style="font-size:90%;"> to hidden vector </span><math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="\bm{f}" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mi mathsize="90%" id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">ğ’‡</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">ğ’‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">\bm{f}</annotation></semantics></math><span id="S2.SS1.p1.6.12" class="ltx_text" style="font-size:90%;">, and the label encoder predicts a new token </span><math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="\bm{y}_{U}" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><msub id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p1.5.m5.1.1.2" xref="S2.SS1.p1.5.m5.1.1.2.cmml">ğ’š</mi><mi mathsize="90%" id="S2.SS1.p1.5.m5.1.1.3" xref="S2.SS1.p1.5.m5.1.1.3.cmml">U</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2">ğ’š</ci><ci id="S2.SS1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">\bm{y}_{U}</annotation></semantics></math><span id="S2.SS1.p1.6.13" class="ltx_text" style="font-size:90%;"> based on past tokens except for a blank token. The joint network outputs vector </span><math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="J" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi mathsize="90%" id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">J</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">ğ½</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">J</annotation></semantics></math><span id="S2.SS1.p1.6.14" class="ltx_text" style="font-size:90%;"> using two hidden vectors from audio and label encoders, and softmax outputs logits.</span></p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.8" class="ltx_p"><span id="S2.SS1.p2.8.1" class="ltx_text" style="font-size:90%;">A </span><span id="S2.SS1.p2.8.2" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S2.SS1.p2.8.3" class="ltx_text" style="font-size:90%;"> audio encoder consists of </span><span id="S2.SS1.p2.8.4" class="ltx_text" style="font-size:90%;">channel-wise</span><span id="S2.SS1.p2.8.5" class="ltx_text" style="font-size:90%;"> </span><span id="S2.SS1.p2.8.6" class="ltx_text" style="font-size:90%;">self-attention</span><span id="S2.SS1.p2.8.7" class="ltx_text" style="font-size:90%;"> and </span><span id="S2.SS1.p2.8.8" class="ltx_text" style="font-size:90%;">cross-channel</span><span id="S2.SS1.p2.8.9" class="ltx_text" style="font-size:90%;"> </span><span id="S2.SS1.p2.8.10" class="ltx_text" style="font-size:90%;">self-attention</span><span id="S2.SS1.p2.8.11" class="ltx_text" style="font-size:90%;"> layers. The </span><span id="S2.SS1.p2.8.12" class="ltx_text" style="font-size:90%;">channel-wise self-attention</span><span id="S2.SS1.p2.8.13" class="ltx_text" style="font-size:90%;"> layers convert inputs from each channel to hidden vectors independently via multi-head attention (MHA) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p2.8.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S2.SS1.p2.8.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p2.8.16" class="ltx_text" style="font-size:90%;">. The </span><span id="S2.SS1.p2.8.17" class="ltx_text" style="font-size:90%;">cross-channel self-attention</span><span id="S2.SS1.p2.8.18" class="ltx_text" style="font-size:90%;"> layers learn the contextual relationship across channels. We convert hidden vector </span><math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="h_{i}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><msub id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">h</mi><mi mathsize="90%" id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">â„</ci><ci id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">h_{i}</annotation></semantics></math><span id="S2.SS1.p2.8.19" class="ltx_text" style="font-size:90%;"> of the </span><math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi mathsize="90%" id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">i</annotation></semantics></math><span id="S2.SS1.p2.8.20" class="ltx_text" style="font-size:90%;">th channel from the </span><span id="S2.SS1.p2.8.21" class="ltx_text" style="font-size:90%;">channel-wise self-attention</span><span id="S2.SS1.p2.8.22" class="ltx_text" style="font-size:90%;"> layers to query </span><math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="Q_{i}" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><msub id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p2.3.m3.1.1.2" xref="S2.SS1.p2.3.m3.1.1.2.cmml">Q</mi><mi mathsize="90%" id="S2.SS1.p2.3.m3.1.1.3" xref="S2.SS1.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><apply id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.p2.3.m3.1.1.2">ğ‘„</ci><ci id="S2.SS1.p2.3.m3.1.1.3.cmml" xref="S2.SS1.p2.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">Q_{i}</annotation></semantics></math><span id="S2.SS1.p2.8.23" class="ltx_text" style="font-size:90%;">, and the mean vector of the hidden vectors of other channel inputs from the </span><span id="S2.SS1.p2.8.24" class="ltx_text" style="font-size:90%;">channel-wise self-attention</span><span id="S2.SS1.p2.8.25" class="ltx_text" style="font-size:90%;"> layers is converted to key </span><math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="{K_{i}}" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><msub id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p2.4.m4.1.1.2" xref="S2.SS1.p2.4.m4.1.1.2.cmml">K</mi><mi mathsize="90%" id="S2.SS1.p2.4.m4.1.1.3" xref="S2.SS1.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><apply id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.1.2.cmml" xref="S2.SS1.p2.4.m4.1.1.2">ğ¾</ci><ci id="S2.SS1.p2.4.m4.1.1.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">{K_{i}}</annotation></semantics></math><span id="S2.SS1.p2.8.26" class="ltx_text" style="font-size:90%;"> and value </span><math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="{V_{i}}" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><msub id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p2.5.m5.1.1.2" xref="S2.SS1.p2.5.m5.1.1.2.cmml">V</mi><mi mathsize="90%" id="S2.SS1.p2.5.m5.1.1.3" xref="S2.SS1.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2">ğ‘‰</ci><ci id="S2.SS1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">{V_{i}}</annotation></semantics></math><span id="S2.SS1.p2.8.27" class="ltx_text" style="font-size:90%;">. The MHA is calculated using </span><math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="Q_{i}" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><msub id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p2.6.m6.1.1.2" xref="S2.SS1.p2.6.m6.1.1.2.cmml">Q</mi><mi mathsize="90%" id="S2.SS1.p2.6.m6.1.1.3" xref="S2.SS1.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><apply id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.p2.6.m6.1.1.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2">ğ‘„</ci><ci id="S2.SS1.p2.6.m6.1.1.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">Q_{i}</annotation></semantics></math><span id="S2.SS1.p2.8.28" class="ltx_text" style="font-size:90%;">, </span><math id="S2.SS1.p2.7.m7.1" class="ltx_Math" alttext="K_{i}" display="inline"><semantics id="S2.SS1.p2.7.m7.1a"><msub id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p2.7.m7.1.1.2" xref="S2.SS1.p2.7.m7.1.1.2.cmml">K</mi><mi mathsize="90%" id="S2.SS1.p2.7.m7.1.1.3" xref="S2.SS1.p2.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><apply id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m7.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2">ğ¾</ci><ci id="S2.SS1.p2.7.m7.1.1.3.cmml" xref="S2.SS1.p2.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">K_{i}</annotation></semantics></math><span id="S2.SS1.p2.8.29" class="ltx_text" style="font-size:90%;"> and </span><math id="S2.SS1.p2.8.m8.1" class="ltx_Math" alttext="V_{i}" display="inline"><semantics id="S2.SS1.p2.8.m8.1a"><msub id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p2.8.m8.1.1.2" xref="S2.SS1.p2.8.m8.1.1.2.cmml">V</mi><mi mathsize="90%" id="S2.SS1.p2.8.m8.1.1.3" xref="S2.SS1.p2.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><apply id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.8.m8.1.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.p2.8.m8.1.1.2.cmml" xref="S2.SS1.p2.8.m8.1.1.2">ğ‘‰</ci><ci id="S2.SS1.p2.8.m8.1.1.3.cmml" xref="S2.SS1.p2.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">V_{i}</annotation></semantics></math><span id="S2.SS1.p2.8.30" class="ltx_text" style="font-size:90%;">. Finally, hidden vectors from the </span><span id="S2.SS1.p2.8.31" class="ltx_text" style="font-size:90%;">cross-channel</span><span id="S2.SS1.p2.8.32" class="ltx_text" style="font-size:90%;"> </span><span id="S2.SS1.p2.8.33" class="ltx_text" style="font-size:90%;">self-attention</span><span id="S2.SS1.p2.8.34" class="ltx_text" style="font-size:90%;"> layers are fused by taking a simple average. For input features, a </span><span id="S2.SS1.p2.8.35" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S2.SS1.p2.8.36" class="ltx_text" style="font-size:90%;"> audio encoder obtains not only amplitude features but also phase features, unlike a </span><span id="S2.SS1.p2.8.37" class="ltx_text" style="font-size:90%;">single-channel</span><span id="S2.SS1.p2.8.38" class="ltx_text" style="font-size:90%;"> neural transducer.</span></p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.3" class="ltx_p"><span id="S2.SS1.p3.3.1" class="ltx_text" style="font-size:90%;">A </span><span id="S2.SS1.p3.3.2" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S2.SS1.p3.3.3" class="ltx_text" style="font-size:90%;"> neural transducer is trained using the </span><span id="S2.SS1.p3.3.4" class="ltx_text" style="font-size:90%;">recurrent neural networkâ€“Transducer</span><span id="S2.SS1.p3.3.5" class="ltx_text" style="font-size:90%;"> (</span><span id="S2.SS1.p3.3.6" class="ltx_text" style="font-size:90%;">RNNâ€“T</span><span id="S2.SS1.p3.3.7" class="ltx_text" style="font-size:90%;">) loss </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p3.3.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S2.SS1.p3.3.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p3.3.10" class="ltx_text" style="font-size:90%;">. Given acoustic features </span><math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="\bm{x}" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mi mathsize="90%" id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">ğ’™</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">ğ’™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\bm{x}</annotation></semantics></math><span id="S2.SS1.p3.3.11" class="ltx_text" style="font-size:90%;"> and label sequence </span><math id="S2.SS1.p3.2.m2.1" class="ltx_Math" alttext="\bm{y}" display="inline"><semantics id="S2.SS1.p3.2.m2.1a"><mi mathsize="90%" id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">ğ’š</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">ğ’š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">\bm{y}</annotation></semantics></math><span id="S2.SS1.p3.3.12" class="ltx_text" style="font-size:90%;">, the neural transducer outputs </span><math id="S2.SS1.p3.3.m3.1" class="ltx_Math" alttext="T\times U" display="inline"><semantics id="S2.SS1.p3.3.m3.1a"><mrow id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p3.3.m3.1.1.2" xref="S2.SS1.p3.3.m3.1.1.2.cmml">T</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S2.SS1.p3.3.m3.1.1.1" xref="S2.SS1.p3.3.m3.1.1.1.cmml">Ã—</mo><mi mathsize="90%" id="S2.SS1.p3.3.m3.1.1.3" xref="S2.SS1.p3.3.m3.1.1.3.cmml">U</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><apply id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1"><times id="S2.SS1.p3.3.m3.1.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1.1"></times><ci id="S2.SS1.p3.3.m3.1.1.2.cmml" xref="S2.SS1.p3.3.m3.1.1.2">ğ‘‡</ci><ci id="S2.SS1.p3.3.m3.1.1.3.cmml" xref="S2.SS1.p3.3.m3.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">T\times U</annotation></semantics></math><span id="S2.SS1.p3.3.13" class="ltx_text" style="font-size:90%;"> logits. The </span><span id="S2.SS1.p3.3.14" class="ltx_text" style="font-size:90%;">RNNâ€“T</span><span id="S2.SS1.p3.3.15" class="ltx_text" style="font-size:90%;"> loss is calculated as the sum of probabilities for all paths using a </span><span id="S2.SS1.p3.3.16" class="ltx_text" style="font-size:90%;">forwardâ€“backward</span><span id="S2.SS1.p3.3.17" class="ltx_text" style="font-size:90%;"> algorithm. The </span><span id="S2.SS1.p3.3.18" class="ltx_text" style="font-size:90%;">RNNâ€“T</span><span id="S2.SS1.p3.3.19" class="ltx_text" style="font-size:90%;"> loss function is written as</span></p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\lambda_{\rm RNN-T}=-\sum_{i}\log{P(\bm{y}|{\rm x})}," display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><msub id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.E1.m1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.3.2.cmml">Î»</mi><mrow id="S2.E1.m1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.3.3.cmml"><mi mathsize="90%" id="S2.E1.m1.1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.3.3.2.cmml">RNN</mi><mo mathsize="90%" id="S2.E1.m1.1.1.1.1.3.3.1" xref="S2.E1.m1.1.1.1.1.3.3.1.cmml">âˆ’</mo><mi mathsize="90%" mathvariant="normal" id="S2.E1.m1.1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.3.3.3.cmml">T</mi></mrow></msub><mo mathsize="90%" id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mo mathsize="90%" id="S2.E1.m1.1.1.1.1.1a" xref="S2.E1.m1.1.1.1.1.1.cmml">âˆ’</mo><mrow id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml"><munder id="S2.E1.m1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" id="S2.E1.m1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.2.2.cmml">âˆ‘</mo><mi mathsize="90%" id="S2.E1.m1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.2.3.cmml">i</mi></munder><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.E1.m1.1.1.1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.E1.m1.1.1.1.1.1.1.1.3a" xref="S2.E1.m1.1.1.1.1.1.1.1.3.cmml">â¡</mo><mi mathsize="90%" id="S2.E1.m1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">ğ’š</mi><mo fence="false" mathsize="90%" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi mathsize="90%" mathvariant="normal" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo maxsize="90%" minsize="90%" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo mathsize="90%" id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"></eq><apply id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2">ğœ†</ci><apply id="S2.E1.m1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3"><minus id="S2.E1.m1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.3.1"></minus><ci id="S2.E1.m1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.3.2">RNN</ci><ci id="S2.E1.m1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3.3">T</ci></apply></apply><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1"></minus><apply id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><apply id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.2"></sum><ci id="S2.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3"><log id="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1"></log><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2">ğ‘ƒ</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2">ğ’š</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3">x</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\lambda_{\rm RNN-T}=-\sum_{i}\log{P(\bm{y}|{\rm x})},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.3" class="ltx_Math" alttext="P(\bm{y}|{\rm x})=\sum_{\bm{J}\in\mathcal{Z}(\bm{y},T)}P(J|{\rm x})," display="block"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1.1" xref="S2.E2.m1.3.3.1.1.1.cmml"><mi mathsize="90%" id="S2.E2.m1.3.3.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E2.m1.3.3.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S2.E2.m1.3.3.1.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.cmml">ğ’š</mi><mo fence="false" mathsize="90%" id="S2.E2.m1.3.3.1.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.cmml">|</mo><mi mathsize="90%" mathvariant="normal" id="S2.E2.m1.3.3.1.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo maxsize="90%" minsize="90%" id="S2.E2.m1.3.3.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" rspace="0.111em" id="S2.E2.m1.3.3.1.1.3" xref="S2.E2.m1.3.3.1.1.3.cmml">=</mo><mrow id="S2.E2.m1.3.3.1.1.2" xref="S2.E2.m1.3.3.1.1.2.cmml"><munder id="S2.E2.m1.3.3.1.1.2.2" xref="S2.E2.m1.3.3.1.1.2.2.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" id="S2.E2.m1.3.3.1.1.2.2.2" xref="S2.E2.m1.3.3.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.2.cmml"><mi mathsize="90%" id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.4.cmml">ğ‘±</mi><mo mathsize="90%" id="S2.E2.m1.2.2.2.3" xref="S2.E2.m1.2.2.2.3.cmml">âˆˆ</mo><mrow id="S2.E2.m1.2.2.2.5" xref="S2.E2.m1.2.2.2.5.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S2.E2.m1.2.2.2.5.2" xref="S2.E2.m1.2.2.2.5.2.cmml">ğ’µ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.5.1" xref="S2.E2.m1.2.2.2.5.1.cmml">â€‹</mo><mrow id="S2.E2.m1.2.2.2.5.3.2" xref="S2.E2.m1.2.2.2.5.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E2.m1.2.2.2.5.3.2.1" xref="S2.E2.m1.2.2.2.5.3.1.cmml">(</mo><mi mathsize="90%" id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">ğ’š</mi><mo mathsize="90%" id="S2.E2.m1.2.2.2.5.3.2.2" xref="S2.E2.m1.2.2.2.5.3.1.cmml">,</mo><mi mathsize="90%" id="S2.E2.m1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.cmml">T</mi><mo maxsize="90%" minsize="90%" id="S2.E2.m1.2.2.2.5.3.2.3" xref="S2.E2.m1.2.2.2.5.3.1.cmml">)</mo></mrow></mrow></mrow></munder><mrow id="S2.E2.m1.3.3.1.1.2.1" xref="S2.E2.m1.3.3.1.1.2.1.cmml"><mi mathsize="90%" id="S2.E2.m1.3.3.1.1.2.1.3" xref="S2.E2.m1.3.3.1.1.2.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.1.2.1.2" xref="S2.E2.m1.3.3.1.1.2.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.3.3.1.1.2.1.1.1" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E2.m1.3.3.1.1.2.1.1.1.2" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.3.3.1.1.2.1.1.1.1" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.cmml"><mi mathsize="90%" id="S2.E2.m1.3.3.1.1.2.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.2.cmml">J</mi><mo fence="false" mathsize="90%" id="S2.E2.m1.3.3.1.1.2.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.1.cmml">|</mo><mi mathsize="90%" mathvariant="normal" id="S2.E2.m1.3.3.1.1.2.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.3.cmml">x</mi></mrow><mo maxsize="90%" minsize="90%" id="S2.E2.m1.3.3.1.1.2.1.1.1.3" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo mathsize="90%" id="S2.E2.m1.3.3.1.2" xref="S2.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1"><eq id="S2.E2.m1.3.3.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.3"></eq><apply id="S2.E2.m1.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1"><times id="S2.E2.m1.3.3.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.2"></times><ci id="S2.E2.m1.3.3.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.3">ğ‘ƒ</ci><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2">ğ’š</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3">x</ci></apply></apply><apply id="S2.E2.m1.3.3.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2"><apply id="S2.E2.m1.3.3.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.2.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2.2">subscript</csymbol><sum id="S2.E2.m1.3.3.1.1.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2.2"></sum><apply id="S2.E2.m1.2.2.2.cmml" xref="S2.E2.m1.2.2.2"><in id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.3"></in><ci id="S2.E2.m1.2.2.2.4.cmml" xref="S2.E2.m1.2.2.2.4">ğ‘±</ci><apply id="S2.E2.m1.2.2.2.5.cmml" xref="S2.E2.m1.2.2.2.5"><times id="S2.E2.m1.2.2.2.5.1.cmml" xref="S2.E2.m1.2.2.2.5.1"></times><ci id="S2.E2.m1.2.2.2.5.2.cmml" xref="S2.E2.m1.2.2.2.5.2">ğ’µ</ci><interval closure="open" id="S2.E2.m1.2.2.2.5.3.1.cmml" xref="S2.E2.m1.2.2.2.5.3.2"><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">ğ’š</ci><ci id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2">ğ‘‡</ci></interval></apply></apply></apply><apply id="S2.E2.m1.3.3.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2.1"><times id="S2.E2.m1.3.3.1.1.2.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2.1.2"></times><ci id="S2.E2.m1.3.3.1.1.2.1.3.cmml" xref="S2.E2.m1.3.3.1.1.2.1.3">ğ‘ƒ</ci><apply id="S2.E2.m1.3.3.1.1.2.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.3.3.1.1.2.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.1">conditional</csymbol><ci id="S2.E2.m1.3.3.1.1.2.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.2">ğ½</ci><ci id="S2.E2.m1.3.3.1.1.2.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1.1.3">x</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">P(\bm{y}|{\rm x})=\sum_{\bm{J}\in\mathcal{Z}(\bm{y},T)}P(J|{\rm x}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p3.5" class="ltx_p"><span id="S2.SS1.p3.5.1" class="ltx_text" style="font-size:90%;">where </span><math id="S2.SS1.p3.4.m1.2" class="ltx_Math" alttext="\mathcal{Z}(\bm{y},T)" display="inline"><semantics id="S2.SS1.p3.4.m1.2a"><mrow id="S2.SS1.p3.4.m1.2.3" xref="S2.SS1.p3.4.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S2.SS1.p3.4.m1.2.3.2" xref="S2.SS1.p3.4.m1.2.3.2.cmml">ğ’µ</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.4.m1.2.3.1" xref="S2.SS1.p3.4.m1.2.3.1.cmml">â€‹</mo><mrow id="S2.SS1.p3.4.m1.2.3.3.2" xref="S2.SS1.p3.4.m1.2.3.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.SS1.p3.4.m1.2.3.3.2.1" xref="S2.SS1.p3.4.m1.2.3.3.1.cmml">(</mo><mi mathsize="90%" id="S2.SS1.p3.4.m1.1.1" xref="S2.SS1.p3.4.m1.1.1.cmml">ğ’š</mi><mo mathsize="90%" id="S2.SS1.p3.4.m1.2.3.3.2.2" xref="S2.SS1.p3.4.m1.2.3.3.1.cmml">,</mo><mi mathsize="90%" id="S2.SS1.p3.4.m1.2.2" xref="S2.SS1.p3.4.m1.2.2.cmml">T</mi><mo maxsize="90%" minsize="90%" id="S2.SS1.p3.4.m1.2.3.3.2.3" xref="S2.SS1.p3.4.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m1.2b"><apply id="S2.SS1.p3.4.m1.2.3.cmml" xref="S2.SS1.p3.4.m1.2.3"><times id="S2.SS1.p3.4.m1.2.3.1.cmml" xref="S2.SS1.p3.4.m1.2.3.1"></times><ci id="S2.SS1.p3.4.m1.2.3.2.cmml" xref="S2.SS1.p3.4.m1.2.3.2">ğ’µ</ci><interval closure="open" id="S2.SS1.p3.4.m1.2.3.3.1.cmml" xref="S2.SS1.p3.4.m1.2.3.3.2"><ci id="S2.SS1.p3.4.m1.1.1.cmml" xref="S2.SS1.p3.4.m1.1.1">ğ’š</ci><ci id="S2.SS1.p3.4.m1.2.2.cmml" xref="S2.SS1.p3.4.m1.2.2">ğ‘‡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m1.2c">\mathcal{Z}(\bm{y},T)</annotation></semantics></math><span id="S2.SS1.p3.5.2" class="ltx_text" style="font-size:90%;"> is the set of all alignments of length </span><math id="S2.SS1.p3.5.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS1.p3.5.m2.1a"><mi mathsize="90%" id="S2.SS1.p3.5.m2.1.1" xref="S2.SS1.p3.5.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m2.1b"><ci id="S2.SS1.p3.5.m2.1.1.cmml" xref="S2.SS1.p3.5.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m2.1c">T</annotation></semantics></math><span id="S2.SS1.p3.5.3" class="ltx_text" style="font-size:90%;"> for the token sequence.</span></p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Self-supervised learning based on wav2vec 2.0 framework</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.4" class="ltx_p"><span id="S2.SS2.p1.4.1" class="ltx_text" style="font-size:90%;">We next describe </span><span id="S2.SS2.p1.4.2" class="ltx_text" style="font-size:90%;">self-supervised</span><span id="S2.SS2.p1.4.3" class="ltx_text" style="font-size:90%;"> learning based on the wav2vec 2.0 framework. In wav2vec 2.0 </span><span id="S2.SS2.p1.4.4" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S2.SS2.p1.4.5" class="ltx_text" style="font-size:90%;">, the audio encoder is trained by minimizing the contrastive loss. Given target quantized feature </span><math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="{\bm{q}}_{t}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><msub id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi mathsize="90%" id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">ğ’’</mi><mi mathsize="90%" id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">ğ’’</ci><ci id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">{\bm{q}}_{t}</annotation></semantics></math><span id="S2.SS2.p1.4.6" class="ltx_text" style="font-size:90%;"> and </span><math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mi mathsize="90%" id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">K</annotation></semantics></math><span id="S2.SS2.p1.4.7" class="ltx_text" style="font-size:90%;"> distractors (non-target quantized features), the model must identify the true quantized feature among </span><math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="K+1" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mrow id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi mathsize="90%" id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">K</mi><mo mathsize="90%" id="S2.SS2.p1.3.m3.1.1.1" xref="S2.SS2.p1.3.m3.1.1.1.cmml">+</mo><mn mathsize="90%" id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><plus id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1.1"></plus><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">ğ¾</ci><cn type="integer" id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">K+1</annotation></semantics></math><span id="S2.SS2.p1.4.8" class="ltx_text" style="font-size:90%;"> quantized features </span><math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="{\bm{\tilde{q}}\in\bm{Q}_{t}}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><mrow id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mover accent="true" id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml"><mi mathsize="90%" id="S2.SS2.p1.4.m4.1.1.2.2" xref="S2.SS2.p1.4.m4.1.1.2.2.cmml">ğ’’</mi><mo class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S2.SS2.p1.4.m4.1.1.2.1" xref="S2.SS2.p1.4.m4.1.1.2.1.cmml">~</mo></mover><mo mathsize="90%" id="S2.SS2.p1.4.m4.1.1.1" xref="S2.SS2.p1.4.m4.1.1.1.cmml">âˆˆ</mo><msub id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml"><mi mathsize="90%" id="S2.SS2.p1.4.m4.1.1.3.2" xref="S2.SS2.p1.4.m4.1.1.3.2.cmml">ğ‘¸</mi><mi mathsize="90%" id="S2.SS2.p1.4.m4.1.1.3.3" xref="S2.SS2.p1.4.m4.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><in id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1.1"></in><apply id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2"><ci id="S2.SS2.p1.4.m4.1.1.2.1.cmml" xref="S2.SS2.p1.4.m4.1.1.2.1">bold-~</ci><ci id="S2.SS2.p1.4.m4.1.1.2.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2.2">ğ’’</ci></apply><apply id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.3.1.cmml" xref="S2.SS2.p1.4.m4.1.1.3">subscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.3.2.cmml" xref="S2.SS2.p1.4.m4.1.1.3.2">ğ‘¸</ci><ci id="S2.SS2.p1.4.m4.1.1.3.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">{\bm{\tilde{q}}\in\bm{Q}_{t}}</annotation></semantics></math><span id="S2.SS2.p1.4.9" class="ltx_text" style="font-size:90%;">.
The contrastive loss is calculated as</span></p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.5" class="ltx_Math" alttext="\lambda=-\log{\frac{\exp(sim(\bm{f}_{t},\bm{q}_{t}))}{\sum_{\bm{\tilde{q}}\sim\bm{Q}_{t}}\exp(sim(\bm{f}_{t},\bm{\tilde{q}}_{t}))}}," display="block"><semantics id="S2.E3.m1.5a"><mrow id="S2.E3.m1.5.5.1" xref="S2.E3.m1.5.5.1.1.cmml"><mrow id="S2.E3.m1.5.5.1.1" xref="S2.E3.m1.5.5.1.1.cmml"><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.2" xref="S2.E3.m1.5.5.1.1.2.cmml">Î»</mi><mo mathsize="90%" id="S2.E3.m1.5.5.1.1.1" xref="S2.E3.m1.5.5.1.1.1.cmml">=</mo><mrow id="S2.E3.m1.5.5.1.1.3" xref="S2.E3.m1.5.5.1.1.3.cmml"><mo mathsize="90%" rspace="0.167em" id="S2.E3.m1.5.5.1.1.3a" xref="S2.E3.m1.5.5.1.1.3.cmml">âˆ’</mo><mrow id="S2.E3.m1.5.5.1.1.3.2" xref="S2.E3.m1.5.5.1.1.3.2.cmml"><mi mathsize="90%" id="S2.E3.m1.5.5.1.1.3.2.1" xref="S2.E3.m1.5.5.1.1.3.2.1.cmml">log</mi><mo lspace="0.167em" id="S2.E3.m1.5.5.1.1.3.2a" xref="S2.E3.m1.5.5.1.1.3.2.cmml">â¡</mo><mfrac id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml"><mrow id="S2.E3.m1.2.2.2.2" xref="S2.E3.m1.2.2.2.3.cmml"><mi mathsize="90%" id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">exp</mi><mo id="S2.E3.m1.2.2.2.2a" xref="S2.E3.m1.2.2.2.3.cmml">â¡</mo><mrow id="S2.E3.m1.2.2.2.2.1" xref="S2.E3.m1.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.2.2.2.2.1.2" xref="S2.E3.m1.2.2.2.3.cmml">(</mo><mrow id="S2.E3.m1.2.2.2.2.1.1" xref="S2.E3.m1.2.2.2.2.1.1.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.1.1.4" xref="S2.E3.m1.2.2.2.2.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.3.cmml">â€‹</mo><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.1.1.5" xref="S2.E3.m1.2.2.2.2.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.3a" xref="S2.E3.m1.2.2.2.2.1.1.3.cmml">â€‹</mo><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.1.1.6" xref="S2.E3.m1.2.2.2.2.1.1.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.3b" xref="S2.E3.m1.2.2.2.2.1.1.3.cmml">â€‹</mo><mrow id="S2.E3.m1.2.2.2.2.1.1.2.2" xref="S2.E3.m1.2.2.2.2.1.1.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.2.2.2.2.1.1.2.2.3" xref="S2.E3.m1.2.2.2.2.1.1.2.3.cmml">(</mo><msub id="S2.E3.m1.2.2.2.2.1.1.1.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.1.1.1.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.2.cmml">ğ’‡</mi><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.1.1.1.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.3.cmml">t</mi></msub><mo mathsize="90%" id="S2.E3.m1.2.2.2.2.1.1.2.2.4" xref="S2.E3.m1.2.2.2.2.1.1.2.3.cmml">,</mo><msub id="S2.E3.m1.2.2.2.2.1.1.2.2.2" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.1.1.2.2.2.2" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2.2.cmml">ğ’’</mi><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.1.1.2.2.2.3" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2.3.cmml">t</mi></msub><mo maxsize="90%" minsize="90%" id="S2.E3.m1.2.2.2.2.1.1.2.2.5" xref="S2.E3.m1.2.2.2.2.1.1.2.3.cmml">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="S2.E3.m1.2.2.2.2.1.3" xref="S2.E3.m1.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S2.E3.m1.4.4.4" xref="S2.E3.m1.4.4.4.cmml"><msub id="S2.E3.m1.4.4.4.3" xref="S2.E3.m1.4.4.4.3.cmml"><mo maxsize="90%" minsize="90%" stretchy="true" id="S2.E3.m1.4.4.4.3.2" xref="S2.E3.m1.4.4.4.3.2.cmml">âˆ‘</mo><mrow id="S2.E3.m1.4.4.4.3.3" xref="S2.E3.m1.4.4.4.3.3.cmml"><mover accent="true" id="S2.E3.m1.4.4.4.3.3.2" xref="S2.E3.m1.4.4.4.3.3.2.cmml"><mi mathsize="90%" id="S2.E3.m1.4.4.4.3.3.2.2" xref="S2.E3.m1.4.4.4.3.3.2.2.cmml">ğ’’</mi><mo class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S2.E3.m1.4.4.4.3.3.2.1" xref="S2.E3.m1.4.4.4.3.3.2.1.cmml">~</mo></mover><mo mathsize="90%" id="S2.E3.m1.4.4.4.3.3.1" xref="S2.E3.m1.4.4.4.3.3.1.cmml">âˆ¼</mo><msub id="S2.E3.m1.4.4.4.3.3.3" xref="S2.E3.m1.4.4.4.3.3.3.cmml"><mi mathsize="90%" id="S2.E3.m1.4.4.4.3.3.3.2" xref="S2.E3.m1.4.4.4.3.3.3.2.cmml">ğ‘¸</mi><mi mathsize="90%" id="S2.E3.m1.4.4.4.3.3.3.3" xref="S2.E3.m1.4.4.4.3.3.3.3.cmml">t</mi></msub></mrow></msub><mrow id="S2.E3.m1.4.4.4.2.1" xref="S2.E3.m1.4.4.4.2.2.cmml"><mi mathsize="90%" id="S2.E3.m1.3.3.3.1" xref="S2.E3.m1.3.3.3.1.cmml">exp</mi><mo id="S2.E3.m1.4.4.4.2.1a" xref="S2.E3.m1.4.4.4.2.2.cmml">â¡</mo><mrow id="S2.E3.m1.4.4.4.2.1.1" xref="S2.E3.m1.4.4.4.2.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.4.4.4.2.1.1.2" xref="S2.E3.m1.4.4.4.2.2.cmml">(</mo><mrow id="S2.E3.m1.4.4.4.2.1.1.1" xref="S2.E3.m1.4.4.4.2.1.1.1.cmml"><mi mathsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.4" xref="S2.E3.m1.4.4.4.2.1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.4.2.1.1.1.3" xref="S2.E3.m1.4.4.4.2.1.1.1.3.cmml">â€‹</mo><mi mathsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.5" xref="S2.E3.m1.4.4.4.2.1.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.4.2.1.1.1.3a" xref="S2.E3.m1.4.4.4.2.1.1.1.3.cmml">â€‹</mo><mi mathsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.6" xref="S2.E3.m1.4.4.4.2.1.1.1.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.4.2.1.1.1.3b" xref="S2.E3.m1.4.4.4.2.1.1.1.3.cmml">â€‹</mo><mrow id="S2.E3.m1.4.4.4.2.1.1.1.2.2" xref="S2.E3.m1.4.4.4.2.1.1.1.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.2.2.3" xref="S2.E3.m1.4.4.4.2.1.1.1.2.3.cmml">(</mo><msub id="S2.E3.m1.4.4.4.2.1.1.1.1.1.1" xref="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.2.cmml">ğ’‡</mi><mi mathsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.3.cmml">t</mi></msub><mo mathsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.2.2.4" xref="S2.E3.m1.4.4.4.2.1.1.1.2.3.cmml">,</mo><msub id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.cmml"><mover accent="true" id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.cmml"><mi mathsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.2" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.2.cmml">ğ’’</mi><mo class="ltx_mathvariant_bold" mathsize="90%" mathvariant="bold" id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.1" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.1.cmml">~</mo></mover><mi mathsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.3" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.3.cmml">t</mi></msub><mo maxsize="90%" minsize="90%" id="S2.E3.m1.4.4.4.2.1.1.1.2.2.5" xref="S2.E3.m1.4.4.4.2.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="S2.E3.m1.4.4.4.2.1.1.3" xref="S2.E3.m1.4.4.4.2.2.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow></mrow></mrow><mo mathsize="90%" id="S2.E3.m1.5.5.1.2" xref="S2.E3.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.5b"><apply id="S2.E3.m1.5.5.1.1.cmml" xref="S2.E3.m1.5.5.1"><eq id="S2.E3.m1.5.5.1.1.1.cmml" xref="S2.E3.m1.5.5.1.1.1"></eq><ci id="S2.E3.m1.5.5.1.1.2.cmml" xref="S2.E3.m1.5.5.1.1.2">ğœ†</ci><apply id="S2.E3.m1.5.5.1.1.3.cmml" xref="S2.E3.m1.5.5.1.1.3"><minus id="S2.E3.m1.5.5.1.1.3.1.cmml" xref="S2.E3.m1.5.5.1.1.3"></minus><apply id="S2.E3.m1.5.5.1.1.3.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2"><log id="S2.E3.m1.5.5.1.1.3.2.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1"></log><apply id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4"><divide id="S2.E3.m1.4.4.5.cmml" xref="S2.E3.m1.4.4"></divide><apply id="S2.E3.m1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.2"><exp id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1"></exp><apply id="S2.E3.m1.2.2.2.2.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1"><times id="S2.E3.m1.2.2.2.2.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3"></times><ci id="S2.E3.m1.2.2.2.2.1.1.4.cmml" xref="S2.E3.m1.2.2.2.2.1.1.4">ğ‘ </ci><ci id="S2.E3.m1.2.2.2.2.1.1.5.cmml" xref="S2.E3.m1.2.2.2.2.1.1.5">ğ‘–</ci><ci id="S2.E3.m1.2.2.2.2.1.1.6.cmml" xref="S2.E3.m1.2.2.2.2.1.1.6">ğ‘š</ci><interval closure="open" id="S2.E3.m1.2.2.2.2.1.1.2.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2"><apply id="S2.E3.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.2">ğ’‡</ci><ci id="S2.E3.m1.2.2.2.2.1.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S2.E3.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.2.2.2.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2.2">ğ’’</ci><ci id="S2.E3.m1.2.2.2.2.1.1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply><apply id="S2.E3.m1.4.4.4.cmml" xref="S2.E3.m1.4.4.4"><apply id="S2.E3.m1.4.4.4.3.cmml" xref="S2.E3.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.4.3.1.cmml" xref="S2.E3.m1.4.4.4.3">subscript</csymbol><sum id="S2.E3.m1.4.4.4.3.2.cmml" xref="S2.E3.m1.4.4.4.3.2"></sum><apply id="S2.E3.m1.4.4.4.3.3.cmml" xref="S2.E3.m1.4.4.4.3.3"><csymbol cd="latexml" id="S2.E3.m1.4.4.4.3.3.1.cmml" xref="S2.E3.m1.4.4.4.3.3.1">similar-to</csymbol><apply id="S2.E3.m1.4.4.4.3.3.2.cmml" xref="S2.E3.m1.4.4.4.3.3.2"><ci id="S2.E3.m1.4.4.4.3.3.2.1.cmml" xref="S2.E3.m1.4.4.4.3.3.2.1">bold-~</ci><ci id="S2.E3.m1.4.4.4.3.3.2.2.cmml" xref="S2.E3.m1.4.4.4.3.3.2.2">ğ’’</ci></apply><apply id="S2.E3.m1.4.4.4.3.3.3.cmml" xref="S2.E3.m1.4.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.4.3.3.3.1.cmml" xref="S2.E3.m1.4.4.4.3.3.3">subscript</csymbol><ci id="S2.E3.m1.4.4.4.3.3.3.2.cmml" xref="S2.E3.m1.4.4.4.3.3.3.2">ğ‘¸</ci><ci id="S2.E3.m1.4.4.4.3.3.3.3.cmml" xref="S2.E3.m1.4.4.4.3.3.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S2.E3.m1.4.4.4.2.2.cmml" xref="S2.E3.m1.4.4.4.2.1"><exp id="S2.E3.m1.3.3.3.1.cmml" xref="S2.E3.m1.3.3.3.1"></exp><apply id="S2.E3.m1.4.4.4.2.1.1.1.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1"><times id="S2.E3.m1.4.4.4.2.1.1.1.3.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.3"></times><ci id="S2.E3.m1.4.4.4.2.1.1.1.4.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.4">ğ‘ </ci><ci id="S2.E3.m1.4.4.4.2.1.1.1.5.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.5">ğ‘–</ci><ci id="S2.E3.m1.4.4.4.2.1.1.1.6.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.6">ğ‘š</ci><interval closure="open" id="S2.E3.m1.4.4.4.2.1.1.1.2.3.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2"><apply id="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.2">ğ’‡</ci><ci id="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.1.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2">subscript</csymbol><apply id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2"><ci id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.1.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.1">bold-~</ci><ci id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.2.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.2.2">ğ’’</ci></apply><ci id="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.3.cmml" xref="S2.E3.m1.4.4.4.2.1.1.1.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.5c">\lambda=-\log{\frac{\exp(sim(\bm{f}_{t},\bm{q}_{t}))}{\sum_{\bm{\tilde{q}}\sim\bm{Q}_{t}}\exp(sim(\bm{f}_{t},\bm{\tilde{q}}_{t}))}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p1.7" class="ltx_p"><span id="S2.SS2.p1.7.1" class="ltx_text" style="font-size:90%;">where
</span><math id="S2.SS2.p1.5.m1.1" class="ltx_Math" alttext="\bm{f}" display="inline"><semantics id="S2.SS2.p1.5.m1.1a"><mi mathsize="90%" id="S2.SS2.p1.5.m1.1.1" xref="S2.SS2.p1.5.m1.1.1.cmml">ğ’‡</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m1.1b"><ci id="S2.SS2.p1.5.m1.1.1.cmml" xref="S2.SS2.p1.5.m1.1.1">ğ’‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m1.1c">\bm{f}</annotation></semantics></math><span id="S2.SS2.p1.7.2" class="ltx_text" style="font-size:90%;"> denotes hidden vectors from the masked audio encoder and </span><math id="S2.SS2.p1.6.m2.1" class="ltx_Math" alttext="sim" display="inline"><semantics id="S2.SS2.p1.6.m2.1a"><mrow id="S2.SS2.p1.6.m2.1.1" xref="S2.SS2.p1.6.m2.1.1.cmml"><mi mathsize="90%" id="S2.SS2.p1.6.m2.1.1.2" xref="S2.SS2.p1.6.m2.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m2.1.1.1" xref="S2.SS2.p1.6.m2.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="S2.SS2.p1.6.m2.1.1.3" xref="S2.SS2.p1.6.m2.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.6.m2.1.1.1a" xref="S2.SS2.p1.6.m2.1.1.1.cmml">â€‹</mo><mi mathsize="90%" id="S2.SS2.p1.6.m2.1.1.4" xref="S2.SS2.p1.6.m2.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m2.1b"><apply id="S2.SS2.p1.6.m2.1.1.cmml" xref="S2.SS2.p1.6.m2.1.1"><times id="S2.SS2.p1.6.m2.1.1.1.cmml" xref="S2.SS2.p1.6.m2.1.1.1"></times><ci id="S2.SS2.p1.6.m2.1.1.2.cmml" xref="S2.SS2.p1.6.m2.1.1.2">ğ‘ </ci><ci id="S2.SS2.p1.6.m2.1.1.3.cmml" xref="S2.SS2.p1.6.m2.1.1.3">ğ‘–</ci><ci id="S2.SS2.p1.6.m2.1.1.4.cmml" xref="S2.SS2.p1.6.m2.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m2.1c">sim</annotation></semantics></math><span id="S2.SS2.p1.7.3" class="ltx_text" style="font-size:90%;"> is a function for calculating the cosine similarity between two vectors: </span><math id="S2.SS2.p1.7.m3.4" class="ltx_Math" alttext="sim(\bm{a},\bm{b})=\bm{a}^{T}\bm{b}/||\bm{a}||||\bm{b}||" display="inline"><semantics id="S2.SS2.p1.7.m3.4a"><mrow id="S2.SS2.p1.7.m3.4.5" xref="S2.SS2.p1.7.m3.4.5.cmml"><mrow id="S2.SS2.p1.7.m3.4.5.2" xref="S2.SS2.p1.7.m3.4.5.2.cmml"><mi mathsize="90%" id="S2.SS2.p1.7.m3.4.5.2.2" xref="S2.SS2.p1.7.m3.4.5.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m3.4.5.2.1" xref="S2.SS2.p1.7.m3.4.5.2.1.cmml">â€‹</mo><mi mathsize="90%" id="S2.SS2.p1.7.m3.4.5.2.3" xref="S2.SS2.p1.7.m3.4.5.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m3.4.5.2.1a" xref="S2.SS2.p1.7.m3.4.5.2.1.cmml">â€‹</mo><mi mathsize="90%" id="S2.SS2.p1.7.m3.4.5.2.4" xref="S2.SS2.p1.7.m3.4.5.2.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m3.4.5.2.1b" xref="S2.SS2.p1.7.m3.4.5.2.1.cmml">â€‹</mo><mrow id="S2.SS2.p1.7.m3.4.5.2.5.2" xref="S2.SS2.p1.7.m3.4.5.2.5.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.SS2.p1.7.m3.4.5.2.5.2.1" xref="S2.SS2.p1.7.m3.4.5.2.5.1.cmml">(</mo><mi mathsize="90%" id="S2.SS2.p1.7.m3.1.1" xref="S2.SS2.p1.7.m3.1.1.cmml">ğ’‚</mi><mo mathsize="90%" id="S2.SS2.p1.7.m3.4.5.2.5.2.2" xref="S2.SS2.p1.7.m3.4.5.2.5.1.cmml">,</mo><mi mathsize="90%" id="S2.SS2.p1.7.m3.2.2" xref="S2.SS2.p1.7.m3.2.2.cmml">ğ’ƒ</mi><mo maxsize="90%" minsize="90%" id="S2.SS2.p1.7.m3.4.5.2.5.2.3" xref="S2.SS2.p1.7.m3.4.5.2.5.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S2.SS2.p1.7.m3.4.5.1" xref="S2.SS2.p1.7.m3.4.5.1.cmml">=</mo><mrow id="S2.SS2.p1.7.m3.4.5.3" xref="S2.SS2.p1.7.m3.4.5.3.cmml"><mrow id="S2.SS2.p1.7.m3.4.5.3.2" xref="S2.SS2.p1.7.m3.4.5.3.2.cmml"><mrow id="S2.SS2.p1.7.m3.4.5.3.2.2" xref="S2.SS2.p1.7.m3.4.5.3.2.2.cmml"><msup id="S2.SS2.p1.7.m3.4.5.3.2.2.2" xref="S2.SS2.p1.7.m3.4.5.3.2.2.2.cmml"><mi mathsize="90%" id="S2.SS2.p1.7.m3.4.5.3.2.2.2.2" xref="S2.SS2.p1.7.m3.4.5.3.2.2.2.2.cmml">ğ’‚</mi><mi mathsize="90%" id="S2.SS2.p1.7.m3.4.5.3.2.2.2.3" xref="S2.SS2.p1.7.m3.4.5.3.2.2.2.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m3.4.5.3.2.2.1" xref="S2.SS2.p1.7.m3.4.5.3.2.2.1.cmml">â€‹</mo><mi mathsize="90%" id="S2.SS2.p1.7.m3.4.5.3.2.2.3" xref="S2.SS2.p1.7.m3.4.5.3.2.2.3.cmml">ğ’ƒ</mi></mrow><mo maxsize="90%" minsize="90%" stretchy="true" symmetric="true" id="S2.SS2.p1.7.m3.4.5.3.2.1" xref="S2.SS2.p1.7.m3.4.5.3.2.1.cmml">/</mo><mrow id="S2.SS2.p1.7.m3.4.5.3.2.3.2" xref="S2.SS2.p1.7.m3.4.5.3.2.3.1.cmml"><mo stretchy="false" id="S2.SS2.p1.7.m3.4.5.3.2.3.2.1" xref="S2.SS2.p1.7.m3.4.5.3.2.3.1.1.cmml">â€–</mo><mi mathsize="90%" id="S2.SS2.p1.7.m3.3.3" xref="S2.SS2.p1.7.m3.3.3.cmml">ğ’‚</mi><mo stretchy="false" id="S2.SS2.p1.7.m3.4.5.3.2.3.2.2" xref="S2.SS2.p1.7.m3.4.5.3.2.3.1.1.cmml">â€–</mo></mrow></mrow><mo lspace="0em" rspace="0em" id="S2.SS2.p1.7.m3.4.5.3.1" xref="S2.SS2.p1.7.m3.4.5.3.1.cmml">â€‹</mo><mrow id="S2.SS2.p1.7.m3.4.5.3.3.2" xref="S2.SS2.p1.7.m3.4.5.3.3.1.cmml"><mo stretchy="false" id="S2.SS2.p1.7.m3.4.5.3.3.2.1" xref="S2.SS2.p1.7.m3.4.5.3.3.1.1.cmml">â€–</mo><mi mathsize="90%" id="S2.SS2.p1.7.m3.4.4" xref="S2.SS2.p1.7.m3.4.4.cmml">ğ’ƒ</mi><mo stretchy="false" id="S2.SS2.p1.7.m3.4.5.3.3.2.2" xref="S2.SS2.p1.7.m3.4.5.3.3.1.1.cmml">â€–</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m3.4b"><apply id="S2.SS2.p1.7.m3.4.5.cmml" xref="S2.SS2.p1.7.m3.4.5"><eq id="S2.SS2.p1.7.m3.4.5.1.cmml" xref="S2.SS2.p1.7.m3.4.5.1"></eq><apply id="S2.SS2.p1.7.m3.4.5.2.cmml" xref="S2.SS2.p1.7.m3.4.5.2"><times id="S2.SS2.p1.7.m3.4.5.2.1.cmml" xref="S2.SS2.p1.7.m3.4.5.2.1"></times><ci id="S2.SS2.p1.7.m3.4.5.2.2.cmml" xref="S2.SS2.p1.7.m3.4.5.2.2">ğ‘ </ci><ci id="S2.SS2.p1.7.m3.4.5.2.3.cmml" xref="S2.SS2.p1.7.m3.4.5.2.3">ğ‘–</ci><ci id="S2.SS2.p1.7.m3.4.5.2.4.cmml" xref="S2.SS2.p1.7.m3.4.5.2.4">ğ‘š</ci><interval closure="open" id="S2.SS2.p1.7.m3.4.5.2.5.1.cmml" xref="S2.SS2.p1.7.m3.4.5.2.5.2"><ci id="S2.SS2.p1.7.m3.1.1.cmml" xref="S2.SS2.p1.7.m3.1.1">ğ’‚</ci><ci id="S2.SS2.p1.7.m3.2.2.cmml" xref="S2.SS2.p1.7.m3.2.2">ğ’ƒ</ci></interval></apply><apply id="S2.SS2.p1.7.m3.4.5.3.cmml" xref="S2.SS2.p1.7.m3.4.5.3"><times id="S2.SS2.p1.7.m3.4.5.3.1.cmml" xref="S2.SS2.p1.7.m3.4.5.3.1"></times><apply id="S2.SS2.p1.7.m3.4.5.3.2.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2"><divide id="S2.SS2.p1.7.m3.4.5.3.2.1.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.1"></divide><apply id="S2.SS2.p1.7.m3.4.5.3.2.2.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.2"><times id="S2.SS2.p1.7.m3.4.5.3.2.2.1.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.2.1"></times><apply id="S2.SS2.p1.7.m3.4.5.3.2.2.2.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m3.4.5.3.2.2.2.1.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.2.2">superscript</csymbol><ci id="S2.SS2.p1.7.m3.4.5.3.2.2.2.2.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.2.2.2">ğ’‚</ci><ci id="S2.SS2.p1.7.m3.4.5.3.2.2.2.3.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.2.2.3">ğ‘‡</ci></apply><ci id="S2.SS2.p1.7.m3.4.5.3.2.2.3.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.2.3">ğ’ƒ</ci></apply><apply id="S2.SS2.p1.7.m3.4.5.3.2.3.1.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.3.2"><csymbol cd="latexml" id="S2.SS2.p1.7.m3.4.5.3.2.3.1.1.cmml" xref="S2.SS2.p1.7.m3.4.5.3.2.3.2.1">norm</csymbol><ci id="S2.SS2.p1.7.m3.3.3.cmml" xref="S2.SS2.p1.7.m3.3.3">ğ’‚</ci></apply></apply><apply id="S2.SS2.p1.7.m3.4.5.3.3.1.cmml" xref="S2.SS2.p1.7.m3.4.5.3.3.2"><csymbol cd="latexml" id="S2.SS2.p1.7.m3.4.5.3.3.1.1.cmml" xref="S2.SS2.p1.7.m3.4.5.3.3.2.1">norm</csymbol><ci id="S2.SS2.p1.7.m3.4.4.cmml" xref="S2.SS2.p1.7.m3.4.4">ğ’ƒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m3.4c">sim(\bm{a},\bm{b})=\bm{a}^{T}\bm{b}/||\bm{a}||||\bm{b}||</annotation></semantics></math><span id="S2.SS2.p1.7.4" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">An audio encoder consists of Transformer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S2.SS2.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p2.1.4" class="ltx_text" style="font-size:90%;"> or Conformer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S2.SS2.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p2.1.7" class="ltx_text" style="font-size:90%;">. A quantizer consists of a quantization </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p2.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S2.SS2.p2.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p2.1.10" class="ltx_text" style="font-size:90%;"> or linear </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p2.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S2.SS2.p2.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p2.1.13" class="ltx_text" style="font-size:90%;"> layer.</span></p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Self-supervised learning for multi-channel neural transducer</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p"><span id="S3.p1.1.1" class="ltx_text" style="font-size:90%;">For the training of the </span><span id="S3.p1.1.2" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S3.p1.1.3" class="ltx_text" style="font-size:90%;"> audio encoder, we explore three quantization methods: joint quantization, </span><span id="S3.p1.1.4" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S3.p1.1.5" class="ltx_text" style="font-size:90%;"> quantization and </span><span id="S3.p1.1.6" class="ltx_text" style="font-size:90%;">channel-wise quantization</span><span id="S3.p1.1.7" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Joint quantization</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.6" class="ltx_p"><span id="S3.SS1.p1.6.1" class="ltx_text" style="font-size:90%;">FigureÂ </span><a href="#S3.F2" title="Figure 2 â€£ 3.1 Joint quantization â€£ 3 Self-supervised learning for multi-channel neural transducer â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S3.SS1.p1.6.2" class="ltx_text" style="font-size:90%;"> shows joint quantization. In this figure, </span><math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="X^{\rm amplitude}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><msup id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">X</mi><mi mathsize="90%" id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">amplitude</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ‘‹</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">amplitude</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">X^{\rm amplitude}</annotation></semantics></math><span id="S3.SS1.p1.6.3" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="X^{\rm phase}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><msup id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">X</mi><mi mathsize="90%" id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">phase</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ‘‹</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">phase</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">X^{\rm phase}</annotation></semantics></math><span id="S3.SS1.p1.6.4" class="ltx_text" style="font-size:90%;">
are the amplitude and phase features, respectively. </span><math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\bm{f}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi mathsize="90%" id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">ğ’‡</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ’‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\bm{f}</annotation></semantics></math><span id="S3.SS1.p1.6.5" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi mathsize="90%" id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\bm{q}</annotation></semantics></math><span id="S3.SS1.p1.6.6" class="ltx_text" style="font-size:90%;"> are the hidden vector from the masked features and the quantized feature as in figure, respectively. This example shows the case of two channels. In this approach, the quantizer converts concatenated vectors </span><math id="S3.SS1.p1.5.m5.4" class="ltx_Math" alttext="[{X_{1}}^{\rm amplitude};{X_{2}}^{\rm amplitude};{X_{2}}^{\rm amplitude};{X_{2}}^{\rm phase}]" display="inline"><semantics id="S3.SS1.p1.5.m5.4a"><mrow id="S3.SS1.p1.5.m5.4.4.4" xref="S3.SS1.p1.5.m5.4.4.5.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS1.p1.5.m5.4.4.4.5" xref="S3.SS1.p1.5.m5.4.4.5.cmml">[</mo><mmultiscripts id="S3.SS1.p1.5.m5.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p1.5.m5.1.1.1.1.2.2" xref="S3.SS1.p1.5.m5.1.1.1.1.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS1.p1.5.m5.1.1.1.1.2.3" xref="S3.SS1.p1.5.m5.1.1.1.1.2.3.cmml">1</mn><mrow id="S3.SS1.p1.5.m5.1.1.1.1a" xref="S3.SS1.p1.5.m5.1.1.1.1.cmml"></mrow><mrow id="S3.SS1.p1.5.m5.1.1.1.1b" xref="S3.SS1.p1.5.m5.1.1.1.1.cmml"></mrow><mi mathsize="90%" id="S3.SS1.p1.5.m5.1.1.1.1.3" xref="S3.SS1.p1.5.m5.1.1.1.1.3.cmml">amplitude</mi></mmultiscripts><mo mathsize="90%" id="S3.SS1.p1.5.m5.4.4.4.6" xref="S3.SS1.p1.5.m5.4.4.5.cmml">;</mo><mmultiscripts id="S3.SS1.p1.5.m5.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS1.p1.5.m5.2.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS1.p1.5.m5.2.2.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.2.2.2.3.cmml">2</mn><mrow id="S3.SS1.p1.5.m5.2.2.2.2a" xref="S3.SS1.p1.5.m5.2.2.2.2.cmml"></mrow><mrow id="S3.SS1.p1.5.m5.2.2.2.2b" xref="S3.SS1.p1.5.m5.2.2.2.2.cmml"></mrow><mi mathsize="90%" id="S3.SS1.p1.5.m5.2.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.2.2.3.cmml">amplitude</mi></mmultiscripts><mo mathsize="90%" id="S3.SS1.p1.5.m5.4.4.4.7" xref="S3.SS1.p1.5.m5.4.4.5.cmml">;</mo><mmultiscripts id="S3.SS1.p1.5.m5.3.3.3.3" xref="S3.SS1.p1.5.m5.3.3.3.3.cmml"><mi mathsize="90%" id="S3.SS1.p1.5.m5.3.3.3.3.2.2" xref="S3.SS1.p1.5.m5.3.3.3.3.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS1.p1.5.m5.3.3.3.3.2.3" xref="S3.SS1.p1.5.m5.3.3.3.3.2.3.cmml">2</mn><mrow id="S3.SS1.p1.5.m5.3.3.3.3a" xref="S3.SS1.p1.5.m5.3.3.3.3.cmml"></mrow><mrow id="S3.SS1.p1.5.m5.3.3.3.3b" xref="S3.SS1.p1.5.m5.3.3.3.3.cmml"></mrow><mi mathsize="90%" id="S3.SS1.p1.5.m5.3.3.3.3.3" xref="S3.SS1.p1.5.m5.3.3.3.3.3.cmml">amplitude</mi></mmultiscripts><mo mathsize="90%" id="S3.SS1.p1.5.m5.4.4.4.8" xref="S3.SS1.p1.5.m5.4.4.5.cmml">;</mo><mmultiscripts id="S3.SS1.p1.5.m5.4.4.4.4" xref="S3.SS1.p1.5.m5.4.4.4.4.cmml"><mi mathsize="90%" id="S3.SS1.p1.5.m5.4.4.4.4.2.2" xref="S3.SS1.p1.5.m5.4.4.4.4.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS1.p1.5.m5.4.4.4.4.2.3" xref="S3.SS1.p1.5.m5.4.4.4.4.2.3.cmml">2</mn><mrow id="S3.SS1.p1.5.m5.4.4.4.4a" xref="S3.SS1.p1.5.m5.4.4.4.4.cmml"></mrow><mrow id="S3.SS1.p1.5.m5.4.4.4.4b" xref="S3.SS1.p1.5.m5.4.4.4.4.cmml"></mrow><mi mathsize="90%" id="S3.SS1.p1.5.m5.4.4.4.4.3" xref="S3.SS1.p1.5.m5.4.4.4.4.3.cmml">phase</mi></mmultiscripts><mo maxsize="90%" minsize="90%" id="S3.SS1.p1.5.m5.4.4.4.9" xref="S3.SS1.p1.5.m5.4.4.5.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.4b"><list id="S3.SS1.p1.5.m5.4.4.5.cmml" xref="S3.SS1.p1.5.m5.4.4.4"><apply id="S3.SS1.p1.5.m5.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.5.m5.1.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS1.p1.5.m5.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.2.3">1</cn></apply><ci id="S3.SS1.p1.5.m5.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3">amplitude</ci></apply><apply id="S3.SS1.p1.5.m5.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.2.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p1.5.m5.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS1.p1.5.m5.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2.3">2</cn></apply><ci id="S3.SS1.p1.5.m5.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.3">amplitude</ci></apply><apply id="S3.SS1.p1.5.m5.3.3.3.3.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.3.3.3.3.1.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3">superscript</csymbol><apply id="S3.SS1.p1.5.m5.3.3.3.3.2.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.3.3.3.3.2.1.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.3.3.3.3.2.2.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS1.p1.5.m5.3.3.3.3.2.3.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3.2.3">2</cn></apply><ci id="S3.SS1.p1.5.m5.3.3.3.3.3.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3.3">amplitude</ci></apply><apply id="S3.SS1.p1.5.m5.4.4.4.4.cmml" xref="S3.SS1.p1.5.m5.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.4.4.4.4.1.cmml" xref="S3.SS1.p1.5.m5.4.4.4.4">superscript</csymbol><apply id="S3.SS1.p1.5.m5.4.4.4.4.2.cmml" xref="S3.SS1.p1.5.m5.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.4.4.4.4.2.1.cmml" xref="S3.SS1.p1.5.m5.4.4.4.4">subscript</csymbol><ci id="S3.SS1.p1.5.m5.4.4.4.4.2.2.cmml" xref="S3.SS1.p1.5.m5.4.4.4.4.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS1.p1.5.m5.4.4.4.4.2.3.cmml" xref="S3.SS1.p1.5.m5.4.4.4.4.2.3">2</cn></apply><ci id="S3.SS1.p1.5.m5.4.4.4.4.3.cmml" xref="S3.SS1.p1.5.m5.4.4.4.4.3">phase</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.4c">[{X_{1}}^{\rm amplitude};{X_{2}}^{\rm amplitude};{X_{2}}^{\rm amplitude};{X_{2}}^{\rm phase}]</annotation></semantics></math><span id="S3.SS1.p1.6.7" class="ltx_text" style="font-size:90%;"> to quantized vector </span><math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi mathsize="90%" id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\bm{q}</annotation></semantics></math><span id="S3.SS1.p1.6.8" class="ltx_text" style="font-size:90%;">. The quantizer consists of a single linear layer.</span></p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2408.02945/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="189" height="58" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Joint quantization in the case of two channels.</figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F4.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:216.8pt;"><img src="/html/2408.02945/assets/x3.png" id="S3.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="179" height="62" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Feature-wise quantization.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F4.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:216.8pt;"><img src="/html/2408.02945/assets/x4.png" id="S3.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="178" height="85" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Channel-wise quantization.</figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Feature-wise quantization</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.6" class="ltx_p"><span id="S3.SS2.p1.6.1" class="ltx_text" style="font-size:90%;">FigureÂ </span><a href="#S3.F4" title="Figure 4 â€£ 3.1 Joint quantization â€£ 3 Self-supervised learning for multi-channel neural transducer â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S3.SS2.p1.6.2" class="ltx_text" style="font-size:90%;"> shows </span><span id="S3.SS2.p1.6.3" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S3.SS2.p1.6.4" class="ltx_text" style="font-size:90%;"> quantization in the case of two channels. In this method, the quantization module consists of amplitude, phase and joint quantizers. The amplitude quantizer converts amplitude features </span><math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="[{X_{1}}^{\rm amplitude};{X_{2}}^{\rm amplitude}]" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><mrow id="S3.SS2.p1.1.m1.2.2.2" xref="S3.SS2.p1.1.m1.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.1.m1.2.2.2.3" xref="S3.SS2.p1.1.m1.2.2.3.cmml">[</mo><mmultiscripts id="S3.SS2.p1.1.m1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.1.m1.1.1.1.1.2.2" xref="S3.SS2.p1.1.m1.1.1.1.1.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS2.p1.1.m1.1.1.1.1.2.3" xref="S3.SS2.p1.1.m1.1.1.1.1.2.3.cmml">1</mn><mrow id="S3.SS2.p1.1.m1.1.1.1.1a" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml"></mrow><mrow id="S3.SS2.p1.1.m1.1.1.1.1b" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml"></mrow><mi mathsize="90%" id="S3.SS2.p1.1.m1.1.1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.1.1.3.cmml">amplitude</mi></mmultiscripts><mo mathsize="90%" id="S3.SS2.p1.1.m1.2.2.2.4" xref="S3.SS2.p1.1.m1.2.2.3.cmml">;</mo><mmultiscripts id="S3.SS2.p1.1.m1.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.1.m1.2.2.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS2.p1.1.m1.2.2.2.2.2.3" xref="S3.SS2.p1.1.m1.2.2.2.2.2.3.cmml">2</mn><mrow id="S3.SS2.p1.1.m1.2.2.2.2a" xref="S3.SS2.p1.1.m1.2.2.2.2.cmml"></mrow><mrow id="S3.SS2.p1.1.m1.2.2.2.2b" xref="S3.SS2.p1.1.m1.2.2.2.2.cmml"></mrow><mi mathsize="90%" id="S3.SS2.p1.1.m1.2.2.2.2.3" xref="S3.SS2.p1.1.m1.2.2.2.2.3.cmml">amplitude</mi></mmultiscripts><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.1.m1.2.2.2.5" xref="S3.SS2.p1.1.m1.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><list id="S3.SS2.p1.1.m1.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2"><apply id="S3.SS2.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS2.p1.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.2.3">1</cn></apply><ci id="S3.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1.3">amplitude</ci></apply><apply id="S3.SS2.p1.1.m1.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS2.p1.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.2.3">2</cn></apply><ci id="S3.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2.3">amplitude</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">[{X_{1}}^{\rm amplitude};{X_{2}}^{\rm amplitude}]</annotation></semantics></math><span id="S3.SS2.p1.6.5" class="ltx_text" style="font-size:90%;"> to quantized amplitude features </span><math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\bm{q}^{\rm amplitude}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><msup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">ğ’’</mi><mi mathsize="90%" id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">amplitude</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ’’</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">amplitude</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\bm{q}^{\rm amplitude}</annotation></semantics></math><span id="S3.SS2.p1.6.6" class="ltx_text" style="font-size:90%;">. The phase quantizer converts phase features </span><math id="S3.SS2.p1.3.m3.2" class="ltx_Math" alttext="[{X_{1}}^{\rm phase};{X_{2}}^{\rm phase}]" display="inline"><semantics id="S3.SS2.p1.3.m3.2a"><mrow id="S3.SS2.p1.3.m3.2.2.2" xref="S3.SS2.p1.3.m3.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.3.m3.2.2.2.3" xref="S3.SS2.p1.3.m3.2.2.3.cmml">[</mo><mmultiscripts id="S3.SS2.p1.3.m3.1.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.3.m3.1.1.1.1.2.2" xref="S3.SS2.p1.3.m3.1.1.1.1.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS2.p1.3.m3.1.1.1.1.2.3" xref="S3.SS2.p1.3.m3.1.1.1.1.2.3.cmml">1</mn><mrow id="S3.SS2.p1.3.m3.1.1.1.1a" xref="S3.SS2.p1.3.m3.1.1.1.1.cmml"></mrow><mrow id="S3.SS2.p1.3.m3.1.1.1.1b" xref="S3.SS2.p1.3.m3.1.1.1.1.cmml"></mrow><mi mathsize="90%" id="S3.SS2.p1.3.m3.1.1.1.1.3" xref="S3.SS2.p1.3.m3.1.1.1.1.3.cmml">phase</mi></mmultiscripts><mo mathsize="90%" id="S3.SS2.p1.3.m3.2.2.2.4" xref="S3.SS2.p1.3.m3.2.2.3.cmml">;</mo><mmultiscripts id="S3.SS2.p1.3.m3.2.2.2.2" xref="S3.SS2.p1.3.m3.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.3.m3.2.2.2.2.2.2" xref="S3.SS2.p1.3.m3.2.2.2.2.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS2.p1.3.m3.2.2.2.2.2.3" xref="S3.SS2.p1.3.m3.2.2.2.2.2.3.cmml">2</mn><mrow id="S3.SS2.p1.3.m3.2.2.2.2a" xref="S3.SS2.p1.3.m3.2.2.2.2.cmml"></mrow><mrow id="S3.SS2.p1.3.m3.2.2.2.2b" xref="S3.SS2.p1.3.m3.2.2.2.2.cmml"></mrow><mi mathsize="90%" id="S3.SS2.p1.3.m3.2.2.2.2.3" xref="S3.SS2.p1.3.m3.2.2.2.2.3.cmml">phase</mi></mmultiscripts><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.3.m3.2.2.2.5" xref="S3.SS2.p1.3.m3.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.2b"><list id="S3.SS2.p1.3.m3.2.2.3.cmml" xref="S3.SS2.p1.3.m3.2.2.2"><apply id="S3.SS2.p1.3.m3.1.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.3.m3.1.1.1.1.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS2.p1.3.m3.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.3.m3.1.1.1.1.2.3">1</cn></apply><ci id="S3.SS2.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.1.1.3">phase</ci></apply><apply id="S3.SS2.p1.3.m3.2.2.2.2.cmml" xref="S3.SS2.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS2.p1.3.m3.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS2.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.p1.3.m3.2.2.2.2.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS2.p1.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS2.p1.3.m3.2.2.2.2.2.3">2</cn></apply><ci id="S3.SS2.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS2.p1.3.m3.2.2.2.2.3">phase</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.2c">[{X_{1}}^{\rm phase};{X_{2}}^{\rm phase}]</annotation></semantics></math><span id="S3.SS2.p1.6.7" class="ltx_text" style="font-size:90%;"> to quantized phase features </span><math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\bm{q}^{\rm phase}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><msup id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">ğ’’</mi><mi mathsize="90%" id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">phase</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">ğ’’</ci><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">phase</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\bm{q}^{\rm phase}</annotation></semantics></math><span id="S3.SS2.p1.6.8" class="ltx_text" style="font-size:90%;">.
The joint quantizer obtains the two vectors </span><math id="S3.SS2.p1.5.m5.2" class="ltx_Math" alttext="[\bm{q}^{\rm amplitude};\bm{q}^{\rm phase}]" display="inline"><semantics id="S3.SS2.p1.5.m5.2a"><mrow id="S3.SS2.p1.5.m5.2.2.2" xref="S3.SS2.p1.5.m5.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.5.m5.2.2.2.3" xref="S3.SS2.p1.5.m5.2.2.3.cmml">[</mo><msup id="S3.SS2.p1.5.m5.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.5.m5.1.1.1.1.2" xref="S3.SS2.p1.5.m5.1.1.1.1.2.cmml">ğ’’</mi><mi mathsize="90%" id="S3.SS2.p1.5.m5.1.1.1.1.3" xref="S3.SS2.p1.5.m5.1.1.1.1.3.cmml">amplitude</mi></msup><mo mathsize="90%" id="S3.SS2.p1.5.m5.2.2.2.4" xref="S3.SS2.p1.5.m5.2.2.3.cmml">;</mo><msup id="S3.SS2.p1.5.m5.2.2.2.2" xref="S3.SS2.p1.5.m5.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.5.m5.2.2.2.2.2" xref="S3.SS2.p1.5.m5.2.2.2.2.2.cmml">ğ’’</mi><mi mathsize="90%" id="S3.SS2.p1.5.m5.2.2.2.2.3" xref="S3.SS2.p1.5.m5.2.2.2.2.3.cmml">phase</mi></msup><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.5.m5.2.2.2.5" xref="S3.SS2.p1.5.m5.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.2b"><list id="S3.SS2.p1.5.m5.2.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2"><apply id="S3.SS2.p1.5.m5.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.2">ğ’’</ci><ci id="S3.SS2.p1.5.m5.1.1.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1.3">amplitude</ci></apply><apply id="S3.SS2.p1.5.m5.2.2.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.2.2.1.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2">superscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.2.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2.2">ğ’’</ci><ci id="S3.SS2.p1.5.m5.2.2.2.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.2.3">phase</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.2c">[\bm{q}^{\rm amplitude};\bm{q}^{\rm phase}]</annotation></semantics></math><span id="S3.SS2.p1.6.9" class="ltx_text" style="font-size:90%;"> from the two quantizers and converts them to quantized feature </span><math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mi mathsize="90%" id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\bm{q}</annotation></semantics></math><span id="S3.SS2.p1.6.10" class="ltx_text" style="font-size:90%;">. All quantizers consist of linear layers.</span></p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Channel-wise quantization</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.2" class="ltx_p"><span id="S3.SS3.p1.2.1" class="ltx_text" style="font-size:90%;">FigureÂ </span><a href="#S3.F4" title="Figure 4 â€£ 3.1 Joint quantization â€£ 3 Self-supervised learning for multi-channel neural transducer â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S3.SS3.p1.2.2" class="ltx_text" style="font-size:90%;"> shows </span><span id="S3.SS3.p1.2.3" class="ltx_text" style="font-size:90%;">channel-wise</span><span id="S3.SS3.p1.2.4" class="ltx_text" style="font-size:90%;"> quantization. In this method, the quantization module consists of channel quantizers, the attention and the joint quantizer. The channel quantizers convert the amplitude and phase features </span><math id="S3.SS3.p1.1.m1.2" class="ltx_Math" alttext="[{X_{c}}^{\rm amplitude};{X_{c}}^{\rm phase}]" display="inline"><semantics id="S3.SS3.p1.1.m1.2a"><mrow id="S3.SS3.p1.1.m1.2.2.2" xref="S3.SS3.p1.1.m1.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.1.m1.2.2.2.3" xref="S3.SS3.p1.1.m1.2.2.3.cmml">[</mo><mmultiscripts id="S3.SS3.p1.1.m1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.1.1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.1.1.2.2.cmml">X</mi><mi mathsize="90%" id="S3.SS3.p1.1.m1.1.1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.1.1.2.3.cmml">c</mi><mrow id="S3.SS3.p1.1.m1.1.1.1.1a" xref="S3.SS3.p1.1.m1.1.1.1.1.cmml"></mrow><mrow id="S3.SS3.p1.1.m1.1.1.1.1b" xref="S3.SS3.p1.1.m1.1.1.1.1.cmml"></mrow><mi mathsize="90%" id="S3.SS3.p1.1.m1.1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.1.1.3.cmml">amplitude</mi></mmultiscripts><mo mathsize="90%" id="S3.SS3.p1.1.m1.2.2.2.4" xref="S3.SS3.p1.1.m1.2.2.3.cmml">;</mo><mmultiscripts id="S3.SS3.p1.1.m1.2.2.2.2" xref="S3.SS3.p1.1.m1.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.2.2.2.2.2.2" xref="S3.SS3.p1.1.m1.2.2.2.2.2.2.cmml">X</mi><mi mathsize="90%" id="S3.SS3.p1.1.m1.2.2.2.2.2.3" xref="S3.SS3.p1.1.m1.2.2.2.2.2.3.cmml">c</mi><mrow id="S3.SS3.p1.1.m1.2.2.2.2a" xref="S3.SS3.p1.1.m1.2.2.2.2.cmml"></mrow><mrow id="S3.SS3.p1.1.m1.2.2.2.2b" xref="S3.SS3.p1.1.m1.2.2.2.2.cmml"></mrow><mi mathsize="90%" id="S3.SS3.p1.1.m1.2.2.2.2.3" xref="S3.SS3.p1.1.m1.2.2.2.2.3.cmml">phase</mi></mmultiscripts><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.1.m1.2.2.2.5" xref="S3.SS3.p1.1.m1.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.2b"><list id="S3.SS3.p1.1.m1.2.2.3.cmml" xref="S3.SS3.p1.1.m1.2.2.2"><apply id="S3.SS3.p1.1.m1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1">superscript</csymbol><apply id="S3.SS3.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.2.2">ğ‘‹</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS3.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.3">amplitude</ci></apply><apply id="S3.SS3.p1.1.m1.2.2.2.2.cmml" xref="S3.SS3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS3.p1.1.m1.2.2.2.2">superscript</csymbol><apply id="S3.SS3.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.1.m1.2.2.2.2.2.2">ğ‘‹</ci><ci id="S3.SS3.p1.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.1.m1.2.2.2.2.2.3">ğ‘</ci></apply><ci id="S3.SS3.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS3.p1.1.m1.2.2.2.2.3">phase</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.2c">[{X_{c}}^{\rm amplitude};{X_{c}}^{\rm phase}]</annotation></semantics></math><span id="S3.SS3.p1.2.5" class="ltx_text" style="font-size:90%;"> from each input channel to </span><span id="S3.SS3.p1.2.6" class="ltx_text" style="font-size:90%;">channel-wise</span><span id="S3.SS3.p1.2.7" class="ltx_text" style="font-size:90%;"> quantized features </span><math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="{\bm{q}_{c}}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">ğ’’</mi><mi mathsize="90%" id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">ğ’’</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">{\bm{q}_{c}}</annotation></semantics></math><span id="S3.SS3.p1.2.8" class="ltx_text" style="font-size:90%;">. To capture the contextual relationship across channels, the attention was calculated.
For instance, the attention for the first channel in the case of two channels is calculated as</span></p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="{\bm{a}}_{1}={\rm Softmax}(\bm{w}^{T}{\rm Tanh}(UX_{1}+HX_{2}+\bm{b}))," display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.3.2.cmml">ğ’‚</mi><mn mathsize="90%" id="S3.E4.m1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.3.cmml">Softmax</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><msup id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml">ğ’˜</mi><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.4" xref="S3.E4.m1.1.1.1.1.1.1.1.1.4.cmml">Tanh</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.1.1.2a" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">X</mi><mn mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">1</mn></msub></mrow><mo mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">X</mi><mn mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">2</mn></msub></mrow><mo mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.4.cmml">ğ’ƒ</mi></mrow><mo maxsize="90%" minsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo mathsize="90%" id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"></eq><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2">ğ’‚</ci><cn type="integer" id="S3.E4.m1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3">1</cn></apply><apply id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3">Softmax</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2">ğ’˜</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.3">ğ‘‡</ci></apply><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.4">Tanh</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"><plus id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1"></times><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘ˆ</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2">ğ‘‹</ci><cn type="integer" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ»</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.2">ğ‘‹</ci><cn type="integer" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3">2</cn></apply></apply><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.4">ğ’ƒ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">{\bm{a}}_{1}={\rm Softmax}(\bm{w}^{T}{\rm Tanh}(UX_{1}+HX_{2}+\bm{b})),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.10" class="ltx_p"><span id="S3.SS3.p1.10.1" class="ltx_text" style="font-size:90%;">where </span><math id="S3.SS3.p1.3.m1.2" class="ltx_Math" alttext="X_{1}=[{X_{1}}^{\rm amplitude};{X_{1}}^{\rm phase}]" display="inline"><semantics id="S3.SS3.p1.3.m1.2a"><mrow id="S3.SS3.p1.3.m1.2.2" xref="S3.SS3.p1.3.m1.2.2.cmml"><msub id="S3.SS3.p1.3.m1.2.2.4" xref="S3.SS3.p1.3.m1.2.2.4.cmml"><mi mathsize="90%" id="S3.SS3.p1.3.m1.2.2.4.2" xref="S3.SS3.p1.3.m1.2.2.4.2.cmml">X</mi><mn mathsize="90%" id="S3.SS3.p1.3.m1.2.2.4.3" xref="S3.SS3.p1.3.m1.2.2.4.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.SS3.p1.3.m1.2.2.3" xref="S3.SS3.p1.3.m1.2.2.3.cmml">=</mo><mrow id="S3.SS3.p1.3.m1.2.2.2.2" xref="S3.SS3.p1.3.m1.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.3.m1.2.2.2.2.3" xref="S3.SS3.p1.3.m1.2.2.2.3.cmml">[</mo><mmultiscripts id="S3.SS3.p1.3.m1.1.1.1.1.1" xref="S3.SS3.p1.3.m1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.3.m1.1.1.1.1.1.2.2" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS3.p1.3.m1.1.1.1.1.1.2.3" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.3.cmml">1</mn><mrow id="S3.SS3.p1.3.m1.1.1.1.1.1a" xref="S3.SS3.p1.3.m1.1.1.1.1.1.cmml"></mrow><mrow id="S3.SS3.p1.3.m1.1.1.1.1.1b" xref="S3.SS3.p1.3.m1.1.1.1.1.1.cmml"></mrow><mi mathsize="90%" id="S3.SS3.p1.3.m1.1.1.1.1.1.3" xref="S3.SS3.p1.3.m1.1.1.1.1.1.3.cmml">amplitude</mi></mmultiscripts><mo mathsize="90%" id="S3.SS3.p1.3.m1.2.2.2.2.4" xref="S3.SS3.p1.3.m1.2.2.2.3.cmml">;</mo><mmultiscripts id="S3.SS3.p1.3.m1.2.2.2.2.2" xref="S3.SS3.p1.3.m1.2.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.3.m1.2.2.2.2.2.2.2" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS3.p1.3.m1.2.2.2.2.2.2.3" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.3.cmml">1</mn><mrow id="S3.SS3.p1.3.m1.2.2.2.2.2a" xref="S3.SS3.p1.3.m1.2.2.2.2.2.cmml"></mrow><mrow id="S3.SS3.p1.3.m1.2.2.2.2.2b" xref="S3.SS3.p1.3.m1.2.2.2.2.2.cmml"></mrow><mi mathsize="90%" id="S3.SS3.p1.3.m1.2.2.2.2.2.3" xref="S3.SS3.p1.3.m1.2.2.2.2.2.3.cmml">phase</mi></mmultiscripts><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.3.m1.2.2.2.2.5" xref="S3.SS3.p1.3.m1.2.2.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m1.2b"><apply id="S3.SS3.p1.3.m1.2.2.cmml" xref="S3.SS3.p1.3.m1.2.2"><eq id="S3.SS3.p1.3.m1.2.2.3.cmml" xref="S3.SS3.p1.3.m1.2.2.3"></eq><apply id="S3.SS3.p1.3.m1.2.2.4.cmml" xref="S3.SS3.p1.3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.2.2.4.1.cmml" xref="S3.SS3.p1.3.m1.2.2.4">subscript</csymbol><ci id="S3.SS3.p1.3.m1.2.2.4.2.cmml" xref="S3.SS3.p1.3.m1.2.2.4.2">ğ‘‹</ci><cn type="integer" id="S3.SS3.p1.3.m1.2.2.4.3.cmml" xref="S3.SS3.p1.3.m1.2.2.4.3">1</cn></apply><list id="S3.SS3.p1.3.m1.2.2.2.3.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2"><apply id="S3.SS3.p1.3.m1.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS3.p1.3.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS3.p1.3.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1.2.3">1</cn></apply><ci id="S3.SS3.p1.3.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.3.m1.1.1.1.1.1.3">amplitude</ci></apply><apply id="S3.SS3.p1.3.m1.2.2.2.2.2.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2">superscript</csymbol><apply id="S3.SS3.p1.3.m1.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.2.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.3.m1.2.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS3.p1.3.m1.2.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2.2.3">1</cn></apply><ci id="S3.SS3.p1.3.m1.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.3.m1.2.2.2.2.2.3">phase</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m1.2c">X_{1}=[{X_{1}}^{\rm amplitude};{X_{1}}^{\rm phase}]</annotation></semantics></math><span id="S3.SS3.p1.10.2" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS3.p1.4.m2.2" class="ltx_Math" alttext="X_{2}=[{X_{2}}^{\rm amplitude};{X_{2}}^{\rm phase}]" display="inline"><semantics id="S3.SS3.p1.4.m2.2a"><mrow id="S3.SS3.p1.4.m2.2.2" xref="S3.SS3.p1.4.m2.2.2.cmml"><msub id="S3.SS3.p1.4.m2.2.2.4" xref="S3.SS3.p1.4.m2.2.2.4.cmml"><mi mathsize="90%" id="S3.SS3.p1.4.m2.2.2.4.2" xref="S3.SS3.p1.4.m2.2.2.4.2.cmml">X</mi><mn mathsize="90%" id="S3.SS3.p1.4.m2.2.2.4.3" xref="S3.SS3.p1.4.m2.2.2.4.3.cmml">2</mn></msub><mo mathsize="90%" id="S3.SS3.p1.4.m2.2.2.3" xref="S3.SS3.p1.4.m2.2.2.3.cmml">=</mo><mrow id="S3.SS3.p1.4.m2.2.2.2.2" xref="S3.SS3.p1.4.m2.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.4.m2.2.2.2.2.3" xref="S3.SS3.p1.4.m2.2.2.2.3.cmml">[</mo><mmultiscripts id="S3.SS3.p1.4.m2.1.1.1.1.1" xref="S3.SS3.p1.4.m2.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.4.m2.1.1.1.1.1.2.2" xref="S3.SS3.p1.4.m2.1.1.1.1.1.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS3.p1.4.m2.1.1.1.1.1.2.3" xref="S3.SS3.p1.4.m2.1.1.1.1.1.2.3.cmml">2</mn><mrow id="S3.SS3.p1.4.m2.1.1.1.1.1a" xref="S3.SS3.p1.4.m2.1.1.1.1.1.cmml"></mrow><mrow id="S3.SS3.p1.4.m2.1.1.1.1.1b" xref="S3.SS3.p1.4.m2.1.1.1.1.1.cmml"></mrow><mi mathsize="90%" id="S3.SS3.p1.4.m2.1.1.1.1.1.3" xref="S3.SS3.p1.4.m2.1.1.1.1.1.3.cmml">amplitude</mi></mmultiscripts><mo mathsize="90%" id="S3.SS3.p1.4.m2.2.2.2.2.4" xref="S3.SS3.p1.4.m2.2.2.2.3.cmml">;</mo><mmultiscripts id="S3.SS3.p1.4.m2.2.2.2.2.2" xref="S3.SS3.p1.4.m2.2.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.4.m2.2.2.2.2.2.2.2" xref="S3.SS3.p1.4.m2.2.2.2.2.2.2.2.cmml">X</mi><mn mathsize="90%" id="S3.SS3.p1.4.m2.2.2.2.2.2.2.3" xref="S3.SS3.p1.4.m2.2.2.2.2.2.2.3.cmml">2</mn><mrow id="S3.SS3.p1.4.m2.2.2.2.2.2a" xref="S3.SS3.p1.4.m2.2.2.2.2.2.cmml"></mrow><mrow id="S3.SS3.p1.4.m2.2.2.2.2.2b" xref="S3.SS3.p1.4.m2.2.2.2.2.2.cmml"></mrow><mi mathsize="90%" id="S3.SS3.p1.4.m2.2.2.2.2.2.3" xref="S3.SS3.p1.4.m2.2.2.2.2.2.3.cmml">phase</mi></mmultiscripts><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.4.m2.2.2.2.2.5" xref="S3.SS3.p1.4.m2.2.2.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m2.2b"><apply id="S3.SS3.p1.4.m2.2.2.cmml" xref="S3.SS3.p1.4.m2.2.2"><eq id="S3.SS3.p1.4.m2.2.2.3.cmml" xref="S3.SS3.p1.4.m2.2.2.3"></eq><apply id="S3.SS3.p1.4.m2.2.2.4.cmml" xref="S3.SS3.p1.4.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m2.2.2.4.1.cmml" xref="S3.SS3.p1.4.m2.2.2.4">subscript</csymbol><ci id="S3.SS3.p1.4.m2.2.2.4.2.cmml" xref="S3.SS3.p1.4.m2.2.2.4.2">ğ‘‹</ci><cn type="integer" id="S3.SS3.p1.4.m2.2.2.4.3.cmml" xref="S3.SS3.p1.4.m2.2.2.4.3">2</cn></apply><list id="S3.SS3.p1.4.m2.2.2.2.3.cmml" xref="S3.SS3.p1.4.m2.2.2.2.2"><apply id="S3.SS3.p1.4.m2.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1.1.1.1">superscript</csymbol><apply id="S3.SS3.p1.4.m2.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.4.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m2.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.4.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m2.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.4.m2.1.1.1.1.1.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS3.p1.4.m2.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.4.m2.1.1.1.1.1.2.3">2</cn></apply><ci id="S3.SS3.p1.4.m2.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.4.m2.1.1.1.1.1.3">amplitude</ci></apply><apply id="S3.SS3.p1.4.m2.2.2.2.2.2.cmml" xref="S3.SS3.p1.4.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m2.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.4.m2.2.2.2.2.2">superscript</csymbol><apply id="S3.SS3.p1.4.m2.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.4.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m2.2.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.4.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.4.m2.2.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.4.m2.2.2.2.2.2.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS3.p1.4.m2.2.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.4.m2.2.2.2.2.2.2.3">2</cn></apply><ci id="S3.SS3.p1.4.m2.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.4.m2.2.2.2.2.2.3">phase</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m2.2c">X_{2}=[{X_{2}}^{\rm amplitude};{X_{2}}^{\rm phase}]</annotation></semantics></math><span id="S3.SS3.p1.10.3" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS3.p1.5.m3.1" class="ltx_Math" alttext="\bm{w}" display="inline"><semantics id="S3.SS3.p1.5.m3.1a"><mi mathsize="90%" id="S3.SS3.p1.5.m3.1.1" xref="S3.SS3.p1.5.m3.1.1.cmml">ğ’˜</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m3.1b"><ci id="S3.SS3.p1.5.m3.1.1.cmml" xref="S3.SS3.p1.5.m3.1.1">ğ’˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m3.1c">\bm{w}</annotation></semantics></math><span id="S3.SS3.p1.10.4" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS3.p1.6.m4.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S3.SS3.p1.6.m4.1a"><mi mathsize="90%" id="S3.SS3.p1.6.m4.1.1" xref="S3.SS3.p1.6.m4.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m4.1b"><ci id="S3.SS3.p1.6.m4.1.1.cmml" xref="S3.SS3.p1.6.m4.1.1">ğ‘ˆ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m4.1c">U</annotation></semantics></math><span id="S3.SS3.p1.10.5" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS3.p1.7.m5.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS3.p1.7.m5.1a"><mi mathsize="90%" id="S3.SS3.p1.7.m5.1.1" xref="S3.SS3.p1.7.m5.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m5.1b"><ci id="S3.SS3.p1.7.m5.1.1.cmml" xref="S3.SS3.p1.7.m5.1.1">ğ»</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m5.1c">H</annotation></semantics></math><span id="S3.SS3.p1.10.6" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS3.p1.8.m6.1" class="ltx_Math" alttext="\bm{b}" display="inline"><semantics id="S3.SS3.p1.8.m6.1a"><mi mathsize="90%" id="S3.SS3.p1.8.m6.1.1" xref="S3.SS3.p1.8.m6.1.1.cmml">ğ’ƒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m6.1b"><ci id="S3.SS3.p1.8.m6.1.1.cmml" xref="S3.SS3.p1.8.m6.1.1">ğ’ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m6.1c">\bm{b}</annotation></semantics></math><span id="S3.SS3.p1.10.7" class="ltx_text" style="font-size:90%;"> are model parameters. The attention is used to calculate weighted quantized vector </span><math id="S3.SS3.p1.9.m7.1" class="ltx_Math" alttext="{\bm{q}_{c}}^{{}^{\prime}}" display="inline"><semantics id="S3.SS3.p1.9.m7.1a"><mmultiscripts id="S3.SS3.p1.9.m7.1.1" xref="S3.SS3.p1.9.m7.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.9.m7.1.1.2.2" xref="S3.SS3.p1.9.m7.1.1.2.2.cmml">ğ’’</mi><mi mathsize="90%" id="S3.SS3.p1.9.m7.1.1.2.3" xref="S3.SS3.p1.9.m7.1.1.2.3.cmml">c</mi><mrow id="S3.SS3.p1.9.m7.1.1a" xref="S3.SS3.p1.9.m7.1.1.cmml"></mrow><mrow id="S3.SS3.p1.9.m7.1.1b" xref="S3.SS3.p1.9.m7.1.1.cmml"></mrow><msup id="S3.SS3.p1.9.m7.1.1.3" xref="S3.SS3.p1.9.m7.1.1.3.cmml"><mi id="S3.SS3.p1.9.m7.1.1.3a" xref="S3.SS3.p1.9.m7.1.1.3.cmml"></mi><mo mathsize="90%" id="S3.SS3.p1.9.m7.1.1.3.1" xref="S3.SS3.p1.9.m7.1.1.3.1.cmml">â€²</mo></msup></mmultiscripts><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m7.1b"><apply id="S3.SS3.p1.9.m7.1.1.cmml" xref="S3.SS3.p1.9.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m7.1.1.1.cmml" xref="S3.SS3.p1.9.m7.1.1">superscript</csymbol><apply id="S3.SS3.p1.9.m7.1.1.2.cmml" xref="S3.SS3.p1.9.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m7.1.1.2.1.cmml" xref="S3.SS3.p1.9.m7.1.1">subscript</csymbol><ci id="S3.SS3.p1.9.m7.1.1.2.2.cmml" xref="S3.SS3.p1.9.m7.1.1.2.2">ğ’’</ci><ci id="S3.SS3.p1.9.m7.1.1.2.3.cmml" xref="S3.SS3.p1.9.m7.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS3.p1.9.m7.1.1.3.cmml" xref="S3.SS3.p1.9.m7.1.1.3"><ci id="S3.SS3.p1.9.m7.1.1.3.1.cmml" xref="S3.SS3.p1.9.m7.1.1.3.1">â€²</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m7.1c">{\bm{q}_{c}}^{{}^{\prime}}</annotation></semantics></math><span id="S3.SS3.p1.10.8" class="ltx_text" style="font-size:90%;">. The joint quantizer converts the weighted quantized features from each channel quantizer to quantized vector </span><math id="S3.SS3.p1.10.m8.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS3.p1.10.m8.1a"><mi mathsize="90%" id="S3.SS3.p1.10.m8.1.1" xref="S3.SS3.p1.10.m8.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.m8.1b"><ci id="S3.SS3.p1.10.m8.1.1.cmml" xref="S3.SS3.p1.10.m8.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.m8.1c">\bm{q}</annotation></semantics></math><span id="S3.SS3.p1.10.9" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Data preparation</h3>

<div id="S4.SS1.p1" class="ltx_para">
<dl id="S4.I1" class="ltx_description">
<dt id="S4.I1.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S4.I1.ix1.1.1.1" class="ltx_text ltx_font_bold">Far-field in-house dataset</span></span></dt>
<dd class="ltx_item">
<div id="S4.I1.ix1.p1" class="ltx_para">
<p id="S4.I1.ix1.p1.1" class="ltx_p"><span id="S4.I1.ix1.p1.1.1" class="ltx_text" style="font-size:90%;">As the experimental dataset, we use the </span><span id="S4.I1.ix1.p1.1.2" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S4.I1.ix1.p1.1.3" class="ltx_text" style="font-size:90%;"> dataset, which consists of 104.3 hours of transcribed Japanese speech. The speech is recorded by a </span><span id="S4.I1.ix1.p1.1.4" class="ltx_text" style="font-size:90%;">two-channel</span><span id="S4.I1.ix1.p1.1.5" class="ltx_text" style="font-size:90%;"> linear microphone array with
an </span><span id="S4.I1.ix1.p1.1.6" class="ltx_text" style="font-size:90%;">inter-microphone</span><span id="S4.I1.ix1.p1.1.7" class="ltx_text" style="font-size:90%;"> spacing of 8 mm. The amounts of training and test data are 102 and 2.3 hours, respectively. For </span><span id="S4.I1.ix1.p1.1.8" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S4.I1.ix1.p1.1.9" class="ltx_text" style="font-size:90%;"> and </span><span id="S4.I1.ix1.p1.1.10" class="ltx_text" style="font-size:90%;">fine-tuning</span><span id="S4.I1.ix1.p1.1.11" class="ltx_text" style="font-size:90%;">, we use the training set, and for the evaluation, we use the test set. For this dataset, we report the character error rate (CER).</span></p>
</div>
</dd>
<dt id="S4.I1.ix2" class="ltx_item"><span class="ltx_tag ltx_tag_item"><span id="S4.I1.ix2.1.1.1" class="ltx_text ltx_font_bold">CHiME-4 dataset</span></span></dt>
<dd class="ltx_item">
<div id="S4.I1.ix2.p1" class="ltx_para">
<p id="S4.I1.ix2.p1.1" class="ltx_p"><span id="S4.I1.ix2.p1.1.1" class="ltx_text" style="font-size:90%;">We also use the </span><span id="S4.I1.ix2.p1.1.2" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="S4.I1.ix2.p1.1.3" class="ltx_text" style="font-size:90%;"> dataset to evaluate our proposed method. Speech in English is recorded by six microphones. For efficient training, we pick up the first and sixth microphone channels as input signals. In this experiment, we use training and evaluation sets on real data. For </span><span id="S4.I1.ix2.p1.1.4" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S4.I1.ix2.p1.1.5" class="ltx_text" style="font-size:90%;"> and </span><span id="S4.I1.ix2.p1.1.6" class="ltx_text" style="font-size:90%;">fine-tuning</span><span id="S4.I1.ix2.p1.1.7" class="ltx_text" style="font-size:90%;">, we use the training set. For evaluation, we use the eval set. For this dataset, we report the word error rate (WER) and CER.</span></p>
</div>
</dd>
</dl>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">We next describe the architecture of the </span><span id="S4.SS2.p1.1.2" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS2.p1.1.3" class="ltx_text" style="font-size:90%;"> neural transducer. We use eight conformer layers and a unidirectional long </span><span id="S4.SS2.p1.1.4" class="ltx_text" style="font-size:90%;">short-term</span><span id="S4.SS2.p1.1.5" class="ltx_text" style="font-size:90%;"> memory (LSTM) layer with 256 hidden nodes for the </span><span id="S4.SS2.p1.1.6" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS2.p1.1.7" class="ltx_text" style="font-size:90%;"> audio and label encoders, respectively. TableÂ </span><a href="#S4.T1" title="Table 1 â€£ 4.2 Model details â€£ 4 Experiments â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S4.SS2.p1.1.8" class="ltx_text" style="font-size:90%;"> shows the parameters of the Conformer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p1.1.9.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S4.SS2.p1.1.10.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p1.1.11" class="ltx_text" style="font-size:90%;"> encoder model. The parameter size of the </span><span id="S4.SS2.p1.1.12" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS2.p1.1.13" class="ltx_text" style="font-size:90%;"> audio encoder is 15.0 (M). The joint network obtains </span><span id="S4.SS2.p1.1.14" class="ltx_text" style="font-size:90%;">512-dimensional</span><span id="S4.SS2.p1.1.15" class="ltx_text" style="font-size:90%;"> vectors from audio and label encoders, and outputs </span><span id="S4.SS2.p1.1.16" class="ltx_text" style="font-size:90%;">256-dimensional</span><span id="S4.SS2.p1.1.17" class="ltx_text" style="font-size:90%;"> vector with Tanh activation. Finally, softmax outputs logits.</span></p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S4.T1.4.1" class="ltx_text">Multi-channel</span> Conformer encoder architecture.</figcaption>
<table id="S4.T1.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.5.1.1" class="ltx_tr">
<th id="S4.T1.5.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Parameter</span></th>
<th id="S4.T1.5.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.5.1.1.2.1" class="ltx_text" style="font-size:90%;">Value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.5.2.1" class="ltx_tr">
<td id="S4.T1.5.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.2.1.1.1" class="ltx_text" style="font-size:90%;">Number of layers</span></td>
<td id="S4.T1.5.2.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.5.2.1.2.1" class="ltx_text" style="font-size:90%;">8</span></td>
</tr>
<tr id="S4.T1.5.3.2" class="ltx_tr">
<td id="S4.T1.5.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.3.2.1.1" class="ltx_text" style="font-size:90%;">Number of channels</span></td>
<td id="S4.T1.5.3.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.5.3.2.2.1" class="ltx_text" style="font-size:90%;">2</span></td>
</tr>
<tr id="S4.T1.5.4.3" class="ltx_tr">
<td id="S4.T1.5.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.4.3.1.1" class="ltx_text" style="font-size:90%;">Number of heads</span></td>
<td id="S4.T1.5.4.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.5.4.3.2.1" class="ltx_text" style="font-size:90%;">8</span></td>
</tr>
<tr id="S4.T1.5.5.4" class="ltx_tr">
<td id="S4.T1.5.5.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.5.4.1.1" class="ltx_text" style="font-size:90%;">Head dimension</span></td>
<td id="S4.T1.5.5.4.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.5.5.4.2.1" class="ltx_text" style="font-size:90%;">32</span></td>
</tr>
<tr id="S4.T1.5.6.5" class="ltx_tr">
<td id="S4.T1.5.6.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.6.5.1.1" class="ltx_text" style="font-size:90%;">Kernel size</span></td>
<td id="S4.T1.5.6.5.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.5.6.5.2.1" class="ltx_text" style="font-size:90%;">7</span></td>
</tr>
<tr id="S4.T1.5.7.6" class="ltx_tr">
<td id="S4.T1.5.7.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.5.7.6.1.1" class="ltx_text" style="font-size:90%;">Number of hidden nodes</span></td>
<td id="S4.T1.5.7.6.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.5.7.6.2.1" class="ltx_text" style="font-size:90%;">256</span></td>
</tr>
<tr id="S4.T1.5.8.7" class="ltx_tr">
<td id="S4.T1.5.8.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.5.8.7.1.1" class="ltx_inline-block">
<span id="S4.T1.5.8.7.1.1.1" class="ltx_p"><span id="S4.T1.5.8.7.1.1.1.1" class="ltx_text" style="font-size:90%;">Position-wise feed-forward</span></span>
<span id="S4.T1.5.8.7.1.1.2" class="ltx_p"><span id="S4.T1.5.8.7.1.1.2.1" class="ltx_text" style="font-size:90%;">dimension</span></span>
</span>
</td>
<td id="S4.T1.5.8.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t"><span id="S4.T1.5.8.7.2.1" class="ltx_text" style="font-size:90%;">512</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">For the amplitude feature, we use the </span><span id="S4.SS2.p2.1.2" class="ltx_text" style="font-size:90%;">log-STFT</span><span id="S4.SS2.p2.1.3" class="ltx_text" style="font-size:90%;"> square magnitude. For the phase feature,
we use cosine interchannel phase differences (cosIPD) and sinIPD </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p2.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S4.SS2.p2.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p2.1.6" class="ltx_text" style="font-size:90%;">. The features are extracted every 10 ms with a window size of 25 ms from audio samples. We set the FFT size as 512.</span></p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text" style="font-size:90%;">In the wav2vec 2.0 </span><span id="S4.SS2.p3.1.2" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S4.SS2.p3.1.3" class="ltx_text" style="font-size:90%;">, we train the </span><span id="S4.SS2.p3.1.4" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS2.p3.1.5" class="ltx_text" style="font-size:90%;"> audio encoder by minimizing the contrastive loss. We mask 50% of the time steps and set the number of distractors as 100. The distractors are uniformly sampled from other masked time steps of the same utterance.</span></p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.3" class="ltx_p"><span id="S4.SS2.p4.3.1" class="ltx_text" style="font-size:90%;">For </span><span id="S4.SS2.p4.3.2" class="ltx_text" style="font-size:90%;">fine-tuning</span><span id="S4.SS2.p4.3.3" class="ltx_text" style="font-size:90%;">, we train the </span><span id="S4.SS2.p4.3.4" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS2.p4.3.5" class="ltx_text" style="font-size:90%;"> neural transducer by minimizing the </span><span id="S4.SS2.p4.3.6" class="ltx_text" style="font-size:90%;">RNNâ€“T</span><span id="S4.SS2.p4.3.7" class="ltx_text" style="font-size:90%;"> loss. As the baseline system, we use the </span><span id="S4.SS2.p4.3.8" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS2.p4.3.9" class="ltx_text" style="font-size:90%;"> neural transducer without any </span><span id="S4.SS2.p4.3.10" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S4.SS2.p4.3.11" class="ltx_text" style="font-size:90%;">. For the </span><span id="S4.SS2.p4.3.12" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S4.SS2.p4.3.13" class="ltx_text" style="font-size:90%;"> dataset, the model outputs 715 characters and a blank token. For the </span><span id="S4.SS2.p4.3.14" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="S4.SS2.p4.3.15" class="ltx_text" style="font-size:90%;"> dataset, the model outputs 26 lower-case alphabet characters, three special tokens (apostrophe, period and whitespace) and a blank token. In addition, gradient clipping is applied with a value of 5 to avoid an exploding gradient. We apply SpecAugment </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p4.3.16.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S4.SS2.p4.3.17.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p4.3.18" class="ltx_text" style="font-size:90%;"> to improve robustness. For the training of all models, we use the Transformer learning schedule </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p4.3.19.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S4.SS2.p4.3.20.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p4.3.21" class="ltx_text" style="font-size:90%;">. We also use the Adam optimizer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p4.3.22.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S4.SS2.p4.3.23.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p4.3.24" class="ltx_text" style="font-size:90%;">, setting </span><math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="{\beta}_{1}=0.9" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mrow id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><msub id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2.cmml"><mi mathsize="90%" id="S4.SS2.p4.1.m1.1.1.2.2" xref="S4.SS2.p4.1.m1.1.1.2.2.cmml">Î²</mi><mn mathsize="90%" id="S4.SS2.p4.1.m1.1.1.2.3" xref="S4.SS2.p4.1.m1.1.1.2.3.cmml">1</mn></msub><mo mathsize="90%" id="S4.SS2.p4.1.m1.1.1.1" xref="S4.SS2.p4.1.m1.1.1.1.cmml">=</mo><mn mathsize="90%" id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><eq id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1.1"></eq><apply id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.2.1.cmml" xref="S4.SS2.p4.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.2.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2.2">ğ›½</ci><cn type="integer" id="S4.SS2.p4.1.m1.1.1.2.3.cmml" xref="S4.SS2.p4.1.m1.1.1.2.3">1</cn></apply><cn type="float" id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">{\beta}_{1}=0.9</annotation></semantics></math><span id="S4.SS2.p4.3.25" class="ltx_text" style="font-size:90%;">, </span><math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="{\beta}_{2}=0.98" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mrow id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><msub id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml"><mi mathsize="90%" id="S4.SS2.p4.2.m2.1.1.2.2" xref="S4.SS2.p4.2.m2.1.1.2.2.cmml">Î²</mi><mn mathsize="90%" id="S4.SS2.p4.2.m2.1.1.2.3" xref="S4.SS2.p4.2.m2.1.1.2.3.cmml">2</mn></msub><mo mathsize="90%" id="S4.SS2.p4.2.m2.1.1.1" xref="S4.SS2.p4.2.m2.1.1.1.cmml">=</mo><mn mathsize="90%" id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml">0.98</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><eq id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1.1"></eq><apply id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.2.1.cmml" xref="S4.SS2.p4.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2.2">ğ›½</ci><cn type="integer" id="S4.SS2.p4.2.m2.1.1.2.3.cmml" xref="S4.SS2.p4.2.m2.1.1.2.3">2</cn></apply><cn type="float" id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3">0.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">{\beta}_{2}=0.98</annotation></semantics></math><span id="S4.SS2.p4.3.26" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="\epsilon=10" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mrow id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml"><mi mathsize="90%" id="S4.SS2.p4.3.m3.1.1.2" xref="S4.SS2.p4.3.m3.1.1.2.cmml">Ïµ</mi><mo mathsize="90%" id="S4.SS2.p4.3.m3.1.1.1" xref="S4.SS2.p4.3.m3.1.1.1.cmml">=</mo><mn mathsize="90%" id="S4.SS2.p4.3.m3.1.1.3" xref="S4.SS2.p4.3.m3.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><apply id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1"><eq id="S4.SS2.p4.3.m3.1.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1.1"></eq><ci id="S4.SS2.p4.3.m3.1.1.2.cmml" xref="S4.SS2.p4.3.m3.1.1.2">italic-Ïµ</ci><cn type="integer" id="S4.SS2.p4.3.m3.1.1.3.cmml" xref="S4.SS2.p4.3.m3.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">\epsilon=10</annotation></semantics></math><span id="S4.SS2.p4.3.27" class="ltx_text" style="font-size:90%;">. All networks are implemented using Pytorch </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p4.3.28.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S4.SS2.p4.3.29.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p4.3.30" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results</h3>

<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Far-field in-house dataset</h4>

<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of feature-wise quantization for <span id="S4.T2.6.1" class="ltx_text">far-field in-house</span> dataset. Results are given as relative character error rate reduction (CERR) [%]. A positive value indicates an improvement.</figcaption>
<div id="S4.T2.1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:285.5pt;height:110.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.9pt,6.2pt) scale(0.9,0.9) ;">
<table id="S4.T2.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1.2.1" class="ltx_tr">
<th id="S4.T2.1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.2.1.1.1" class="ltx_text" style="font-size:90%;">ID</span></th>
<th id="S4.T2.1.1.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.2.1.2.1" class="ltx_text" style="font-size:90%;">pre-training</span></th>
<th id="S4.T2.1.1.1.2.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.2.1.3.1" class="ltx_text" style="font-size:90%;">quantization</span></th>
<th id="S4.T2.1.1.1.2.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<span id="S4.T2.1.1.1.2.1.4.1" class="ltx_inline-block">
<span id="S4.T2.1.1.1.2.1.4.1.1" class="ltx_p"><span id="S4.T2.1.1.1.2.1.4.1.1.1" class="ltx_text" style="font-size:90%;">amplitude</span></span>
<span id="S4.T2.1.1.1.2.1.4.1.2" class="ltx_p"><span id="S4.T2.1.1.1.2.1.4.1.2.1" class="ltx_text" style="font-size:90%;">quantizer</span></span>
<span id="S4.T2.1.1.1.2.1.4.1.3" class="ltx_p"><span id="S4.T2.1.1.1.2.1.4.1.3.1" class="ltx_text" style="font-size:90%;">activation</span></span>
</span>
</th>
<th id="S4.T2.1.1.1.2.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<span id="S4.T2.1.1.1.2.1.5.1" class="ltx_inline-block">
<span id="S4.T2.1.1.1.2.1.5.1.1" class="ltx_p"><span id="S4.T2.1.1.1.2.1.5.1.1.1" class="ltx_text" style="font-size:90%;">phase</span></span>
<span id="S4.T2.1.1.1.2.1.5.1.2" class="ltx_p"><span id="S4.T2.1.1.1.2.1.5.1.2.1" class="ltx_text" style="font-size:90%;">quantizer</span></span>
<span id="S4.T2.1.1.1.2.1.5.1.3" class="ltx_p"><span id="S4.T2.1.1.1.2.1.5.1.3.1" class="ltx_text" style="font-size:90%;">activation</span></span>
</span>
</th>
<th id="S4.T2.1.1.1.2.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.2.1.6.1" class="ltx_text" style="font-size:90%;">CERR (%)</span></th>
</tr>
<tr id="S4.T2.1.1.1.3.2" class="ltx_tr">
<th id="S4.T2.1.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.3.2.1.1" class="ltx_text" style="font-size:90%;">exp0</span></th>
<th id="S4.T2.1.1.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.3.2.2.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T2.1.1.1.3.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.3.2.3.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T2.1.1.1.3.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.3.2.4.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T2.1.1.1.3.2.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.3.2.5.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T2.1.1.1.3.2.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.3.2.6.1" class="ltx_text" style="font-size:90%;">0</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.1.4.1" class="ltx_tr">
<td id="S4.T2.1.1.1.4.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.1.1.1.4.1.1.1" class="ltx_text" style="font-size:90%;">exp1</span></td>
<td id="S4.T2.1.1.1.4.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.1.1.1.4.1.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T2.1.1.1.4.1.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.1.1.1.4.1.3.1" class="ltx_text" style="font-size:90%;">feature</span></td>
<td id="S4.T2.1.1.1.4.1.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.1.1.1.4.1.4.1" class="ltx_text" style="font-size:90%;">Swish</span></td>
<td id="S4.T2.1.1.1.4.1.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.1.1.1.4.1.5.1" class="ltx_text" style="font-size:90%;">Swish</span></td>
<td id="S4.T2.1.1.1.4.1.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.1.1.1.4.1.6.1" class="ltx_text" style="font-size:90%;">58.1</span></td>
</tr>
<tr id="S4.T2.1.1.1.5.2" class="ltx_tr">
<td id="S4.T2.1.1.1.5.2.1" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.5.2.1.1" class="ltx_text" style="font-size:90%;">exp2</span></td>
<td id="S4.T2.1.1.1.5.2.2" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.5.2.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T2.1.1.1.5.2.3" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.5.2.3.1" class="ltx_text" style="font-size:90%;">feature</span></td>
<td id="S4.T2.1.1.1.5.2.4" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.5.2.4.1" class="ltx_text" style="font-size:90%;">Swish</span></td>
<td id="S4.T2.1.1.1.5.2.5" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.5.2.5.1" class="ltx_text" style="font-size:90%;">ReLU</span></td>
<td id="S4.T2.1.1.1.5.2.6" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.5.2.6.1" class="ltx_text" style="font-size:90%;">60.5</span></td>
</tr>
<tr id="S4.T2.1.1.1.6.3" class="ltx_tr">
<td id="S4.T2.1.1.1.6.3.1" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.6.3.1.1" class="ltx_text" style="font-size:90%;">exp3</span></td>
<td id="S4.T2.1.1.1.6.3.2" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.6.3.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T2.1.1.1.6.3.3" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.6.3.3.1" class="ltx_text" style="font-size:90%;">joint</span></td>
<td id="S4.T2.1.1.1.6.3.4" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.6.3.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.1.1.1.6.3.5" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.6.3.5.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.1.1.1.6.3.6" class="ltx_td ltx_align_left"><span id="S4.T2.1.1.1.6.3.6.1" class="ltx_text" style="font-size:90%;">62.1</span></td>
</tr>
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T2.1.1.1.1.2.1" class="ltx_text" style="font-size:90%;">exp4</span></td>
<td id="S4.T2.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T2.1.1.1.1.3.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T2.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T2.1.1.1.1.4.1" class="ltx_text" style="font-size:90%;">feature</span></td>
<td id="S4.T2.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T2.1.1.1.1.5.1" class="ltx_text" style="font-size:90%;">Swish</span></td>
<td id="S4.T2.1.1.1.1.6" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T2.1.1.1.1.6.1" class="ltx_text" style="font-size:90%;">None</span></td>
<td id="S4.T2.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_b"><math id="S4.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{\bf 66}" display="inline"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><mn mathsize="90%" id="S4.T2.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml">ğŸ”ğŸ”</mn><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><cn type="integer" id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1">66</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">{\bf 66}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p"><span id="S4.SS3.SSS1.p1.1.1" class="ltx_text" style="font-size:90%;">TableÂ </span><a href="#S4.T2" title="Table 2 â€£ 4.3.1 Far-field in-house dataset â€£ 4.3 Results â€£ 4 Experiments â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S4.SS3.SSS1.p1.1.2" class="ltx_text" style="font-size:90%;"> shows the results of </span><span id="S4.SS3.SSS1.p1.1.3" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S4.SS3.SSS1.p1.1.4" class="ltx_text" style="font-size:90%;"> quantization for the </span><span id="S4.SS3.SSS1.p1.1.5" class="ltx_text" style="font-size:90%;">far-field in-house dataset</span><span id="S4.SS3.SSS1.p1.1.6" class="ltx_text" style="font-size:90%;">.
In this experiment, we investigate the effect of the activation function for the amplitude and phase quantizers. Compared with the result of the model without any </span><span id="S4.SS3.SSS1.p1.1.7" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S4.SS3.SSS1.p1.1.8" class="ltx_text" style="font-size:90%;"> (exp0), we observe an improvement for all </span><span id="S4.SS3.SSS1.p1.1.9" class="ltx_text" style="font-size:90%;">pre-training methods</span><span id="S4.SS3.SSS1.p1.1.10" class="ltx_text" style="font-size:90%;"> (exp1, exp2, exp3, exp4). In addition, the amount of improvement depends on the activation function (exp1, exp2, exp4). We observe a 66% relative reduction in CER using the quantization method employing the amplitude quantizer with Swish activation </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS3.SSS1.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a><span id="S4.SS3.SSS1.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS3.SSS1.p1.1.13" class="ltx_text" style="font-size:90%;"> and the phase quantizer without any activation (exp4). The CER of the method was lower than that for joint quantization (exp3).</span></p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Results of channel-wise quantization for <span id="S4.T3.5.1" class="ltx_text">far-field in-house</span> dataset. Results are given as relative character error rate reduction (CERR) [%]. A positive value indicates an improvement.</figcaption>
<table id="S4.T3.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.6.1.1" class="ltx_tr">
<th id="S4.T3.6.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.6.1.1.1.1" class="ltx_text" style="font-size:90%;">ID</span></th>
<th id="S4.T3.6.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.6.1.1.2.1" class="ltx_text" style="font-size:90%;">pre-training</span></th>
<th id="S4.T3.6.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.6.1.1.3.1" class="ltx_text" style="font-size:90%;">quantization</span></th>
<th id="S4.T3.6.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.6.1.1.4.1" class="ltx_text" style="font-size:90%;">CERR (%)</span></th>
</tr>
<tr id="S4.T3.6.2.2" class="ltx_tr">
<th id="S4.T3.6.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.6.2.2.1.1" class="ltx_text" style="font-size:90%;">exp0</span></th>
<th id="S4.T3.6.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.6.2.2.2.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T3.6.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.6.2.2.3.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T3.6.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.6.2.2.4.1" class="ltx_text" style="font-size:90%;">0</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.6.3.1" class="ltx_tr">
<th id="S4.T3.6.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.6.3.1.1.1" class="ltx_text" style="font-size:90%;">exp3</span></th>
<td id="S4.T3.6.3.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.6.3.1.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T3.6.3.1.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.6.3.1.3.1" class="ltx_text" style="font-size:90%;">joint</span></td>
<td id="S4.T3.6.3.1.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.6.3.1.4.1" class="ltx_text" style="font-size:90%;">62.1</span></td>
</tr>
<tr id="S4.T3.6.4.2" class="ltx_tr">
<th id="S4.T3.6.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T3.6.4.2.1.1" class="ltx_text" style="font-size:90%;">exp5</span></th>
<td id="S4.T3.6.4.2.2" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.6.4.2.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T3.6.4.2.3" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.6.4.2.3.1" class="ltx_text" style="font-size:90%;">channel</span></td>
<td id="S4.T3.6.4.2.4" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T3.6.4.2.4.1" class="ltx_text" style="font-size:90%;">49.1</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p"><span id="S4.SS3.SSS1.p2.1.1" class="ltx_text" style="font-size:90%;">TableÂ </span><a href="#S4.T3" title="Table 3 â€£ 4.3.1 Far-field in-house dataset â€£ 4.3 Results â€£ 4 Experiments â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S4.SS3.SSS1.p2.1.2" class="ltx_text" style="font-size:90%;"> shows the results of </span><span id="S4.SS3.SSS1.p2.1.3" class="ltx_text" style="font-size:90%;">channel-wise</span><span id="S4.SS3.SSS1.p2.1.4" class="ltx_text" style="font-size:90%;"> quantization. Compared with the result of the model without any </span><span id="S4.SS3.SSS1.p2.1.5" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S4.SS3.SSS1.p2.1.6" class="ltx_text" style="font-size:90%;"> (exp0), the quantization method also reduced CER (exp5). The improvement was greater for joint quantization (exp3) than for </span><span id="S4.SS3.SSS1.p2.1.7" class="ltx_text" style="font-size:90%;">channel-wise</span><span id="S4.SS3.SSS1.p2.1.8" class="ltx_text" style="font-size:90%;"> quantization (exp5).</span></p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>CHiME-4 dataset</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p"><span id="S4.SS3.SSS2.p1.1.1" class="ltx_text" style="font-size:90%;">TableÂ </span><a href="#S4.T4" title="Table 4 â€£ 4.3.2 CHiME-4 dataset â€£ 4.3 Results â€£ 4 Experiments â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S4.SS3.SSS2.p1.1.2" class="ltx_text" style="font-size:90%;"> shows the results of </span><span id="S4.SS3.SSS2.p1.1.3" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S4.SS3.SSS2.p1.1.4" class="ltx_text" style="font-size:90%;"> quantization for the </span><span id="S4.SS3.SSS2.p1.1.5" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="S4.SS3.SSS2.p1.1.6" class="ltx_text" style="font-size:90%;"> dataset.
Compared with the result of the model without any </span><span id="S4.SS3.SSS2.p1.1.7" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S4.SS3.SSS2.p1.1.8" class="ltx_text" style="font-size:90%;"> (expA), we observe an improvement for all </span><span id="S4.SS3.SSS2.p1.1.9" class="ltx_text" style="font-size:90%;">pre-training methods</span><span id="S4.SS3.SSS2.p1.1.10" class="ltx_text" style="font-size:90%;"> (expB, expC, expD, expE), the same as that for the </span><span id="S4.SS3.SSS2.p1.1.11" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S4.SS3.SSS2.p1.1.12" class="ltx_text" style="font-size:90%;"> dataset. We observe a 2.4% relative reduction in WER using the quantization method employing the amplitude quantizer with Swish activation and the phase quantizer with Swish activation (expB). We observe a 4.2% relative reduction in CER using the quantization method employing the amplitude quantizer with Swish activation and the phase quantizer without any activation (expE). Comparing the improvement of CER the for </span><span id="S4.SS3.SSS2.p1.1.13" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S4.SS3.SSS2.p1.1.14" class="ltx_text" style="font-size:90%;"> dataset, the improvement of CER for the </span><span id="S4.SS3.SSS2.p1.1.15" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="S4.SS3.SSS2.p1.1.16" class="ltx_text" style="font-size:90%;"> dataset was small. We concluded that this is caused by the amount of training data in the </span><span id="S4.SS3.SSS2.p1.1.17" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="S4.SS3.SSS2.p1.1.18" class="ltx_text" style="font-size:90%;"> dataset being smaller than that in the </span><span id="S4.SS3.SSS2.p1.1.19" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S4.SS3.SSS2.p1.1.20" class="ltx_text" style="font-size:90%;"> dataset.</span></p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Results of feature-wise quantization for <span id="S4.T4.5.1" class="ltx_text">CHiME-4</span> dataset. Results are given as relative character error rate reduction (CERR) [%] and relative word error rate reduction (WERR) [%]. A positive value indicates an improvement.</figcaption>
<div id="S4.T4.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:266.5pt;height:86.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-57.1pt,18.5pt) scale(0.7,0.7) ;">
<table id="S4.T4.6.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.6.1.1.1" class="ltx_tr">
<th id="S4.T4.6.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.1.1.1.1" class="ltx_text" style="font-size:90%;">ID</span></th>
<th id="S4.T4.6.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.1.1.2.1" class="ltx_text" style="font-size:90%;">pre-training</span></th>
<th id="S4.T4.6.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.1.1.3.1" class="ltx_text" style="font-size:90%;">quantization</span></th>
<th id="S4.T4.6.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<span id="S4.T4.6.1.1.1.4.1" class="ltx_inline-block">
<span id="S4.T4.6.1.1.1.4.1.1" class="ltx_p"><span id="S4.T4.6.1.1.1.4.1.1.1" class="ltx_text" style="font-size:90%;">amplitude</span></span>
<span id="S4.T4.6.1.1.1.4.1.2" class="ltx_p"><span id="S4.T4.6.1.1.1.4.1.2.1" class="ltx_text" style="font-size:90%;">quantizer</span></span>
<span id="S4.T4.6.1.1.1.4.1.3" class="ltx_p"><span id="S4.T4.6.1.1.1.4.1.3.1" class="ltx_text" style="font-size:90%;">activation</span></span>
</span>
</th>
<th id="S4.T4.6.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<span id="S4.T4.6.1.1.1.5.1" class="ltx_inline-block">
<span id="S4.T4.6.1.1.1.5.1.1" class="ltx_p"><span id="S4.T4.6.1.1.1.5.1.1.1" class="ltx_text" style="font-size:90%;">phase</span></span>
<span id="S4.T4.6.1.1.1.5.1.2" class="ltx_p"><span id="S4.T4.6.1.1.1.5.1.2.1" class="ltx_text" style="font-size:90%;">quantizer</span></span>
<span id="S4.T4.6.1.1.1.5.1.3" class="ltx_p"><span id="S4.T4.6.1.1.1.5.1.3.1" class="ltx_text" style="font-size:90%;">activation</span></span>
</span>
</th>
<th id="S4.T4.6.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.1.1.6.1" class="ltx_text" style="font-size:90%;">CERR (%)</span></th>
<th id="S4.T4.6.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.1.1.7.1" class="ltx_text" style="font-size:90%;">WERR (%)</span></th>
</tr>
<tr id="S4.T4.6.1.2.2" class="ltx_tr">
<th id="S4.T4.6.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.2.2.1.1" class="ltx_text" style="font-size:90%;">expA</span></th>
<th id="S4.T4.6.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.2.2.2.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T4.6.1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.2.2.3.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T4.6.1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.2.2.4.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T4.6.1.2.2.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.2.2.5.1" class="ltx_text" style="font-size:90%;">-</span></th>
<th id="S4.T4.6.1.2.2.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.2.2.6.1" class="ltx_text" style="font-size:90%;">0</span></th>
<th id="S4.T4.6.1.2.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.6.1.2.2.7.1" class="ltx_text" style="font-size:90%;">0</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.6.1.3.1" class="ltx_tr">
<td id="S4.T4.6.1.3.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.6.1.3.1.1.1" class="ltx_text" style="font-size:90%;">expB</span></td>
<td id="S4.T4.6.1.3.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.6.1.3.1.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T4.6.1.3.1.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.6.1.3.1.3.1" class="ltx_text" style="font-size:90%;">feature</span></td>
<td id="S4.T4.6.1.3.1.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.6.1.3.1.4.1" class="ltx_text" style="font-size:90%;">Swish</span></td>
<td id="S4.T4.6.1.3.1.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.6.1.3.1.5.1" class="ltx_text" style="font-size:90%;">Swish</span></td>
<td id="S4.T4.6.1.3.1.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.6.1.3.1.6.1" class="ltx_text" style="font-size:90%;">3.6</span></td>
<td id="S4.T4.6.1.3.1.7" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T4.6.1.3.1.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">2.4</span></td>
</tr>
<tr id="S4.T4.6.1.4.2" class="ltx_tr">
<td id="S4.T4.6.1.4.2.1" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.4.2.1.1" class="ltx_text" style="font-size:90%;">expC</span></td>
<td id="S4.T4.6.1.4.2.2" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.4.2.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T4.6.1.4.2.3" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.4.2.3.1" class="ltx_text" style="font-size:90%;">feature</span></td>
<td id="S4.T4.6.1.4.2.4" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.4.2.4.1" class="ltx_text" style="font-size:90%;">Swish</span></td>
<td id="S4.T4.6.1.4.2.5" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.4.2.5.1" class="ltx_text" style="font-size:90%;">ReLU</span></td>
<td id="S4.T4.6.1.4.2.6" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.4.2.6.1" class="ltx_text" style="font-size:90%;">2.6</span></td>
<td id="S4.T4.6.1.4.2.7" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.4.2.7.1" class="ltx_text" style="font-size:90%;">1.7</span></td>
</tr>
<tr id="S4.T4.6.1.5.3" class="ltx_tr">
<td id="S4.T4.6.1.5.3.1" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.5.3.1.1" class="ltx_text" style="font-size:90%;">expD</span></td>
<td id="S4.T4.6.1.5.3.2" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.5.3.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T4.6.1.5.3.3" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.5.3.3.1" class="ltx_text" style="font-size:90%;">joint</span></td>
<td id="S4.T4.6.1.5.3.4" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.5.3.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T4.6.1.5.3.5" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.5.3.5.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T4.6.1.5.3.6" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.5.3.6.1" class="ltx_text" style="font-size:90%;">3.2</span></td>
<td id="S4.T4.6.1.5.3.7" class="ltx_td ltx_align_left"><span id="S4.T4.6.1.5.3.7.1" class="ltx_text" style="font-size:90%;">1.4</span></td>
</tr>
<tr id="S4.T4.6.1.6.4" class="ltx_tr">
<td id="S4.T4.6.1.6.4.1" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T4.6.1.6.4.1.1" class="ltx_text" style="font-size:90%;">expE</span></td>
<td id="S4.T4.6.1.6.4.2" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T4.6.1.6.4.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S4.T4.6.1.6.4.3" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T4.6.1.6.4.3.1" class="ltx_text" style="font-size:90%;">feature</span></td>
<td id="S4.T4.6.1.6.4.4" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T4.6.1.6.4.4.1" class="ltx_text" style="font-size:90%;">Swish</span></td>
<td id="S4.T4.6.1.6.4.5" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T4.6.1.6.4.5.1" class="ltx_text" style="font-size:90%;">None</span></td>
<td id="S4.T4.6.1.6.4.6" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T4.6.1.6.4.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.2</span></td>
<td id="S4.T4.6.1.6.4.7" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T4.6.1.6.4.7.1" class="ltx_text" style="font-size:90%;">0.1</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Analysis of hidden vectors</h3>

<figure id="S4.F5" class="ltx_figure"><img src="/html/2408.02945/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="180" height="98" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Analysis of hidden vectors after self-supervised learning.</figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text" style="font-size:90%;">We next analyze the hidden vectors from the </span><span id="S4.SS4.p1.1.2" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS4.p1.1.3" class="ltx_text" style="font-size:90%;"> audio encoder after </span><span id="S4.SS4.p1.1.4" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S4.SS4.p1.1.5" class="ltx_text" style="font-size:90%;">. FigureÂ </span><a href="#S4.F5" title="Figure 5 â€£ 4.4 Analysis of hidden vectors â€£ 4 Experiments â€£ Self-Supervised Learning for Multi-Channel Neural Transducer" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S4.SS4.p1.1.6" class="ltx_text" style="font-size:90%;"> shows hidden vectors from </span><span id="S4.SS4.p1.1.7" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS4.p1.1.8" class="ltx_text" style="font-size:90%;"> audio encoders trained by different quantization methods for the </span><span id="S4.SS4.p1.1.9" class="ltx_text" style="font-size:90%;">far-field in-house dataset</span><span id="S4.SS4.p1.1.10" class="ltx_text" style="font-size:90%;">. The upper figure shows the </span><span id="S4.SS4.p1.1.11" class="ltx_text" style="font-size:90%;">log-STFT</span><span id="S4.SS4.p1.1.12" class="ltx_text" style="font-size:90%;"> square magnitude. The middle figure shows the hidden vector from the </span><span id="S4.SS4.p1.1.13" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS4.p1.1.14" class="ltx_text" style="font-size:90%;"> audio encoder trained by joint quantization (exp3). The lower figure shows the hidden vector from the </span><span id="S4.SS4.p1.1.15" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS4.p1.1.16" class="ltx_text" style="font-size:90%;"> audio encoder trained by </span><span id="S4.SS4.p1.1.17" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S4.SS4.p1.1.18" class="ltx_text" style="font-size:90%;"> quantization (exp4). By comparing the hidden vectors, we observe a clearer contrast between the speech and noise sections for </span><span id="S4.SS4.p1.1.19" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S4.SS4.p1.1.20" class="ltx_text" style="font-size:90%;"> quantization. This result suggests that the </span><span id="S4.SS4.p1.1.21" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS4.p1.1.22" class="ltx_text" style="font-size:90%;"> audio encoder trained by </span><span id="S4.SS4.p1.1.23" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S4.SS4.p1.1.24" class="ltx_text" style="font-size:90%;"> quantization learns the latent representation better than the </span><span id="S4.SS4.p1.1.25" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S4.SS4.p1.1.26" class="ltx_text" style="font-size:90%;"> audio encoder trained by joint quantization in terms of noise robustness.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text" style="font-size:90%;">In this work, we trained a </span><span id="S5.p1.1.2" class="ltx_text" style="font-size:90%;">multi-channel</span><span id="S5.p1.1.3" class="ltx_text" style="font-size:90%;"> neural transducer based on wav2vec 2.0 </span><span id="S5.p1.1.4" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S5.p1.1.5" class="ltx_text" style="font-size:90%;">.
For the training, we explored three quantization methods: joint quantization, </span><span id="S5.p1.1.6" class="ltx_text" style="font-size:90%;">feature-wise</span><span id="S5.p1.1.7" class="ltx_text" style="font-size:90%;"> quantization and </span><span id="S5.p1.1.8" class="ltx_text" style="font-size:90%;">channel-wise quantization</span><span id="S5.p1.1.9" class="ltx_text" style="font-size:90%;">.
We reported the results of experiments using the </span><span id="S5.p1.1.10" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S5.p1.1.11" class="ltx_text" style="font-size:90%;"> and public datasets. We experimentally showed that the </span><span id="S5.p1.1.12" class="ltx_text" style="font-size:90%;">feature-wise quantization</span><span id="S5.p1.1.13" class="ltx_text" style="font-size:90%;"> method had the best performance. We observed 66% and 4.2% relative reductions in CER compared with the model without any </span><span id="S5.p1.1.14" class="ltx_text" style="font-size:90%;">pre-training</span><span id="S5.p1.1.15" class="ltx_text" style="font-size:90%;"> for the </span><span id="S5.p1.1.16" class="ltx_text" style="font-size:90%;">far-field in-house</span><span id="S5.p1.1.17" class="ltx_text" style="font-size:90%;"> and </span><span id="S5.p1.1.18" class="ltx_text" style="font-size:90%;">CHiME-4</span><span id="S5.p1.1.19" class="ltx_text" style="font-size:90%;"> datasets, respectively.</span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
W. Chan, N. Jaitly, Q. Le and O. Vinyals,
â€œListen, attend and spell: A neural network for large vocabulary conversational speech recognition,â€
in </span><span id="bib.bib1.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ICASSP</span><span id="bib.bib1.3.3" class="ltx_text" style="font-size:90%;">, 2016. </span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
A. Graves, S. FernÃ¡ndez, F. Gomez and J. Schmidhuber,
â€œConnectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks,â€
in </span><span id="bib.bib2.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ICML</span><span id="bib.bib2.3.3" class="ltx_text" style="font-size:90%;">, 2006.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
A. Graves,
â€œSequence transduction with recurrent neural networks,â€
</span><span id="bib.bib3.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1211.3711</span><span id="bib.bib3.3.3" class="ltx_text" style="font-size:90%;">, 2012.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
A. Baevski, H. Zhou, A. Mohamed and M. Auli,
â€œwav2vec 2.0: A framework for self-supervised learning of speech representations,â€
</span><span id="bib.bib4.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2006.11477</span><span id="bib.bib4.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
J. Devlin, M.-W. Chang, K. Lee and K. Toutanova,
â€œBert: Pre-training of deep bidirectional transformers for language understanding,â€
arXiv, abs/1810.04805, 2018. </span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Y. Zhang, J. Qin, D. S. Park, W. Han, C.-C. Chiu, R. Pang, Q. V. Le and Y. Wu,
â€œPushing the limits of semi-supervised learning for automatic speech recognition,â€
</span><span id="bib.bib6.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2010.10504</span><span id="bib.bib6.3.3" class="ltx_text" style="font-size:90%;">, 2020. </span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
S. Sadhu, D. He, C.-W. Huang, S. H. Mallidi, M. Wu, A. Rastrow, A. Stolcke, J. Droppo and R. Maas,
â€œWav2vec-C: A self-supervised model for speech representation learning,â€
in </span><span id="bib.bib7.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH</span><span id="bib.bib7.3.3" class="ltx_text" style="font-size:90%;">, 2021. </span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
R. Haeb-Umbach, J. Heymann, L. Drude, S. Watanabe, M. Delcroix and T. Nakatani,
â€œFar-field automatic speech recognition,â€
</span><span id="bib.bib8.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. IEEE</span><span id="bib.bib8.3.3" class="ltx_text" style="font-size:90%;">, 2020. </span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">E. Vincent, S. Watanabe, A. A. Nugraha, J. Barker and R. Marxer,
â€œAn analysis of environment, microphone and data simulation mismatches in robust speech recognition,â€ </span><span id="bib.bib9.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Speech &amp; Language</span><span id="bib.bib9.3.3" class="ltx_text" style="font-size:90%;">, vol. 46, pp. 535-557, 2017.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;"> T. Ochiai, S. Watanabe, T. Hori and J. R. Hershey,
â€œMultichannel end-to-end speech recognition,â€ </span><span id="bib.bib10.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1703.04783</span><span id="bib.bib10.3.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;"> X. Chang, W. Zhang, Y. Qian, J. Le Roux and S. Watanabe,
â€œMIMO-SPEECH: End-to-end multi-channel multi-speaker speech recognition,â€ in </span><span id="bib.bib11.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ASRU</span><span id="bib.bib11.3.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
A. S. Subramanian, X. Wang, S. Watanabe, T. Taniguchi, D. Tran and Y. Fujita,
â€œAn investigation of end-to-end multichannel speech recognition for reverberant and mismatch conditions,â€ </span><span id="bib.bib12.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1904.09049</span><span id="bib.bib12.3.3" class="ltx_text" style="font-size:90%;">, 2019. </span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;"> F. Chang, M. Radfar, A. Mouchtaris, B. King and S. Kunzmann,
â€œEnd-to-end multi-channel Transformer for speech recognition,â€ in </span><span id="bib.bib13.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ICASSP</span><span id="bib.bib13.3.3" class="ltx_text" style="font-size:90%;">, 2021. </span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
F. Chang, M. Radfar, A. Mouchtaris and M. Omologo,
â€œMulti-channel Transformer Transducer for speech recognition,â€ in </span><span id="bib.bib14.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH</span><span id="bib.bib14.3.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
B. Li, T. N. Sainath, R. J. Weiss, K. W. Wilson and M. Bacchiani,
â€œNeural network adaptive beamforming for robust multichannel speech recognition,â€ in </span><span id="bib.bib15.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH</span><span id="bib.bib15.3.3" class="ltx_text" style="font-size:90%;">, 2016. </span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">C. F. Yeh, J. Mahadeokar, K. Kalgaonkar, Y. Wang, D. Le, M. Jain, K. Schubert, C. Fuegen and M. L. Seltzer,
â€œTransformerâ€“Transducer: End-to-end speech recognition with self-attention,â€
in </span><span id="bib.bib16.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH</span><span id="bib.bib16.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">Q. Zhang, H. Lu, H. Sak, A. Tripathi, E. McDermott, S. Koo and S. Kumar,
â€œTransformer Transducer: A streamable speech recognition model with Transformer encoders and RNNâ€“T loss,â€
in </span><span id="bib.bib17.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH</span><span id="bib.bib17.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
A. Gulati, J. Qin, C.-C. Chiu, N. Parmar, Y. Zhang, J. Yu, W. Han, S. Wang, Z. Zhang, Y. Wu and R. Pang,
â€œConformer: Convolution-augmented transformer for speech recognition,â€in </span><span id="bib.bib18.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH</span><span id="bib.bib18.3.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
J. Heymann, L. Drude and R. Haeb-Umbach,
â€œNeural network based spectral mask estimation for acoustic beamforming,â€ in </span><span id="bib.bib19.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ICASSP</span><span id="bib.bib19.3.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
H. Erdogan, J. Hershey, S. Watanabe, M. Mandel, and J. Le Roux,
â€œImproved MVDR beamforming using single-channel mask prediction networks,â€ in </span><span id="bib.bib20.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH</span><span id="bib.bib20.3.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
T. Higuchi, K. Kinoshita, N. Ito, S. Karita and T. Nakatani,
â€œFrame-by-frame closed-form update for mask-based adaptive MVDR beamforming,â€ in </span><span id="bib.bib21.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ICASSP</span><span id="bib.bib21.3.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;"> A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, L. Kaiser and I. Polosukhin,
â€œAttention is all you need,â€
in </span><span id="bib.bib22.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. NIPS</span><span id="bib.bib22.3.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Z. Wang, J. Le Roux and J. R. Hershey,
â€œMulti-channel deep clustering: Discriminative spectral and spatial embeddings for speaker-independent speech separation,â€ in </span><span id="bib.bib23.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ICASSP</span><span id="bib.bib23.3.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
D. S. Park, W. Chan, Y. Zhang, C. Chiu, B. Zoph, E. D. Cubuk and Q. V. Le,
â€œSpecAugment: A simple data augmentation method for automatic speech recognition,â€
in </span><span id="bib.bib24.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH</span><span id="bib.bib24.3.3" class="ltx_text" style="font-size:90%;">, 2019. </span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
D. P. Kingma and J. Ba,
â€œAdam: A method for stochastic optimization,â€
in </span><span id="bib.bib25.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ICLR</span><span id="bib.bib25.3.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein,
L. Antiga, A. Desmaison, A. KÃ¶pf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai and S. Chintala,
â€œPyTorch: An imperative style, high-performance deep learning library,â€
in </span><span id="bib.bib26.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. NeurIPS</span><span id="bib.bib26.3.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
P. Ramachandran, B. Zoph and Q. V Le,
â€œSearching for activation functions,â€
</span><span id="bib.bib27.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1710.05941</span><span id="bib.bib27.3.3" class="ltx_text" style="font-size:90%;">, 2017. </span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.02944" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.02945" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.02945">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.02945" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.02946" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 16:03:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
