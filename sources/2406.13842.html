<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.13842] Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control</title><meta property="og:description" content="Utilizing air-traffic control (ATC) data for downstream natural-language processing tasks requires preprocessing steps. Key steps are the transcription of the data via automatic speech recognition (ASR) and speaker dia…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.13842">

<!--Generated on Sat Jul  6 01:51:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.2" class="ltx_ERROR undefined">\name</span>
<p id="p1.3" class="ltx_p">[]AlexanderBlatt
<span id="p1.3.1" class="ltx_ERROR undefined">\name</span>[]AravindKrishnan
<span id="p1.3.2" class="ltx_ERROR undefined">\name</span>[]DietrichKlakow</p>
</div>
<h1 class="ltx_title ltx_title_document">Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Utilizing air-traffic control (ATC) data for downstream natural-language processing tasks requires preprocessing steps. Key steps are the transcription of the data via automatic speech recognition (ASR) and speaker diarization, respectively speaker role detection (SRD) to divide the transcripts into pilot and air-traffic controller (ATCO) transcripts. While traditional approaches take on these tasks separately, we propose a transformer-based joint ASR-SRD system that solves both tasks jointly while relying on a standard ASR architecture. We compare this joint system against two cascaded approaches for ASR and SRD on multiple ATC datasets. Our study shows in which cases our joint system can outperform the two traditional approaches and in which cases the other architectures are preferable. We additionally evaluate how acoustic and lexical differences influence all architectures and show how to overcome them for our joint architecture.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>diarization, speech recognition, speaker role detection, air-traffic control
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">A standard speech processing pipeline starts with a speaker diarization (SD) module, which removes the unvoiced parts of the audio and leaves speaker labeled voiced chunks. These chunks are fed into an automatic speech recognition (ASR) system for transcription. The transcribed audio can then be further processed for example with a natural language processing (NLP) module for information extraction. Recent architectures that combine SD and ASR show however, that they can outperform this traditional pipeline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> by jointly utilizing acoustic and linguistic information during diarization.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The acoustic and linguistic information of air-traffic control (ATC) datasets however differs significantly from standard ASR and diarization datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. ATC recordings typically have a low signal-to-noise ratio (SNR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> and a strict phraseology<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>ATC examples: https://wiki.flightgear.org/ATC_phraseology</span></span></span>, which ensures an effective communication between air-traffic controllers (ATCOs) and pilots. Pilot and ATCO utterances differ in the noise level as well as in the sentence structure. This can be utilized by a SD system to differentiate between the two speaker roles <span id="S1.p2.1.1" class="ltx_text ltx_font_typewriter">ATCO</span> or <span id="S1.p2.1.2" class="ltx_text ltx_font_typewriter">PILOT</span>, which effectively leverages it to a speaker role detection (SRD) system.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this work, we study how a SRD system can effectively utilize the acoustic and linguistc differences between pilot and ATCO speech by analyzing the performance, respectively robustness of different ASR&amp;SRD architectures on multiple ATC datasets. We investigate a correlation to acoustic and linguistic properties as well as a correlation between the ASR and SRD performance. We compare three different architectures for ATC-ASR&amp;SRD. The first method, <span id="S1.p3.1.1" class="ltx_text ltx_font_typewriter">SRD-ASR</span>, consists of an acoustic-based speaker-role detection step followed by the ASR step. The second method, <span id="S1.p3.1.2" class="ltx_text ltx_font_typewriter">ASR-SRD</span>, first transcribes the audio before doing text-based SRD. Our proposed <span id="S1.p3.1.3" class="ltx_text ltx_font_typewriter">Joint</span> method performs SRD and ASR simultaneously.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Park et al. give good general overview of speaker diarization methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Our <span id="S2.p1.1.1" class="ltx_text ltx_font_typewriter">Joint</span> system is inspired by Shafey et al. which have first introduced a joint ASR&amp;SD system based on a recurrent neural network transducer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. In contrast to Shafey et al., our system performs SRD and does not require transducers, but relies on standard transformer-based ASR models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and can be trained with traditional CTC loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Recent joint ASR&amp;SD systems require even more complex architectures than the approach of Shafey et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Our text-based SRD system is based on BERTraffic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, which shows a 7.7 % improvement over a classical variational Bayesian hidden Markov model (VBx) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> based approach and is to the best of our knowledge the most recent SRD model for ATC. I a previous work, we have shown that acoustic and linguistic differences between ATC datasets negatively correlate with the performance of pretrained transformer-based ASR models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Thus, we investigate if there is a similar correlation for SRD.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Datasets</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We use the ATCO2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, LiveATC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and the LDC-ATCC corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> for our experiments, since they all contain speaker labels, that allow to assign each speaker either to the <span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">ATCO</span> or <span id="S3.p1.1.2" class="ltx_text ltx_font_typewriter">PILOT</span> class. All three corpora contain ATC communication recordings. The LDC-ATCC corpus contains solely recordings from American airports, namely Dallas Fort Worth International Airport (KDFW), Logan International Airport (KBOS) and Ronald Reagan Washington National Airport (KDCA), while the ATCO2 and LiveATC datasets contain mainly samples from European airports. They both contain samples from Václav Havel Airport Prague (LKPR) and Zurich Airport (LSZH). The ATCO2 dataset contains additionally samples from Sion Airport (LSGS), Bratislava Airport (LZIB), Bern Airport (LSZB) and Sydney Airport (YSSY) as only non-European airport. The Live ATC dataset contains additionally samples from Stockholm Västerås Airport (ESOW), Göteborg Landvetter Airport (ESGG), Dublin Airport (EIDW), Amsterdam Airport Schiphol (EHAM) and Hartsfield–Jackson Atlanta International Airport (KATL) as only American airport. All airport locations are marked in <a href="#S3.F1" title="Figure 1 ‣ 3 Datasets ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>(b). The ATCO2 corpus and the LiveATC corpus were recorded during the ATCO2 project<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>ATCO2 project: https://www.atco2.org/</span></span></span>. While the ATCO2 data was recorded with VHF-receivers<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Receiver guide: https://ui.atc.opensky-network.org/intro</span></span></span>, the LiveATC corpus, consisting of the two subcorpora LiveATC1 and LiveATC2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, was recorded from the LiveATC web-page<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>LiveATC webpage: https://www.liveatc.net/</span></span></span> which broadcasts ATC conversations. The ATCO2 and LiveATC dataset audio samples are recorded with a sampling frequency of 16 kHz and 16-bit, while the LDC-ATCC data is recorded with 8 kHz and 16-bit.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Number of samples for the train|test|val split and the mean WADA-SNR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, mean number of speaker turns and the mean (chunked) audio duration for each dataset.</figcaption>
<table id="S3.T1.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.6.1.1" class="ltx_tr">
<th id="S3.T1.6.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.1.1.1.1" class="ltx_text" style="font-size:80%;">Dataset</span></th>
<th id="S3.T1.6.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.1.1.2.1" class="ltx_text" style="font-size:80%;">Train</span></th>
<th id="S3.T1.6.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.1.1.3.1" class="ltx_text" style="font-size:80%;">Val</span></th>
<th id="S3.T1.6.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.1.1.4.1" class="ltx_text" style="font-size:80%;">Test</span></th>
<th id="S3.T1.6.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.1.1.5.1" class="ltx_text" style="font-size:80%;">SNR</span></th>
<th id="S3.T1.6.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.1.1.6.1" class="ltx_text" style="font-size:80%;">Turns</span></th>
<th id="S3.T1.6.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.1.1.7.1" class="ltx_text" style="font-size:80%;">Duration</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.6.2.1" class="ltx_tr">
<td id="S3.T1.6.2.1.1" class="ltx_td" style="padding-left:3.6pt;padding-right:3.6pt;"></td>
<th id="S3.T1.6.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.2.1.2.1" class="ltx_text" style="font-size:80%;">size</span></th>
<th id="S3.T1.6.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.2.1.3.1" class="ltx_text" style="font-size:80%;">size</span></th>
<th id="S3.T1.6.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.2.1.4.1" class="ltx_text" style="font-size:80%;">size</span></th>
<th id="S3.T1.6.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.2.1.5.1" class="ltx_text" style="font-size:80%;">(dB)</span></th>
<th id="S3.T1.6.2.1.6" class="ltx_td ltx_th ltx_th_column" style="padding-left:3.6pt;padding-right:3.6pt;"></th>
<th id="S3.T1.6.2.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.2.1.7.1" class="ltx_text" style="font-size:80%;">(s)</span></th>
</tr>
<tr id="S3.T1.6.3.2" class="ltx_tr">
<td id="S3.T1.6.3.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.3.2.1.1" class="ltx_text" style="font-size:80%;">ATCO2</span></td>
<td id="S3.T1.6.3.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.3.2.2.1" class="ltx_text" style="font-size:80%;">856</span></td>
<td id="S3.T1.6.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.3.2.3.1" class="ltx_text" style="font-size:80%;">107</span></td>
<td id="S3.T1.6.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.3.2.4.1" class="ltx_text" style="font-size:80%;">108</span></td>
<td id="S3.T1.6.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.3.2.5.1" class="ltx_text" style="font-size:80%;">15.8</span></td>
<td id="S3.T1.6.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.3.2.6.1" class="ltx_text" style="font-size:80%;">2.28</span></td>
<td id="S3.T1.6.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.3.2.7.1" class="ltx_text" style="font-size:80%;">9.4</span></td>
</tr>
<tr id="S3.T1.6.4.3" class="ltx_tr">
<td id="S3.T1.6.4.3.1" class="ltx_td ltx_align_left" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.4.3.1.1" class="ltx_text" style="font-size:80%;">LDC-ATCC</span></td>
<td id="S3.T1.6.4.3.2" class="ltx_td ltx_align_center" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.4.3.2.1" class="ltx_text" style="font-size:80%;">1000</span></td>
<td id="S3.T1.6.4.3.3" class="ltx_td ltx_align_center" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.4.3.3.1" class="ltx_text" style="font-size:80%;">500</span></td>
<td id="S3.T1.6.4.3.4" class="ltx_td ltx_align_center" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.4.3.4.1" class="ltx_text" style="font-size:80%;">500</span></td>
<td id="S3.T1.6.4.3.5" class="ltx_td ltx_align_center" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.4.3.5.1" class="ltx_text" style="font-size:80%;">16.8</span></td>
<td id="S3.T1.6.4.3.6" class="ltx_td ltx_align_center" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.4.3.6.1" class="ltx_text" style="font-size:80%;">3.26</span></td>
<td id="S3.T1.6.4.3.7" class="ltx_td ltx_align_center" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.4.3.7.1" class="ltx_text" style="font-size:80%;">13.1</span></td>
</tr>
<tr id="S3.T1.6.5.4" class="ltx_tr">
<td id="S3.T1.6.5.4.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.5.4.1.1" class="ltx_text" style="font-size:80%;">LiveATC</span></td>
<td id="S3.T1.6.5.4.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.5.4.2.1" class="ltx_text" style="font-size:80%;">413</span></td>
<td id="S3.T1.6.5.4.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.5.4.3.1" class="ltx_text" style="font-size:80%;">42</span></td>
<td id="S3.T1.6.5.4.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.5.4.4.1" class="ltx_text" style="font-size:80%;">41</span></td>
<td id="S3.T1.6.5.4.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.5.4.5.1" class="ltx_text" style="font-size:80%;">18.9</span></td>
<td id="S3.T1.6.5.4.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.5.4.6.1" class="ltx_text" style="font-size:80%;">2.15</span></td>
<td id="S3.T1.6.5.4.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.6pt;padding-right:3.6pt;"><span id="S3.T1.6.5.4.7.1" class="ltx_text" style="font-size:80%;">12.9</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Several preprocessing steps are necessary to prepare the datasets for the SRD task. To reduce the training time to a few hours per run, the original audio is chunked to samples with a target duration of 2-19 seconds. The mean chunk duration can be found in <a href="#S3.T1" title="Table 1 ‣ 3 Datasets ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>. This results in 2-3 speaker turns on average as <a href="#S3.T1" title="Table 1 ‣ 3 Datasets ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a> shows. Samples that just contain one speaker, respectively one speaker role, are sorted out. Using the timestamps for the speaker IDs, each speaker turn is labeled with one of the two speaker roles, <span id="S3.p2.1.1" class="ltx_text ltx_font_typewriter">ATCO</span> or <span id="S3.p2.1.2" class="ltx_text ltx_font_typewriter">PILOT</span>. This results in transcripts, where word sequences belonging to one speaker role are tagged with
either <span id="S3.p2.1.3" class="ltx_text ltx_font_typewriter">ATCOTAG</span> or <span id="S3.p2.1.4" class="ltx_text ltx_font_typewriter">PILOTTAG</span> as shown in <a href="#S4.F2" title="Figure 2 ‣ 4 ASR&amp;SRD architectures ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>. For fine-tuning the ASR models of <span id="S3.p2.1.5" class="ltx_text ltx_font_typewriter">SRD-ASR</span> and <span id="S3.p2.1.6" class="ltx_text ltx_font_typewriter">ASR-SRD</span>, the tags are removed from the transcripts.</p>
</div>
<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S3.F1.1" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:186.5pt;">
<p id="S3.F1.1.1" class="ltx_p ltx_align_center"><span id="S3.F1.1.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/noiseDistribution.png" id="S3.F1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption"></span></p>
<p id="S3.F1.1.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S3.F1.1.2.1" class="ltx_text">(a) Noise Distribution</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S3.F1.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:236.3pt;">
<p id="S3.F1.2.1" class="ltx_p ltx_align_center"><span id="S3.F1.2.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/locations2.png" id="S3.F1.2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="308" alt="Refer to caption"></span></p>
<p id="S3.F1.2.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S3.F1.2.2.1" class="ltx_text">(b) Geographical Distribution</span></p>
</div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Dataset dependent distributions</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>ASR&amp;SRD architectures</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">For the ASR task of all ASR&amp;SRD architectures, we fine-tune the Hugging Face (HF) models wav2vec 2.0<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>HF model: facebook/wav2vec2-base-960h</span></span></span> (w2v2) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and xlsr<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>HF model: jonatasgrosman/wav2vec2-large-xlsr-53-english</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> on the train split of each ATC dataset.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div id="S4.F2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:433.6pt;">
<p id="S4.F2.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S4.F2.1.1.1" class="ltx_text"><img src="/html/2406.13842/assets/x1.png" id="S4.F2.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="438" height="276" alt="Refer to caption"></span></p>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>ASR&amp;SRD architectures; left: acoustic SRD followed by ASR (<span id="S4.F2.5.1" class="ltx_text ltx_font_typewriter">SRD-ASR</span>); center: Joint ASR&amp;SRD (<span id="S4.F2.6.2" class="ltx_text ltx_font_typewriter">Joint</span>); right: ASR followed by linguistic-based SRD (<span id="S4.F2.7.3" class="ltx_text ltx_font_typewriter">ASR-SRD</span>)</figcaption>
</figure>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Each ASR&amp;SRD architecture is visualized in <a href="#S4.F2" title="Figure 2 ‣ 4 ASR&amp;SRD architectures ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a> and explained in the following sections.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>SRD-ASR</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">For the SRD task of the <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">SRD-ASR</span> model we use the SD of Pyannote.audio 3.0<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>HF model: pyannote/speaker-diarization-3.0</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> which combines speaker segmentation with speaker embedding based clustering for SD. The SD tool is used out-of-the-box without further fine-tuning. Just the <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">max_speakers</span> argument is set to 2, restricting diarization to two speakers. To leverage this SD to a SRD system, the extracted speakers are matched to the speaker roles by extracting the speaker embeddings of the identified speaker with the Pyannote speaker embedding extraction model<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>HF model: pyannote/embedding</span></span></span>. The classification into <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">PILOT</span> and <span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_typewriter">ATCO</span> is done via measuring the cosine similarity between the speaker embeddings and the cluster centers of the two speaker roles for the current training data set. The cluster centers are extracted with a nearest centroid classifier<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>scikitlearn: Nearest centroid classifier</span></span></span> for each training data set by randomly selecting 50 samples for <span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_typewriter">PILOT</span> and <span id="S4.SS1.p1.1.6" class="ltx_text ltx_font_typewriter">ATCO</span>. The speaker role tagged utterance chunks that are produced by the SRD system are then fed into the ASR model to generate the tagged transcripts.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>ASR-SRD</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In this approach, we train a text-based diarizer using token-level speaker labels, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Each word in an utterance is assigned an <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">ATCO</span> or <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">PILOT</span> tag and a binary classifier is trained to predict the tag of each token. We encode <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_typewriter">ATCO</span> and <span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_typewriter">PILOT</span> tags consistently across utterances to let the model learn speaker roles in addition to speaker turns. For training, ground truth transcripts from the train set are used. Testing is done on the ASR transcripts generated from the test audio.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Joint</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In the <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">Joint</span> approach, the ASR models (w2v2 &amp; xlsr) are directly fine-tuned on the speaker role tagged transcripts instead of transcripts without tags. Since fine-tuning is done without modifying the CTC-loss function, this approach can be applied to any transformer-based ASR model with CTC loss.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Inter-dataset scores: WDER,PER and WER in case the models are finetuned and tested on different datasets. Mean values over three runs and two training datasets are given with the standard deviation in brackets</figcaption>
<table id="S4.T2.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.3.1.1" class="ltx_tr">
<td id="S4.T2.3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S4.T2.3.1.1.1.1" class="ltx_text" style="font-size:80%;">Architecture</span></td>
<td id="S4.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T2.3.1.1.2.1" class="ltx_text" style="font-size:80%;">ASR</span></td>
<td id="S4.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T2.3.1.1.3.1" class="ltx_text" style="font-size:80%;">ATCO2</span></td>
<td id="S4.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T2.3.1.1.4.1" class="ltx_text" style="font-size:80%;">LDC-ATCC</span></td>
<td id="S4.T2.3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T2.3.1.1.5.1" class="ltx_text" style="font-size:80%;">LiveATC</span></td>
</tr>
<tr id="S4.T2.3.2.2" class="ltx_tr">
<td id="S4.T2.3.2.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.1.1" class="ltx_text" style="font-size:80%;">WDER</span></td>
<td id="S4.T2.3.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.2.1" class="ltx_text" style="font-size:80%;">PER</span></td>
<td id="S4.T2.3.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.3.1" class="ltx_text" style="font-size:80%;">WER</span></td>
<td id="S4.T2.3.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.4.1" class="ltx_text" style="font-size:80%;">WDER</span></td>
<td id="S4.T2.3.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.5.1" class="ltx_text" style="font-size:80%;">PER</span></td>
<td id="S4.T2.3.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.6.1" class="ltx_text" style="font-size:80%;">WER</span></td>
<td id="S4.T2.3.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.7.1" class="ltx_text" style="font-size:80%;">WDER</span></td>
<td id="S4.T2.3.2.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.8.1" class="ltx_text" style="font-size:80%;">PER</span></td>
<td id="S4.T2.3.2.2.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.2.2.9.1" class="ltx_text" style="font-size:80%;">WER</span></td>
</tr>
<tr id="S4.T2.3.3.3" class="ltx_tr">
<td id="S4.T2.3.3.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.3.3.3.1.1" class="ltx_text" style="font-size:80%;">SRD-ASR</span></td>
<td id="S4.T2.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T2.3.3.3.2.1" class="ltx_text" style="font-size:80%;">w2v2</span></td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.3.3.1" class="ltx_text" style="font-size:80%;">38.0 (0.5)</span></td>
<td id="S4.T2.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.3.4.1" class="ltx_text" style="font-size:80%;">32.8 (4.0)</span></td>
<td id="S4.T2.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.3.5.1" class="ltx_text" style="font-size:80%;">71.7 (4.2)</span></td>
<td id="S4.T2.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.3.6.1" class="ltx_text" style="font-size:80%;">42.9 (0.1)</span></td>
<td id="S4.T2.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.3.7.1" class="ltx_text" style="font-size:80%;">37.3 (8.8)</span></td>
<td id="S4.T2.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.3.8.1" class="ltx_text" style="font-size:80%;">68.5 (2.7)</span></td>
<td id="S4.T2.3.3.3.9" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T2.3.3.3.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">32.0</span><span id="S4.T2.3.3.3.9.2" class="ltx_text" style="font-size:80%;"> (0.6)</span>
</td>
<td id="S4.T2.3.3.3.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.3.10.1" class="ltx_text" style="font-size:80%;">52.2 (4.2)</span></td>
<td id="S4.T2.3.3.3.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.3.3.11.1" class="ltx_text" style="font-size:80%;">82.1 (4.1)</span></td>
</tr>
<tr id="S4.T2.3.4.4" class="ltx_tr">
<td id="S4.T2.3.4.4.1" class="ltx_td ltx_align_left"><span id="S4.T2.3.4.4.1.1" class="ltx_text" style="font-size:80%;">ASR-SRD</span></td>
<td id="S4.T2.3.4.4.2" class="ltx_td ltx_align_center">
<span id="S4.T2.3.4.4.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">37.4</span><span id="S4.T2.3.4.4.2.2" class="ltx_text" style="font-size:80%;"> (0.4)</span>
</td>
<td id="S4.T2.3.4.4.3" class="ltx_td ltx_align_center"><span id="S4.T2.3.4.4.3.1" class="ltx_text" style="font-size:80%;">70.5 (1.0)</span></td>
<td id="S4.T2.3.4.4.4" class="ltx_td ltx_align_center">
<span id="S4.T2.3.4.4.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">69.4</span><span id="S4.T2.3.4.4.4.2" class="ltx_text" style="font-size:80%;"> (1.5)</span>
</td>
<td id="S4.T2.3.4.4.5" class="ltx_td ltx_align_center">
<span id="S4.T2.3.4.4.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">40.7</span><span id="S4.T2.3.4.4.5.2" class="ltx_text" style="font-size:80%;"> (1.0)</span>
</td>
<td id="S4.T2.3.4.4.6" class="ltx_td ltx_align_center"><span id="S4.T2.3.4.4.6.1" class="ltx_text" style="font-size:80%;">71.7 (1.7)</span></td>
<td id="S4.T2.3.4.4.7" class="ltx_td ltx_align_center">
<span id="S4.T2.3.4.4.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">58.7</span><span id="S4.T2.3.4.4.7.2" class="ltx_text" style="font-size:80%;"> (1.0)</span>
</td>
<td id="S4.T2.3.4.4.8" class="ltx_td ltx_align_center"><span id="S4.T2.3.4.4.8.1" class="ltx_text" style="font-size:80%;">39.8 (1.1)</span></td>
<td id="S4.T2.3.4.4.9" class="ltx_td ltx_align_center"><span id="S4.T2.3.4.4.9.1" class="ltx_text" style="font-size:80%;">71.4 (3.9)</span></td>
<td id="S4.T2.3.4.4.10" class="ltx_td ltx_align_center">
<span id="S4.T2.3.4.4.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">72.5</span><span id="S4.T2.3.4.4.10.2" class="ltx_text" style="font-size:80%;"> (2.2)</span>
</td>
</tr>
<tr id="S4.T2.3.5.5" class="ltx_tr">
<td id="S4.T2.3.5.5.1" class="ltx_td ltx_align_left"><span id="S4.T2.3.5.5.1.1" class="ltx_text" style="font-size:80%;">Joint</span></td>
<td id="S4.T2.3.5.5.2" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.2.1" class="ltx_text" style="font-size:80%;">39.1 (4.2)</span></td>
<td id="S4.T2.3.5.5.3" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">19.8 (2.1)</span></td>
<td id="S4.T2.3.5.5.4" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.4.1" class="ltx_text" style="font-size:80%;">70.0 (1.1)</span></td>
<td id="S4.T2.3.5.5.5" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.5.1" class="ltx_text" style="font-size:80%;">63.4 (3.8)</span></td>
<td id="S4.T2.3.5.5.6" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">13.8 (1.9)</span></td>
<td id="S4.T2.3.5.5.7" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.7.1" class="ltx_text" style="font-size:80%;">64.8 (1.0)</span></td>
<td id="S4.T2.3.5.5.8" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.8.1" class="ltx_text" style="font-size:80%;">38.5 (10.3)</span></td>
<td id="S4.T2.3.5.5.9" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">46.3 (4.0)</span></td>
<td id="S4.T2.3.5.5.10" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.5.10.1" class="ltx_text" style="font-size:80%;">76.7 (3.0)</span></td>
</tr>
<tr id="S4.T2.3.6.6" class="ltx_tr">
<td id="S4.T2.3.6.6.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T2.3.6.6.1.1" class="ltx_text" style="font-size:80%;">SRD-ASR</span></td>
<td id="S4.T2.3.6.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="3"><span id="S4.T2.3.6.6.2.1" class="ltx_text" style="font-size:80%;">xlsr</span></td>
<td id="S4.T2.3.6.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.6.6.3.1" class="ltx_text" style="font-size:80%;">38.6 (0.5)</span></td>
<td id="S4.T2.3.6.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.6.6.4.1" class="ltx_text" style="font-size:80%;">31.5 (5.1)</span></td>
<td id="S4.T2.3.6.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.6.6.5.1" class="ltx_text" style="font-size:80%;">66.9 (5.1)</span></td>
<td id="S4.T2.3.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.6.6.6.1" class="ltx_text" style="font-size:80%;">43.0 (0.3)</span></td>
<td id="S4.T2.3.6.6.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.6.6.7.1" class="ltx_text" style="font-size:80%;">35.7 (9.2)</span></td>
<td id="S4.T2.3.6.6.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.6.6.8.1" class="ltx_text" style="font-size:80%;">64.6 (9.1)</span></td>
<td id="S4.T2.3.6.6.9" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T2.3.6.6.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">31.3</span><span id="S4.T2.3.6.6.9.2" class="ltx_text" style="font-size:80%;"> (0.5)</span>
</td>
<td id="S4.T2.3.6.6.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.6.6.10.1" class="ltx_text" style="font-size:80%;">52.0 (3.9)</span></td>
<td id="S4.T2.3.6.6.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.6.6.11.1" class="ltx_text" style="font-size:80%;">76.5 (3.9)</span></td>
</tr>
<tr id="S4.T2.3.7.7" class="ltx_tr">
<td id="S4.T2.3.7.7.1" class="ltx_td ltx_align_left"><span id="S4.T2.3.7.7.1.1" class="ltx_text" style="font-size:80%;">ASR-SRD</span></td>
<td id="S4.T2.3.7.7.2" class="ltx_td ltx_align_center"><span id="S4.T2.3.7.7.2.1" class="ltx_text" style="font-size:80%;">36.7 (0.7)</span></td>
<td id="S4.T2.3.7.7.3" class="ltx_td ltx_align_center"><span id="S4.T2.3.7.7.3.1" class="ltx_text" style="font-size:80%;">68.4 (1.7)</span></td>
<td id="S4.T2.3.7.7.4" class="ltx_td ltx_align_center">
<span id="S4.T2.3.7.7.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">60.8</span><span id="S4.T2.3.7.7.4.2" class="ltx_text" style="font-size:80%;"> (0.8)</span>
</td>
<td id="S4.T2.3.7.7.5" class="ltx_td ltx_align_center">
<span id="S4.T2.3.7.7.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">39.0</span><span id="S4.T2.3.7.7.5.2" class="ltx_text" style="font-size:80%;"> (0.8)</span>
</td>
<td id="S4.T2.3.7.7.6" class="ltx_td ltx_align_center"><span id="S4.T2.3.7.7.6.1" class="ltx_text" style="font-size:80%;">70.8 (2.0)</span></td>
<td id="S4.T2.3.7.7.7" class="ltx_td ltx_align_center">
<span id="S4.T2.3.7.7.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">53.3</span><span id="S4.T2.3.7.7.7.2" class="ltx_text" style="font-size:80%;"> (1.4)</span>
</td>
<td id="S4.T2.3.7.7.8" class="ltx_td ltx_align_center"><span id="S4.T2.3.7.7.8.1" class="ltx_text" style="font-size:80%;">37.8 (2.5)</span></td>
<td id="S4.T2.3.7.7.9" class="ltx_td ltx_align_center"><span id="S4.T2.3.7.7.9.1" class="ltx_text" style="font-size:80%;">69.1 (1.8)</span></td>
<td id="S4.T2.3.7.7.10" class="ltx_td ltx_align_center">
<span id="S4.T2.3.7.7.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">65.3</span><span id="S4.T2.3.7.7.10.2" class="ltx_text" style="font-size:80%;"> (1.4)</span>
</td>
</tr>
<tr id="S4.T2.3.8.8" class="ltx_tr">
<td id="S4.T2.3.8.8.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T2.3.8.8.1.1" class="ltx_text" style="font-size:80%;">Joint</span></td>
<td id="S4.T2.3.8.8.2" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T2.3.8.8.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">36.6</span><span id="S4.T2.3.8.8.2.2" class="ltx_text" style="font-size:80%;"> (4.3)</span>
</td>
<td id="S4.T2.3.8.8.3" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T2.3.8.8.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">16.9</span><span id="S4.T2.3.8.8.3.2" class="ltx_text" style="font-size:80%;"> (1.7)</span>
</td>
<td id="S4.T2.3.8.8.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.3.8.8.4.1" class="ltx_text" style="font-size:80%;">61.3 (1.9)</span></td>
<td id="S4.T2.3.8.8.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.3.8.8.5.1" class="ltx_text" style="font-size:80%;">57.9 (3.1)</span></td>
<td id="S4.T2.3.8.8.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.3.8.8.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">10.6 (2.8)</span></td>
<td id="S4.T2.3.8.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.3.8.8.7.1" class="ltx_text" style="font-size:80%;">59.7 (1.1)</span></td>
<td id="S4.T2.3.8.8.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.3.8.8.8.1" class="ltx_text" style="font-size:80%;">33.8 (2.3)</span></td>
<td id="S4.T2.3.8.8.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.3.8.8.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">41.3 (1.3)</span></td>
<td id="S4.T2.3.8.8.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.3.8.8.10.1" class="ltx_text" style="font-size:80%;">71.0 (2.2)</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Intra-dataset scores: WDER,PER and WER in case the models are finetuned and tested on the same dataset. Mean values over three runs are given with the standard deviation in brackets</figcaption>
<table id="S4.T3.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.3.1.1" class="ltx_tr">
<td id="S4.T3.3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S4.T3.3.1.1.1.1" class="ltx_text" style="font-size:80%;">Architecture</span></td>
<td id="S4.T3.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T3.3.1.1.2.1" class="ltx_text" style="font-size:80%;">ASR</span></td>
<td id="S4.T3.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T3.3.1.1.3.1" class="ltx_text" style="font-size:80%;">ATCO2</span></td>
<td id="S4.T3.3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T3.3.1.1.4.1" class="ltx_text" style="font-size:80%;">LDC-ATCC</span></td>
<td id="S4.T3.3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T3.3.1.1.5.1" class="ltx_text" style="font-size:80%;">LiveATC</span></td>
</tr>
<tr id="S4.T3.3.2.2" class="ltx_tr">
<td id="S4.T3.3.2.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.1.1" class="ltx_text" style="font-size:80%;">WDER</span></td>
<td id="S4.T3.3.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.2.1" class="ltx_text" style="font-size:80%;">PER</span></td>
<td id="S4.T3.3.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.3.1" class="ltx_text" style="font-size:80%;">WER</span></td>
<td id="S4.T3.3.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.4.1" class="ltx_text" style="font-size:80%;">WDER</span></td>
<td id="S4.T3.3.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.5.1" class="ltx_text" style="font-size:80%;">PER</span></td>
<td id="S4.T3.3.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.6.1" class="ltx_text" style="font-size:80%;">WER</span></td>
<td id="S4.T3.3.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.7.1" class="ltx_text" style="font-size:80%;">WDER</span></td>
<td id="S4.T3.3.2.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.8.1" class="ltx_text" style="font-size:80%;">PER</span></td>
<td id="S4.T3.3.2.2.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.2.2.9.1" class="ltx_text" style="font-size:80%;">WER</span></td>
</tr>
<tr id="S4.T3.3.3.3" class="ltx_tr">
<td id="S4.T3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.3.3.3.1.1" class="ltx_text" style="font-size:80%;">SRD-ASR</span></td>
<td id="S4.T3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T3.3.3.3.2.1" class="ltx_text" style="font-size:80%;">w2v2</span></td>
<td id="S4.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.3.1" class="ltx_text" style="font-size:80%;">27.4 (0.4)</span></td>
<td id="S4.T3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.4.1" class="ltx_text" style="font-size:80%;">25.5 (7.9)</span></td>
<td id="S4.T3.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.5.1" class="ltx_text" style="font-size:80%;">34.8 (3.1)</span></td>
<td id="S4.T3.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.6.1" class="ltx_text" style="font-size:80%;">27.4 (0.1)</span></td>
<td id="S4.T3.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.7.1" class="ltx_text" style="font-size:80%;">27.2 (5.0)</span></td>
<td id="S4.T3.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.8.1" class="ltx_text" style="font-size:80%;">36.2 (3.1)</span></td>
<td id="S4.T3.3.3.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.9.1" class="ltx_text" style="font-size:80%;">23.7 (0.4)</span></td>
<td id="S4.T3.3.3.3.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.10.1" class="ltx_text" style="font-size:80%;">51.0 (3.6)</span></td>
<td id="S4.T3.3.3.3.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.3.3.11.1" class="ltx_text" style="font-size:80%;">55.8 (4.3)</span></td>
</tr>
<tr id="S4.T3.3.4.4" class="ltx_tr">
<td id="S4.T3.3.4.4.1" class="ltx_td ltx_align_left"><span id="S4.T3.3.4.4.1.1" class="ltx_text" style="font-size:80%;">ASR-SRD</span></td>
<td id="S4.T3.3.4.4.2" class="ltx_td ltx_align_center"><span id="S4.T3.3.4.4.2.1" class="ltx_text" style="font-size:80%;">11.4 (0.8)</span></td>
<td id="S4.T3.3.4.4.3" class="ltx_td ltx_align_center"><span id="S4.T3.3.4.4.3.1" class="ltx_text" style="font-size:80%;">33.5 (3.3)</span></td>
<td id="S4.T3.3.4.4.4" class="ltx_td ltx_align_center"><span id="S4.T3.3.4.4.4.1" class="ltx_text" style="font-size:80%;">25.9 (0.4)</span></td>
<td id="S4.T3.3.4.4.5" class="ltx_td ltx_align_center"><span id="S4.T3.3.4.4.5.1" class="ltx_text" style="font-size:80%;">12.6 (0.2)</span></td>
<td id="S4.T3.3.4.4.6" class="ltx_td ltx_align_center"><span id="S4.T3.3.4.4.6.1" class="ltx_text" style="font-size:80%;">42.1 (1.0)</span></td>
<td id="S4.T3.3.4.4.7" class="ltx_td ltx_align_center">
<span id="S4.T3.3.4.4.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">20.2</span><span id="S4.T3.3.4.4.7.2" class="ltx_text" style="font-size:80%;"> (0.1)</span>
</td>
<td id="S4.T3.3.4.4.8" class="ltx_td ltx_align_center"><span id="S4.T3.3.4.4.8.1" class="ltx_text" style="font-size:80%;">30.7 (0.5)</span></td>
<td id="S4.T3.3.4.4.9" class="ltx_td ltx_align_center"><span id="S4.T3.3.4.4.9.1" class="ltx_text" style="font-size:80%;">80.8 (1.6)</span></td>
<td id="S4.T3.3.4.4.10" class="ltx_td ltx_align_center">
<span id="S4.T3.3.4.4.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">43.3</span><span id="S4.T3.3.4.4.10.2" class="ltx_text" style="font-size:80%;"> (0.4)</span>
</td>
</tr>
<tr id="S4.T3.3.5.5" class="ltx_tr">
<td id="S4.T3.3.5.5.1" class="ltx_td ltx_align_left"><span id="S4.T3.3.5.5.1.1" class="ltx_text" style="font-size:80%;">Joint</span></td>
<td id="S4.T3.3.5.5.2" class="ltx_td ltx_align_center">
<span id="S4.T3.3.5.5.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">6.5</span><span id="S4.T3.3.5.5.2.2" class="ltx_text" style="font-size:80%;"> (0.4)</span>
</td>
<td id="S4.T3.3.5.5.3" class="ltx_td ltx_align_center">
<span id="S4.T3.3.5.5.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">4.8</span><span id="S4.T3.3.5.5.3.2" class="ltx_text" style="font-size:80%;"> (0.8)</span>
</td>
<td id="S4.T3.3.5.5.4" class="ltx_td ltx_align_center">
<span id="S4.T3.3.5.5.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">24.1</span><span id="S4.T3.3.5.5.4.2" class="ltx_text" style="font-size:80%;"> (0.3)</span>
</td>
<td id="S4.T3.3.5.5.5" class="ltx_td ltx_align_center">
<span id="S4.T3.3.5.5.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">8.0</span><span id="S4.T3.3.5.5.5.2" class="ltx_text" style="font-size:80%;"> (1.1)</span>
</td>
<td id="S4.T3.3.5.5.6" class="ltx_td ltx_align_center">
<span id="S4.T3.3.5.5.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">9.3</span><span id="S4.T3.3.5.5.6.2" class="ltx_text" style="font-size:80%;"> (0.5)</span>
</td>
<td id="S4.T3.3.5.5.7" class="ltx_td ltx_align_center"><span id="S4.T3.3.5.5.7.1" class="ltx_text" style="font-size:80%;">27.5 (1.1)</span></td>
<td id="S4.T3.3.5.5.8" class="ltx_td ltx_align_center">
<span id="S4.T3.3.5.5.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">19.2</span><span id="S4.T3.3.5.5.8.2" class="ltx_text" style="font-size:80%;"> (7.3)</span>
</td>
<td id="S4.T3.3.5.5.9" class="ltx_td ltx_align_center">
<span id="S4.T3.3.5.5.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">9.3</span><span id="S4.T3.3.5.5.9.2" class="ltx_text" style="font-size:80%;"> (0.5)</span>
</td>
<td id="S4.T3.3.5.5.10" class="ltx_td ltx_align_center"><span id="S4.T3.3.5.5.10.1" class="ltx_text" style="font-size:80%;">45.5 (1.8)</span></td>
</tr>
<tr id="S4.T3.3.6.6" class="ltx_tr">
<td id="S4.T3.3.6.6.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.3.6.6.1.1" class="ltx_text" style="font-size:80%;">SRD-ASR</span></td>
<td id="S4.T3.3.6.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="3"><span id="S4.T3.3.6.6.2.1" class="ltx_text" style="font-size:80%;">xlsr</span></td>
<td id="S4.T3.3.6.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.3.1" class="ltx_text" style="font-size:80%;">27.4 (0.5)</span></td>
<td id="S4.T3.3.6.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.4.1" class="ltx_text" style="font-size:80%;">26.6 (9.0)</span></td>
<td id="S4.T3.3.6.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.5.1" class="ltx_text" style="font-size:80%;">32.0 (3.3)</span></td>
<td id="S4.T3.3.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.6.1" class="ltx_text" style="font-size:80%;">27.5 (0.3)</span></td>
<td id="S4.T3.3.6.6.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.7.1" class="ltx_text" style="font-size:80%;">25.9 (4.7)</span></td>
<td id="S4.T3.3.6.6.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.8.1" class="ltx_text" style="font-size:80%;">34.4 (1.6)</span></td>
<td id="S4.T3.3.6.6.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.9.1" class="ltx_text" style="font-size:80%;">24.7 (0.4)</span></td>
<td id="S4.T3.3.6.6.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.10.1" class="ltx_text" style="font-size:80%;">50.7 (2.1)</span></td>
<td id="S4.T3.3.6.6.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.6.6.11.1" class="ltx_text" style="font-size:80%;">53.1 (0.8)</span></td>
</tr>
<tr id="S4.T3.3.7.7" class="ltx_tr">
<td id="S4.T3.3.7.7.1" class="ltx_td ltx_align_left"><span id="S4.T3.3.7.7.1.1" class="ltx_text" style="font-size:80%;">ASR-SRD</span></td>
<td id="S4.T3.3.7.7.2" class="ltx_td ltx_align_center"><span id="S4.T3.3.7.7.2.1" class="ltx_text" style="font-size:80%;">10.4 (0.2)</span></td>
<td id="S4.T3.3.7.7.3" class="ltx_td ltx_align_center"><span id="S4.T3.3.7.7.3.1" class="ltx_text" style="font-size:80%;">28.6 (3.4)</span></td>
<td id="S4.T3.3.7.7.4" class="ltx_td ltx_align_center">
<span id="S4.T3.3.7.7.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">22.1</span><span id="S4.T3.3.7.7.4.2" class="ltx_text" style="font-size:80%;"> (0.6)</span>
</td>
<td id="S4.T3.3.7.7.5" class="ltx_td ltx_align_center"><span id="S4.T3.3.7.7.5.1" class="ltx_text" style="font-size:80%;">12.3 (0.3)</span></td>
<td id="S4.T3.3.7.7.6" class="ltx_td ltx_align_center"><span id="S4.T3.3.7.7.6.1" class="ltx_text" style="font-size:80%;">41.0 (0.1)</span></td>
<td id="S4.T3.3.7.7.7" class="ltx_td ltx_align_center">
<span id="S4.T3.3.7.7.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">17.6</span><span id="S4.T3.3.7.7.7.2" class="ltx_text" style="font-size:80%;"> (0.4)</span>
</td>
<td id="S4.T3.3.7.7.8" class="ltx_td ltx_align_center"><span id="S4.T3.3.7.7.8.1" class="ltx_text" style="font-size:80%;">30.2 (0.2)</span></td>
<td id="S4.T3.3.7.7.9" class="ltx_td ltx_align_center"><span id="S4.T3.3.7.7.9.1" class="ltx_text" style="font-size:80%;">81.8 (0.6)</span></td>
<td id="S4.T3.3.7.7.10" class="ltx_td ltx_align_center">
<span id="S4.T3.3.7.7.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">41.0</span><span id="S4.T3.3.7.7.10.2" class="ltx_text" style="font-size:80%;"> (0.2)</span>
</td>
</tr>
<tr id="S4.T3.3.8.8" class="ltx_tr">
<td id="S4.T3.3.8.8.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.3.8.8.1.1" class="ltx_text" style="font-size:80%;">Joint</span></td>
<td id="S4.T3.3.8.8.2" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T3.3.8.8.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">9.9</span><span id="S4.T3.3.8.8.2.2" class="ltx_text" style="font-size:80%;"> (3.0)</span>
</td>
<td id="S4.T3.3.8.8.3" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T3.3.8.8.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">4.0</span><span id="S4.T3.3.8.8.3.2" class="ltx_text" style="font-size:80%;"> (1.0)</span>
</td>
<td id="S4.T3.3.8.8.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.3.8.8.4.1" class="ltx_text" style="font-size:80%;">23.1 (1.5)</span></td>
<td id="S4.T3.3.8.8.5" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T3.3.8.8.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">6.2</span><span id="S4.T3.3.8.8.5.2" class="ltx_text" style="font-size:80%;"> (0.3)</span>
</td>
<td id="S4.T3.3.8.8.6" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T3.3.8.8.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">2.6</span><span id="S4.T3.3.8.8.6.2" class="ltx_text" style="font-size:80%;"> (0.3)</span>
</td>
<td id="S4.T3.3.8.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.3.8.8.7.1" class="ltx_text" style="font-size:80%;">23.9 (1.1)</span></td>
<td id="S4.T3.3.8.8.8" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T3.3.8.8.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">19.1</span><span id="S4.T3.3.8.8.8.2" class="ltx_text" style="font-size:80%;"> (0.5)</span>
</td>
<td id="S4.T3.3.8.8.9" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T3.3.8.8.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">12.7</span><span id="S4.T3.3.8.8.9.2" class="ltx_text" style="font-size:80%;"> (2.9)</span>
</td>
<td id="S4.T3.3.8.8.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.3.8.8.10.1" class="ltx_text" style="font-size:80%;">43.5 (0.9)</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental setup</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.3" class="ltx_p">All experiments are performed on a NVIDIA V100 GPU. The ASR and the <span id="S5.p1.3.1" class="ltx_text ltx_font_typewriter">Joint</span> model are trained for 2000 steps, 1000 warm-up steps, a learning rate of 4e-4 and a batch size of 4 with 8 gradient accumulation steps. We choose steps instead of epochs to ensure the same number of training steps despite different sized training sets. ASR fine-tuning takes roughly 4-5 hours with these parameters. The text-based diarizer is a BERT<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>HF model: https://huggingface.co/google-bert/bert-base-uncased</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> model with a binary classification head on top. It is trained with a learning rate of 2e-5, 25 warmup steps and a batch size of 16. Training is terminated by an early stopping mechanism, with a patience of 5. The models with the lowest WER (for ASR), respectively word diarization error rate (WDER) (for SRD) on the validation data are used for testing. The WDER is implemented based on Shafey at al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. We additionally measure the position error rate (PER) of the speaker role tokens. This PER allows to measure if a speaker role token is placed in the correct position in the sentence independently of the speaker role. We define the PER as follows:</p>
<table id="S5.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E1.m1.1" class="ltx_Math" alttext="\text{PER}=1-\frac{t_{c}}{t_{p}}" display="block"><semantics id="S5.E1.m1.1a"><mrow id="S5.E1.m1.1.1" xref="S5.E1.m1.1.1.cmml"><mtext id="S5.E1.m1.1.1.2" xref="S5.E1.m1.1.1.2a.cmml">PER</mtext><mo id="S5.E1.m1.1.1.1" xref="S5.E1.m1.1.1.1.cmml">=</mo><mrow id="S5.E1.m1.1.1.3" xref="S5.E1.m1.1.1.3.cmml"><mn id="S5.E1.m1.1.1.3.2" xref="S5.E1.m1.1.1.3.2.cmml">1</mn><mo id="S5.E1.m1.1.1.3.1" xref="S5.E1.m1.1.1.3.1.cmml">−</mo><mfrac id="S5.E1.m1.1.1.3.3" xref="S5.E1.m1.1.1.3.3.cmml"><msub id="S5.E1.m1.1.1.3.3.2" xref="S5.E1.m1.1.1.3.3.2.cmml"><mi id="S5.E1.m1.1.1.3.3.2.2" xref="S5.E1.m1.1.1.3.3.2.2.cmml">t</mi><mi id="S5.E1.m1.1.1.3.3.2.3" xref="S5.E1.m1.1.1.3.3.2.3.cmml">c</mi></msub><msub id="S5.E1.m1.1.1.3.3.3" xref="S5.E1.m1.1.1.3.3.3.cmml"><mi id="S5.E1.m1.1.1.3.3.3.2" xref="S5.E1.m1.1.1.3.3.3.2.cmml">t</mi><mi id="S5.E1.m1.1.1.3.3.3.3" xref="S5.E1.m1.1.1.3.3.3.3.cmml">p</mi></msub></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.1b"><apply id="S5.E1.m1.1.1.cmml" xref="S5.E1.m1.1.1"><eq id="S5.E1.m1.1.1.1.cmml" xref="S5.E1.m1.1.1.1"></eq><ci id="S5.E1.m1.1.1.2a.cmml" xref="S5.E1.m1.1.1.2"><mtext id="S5.E1.m1.1.1.2.cmml" xref="S5.E1.m1.1.1.2">PER</mtext></ci><apply id="S5.E1.m1.1.1.3.cmml" xref="S5.E1.m1.1.1.3"><minus id="S5.E1.m1.1.1.3.1.cmml" xref="S5.E1.m1.1.1.3.1"></minus><cn type="integer" id="S5.E1.m1.1.1.3.2.cmml" xref="S5.E1.m1.1.1.3.2">1</cn><apply id="S5.E1.m1.1.1.3.3.cmml" xref="S5.E1.m1.1.1.3.3"><divide id="S5.E1.m1.1.1.3.3.1.cmml" xref="S5.E1.m1.1.1.3.3"></divide><apply id="S5.E1.m1.1.1.3.3.2.cmml" xref="S5.E1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.3.3.2.1.cmml" xref="S5.E1.m1.1.1.3.3.2">subscript</csymbol><ci id="S5.E1.m1.1.1.3.3.2.2.cmml" xref="S5.E1.m1.1.1.3.3.2.2">𝑡</ci><ci id="S5.E1.m1.1.1.3.3.2.3.cmml" xref="S5.E1.m1.1.1.3.3.2.3">𝑐</ci></apply><apply id="S5.E1.m1.1.1.3.3.3.cmml" xref="S5.E1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S5.E1.m1.1.1.3.3.3.1.cmml" xref="S5.E1.m1.1.1.3.3.3">subscript</csymbol><ci id="S5.E1.m1.1.1.3.3.3.2.cmml" xref="S5.E1.m1.1.1.3.3.3.2">𝑡</ci><ci id="S5.E1.m1.1.1.3.3.3.3.cmml" xref="S5.E1.m1.1.1.3.3.3.3">𝑝</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.1c">\text{PER}=1-\frac{t_{c}}{t_{p}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S5.p1.2" class="ltx_p">where <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="t_{p}" display="inline"><semantics id="S5.p1.1.m1.1a"><msub id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">t</mi><mi id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1">subscript</csymbol><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">𝑡</ci><ci id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">t_{p}</annotation></semantics></math> is the number of ground truth speaker role tag positions and <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="t_{c}" display="inline"><semantics id="S5.p1.2.m2.1a"><msub id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml"><mi id="S5.p1.2.m2.1.1.2" xref="S5.p1.2.m2.1.1.2.cmml">t</mi><mi id="S5.p1.2.m2.1.1.3" xref="S5.p1.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><apply id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p1.2.m2.1.1.1.cmml" xref="S5.p1.2.m2.1.1">subscript</csymbol><ci id="S5.p1.2.m2.1.1.2.cmml" xref="S5.p1.2.m2.1.1.2">𝑡</ci><ci id="S5.p1.2.m2.1.1.3.cmml" xref="S5.p1.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">t_{c}</annotation></semantics></math> is the number of correctly placed tokens at all ground truth speaker role tag positions (class independent).</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">High WERs can result in missing parts of the transcripts, which not only influences the WER but also the WDER and PER. To uncouple these, we align the target and predicted transcript with the Needleman-Wunsch algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and add placeholder tokens for non-transcribed words before calculating the WDER and PER. All experiments given in the following section are repeated thrice with different seeds and the mean and standard deviation are given over those three runs if not mentioned otherwise.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Inter-and intra-dataset evaluation</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">The ASR&amp;SRD models are tested in an inter-dataset scenario, where the train and test splits come from different datasets and an intra-dataset scenario, with the train and test splits from the same dataset. The fact that pretrained transformer-based ASR models are susceptible to inter-dataset acoustic and linguistic variabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> allows to investigate the WDER and PER scores over a wide range of WERs.
The inter-dataset scores in <a href="#S4.T2" title="Table 2 ‣ 4.3 Joint ‣ 4 ASR&amp;SRD architectures ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a> show that the <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">ASR-SRD</span> architecture outperforms the other architectures on the ATCO2 and LDC-ATCC dataset in terms of WDER when the wave2vec 2.0 model is used. On the LiveATC dataset, the <span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_typewriter">SRD-ASR</span> model reaches the lowest WDER despite having the highest WER. Switching from wave2vec 2.0 to xlsr results in the lowest WDER for the <span id="S6.SS1.p1.1.3" class="ltx_text ltx_font_typewriter">Joint</span> model on ATCO2. The <span id="S6.SS1.p1.1.4" class="ltx_text ltx_font_typewriter">Joint</span> model also benefits the most from the model change in the other metrics. Regarding the WER, the <span id="S6.SS1.p1.1.5" class="ltx_text ltx_font_typewriter">ASR-SRD</span> model outperforms the others on all datasets, while the <span id="S6.SS1.p1.1.6" class="ltx_text ltx_font_typewriter">Joint</span> model has the lowest PER score on all datasets by a margin.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">This holds also true for the intra-dataset scores as shown in <a href="#S4.T2" title="Table 2 ‣ 4.3 Joint ‣ 4 ASR&amp;SRD architectures ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>. The <span id="S6.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">Joint</span> model additionally has the lowest WDER on all datasets, for both, the xlsr and the wave2vec 2.0 model. Although WER scores of the <span id="S6.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">Joint</span> and <span id="S6.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">ASR-SRD</span> architecture are close in all datasets, the <span id="S6.SS1.p2.1.4" class="ltx_text ltx_font_typewriter">ASR-SRD</span> model still reaches the lowest WERs in all scenarios tested. In contrast to the <span id="S6.SS1.p2.1.5" class="ltx_text ltx_font_typewriter">SRD-ASR</span> architecture, the other two ASR&amp;SRD models can more then half their WDER scores on the ATCO2 and LDC-ATCC dataset compared to the inter-dataset scenario. This indicates that they can utilize the fact that the lexical features don't change significantly between the training and testing scenario. This is further analyzed in the next chapter.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Relation and causation analysis for ASR&amp;SRD</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">To decouple/correlate the ASR and SRD performance, we analyze the confusion matrices for WDER, PER and WER in <a href="#S6.F3" title="Figure 3 ‣ 6.2 Relation and causation analysis for ASR&amp;SRD ‣ 6 Results ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>. Additional matrices for the out-of-vocabulary (OOV) rates and the perplexities allow to draw a connection to linguistic differences between the datasets. The perplexities are calculated by building a 4-gram language model (LM) on the training data and calculating the perplexity with this LM on the test data. The acoustic influences can be investigated by analyzing the SNR train/test ratio confusion matrix. The SNR values are estimated with the WADA-SNR algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">All three architectures have similar WER confusions matrices, the fact that the <span id="S6.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">SRD-ASR</span> transcribes already speaker role chunked audio files just shows in the absolute values. The PER matrices differ however significantly. The <span id="S6.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">SRD-ASR</span> model seems to mostly under-perform when tested on the LiveATC dataset while the <span id="S6.SS2.p2.1.3" class="ltx_text ltx_font_typewriter">ASR-SRD</span> model produces high PERs when trained on the LiveATC dataset.</p>
</div>
<figure id="S6.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.1" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.1.1" class="ltx_p ltx_align_center"><span id="S6.F3.1.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hPerplexity.png" id="S6.F3.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="439" alt="Refer to caption"></span></p>
<p id="S6.F3.1.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.1.2.1" class="ltx_text">(a) Perplexity</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.2.1" class="ltx_p ltx_align_center"><span id="S6.F3.2.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hOOVs.png" id="S6.F3.2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="433" alt="Refer to caption"></span></p>
<p id="S6.F3.2.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.2.2.1" class="ltx_text">(b) OOV rate</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.3" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.3.1" class="ltx_p ltx_align_center"><span id="S6.F3.3.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hSNR.png" id="S6.F3.3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="446" alt="Refer to caption"></span></p>
<p id="S6.F3.3.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.3.2.1" class="ltx_text">(c) SNR ratio</span></p>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.4" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.4.1" class="ltx_p ltx_align_center"><span id="S6.F3.4.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hSRD-ASRWDER2.png" id="S6.F3.4.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="453" alt="Refer to caption"></span></p>
<p id="S6.F3.4.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.4.2.1" class="ltx_text">(d) WDER SRD-ASR</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.5" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.5.1" class="ltx_p ltx_align_center"><span id="S6.F3.5.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hJoinedWDER2.png" id="S6.F3.5.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="453" alt="Refer to caption"></span></p>
<p id="S6.F3.5.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.5.2.1" class="ltx_text">(e) WDER Joint</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.6" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.6.1" class="ltx_p ltx_align_center"><span id="S6.F3.6.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hASR-SRDWDER2.png" id="S6.F3.6.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="453" alt="Refer to caption"></span></p>
<p id="S6.F3.6.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.6.2.1" class="ltx_text">(f) WDER ASR-SRD</span></p>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.7" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.7.1" class="ltx_p ltx_align_center"><span id="S6.F3.7.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hSRD-ASRPER2.png" id="S6.F3.7.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="468" alt="Refer to caption"></span></p>
<p id="S6.F3.7.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.7.2.1" class="ltx_text">(g) PER SRD-ASR</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.8" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.8.1" class="ltx_p ltx_align_center"><span id="S6.F3.8.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hJoinedPER2.png" id="S6.F3.8.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="468" alt="Refer to caption"></span></p>
<p id="S6.F3.8.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.8.2.1" class="ltx_text">(h) PER Joint</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.9" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.9.1" class="ltx_p ltx_align_center"><span id="S6.F3.9.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hASR-SRDPER2.png" id="S6.F3.9.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="468" alt="Refer to caption"></span></p>
<p id="S6.F3.9.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.9.2.1" class="ltx_text">(i) PER ASR-SRD</span></p>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.10" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.10.1" class="ltx_p ltx_align_center"><span id="S6.F3.10.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hSRD-ASRWER2.png" id="S6.F3.10.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="453" alt="Refer to caption"></span></p>
<p id="S6.F3.10.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.10.2.1" class="ltx_text">(j) WER SRD-ASR</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.11" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.11.1" class="ltx_p ltx_align_center"><span id="S6.F3.11.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hJoinedWER2.png" id="S6.F3.11.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="453" alt="Refer to caption"></span></p>
<p id="S6.F3.11.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.11.2.1" class="ltx_text">(k) WER Joint</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div id="S6.F3.12" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:138.8pt;">
<p id="S6.F3.12.1" class="ltx_p ltx_align_center"><span id="S6.F3.12.1.1" class="ltx_text"><img src="/html/2406.13842/assets/figs/hASR-SRDWER2.png" id="S6.F3.12.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="453" alt="Refer to caption"></span></p>
<p id="S6.F3.12.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.12.2.1" class="ltx_text">(l) WER ASR-SRD</span></p>
</div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Confusion matrices for different metrics (a)-(l) and different ASR&amp;SRD methods (d)-(l) run with the xlsr model. The columns correspond to the test datasets and the rows to the training dataset. The SNR train/test ratio is calculated based on the values of <a href="#S3.T1" title="Table 1 ‣ 3 Datasets ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>. The datasets are abbreviated as follows: AT: ATCO2, LD: LDC-ATCC, Li: LiveATC.</figcaption>
</figure>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">The <span id="S6.SS2.p3.1.1" class="ltx_text ltx_font_typewriter">Joint</span> model shows a balanced performance except for the case when trained on LDC-ATCC and tested on LiveATC. This corresponds with the perplexity and OOV rate matrices, which also show a high value for this pairing.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">The WDER matrices show that the <span id="S6.SS2.p4.1.1" class="ltx_text ltx_font_typewriter">SRD-ASR</span> architecture has the most balanced performance while only producing high WDERs on the liveATC - LDC-ATCC pairing, which is also the case for the other architectures. This could be due to the fact that this pairing shows also a high perplexity, OOV rate and SNR ratio. The confusion matrix on the <span id="S6.SS2.p4.1.2" class="ltx_text ltx_font_typewriter">Joint</span> model highlights the performance gap between the inter and intra-dataset scenario. The WDER, WER and PER matrices of the <span id="S6.SS2.p4.1.3" class="ltx_text ltx_font_typewriter">ASR-SRD</span> value show a high similarity, indicating a correlation between the three measures. Overall, the perplexity and OOV rates seem to have a higher influence on the ASR&amp;SRD metrics than the SNR ratio. But it should be noted, that the WADA-SNR values of the datasets are quite similar as <a href="#S3.T1" title="Table 1 ‣ 3 Datasets ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a> shows. However, the distribution of the SNR values are quite different as <a href="#S3.F1" title="Figure 1 ‣ 3 Datasets ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a> (a) indicates. An additional noise analysis is therefore necessary to draw noise-related conclusions.</p>
</div>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2406.13842/assets/figs/fewShot2.png" id="S6.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="353" height="268" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Few-shot learning on LDC-ATCC of a <span id="S6.F4.2.1" class="ltx_text ltx_font_typewriter">Joint</span>-xlsr model finetuned previously on Live ATC data. All experiments are just conducted once.</figcaption>
</figure>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Few-shot learning</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">The difference between the inter- vs intra-dataset WDER scores for the <span id="S6.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">Joint</span> architecture is quite large as shown above. To ameliorate this with domain familiarization, we resort to few-shot training. As an example case, we use the LDC-ATCC data to further train a <span id="S6.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">Joint</span>-xlsr model finetuned on Live ATC data. <a href="#S6.F4" title="Figure 4 ‣ 6.2 Relation and causation analysis for ASR&amp;SRD ‣ 6 Results ‣ Joint vs Sequential Speaker-Role Detection and Automatic Speech Recognition for Air-traffic Control" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 4</span></a> shows that the WDER on LDC-ATCC drops to 42% by just using 10 samples from the LDC-ATCC data for fine-tuning. This is already the level that the other architecture reach on this dataset. By using 50 samples, the WDER is already under 20%. There is however a noticeable increase in the WDER/WER on the Live ATC dataset. At 25 samples, the model shows a balanced inter-and intra-dataset performance. This shows that adaptation to the cross-dataset scenario is possible by using few-shot training.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Recently proposed joint diarization and ASR models outperform the traditional sequential approaches. The air-traffic control (ATC) domain differs however acoustically and linguistically from standard diarization and ASR datasets. In ATC, identifying the speaker role, pilot or air-traffic controller, is often more important than identifying the speaker. We have therefore proposed a joint speaker-role detection (SRD) and ASR system for ATC (<span id="S7.p1.1.1" class="ltx_text ltx_font_typewriter">Joint</span>). This system purely relies on a transformer based ASR models. We have compared this architecture against two traditional cascaded approaches, that either first perform ASR, then text based SRD (<span id="S7.p1.1.2" class="ltx_text ltx_font_typewriter">ASR-SRD</span>), or first acoustic based SRD and then ASR (<span id="S7.p1.1.3" class="ltx_text ltx_font_typewriter">SRD-ASR</span>). Our system clearly outperforms the other systems in the intra-dataset scenario in terms of the word diarization error rate
(WDER). The position error rate (PER) scores are lower in all scenarios. We can show that the WDER scores of the (<span id="S7.p1.1.4" class="ltx_text ltx_font_typewriter">Joint</span>) and (<span id="S7.p1.1.5" class="ltx_text ltx_font_typewriter">ASR-SRD</span>) systems scale with a better ASR performance, while the (<span id="S7.p1.1.6" class="ltx_text ltx_font_typewriter">Joint</span>) models seems to benefit more from a potent ASR model. Few-shot training results indicate that the inter-dataset scores of the <span id="S7.p1.1.7" class="ltx_text ltx_font_typewriter">Joint</span> model can be significantly improved with just 25 samples. The <span id="S7.p1.1.8" class="ltx_text ltx_font_typewriter">ASR-SRD</span> architecture shows a more balanced performance between the intra- and inter-dataset scenario, while the <span id="S7.p1.1.9" class="ltx_text ltx_font_typewriter">SRD-ASR</span> approach only seems to be superior if there is a high WER scenario. These insights allow to pick the correct architecture for an individual ASR&amp;SRD task.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Sarkar, S. Dasgupta, S. K. Naskar, and S. Bandyopadhyay, ``Says who? Deep learning models for joint speech recognition, segmentation and diarization,'' in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings</em>, vol. 2018-April.   IEEE, 2018, pp. 5229–5233.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
L. E. Shafey, H. Soltau, and I. Shafran, ``Joint speech recognition and speaker diarization via sequence transduction,'' <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</em>, vol. 2019-Septe, pp. 396–400, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
W. Xia, H. Lu, Q. Wang, A. Tripathi, Y. Huang, I. L. Moreno, and H. Sak, ``Turn-To-Diarize: Online Speaker Diarization Constrained By Transformer Transducer Speaker Turn Detection,'' <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings</em>, vol. 2022-May, no. 2, pp. 8077–8081, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Z. Huang, M. Delcroix, L. P. Garcia, S. Watanabe, D. Raj, and S. Khudanpur, ``Computer Speech &amp; Language Joint speaker diarization and speech recognition based on region,'' <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, vol. 72, no. September 2021, p. 101316, 2022. [Online]. Available: <a target="_blank" href="https://doi.org/10.1016/j.csl.2021.101316" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.csl.2021.101316</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S. Cornell, J.-w. Jung, S. Watanabe, and S. Squartini, ``One model to rule them all ? Towards End-to-End Joint Speaker Diarization and Speech Recognition,'' pp. 2–6, 2023. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/2310.01688" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2310.01688</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A. Blatt, B. M. Abdullah, and D. Klakow, ``Ending the blind flight: Analyzing the impact of acoustic and lexical factors on wav2vec 2.0 in air-traffic control,'' in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>, 2023, pp. 1–8.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T. J. Park, N. Kanda, D. Dimitriadis, K. J. Han, S. Watanabe, and S. Narayanan, ``A review of speaker diarization: Recent advances with deep learning,'' <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Computer Speech and Language</em>, vol. 72, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A. Baevski, H. Zhou, A. Mohamed, and M. Auli, ``wav2vec 2.0: A framework for self-supervised learning of speech representations,'' <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 2020-Decem, no. Figure 1, pp. 1–19, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
A. Babu, C. Wang, A. Tjandra, K. Lakhotia, Q. Xu, N. Goyal, K. Singh, P. von Platen, Y. Saraf, J. Pino, A. Baevski, A. Conneau, and M. Auli, ``XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale,'' <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</em>, vol. 2022-September, pp. 2278–2282, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Graves, S. Fernández, F. Gomez, and J. Schmidhuber, ``Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,'' in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd international conference on Machine learning</em>, 2006, pp. 369–376.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
N. Kanda, S. Horiguchi, Y. Fujita, Y. Xue, K. Nagamatsu, and S. Watanabe, ``Simultaneous Speech Recognition and Speaker Diarization for Monaural Dialogue Recordings with Target-Speaker Acoustic Models,'' <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Automatic Speech Recognition and Understanding Workshop, ASRU 2019 - Proceedings</em>, pp. 31–38, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. Zuluaga-Gomez, S. S. Sarfjoo, A. Prasad, I. Nigmatulina, P. Motlicek, K. Ondrej, O. Ohneiser, and H. Helmke, ``Bertraffic: Bert-based joint speaker role and speaker change detection for air traffic control communications,'' in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">2022 IEEE Spoken Language Technology Workshop (SLT)</em>, 2023, pp. 633–640.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
F. Landini, J. Profant, M. Diez, and L. Burget, ``Bayesian hmm clustering of x-vector sequences (vbx) in speaker diarization: Theory, implementation and analysis on standard tasks,'' <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, vol. 71, p. 101254, 2022. [Online]. Available: <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0885230821000619" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S0885230821000619</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
J. Zuluaga-Gomez, K. Veselý, I. Szöke, P. Motlicek, M. Kocour, M. Rigault, K. Choukri, A. Prasad, S. S. Sarfjoo, I. Nigmatulina, C. Cevenini, P. Kolčárek, A. Tart, and J. Černocký, ``ATCO2 corpus: A Large-Scale Dataset for Research on Automatic Speech Recognition and Natural Language Understanding of Air Traffic Control Communications,'' pp. 1–29, 2022. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/2211.04054" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2211.04054</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Zuluaga-Gomez, K. Veselý, A. Blatt, P. Motlicek, D. Klakow, A. Tart, I. Szöke, A. Prasad, S. Sarfjoo, P. Kolčárek, M. Kocour, H. Černocký, C. Cevenini, K. Choukri, M. Rigault, and F. Landis, ``Automatic Call Sign Detection: Matching Air Surveillance Data with Air Traffic Spoken Communications,'' <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings</em>, vol. 59, no. 1, p. 14, dec 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
J. J. Godfrey, ``Air traffic control complete ldc94s14a,'' 1994. [Online]. Available: <a target="_blank" href="https://catalog.ldc.upenn.edu/LDC94S14A" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://catalog.ldc.upenn.edu/LDC94S14A</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
C. Kim and R. M. Stern, ``Robust signal-to-noise ratio estimation based on waveform amplitude distribution analysis,'' <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</em>, pp. 2598–2601, 2008.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
H. Bredin, ``pyannote. audio 2.1 speaker diarization pipeline: principle, benchmark, and recipe,'' in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">24th INTERSPEECH Conference (INTERSPEECH 2023)</em>.   ISCA, 2023, pp. 1983–1987.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
A. Plaquet and H. Bredin, ``Powerset multi-class cross entropy loss for neural speaker diarization,'' in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proc. INTERSPEECH 2023</em>, 2023, pp. 3222–3226.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J. Devlin, M. Chang, K. Lee, and K. Toutanova, ``BERT: pre-training of deep bidirectional transformers for language understanding,'' in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, J. Burstein, C. Doran, and T. Solorio, Eds.   Association for Computational Linguistics, 2019, pp. 4171–4186. [Online]. Available: <a target="_blank" href="https://doi.org/10.18653/v1/n19-1423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/n19-1423</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
S. B. Needleman and C. D. Wunsch, ``A general method applicable to the search for similarities in the amino acid sequence of two proteins,'' <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Journal of Molecular Biology</em>, vol. 48, no. 3, pp. 443–453, 1970. [Online]. Available: <a target="_blank" href="https://www.sciencedirect.com/science/article/pii/0022283670900574" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/0022283670900574</a>

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.13841" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.13842" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.13842">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.13842" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.13843" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Jul  6 01:51:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
