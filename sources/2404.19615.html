<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.19615] SemiPL: A Semi-supervised Method for Event Sound Source Localization</title><meta property="og:description" content="In recent years, Event Sound Source Localization has been widely applied in various fields. Recent works typically relying on the contrastive learning framework show impressive performance. However, all work is based oâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SemiPL: A Semi-supervised Method for Event Sound Source Localization">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SemiPL: A Semi-supervised Method for Event Sound Source Localization">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.19615">

<!--Generated on Sun May  5 20:58:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SemiPL: A Semi-supervised Method for Event Sound Source Localization</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">In recent years, Event Sound Source Localization has been widely applied in various fields. Recent works typically relying on the contrastive learning framework show impressive performance. However, all work is based on large relatively simple datasets. Itâ€™s also crucial to understand and analyze human behaviors (actions and interactions of people), voices and sounds in chaotic events in many applications, e.g., crowd management, and emergency response services. In this paper, we apply the existing model to a more complex dataset, explore the influence of parameters on the model, and propose a semi-supervised improvement method SemiPL. With the increase in data quantity and the influence of label quality, self-supervised learning will be an unstoppable trend. The experiment shows that the parameter adjustment will positively affect the existing model. In particular, SSPL achieved an improvement of 12.2% cIoU and 0.56% AUC in Chaotic World compared to the results provided. The code is available at:
https://github.com/ly245422/SSPL</p>
</div>
<section id="S1" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Vision can influence our perception of sound. For example, when we view a picture, visual images can change our interpretation and emotional experience of the sound. Visual images, colors, and motion can guide our perception of sound and the construction of scenarios. Hearing can also influence our perception and experience of visuals <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. For example, when we hear a sound, the pitch, volume, and rhythm of the sound can influence our perception and emotion of visual objects. Sound can enhance or diminish our attention, emotions, and feelings about our visual environment.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">When we hear the roar of a car engine, we can infer the speed and motion of the car based on the pitch and volume of the engine sound. Early experiments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> have shown that sudden sounds enhance perceptual processing of subsequent visual stimuli. This sound perception of speed directly affects our visual perception of the road and vehicles around us. This interplay and interaction stems from the brainâ€™s ability to synthesize and process different sensations. By integrating existing sensory inputs, the brain develops a more comprehensive and accurate perceptual experience. This interaction also reflects the connections and coordination between perceptions, helping us to better understand and adapt to our surroundings.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Thus, acoustic event detection is a rather broad topic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> in the field of environmental sound detection and classification, with a wide range of applicability in surveillance and monitoring, assistive technologies, and multimedia indexing. Recent works showing impressive localization performance typically rely on the contrastive learning framework. With the increase in data quantity and the influence of label quality, self-supervised learning will be an unstoppable trend in the future <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. For datasets with partial labels, undoubtedly, semi-supervised learning is the best choice and also the inevitable trend for the future development of sound source localization. So, we propose a semi-supervised method SemiPL.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The main contributions of this paper are:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We apply SSPL to the Chaotic World dataset achieving an improvement of 12.2% cIoU and 0.56% AUC.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We explore the application of the semi-supervised method SemiPL and the effect of different parameters on SSPL on the Chaotic World dataset.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Sound Localization in Visual Scenes</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Sound source localization within visual scenes seeks to pinpoint the location of objects producing sound within a specified image. Initial efforts to address this challenging task predominantly focused on leveraging statistical modeling of crossmodal relationships, utilizing techniques such as mutual information and canonical correlation analysis to effectively capture the underlying associations. Nonetheless, these shallow models primarily demonstrate their strengths in relatively straightforward audio-visual scenarios. Currently, employing deep learning techniques to tackle this task has become the mainstream approach. For example, Senocak et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> introduce an innovative unsupervised algorithm for localizing sound sources by utilizing an attention mechanism. This mechanism is guided by auditory information in conjunction with paired sound and video frames, offering a sophisticated approach to address the problem. In response to the daunting challenge of visually localizing multiple sound sources in unconstrained videos without the availability of pairwise sound-object annotations, Qian et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> engineered a two-stage audiovisual learning framework. This innovative solution separates audio and visual representations of different categories within complex scenes and subsequently executes a cross-modal feature alignment in a progressively refined manner.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Self-Supervised Visual Representation Learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Self-supervised learning (SSL) has made significant strides and achieved remarkable breakthroughs in large-scale computer vision benchmarks. The majority of contemporary SSL methods rely on the implementation of contrastive learning strategies. Fundamentally, these approaches transform a single image into multiple views, simultaneously repelling distinct images (negatives) while attracting various perspectives of the same image (positives). Numerous efforts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> have been dedicated to alleviating the reliance on negatives and streamlining the SSL framework beyond the scope of traditional contrastive learning approaches. For instance, to minimize the computational burden associated with positive and negative sample pairs, Ermolov et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> chart a different course by proposing a novel loss function for SSL, which is founded on the whitening of latent-space features. Grill et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> presents a fresh approach to self-supervised image representation learning, known as Bootstrap Your Own Latent (BYOL). This innovative method hinges on the synergy between two neural networks, dubbed online and target networks, which collaborate and continuously learn from one another.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Audio-Visual Representation Learning.</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Often, vision and sound function as complementary senses that naturally aid in supervising audio-visual learning
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, visual features drawn from a pre-trained teacher network assist a student network in acquiring more distinctive audio representations, and the reverse is also true <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Korbar et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and Owens and Efros [41] leveraged the synchronization between audio and visual streams to create negative samples and formulate contrast loss, respectively, aiming to derive generalized multisensory characteristics. Certain investigations have also delved into audio-visual correspondences via feature clustering. Primarily, these methodologies concentrate on acquiring task-independent representations for downstream classification-related endeavors, including action/scene recognition, audio event categorization, and video retrieval. Nevertheless, as they are not tailored for sound source localization, their performance on this particular task remains constrained.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Chaotic World Dataset</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The SSPL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> model has achieved excellent results on the traditional Flickr-SoundNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> dataset and VGG-Sound <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> with the leading edge. However, Itâ€™s also crucial to understand and analyze human behaviors (actions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and interactions of people <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>), voices, and sounds in chaotic events in many applications, e.g., crowd management, and emergency response services. Unlike human behavior in everyday life, human behavior during chaotic events is often more complex and their actions and impacts on others are often unusual. Thus, this paper aims to utilize the Chaotic World dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, which is a large and challenging multi-modal video dataset.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Chaotic World dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> consists of a total of 378,093 annotated instances for triangulating the source of sound for Event Sound Source Localization. The dataset aims to analyze multiple dimensions of a scene to study human behavior in chaotic situations in a comprehensive and detailed manner, and to understand the nature of human behavior (including human actions and interactions) during chaotic events. Sound is critical in the understanding and response to chaotic events in many applications, such as crowd management and emergency response services. Therefore, it is important to provide a comprehensive analysis of human behavior during chaotic events.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">In this paper, we use the Chaotic World dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, which contains data on the localization of event sound sources as well as acoustic aspects, to fully understand human behavior in chaotic situations.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2404.19615/assets/image/dataset.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="315" height="114" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig.Â 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Left: SSPL (w/ PCM) input data format. Right: SSPL (w/o PCM) input data format.</span></figcaption>
</figure>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2404.19615/assets/image/model.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="274" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig.Â 2</span>: </span><span id="S3.F2.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Framework of our Semi-Supervised Model SemiPL.<span id="S3.F2.4.2.1" class="ltx_text ltx_font_medium"> The AM and PCM modules remain consistent with SSPL, with the addition of an unsupervised loss. </span></span></figcaption>
</figure>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">This paper uses 456 videos from this dataset, 384 training videos, and 72 test videos. We first extract each video frame by frame, and then extract the middle frame of each video and 1.5s of audio before and after the middle frame, for a total of 3s of audio, to form image-audio pairs. After that, we train the model using two random subsets of 1595 image-audio pairs and provide 304 annotated image-audio pairs for evaluation. The annotations in the Chaotic World dataset provide the fps corresponding to the start and end times of the videos and the bounding box coordinates in non-normalized xyxy format from start time to end time, we extract the intermediate video frames and the corresponding audio and annotation boxes based on the video frame index, as shown in Figure <a href="#S3.F1" title="Figure 1 â€£ 3 Chaotic World Dataset â€£ SemiPL: A Semi-supervised Method for Event Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For SSPL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> without PCM(a predictive coding module), we also extract the keywords ssl(type of sound) in the annotations as the class labels, as shown in Figure <a href="#S3.F1" title="Figure 1 â€£ 3 Chaotic World Dataset â€£ SemiPL: A Semi-supervised Method for Event Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. If there exists only one annotation frame for a certain video, the first annotation frame is selected as the true value.</p>
</div>
</section>
<section id="S4" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Method</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we delved deeper into the influence of various parameters on the effectiveness of SSPL (Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Through rigorous experimentation, we observed how changes in these parameters affected the algorithmâ€™s accuracy, efficiency, and stability. Additionally, we introduced our novel semi-supervised learning approach, SemiPL, which incorporates advancements in both supervised and unsupervised learning techniques. By leveraging unlabeled data more effectively, SemiPL aims to enhance the overall performance and generalizability of machine learning models, especially in scenarios where labeled data is scarce.</p>
</div>
<section id="S4.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Parameter adjustments</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">During the research process, we found that learning rates have a significant impact on the performance of SSPL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Therefore, we attempted to adjust the learning rates and batch size per GPU to observe their effects on the performance of SSPL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. We reduced the ssl head learning rate from 5e-5 to 3e-5. Also, we reduce batch size per GPU from 128 to 64. The results and analysis will be provided in the section experiment.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Semi-supervised Learning</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.11" class="ltx_p">To achieve the same performance, semi-supervised learning requires only a small amount of labeled data and a certain amount of unlabeled data, while self-supervised learning usually requires a large amount of unlabeled data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Therefore, for the Chaotic World dataset, self-supervised learning may not obtain enough information to learn effective feature representations. We devised a semi-supervised method SemiPL under the self-supervised learning setup. We incorporated supervised loss into the SSPL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> network architecture. To achieve this, we formulated a semi-supervised loss,</p>
<table id="S7.EGx1" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S4.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E1.m1.6" class="ltx_Math" alttext="\displaystyle L_{SSPL}=L_{S}\left(\hat{y}_{i},y_{i}\right)+L_{U}\left(p_{1},p_{2},z_{1},z_{2}\right)" display="inline"><semantics id="S4.E1.m1.6a"><mrow id="S4.E1.m1.6.6" xref="S4.E1.m1.6.6.cmml"><msub id="S4.E1.m1.6.6.8" xref="S4.E1.m1.6.6.8.cmml"><mi id="S4.E1.m1.6.6.8.2" xref="S4.E1.m1.6.6.8.2.cmml">L</mi><mrow id="S4.E1.m1.6.6.8.3" xref="S4.E1.m1.6.6.8.3.cmml"><mi id="S4.E1.m1.6.6.8.3.2" xref="S4.E1.m1.6.6.8.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.6.6.8.3.1" xref="S4.E1.m1.6.6.8.3.1.cmml">â€‹</mo><mi id="S4.E1.m1.6.6.8.3.3" xref="S4.E1.m1.6.6.8.3.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.6.6.8.3.1a" xref="S4.E1.m1.6.6.8.3.1.cmml">â€‹</mo><mi id="S4.E1.m1.6.6.8.3.4" xref="S4.E1.m1.6.6.8.3.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.6.6.8.3.1b" xref="S4.E1.m1.6.6.8.3.1.cmml">â€‹</mo><mi id="S4.E1.m1.6.6.8.3.5" xref="S4.E1.m1.6.6.8.3.5.cmml">L</mi></mrow></msub><mo id="S4.E1.m1.6.6.7" xref="S4.E1.m1.6.6.7.cmml">=</mo><mrow id="S4.E1.m1.6.6.6" xref="S4.E1.m1.6.6.6.cmml"><mrow id="S4.E1.m1.2.2.2.2" xref="S4.E1.m1.2.2.2.2.cmml"><msub id="S4.E1.m1.2.2.2.2.4" xref="S4.E1.m1.2.2.2.2.4.cmml"><mi id="S4.E1.m1.2.2.2.2.4.2" xref="S4.E1.m1.2.2.2.2.4.2.cmml">L</mi><mi id="S4.E1.m1.2.2.2.2.4.3" xref="S4.E1.m1.2.2.2.2.4.3.cmml">S</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.2.2.2.2.3" xref="S4.E1.m1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S4.E1.m1.2.2.2.2.2.2" xref="S4.E1.m1.2.2.2.2.2.3.cmml"><mo id="S4.E1.m1.2.2.2.2.2.2.3" xref="S4.E1.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S4.E1.m1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E1.m1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.1.2.2" xref="S4.E1.m1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mo id="S4.E1.m1.1.1.1.1.1.1.1.2.1" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S4.E1.m1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.E1.m1.2.2.2.2.2.2.4" xref="S4.E1.m1.2.2.2.2.2.3.cmml">,</mo><msub id="S4.E1.m1.2.2.2.2.2.2.2" xref="S4.E1.m1.2.2.2.2.2.2.2.cmml"><mi id="S4.E1.m1.2.2.2.2.2.2.2.2" xref="S4.E1.m1.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="S4.E1.m1.2.2.2.2.2.2.2.3" xref="S4.E1.m1.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S4.E1.m1.2.2.2.2.2.2.5" xref="S4.E1.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.6.6.6.7" xref="S4.E1.m1.6.6.6.7.cmml">+</mo><mrow id="S4.E1.m1.6.6.6.6" xref="S4.E1.m1.6.6.6.6.cmml"><msub id="S4.E1.m1.6.6.6.6.6" xref="S4.E1.m1.6.6.6.6.6.cmml"><mi id="S4.E1.m1.6.6.6.6.6.2" xref="S4.E1.m1.6.6.6.6.6.2.cmml">L</mi><mi id="S4.E1.m1.6.6.6.6.6.3" xref="S4.E1.m1.6.6.6.6.6.3.cmml">U</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.6.6.6.6.5" xref="S4.E1.m1.6.6.6.6.5.cmml">â€‹</mo><mrow id="S4.E1.m1.6.6.6.6.4.4" xref="S4.E1.m1.6.6.6.6.4.5.cmml"><mo id="S4.E1.m1.6.6.6.6.4.4.5" xref="S4.E1.m1.6.6.6.6.4.5.cmml">(</mo><msub id="S4.E1.m1.3.3.3.3.1.1.1" xref="S4.E1.m1.3.3.3.3.1.1.1.cmml"><mi id="S4.E1.m1.3.3.3.3.1.1.1.2" xref="S4.E1.m1.3.3.3.3.1.1.1.2.cmml">p</mi><mn id="S4.E1.m1.3.3.3.3.1.1.1.3" xref="S4.E1.m1.3.3.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S4.E1.m1.6.6.6.6.4.4.6" xref="S4.E1.m1.6.6.6.6.4.5.cmml">,</mo><msub id="S4.E1.m1.4.4.4.4.2.2.2" xref="S4.E1.m1.4.4.4.4.2.2.2.cmml"><mi id="S4.E1.m1.4.4.4.4.2.2.2.2" xref="S4.E1.m1.4.4.4.4.2.2.2.2.cmml">p</mi><mn id="S4.E1.m1.4.4.4.4.2.2.2.3" xref="S4.E1.m1.4.4.4.4.2.2.2.3.cmml">2</mn></msub><mo id="S4.E1.m1.6.6.6.6.4.4.7" xref="S4.E1.m1.6.6.6.6.4.5.cmml">,</mo><msub id="S4.E1.m1.5.5.5.5.3.3.3" xref="S4.E1.m1.5.5.5.5.3.3.3.cmml"><mi id="S4.E1.m1.5.5.5.5.3.3.3.2" xref="S4.E1.m1.5.5.5.5.3.3.3.2.cmml">z</mi><mn id="S4.E1.m1.5.5.5.5.3.3.3.3" xref="S4.E1.m1.5.5.5.5.3.3.3.3.cmml">1</mn></msub><mo id="S4.E1.m1.6.6.6.6.4.4.8" xref="S4.E1.m1.6.6.6.6.4.5.cmml">,</mo><msub id="S4.E1.m1.6.6.6.6.4.4.4" xref="S4.E1.m1.6.6.6.6.4.4.4.cmml"><mi id="S4.E1.m1.6.6.6.6.4.4.4.2" xref="S4.E1.m1.6.6.6.6.4.4.4.2.cmml">z</mi><mn id="S4.E1.m1.6.6.6.6.4.4.4.3" xref="S4.E1.m1.6.6.6.6.4.4.4.3.cmml">2</mn></msub><mo id="S4.E1.m1.6.6.6.6.4.4.9" xref="S4.E1.m1.6.6.6.6.4.5.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.6b"><apply id="S4.E1.m1.6.6.cmml" xref="S4.E1.m1.6.6"><eq id="S4.E1.m1.6.6.7.cmml" xref="S4.E1.m1.6.6.7"></eq><apply id="S4.E1.m1.6.6.8.cmml" xref="S4.E1.m1.6.6.8"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.8.1.cmml" xref="S4.E1.m1.6.6.8">subscript</csymbol><ci id="S4.E1.m1.6.6.8.2.cmml" xref="S4.E1.m1.6.6.8.2">ğ¿</ci><apply id="S4.E1.m1.6.6.8.3.cmml" xref="S4.E1.m1.6.6.8.3"><times id="S4.E1.m1.6.6.8.3.1.cmml" xref="S4.E1.m1.6.6.8.3.1"></times><ci id="S4.E1.m1.6.6.8.3.2.cmml" xref="S4.E1.m1.6.6.8.3.2">ğ‘†</ci><ci id="S4.E1.m1.6.6.8.3.3.cmml" xref="S4.E1.m1.6.6.8.3.3">ğ‘†</ci><ci id="S4.E1.m1.6.6.8.3.4.cmml" xref="S4.E1.m1.6.6.8.3.4">ğ‘ƒ</ci><ci id="S4.E1.m1.6.6.8.3.5.cmml" xref="S4.E1.m1.6.6.8.3.5">ğ¿</ci></apply></apply><apply id="S4.E1.m1.6.6.6.cmml" xref="S4.E1.m1.6.6.6"><plus id="S4.E1.m1.6.6.6.7.cmml" xref="S4.E1.m1.6.6.6.7"></plus><apply id="S4.E1.m1.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2"><times id="S4.E1.m1.2.2.2.2.3.cmml" xref="S4.E1.m1.2.2.2.2.3"></times><apply id="S4.E1.m1.2.2.2.2.4.cmml" xref="S4.E1.m1.2.2.2.2.4"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.4.1.cmml" xref="S4.E1.m1.2.2.2.2.4">subscript</csymbol><ci id="S4.E1.m1.2.2.2.2.4.2.cmml" xref="S4.E1.m1.2.2.2.2.4.2">ğ¿</ci><ci id="S4.E1.m1.2.2.2.2.4.3.cmml" xref="S4.E1.m1.2.2.2.2.4.3">ğ‘†</ci></apply><interval closure="open" id="S4.E1.m1.2.2.2.2.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2"><apply id="S4.E1.m1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2"><ci id="S4.E1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S4.E1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.2.2">ğ‘¦</ci></apply><ci id="S4.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S4.E1.m1.2.2.2.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.2.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S4.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2.2.2">ğ‘¦</ci><ci id="S4.E1.m1.2.2.2.2.2.2.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.2.2.3">ğ‘–</ci></apply></interval></apply><apply id="S4.E1.m1.6.6.6.6.cmml" xref="S4.E1.m1.6.6.6.6"><times id="S4.E1.m1.6.6.6.6.5.cmml" xref="S4.E1.m1.6.6.6.6.5"></times><apply id="S4.E1.m1.6.6.6.6.6.cmml" xref="S4.E1.m1.6.6.6.6.6"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.6.6.6.1.cmml" xref="S4.E1.m1.6.6.6.6.6">subscript</csymbol><ci id="S4.E1.m1.6.6.6.6.6.2.cmml" xref="S4.E1.m1.6.6.6.6.6.2">ğ¿</ci><ci id="S4.E1.m1.6.6.6.6.6.3.cmml" xref="S4.E1.m1.6.6.6.6.6.3">ğ‘ˆ</ci></apply><vector id="S4.E1.m1.6.6.6.6.4.5.cmml" xref="S4.E1.m1.6.6.6.6.4.4"><apply id="S4.E1.m1.3.3.3.3.1.1.1.cmml" xref="S4.E1.m1.3.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.3.3.1.1.1.1.cmml" xref="S4.E1.m1.3.3.3.3.1.1.1">subscript</csymbol><ci id="S4.E1.m1.3.3.3.3.1.1.1.2.cmml" xref="S4.E1.m1.3.3.3.3.1.1.1.2">ğ‘</ci><cn type="integer" id="S4.E1.m1.3.3.3.3.1.1.1.3.cmml" xref="S4.E1.m1.3.3.3.3.1.1.1.3">1</cn></apply><apply id="S4.E1.m1.4.4.4.4.2.2.2.cmml" xref="S4.E1.m1.4.4.4.4.2.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.2.2.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.2.2">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.2.2.2.2.cmml" xref="S4.E1.m1.4.4.4.4.2.2.2.2">ğ‘</ci><cn type="integer" id="S4.E1.m1.4.4.4.4.2.2.2.3.cmml" xref="S4.E1.m1.4.4.4.4.2.2.2.3">2</cn></apply><apply id="S4.E1.m1.5.5.5.5.3.3.3.cmml" xref="S4.E1.m1.5.5.5.5.3.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.5.5.5.5.3.3.3.1.cmml" xref="S4.E1.m1.5.5.5.5.3.3.3">subscript</csymbol><ci id="S4.E1.m1.5.5.5.5.3.3.3.2.cmml" xref="S4.E1.m1.5.5.5.5.3.3.3.2">ğ‘§</ci><cn type="integer" id="S4.E1.m1.5.5.5.5.3.3.3.3.cmml" xref="S4.E1.m1.5.5.5.5.3.3.3.3">1</cn></apply><apply id="S4.E1.m1.6.6.6.6.4.4.4.cmml" xref="S4.E1.m1.6.6.6.6.4.4.4"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.6.6.4.4.4.1.cmml" xref="S4.E1.m1.6.6.6.6.4.4.4">subscript</csymbol><ci id="S4.E1.m1.6.6.6.6.4.4.4.2.cmml" xref="S4.E1.m1.6.6.6.6.4.4.4.2">ğ‘§</ci><cn type="integer" id="S4.E1.m1.6.6.6.6.4.4.4.3.cmml" xref="S4.E1.m1.6.6.6.6.4.4.4.3">2</cn></apply></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.6c">\displaystyle L_{SSPL}=L_{S}\left(\hat{y}_{i},y_{i}\right)+L_{U}\left(p_{1},p_{2},z_{1},z_{2}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.3" class="ltx_p">where <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="L_{U}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msub id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">L</mi><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">U</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">ğ¿</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">L_{U}</annotation></semantics></math> and <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="L_{S}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msub id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">L</mi><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">ğ¿</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">L_{S}</annotation></semantics></math> denote unsupervised and supervised losses respectively. The unsupervised loss <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="L_{U}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><msub id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">L</mi><mi id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">U</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">ğ¿</ci><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">ğ‘ˆ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">L_{U}</annotation></semantics></math> function is defined as,</p>
<table id="S7.EGx2" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S4.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E2.m1.1" class="ltx_Math" alttext="\displaystyle\text{L}_{U}=\frac{1}{2}\left(\text{NCS}(p_{1},z_{2})+\text{NCS}(p_{2},z_{1})\right)" display="inline"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><msub id="S4.E2.m1.1.1.3" xref="S4.E2.m1.1.1.3.cmml"><mtext id="S4.E2.m1.1.1.3.2" xref="S4.E2.m1.1.1.3.2a.cmml">L</mtext><mi id="S4.E2.m1.1.1.3.3" xref="S4.E2.m1.1.1.3.3.cmml">U</mi></msub><mo id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">=</mo><mrow id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.cmml"><mstyle displaystyle="true" id="S4.E2.m1.1.1.1.3" xref="S4.E2.m1.1.1.1.3.cmml"><mfrac id="S4.E2.m1.1.1.1.3a" xref="S4.E2.m1.1.1.1.3.cmml"><mn id="S4.E2.m1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.3.2.cmml">1</mn><mn id="S4.E2.m1.1.1.1.3.3" xref="S4.E2.m1.1.1.1.3.3.cmml">2</mn></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.2" xref="S4.E2.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml"><mo id="S4.E2.m1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.2.cmml"><mtext id="S4.E2.m1.1.1.1.1.1.1.2.4" xref="S4.E2.m1.1.1.1.1.1.1.2.4a.cmml">NCS</mtext><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.2.3" xref="S4.E2.m1.1.1.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.2.2.2" xref="S4.E2.m1.1.1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.2.2.2.3" xref="S4.E2.m1.1.1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">p</mi><mn id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.E2.m1.1.1.1.1.1.1.2.2.2.4" xref="S4.E2.m1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S4.E2.m1.1.1.1.1.1.1.2.2.2.2" xref="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.2" xref="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.2.cmml">z</mi><mn id="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.3" xref="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.2.2.2.5" xref="S4.E2.m1.1.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.1.1.1.1.1.1.5" xref="S4.E2.m1.1.1.1.1.1.1.5.cmml">+</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.4" xref="S4.E2.m1.1.1.1.1.1.1.4.cmml"><mtext id="S4.E2.m1.1.1.1.1.1.1.4.4" xref="S4.E2.m1.1.1.1.1.1.1.4.4a.cmml">NCS</mtext><mo lspace="0em" rspace="0em" id="S4.E2.m1.1.1.1.1.1.1.4.3" xref="S4.E2.m1.1.1.1.1.1.1.4.3.cmml">â€‹</mo><mrow id="S4.E2.m1.1.1.1.1.1.1.4.2.2" xref="S4.E2.m1.1.1.1.1.1.1.4.2.3.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.4.2.2.3" xref="S4.E2.m1.1.1.1.1.1.1.4.2.3.cmml">(</mo><msub id="S4.E2.m1.1.1.1.1.1.1.3.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.2.cmml">p</mi><mn id="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.3.cmml">2</mn></msub><mo id="S4.E2.m1.1.1.1.1.1.1.4.2.2.4" xref="S4.E2.m1.1.1.1.1.1.1.4.2.3.cmml">,</mo><msub id="S4.E2.m1.1.1.1.1.1.1.4.2.2.2" xref="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.2" xref="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.2.cmml">z</mi><mn id="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.3" xref="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.4.2.2.5" xref="S4.E2.m1.1.1.1.1.1.1.4.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E2.m1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"><eq id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2"></eq><apply id="S4.E2.m1.1.1.3.cmml" xref="S4.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.3">subscript</csymbol><ci id="S4.E2.m1.1.1.3.2a.cmml" xref="S4.E2.m1.1.1.3.2"><mtext id="S4.E2.m1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.3.2">L</mtext></ci><ci id="S4.E2.m1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.3.3">ğ‘ˆ</ci></apply><apply id="S4.E2.m1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"><times id="S4.E2.m1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.2"></times><apply id="S4.E2.m1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.3"><divide id="S4.E2.m1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.3"></divide><cn type="integer" id="S4.E2.m1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.3.2">1</cn><cn type="integer" id="S4.E2.m1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.3.3">2</cn></apply><apply id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1"><plus id="S4.E2.m1.1.1.1.1.1.1.5.cmml" xref="S4.E2.m1.1.1.1.1.1.1.5"></plus><apply id="S4.E2.m1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2"><times id="S4.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.3"></times><ci id="S4.E2.m1.1.1.1.1.1.1.2.4a.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.4"><mtext id="S4.E2.m1.1.1.1.1.1.1.2.4.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.4">NCS</mtext></ci><interval closure="open" id="S4.E2.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.2.2"><apply id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.1.1.1.3">1</cn></apply><apply id="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.2">ğ‘§</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S4.E2.m1.1.1.1.1.1.1.4.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4"><times id="S4.E2.m1.1.1.1.1.1.1.4.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4.3"></times><ci id="S4.E2.m1.1.1.1.1.1.1.4.4a.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4.4"><mtext id="S4.E2.m1.1.1.1.1.1.1.4.4.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4.4">NCS</mtext></ci><interval closure="open" id="S4.E2.m1.1.1.1.1.1.1.4.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4.2.2"><apply id="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.1.1.1">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.2">ğ‘</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.3.1.1.1.3">2</cn></apply><apply id="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4.2.2.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.2">ğ‘§</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.4.2.2.2.3">1</cn></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">\displaystyle\text{L}_{U}=\frac{1}{2}\left(\text{NCS}(p_{1},z_{2})+\text{NCS}(p_{2},z_{1})\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.7" class="ltx_p">where <math id="S4.SS2.p1.4.m1.1" class="ltx_Math" alttext="p_{1}" display="inline"><semantics id="S4.SS2.p1.4.m1.1a"><msub id="S4.SS2.p1.4.m1.1.1" xref="S4.SS2.p1.4.m1.1.1.cmml"><mi id="S4.SS2.p1.4.m1.1.1.2" xref="S4.SS2.p1.4.m1.1.1.2.cmml">p</mi><mn id="S4.SS2.p1.4.m1.1.1.3" xref="S4.SS2.p1.4.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m1.1b"><apply id="S4.SS2.p1.4.m1.1.1.cmml" xref="S4.SS2.p1.4.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m1.1.1.1.cmml" xref="S4.SS2.p1.4.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.4.m1.1.1.2.cmml" xref="S4.SS2.p1.4.m1.1.1.2">ğ‘</ci><cn type="integer" id="S4.SS2.p1.4.m1.1.1.3.cmml" xref="S4.SS2.p1.4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m1.1c">p_{1}</annotation></semantics></math> and <math id="S4.SS2.p1.5.m2.1" class="ltx_Math" alttext="p_{2}" display="inline"><semantics id="S4.SS2.p1.5.m2.1a"><msub id="S4.SS2.p1.5.m2.1.1" xref="S4.SS2.p1.5.m2.1.1.cmml"><mi id="S4.SS2.p1.5.m2.1.1.2" xref="S4.SS2.p1.5.m2.1.1.2.cmml">p</mi><mn id="S4.SS2.p1.5.m2.1.1.3" xref="S4.SS2.p1.5.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m2.1b"><apply id="S4.SS2.p1.5.m2.1.1.cmml" xref="S4.SS2.p1.5.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.5.m2.1.1.1.cmml" xref="S4.SS2.p1.5.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.5.m2.1.1.2.cmml" xref="S4.SS2.p1.5.m2.1.1.2">ğ‘</ci><cn type="integer" id="S4.SS2.p1.5.m2.1.1.3.cmml" xref="S4.SS2.p1.5.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m2.1c">p_{2}</annotation></semantics></math> are the outputs of the two projection heads of the network, and <math id="S4.SS2.p1.6.m3.1" class="ltx_Math" alttext="z_{1}" display="inline"><semantics id="S4.SS2.p1.6.m3.1a"><msub id="S4.SS2.p1.6.m3.1.1" xref="S4.SS2.p1.6.m3.1.1.cmml"><mi id="S4.SS2.p1.6.m3.1.1.2" xref="S4.SS2.p1.6.m3.1.1.2.cmml">z</mi><mn id="S4.SS2.p1.6.m3.1.1.3" xref="S4.SS2.p1.6.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m3.1b"><apply id="S4.SS2.p1.6.m3.1.1.cmml" xref="S4.SS2.p1.6.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m3.1.1.1.cmml" xref="S4.SS2.p1.6.m3.1.1">subscript</csymbol><ci id="S4.SS2.p1.6.m3.1.1.2.cmml" xref="S4.SS2.p1.6.m3.1.1.2">ğ‘§</ci><cn type="integer" id="S4.SS2.p1.6.m3.1.1.3.cmml" xref="S4.SS2.p1.6.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m3.1c">z_{1}</annotation></semantics></math> and <math id="S4.SS2.p1.7.m4.1" class="ltx_Math" alttext="z_{2}" display="inline"><semantics id="S4.SS2.p1.7.m4.1a"><msub id="S4.SS2.p1.7.m4.1.1" xref="S4.SS2.p1.7.m4.1.1.cmml"><mi id="S4.SS2.p1.7.m4.1.1.2" xref="S4.SS2.p1.7.m4.1.1.2.cmml">z</mi><mn id="S4.SS2.p1.7.m4.1.1.3" xref="S4.SS2.p1.7.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m4.1b"><apply id="S4.SS2.p1.7.m4.1.1.cmml" xref="S4.SS2.p1.7.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.7.m4.1.1.1.cmml" xref="S4.SS2.p1.7.m4.1.1">subscript</csymbol><ci id="S4.SS2.p1.7.m4.1.1.2.cmml" xref="S4.SS2.p1.7.m4.1.1.2">ğ‘§</ci><cn type="integer" id="S4.SS2.p1.7.m4.1.1.3.cmml" xref="S4.SS2.p1.7.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m4.1c">z_{2}</annotation></semantics></math> are the outputs of the corresponding augmented samples, and negative cosine similarity (NCS) is calculated by:</p>
<table id="S7.EGx3" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S4.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E3.m1.4" class="ltx_Math" alttext="\displaystyle\text{NCS}(p,z)=\frac{p\cdot z}{\|p\|\|z\|}" display="inline"><semantics id="S4.E3.m1.4a"><mrow id="S4.E3.m1.4.5" xref="S4.E3.m1.4.5.cmml"><mrow id="S4.E3.m1.4.5.2" xref="S4.E3.m1.4.5.2.cmml"><mtext id="S4.E3.m1.4.5.2.2" xref="S4.E3.m1.4.5.2.2a.cmml">NCS</mtext><mo lspace="0em" rspace="0em" id="S4.E3.m1.4.5.2.1" xref="S4.E3.m1.4.5.2.1.cmml">â€‹</mo><mrow id="S4.E3.m1.4.5.2.3.2" xref="S4.E3.m1.4.5.2.3.1.cmml"><mo stretchy="false" id="S4.E3.m1.4.5.2.3.2.1" xref="S4.E3.m1.4.5.2.3.1.cmml">(</mo><mi id="S4.E3.m1.3.3" xref="S4.E3.m1.3.3.cmml">p</mi><mo id="S4.E3.m1.4.5.2.3.2.2" xref="S4.E3.m1.4.5.2.3.1.cmml">,</mo><mi id="S4.E3.m1.4.4" xref="S4.E3.m1.4.4.cmml">z</mi><mo stretchy="false" id="S4.E3.m1.4.5.2.3.2.3" xref="S4.E3.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E3.m1.4.5.1" xref="S4.E3.m1.4.5.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E3.m1.2.2" xref="S4.E3.m1.2.2.cmml"><mfrac id="S4.E3.m1.2.2a" xref="S4.E3.m1.2.2.cmml"><mrow id="S4.E3.m1.2.2.4" xref="S4.E3.m1.2.2.4.cmml"><mi id="S4.E3.m1.2.2.4.2" xref="S4.E3.m1.2.2.4.2.cmml">p</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E3.m1.2.2.4.1" xref="S4.E3.m1.2.2.4.1.cmml">â‹…</mo><mi id="S4.E3.m1.2.2.4.3" xref="S4.E3.m1.2.2.4.3.cmml">z</mi></mrow><mrow id="S4.E3.m1.2.2.2" xref="S4.E3.m1.2.2.2.cmml"><mrow id="S4.E3.m1.2.2.2.4.2" xref="S4.E3.m1.2.2.2.4.1.cmml"><mo stretchy="false" id="S4.E3.m1.2.2.2.4.2.1" xref="S4.E3.m1.2.2.2.4.1.1.cmml">â€–</mo><mi id="S4.E3.m1.1.1.1.1" xref="S4.E3.m1.1.1.1.1.cmml">p</mi><mo stretchy="false" id="S4.E3.m1.2.2.2.4.2.2" xref="S4.E3.m1.2.2.2.4.1.1.cmml">â€–</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.2.3" xref="S4.E3.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S4.E3.m1.2.2.2.5.2" xref="S4.E3.m1.2.2.2.5.1.cmml"><mo stretchy="false" id="S4.E3.m1.2.2.2.5.2.1" xref="S4.E3.m1.2.2.2.5.1.1.cmml">â€–</mo><mi id="S4.E3.m1.2.2.2.2" xref="S4.E3.m1.2.2.2.2.cmml">z</mi><mo stretchy="false" id="S4.E3.m1.2.2.2.5.2.2" xref="S4.E3.m1.2.2.2.5.1.1.cmml">â€–</mo></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.4b"><apply id="S4.E3.m1.4.5.cmml" xref="S4.E3.m1.4.5"><eq id="S4.E3.m1.4.5.1.cmml" xref="S4.E3.m1.4.5.1"></eq><apply id="S4.E3.m1.4.5.2.cmml" xref="S4.E3.m1.4.5.2"><times id="S4.E3.m1.4.5.2.1.cmml" xref="S4.E3.m1.4.5.2.1"></times><ci id="S4.E3.m1.4.5.2.2a.cmml" xref="S4.E3.m1.4.5.2.2"><mtext id="S4.E3.m1.4.5.2.2.cmml" xref="S4.E3.m1.4.5.2.2">NCS</mtext></ci><interval closure="open" id="S4.E3.m1.4.5.2.3.1.cmml" xref="S4.E3.m1.4.5.2.3.2"><ci id="S4.E3.m1.3.3.cmml" xref="S4.E3.m1.3.3">ğ‘</ci><ci id="S4.E3.m1.4.4.cmml" xref="S4.E3.m1.4.4">ğ‘§</ci></interval></apply><apply id="S4.E3.m1.2.2.cmml" xref="S4.E3.m1.2.2"><divide id="S4.E3.m1.2.2.3.cmml" xref="S4.E3.m1.2.2"></divide><apply id="S4.E3.m1.2.2.4.cmml" xref="S4.E3.m1.2.2.4"><ci id="S4.E3.m1.2.2.4.1.cmml" xref="S4.E3.m1.2.2.4.1">â‹…</ci><ci id="S4.E3.m1.2.2.4.2.cmml" xref="S4.E3.m1.2.2.4.2">ğ‘</ci><ci id="S4.E3.m1.2.2.4.3.cmml" xref="S4.E3.m1.2.2.4.3">ğ‘§</ci></apply><apply id="S4.E3.m1.2.2.2.cmml" xref="S4.E3.m1.2.2.2"><times id="S4.E3.m1.2.2.2.3.cmml" xref="S4.E3.m1.2.2.2.3"></times><apply id="S4.E3.m1.2.2.2.4.1.cmml" xref="S4.E3.m1.2.2.2.4.2"><csymbol cd="latexml" id="S4.E3.m1.2.2.2.4.1.1.cmml" xref="S4.E3.m1.2.2.2.4.2.1">norm</csymbol><ci id="S4.E3.m1.1.1.1.1.cmml" xref="S4.E3.m1.1.1.1.1">ğ‘</ci></apply><apply id="S4.E3.m1.2.2.2.5.1.cmml" xref="S4.E3.m1.2.2.2.5.2"><csymbol cd="latexml" id="S4.E3.m1.2.2.2.5.1.1.cmml" xref="S4.E3.m1.2.2.2.5.2.1">norm</csymbol><ci id="S4.E3.m1.2.2.2.2.cmml" xref="S4.E3.m1.2.2.2.2">ğ‘§</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.4c">\displaystyle\text{NCS}(p,z)=\frac{p\cdot z}{\|p\|\|z\|}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.8" class="ltx_p"><math id="S4.SS2.p1.8.m1.1" class="ltx_Math" alttext="L_{S}" display="inline"><semantics id="S4.SS2.p1.8.m1.1a"><msub id="S4.SS2.p1.8.m1.1.1" xref="S4.SS2.p1.8.m1.1.1.cmml"><mi id="S4.SS2.p1.8.m1.1.1.2" xref="S4.SS2.p1.8.m1.1.1.2.cmml">L</mi><mi id="S4.SS2.p1.8.m1.1.1.3" xref="S4.SS2.p1.8.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m1.1b"><apply id="S4.SS2.p1.8.m1.1.1.cmml" xref="S4.SS2.p1.8.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.8.m1.1.1.1.cmml" xref="S4.SS2.p1.8.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.8.m1.1.1.2.cmml" xref="S4.SS2.p1.8.m1.1.1.2">ğ¿</ci><ci id="S4.SS2.p1.8.m1.1.1.3.cmml" xref="S4.SS2.p1.8.m1.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m1.1c">L_{S}</annotation></semantics></math> utilizes the cross-entropy loss function, defined by,</p>
<table id="S7.EGx4" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S4.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E4.m1.3" class="ltx_Math" alttext="\displaystyle L_{S}=-\frac{1}{N}\sum_{i=1}^{N}\left(y_{i}\log(\hat{y}_{i})+(1-y_{i})\log(1-\hat{y}_{i})\right)" display="inline"><semantics id="S4.E4.m1.3a"><mrow id="S4.E4.m1.3.3" xref="S4.E4.m1.3.3.cmml"><msub id="S4.E4.m1.3.3.3" xref="S4.E4.m1.3.3.3.cmml"><mi id="S4.E4.m1.3.3.3.2" xref="S4.E4.m1.3.3.3.2.cmml">L</mi><mi id="S4.E4.m1.3.3.3.3" xref="S4.E4.m1.3.3.3.3.cmml">S</mi></msub><mo id="S4.E4.m1.3.3.2" xref="S4.E4.m1.3.3.2.cmml">=</mo><mrow id="S4.E4.m1.3.3.1" xref="S4.E4.m1.3.3.1.cmml"><mo id="S4.E4.m1.3.3.1a" xref="S4.E4.m1.3.3.1.cmml">âˆ’</mo><mrow id="S4.E4.m1.3.3.1.1" xref="S4.E4.m1.3.3.1.1.cmml"><mstyle displaystyle="true" id="S4.E4.m1.3.3.1.1.3" xref="S4.E4.m1.3.3.1.1.3.cmml"><mfrac id="S4.E4.m1.3.3.1.1.3a" xref="S4.E4.m1.3.3.1.1.3.cmml"><mn id="S4.E4.m1.3.3.1.1.3.2" xref="S4.E4.m1.3.3.1.1.3.2.cmml">1</mn><mi id="S4.E4.m1.3.3.1.1.3.3" xref="S4.E4.m1.3.3.1.1.3.3.cmml">N</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.1.1.2" xref="S4.E4.m1.3.3.1.1.2.cmml">â€‹</mo><mrow id="S4.E4.m1.3.3.1.1.1" xref="S4.E4.m1.3.3.1.1.1.cmml"><mstyle displaystyle="true" id="S4.E4.m1.3.3.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.2.cmml"><munderover id="S4.E4.m1.3.3.1.1.1.2a" xref="S4.E4.m1.3.3.1.1.1.2.cmml"><mo movablelimits="false" id="S4.E4.m1.3.3.1.1.1.2.2.2" xref="S4.E4.m1.3.3.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E4.m1.3.3.1.1.1.2.2.3" xref="S4.E4.m1.3.3.1.1.1.2.2.3.cmml"><mi id="S4.E4.m1.3.3.1.1.1.2.2.3.2" xref="S4.E4.m1.3.3.1.1.1.2.2.3.2.cmml">i</mi><mo id="S4.E4.m1.3.3.1.1.1.2.2.3.1" xref="S4.E4.m1.3.3.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E4.m1.3.3.1.1.1.2.2.3.3" xref="S4.E4.m1.3.3.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E4.m1.3.3.1.1.1.2.3" xref="S4.E4.m1.3.3.1.1.1.2.3.cmml">N</mi></munderover></mstyle><mrow id="S4.E4.m1.3.3.1.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S4.E4.m1.3.3.1.1.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.cmml"><msub id="S4.E4.m1.3.3.1.1.1.1.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0.167em" rspace="0em" id="S4.E4.m1.3.3.1.1.1.1.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml">log</mi><mo id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1a" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">â¡</mo><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mo id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E4.m1.3.3.1.1.1.1.1.1.4" xref="S4.E4.m1.3.3.1.1.1.1.1.1.4.cmml">+</mo><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.cmml"><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.cmml"><mn id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.2.cmml">1</mn><mo id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.1.cmml">âˆ’</mo><msub id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.cmml"><mi id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.2.cmml">y</mi><mi id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow><mo lspace="0.167em" rspace="0em" id="S4.E4.m1.3.3.1.1.1.1.1.1.3.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.3.cmml">â€‹</mo><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.2.cmml"><mi id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml">log</mi><mo id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1a" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.2.cmml">â¡</mo><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.2.cmml"><mo stretchy="false" id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.2.cmml">(</mo><mrow id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.cmml"><mn id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.2.cmml">1</mn><mo id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.1.cmml">âˆ’</mo><msub id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.cmml"><mover accent="true" id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.cmml"><mi id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.2" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.2.cmml">y</mi><mo id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.1" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E4.m1.3.3.1.1.1.1.1.3" xref="S4.E4.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.3b"><apply id="S4.E4.m1.3.3.cmml" xref="S4.E4.m1.3.3"><eq id="S4.E4.m1.3.3.2.cmml" xref="S4.E4.m1.3.3.2"></eq><apply id="S4.E4.m1.3.3.3.cmml" xref="S4.E4.m1.3.3.3"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.3.1.cmml" xref="S4.E4.m1.3.3.3">subscript</csymbol><ci id="S4.E4.m1.3.3.3.2.cmml" xref="S4.E4.m1.3.3.3.2">ğ¿</ci><ci id="S4.E4.m1.3.3.3.3.cmml" xref="S4.E4.m1.3.3.3.3">ğ‘†</ci></apply><apply id="S4.E4.m1.3.3.1.cmml" xref="S4.E4.m1.3.3.1"><minus id="S4.E4.m1.3.3.1.2.cmml" xref="S4.E4.m1.3.3.1"></minus><apply id="S4.E4.m1.3.3.1.1.cmml" xref="S4.E4.m1.3.3.1.1"><times id="S4.E4.m1.3.3.1.1.2.cmml" xref="S4.E4.m1.3.3.1.1.2"></times><apply id="S4.E4.m1.3.3.1.1.3.cmml" xref="S4.E4.m1.3.3.1.1.3"><divide id="S4.E4.m1.3.3.1.1.3.1.cmml" xref="S4.E4.m1.3.3.1.1.3"></divide><cn type="integer" id="S4.E4.m1.3.3.1.1.3.2.cmml" xref="S4.E4.m1.3.3.1.1.3.2">1</cn><ci id="S4.E4.m1.3.3.1.1.3.3.cmml" xref="S4.E4.m1.3.3.1.1.3.3">ğ‘</ci></apply><apply id="S4.E4.m1.3.3.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1"><apply id="S4.E4.m1.3.3.1.1.1.2.cmml" xref="S4.E4.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.1.1.1.2.1.cmml" xref="S4.E4.m1.3.3.1.1.1.2">superscript</csymbol><apply id="S4.E4.m1.3.3.1.1.1.2.2.cmml" xref="S4.E4.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.1.1.1.2.2.1.cmml" xref="S4.E4.m1.3.3.1.1.1.2">subscript</csymbol><sum id="S4.E4.m1.3.3.1.1.1.2.2.2.cmml" xref="S4.E4.m1.3.3.1.1.1.2.2.2"></sum><apply id="S4.E4.m1.3.3.1.1.1.2.2.3.cmml" xref="S4.E4.m1.3.3.1.1.1.2.2.3"><eq id="S4.E4.m1.3.3.1.1.1.2.2.3.1.cmml" xref="S4.E4.m1.3.3.1.1.1.2.2.3.1"></eq><ci id="S4.E4.m1.3.3.1.1.1.2.2.3.2.cmml" xref="S4.E4.m1.3.3.1.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S4.E4.m1.3.3.1.1.1.2.2.3.3.cmml" xref="S4.E4.m1.3.3.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E4.m1.3.3.1.1.1.2.3.cmml" xref="S4.E4.m1.3.3.1.1.1.2.3">ğ‘</ci></apply><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1"><plus id="S4.E4.m1.3.3.1.1.1.1.1.1.4.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.4"></plus><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1"><times id="S4.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.2"></times><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.2">ğ‘¦</ci><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1"><log id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1"></log><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2"><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘¦</ci></apply><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3"><times id="S4.E4.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.3"></times><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1"><minus id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.1"></minus><cn type="integer" id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.2">1</cn><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.2">ğ‘¦</ci><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.2.1.1.1.3.3">ğ‘–</ci></apply></apply><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1"><log id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2"></log><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1"><minus id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.1"></minus><cn type="integer" id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.2">1</cn><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3">subscript</csymbol><apply id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2"><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.1.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.1">^</ci><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.2.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.2.2">ğ‘¦</ci></apply><ci id="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.3.cmml" xref="S4.E4.m1.3.3.1.1.1.1.1.1.3.2.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.3c">\displaystyle L_{S}=-\frac{1}{N}\sum_{i=1}^{N}\left(y_{i}\log(\hat{y}_{i})+(1-y_{i})\log(1-\hat{y}_{i})\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.10" class="ltx_p">where N is the size of the flattening pixel of a 224Ã—224 image. <math id="S4.SS2.p1.9.m1.1" class="ltx_Math" alttext="\hat{y}_{i}" display="inline"><semantics id="S4.SS2.p1.9.m1.1a"><msub id="S4.SS2.p1.9.m1.1.1" xref="S4.SS2.p1.9.m1.1.1.cmml"><mover accent="true" id="S4.SS2.p1.9.m1.1.1.2" xref="S4.SS2.p1.9.m1.1.1.2.cmml"><mi id="S4.SS2.p1.9.m1.1.1.2.2" xref="S4.SS2.p1.9.m1.1.1.2.2.cmml">y</mi><mo id="S4.SS2.p1.9.m1.1.1.2.1" xref="S4.SS2.p1.9.m1.1.1.2.1.cmml">^</mo></mover><mi id="S4.SS2.p1.9.m1.1.1.3" xref="S4.SS2.p1.9.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m1.1b"><apply id="S4.SS2.p1.9.m1.1.1.cmml" xref="S4.SS2.p1.9.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.9.m1.1.1.1.cmml" xref="S4.SS2.p1.9.m1.1.1">subscript</csymbol><apply id="S4.SS2.p1.9.m1.1.1.2.cmml" xref="S4.SS2.p1.9.m1.1.1.2"><ci id="S4.SS2.p1.9.m1.1.1.2.1.cmml" xref="S4.SS2.p1.9.m1.1.1.2.1">^</ci><ci id="S4.SS2.p1.9.m1.1.1.2.2.cmml" xref="S4.SS2.p1.9.m1.1.1.2.2">ğ‘¦</ci></apply><ci id="S4.SS2.p1.9.m1.1.1.3.cmml" xref="S4.SS2.p1.9.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m1.1c">\hat{y}_{i}</annotation></semantics></math> and <math id="S4.SS2.p1.10.m2.1" class="ltx_Math" alttext="{y}_{i}" display="inline"><semantics id="S4.SS2.p1.10.m2.1a"><msub id="S4.SS2.p1.10.m2.1.1" xref="S4.SS2.p1.10.m2.1.1.cmml"><mi id="S4.SS2.p1.10.m2.1.1.2" xref="S4.SS2.p1.10.m2.1.1.2.cmml">y</mi><mi id="S4.SS2.p1.10.m2.1.1.3" xref="S4.SS2.p1.10.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m2.1b"><apply id="S4.SS2.p1.10.m2.1.1.cmml" xref="S4.SS2.p1.10.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.10.m2.1.1.1.cmml" xref="S4.SS2.p1.10.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.10.m2.1.1.2.cmml" xref="S4.SS2.p1.10.m2.1.1.2">ğ‘¦</ci><ci id="S4.SS2.p1.10.m2.1.1.3.cmml" xref="S4.SS2.p1.10.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m2.1c">{y}_{i}</annotation></semantics></math> are one-dimensional vectors obtained by flattening the ground-truth heatmap and the interpolated heatmap of the predicted values resized to 224Ã—224 size, respectively.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The rest retains the original model structure.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiment</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we will present the experimental results of parameter tuning and SemiPL, analyze their strengths and weaknesses, and discuss potential improvements.</p>
</div>
<section id="S5.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation Metric.</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We follow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>and use consensus-IoU (cIoU@0.5), whereby the score of each pixel is computed based on the consensus of multiple annotations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, as well as Area Under the Curve (AUC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> for Event Sound Source Localization (ESSL).</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.2" class="ltx_p">Considering that the annotations provided by the dataset are based on bounding boxes of images sized 328Ã—120, we will first convert the bounding box annotations to size 224Ã—224. Then, we will convert the bounding box annotations into binary maps <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="\left\{gt_{i}\right\}_{i=1}^{N}" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><msubsup id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mrow id="S5.SS1.p2.1.m1.1.1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.1.2.cmml"><mo id="S5.SS1.p2.1.m1.1.1.1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.1.1.2.cmml">{</mo><mrow id="S5.SS1.p2.1.m1.1.1.1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="S5.SS1.p2.1.m1.1.1.1.1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p2.1.m1.1.1.1.1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml">â€‹</mo><msub id="S5.SS1.p2.1.m1.1.1.1.1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.cmml"><mi id="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.2" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.2.cmml">t</mi><mi id="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.3" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.SS1.p2.1.m1.1.1.1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S5.SS1.p2.1.m1.1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.1.3.cmml"><mi id="S5.SS1.p2.1.m1.1.1.1.3.2" xref="S5.SS1.p2.1.m1.1.1.1.3.2.cmml">i</mi><mo id="S5.SS1.p2.1.m1.1.1.1.3.1" xref="S5.SS1.p2.1.m1.1.1.1.3.1.cmml">=</mo><mn id="S5.SS1.p2.1.m1.1.1.1.3.3" xref="S5.SS1.p2.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">N</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1">superscript</csymbol><apply id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1">subscript</csymbol><set id="S5.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1.1"><apply id="S5.SS1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1"><times id="S5.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.1"></times><ci id="S5.SS1.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.2">ğ‘”</ci><apply id="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.2">ğ‘¡</ci><ci id="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S5.SS1.p2.1.m1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></set><apply id="S5.SS1.p2.1.m1.1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.1.3"><eq id="S5.SS1.p2.1.m1.1.1.1.3.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1.3.1"></eq><ci id="S5.SS1.p2.1.m1.1.1.1.3.2.cmml" xref="S5.SS1.p2.1.m1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S5.SS1.p2.1.m1.1.1.1.3.3.cmml" xref="S5.SS1.p2.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">\left\{gt_{i}\right\}_{i=1}^{N}</annotation></semantics></math>, where N is the number of subjects. Infer maps <math id="S5.SS1.p2.2.m2.1" class="ltx_Math" alttext="\left\{infer_{i}\right\}_{i=1}^{N}" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><msubsup id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml"><mrow id="S5.SS1.p2.2.m2.1.1.1.1.1" xref="S5.SS1.p2.2.m2.1.1.1.1.2.cmml"><mo id="S5.SS1.p2.2.m2.1.1.1.1.1.2" xref="S5.SS1.p2.2.m2.1.1.1.1.2.cmml">{</mo><mrow id="S5.SS1.p2.2.m2.1.1.1.1.1.1" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.cmml"><mi id="S5.SS1.p2.2.m2.1.1.1.1.1.1.2" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p2.2.m2.1.1.1.1.1.1.1" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS1.p2.2.m2.1.1.1.1.1.1.3" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p2.2.m2.1.1.1.1.1.1.1a" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS1.p2.2.m2.1.1.1.1.1.1.4" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p2.2.m2.1.1.1.1.1.1.1b" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.SS1.p2.2.m2.1.1.1.1.1.1.5" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p2.2.m2.1.1.1.1.1.1.1c" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.1.cmml">â€‹</mo><msub id="S5.SS1.p2.2.m2.1.1.1.1.1.1.6" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.cmml"><mi id="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.2" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.2.cmml">r</mi><mi id="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.3" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.3.cmml">i</mi></msub></mrow><mo id="S5.SS1.p2.2.m2.1.1.1.1.1.3" xref="S5.SS1.p2.2.m2.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S5.SS1.p2.2.m2.1.1.1.3" xref="S5.SS1.p2.2.m2.1.1.1.3.cmml"><mi id="S5.SS1.p2.2.m2.1.1.1.3.2" xref="S5.SS1.p2.2.m2.1.1.1.3.2.cmml">i</mi><mo id="S5.SS1.p2.2.m2.1.1.1.3.1" xref="S5.SS1.p2.2.m2.1.1.1.3.1.cmml">=</mo><mn id="S5.SS1.p2.2.m2.1.1.1.3.3" xref="S5.SS1.p2.2.m2.1.1.1.3.3.cmml">1</mn></mrow><mi id="S5.SS1.p2.2.m2.1.1.3" xref="S5.SS1.p2.2.m2.1.1.3.cmml">N</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><apply id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1">superscript</csymbol><apply id="S5.SS1.p2.2.m2.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.1.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1">subscript</csymbol><set id="S5.SS1.p2.2.m2.1.1.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1"><apply id="S5.SS1.p2.2.m2.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1"><times id="S5.SS1.p2.2.m2.1.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.1"></times><ci id="S5.SS1.p2.2.m2.1.1.1.1.1.1.2.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.2">ğ‘–</ci><ci id="S5.SS1.p2.2.m2.1.1.1.1.1.1.3.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.3">ğ‘›</ci><ci id="S5.SS1.p2.2.m2.1.1.1.1.1.1.4.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.4">ğ‘“</ci><ci id="S5.SS1.p2.2.m2.1.1.1.1.1.1.5.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.5">ğ‘’</ci><apply id="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.6"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.1.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.6">subscript</csymbol><ci id="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.2.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.2">ğ‘Ÿ</ci><ci id="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.3.cmml" xref="S5.SS1.p2.2.m2.1.1.1.1.1.1.6.3">ğ‘–</ci></apply></apply></set><apply id="S5.SS1.p2.2.m2.1.1.1.3.cmml" xref="S5.SS1.p2.2.m2.1.1.1.3"><eq id="S5.SS1.p2.2.m2.1.1.1.3.1.cmml" xref="S5.SS1.p2.2.m2.1.1.1.3.1"></eq><ci id="S5.SS1.p2.2.m2.1.1.1.3.2.cmml" xref="S5.SS1.p2.2.m2.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S5.SS1.p2.2.m2.1.1.1.3.3.cmml" xref="S5.SS1.p2.2.m2.1.1.1.3.3">1</cn></apply></apply><ci id="S5.SS1.p2.2.m2.1.1.3.cmml" xref="S5.SS1.p2.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">\left\{infer_{i}\right\}_{i=1}^{N}</annotation></semantics></math> are binary maps of prediction maps, we use 0.5 for the cIoU threshold in the experiments, cIoUâ€™s formula is:</p>
<table id="S7.EGx5" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S5.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S5.E5.m1.1" class="ltx_math_unparsed" alttext="\displaystyle\text{cIoU}=\frac{\sum_{i=1}^{N}\text{infer}_{i}\cap\text{gt}_{i}}{\sum_{i=1}^{N}\left[\text{gt}_{i}+\text{infer}_{i}\cup(\text{gt}_{i}==0)\right]}" display="inline"><semantics id="S5.E5.m1.1a"><mrow id="S5.E5.m1.1.1"><mtext id="S5.E5.m1.1.1.2">cIoU</mtext><mo id="S5.E5.m1.1.1.1">=</mo><mstyle displaystyle="true" id="S5.E5.m1.1.1.3"><mfrac id="S5.E5.m1.1.1.3a"><mrow id="S5.E5.m1.1.1.3.2"><mrow id="S5.E5.m1.1.1.3.2.2"><msubsup id="S5.E5.m1.1.1.3.2.2.1"><mo id="S5.E5.m1.1.1.3.2.2.1.2.2">âˆ‘</mo><mrow id="S5.E5.m1.1.1.3.2.2.1.2.3"><mi id="S5.E5.m1.1.1.3.2.2.1.2.3.2">i</mi><mo id="S5.E5.m1.1.1.3.2.2.1.2.3.1">=</mo><mn id="S5.E5.m1.1.1.3.2.2.1.2.3.3">1</mn></mrow><mi id="S5.E5.m1.1.1.3.2.2.1.3">N</mi></msubsup><msub id="S5.E5.m1.1.1.3.2.2.2"><mtext id="S5.E5.m1.1.1.3.2.2.2.2">infer</mtext><mi id="S5.E5.m1.1.1.3.2.2.2.3">i</mi></msub></mrow><mo id="S5.E5.m1.1.1.3.2.1">âˆ©</mo><msub id="S5.E5.m1.1.1.3.2.3"><mtext id="S5.E5.m1.1.1.3.2.3.2">gt</mtext><mi id="S5.E5.m1.1.1.3.2.3.3">i</mi></msub></mrow><mrow id="S5.E5.m1.1.1.3.3"><msubsup id="S5.E5.m1.1.1.3.3.1"><mo id="S5.E5.m1.1.1.3.3.1.2.2">âˆ‘</mo><mrow id="S5.E5.m1.1.1.3.3.1.2.3"><mi id="S5.E5.m1.1.1.3.3.1.2.3.2">i</mi><mo id="S5.E5.m1.1.1.3.3.1.2.3.1">=</mo><mn id="S5.E5.m1.1.1.3.3.1.2.3.3">1</mn></mrow><mi id="S5.E5.m1.1.1.3.3.1.3">N</mi></msubsup><mrow id="S5.E5.m1.1.1.3.3.2"><mo lspace="0em" id="S5.E5.m1.1.1.3.3.2.1">[</mo><msub id="S5.E5.m1.1.1.3.3.2.2"><mtext id="S5.E5.m1.1.1.3.3.2.2.2">gt</mtext><mi id="S5.E5.m1.1.1.3.3.2.2.3">i</mi></msub><mo id="S5.E5.m1.1.1.3.3.2.3">+</mo><msub id="S5.E5.m1.1.1.3.3.2.4"><mtext id="S5.E5.m1.1.1.3.3.2.4.2">infer</mtext><mi id="S5.E5.m1.1.1.3.3.2.4.3">i</mi></msub><mo id="S5.E5.m1.1.1.3.3.2.5">âˆª</mo><mrow id="S5.E5.m1.1.1.3.3.2.6"><mo stretchy="false" id="S5.E5.m1.1.1.3.3.2.6.1">(</mo><msub id="S5.E5.m1.1.1.3.3.2.6.2"><mtext id="S5.E5.m1.1.1.3.3.2.6.2.2">gt</mtext><mi id="S5.E5.m1.1.1.3.3.2.6.2.3">i</mi></msub><mo rspace="0em" id="S5.E5.m1.1.1.3.3.2.6.3">=</mo><mo lspace="0em" id="S5.E5.m1.1.1.3.3.2.6.4">=</mo><mn id="S5.E5.m1.1.1.3.3.2.6.5">0</mn><mo stretchy="false" id="S5.E5.m1.1.1.3.3.2.6.6">)</mo></mrow><mo id="S5.E5.m1.1.1.3.3.2.7">]</mo></mrow></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex" id="S5.E5.m1.1b">\displaystyle\text{cIoU}=\frac{\sum_{i=1}^{N}\text{infer}_{i}\cap\text{gt}_{i}}{\sum_{i=1}^{N}\left[\text{gt}_{i}+\text{infer}_{i}\cup(\text{gt}_{i}==0)\right]}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<table id="S7.EGx6" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S5.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S5.E6.m1.1" class="ltx_Math" alttext="\displaystyle\text{infer}_{i}\cap\text{gt}_{i}=\left(\text{infer}_{i}\times\text{gt}_{i}\right)" display="inline"><semantics id="S5.E6.m1.1a"><mrow id="S5.E6.m1.1.1" xref="S5.E6.m1.1.1.cmml"><mrow id="S5.E6.m1.1.1.3" xref="S5.E6.m1.1.1.3.cmml"><msub id="S5.E6.m1.1.1.3.2" xref="S5.E6.m1.1.1.3.2.cmml"><mtext id="S5.E6.m1.1.1.3.2.2" xref="S5.E6.m1.1.1.3.2.2a.cmml">infer</mtext><mi id="S5.E6.m1.1.1.3.2.3" xref="S5.E6.m1.1.1.3.2.3.cmml">i</mi></msub><mo id="S5.E6.m1.1.1.3.1" xref="S5.E6.m1.1.1.3.1.cmml">âˆ©</mo><msub id="S5.E6.m1.1.1.3.3" xref="S5.E6.m1.1.1.3.3.cmml"><mtext id="S5.E6.m1.1.1.3.3.2" xref="S5.E6.m1.1.1.3.3.2a.cmml">gt</mtext><mi id="S5.E6.m1.1.1.3.3.3" xref="S5.E6.m1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo id="S5.E6.m1.1.1.2" xref="S5.E6.m1.1.1.2.cmml">=</mo><mrow id="S5.E6.m1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.cmml"><mo id="S5.E6.m1.1.1.1.1.2" xref="S5.E6.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E6.m1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.cmml"><msub id="S5.E6.m1.1.1.1.1.1.2" xref="S5.E6.m1.1.1.1.1.1.2.cmml"><mtext id="S5.E6.m1.1.1.1.1.1.2.2" xref="S5.E6.m1.1.1.1.1.1.2.2a.cmml">infer</mtext><mi id="S5.E6.m1.1.1.1.1.1.2.3" xref="S5.E6.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S5.E6.m1.1.1.1.1.1.1" xref="S5.E6.m1.1.1.1.1.1.1.cmml">Ã—</mo><msub id="S5.E6.m1.1.1.1.1.1.3" xref="S5.E6.m1.1.1.1.1.1.3.cmml"><mtext id="S5.E6.m1.1.1.1.1.1.3.2" xref="S5.E6.m1.1.1.1.1.1.3.2a.cmml">gt</mtext><mi id="S5.E6.m1.1.1.1.1.1.3.3" xref="S5.E6.m1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.E6.m1.1.1.1.1.3" xref="S5.E6.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E6.m1.1b"><apply id="S5.E6.m1.1.1.cmml" xref="S5.E6.m1.1.1"><eq id="S5.E6.m1.1.1.2.cmml" xref="S5.E6.m1.1.1.2"></eq><apply id="S5.E6.m1.1.1.3.cmml" xref="S5.E6.m1.1.1.3"><intersect id="S5.E6.m1.1.1.3.1.cmml" xref="S5.E6.m1.1.1.3.1"></intersect><apply id="S5.E6.m1.1.1.3.2.cmml" xref="S5.E6.m1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.3.2.1.cmml" xref="S5.E6.m1.1.1.3.2">subscript</csymbol><ci id="S5.E6.m1.1.1.3.2.2a.cmml" xref="S5.E6.m1.1.1.3.2.2"><mtext id="S5.E6.m1.1.1.3.2.2.cmml" xref="S5.E6.m1.1.1.3.2.2">infer</mtext></ci><ci id="S5.E6.m1.1.1.3.2.3.cmml" xref="S5.E6.m1.1.1.3.2.3">ğ‘–</ci></apply><apply id="S5.E6.m1.1.1.3.3.cmml" xref="S5.E6.m1.1.1.3.3"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.3.3.1.cmml" xref="S5.E6.m1.1.1.3.3">subscript</csymbol><ci id="S5.E6.m1.1.1.3.3.2a.cmml" xref="S5.E6.m1.1.1.3.3.2"><mtext id="S5.E6.m1.1.1.3.3.2.cmml" xref="S5.E6.m1.1.1.3.3.2">gt</mtext></ci><ci id="S5.E6.m1.1.1.3.3.3.cmml" xref="S5.E6.m1.1.1.3.3.3">ğ‘–</ci></apply></apply><apply id="S5.E6.m1.1.1.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1"><times id="S5.E6.m1.1.1.1.1.1.1.cmml" xref="S5.E6.m1.1.1.1.1.1.1"></times><apply id="S5.E6.m1.1.1.1.1.1.2.cmml" xref="S5.E6.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.1.2.1.cmml" xref="S5.E6.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.1.2.2a.cmml" xref="S5.E6.m1.1.1.1.1.1.2.2"><mtext id="S5.E6.m1.1.1.1.1.1.2.2.cmml" xref="S5.E6.m1.1.1.1.1.1.2.2">infer</mtext></ci><ci id="S5.E6.m1.1.1.1.1.1.2.3.cmml" xref="S5.E6.m1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S5.E6.m1.1.1.1.1.1.3.cmml" xref="S5.E6.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E6.m1.1.1.1.1.1.3.1.cmml" xref="S5.E6.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E6.m1.1.1.1.1.1.3.2a.cmml" xref="S5.E6.m1.1.1.1.1.1.3.2"><mtext id="S5.E6.m1.1.1.1.1.1.3.2.cmml" xref="S5.E6.m1.1.1.1.1.1.3.2">gt</mtext></ci><ci id="S5.E6.m1.1.1.1.1.1.3.3.cmml" xref="S5.E6.m1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E6.m1.1c">\displaystyle\text{infer}_{i}\cap\text{gt}_{i}=\left(\text{infer}_{i}\times\text{gt}_{i}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<table id="S7.EGx7" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S5.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S5.E7.m1.1" class="ltx_math_unparsed" alttext="\displaystyle\text{infer}_{i}\cup(\text{gt}_{i}==0)=\left(\text{infer}_{i}\times(\text{gt}_{i}==0)\right)" display="inline"><semantics id="S5.E7.m1.1a"><mrow id="S5.E7.m1.1b"><msub id="S5.E7.m1.1.1"><mtext id="S5.E7.m1.1.1.2">infer</mtext><mi id="S5.E7.m1.1.1.3">i</mi></msub><mo id="S5.E7.m1.1.2">âˆª</mo><mrow id="S5.E7.m1.1.3"><mo stretchy="false" id="S5.E7.m1.1.3.1">(</mo><msub id="S5.E7.m1.1.3.2"><mtext id="S5.E7.m1.1.3.2.2">gt</mtext><mi id="S5.E7.m1.1.3.2.3">i</mi></msub><mo rspace="0em" id="S5.E7.m1.1.3.3">=</mo><mo lspace="0em" id="S5.E7.m1.1.3.4">=</mo><mn id="S5.E7.m1.1.3.5">0</mn><mo stretchy="false" id="S5.E7.m1.1.3.6">)</mo></mrow><mo id="S5.E7.m1.1.4">=</mo><mrow id="S5.E7.m1.1.5"><mo id="S5.E7.m1.1.5.1">(</mo><msub id="S5.E7.m1.1.5.2"><mtext id="S5.E7.m1.1.5.2.2">infer</mtext><mi id="S5.E7.m1.1.5.2.3">i</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S5.E7.m1.1.5.3">Ã—</mo><mrow id="S5.E7.m1.1.5.4"><mo stretchy="false" id="S5.E7.m1.1.5.4.1">(</mo><msub id="S5.E7.m1.1.5.4.2"><mtext id="S5.E7.m1.1.5.4.2.2">gt</mtext><mi id="S5.E7.m1.1.5.4.2.3">i</mi></msub><mo rspace="0em" id="S5.E7.m1.1.5.4.3">=</mo><mo lspace="0em" id="S5.E7.m1.1.5.4.4">=</mo><mn id="S5.E7.m1.1.5.4.5">0</mn><mo stretchy="false" id="S5.E7.m1.1.5.4.6">)</mo></mrow><mo id="S5.E7.m1.1.5.5">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S5.E7.m1.1c">\displaystyle\text{infer}_{i}\cup(\text{gt}_{i}==0)=\left(\text{infer}_{i}\times(\text{gt}_{i}==0)\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S5.SS1.p2.3" class="ltx_p">Using the common practice in object detection, we use 0.5 for the cIoU threshold in the experiments.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Qualitative Results and Analysis.</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In qualitative comparisons, we mainly visualize the localization results in figure <a href="#S5.F3" title="Figure 3 â€£ 5.2 Qualitative Results and Analysis. â€£ 5 Experiment â€£ SemiPL: A Semi-supervised Method for Event Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and figure <a href="#S5.F4" title="Figure 4 â€£ 5.2 Qualitative Results and Analysis. â€£ 5 Experiment â€£ SemiPL: A Semi-supervised Method for Event Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">We observe that when the scene is complex, the model is prone to overlook target objects (e.g., the first and second rows in Figure 3), while when the scene is simple (e.g., the first, second, and third rows in Figure 4), the model can locate target objects well but cover unrelated background details (e.g., ground and trees). It is hypothesized that because most of the occurring objects in the dataset are people, the model did not learn the vocal characteristics of the rest of the vocal objects (e.g., drums) very well. The semi-supervised model may have been disturbed by the data where some of the vocalized objects were not people, and the training effect was instead reduced.</p>
</div>
<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.1" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption">Annotations</figcaption><img src="/html/2404.19615/assets/image/ADCCAWWD_004398_annotation.png" id="S5.F3.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.2" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption">SSPL(w/ PCM)</figcaption><img src="/html/2404.19615/assets/image/ADCCAWWD_004398_w.png" id="S5.F3.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.19615/assets/image/ADCCAWWD_004398_annotation.png" id="S5.F3.3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F3.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.19615/assets/image/gt_ADCCAWWD_004398_w.png" id="S5.F3.4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.6.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig.Â 3</span>: </span><span id="S5.F3.7.2" class="ltx_text" style="font-size:90%;">The first row is the self-supervised model, and the second row is the semi-supervised model SemiPL. It can be seen that self-supervised model has a somewhat larger recognition area for vocalized objects.</span></figcaption>
</figure>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Similarly, the model tends to underestimate or overestimate the extent of the sound-emitting object, as evident in the first and second rows of Figure 2. This may be because positive and negative regions in different images cannot be easily distinguished using the same threshold parameter.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">In contrast, the SSPL method can cover the regions of interest, and the use of PCM (possibly referring to a specific technique or method) further helps reduce the influence of background noise, resulting in more accurate localization.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.1" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption">Annotations</figcaption><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_annotation.png" id="S5.F4.1.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.2" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption">SSPL(w/o PCM)</figcaption><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_wo_64.png" id="S5.F4.2.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.3" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption">SSPL(w/ PCM)</figcaption><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_w_64.png" id="S5.F4.3.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_annotation.png" id="S5.F4.4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_wo_3.png" id="S5.F4.5.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_w_3.png" id="S5.F4.6.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_annotation.png" id="S5.F4.7.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_wo.png" id="S5.F4.8.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F4.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.19615/assets/image/AJJFTGGI_000233_w.png" id="S5.F4.9.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.11.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig.Â 4</span>: </span><span id="S5.F4.12.2" class="ltx_text" style="font-size:90%;">The first row is batch size 64, learning rate 5e-5, The second row is batch size 128, learning rate 3e-5,
The third row is batch size 128, learning rate 5e-5,</span></figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Quantitative Results and Analysis.</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Table <a href="#S5.T1" title="Table 1 â€£ 5.3 Quantitative Results and Analysis. â€£ 5 Experiment â€£ SemiPL: A Semi-supervised Method for Event Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows results using different parameters, the best outcome is observed when batch size = 128. Larger batch size improves memory utilization as well as parallelization efficiency for large matrix multiplications, requires fewer iterations to run through an epoch (the full dataset), and is processed faster than a smaller batch size for the same amount of data. Within a certain range, generally speaking, the larger the batch size is, the more accurate the direction of descent it determines, and the less training oscillations it causes.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Table 1</span>: </span><span id="S5.T1.3.2" class="ltx_text" style="font-size:90%;">Results of Parameter Adjustments</span></figcaption>
<table id="S5.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.4.1.1" class="ltx_tr">
<th id="S5.T1.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">Method</th>
<th id="S5.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">bz</th>
<th id="S5.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">lr</th>
<th id="S5.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">cIoU</th>
<th id="S5.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">AUC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.4.2.1" class="ltx_tr">
<th id="S5.T1.4.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">SSPL(Unsupervised)</th>
<th id="S5.T1.4.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">128</th>
<td id="S5.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t">3e-5</td>
<td id="S5.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t">41.02</td>
<td id="S5.T1.4.2.1.5" class="ltx_td ltx_align_center ltx_border_t">42.23</td>
</tr>
<tr id="S5.T1.4.3.2" class="ltx_tr">
<th id="S5.T1.4.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">SSPL(Unsupervised)</th>
<th id="S5.T1.4.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">64</th>
<td id="S5.T1.4.3.2.3" class="ltx_td ltx_align_center">5e-5</td>
<td id="S5.T1.4.3.2.4" class="ltx_td ltx_align_center">42.03</td>
<td id="S5.T1.4.3.2.5" class="ltx_td ltx_align_center">43.38</td>
</tr>
<tr id="S5.T1.4.4.3" class="ltx_tr">
<th id="S5.T1.4.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b">SSPL(Unsupervised)</th>
<th id="S5.T1.4.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b">128</th>
<td id="S5.T1.4.4.3.3" class="ltx_td ltx_align_center ltx_border_b">5e-5</td>
<td id="S5.T1.4.4.3.4" class="ltx_td ltx_align_center ltx_border_b">47.70</td>
<td id="S5.T1.4.4.3.5" class="ltx_td ltx_align_center ltx_border_b">44.14</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">As depicted in Figure <a href="#S5.F5" title="Figure 5 â€£ 5.3 Quantitative Results and Analysis. â€£ 5 Experiment â€£ SemiPL: A Semi-supervised Method for Event Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, when examining the impact of varying learning rates on the training process, a noticeable trend emerges. Decreasing the learning rate appears to mitigate the fluctuations in accuracy throughout the training epochs. However, this seemingly beneficial effect comes at a cost: a significant reduction in the convergence speed of the model. In practical terms, this slowdown in convergence renders the training process prohibitively slow, thereby undermining the overall efficacy of the learning algorithm. Consequently, striking a balance between stability and speed becomes paramount in optimizing the learning rate for the given task or model architecture.</p>
</div>
<figure id="S5.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F5.1" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption">learning rate = 3e-5</figcaption><img src="/html/2404.19615/assets/image/ciou_auc_3e-5.png" id="S5.F5.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F5.2" class="ltx_figure ltx_figure_panel ltx_align_center">
<figcaption class="ltx_caption">learning rate = 5e-5</figcaption><img src="/html/2404.19615/assets/image/ciou_auc_5e-5.png" id="S5.F5.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F5.4.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Fig.Â 5</span>: </span><span id="S5.F5.5.2" class="ltx_text" style="font-size:90%;">Different learning rate parameter results. The top learning rate is 3e-5, the bottom learning rate is 5e-5.</span></figcaption>
</figure>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.3.2" class="ltx_text" style="font-size:90%;">Results of different kinds of supervision</span></figcaption>
<table id="S5.T2.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.4.1.1" class="ltx_tr">
<th id="S5.T2.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Methods</th>
<th id="S5.T2.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">cIoU</th>
<th id="S5.T2.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">AUC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.4.2.1" class="ltx_tr">
<td id="S5.T2.4.2.1.1" class="ltx_td ltx_align_center ltx_border_t">LSS(Unsupervised)</td>
<td id="S5.T2.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t">23.85</td>
<td id="S5.T2.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t">36.56</td>
</tr>
<tr id="S5.T2.4.3.2" class="ltx_tr">
<td id="S5.T2.4.3.2.1" class="ltx_td ltx_align_center">SemiPL(Semi-supervised)</td>
<td id="S5.T2.4.3.2.2" class="ltx_td ltx_align_center">36.84</td>
<td id="S5.T2.4.3.2.3" class="ltx_td ltx_align_center">41.86</td>
</tr>
<tr id="S5.T2.4.4.3" class="ltx_tr">
<td id="S5.T2.4.4.3.1" class="ltx_td ltx_align_center ltx_border_b">SSPL(Unsupervised)</td>
<td id="S5.T2.4.4.3.2" class="ltx_td ltx_align_center ltx_border_b">47.70</td>
<td id="S5.T2.4.4.3.3" class="ltx_td ltx_align_center ltx_border_b">44.14</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">The performance of our SemiPL, while promising, is not quite on par with that of self-supervised models. One potential reason for this could be the relatively large bounding box range used during training. This extensive range may have interfered with the modelâ€™s ability to learn precise localization, as it introduced too much noise and irrelevant information into the learning process. This hypothesis suggests that refining the bounding box or exploring new data annotation strategies may improve the performance of semi-supervised learning models. Future research in this area is expected to provide valuable insights and advances in the overall development of semi-supervised learning.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this study, we implemented the Self-Supervised Predictive Learning method (SSPL) and our novel Semi-supervised Predictive Learning approach, SemiPL, on the Chaotic World dataset. Our primary objective was to elevate the accuracy of visual-audio localization by explicitly mining positive correspondences. To achieve this, we utilized a tri-stream network coupled with a strategic training regimen to establish the relationship between audio signals and their corresponding video frames within the same video clip. Although SSPL proved effective in single-source audio localization tasks, it fell short in multi-source scenarios primarily due to the limited size of the dataset. Despite this limitation, the expanding availability of data and the escalating importance of label quality indicate that self-supervised learning is destined to become a prevailing trend in machine learning. A potential solution is to develop a fully supervised approach to multi-source localization tasks, which we leave for future work.</p>
</div>
</section>
<section id="S7" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgement</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This work was supported by National Natural Science Foundation of China (No. 62203476), Natural Science Foundation of Shenzhen (No. JCYJ20230807120801002).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
WilliamÂ W Gaver,

</span>
<span class="ltx_bibblock">â€œWhat in the world do we hear?: An ecological approach to auditory event perception,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Ecological psychology</span>, vol. 5, no. 1, pp. 1â€“29, 1993.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Francesca Frassinetti, Nadia Bolognini, and Elisabetta LÃ davas,

</span>
<span class="ltx_bibblock">â€œEnhancement of visual perception by crossmodal visuo-auditory interaction,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Experimental brain research</span>, vol. 147, pp. 332â€“343, 2002.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
John Hershey and Javier Movellan,

</span>
<span class="ltx_bibblock">â€œAudio vision: Using audio-visual synchrony to locate sounds,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, vol. 12, 1999.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
JesperÂ E VanÂ Engelen and HolgerÂ H Hoos,

</span>
<span class="ltx_bibblock">â€œA survey on semi-supervised learning,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Machine learning</span>, vol. 109, no. 2, pp. 373â€“440, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Arda Senocak, Tae-Hyun Oh, Junsik Kim, Ming-Hsuan Yang, and InÂ So Kweon,

</span>
<span class="ltx_bibblock">â€œLearning to localize sound source in visual scenes,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2018, pp. 4358â€“4366.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Rui Qian, DiÂ Hu, Heinrich Dinkel, Mengyue Wu, Ning Xu, and Weiyao Lin,

</span>
<span class="ltx_bibblock">â€œMultiple sound sources localization from coarse to fine,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Proceedings of the European Conference on Computer Vision (ECCV)</span>, 2020, pp. 292â€“308.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Jure Zbontar, LiÂ Jing, Ishan Misra, Yann LeCun, and StÃ©phane Deny,

</span>
<span class="ltx_bibblock">â€œBarlow twins: Self-supervised learning via redundancy reduction,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Proceedings of the International conference on machine learning (ICML)</span>, 2021, pp. 12310â€“12320.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Aleksandr Ermolov, Aliaksandr Siarohin, Enver Sangineto, and Nicu Sebe,

</span>
<span class="ltx_bibblock">â€œWhitening for self-supervised representation learning,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Proceedings of the International conference on machine learning (ICML)</span>. PMLR, 2021, pp. 3015â€“3024.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Jean-Bastien Grill, Florian Strub, Florent AltchÃ©, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo AvilaÂ Pires, Zhaohan Guo, Mohammad GheshlaghiÂ Azar, etÂ al.,

</span>
<span class="ltx_bibblock">â€œBootstrap your own latent-a new approach to self-supervised learning,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, vol. 33, pp. 21271â€“21284, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Yusuf Aytar, Carl Vondrick, and Antonio Torralba,

</span>
<span class="ltx_bibblock">â€œSoundnet: Learning sound representations from unlabeled video,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv: Computer Vision and Pattern Recognition,arXiv: Computer Vision and Pattern Recognition</span>, Oct 2016.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Bruno Korbar, DuÂ Tran, and Lorenzo Torresani,

</span>
<span class="ltx_bibblock">â€œCooperative learning of audio and video models from self-supervised synchronization,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv: Computer Vision and Pattern Recognition,arXiv: Computer Vision and Pattern Recognition</span>, Jun 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Andrew Owens, Jiajun Wu, JoshH. McDermott, WilliamT. Freeman, and Antonio Torralba,

</span>
<span class="ltx_bibblock">â€œAmbient sound provides supervision for visual learning,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">arXiv: Computer Vision and Pattern Recognition,arXiv: Computer Vision and Pattern Recognition</span>, Aug 2016.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Zengjie Song, Yuxi Wang, Junsong Fan, Tieniu Tan, and Zhaoxiang Zhang,

</span>
<span class="ltx_bibblock">â€œSelf-supervised predictive learning: A negative-free method for sound source localization in visual scenes,â€ 2022.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Yusuf Aytar, Carl Vondrick, and Antonio Torralba,

</span>
<span class="ltx_bibblock">â€œSoundnet: Learning sound representations from unlabeled video,â€ 2016.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Honglie Chen, Weidi Xie, Andrea Vedaldi, and Andrew Zisserman,

</span>
<span class="ltx_bibblock">â€œVggsound: A large-scale audio-visual dataset,â€ 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Mengyuan Liu, Fanyang Meng, Chen Chen, and Songtao Wu,

</span>
<span class="ltx_bibblock">â€œNovel motion patterns matter for practical skeleton-based action recognition,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</span>, 2023, pp. 1701â€“1709.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Jinfu Liu, Xinshun Wang, Can Wang, Yuan Gao, and Mengyuan Liu,

</span>
<span class="ltx_bibblock">â€œTemporal decoupling graph convolutional network for skeleton-based gesture recognition,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Multimedia</span>, pp. 1â€“13, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Jinfu Liu, Runwei Ding, Yuhang Wen, Nan Dai, Fanyang Meng, Shen Zhao, and Mengyuan Liu,

</span>
<span class="ltx_bibblock">â€œExplore human parsing modality for action recognition,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">CAAI Transactions on Intelligence Technology</span>, 2024.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Yuhang Wen, Zixuan Tang, Yunsheng Pang, Beichen Ding, and Mengyuan Liu,

</span>
<span class="ltx_bibblock">â€œInteractive spatiotemporal token attention network for skeleton-based general interactive action recognition,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS)</span>, 2023, pp. 7886â€“7892.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
KianÂ Eng Ong, XunÂ Long Ng, Yanchao Li, Wenjie Ai, Kuangyi Zhao, SiÂ Yong Yeo, and Jun Liu,

</span>
<span class="ltx_bibblock">â€œChaotic world: A large and challenging benchmark for human behavior understanding in chaotic events,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">2023 IEEE/CVF International Conference on Computer Vision (ICCV)</span>, 2023, pp. 20156â€“20166.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Xiaohua Zhai, Avital Oliver, Alexander Kolesnikov, and Lucas Beyer,

</span>
<span class="ltx_bibblock">â€œS4l: Self-supervised semi-supervised learning,â€ 2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Arda Senocak, Tae-Hyun Oh, Junsik Kim, Ming-Hsuan Yang, and InÂ So Kweon,

</span>
<span class="ltx_bibblock">â€œLearning to localize sound source in visual scenes,â€ 2018.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.19614" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.19615" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.19615">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.19615" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.19616" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 20:58:07 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
