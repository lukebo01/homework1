<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.11915] Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound</title><meta property="og:description" content="Foley sound synthesis is crucial for multimedia production, enhancing user experience by synchronizing audio and video both temporally and semantically.
Recent studies on automating this labor-intensive process through…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.11915">

<!--Generated on Thu Sep  5 12:10:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Video-Foley: Two-Stage Video-To-Sound Generation 
<br class="ltx_break">via Temporal Event Condition For Foley Sound</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text" style="font-size:90%;">Foley sound synthesis is crucial for multimedia production, enhancing user experience by synchronizing audio and video both temporally and semantically.
Recent studies on automating this labor-intensive process through video-to-sound generation face significant challenges. Systems lacking explicit temporal features suffer from poor controllability and alignment, while timestamp-based models require costly and subjective human annotation.
We propose <span id="id1.id1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Video-Foley</span>, a video-to-sound system using Root Mean Square (RMS) as a temporal event condition with semantic timbre prompts (audio or text). RMS, a frame-level intensity envelope feature closely related to audio semantics, ensures high controllability and synchronization. The annotation-free self-supervised learning framework consists of two stages, Video2RMS and RMS2Sound, incorporating novel ideas including RMS discretization and RMS-ControlNet with a pretrained text-to-audio model. Our extensive evaluation shows that Video-Foley achieves state-of-the-art performance in audio-visual alignment and controllability for sound timing, intensity, timbre, and nuance. Code, model weights, and demonstrations are available on the accompanying website.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnote1.1.1.1" class="ltx_text" style="font-size:111%;">1</span></span><a target="_blank" href="https://jnwnlee.github.io/video-foley-demo" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:111%;">https://jnwnlee.github.io/video-foley-demo</a></span></span></span></span></p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:90%;">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— <span id="p1.1.1.1.1" class="ltx_text ltx_font_medium">
Video-to-Sound, Controllable Audio Generation, Multimodal Deep Learning</span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text" style="font-size:90%;">Foley sound plays an important role in enhancing immersive experiences by providing synchronized audio with visual content in film, gaming, and VR environments. However, creating sounds that precisely match the timing, intensity, timbre, and nuance of the visual objects is labor-intensive, highlighting the need for automation or assistance </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib1" title="" class="ltx_ref">1</a><span id="S1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.4" class="ltx_text" style="font-size:90%;">. Recent advances in generative AI have encouraged researchers to explore models that learn the cross-modal correspondence and synthesize audio content from the video input.</span></p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text" style="font-size:90%;">In the video-to-sound generation, achieving semantic and temporal synchronization between the two modalities is crucial. However, existing studies have not successfully accomplished this dual goal.
Early video-to-sound models, such as GAN-based methods </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S1.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.4" class="ltx_text" style="font-size:90%;">, aimed to generate audio from video input in an unsupervised manner. They focused on learning the semantic correspondence between audio and visual from datasets of in-the-wild-quality.
Subsequent work has proposed controllable video-to-sound generation models that allow for changing timbre with audio prompts </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S1.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.7" class="ltx_text" style="font-size:90%;"> or audio-visual correlations </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S1.p2.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.10" class="ltx_text" style="font-size:90%;">.
While these approaches showed promising results, they generally suffered from temporal misalignment and low audio quality due to a lack of explicit temporal guidance or low-quality data.</span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text" style="font-size:90%;">More recent studies have explicitly incorporated temporal information into their models. Diff-Foley </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S1.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.4" class="ltx_text" style="font-size:90%;"> utilized a temporal-aware audio-visual joint embedding space to condition the audio-generating diffusion model.
However, low visual temporal resolution (4fps) due to high computational costs limited the accuracy of temporal alignment.
Other approaches used onset/offset timestamps of sounds in a text from to guide audio generation </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S1.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.7" class="ltx_text" style="font-size:90%;">. They trained timestamp detection networks to classify each video frame via supervised learning. However, this method requires human-annotated data, which is costly and often ambiguous in defining a golden standard. Additionally, simply detecting the start and end points of sound events misses many important aspects of audio, such as the volume dynamics of a moving car, which are difficult to represent in text.</span></p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div id="S1.F1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:305.9pt;vertical-align:-0.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-372.9pt,292.0pt) scale(0.343509110613396,0.343509110613396) ;"><img src="/html/2408.11915/assets/Fig/model.png" id="S1.F1.1.g1" class="ltx_graphics ltx_img_landscape" width="1572" height="1231" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.5.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span>Overall pipeline of the proposed model, a two-stage Video-to-Sound generation framework. Note that RMS can be extracted from audio waveform numerically. Video2RMS and RMS2Sound part are trained separately.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text" style="font-size:90%;">We propose </span><span id="S1.p4.1.2" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:90%;">Video-Foley</span><span id="S1.p4.1.3" class="ltx_text" style="font-size:90%;">, a temporal-event-guided Video-To-Sound model for highly synchronized and controllable Foley sound generation (Fig. </span><a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S1.p4.1.4" class="ltx_text" style="font-size:90%;">). Our contributions are as follows:
1) We introduce the Root Mean Square (RMS) of audio content as a key temporal feature for audio-visual synchrony. Here, we define RMS as a frame-level energy feature calculated from an audio waveform. This captures not only the presence of sound events but also their intensity and temporal change,
deeply intertwined with subtle timbre and nuance</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S1.p4.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.7" class="ltx_text" style="font-size:90%;">. RMS-guided systems, along with audio or text prompts, ensure high temporal and semantic synchronization, providing enhanced controllability.
2) We propose a two-stage framework that predicts the RMS of audio waveforms from video (Video2RMS) and generates temporally aligned audio waveforms from the predicted RMS (RMS2Sound). Our model is efficiently trained with video-audio pairs (i.e., general video files) and audio-only data without human annotations, using novel techniques including RMS discretization and RMS-ControlNet leveraging a pretrained text-to-audio model.
3) Through quantitative evaluation, including human surveys, we demonstrate that Video-Foley achieves state-of-the-art performance in both temporal and semantic alignment on the Greatest Hits dataset. The subsequent qualitative analysis and accompanying demo highlight the high controllability in timing, intensity, timbre, and nuance of the audio.</span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Proposed Method</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.4" class="ltx_p"><span id="S2.p1.4.1" class="ltx_text" style="font-size:90%;">Video-Foley consists of two components, Video2RMS and RMS2Sound, which are trained separately in a self-supervised manner. Video2RMS predicts the RMS curve from video input, while RMS2Sound generates audio waveforms from the RMS curve along with semantic control with text/audio.
We defined RMS as a frame-level amplitude envelope feature of audio waveform defined as follows: for the i-th frame,</span></p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="R_{i}(x)=\sqrt{{1\over W}\Sigma_{t=ih}^{ih+W}x^{2}(t)}" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.3" xref="S2.E1.m1.2.3.cmml"><mrow id="S2.E1.m1.2.3.2" xref="S2.E1.m1.2.3.2.cmml"><msub id="S2.E1.m1.2.3.2.2" xref="S2.E1.m1.2.3.2.2.cmml"><mi mathsize="90%" id="S2.E1.m1.2.3.2.2.2" xref="S2.E1.m1.2.3.2.2.2.cmml">R</mi><mi mathsize="90%" id="S2.E1.m1.2.3.2.2.3" xref="S2.E1.m1.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.3.2.1" xref="S2.E1.m1.2.3.2.1.cmml">​</mo><mrow id="S2.E1.m1.2.3.2.3.2" xref="S2.E1.m1.2.3.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E1.m1.2.3.2.3.2.1" xref="S2.E1.m1.2.3.2.cmml">(</mo><mi mathsize="90%" id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">x</mi><mo maxsize="90%" minsize="90%" id="S2.E1.m1.2.3.2.3.2.2" xref="S2.E1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S2.E1.m1.2.3.1" xref="S2.E1.m1.2.3.1.cmml">=</mo><msqrt id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml"><mfrac id="S2.E1.m1.1.1.1.3" xref="S2.E1.m1.1.1.1.3.cmml"><mn mathsize="90%" id="S2.E1.m1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.3.2.cmml">1</mn><mi mathsize="90%" id="S2.E1.m1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.3.3.cmml">W</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.2.cmml">​</mo><msubsup id="S2.E1.m1.1.1.1.4" xref="S2.E1.m1.1.1.1.4.cmml"><mi mathsize="90%" mathvariant="normal" id="S2.E1.m1.1.1.1.4.2.2" xref="S2.E1.m1.1.1.1.4.2.2.cmml">Σ</mi><mrow id="S2.E1.m1.1.1.1.4.2.3" xref="S2.E1.m1.1.1.1.4.2.3.cmml"><mi mathsize="90%" id="S2.E1.m1.1.1.1.4.2.3.2" xref="S2.E1.m1.1.1.1.4.2.3.2.cmml">t</mi><mo mathsize="90%" id="S2.E1.m1.1.1.1.4.2.3.1" xref="S2.E1.m1.1.1.1.4.2.3.1.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.4.2.3.3" xref="S2.E1.m1.1.1.1.4.2.3.3.cmml"><mi mathsize="90%" id="S2.E1.m1.1.1.1.4.2.3.3.2" xref="S2.E1.m1.1.1.1.4.2.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.4.2.3.3.1" xref="S2.E1.m1.1.1.1.4.2.3.3.1.cmml">​</mo><mi mathsize="90%" id="S2.E1.m1.1.1.1.4.2.3.3.3" xref="S2.E1.m1.1.1.1.4.2.3.3.3.cmml">h</mi></mrow></mrow><mrow id="S2.E1.m1.1.1.1.4.3" xref="S2.E1.m1.1.1.1.4.3.cmml"><mrow id="S2.E1.m1.1.1.1.4.3.2" xref="S2.E1.m1.1.1.1.4.3.2.cmml"><mi mathsize="90%" id="S2.E1.m1.1.1.1.4.3.2.2" xref="S2.E1.m1.1.1.1.4.3.2.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.4.3.2.1" xref="S2.E1.m1.1.1.1.4.3.2.1.cmml">​</mo><mi mathsize="90%" id="S2.E1.m1.1.1.1.4.3.2.3" xref="S2.E1.m1.1.1.1.4.3.2.3.cmml">h</mi></mrow><mo mathsize="90%" id="S2.E1.m1.1.1.1.4.3.1" xref="S2.E1.m1.1.1.1.4.3.1.cmml">+</mo><mi mathsize="90%" id="S2.E1.m1.1.1.1.4.3.3" xref="S2.E1.m1.1.1.1.4.3.3.cmml">W</mi></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.2a" xref="S2.E1.m1.1.1.1.2.cmml">​</mo><msup id="S2.E1.m1.1.1.1.5" xref="S2.E1.m1.1.1.1.5.cmml"><mi mathsize="90%" id="S2.E1.m1.1.1.1.5.2" xref="S2.E1.m1.1.1.1.5.2.cmml">x</mi><mn mathsize="90%" id="S2.E1.m1.1.1.1.5.3" xref="S2.E1.m1.1.1.1.5.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.2b" xref="S2.E1.m1.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.1.1.1.6.2" xref="S2.E1.m1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E1.m1.1.1.1.6.2.1" xref="S2.E1.m1.1.1.1.cmml">(</mo><mi mathsize="90%" id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">t</mi><mo maxsize="90%" minsize="90%" id="S2.E1.m1.1.1.1.6.2.2" xref="S2.E1.m1.1.1.1.cmml">)</mo></mrow></mrow></msqrt></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.3.cmml" xref="S2.E1.m1.2.3"><eq id="S2.E1.m1.2.3.1.cmml" xref="S2.E1.m1.2.3.1"></eq><apply id="S2.E1.m1.2.3.2.cmml" xref="S2.E1.m1.2.3.2"><times id="S2.E1.m1.2.3.2.1.cmml" xref="S2.E1.m1.2.3.2.1"></times><apply id="S2.E1.m1.2.3.2.2.cmml" xref="S2.E1.m1.2.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.3.2.2.1.cmml" xref="S2.E1.m1.2.3.2.2">subscript</csymbol><ci id="S2.E1.m1.2.3.2.2.2.cmml" xref="S2.E1.m1.2.3.2.2.2">𝑅</ci><ci id="S2.E1.m1.2.3.2.2.3.cmml" xref="S2.E1.m1.2.3.2.2.3">𝑖</ci></apply><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝑥</ci></apply><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><root id="S2.E1.m1.1.1a.cmml" xref="S2.E1.m1.1.1"></root><apply id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><times id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.3"><divide id="S2.E1.m1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.3"></divide><cn type="integer" id="S2.E1.m1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.3.2">1</cn><ci id="S2.E1.m1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.3.3">𝑊</ci></apply><apply id="S2.E1.m1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.4.1.cmml" xref="S2.E1.m1.1.1.1.4">superscript</csymbol><apply id="S2.E1.m1.1.1.1.4.2.cmml" xref="S2.E1.m1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.4.2.1.cmml" xref="S2.E1.m1.1.1.1.4">subscript</csymbol><ci id="S2.E1.m1.1.1.1.4.2.2.cmml" xref="S2.E1.m1.1.1.1.4.2.2">Σ</ci><apply id="S2.E1.m1.1.1.1.4.2.3.cmml" xref="S2.E1.m1.1.1.1.4.2.3"><eq id="S2.E1.m1.1.1.1.4.2.3.1.cmml" xref="S2.E1.m1.1.1.1.4.2.3.1"></eq><ci id="S2.E1.m1.1.1.1.4.2.3.2.cmml" xref="S2.E1.m1.1.1.1.4.2.3.2">𝑡</ci><apply id="S2.E1.m1.1.1.1.4.2.3.3.cmml" xref="S2.E1.m1.1.1.1.4.2.3.3"><times id="S2.E1.m1.1.1.1.4.2.3.3.1.cmml" xref="S2.E1.m1.1.1.1.4.2.3.3.1"></times><ci id="S2.E1.m1.1.1.1.4.2.3.3.2.cmml" xref="S2.E1.m1.1.1.1.4.2.3.3.2">𝑖</ci><ci id="S2.E1.m1.1.1.1.4.2.3.3.3.cmml" xref="S2.E1.m1.1.1.1.4.2.3.3.3">ℎ</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.4.3.cmml" xref="S2.E1.m1.1.1.1.4.3"><plus id="S2.E1.m1.1.1.1.4.3.1.cmml" xref="S2.E1.m1.1.1.1.4.3.1"></plus><apply id="S2.E1.m1.1.1.1.4.3.2.cmml" xref="S2.E1.m1.1.1.1.4.3.2"><times id="S2.E1.m1.1.1.1.4.3.2.1.cmml" xref="S2.E1.m1.1.1.1.4.3.2.1"></times><ci id="S2.E1.m1.1.1.1.4.3.2.2.cmml" xref="S2.E1.m1.1.1.1.4.3.2.2">𝑖</ci><ci id="S2.E1.m1.1.1.1.4.3.2.3.cmml" xref="S2.E1.m1.1.1.1.4.3.2.3">ℎ</ci></apply><ci id="S2.E1.m1.1.1.1.4.3.3.cmml" xref="S2.E1.m1.1.1.1.4.3.3">𝑊</ci></apply></apply><apply id="S2.E1.m1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.5"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.5.1.cmml" xref="S2.E1.m1.1.1.1.5">superscript</csymbol><ci id="S2.E1.m1.1.1.1.5.2.cmml" xref="S2.E1.m1.1.1.1.5.2">𝑥</ci><cn type="integer" id="S2.E1.m1.1.1.1.5.3.cmml" xref="S2.E1.m1.1.1.1.5.3">2</cn></apply><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">R_{i}(x)=\sqrt{{1\over W}\Sigma_{t=ih}^{ih+W}x^{2}(t)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.p1.3" class="ltx_p"><span id="S2.p1.3.1" class="ltx_text" style="font-size:90%;">where </span><math id="S2.p1.1.m1.4" class="ltx_Math" alttext="x(t)\ (t\in[0,T])" display="inline"><semantics id="S2.p1.1.m1.4a"><mrow id="S2.p1.1.m1.4.4" xref="S2.p1.1.m1.4.4.cmml"><mi mathsize="90%" id="S2.p1.1.m1.4.4.3" xref="S2.p1.1.m1.4.4.3.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.p1.1.m1.4.4.2" xref="S2.p1.1.m1.4.4.2.cmml">​</mo><mrow id="S2.p1.1.m1.4.4.4.2" xref="S2.p1.1.m1.4.4.cmml"><mo maxsize="90%" minsize="90%" id="S2.p1.1.m1.4.4.4.2.1" xref="S2.p1.1.m1.4.4.cmml">(</mo><mi mathsize="90%" id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">t</mi><mo maxsize="90%" minsize="90%" id="S2.p1.1.m1.4.4.4.2.2" xref="S2.p1.1.m1.4.4.cmml">)</mo></mrow><mo lspace="0.450em" rspace="0em" id="S2.p1.1.m1.4.4.2a" xref="S2.p1.1.m1.4.4.2.cmml">​</mo><mrow id="S2.p1.1.m1.4.4.1.1" xref="S2.p1.1.m1.4.4.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.p1.1.m1.4.4.1.1.2" xref="S2.p1.1.m1.4.4.1.1.1.cmml">(</mo><mrow id="S2.p1.1.m1.4.4.1.1.1" xref="S2.p1.1.m1.4.4.1.1.1.cmml"><mi mathsize="90%" id="S2.p1.1.m1.4.4.1.1.1.2" xref="S2.p1.1.m1.4.4.1.1.1.2.cmml">t</mi><mo mathsize="90%" id="S2.p1.1.m1.4.4.1.1.1.1" xref="S2.p1.1.m1.4.4.1.1.1.1.cmml">∈</mo><mrow id="S2.p1.1.m1.4.4.1.1.1.3.2" xref="S2.p1.1.m1.4.4.1.1.1.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.p1.1.m1.4.4.1.1.1.3.2.1" xref="S2.p1.1.m1.4.4.1.1.1.3.1.cmml">[</mo><mn mathsize="90%" id="S2.p1.1.m1.2.2" xref="S2.p1.1.m1.2.2.cmml">0</mn><mo mathsize="90%" id="S2.p1.1.m1.4.4.1.1.1.3.2.2" xref="S2.p1.1.m1.4.4.1.1.1.3.1.cmml">,</mo><mi mathsize="90%" id="S2.p1.1.m1.3.3" xref="S2.p1.1.m1.3.3.cmml">T</mi><mo maxsize="90%" minsize="90%" id="S2.p1.1.m1.4.4.1.1.1.3.2.3" xref="S2.p1.1.m1.4.4.1.1.1.3.1.cmml">]</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="S2.p1.1.m1.4.4.1.1.3" xref="S2.p1.1.m1.4.4.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.4b"><apply id="S2.p1.1.m1.4.4.cmml" xref="S2.p1.1.m1.4.4"><times id="S2.p1.1.m1.4.4.2.cmml" xref="S2.p1.1.m1.4.4.2"></times><ci id="S2.p1.1.m1.4.4.3.cmml" xref="S2.p1.1.m1.4.4.3">𝑥</ci><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝑡</ci><apply id="S2.p1.1.m1.4.4.1.1.1.cmml" xref="S2.p1.1.m1.4.4.1.1"><in id="S2.p1.1.m1.4.4.1.1.1.1.cmml" xref="S2.p1.1.m1.4.4.1.1.1.1"></in><ci id="S2.p1.1.m1.4.4.1.1.1.2.cmml" xref="S2.p1.1.m1.4.4.1.1.1.2">𝑡</ci><interval closure="closed" id="S2.p1.1.m1.4.4.1.1.1.3.1.cmml" xref="S2.p1.1.m1.4.4.1.1.1.3.2"><cn type="integer" id="S2.p1.1.m1.2.2.cmml" xref="S2.p1.1.m1.2.2">0</cn><ci id="S2.p1.1.m1.3.3.cmml" xref="S2.p1.1.m1.3.3">𝑇</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.4c">x(t)\ (t\in[0,T])</annotation></semantics></math><span id="S2.p1.3.2" class="ltx_text" style="font-size:90%;"> is the audio waveform, </span><math id="S2.p1.2.m2.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S2.p1.2.m2.1a"><mi mathsize="90%" id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">W</annotation></semantics></math><span id="S2.p1.3.3" class="ltx_text" style="font-size:90%;"> is a window size and </span><math id="S2.p1.3.m3.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S2.p1.3.m3.1a"><mi mathsize="90%" id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">h</annotation></semantics></math><span id="S2.p1.3.4" class="ltx_text" style="font-size:90%;"> is a hop size.</span></p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Video2RMS</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Video2RMS aims to predict the RMS curve, representing the windowed root mean of squared audio amplitude proportional to intensity, from a sequence of video frames.
We introduce two key ideas to tackle this problem. First, we propose to discretize the RMS target and formulate the problem as a classification task.
Since non-ambient action-based sounds are transient and sparse, much of the audio remains nearly silent. Our preliminary experiment showed that training with the L2 loss as a regression task led to poor results, as the model tended to predict silence to reach a local minimum. We discretized the continuous RMS curve into equidistant bins after scaling with the </span><math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi mathsize="90%" id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\mu</annotation></semantics></math><span id="S2.SS1.p1.1.2" class="ltx_text" style="font-size:90%;">-law encoding </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S2.SS1.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.5" class="ltx_text" style="font-size:90%;">, formulated as follows:</span></p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.4" class="ltx_Math" alttext="f(r)={ln(1+\mu|r|)\over ln(1+\mu)}" display="block"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.5" xref="S2.E2.m1.4.5.cmml"><mrow id="S2.E2.m1.4.5.2" xref="S2.E2.m1.4.5.2.cmml"><mi mathsize="90%" id="S2.E2.m1.4.5.2.2" xref="S2.E2.m1.4.5.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.4.5.2.1" xref="S2.E2.m1.4.5.2.1.cmml">​</mo><mrow id="S2.E2.m1.4.5.2.3.2" xref="S2.E2.m1.4.5.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E2.m1.4.5.2.3.2.1" xref="S2.E2.m1.4.5.2.cmml">(</mo><mi mathsize="90%" id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml">r</mi><mo maxsize="90%" minsize="90%" id="S2.E2.m1.4.5.2.3.2.2" xref="S2.E2.m1.4.5.2.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S2.E2.m1.4.5.1" xref="S2.E2.m1.4.5.1.cmml">=</mo><mfrac id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml"><mrow id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.2.cmml"><mi mathsize="90%" id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.3" xref="S2.E2.m1.2.2.2.3.cmml">​</mo><mi mathsize="90%" id="S2.E2.m1.2.2.2.5" xref="S2.E2.m1.2.2.2.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.3a" xref="S2.E2.m1.2.2.2.3.cmml">​</mo><mrow id="S2.E2.m1.2.2.2.2.1" xref="S2.E2.m1.2.2.2.2.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E2.m1.2.2.2.2.1.2" xref="S2.E2.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S2.E2.m1.2.2.2.2.1.1" xref="S2.E2.m1.2.2.2.2.1.1.cmml"><mn mathsize="90%" id="S2.E2.m1.2.2.2.2.1.1.2" xref="S2.E2.m1.2.2.2.2.1.1.2.cmml">1</mn><mo mathsize="90%" id="S2.E2.m1.2.2.2.2.1.1.1" xref="S2.E2.m1.2.2.2.2.1.1.1.cmml">+</mo><mrow id="S2.E2.m1.2.2.2.2.1.1.3" xref="S2.E2.m1.2.2.2.2.1.1.3.cmml"><mi mathsize="90%" id="S2.E2.m1.2.2.2.2.1.1.3.2" xref="S2.E2.m1.2.2.2.2.1.1.3.2.cmml">μ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.2.2.2.2.1.1.3.1" xref="S2.E2.m1.2.2.2.2.1.1.3.1.cmml">​</mo><mrow id="S2.E2.m1.2.2.2.2.1.1.3.3.2" xref="S2.E2.m1.2.2.2.2.1.1.3.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E2.m1.2.2.2.2.1.1.3.3.2.1" xref="S2.E2.m1.2.2.2.2.1.1.3.3.1.1.cmml">|</mo><mi mathsize="90%" id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">r</mi><mo maxsize="90%" minsize="90%" id="S2.E2.m1.2.2.2.2.1.1.3.3.2.2" xref="S2.E2.m1.2.2.2.2.1.1.3.3.1.1.cmml">|</mo></mrow></mrow></mrow><mo maxsize="90%" minsize="90%" id="S2.E2.m1.2.2.2.2.1.3" xref="S2.E2.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.E2.m1.3.3.3" xref="S2.E2.m1.3.3.3.cmml"><mi mathsize="90%" id="S2.E2.m1.3.3.3.3" xref="S2.E2.m1.3.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.3.2" xref="S2.E2.m1.3.3.3.2.cmml">​</mo><mi mathsize="90%" id="S2.E2.m1.3.3.3.4" xref="S2.E2.m1.3.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.3.2a" xref="S2.E2.m1.3.3.3.2.cmml">​</mo><mrow id="S2.E2.m1.3.3.3.1.1" xref="S2.E2.m1.3.3.3.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E2.m1.3.3.3.1.1.2" xref="S2.E2.m1.3.3.3.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.3.3.3.1.1.1" xref="S2.E2.m1.3.3.3.1.1.1.cmml"><mn mathsize="90%" id="S2.E2.m1.3.3.3.1.1.1.2" xref="S2.E2.m1.3.3.3.1.1.1.2.cmml">1</mn><mo mathsize="90%" id="S2.E2.m1.3.3.3.1.1.1.1" xref="S2.E2.m1.3.3.3.1.1.1.1.cmml">+</mo><mi mathsize="90%" id="S2.E2.m1.3.3.3.1.1.1.3" xref="S2.E2.m1.3.3.3.1.1.1.3.cmml">μ</mi></mrow><mo maxsize="90%" minsize="90%" id="S2.E2.m1.3.3.3.1.1.3" xref="S2.E2.m1.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.5.cmml" xref="S2.E2.m1.4.5"><eq id="S2.E2.m1.4.5.1.cmml" xref="S2.E2.m1.4.5.1"></eq><apply id="S2.E2.m1.4.5.2.cmml" xref="S2.E2.m1.4.5.2"><times id="S2.E2.m1.4.5.2.1.cmml" xref="S2.E2.m1.4.5.2.1"></times><ci id="S2.E2.m1.4.5.2.2.cmml" xref="S2.E2.m1.4.5.2.2">𝑓</ci><ci id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4">𝑟</ci></apply><apply id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3"><divide id="S2.E2.m1.3.3.4.cmml" xref="S2.E2.m1.3.3"></divide><apply id="S2.E2.m1.2.2.2.cmml" xref="S2.E2.m1.2.2.2"><times id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.3"></times><ci id="S2.E2.m1.2.2.2.4.cmml" xref="S2.E2.m1.2.2.2.4">𝑙</ci><ci id="S2.E2.m1.2.2.2.5.cmml" xref="S2.E2.m1.2.2.2.5">𝑛</ci><apply id="S2.E2.m1.2.2.2.2.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1"><plus id="S2.E2.m1.2.2.2.2.1.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1"></plus><cn type="integer" id="S2.E2.m1.2.2.2.2.1.1.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.2">1</cn><apply id="S2.E2.m1.2.2.2.2.1.1.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3"><times id="S2.E2.m1.2.2.2.2.1.1.3.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.1"></times><ci id="S2.E2.m1.2.2.2.2.1.1.3.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.2">𝜇</ci><apply id="S2.E2.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3.2"><abs id="S2.E2.m1.2.2.2.2.1.1.3.3.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3.3.2.1"></abs><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">𝑟</ci></apply></apply></apply></apply><apply id="S2.E2.m1.3.3.3.cmml" xref="S2.E2.m1.3.3.3"><times id="S2.E2.m1.3.3.3.2.cmml" xref="S2.E2.m1.3.3.3.2"></times><ci id="S2.E2.m1.3.3.3.3.cmml" xref="S2.E2.m1.3.3.3.3">𝑙</ci><ci id="S2.E2.m1.3.3.3.4.cmml" xref="S2.E2.m1.3.3.3.4">𝑛</ci><apply id="S2.E2.m1.3.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.3.1.1"><plus id="S2.E2.m1.3.3.3.1.1.1.1.cmml" xref="S2.E2.m1.3.3.3.1.1.1.1"></plus><cn type="integer" id="S2.E2.m1.3.3.3.1.1.1.2.cmml" xref="S2.E2.m1.3.3.3.1.1.1.2">1</cn><ci id="S2.E2.m1.3.3.3.1.1.1.3.cmml" xref="S2.E2.m1.3.3.3.1.1.1.3">𝜇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">f(r)={ln(1+\mu|r|)\over ln(1+\mu)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.4" class="ltx_p"><span id="S2.SS1.p1.4.1" class="ltx_text" style="font-size:90%;">where </span><math id="S2.SS1.p1.2.m1.2" class="ltx_Math" alttext="r\in[0,1]" display="inline"><semantics id="S2.SS1.p1.2.m1.2a"><mrow id="S2.SS1.p1.2.m1.2.3" xref="S2.SS1.p1.2.m1.2.3.cmml"><mi mathsize="90%" id="S2.SS1.p1.2.m1.2.3.2" xref="S2.SS1.p1.2.m1.2.3.2.cmml">r</mi><mo mathsize="90%" id="S2.SS1.p1.2.m1.2.3.1" xref="S2.SS1.p1.2.m1.2.3.1.cmml">∈</mo><mrow id="S2.SS1.p1.2.m1.2.3.3.2" xref="S2.SS1.p1.2.m1.2.3.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.SS1.p1.2.m1.2.3.3.2.1" xref="S2.SS1.p1.2.m1.2.3.3.1.cmml">[</mo><mn mathsize="90%" id="S2.SS1.p1.2.m1.1.1" xref="S2.SS1.p1.2.m1.1.1.cmml">0</mn><mo mathsize="90%" id="S2.SS1.p1.2.m1.2.3.3.2.2" xref="S2.SS1.p1.2.m1.2.3.3.1.cmml">,</mo><mn mathsize="90%" id="S2.SS1.p1.2.m1.2.2" xref="S2.SS1.p1.2.m1.2.2.cmml">1</mn><mo maxsize="90%" minsize="90%" id="S2.SS1.p1.2.m1.2.3.3.2.3" xref="S2.SS1.p1.2.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m1.2b"><apply id="S2.SS1.p1.2.m1.2.3.cmml" xref="S2.SS1.p1.2.m1.2.3"><in id="S2.SS1.p1.2.m1.2.3.1.cmml" xref="S2.SS1.p1.2.m1.2.3.1"></in><ci id="S2.SS1.p1.2.m1.2.3.2.cmml" xref="S2.SS1.p1.2.m1.2.3.2">𝑟</ci><interval closure="closed" id="S2.SS1.p1.2.m1.2.3.3.1.cmml" xref="S2.SS1.p1.2.m1.2.3.3.2"><cn type="integer" id="S2.SS1.p1.2.m1.1.1.cmml" xref="S2.SS1.p1.2.m1.1.1">0</cn><cn type="integer" id="S2.SS1.p1.2.m1.2.2.cmml" xref="S2.SS1.p1.2.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m1.2c">r\in[0,1]</annotation></semantics></math><span id="S2.SS1.p1.4.2" class="ltx_text" style="font-size:90%;"> is the RMS value and </span><math id="S2.SS1.p1.3.m2.1" class="ltx_Math" alttext="\mu+1" display="inline"><semantics id="S2.SS1.p1.3.m2.1a"><mrow id="S2.SS1.p1.3.m2.1.1" xref="S2.SS1.p1.3.m2.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p1.3.m2.1.1.2" xref="S2.SS1.p1.3.m2.1.1.2.cmml">μ</mi><mo mathsize="90%" id="S2.SS1.p1.3.m2.1.1.1" xref="S2.SS1.p1.3.m2.1.1.1.cmml">+</mo><mn mathsize="90%" id="S2.SS1.p1.3.m2.1.1.3" xref="S2.SS1.p1.3.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m2.1b"><apply id="S2.SS1.p1.3.m2.1.1.cmml" xref="S2.SS1.p1.3.m2.1.1"><plus id="S2.SS1.p1.3.m2.1.1.1.cmml" xref="S2.SS1.p1.3.m2.1.1.1"></plus><ci id="S2.SS1.p1.3.m2.1.1.2.cmml" xref="S2.SS1.p1.3.m2.1.1.2">𝜇</ci><cn type="integer" id="S2.SS1.p1.3.m2.1.1.3.cmml" xref="S2.SS1.p1.3.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m2.1c">\mu+1</annotation></semantics></math><span id="S2.SS1.p1.4.3" class="ltx_text" style="font-size:90%;"> is the number of discretized bins.
Second, we use the label smoothing to mitigate the penalty for near-correct predictions.
We adopted the Gaussian label smoothing, frequently used in pitch estimation </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.4.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S2.SS1.p1.4.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.4.6" class="ltx_text" style="font-size:90%;">. The smoothed label </span><math id="S2.SS1.p1.4.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS1.p1.4.m3.1a"><mi mathsize="90%" id="S2.SS1.p1.4.m3.1.1" xref="S2.SS1.p1.4.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m3.1b"><ci id="S2.SS1.p1.4.m3.1.1.cmml" xref="S2.SS1.p1.4.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m3.1c">y</annotation></semantics></math><span id="S2.SS1.p1.4.7" class="ltx_text" style="font-size:90%;"> is formulated as follows:</span></p>
<table id="A10.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E3.m1.5" class="ltx_Math" alttext="\displaystyle y(i)=\begin{cases}\exp(-{(c_{i}-c_{gt})^{2}\over 2\sigma^{2}})&amp;\text{if }|c_{i}-c_{gt}|\leq W\ (c_{i},c_{gt}\neq 0)\\
0&amp;\text{otherwise}\end{cases}" display="inline"><semantics id="S2.E3.m1.5a"><mrow id="S2.E3.m1.5.6" xref="S2.E3.m1.5.6.cmml"><mrow id="S2.E3.m1.5.6.2" xref="S2.E3.m1.5.6.2.cmml"><mi mathsize="90%" id="S2.E3.m1.5.6.2.2" xref="S2.E3.m1.5.6.2.2.cmml">y</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.6.2.1" xref="S2.E3.m1.5.6.2.1.cmml">​</mo><mrow id="S2.E3.m1.5.6.2.3.2" xref="S2.E3.m1.5.6.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.5.6.2.3.2.1" xref="S2.E3.m1.5.6.2.cmml">(</mo><mi mathsize="90%" id="S2.E3.m1.5.5" xref="S2.E3.m1.5.5.cmml">i</mi><mo maxsize="90%" minsize="90%" id="S2.E3.m1.5.6.2.3.2.2" xref="S2.E3.m1.5.6.2.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S2.E3.m1.5.6.1" xref="S2.E3.m1.5.6.1.cmml">=</mo><mrow id="S2.E3.m1.4.4a" xref="S2.E3.m1.5.6.3.1.cmml"><mo id="S2.E3.m1.4.4a.5" xref="S2.E3.m1.5.6.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S2.E3.m1.4.4.4a" xref="S2.E3.m1.5.6.3.1.cmml"><mtr id="S2.E3.m1.4.4.4aa" xref="S2.E3.m1.5.6.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m1.4.4.4ab" xref="S2.E3.m1.5.6.3.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.4.cmml"><mi mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.2.cmml">exp</mi><mo id="S2.E3.m1.1.1.1.1.1.1.3a" xref="S2.E3.m1.1.1.1.1.1.1.4.cmml">⁡</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.3.1" xref="S2.E3.m1.1.1.1.1.1.1.4.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.1.1.1.1.1.1.3.1.2" xref="S2.E3.m1.1.1.1.1.1.1.4.cmml">(</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.3.1.1" xref="S2.E3.m1.1.1.1.1.1.1.3.1.1.cmml"><mo mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.3.1.1a" xref="S2.E3.m1.1.1.1.1.1.1.3.1.1.cmml">−</mo><mfrac id="S2.E3.m1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.cmml"><msup id="S2.E3.m1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">c</mi><mi mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">c</mi><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo maxsize="90%" minsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mn mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.3.cmml">2</mn></msup><mrow id="S2.E3.m1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.3.cmml"><mn mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.1.3.1" xref="S2.E3.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><msup id="S2.E3.m1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.cmml"><mi mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.2.cmml">σ</mi><mn mathsize="90%" id="S2.E3.m1.1.1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.3.cmml">2</mn></msup></mrow></mfrac></mrow><mo maxsize="90%" minsize="90%" id="S2.E3.m1.1.1.1.1.1.1.3.1.3" xref="S2.E3.m1.1.1.1.1.1.1.4.cmml">)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m1.4.4.4ac" xref="S2.E3.m1.5.6.3.1.cmml"><mrow id="S2.E3.m1.2.2.2.2.2.1" xref="S2.E3.m1.2.2.2.2.2.1.cmml"><mrow id="S2.E3.m1.2.2.2.2.2.1.1" xref="S2.E3.m1.2.2.2.2.2.1.1.cmml"><mtext mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.3" xref="S2.E3.m1.2.2.2.2.2.1.1.3a.cmml">if </mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.2.1.1.2" xref="S2.E3.m1.2.2.2.2.2.1.1.2.cmml">​</mo><mrow id="S2.E3.m1.2.2.2.2.2.1.1.1.1" xref="S2.E3.m1.2.2.2.2.2.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.2" xref="S2.E3.m1.2.2.2.2.2.1.1.1.2.1.cmml">|</mo><mrow id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.cmml"><msub id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.2" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.2.cmml">c</mi><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.3" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.3.cmml">i</mi></msub><mo mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.1" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.1.cmml">−</mo><msub id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.2" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.2.cmml">c</mi><mrow id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.2" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.1" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.1.cmml">​</mo><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.3" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo maxsize="90%" minsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.3" xref="S2.E3.m1.2.2.2.2.2.1.1.1.2.1.cmml">|</mo></mrow></mrow><mo mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.3" xref="S2.E3.m1.2.2.2.2.2.1.3.cmml">≤</mo><mrow id="S2.E3.m1.2.2.2.2.2.1.2" xref="S2.E3.m1.2.2.2.2.2.1.2.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.3" xref="S2.E3.m1.2.2.2.2.2.1.2.3.cmml">W</mi><mo lspace="0.450em" rspace="0em" id="S2.E3.m1.2.2.2.2.2.1.2.2" xref="S2.E3.m1.2.2.2.2.2.1.2.2.cmml">​</mo><mrow id="S2.E3.m1.2.2.2.2.2.1.2.1.1" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.2" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.cmml"><mrow id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.3.cmml"><msub id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.cmml">c</mi><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.3" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.3.cmml">,</mo><msub id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.2" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.2.cmml">c</mi><mrow id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.cmml"><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.2" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.1" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.1.cmml">​</mo><mi mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.3" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.3.cmml">t</mi></mrow></msub></mrow><mo mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.3" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.3.cmml">≠</mo><mn mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.4" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.4.cmml">0</mn></mrow><mo maxsize="90%" minsize="90%" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.3" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mtd></mtr><mtr id="S2.E3.m1.4.4.4ad" xref="S2.E3.m1.5.6.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m1.4.4.4ae" xref="S2.E3.m1.5.6.3.1.cmml"><mn mathsize="90%" id="S2.E3.m1.3.3.3.3.1.1" xref="S2.E3.m1.3.3.3.3.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m1.4.4.4af" xref="S2.E3.m1.5.6.3.1.cmml"><mtext mathsize="90%" id="S2.E3.m1.4.4.4.4.2.1" xref="S2.E3.m1.4.4.4.4.2.1a.cmml">otherwise</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.5b"><apply id="S2.E3.m1.5.6.cmml" xref="S2.E3.m1.5.6"><eq id="S2.E3.m1.5.6.1.cmml" xref="S2.E3.m1.5.6.1"></eq><apply id="S2.E3.m1.5.6.2.cmml" xref="S2.E3.m1.5.6.2"><times id="S2.E3.m1.5.6.2.1.cmml" xref="S2.E3.m1.5.6.2.1"></times><ci id="S2.E3.m1.5.6.2.2.cmml" xref="S2.E3.m1.5.6.2.2">𝑦</ci><ci id="S2.E3.m1.5.5.cmml" xref="S2.E3.m1.5.5">𝑖</ci></apply><apply id="S2.E3.m1.5.6.3.1.cmml" xref="S2.E3.m1.4.4a"><csymbol cd="latexml" id="S2.E3.m1.5.6.3.1.1.cmml" xref="S2.E3.m1.4.4a.5">cases</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.4.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3"><exp id="S2.E3.m1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2"></exp><apply id="S2.E3.m1.1.1.1.1.1.1.3.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.1.1"><minus id="S2.E3.m1.1.1.1.1.1.1.3.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.1.1"></minus><apply id="S2.E3.m1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1"><divide id="S2.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1"></divide><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1"><minus id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑐</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2">𝑐</ci><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3"><times id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.2">𝑔</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.3">2</cn></apply><apply id="S2.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3"><times id="S2.E3.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.1"></times><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.2">2</cn><apply id="S2.E3.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3">superscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.2">𝜎</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3.3.3">2</cn></apply></apply></apply></apply></apply><apply id="S2.E3.m1.2.2.2.2.2.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1"><leq id="S2.E3.m1.2.2.2.2.2.1.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.3"></leq><apply id="S2.E3.m1.2.2.2.2.2.1.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1"><times id="S2.E3.m1.2.2.2.2.2.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.2"></times><ci id="S2.E3.m1.2.2.2.2.2.1.1.3a.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.3"><mtext mathsize="90%" id="S2.E3.m1.2.2.2.2.2.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.3">if </mtext></ci><apply id="S2.E3.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1"><abs id="S2.E3.m1.2.2.2.2.2.1.1.1.2.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.2"></abs><apply id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1"><minus id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.1"></minus><apply id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.2">𝑐</ci><ci id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.2">𝑐</ci><apply id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3"><times id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.1"></times><ci id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.2">𝑔</ci><ci id="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply></apply><apply id="S2.E3.m1.2.2.2.2.2.1.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2"><times id="S2.E3.m1.2.2.2.2.2.1.2.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.2"></times><ci id="S2.E3.m1.2.2.2.2.2.1.2.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.3">𝑊</ci><apply id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1"><neq id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.3"></neq><list id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2"><apply id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2">𝑐</ci><ci id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.2">𝑐</ci><apply id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3"><times id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.1.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.1"></times><ci id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.2.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.2">𝑔</ci><ci id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.3.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.2.2.2.3.3">𝑡</ci></apply></apply></list><cn type="integer" id="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.4.cmml" xref="S2.E3.m1.2.2.2.2.2.1.2.1.1.1.4">0</cn></apply></apply></apply><cn type="integer" id="S2.E3.m1.3.3.3.3.1.1.cmml" xref="S2.E3.m1.3.3.3.3.1.1">0</cn><ci id="S2.E3.m1.4.4.4.4.2.1a.cmml" xref="S2.E3.m1.4.4.4.4.2.1"><mtext mathsize="90%" id="S2.E3.m1.4.4.4.4.2.1.cmml" xref="S2.E3.m1.4.4.4.4.2.1">otherwise</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.5c">\displaystyle y(i)=\begin{cases}\exp(-{(c_{i}-c_{gt})^{2}\over 2\sigma^{2}})&amp;\text{if }|c_{i}-c_{gt}|\leq W\ (c_{i},c_{gt}\neq 0)\\
0&amp;\text{otherwise}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.8" class="ltx_p"><span id="S2.SS1.p1.8.1" class="ltx_text" style="font-size:90%;">where </span><math id="S2.SS1.p1.5.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p1.5.m1.1a"><mi mathsize="90%" id="S2.SS1.p1.5.m1.1.1" xref="S2.SS1.p1.5.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m1.1b"><ci id="S2.SS1.p1.5.m1.1.1.cmml" xref="S2.SS1.p1.5.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m1.1c">i</annotation></semantics></math><span id="S2.SS1.p1.8.2" class="ltx_text" style="font-size:90%;"> is the class index, </span><math id="S2.SS1.p1.6.m2.1" class="ltx_Math" alttext="c_{gt}" display="inline"><semantics id="S2.SS1.p1.6.m2.1a"><msub id="S2.SS1.p1.6.m2.1.1" xref="S2.SS1.p1.6.m2.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p1.6.m2.1.1.2" xref="S2.SS1.p1.6.m2.1.1.2.cmml">c</mi><mrow id="S2.SS1.p1.6.m2.1.1.3" xref="S2.SS1.p1.6.m2.1.1.3.cmml"><mi mathsize="90%" id="S2.SS1.p1.6.m2.1.1.3.2" xref="S2.SS1.p1.6.m2.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p1.6.m2.1.1.3.1" xref="S2.SS1.p1.6.m2.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S2.SS1.p1.6.m2.1.1.3.3" xref="S2.SS1.p1.6.m2.1.1.3.3.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m2.1b"><apply id="S2.SS1.p1.6.m2.1.1.cmml" xref="S2.SS1.p1.6.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m2.1.1.1.cmml" xref="S2.SS1.p1.6.m2.1.1">subscript</csymbol><ci id="S2.SS1.p1.6.m2.1.1.2.cmml" xref="S2.SS1.p1.6.m2.1.1.2">𝑐</ci><apply id="S2.SS1.p1.6.m2.1.1.3.cmml" xref="S2.SS1.p1.6.m2.1.1.3"><times id="S2.SS1.p1.6.m2.1.1.3.1.cmml" xref="S2.SS1.p1.6.m2.1.1.3.1"></times><ci id="S2.SS1.p1.6.m2.1.1.3.2.cmml" xref="S2.SS1.p1.6.m2.1.1.3.2">𝑔</ci><ci id="S2.SS1.p1.6.m2.1.1.3.3.cmml" xref="S2.SS1.p1.6.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m2.1c">c_{gt}</annotation></semantics></math><span id="S2.SS1.p1.8.3" class="ltx_text" style="font-size:90%;"> is the ground-truth class, </span><math id="S2.SS1.p1.7.m3.1" class="ltx_Math" alttext="\sigma=1" display="inline"><semantics id="S2.SS1.p1.7.m3.1a"><mrow id="S2.SS1.p1.7.m3.1.1" xref="S2.SS1.p1.7.m3.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p1.7.m3.1.1.2" xref="S2.SS1.p1.7.m3.1.1.2.cmml">σ</mi><mo mathsize="90%" id="S2.SS1.p1.7.m3.1.1.1" xref="S2.SS1.p1.7.m3.1.1.1.cmml">=</mo><mn mathsize="90%" id="S2.SS1.p1.7.m3.1.1.3" xref="S2.SS1.p1.7.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m3.1b"><apply id="S2.SS1.p1.7.m3.1.1.cmml" xref="S2.SS1.p1.7.m3.1.1"><eq id="S2.SS1.p1.7.m3.1.1.1.cmml" xref="S2.SS1.p1.7.m3.1.1.1"></eq><ci id="S2.SS1.p1.7.m3.1.1.2.cmml" xref="S2.SS1.p1.7.m3.1.1.2">𝜎</ci><cn type="integer" id="S2.SS1.p1.7.m3.1.1.3.cmml" xref="S2.SS1.p1.7.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m3.1c">\sigma=1</annotation></semantics></math><span id="S2.SS1.p1.8.4" class="ltx_text" style="font-size:90%;">, and </span><math id="S2.SS1.p1.8.m4.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S2.SS1.p1.8.m4.1a"><mi mathsize="90%" id="S2.SS1.p1.8.m4.1.1" xref="S2.SS1.p1.8.m4.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m4.1b"><ci id="S2.SS1.p1.8.m4.1.1.cmml" xref="S2.SS1.p1.8.m4.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m4.1c">W</annotation></semantics></math><span id="S2.SS1.p1.8.5" class="ltx_text" style="font-size:90%;"> is the window size determined by the ablation study.</span></p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.4" class="ltx_p"><span id="S2.SS1.p2.4.1" class="ltx_text" style="font-size:90%;">Video2RMS model consists of three 1D-convolutional blocks, two Bi-LSTM layers, and a linear projection head, similar to the visual encoder of RegNet </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p2.4.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S2.SS1.p2.4.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p2.4.4" class="ltx_text" style="font-size:90%;">. Each convolutional block includes a convolution layer, a batch normalization layer, and a ReLU activation layer.
As for the input, the BN-Inception network </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p2.4.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib12" title="" class="ltx_ref">12</a><span id="S2.SS1.p2.4.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p2.4.7" class="ltx_text" style="font-size:90%;">, pretrained on ImageNet, extracts video features frame-wise from RGB images and 2-channel optical flow.
The loss function is defined as </span><math id="S2.SS1.p2.1.m1.2" class="ltx_Math" alttext="L=\sum_{i}CE(\hat{R}_{i},R_{i})" display="inline"><semantics id="S2.SS1.p2.1.m1.2a"><mrow id="S2.SS1.p2.1.m1.2.2" xref="S2.SS1.p2.1.m1.2.2.cmml"><mi mathsize="90%" id="S2.SS1.p2.1.m1.2.2.4" xref="S2.SS1.p2.1.m1.2.2.4.cmml">L</mi><mo mathsize="90%" rspace="0.111em" id="S2.SS1.p2.1.m1.2.2.3" xref="S2.SS1.p2.1.m1.2.2.3.cmml">=</mo><mrow id="S2.SS1.p2.1.m1.2.2.2" xref="S2.SS1.p2.1.m1.2.2.2.cmml"><msub id="S2.SS1.p2.1.m1.2.2.2.3" xref="S2.SS1.p2.1.m1.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" stretchy="true" id="S2.SS1.p2.1.m1.2.2.2.3.2" xref="S2.SS1.p2.1.m1.2.2.2.3.2.cmml">∑</mo><mi mathsize="90%" id="S2.SS1.p2.1.m1.2.2.2.3.3" xref="S2.SS1.p2.1.m1.2.2.2.3.3.cmml">i</mi></msub><mrow id="S2.SS1.p2.1.m1.2.2.2.2" xref="S2.SS1.p2.1.m1.2.2.2.2.cmml"><mi mathsize="90%" id="S2.SS1.p2.1.m1.2.2.2.2.4" xref="S2.SS1.p2.1.m1.2.2.2.2.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.1.m1.2.2.2.2.3" xref="S2.SS1.p2.1.m1.2.2.2.2.3.cmml">​</mo><mi mathsize="90%" id="S2.SS1.p2.1.m1.2.2.2.2.5" xref="S2.SS1.p2.1.m1.2.2.2.2.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.1.m1.2.2.2.2.3a" xref="S2.SS1.p2.1.m1.2.2.2.2.3.cmml">​</mo><mrow id="S2.SS1.p2.1.m1.2.2.2.2.2.2" xref="S2.SS1.p2.1.m1.2.2.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S2.SS1.p2.1.m1.2.2.2.2.2.2.3" xref="S2.SS1.p2.1.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mo mathsize="90%" id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi mathsize="90%" id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="S2.SS1.p2.1.m1.2.2.2.2.2.2.4" xref="S2.SS1.p2.1.m1.2.2.2.2.2.3.cmml">,</mo><msub id="S2.SS1.p2.1.m1.2.2.2.2.2.2.2" xref="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.cmml"><mi mathsize="90%" id="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.2" xref="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.2.cmml">R</mi><mi mathsize="90%" id="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.3" xref="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="S2.SS1.p2.1.m1.2.2.2.2.2.2.5" xref="S2.SS1.p2.1.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.2b"><apply id="S2.SS1.p2.1.m1.2.2.cmml" xref="S2.SS1.p2.1.m1.2.2"><eq id="S2.SS1.p2.1.m1.2.2.3.cmml" xref="S2.SS1.p2.1.m1.2.2.3"></eq><ci id="S2.SS1.p2.1.m1.2.2.4.cmml" xref="S2.SS1.p2.1.m1.2.2.4">𝐿</ci><apply id="S2.SS1.p2.1.m1.2.2.2.cmml" xref="S2.SS1.p2.1.m1.2.2.2"><apply id="S2.SS1.p2.1.m1.2.2.2.3.cmml" xref="S2.SS1.p2.1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.2.2.2.3.1.cmml" xref="S2.SS1.p2.1.m1.2.2.2.3">subscript</csymbol><sum id="S2.SS1.p2.1.m1.2.2.2.3.2.cmml" xref="S2.SS1.p2.1.m1.2.2.2.3.2"></sum><ci id="S2.SS1.p2.1.m1.2.2.2.3.3.cmml" xref="S2.SS1.p2.1.m1.2.2.2.3.3">𝑖</ci></apply><apply id="S2.SS1.p2.1.m1.2.2.2.2.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2"><times id="S2.SS1.p2.1.m1.2.2.2.2.3.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2.3"></times><ci id="S2.SS1.p2.1.m1.2.2.2.2.4.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2.4">𝐶</ci><ci id="S2.SS1.p2.1.m1.2.2.2.2.5.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2.5">𝐸</ci><interval closure="open" id="S2.SS1.p2.1.m1.2.2.2.2.2.3.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2.2.2"><apply id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2"><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.2.2">𝑅</ci></apply><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.1.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.2">𝑅</ci><ci id="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.3.cmml" xref="S2.SS1.p2.1.m1.2.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.2c">L=\sum_{i}CE(\hat{R}_{i},R_{i})</annotation></semantics></math><span id="S2.SS1.p2.4.8" class="ltx_text" style="font-size:90%;"> where </span><math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi mathsize="90%" id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">R</annotation></semantics></math><span id="S2.SS1.p2.4.9" class="ltx_text" style="font-size:90%;"> denotes the discretized RMS label, </span><math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="\hat{\cdot}" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><mover accent="true" id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml"><mo mathsize="90%" id="S2.SS1.p2.3.m3.1.1.2" xref="S2.SS1.p2.3.m3.1.1.2.cmml">⋅</mo><mo mathsize="90%" id="S2.SS1.p2.3.m3.1.1.1" xref="S2.SS1.p2.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><apply id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1"><ci id="S2.SS1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1.1">^</ci><ci id="S2.SS1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.p2.3.m3.1.1.2">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">\hat{\cdot}</annotation></semantics></math><span id="S2.SS1.p2.4.10" class="ltx_text" style="font-size:90%;"> is the prediction, and </span><math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="CE" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mrow id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml"><mi mathsize="90%" id="S2.SS1.p2.4.m4.1.1.2" xref="S2.SS1.p2.4.m4.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.4.m4.1.1.1" xref="S2.SS1.p2.4.m4.1.1.1.cmml">​</mo><mi mathsize="90%" id="S2.SS1.p2.4.m4.1.1.3" xref="S2.SS1.p2.4.m4.1.1.3.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><apply id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1"><times id="S2.SS1.p2.4.m4.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1.1"></times><ci id="S2.SS1.p2.4.m4.1.1.2.cmml" xref="S2.SS1.p2.4.m4.1.1.2">𝐶</ci><ci id="S2.SS1.p2.4.m4.1.1.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3">𝐸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">CE</annotation></semantics></math><span id="S2.SS1.p2.4.11" class="ltx_text" style="font-size:90%;"> is the cross entropy loss.</span></p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>RMS2Sound</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.10" class="ltx_p"><span id="S2.SS2.p1.10.1" class="ltx_text" style="font-size:90%;">In order to generate audio that matches both semantic and temporal conditions, we developed RMS-ControlNet, which integrates RMS conditioning controls into a pretrained text-to-audio diffusion model. As shown in Fig. </span><a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S2.SS2.p1.10.2" class="ltx_text" style="font-size:90%;">, RMS-ControlNet generates audio conditioned on the given RMS and CLAP </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.10.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib13" title="" class="ltx_ref">13</a><span id="S2.SS2.p1.10.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.10.5" class="ltx_text" style="font-size:90%;"> embedding. Due to CLAP’s ability to extract audio and text embeddings in a joint multimodal space, RMS-ControlNet can generate audio with a target RMS based on both text and audio timbre conditions. We train RMS-ControlNet on audio data only. The training objective is as follows:</span></p>
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.7" class="ltx_Math" alttext="\mathbb{E}_{x,t,\epsilon}\lVert\epsilon-f(z_{t},t,C(x),R(x))\rVert_{2}^{2}" display="block"><semantics id="S2.E4.m1.7a"><mrow id="S2.E4.m1.7.7" xref="S2.E4.m1.7.7.cmml"><msub id="S2.E4.m1.7.7.3" xref="S2.E4.m1.7.7.3.cmml"><mi mathsize="90%" id="S2.E4.m1.7.7.3.2" xref="S2.E4.m1.7.7.3.2.cmml">𝔼</mi><mrow id="S2.E4.m1.3.3.3.5" xref="S2.E4.m1.3.3.3.4.cmml"><mi mathsize="90%" id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml">x</mi><mo mathsize="90%" id="S2.E4.m1.3.3.3.5.1" xref="S2.E4.m1.3.3.3.4.cmml">,</mo><mi mathsize="90%" id="S2.E4.m1.2.2.2.2" xref="S2.E4.m1.2.2.2.2.cmml">t</mi><mo mathsize="90%" id="S2.E4.m1.3.3.3.5.2" xref="S2.E4.m1.3.3.3.4.cmml">,</mo><mi mathsize="90%" id="S2.E4.m1.3.3.3.3" xref="S2.E4.m1.3.3.3.3.cmml">ϵ</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.2" xref="S2.E4.m1.7.7.2.cmml">​</mo><msubsup id="S2.E4.m1.7.7.1" xref="S2.E4.m1.7.7.1.cmml"><mrow id="S2.E4.m1.7.7.1.1.1.1" xref="S2.E4.m1.7.7.1.1.1.2.cmml"><mo fence="true" mathsize="90%" rspace="0em" id="S2.E4.m1.7.7.1.1.1.1.2" xref="S2.E4.m1.7.7.1.1.1.2.1.cmml">∥</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1" xref="S2.E4.m1.7.7.1.1.1.1.1.cmml"><mi mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.5" xref="S2.E4.m1.7.7.1.1.1.1.1.5.cmml">ϵ</mi><mo mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.4" xref="S2.E4.m1.7.7.1.1.1.1.1.4.cmml">−</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1.3" xref="S2.E4.m1.7.7.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.5" xref="S2.E4.m1.7.7.1.1.1.1.1.3.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.1.1.1.1.1.3.4" xref="S2.E4.m1.7.7.1.1.1.1.1.3.4.cmml">​</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.4.cmml"><mo maxsize="90%" minsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.4" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.4.cmml">(</mo><msub id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.5" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.4.cmml">,</mo><mi mathsize="90%" id="S2.E4.m1.6.6" xref="S2.E4.m1.6.6.cmml">t</mi><mo mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.6" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.4.cmml">,</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.cmml"><mi mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.2" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.1" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.1.cmml">​</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.3.2" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.cmml"><mo maxsize="90%" minsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.3.2.1" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.cmml">(</mo><mi mathsize="90%" id="S2.E4.m1.4.4" xref="S2.E4.m1.4.4.cmml">x</mi><mo maxsize="90%" minsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.3.2.2" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.7" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.4.cmml">,</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.cmml"><mi mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.2" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.1" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.1.cmml">​</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.3.2" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.cmml"><mo maxsize="90%" minsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.3.2.1" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.cmml">(</mo><mi mathsize="90%" id="S2.E4.m1.5.5" xref="S2.E4.m1.5.5.cmml">x</mi><mo maxsize="90%" minsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.3.2.2" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.cmml">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.8" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.4.cmml">)</mo></mrow></mrow></mrow><mo fence="true" lspace="0em" mathsize="90%" id="S2.E4.m1.7.7.1.1.1.1.3" xref="S2.E4.m1.7.7.1.1.1.2.1.cmml">∥</mo></mrow><mn mathsize="90%" id="S2.E4.m1.7.7.1.1.3" xref="S2.E4.m1.7.7.1.1.3.cmml">2</mn><mn mathsize="90%" id="S2.E4.m1.7.7.1.3" xref="S2.E4.m1.7.7.1.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.7b"><apply id="S2.E4.m1.7.7.cmml" xref="S2.E4.m1.7.7"><times id="S2.E4.m1.7.7.2.cmml" xref="S2.E4.m1.7.7.2"></times><apply id="S2.E4.m1.7.7.3.cmml" xref="S2.E4.m1.7.7.3"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.3.1.cmml" xref="S2.E4.m1.7.7.3">subscript</csymbol><ci id="S2.E4.m1.7.7.3.2.cmml" xref="S2.E4.m1.7.7.3.2">𝔼</ci><list id="S2.E4.m1.3.3.3.4.cmml" xref="S2.E4.m1.3.3.3.5"><ci id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1">𝑥</ci><ci id="S2.E4.m1.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2">𝑡</ci><ci id="S2.E4.m1.3.3.3.3.cmml" xref="S2.E4.m1.3.3.3.3">italic-ϵ</ci></list></apply><apply id="S2.E4.m1.7.7.1.cmml" xref="S2.E4.m1.7.7.1"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.1.2.cmml" xref="S2.E4.m1.7.7.1">superscript</csymbol><apply id="S2.E4.m1.7.7.1.1.cmml" xref="S2.E4.m1.7.7.1"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.1.1.2.cmml" xref="S2.E4.m1.7.7.1">subscript</csymbol><apply id="S2.E4.m1.7.7.1.1.1.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.7.7.1.1.1.2.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.2">delimited-∥∥</csymbol><apply id="S2.E4.m1.7.7.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1"><minus id="S2.E4.m1.7.7.1.1.1.1.1.4.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.4"></minus><ci id="S2.E4.m1.7.7.1.1.1.1.1.5.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.5">italic-ϵ</ci><apply id="S2.E4.m1.7.7.1.1.1.1.1.3.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.3"><times id="S2.E4.m1.7.7.1.1.1.1.1.3.4.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.3.4"></times><ci id="S2.E4.m1.7.7.1.1.1.1.1.3.5.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.3.5">𝑓</ci><vector id="S2.E4.m1.7.7.1.1.1.1.1.3.3.4.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3"><apply id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.2">𝑧</ci><ci id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="S2.E4.m1.6.6.cmml" xref="S2.E4.m1.6.6">𝑡</ci><apply id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2"><times id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.1"></times><ci id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.2">𝐶</ci><ci id="S2.E4.m1.4.4.cmml" xref="S2.E4.m1.4.4">𝑥</ci></apply><apply id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3"><times id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.1"></times><ci id="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.3.3.3.3.2">𝑅</ci><ci id="S2.E4.m1.5.5.cmml" xref="S2.E4.m1.5.5">𝑥</ci></apply></vector></apply></apply></apply><cn type="integer" id="S2.E4.m1.7.7.1.1.3.cmml" xref="S2.E4.m1.7.7.1.1.3">2</cn></apply><cn type="integer" id="S2.E4.m1.7.7.1.3.cmml" xref="S2.E4.m1.7.7.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.7c">\mathbb{E}_{x,t,\epsilon}\lVert\epsilon-f(z_{t},t,C(x),R(x))\rVert_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p1.9" class="ltx_p"><span id="S2.SS2.p1.9.1" class="ltx_text" style="font-size:90%;">where </span><math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><mi mathsize="90%" id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">x</annotation></semantics></math><span id="S2.SS2.p1.9.2" class="ltx_text" style="font-size:90%;"> is audio waveform, </span><math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mi mathsize="90%" id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">z</annotation></semantics></math><span id="S2.SS2.p1.9.3" class="ltx_text" style="font-size:90%;"> is a latent representation of </span><math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mi mathsize="90%" id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><ci id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">y</annotation></semantics></math><span id="S2.SS2.p1.9.4" class="ltx_text" style="font-size:90%;"> encoded with a variational autoencoder, </span><math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="z_{t}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><msub id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">z</mi><mi mathsize="90%" id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">𝑧</ci><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">z_{t}</annotation></semantics></math><span id="S2.SS2.p1.9.5" class="ltx_text" style="font-size:90%;"> is </span><math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><mi mathsize="90%" id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><ci id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">z</annotation></semantics></math><span id="S2.SS2.p1.9.6" class="ltx_text" style="font-size:90%;"> with </span><math id="S2.SS2.p1.6.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS2.p1.6.m6.1a"><mi mathsize="90%" id="S2.SS2.p1.6.m6.1.1" xref="S2.SS2.p1.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.1b"><ci id="S2.SS2.p1.6.m6.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.1c">t</annotation></semantics></math><span id="S2.SS2.p1.9.7" class="ltx_text" style="font-size:90%;"> times noise added, </span><math id="S2.SS2.p1.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS2.p1.7.m7.1a"><mi mathsize="90%" id="S2.SS2.p1.7.m7.1.1" xref="S2.SS2.p1.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m7.1b"><ci id="S2.SS2.p1.7.m7.1.1.cmml" xref="S2.SS2.p1.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m7.1c">C</annotation></semantics></math><span id="S2.SS2.p1.9.8" class="ltx_text" style="font-size:90%;"> is the CLAP encoder, and </span><math id="S2.SS2.p1.8.m8.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S2.SS2.p1.8.m8.1a"><mi mathsize="90%" id="S2.SS2.p1.8.m8.1.1" xref="S2.SS2.p1.8.m8.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.8.m8.1b"><ci id="S2.SS2.p1.8.m8.1.1.cmml" xref="S2.SS2.p1.8.m8.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.8.m8.1c">R</annotation></semantics></math><span id="S2.SS2.p1.9.9" class="ltx_text" style="font-size:90%;"> is the RMS calculation. We implement RMS-ControlNet similarly to the original implementation of ControlNet </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.9.10.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S2.SS2.p1.9.11.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.9.12" class="ltx_text" style="font-size:90%;">. We freeze the parameters of the text-to-audio model and train only a copy of its encoding layers. To match the feature size of RMS to </span><math id="S2.SS2.p1.9.m9.1" class="ltx_Math" alttext="z_{t}" display="inline"><semantics id="S2.SS2.p1.9.m9.1a"><msub id="S2.SS2.p1.9.m9.1.1" xref="S2.SS2.p1.9.m9.1.1.cmml"><mi mathsize="90%" id="S2.SS2.p1.9.m9.1.1.2" xref="S2.SS2.p1.9.m9.1.1.2.cmml">z</mi><mi mathsize="90%" id="S2.SS2.p1.9.m9.1.1.3" xref="S2.SS2.p1.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.9.m9.1b"><apply id="S2.SS2.p1.9.m9.1.1.cmml" xref="S2.SS2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.9.m9.1.1.1.cmml" xref="S2.SS2.p1.9.m9.1.1">subscript</csymbol><ci id="S2.SS2.p1.9.m9.1.1.2.cmml" xref="S2.SS2.p1.9.m9.1.1.2">𝑧</ci><ci id="S2.SS2.p1.9.m9.1.1.3.cmml" xref="S2.SS2.p1.9.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.9.m9.1c">z_{t}</annotation></semantics></math><span id="S2.SS2.p1.9.13" class="ltx_text" style="font-size:90%;">, we use an additional zero convolution 2D layer.</span></p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Details</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Dataset</span><span id="S3.SS1.p1.1.2" class="ltx_text" style="font-size:90%;"> We used the Greatest Hits dataset</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S3.SS1.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.p1.1.5" class="ltx_text" style="font-size:90%;"> with its official train-test split for training and evaluation. The dataset contains 977 videos of a person making sounds with a wooden drumstick on 17 different materials (wood, metal, rock, leaf, plastic, cloth, water, etc.) using two types of actions (hit, scratch).
We segmented the videos with denoised audio into 10-second clips
without overlap, and resampled to 16kHz for audio and 30fps for video. Each video frame was resized to 344</span><math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mo mathsize="90%" id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><times id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\times</annotation></semantics></math><span id="S3.SS1.p1.1.6" class="ltx_text" style="font-size:90%;">256 pixels. This resulted in 2,212 training videos (6.14 hours) and 732 test videos (2.03 hours). The training set was used to train Video2RMS, and the test set was used to evaluate both Video2RMS and the entire Video-Foley model.
To increase extensibility and applicability, we trained RMS-ControlNet using audio-only data from a variety of sounds, rather than limiting it to hit and scratch sounds. We used the FreeSound dataset</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.p1.1.7.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S3.SS1.p1.1.8.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.p1.1.9" class="ltx_text" style="font-size:90%;">, which contains about 6,000 hours of audio. All audio was resampled to 16 kHz.</span></p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.6" class="ltx_p"><span id="S3.SS1.p2.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Training</span><span id="S3.SS1.p2.6.2" class="ltx_text" style="font-size:90%;"> The Video2RMS and RMS2Sound models are trained separately but combined during inference. For Video2RMS, RMS was discretized into 64 bins (</span><math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\simeq" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mo mathsize="90%" id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">≃</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><csymbol cd="latexml" id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">similar-to-or-equals</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\simeq</annotation></semantics></math><span id="S3.SS1.p2.6.3" class="ltx_text" style="font-size:90%;">0.50dB granularity), and Gaussian label smoothing was applied (</span><math id="S3.SS1.p2.2.m2.1" class="ltx_math_unparsed" alttext="W=2)" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1b"><mi mathsize="90%" id="S3.SS1.p2.2.m2.1.1">W</mi><mo mathsize="90%" id="S3.SS1.p2.2.m2.1.2">=</mo><mn mathsize="90%" id="S3.SS1.p2.2.m2.1.3">2</mn><mo maxsize="90%" minsize="90%" id="S3.SS1.p2.2.m2.1.4">)</mo></mrow><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">W=2)</annotation></semantics></math><span id="S3.SS1.p2.6.4" class="ltx_text" style="font-size:90%;">. The model was trained for 500 epochs using a StepLR scheduler (rate </span><math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="1e" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mn mathsize="90%" id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><times id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"></times><cn type="integer" id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">1</cn><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">1e</annotation></semantics></math><span id="S3.SS1.p2.6.5" class="ltx_text" style="font-size:90%;">-</span><math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mn mathsize="90%" id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><cn type="integer" id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">3</annotation></semantics></math><span id="S3.SS1.p2.6.6" class="ltx_text" style="font-size:90%;">, step size 100).
For RMS2Sound, AudioLDM </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.p2.6.7.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="S3.SS1.p2.6.8.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.p2.6.9" class="ltx_text" style="font-size:90%;"> was used as the backbone text-to-audio model. We initialized the weights of both AudioLDM and ControlNet using an official checkpoint. RMS-ControlNet was trained for 300k steps using the AdamW optimizer.
The learning rate started at </span><math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="1e" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mrow id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mn mathsize="90%" id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><times id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1"></times><cn type="integer" id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">1</cn><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">1e</annotation></semantics></math><span id="S3.SS1.p2.6.10" class="ltx_text" style="font-size:90%;">-</span><math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mn mathsize="90%" id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><cn type="integer" id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">4</annotation></semantics></math><span id="S3.SS1.p2.6.11" class="ltx_text" style="font-size:90%;"> and was halved every 10k steps. During training, only the parameters of ControlNet were updated.</span></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">To measure the performance of synchronized video-to-sound generation, three main aspects are considered.
</span><span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Semantic Alignment</span><span id="S3.SS2.p1.1.3" class="ltx_text" style="font-size:90%;"> evaluates how well the timbre and nuance of sound match the material and action type in the video, </span><span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_italic" style="font-size:90%;">Temporal Alignment</span><span id="S3.SS2.p1.1.5" class="ltx_text" style="font-size:90%;"> examines the accuracy of the start and end timing of a sound event as well as its intensity changes over time, and </span><span id="S3.SS2.p1.1.6" class="ltx_text ltx_font_italic" style="font-size:90%;">Audio Quality</span><span id="S3.SS2.p1.1.7" class="ltx_text" style="font-size:90%;"> assesses the overall quality of the audio. Both objective and subjective evaluations are conducted. To match our experiment settings, we resampled generated audios to 16kHz and combined them with the 30fps videos to create 10sec video-audio pairs.</span></p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.4" class="ltx_p"><span id="S3.SS2.p2.4.5" class="ltx_text" style="font-size:90%;">RMS-ControlNet, based on AudioLDM, can use either an audio prompt or a text prompt for timbre conditions. We conducted ablation studies to compare these two prompt methods. For the audio prompt, we simply used ground-truth audio. For the text prompt, we utilized a prompt template: </span><span id="S3.SS2.p2.4.4" class="ltx_text ltx_font_italic" style="font-size:90%;">“A person <math id="S3.SS2.p2.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="S3.SS2.p2.1.1.m1.1a"><mo stretchy="false" id="S3.SS2.p2.1.1.m1.1.1" xref="S3.SS2.p2.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.1.m1.1b"><ci id="S3.SS2.p2.1.1.m1.1.1.cmml" xref="S3.SS2.p2.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.1.m1.1c">\{</annotation></semantics></math>action<math id="S3.SS2.p2.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S3.SS2.p2.2.2.m2.1a"><mo stretchy="false" id="S3.SS2.p2.2.2.m2.1.1" xref="S3.SS2.p2.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.2.m2.1b"><ci id="S3.SS2.p2.2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.2.m2.1c">\}</annotation></semantics></math> <math id="S3.SS2.p2.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="S3.SS2.p2.3.3.m3.1a"><mo stretchy="false" id="S3.SS2.p2.3.3.m3.1.1" xref="S3.SS2.p2.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.3.m3.1b"><ci id="S3.SS2.p2.3.3.m3.1.1.cmml" xref="S3.SS2.p2.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.3.m3.1c">\{</annotation></semantics></math>material<math id="S3.SS2.p2.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S3.SS2.p2.4.4.m4.1a"><mo stretchy="false" id="S3.SS2.p2.4.4.m4.1.1" xref="S3.SS2.p2.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.4.m4.1b"><ci id="S3.SS2.p2.4.4.m4.1.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.4.m4.1c">\}</annotation></semantics></math> with a wooden stick.”</span><span id="S3.SS2.p2.4.6" class="ltx_text" style="font-size:90%;"> and annotations on material and actions from the Greatest Hits dataset. If there were multiple actions or materials, we made multiple sentences and combined them with </span><span id="S3.SS2.p2.4.7" class="ltx_text ltx_font_italic" style="font-size:90%;">“After that,”</span><span id="S3.SS2.p2.4.8" class="ltx_text" style="font-size:90%;">. If no annotation was available, we used </span><span id="S3.SS2.p2.4.9" class="ltx_text ltx_font_italic" style="font-size:90%;">“A person hit something with a wooden stick.”</span><span id="S3.SS2.p2.4.10" class="ltx_text" style="font-size:90%;"> as the default text prompt.</span></p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:141.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(43.3pt,-16.6pt) scale(1.3069021726016,1.3069021726016) ;">
<table id="S3.T1.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.4.4.4" class="ltx_tr">
<th id="S3.T1.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S3.T1.4.4.4.5.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">
<span id="S3.T1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">E-L1 </span><math id="S3.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.1.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<td id="S3.T1.2.2.2.2" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S3.T1.2.2.2.2.1" class="ltx_text" style="font-size:90%;">Acc@1 </span><math id="S3.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.2.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="S3.T1.2.2.2.2.m1.1.1" xref="S3.T1.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m1.1b"><ci id="S3.T1.2.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S3.T1.3.3.3.3" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S3.T1.3.3.3.3.1" class="ltx_text" style="font-size:90%;">Acc@5 </span><math id="S3.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.3.3.3.3.m1.1a"><mo mathsize="90%" stretchy="false" id="S3.T1.3.3.3.3.m1.1.1" xref="S3.T1.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.3.m1.1b"><ci id="S3.T1.3.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S3.T1.4.4.4.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt">
<span id="S3.T1.4.4.4.4.1" class="ltx_text" style="font-size:90%;">Acc@10 </span><math id="S3.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.4.4.4.4.m1.1a"><mo mathsize="90%" stretchy="false" id="S3.T1.4.4.4.4.m1.1.1" xref="S3.T1.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.4.m1.1b"><ci id="S3.T1.4.4.4.4.m1.1.1.cmml" xref="S3.T1.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T1.4.4.5.1" class="ltx_tr">
<th id="S3.T1.4.4.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S3.T1.4.4.5.1.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Video2RMS</span></th>
<th id="S3.T1.4.4.5.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<td id="S3.T1.4.4.5.1.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.4.4.5.1.4" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.4.4.5.1.5" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T1.4.4.6.2" class="ltx_tr">
<th id="S3.T1.4.4.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.4.4.6.2.1.1" class="ltx_text" style="font-size:90%;">disc. RMS (g.t.)</span></th>
<th id="S3.T1.4.4.6.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.4.4.6.2.2.1" class="ltx_text" style="font-size:90%;">0.00243</span></th>
<td id="S3.T1.4.4.6.2.3" class="ltx_td ltx_align_left"><span id="S3.T1.4.4.6.2.3.1" class="ltx_text" style="font-size:90%;">1</span></td>
<td id="S3.T1.4.4.6.2.4" class="ltx_td ltx_align_left"><span id="S3.T1.4.4.6.2.4.1" class="ltx_text" style="font-size:90%;">1</span></td>
<td id="S3.T1.4.4.6.2.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T1.4.4.6.2.5.1" class="ltx_text" style="font-size:90%;">1</span></td>
</tr>
<tr id="S3.T1.4.4.7.3" class="ltx_tr">
<th id="S3.T1.4.4.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.4.4.7.3.1.1" class="ltx_text" style="font-size:90%;">Video-Foley (Ours)</span></th>
<th id="S3.T1.4.4.7.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.4.4.7.3.2.1" class="ltx_text" style="font-size:90%;">0.0450</span></th>
<td id="S3.T1.4.4.7.3.3" class="ltx_td ltx_align_left"><span id="S3.T1.4.4.7.3.3.1" class="ltx_text" style="font-size:90%;">0.0116</span></td>
<td id="S3.T1.4.4.7.3.4" class="ltx_td ltx_align_left"><span id="S3.T1.4.4.7.3.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.241</span></td>
<td id="S3.T1.4.4.7.3.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T1.4.4.7.3.5.1" class="ltx_text" style="font-size:90%;">0.446</span></td>
</tr>
<tr id="S3.T1.4.4.8.4" class="ltx_tr">
<th id="S3.T1.4.4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.4.4.8.4.1.1" class="ltx_text" style="font-size:90%;">     w/ label smoothing</span></th>
<th id="S3.T1.4.4.8.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T1.4.4.8.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.0431</span></th>
<td id="S3.T1.4.4.8.4.3" class="ltx_td ltx_align_left"><span id="S3.T1.4.4.8.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.0128</span></td>
<td id="S3.T1.4.4.8.4.4" class="ltx_td ltx_align_left"><span id="S3.T1.4.4.8.4.4.1" class="ltx_text" style="font-size:90%;">0.238</span></td>
<td id="S3.T1.4.4.8.4.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T1.4.4.8.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.449</span></td>
</tr>
<tr id="S3.T1.4.4.9.5" class="ltx_tr">
<th id="S3.T1.4.4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S3.T1.4.4.9.5.1.1" class="ltx_text" style="font-size:90%;">random choice (l.b.)</span></th>
<th id="S3.T1.4.4.9.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S3.T1.4.4.9.5.2.1" class="ltx_text" style="font-size:90%;">0.2807</span></th>
<td id="S3.T1.4.4.9.5.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T1.4.4.9.5.3.1" class="ltx_text" style="font-size:90%;">0.0154</span></td>
<td id="S3.T1.4.4.9.5.4" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T1.4.4.9.5.4.1" class="ltx_text" style="font-size:90%;">0.0769</span></td>
<td id="S3.T1.4.4.9.5.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb"><span id="S3.T1.4.4.9.5.5.1" class="ltx_text" style="font-size:90%;">0.154</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.8.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>Performance of Video2RMS module. disc. RMS (g.t.): discretized version of ground-truth RMS, l.b.: lower bound.</figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Objective</span><span id="S3.SS2.p3.1.2" class="ltx_text" style="font-size:90%;">
To measure overall audio quality, Frechet Audio Distance (FAD) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S3.SS2.p3.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.5" class="ltx_text" style="font-size:90%;"> was used, which is a set-wise distance of audios in embedding space.
Given that FAD correlation with human perception is embedding-dependent </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S3.SS2.p3.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.8" class="ltx_text" style="font-size:90%;">, we used pretrained PANNs wavegram-log-mel </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.9.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S3.SS2.p3.1.10.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.11" class="ltx_text" style="font-size:90%;"> and CLAP from Microsoft </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.12.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib13" title="" class="ltx_ref">13</a><span id="S3.SS2.p3.1.13.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.14" class="ltx_text" style="font-size:90%;"> to extract embeddings through </span><span id="S3.SS2.p3.1.15" class="ltx_text ltx_font_italic" style="font-size:90%;">fadtk<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span id="footnote2.1.1.1" class="ltx_text ltx_font_upright" style="font-size:111%;">2</span></span><a target="_blank" href="https://github.com/DCASE2024-Task7-Sound-Scene-Synthesis/fadtk" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" style="font-size:111%;">https://github.com/DCASE2024-Task7-Sound-Scene-Synthesis/fadtk</a></span></span></span></span><span id="S3.SS2.p3.1.16" class="ltx_text" style="font-size:90%;">.
To measure the semantic alignment between audio and video, FAVD </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.17.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S3.SS2.p3.1.18.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.19" class="ltx_text" style="font-size:90%;"> was used, which is the Frechet distance of concatenated video and audio embeddings. Pretrained VGGish </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.20.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S3.SS2.p3.1.21.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.22" class="ltx_text" style="font-size:90%;"> and I3D </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.23.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S3.SS2.p3.1.24.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.25" class="ltx_text" style="font-size:90%;"> were used for audio and video embeddings, respectively.
Additionally, the CLAP </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.26.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S3.SS2.p3.1.27.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.28" class="ltx_text" style="font-size:90%;"> score was calculated by measuring the cosine distance between the generated and ground-truth audio in the joint text-audio embedding space.</span><span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Note that this CLAP model is from LAION, which differs from the Microsoft model used in AudioLDM.</span></span></span><span id="S3.SS2.p3.1.29" class="ltx_text" style="font-size:90%;">
Lastly, we used E-L1, the L1 distance between the continuous RMS values of the generated and ground-truth audio as proposed in T-Foley </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.30.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S3.SS2.p3.1.31.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.32" class="ltx_text" style="font-size:90%;">, to measure the temporal synchrony of audio and video.
For RMS2Sound, all metrics except FAVD were used. E-L1 and class-wise accuracy at k (k=1, 5, 10) measured the RMS prediction performance of Video2RMS, excluding frames where both the ground truth and prediction are silent similar to the previous study </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p3.1.33.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S3.SS2.p3.1.34.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p3.1.35" class="ltx_text" style="font-size:90%;">. This exclusion is necessary because only a small portion of frames in audio are non-silent for hit/scratch actions, making it easier for the model to predict silence and thus failing to effectively capture the performance in non-silent frames.</span></p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Subjective</span><span id="S3.SS2.p4.1.2" class="ltx_text" style="font-size:90%;">
We conducted a human evaluation to assess the perceptual quality of the generated audio in relation to the input video. 20 participants were asked to score the audio on a five-point Likert scale based on four criteria: Material / Action / Temporal Alignment, and Audio Quality. Semantic Alignment was divided into two categories to evaluate how well the sound matches the material type and action nuance of the sound events in the video. The Mean Opinion Score (MOS) and its 95% confidence interval were calculated.
The evaluation survey consisted of 12 questions covering different material-action types.
Since CondFoleyGen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p4.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S3.SS2.p4.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p4.1.5" class="ltx_text" style="font-size:90%;"> does not support text prompts, we used audio prompts for the other models to ensure a fair comparison.</span></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Result</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Analysis on Video2RMS and RMS2Sound</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Table </span><a href="#S3.T1" title="Table 1 ‣ 3.2 Evaluation ‣ 3 Experiments ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S4.SS1.p1.1.2" class="ltx_text" style="font-size:90%;"> demonstrates the performance of the Video2RMS model.
The model successfully predicts the RMS curve from the video, given the scores of discretized ground-truth RMS (upper bound due to information loss) and random choice (lower bound).
Video2RMS significantly outperforms random choice in accuracy at Acc@5 and Acc@10, indicating that the model accurately predicts bins adjacent to the ground truth, as reflected by the low E-L1 value. Although the model scores lower in accuracy at Acc@1, this is due to its focus on predicting a realistic RMS curve rather than matching the exact magnitude bin.
Label smoothing generally improves performance, enhancing both E-L1 and classification accuracy.</span></p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/rms_ablation_v2r.png" id="S4.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="586" height="404" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/rms_ablation_r2s.png" id="S4.F2.2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="571" height="394" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.9.1.1" class="ltx_text ltx_font_bold">Fig. 2</span>: </span>Performance of Video2RMS (left) and RMS2Sound (right) for different numbers of RMS bins. w/o_rms: without RMS condition (Text-to-Audio<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>), cont.: continuous RMS, no discretization.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.38" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:405.2pt;height:170.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-96.1pt,40.5pt) scale(0.678362630917123,0.678362630917123) ;">
<table id="S4.T2.38.38" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.38.38.39.1" class="ltx_tr">
<th id="S4.T2.38.38.39.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T2.38.38.39.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S4.T2.38.38.39.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3"><span id="S4.T2.38.38.39.1.2.1" class="ltx_text" style="font-size:90%;">Audio Quality</span></th>
<th id="S4.T2.38.38.39.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S4.T2.38.38.39.1.3.1" class="ltx_text" style="font-size:90%;">Temporal Alignment</span></th>
<th id="S4.T2.38.38.39.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S4.T2.38.38.39.1.4.1" class="ltx_text" style="font-size:90%;">Semantic Alignment</span></th>
</tr>
<tr id="S4.T2.7.7.7" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.T2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">FAD-P </span><math id="S4.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.1.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.T2.2.2.2.2.1" class="ltx_text" style="font-size:90%;">FAD-C </span><math id="S4.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.2.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T2.7.7.7.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S4.T2.7.7.7.8.1" class="ltx_text" style="font-size:90%;">MOS</span></th>
<th id="S4.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.T2.3.3.3.3.1" class="ltx_text" style="font-size:90%;">E-L1 </span><math id="S4.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.3.3.3.3.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T2.3.3.3.3.m1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><ci id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T2.7.7.7.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S4.T2.7.7.7.9.1" class="ltx_text" style="font-size:90%;">MOS</span></th>
<th id="S4.T2.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.T2.4.4.4.4.1" class="ltx_text" style="font-size:90%;">CLAP </span><math id="S4.T2.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.4.4.4.4.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T2.4.4.4.4.m1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.m1.1b"><ci id="S4.T2.4.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S4.T2.5.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.T2.5.5.5.5.1" class="ltx_text" style="font-size:90%;">FAVD </span><math id="S4.T2.5.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.5.5.5.5.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T2.5.5.5.5.m1.1.1" xref="S4.T2.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.5.m1.1b"><ci id="S4.T2.5.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.5.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T2.6.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.T2.6.6.6.6.1" class="ltx_text" style="font-size:90%;">MOS</span><sub id="S4.T2.6.6.6.6.2" class="ltx_sub"><span id="S4.T2.6.6.6.6.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">material</span></sub>
</th>
<th id="S4.T2.7.7.7.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.T2.7.7.7.7.1" class="ltx_text" style="font-size:90%;">MOS</span><sub id="S4.T2.7.7.7.7.2" class="ltx_sub"><span id="S4.T2.7.7.7.7.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">action</span></sub>
</th>
</tr>
<tr id="S4.T2.11.11.11" class="ltx_tr">
<th id="S4.T2.11.11.11.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.11.11.5.1" class="ltx_text" style="font-size:90%;">Ground Truth</span></th>
<th id="S4.T2.11.11.11.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.11.11.6.1" class="ltx_text" style="font-size:90%;">0</span></th>
<th id="S4.T2.11.11.11.7" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.11.11.7.1" class="ltx_text" style="font-size:90%;">0</span></th>
<th id="S4.T2.8.8.8.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">
<span id="S4.T2.8.8.8.1.2" class="ltx_text" style="font-size:90%;">4.57</span><span id="S4.T2.8.8.8.1.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.8.8.8.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.8.8.8.1.1.m1.1a"><mo id="S4.T2.8.8.8.1.1.m1.1.1" xref="S4.T2.8.8.8.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.8.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.8.8.8.1.1.m1.1.1.cmml" xref="S4.T2.8.8.8.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.8.1.1.m1.1c">\pm</annotation></semantics></math>0.08)</span>
</th>
<th id="S4.T2.11.11.11.8" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.11.11.8.1" class="ltx_text" style="font-size:90%;">0</span></th>
<th id="S4.T2.9.9.9.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">
<span id="S4.T2.9.9.9.2.2" class="ltx_text" style="font-size:90%;">4.83</span><span id="S4.T2.9.9.9.2.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.9.9.9.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.9.9.9.2.1.m1.1a"><mo id="S4.T2.9.9.9.2.1.m1.1.1" xref="S4.T2.9.9.9.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.9.2.1.m1.1b"><csymbol cd="latexml" id="S4.T2.9.9.9.2.1.m1.1.1.cmml" xref="S4.T2.9.9.9.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.9.2.1.m1.1c">\pm</annotation></semantics></math>0.06)</span>
</th>
<th id="S4.T2.11.11.11.9" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.11.11.9.1" class="ltx_text" style="font-size:90%;">1</span></th>
<th id="S4.T2.11.11.11.10" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.11.11.11.10.1" class="ltx_text" style="font-size:90%;">0</span></th>
<th id="S4.T2.10.10.10.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">
<span id="S4.T2.10.10.10.3.2" class="ltx_text" style="font-size:90%;">4.70</span><span id="S4.T2.10.10.10.3.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.10.10.10.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.10.10.10.3.1.m1.1a"><mo id="S4.T2.10.10.10.3.1.m1.1.1" xref="S4.T2.10.10.10.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.10.3.1.m1.1b"><csymbol cd="latexml" id="S4.T2.10.10.10.3.1.m1.1.1.cmml" xref="S4.T2.10.10.10.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.10.3.1.m1.1c">\pm</annotation></semantics></math>0.08)</span>
</th>
<th id="S4.T2.11.11.11.4" class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_t">
<span id="S4.T2.11.11.11.4.2" class="ltx_text" style="font-size:90%;">4.90</span><span id="S4.T2.11.11.11.4.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.11.11.11.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.11.11.11.4.1.m1.1a"><mo id="S4.T2.11.11.11.4.1.m1.1.1" xref="S4.T2.11.11.11.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.11.4.1.m1.1b"><csymbol cd="latexml" id="S4.T2.11.11.11.4.1.m1.1.1.cmml" xref="S4.T2.11.11.11.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.11.4.1.m1.1c">\pm</annotation></semantics></math>0.04)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.38.38.40.1" class="ltx_tr">
<td id="S4.T2.38.38.40.1.1" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T2.38.38.40.1.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">No Prompt</span></td>
<td id="S4.T2.38.38.40.1.2" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.38.38.40.1.3" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.38.38.40.1.4" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.38.38.40.1.5" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.38.38.40.1.6" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.38.38.40.1.7" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.38.38.40.1.8" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.38.38.40.1.9" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.38.38.40.1.10" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S4.T2.12.12.12" class="ltx_tr">
<td id="S4.T2.12.12.12.1" class="ltx_td ltx_align_right">
<span id="S4.T2.12.12.12.1.1" class="ltx_text" style="font-size:90%;">SpecVQGAN</span><sup id="S4.T2.12.12.12.1.2" class="ltx_sup"><span id="S4.T2.12.12.12.1.2.1" class="ltx_text" style="font-size:90%;">†</span></sup><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.12.12.12.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S4.T2.12.12.12.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.12.12.12.2" class="ltx_td ltx_align_right"><span id="S4.T2.12.12.12.2.1" class="ltx_text" style="font-size:90%;">101.0</span></td>
<td id="S4.T2.12.12.12.3" class="ltx_td ltx_align_right"><span id="S4.T2.12.12.12.3.1" class="ltx_text" style="font-size:90%;">579</span></td>
<td id="S4.T2.12.12.12.4" class="ltx_td ltx_align_right"><span id="S4.T2.12.12.12.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.12.12.12.5" class="ltx_td ltx_align_right"><span id="S4.T2.12.12.12.5.1" class="ltx_text" style="font-size:90%;">0.0230</span></td>
<td id="S4.T2.12.12.12.6" class="ltx_td ltx_align_right"><span id="S4.T2.12.12.12.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.12.12.12.7" class="ltx_td ltx_align_right"><span id="S4.T2.12.12.12.7.1" class="ltx_text" style="font-size:90%;">0.323</span></td>
<td id="S4.T2.12.12.12.8" class="ltx_td ltx_align_right"><span id="S4.T2.12.12.12.8.1" class="ltx_text" style="font-size:90%;">6.42</span></td>
<td id="S4.T2.12.12.12.9" class="ltx_td ltx_align_right"><span id="S4.T2.12.12.12.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.12.12.12.10" class="ltx_td ltx_nopad_r ltx_align_right"><span id="S4.T2.12.12.12.10.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T2.17.17.17" class="ltx_tr">
<td id="S4.T2.13.13.13.1" class="ltx_td ltx_align_right">
<span id="S4.T2.13.13.13.1.1" class="ltx_text" style="font-size:90%;">Diff-Foley</span><sup id="S4.T2.13.13.13.1.2" class="ltx_sup"><span id="S4.T2.13.13.13.1.2.1" class="ltx_text" style="font-size:90%;">‡</span></sup><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.13.13.13.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S4.T2.13.13.13.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.17.17.17.6" class="ltx_td ltx_align_right"><span id="S4.T2.17.17.17.6.1" class="ltx_text" style="font-size:90%;">87.0</span></td>
<td id="S4.T2.17.17.17.7" class="ltx_td ltx_align_right"><span id="S4.T2.17.17.17.7.1" class="ltx_text" style="font-size:90%;">550</span></td>
<td id="S4.T2.14.14.14.2" class="ltx_td ltx_align_right">
<span id="S4.T2.14.14.14.2.2" class="ltx_text" style="font-size:90%;">2.11</span><span id="S4.T2.14.14.14.2.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.14.14.14.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.14.14.14.2.1.m1.1a"><mo id="S4.T2.14.14.14.2.1.m1.1.1" xref="S4.T2.14.14.14.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.14.2.1.m1.1b"><csymbol cd="latexml" id="S4.T2.14.14.14.2.1.m1.1.1.cmml" xref="S4.T2.14.14.14.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.14.2.1.m1.1c">\pm</annotation></semantics></math>0.11)</span>
</td>
<td id="S4.T2.17.17.17.8" class="ltx_td ltx_align_right"><span id="S4.T2.17.17.17.8.1" class="ltx_text" style="font-size:90%;">0.0291</span></td>
<td id="S4.T2.15.15.15.3" class="ltx_td ltx_align_right">
<span id="S4.T2.15.15.15.3.2" class="ltx_text" style="font-size:90%;">1.86</span><span id="S4.T2.15.15.15.3.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.15.15.15.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.15.15.15.3.1.m1.1a"><mo id="S4.T2.15.15.15.3.1.m1.1.1" xref="S4.T2.15.15.15.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.15.3.1.m1.1b"><csymbol cd="latexml" id="S4.T2.15.15.15.3.1.m1.1.1.cmml" xref="S4.T2.15.15.15.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.15.3.1.m1.1c">\pm</annotation></semantics></math>0.14)</span>
</td>
<td id="S4.T2.17.17.17.9" class="ltx_td ltx_align_right"><span id="S4.T2.17.17.17.9.1" class="ltx_text" style="font-size:90%;">0.403</span></td>
<td id="S4.T2.17.17.17.10" class="ltx_td ltx_align_right"><span id="S4.T2.17.17.17.10.1" class="ltx_text" style="font-size:90%;">4.61</span></td>
<td id="S4.T2.16.16.16.4" class="ltx_td ltx_align_right">
<span id="S4.T2.16.16.16.4.2" class="ltx_text" style="font-size:90%;">1.78</span><span id="S4.T2.16.16.16.4.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.16.16.16.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.16.16.16.4.1.m1.1a"><mo id="S4.T2.16.16.16.4.1.m1.1.1" xref="S4.T2.16.16.16.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.16.16.16.4.1.m1.1b"><csymbol cd="latexml" id="S4.T2.16.16.16.4.1.m1.1.1.cmml" xref="S4.T2.16.16.16.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.16.16.4.1.m1.1c">\pm</annotation></semantics></math>0.13)</span>
</td>
<td id="S4.T2.17.17.17.5" class="ltx_td ltx_nopad_r ltx_align_right">
<span id="S4.T2.17.17.17.5.2" class="ltx_text" style="font-size:90%;">2.38</span><span id="S4.T2.17.17.17.5.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.17.17.17.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.17.17.17.5.1.m1.1a"><mo id="S4.T2.17.17.17.5.1.m1.1.1" xref="S4.T2.17.17.17.5.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.17.17.17.5.1.m1.1b"><csymbol cd="latexml" id="S4.T2.17.17.17.5.1.m1.1.1.cmml" xref="S4.T2.17.17.17.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.17.17.17.5.1.m1.1c">\pm</annotation></semantics></math>0.17)</span>
</td>
</tr>
<tr id="S4.T2.38.38.41.2" class="ltx_tr">
<td id="S4.T2.38.38.41.2.1" class="ltx_td ltx_align_right"><span id="S4.T2.38.38.41.2.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Audio Prompt</span></td>
<td id="S4.T2.38.38.41.2.2" class="ltx_td"></td>
<td id="S4.T2.38.38.41.2.3" class="ltx_td"></td>
<td id="S4.T2.38.38.41.2.4" class="ltx_td"></td>
<td id="S4.T2.38.38.41.2.5" class="ltx_td"></td>
<td id="S4.T2.38.38.41.2.6" class="ltx_td"></td>
<td id="S4.T2.38.38.41.2.7" class="ltx_td"></td>
<td id="S4.T2.38.38.41.2.8" class="ltx_td"></td>
<td id="S4.T2.38.38.41.2.9" class="ltx_td"></td>
<td id="S4.T2.38.38.41.2.10" class="ltx_td"></td>
</tr>
<tr id="S4.T2.22.22.22" class="ltx_tr">
<td id="S4.T2.18.18.18.1" class="ltx_td ltx_align_right">
<span id="S4.T2.18.18.18.1.1" class="ltx_text" style="font-size:90%;">CondFoleyGen</span><sup id="S4.T2.18.18.18.1.2" class="ltx_sup"><span id="S4.T2.18.18.18.1.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">av</span></sup><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.18.18.18.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S4.T2.18.18.18.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.22.22.22.6" class="ltx_td ltx_align_right"><span id="S4.T2.22.22.22.6.1" class="ltx_text" style="font-size:90%;">42.2</span></td>
<td id="S4.T2.22.22.22.7" class="ltx_td ltx_align_right"><span id="S4.T2.22.22.22.7.1" class="ltx_text" style="font-size:90%;">381</span></td>
<td id="S4.T2.19.19.19.2" class="ltx_td ltx_align_right">
<span id="S4.T2.19.19.19.2.2" class="ltx_text" style="font-size:90%;">3.10</span><span id="S4.T2.19.19.19.2.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.19.19.19.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.19.19.19.2.1.m1.1a"><mo id="S4.T2.19.19.19.2.1.m1.1.1" xref="S4.T2.19.19.19.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.19.19.19.2.1.m1.1b"><csymbol cd="latexml" id="S4.T2.19.19.19.2.1.m1.1.1.cmml" xref="S4.T2.19.19.19.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.19.19.19.2.1.m1.1c">\pm</annotation></semantics></math>0.13)</span>
</td>
<td id="S4.T2.22.22.22.8" class="ltx_td ltx_align_right"><span id="S4.T2.22.22.22.8.1" class="ltx_text" style="font-size:90%;">0.0238</span></td>
<td id="S4.T2.20.20.20.3" class="ltx_td ltx_align_right">
<span id="S4.T2.20.20.20.3.2" class="ltx_text" style="font-size:90%;">1.93</span><span id="S4.T2.20.20.20.3.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.20.20.20.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.20.20.20.3.1.m1.1a"><mo id="S4.T2.20.20.20.3.1.m1.1.1" xref="S4.T2.20.20.20.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.20.20.20.3.1.m1.1b"><csymbol cd="latexml" id="S4.T2.20.20.20.3.1.m1.1.1.cmml" xref="S4.T2.20.20.20.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.20.20.20.3.1.m1.1c">\pm</annotation></semantics></math>0.13)</span>
</td>
<td id="S4.T2.22.22.22.9" class="ltx_td ltx_align_right"><span id="S4.T2.22.22.22.9.1" class="ltx_text" style="font-size:90%;">0.572</span></td>
<td id="S4.T2.22.22.22.10" class="ltx_td ltx_align_right"><span id="S4.T2.22.22.22.10.1" class="ltx_text" style="font-size:90%;">1.01</span></td>
<td id="S4.T2.21.21.21.4" class="ltx_td ltx_align_right">
<span id="S4.T2.21.21.21.4.2" class="ltx_text" style="font-size:90%;">2.36</span><span id="S4.T2.21.21.21.4.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.21.21.21.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.21.21.21.4.1.m1.1a"><mo id="S4.T2.21.21.21.4.1.m1.1.1" xref="S4.T2.21.21.21.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.21.21.21.4.1.m1.1b"><csymbol cd="latexml" id="S4.T2.21.21.21.4.1.m1.1.1.cmml" xref="S4.T2.21.21.21.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.21.21.21.4.1.m1.1c">\pm</annotation></semantics></math>0.16)</span>
</td>
<td id="S4.T2.22.22.22.5" class="ltx_td ltx_nopad_r ltx_align_right">
<span id="S4.T2.22.22.22.5.2" class="ltx_text" style="font-size:90%;">2.79</span><span id="S4.T2.22.22.22.5.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.22.22.22.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.22.22.22.5.1.m1.1a"><mo id="S4.T2.22.22.22.5.1.m1.1.1" xref="S4.T2.22.22.22.5.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.22.22.22.5.1.m1.1b"><csymbol cd="latexml" id="S4.T2.22.22.22.5.1.m1.1.1.cmml" xref="S4.T2.22.22.22.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.22.22.22.5.1.m1.1c">\pm</annotation></semantics></math>0.17)</span>
</td>
</tr>
<tr id="S4.T2.27.27.27" class="ltx_tr">
<td id="S4.T2.27.27.27.6" class="ltx_td ltx_align_right">
<span id="S4.T2.27.27.27.6.1" class="ltx_text" style="font-size:90%;">SyncFusion</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.27.27.27.6.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S4.T2.27.27.27.6.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.27.27.27.7" class="ltx_td ltx_align_right"><span id="S4.T2.27.27.27.7.1" class="ltx_text" style="font-size:90%;">65.9</span></td>
<td id="S4.T2.27.27.27.8" class="ltx_td ltx_align_right"><span id="S4.T2.27.27.27.8.1" class="ltx_text" style="font-size:90%;">335</span></td>
<td id="S4.T2.23.23.23.1" class="ltx_td ltx_align_right">
<span id="S4.T2.23.23.23.1.2" class="ltx_text" style="font-size:90%;">3.10</span><span id="S4.T2.23.23.23.1.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.23.23.23.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.23.23.23.1.1.m1.1a"><mo id="S4.T2.23.23.23.1.1.m1.1.1" xref="S4.T2.23.23.23.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.23.23.23.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.23.23.23.1.1.m1.1.1.cmml" xref="S4.T2.23.23.23.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.23.23.23.1.1.m1.1c">\pm</annotation></semantics></math>0.13)</span>
</td>
<td id="S4.T2.27.27.27.9" class="ltx_td ltx_align_right"><span id="S4.T2.27.27.27.9.1" class="ltx_text" style="font-size:90%;">0.0239</span></td>
<td id="S4.T2.24.24.24.2" class="ltx_td ltx_align_right">
<span id="S4.T2.24.24.24.2.2" class="ltx_text" style="font-size:90%;">3.10</span><span id="S4.T2.24.24.24.2.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.24.24.24.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.24.24.24.2.1.m1.1a"><mo id="S4.T2.24.24.24.2.1.m1.1.1" xref="S4.T2.24.24.24.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.24.24.24.2.1.m1.1b"><csymbol cd="latexml" id="S4.T2.24.24.24.2.1.m1.1.1.cmml" xref="S4.T2.24.24.24.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.24.24.24.2.1.m1.1c">\pm</annotation></semantics></math>0.19)</span>
</td>
<td id="S4.T2.25.25.25.3" class="ltx_td ltx_align_right">
<sup id="S4.T2.25.25.25.3.1" class="ltx_sup"><span id="S4.T2.25.25.25.3.1.1" class="ltx_text" style="font-size:90%;">+</span></sup><span id="S4.T2.25.25.25.3.2" class="ltx_text" style="font-size:90%;">0.631</span>
</td>
<td id="S4.T2.27.27.27.10" class="ltx_td ltx_align_right"><span id="S4.T2.27.27.27.10.1" class="ltx_text" style="font-size:90%;">4.50</span></td>
<td id="S4.T2.26.26.26.4" class="ltx_td ltx_align_right">
<span id="S4.T2.26.26.26.4.2" class="ltx_text" style="font-size:90%;">3.04</span><span id="S4.T2.26.26.26.4.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.26.26.26.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.26.26.26.4.1.m1.1a"><mo id="S4.T2.26.26.26.4.1.m1.1.1" xref="S4.T2.26.26.26.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.26.26.26.4.1.m1.1b"><csymbol cd="latexml" id="S4.T2.26.26.26.4.1.m1.1.1.cmml" xref="S4.T2.26.26.26.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.26.26.26.4.1.m1.1c">\pm</annotation></semantics></math>0.18)</span>
</td>
<td id="S4.T2.27.27.27.5" class="ltx_td ltx_nopad_r ltx_align_right">
<span id="S4.T2.27.27.27.5.2" class="ltx_text" style="font-size:90%;">3.22</span><span id="S4.T2.27.27.27.5.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.27.27.27.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.27.27.27.5.1.m1.1a"><mo id="S4.T2.27.27.27.5.1.m1.1.1" xref="S4.T2.27.27.27.5.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.27.27.27.5.1.m1.1b"><csymbol cd="latexml" id="S4.T2.27.27.27.5.1.m1.1.1.cmml" xref="S4.T2.27.27.27.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.27.27.27.5.1.m1.1c">\pm</annotation></semantics></math>0.19)</span>
</td>
</tr>
<tr id="S4.T2.32.32.32" class="ltx_tr">
<td id="S4.T2.28.28.28.1" class="ltx_td ltx_align_right">
<span id="S4.T2.28.28.28.1.1" class="ltx_text" style="font-size:90%;">Video-Foley</span><sup id="S4.T2.28.28.28.1.2" class="ltx_sup"><span id="S4.T2.28.28.28.1.2.1" class="ltx_text" style="font-size:90%;">⋆</span></sup><span id="S4.T2.28.28.28.1.3" class="ltx_text" style="font-size:90%;"> (Ours)</span>
</td>
<td id="S4.T2.32.32.32.6" class="ltx_td ltx_align_right"><span id="S4.T2.32.32.32.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">27.2</span></td>
<td id="S4.T2.32.32.32.7" class="ltx_td ltx_align_right"><span id="S4.T2.32.32.32.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">187</span></td>
<td id="S4.T2.29.29.29.2" class="ltx_td ltx_align_right"><span id="S4.T2.29.29.29.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.93<span id="S4.T2.29.29.29.2.1.1" class="ltx_text" style="font-size:78%;">(<math id="S4.T2.29.29.29.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.29.29.29.2.1.1.m1.1a"><mo id="S4.T2.29.29.29.2.1.1.m1.1.1" xref="S4.T2.29.29.29.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.29.29.29.2.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.29.29.29.2.1.1.m1.1.1.cmml" xref="S4.T2.29.29.29.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.29.29.29.2.1.1.m1.1c">\pm</annotation></semantics></math>0.12)</span></span></td>
<td id="S4.T2.32.32.32.8" class="ltx_td ltx_align_right"><span id="S4.T2.32.32.32.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.0090</span></td>
<td id="S4.T2.30.30.30.3" class="ltx_td ltx_align_right"><span id="S4.T2.30.30.30.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.40<span id="S4.T2.30.30.30.3.1.1" class="ltx_text" style="font-size:78%;">(<math id="S4.T2.30.30.30.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.30.30.30.3.1.1.m1.1a"><mo id="S4.T2.30.30.30.3.1.1.m1.1.1" xref="S4.T2.30.30.30.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.30.30.30.3.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.30.30.30.3.1.1.m1.1.1.cmml" xref="S4.T2.30.30.30.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.30.30.30.3.1.1.m1.1c">\pm</annotation></semantics></math>0.11)</span></span></td>
<td id="S4.T2.32.32.32.9" class="ltx_td ltx_align_right"><span id="S4.T2.32.32.32.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.644</span></td>
<td id="S4.T2.32.32.32.10" class="ltx_td ltx_align_right"><span id="S4.T2.32.32.32.10.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.80</span></td>
<td id="S4.T2.31.31.31.4" class="ltx_td ltx_align_right"><span id="S4.T2.31.31.31.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.83<span id="S4.T2.31.31.31.4.1.1" class="ltx_text" style="font-size:78%;">(<math id="S4.T2.31.31.31.4.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.31.31.31.4.1.1.m1.1a"><mo id="S4.T2.31.31.31.4.1.1.m1.1.1" xref="S4.T2.31.31.31.4.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.31.31.31.4.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.31.31.31.4.1.1.m1.1.1.cmml" xref="S4.T2.31.31.31.4.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.31.31.31.4.1.1.m1.1c">\pm</annotation></semantics></math>0.15)</span></span></td>
<td id="S4.T2.32.32.32.5" class="ltx_td ltx_nopad_r ltx_align_right"><span id="S4.T2.32.32.32.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.56<span id="S4.T2.32.32.32.5.1.1" class="ltx_text" style="font-size:78%;">(<math id="S4.T2.32.32.32.5.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.32.32.32.5.1.1.m1.1a"><mo id="S4.T2.32.32.32.5.1.1.m1.1.1" xref="S4.T2.32.32.32.5.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.32.32.32.5.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.32.32.32.5.1.1.m1.1.1.cmml" xref="S4.T2.32.32.32.5.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.32.32.32.5.1.1.m1.1c">\pm</annotation></semantics></math>0.08)</span></span></td>
</tr>
<tr id="S4.T2.38.38.42.3" class="ltx_tr">
<td id="S4.T2.38.38.42.3.1" class="ltx_td ltx_align_right"><span id="S4.T2.38.38.42.3.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Text Prompt</span></td>
<td id="S4.T2.38.38.42.3.2" class="ltx_td"></td>
<td id="S4.T2.38.38.42.3.3" class="ltx_td"></td>
<td id="S4.T2.38.38.42.3.4" class="ltx_td"></td>
<td id="S4.T2.38.38.42.3.5" class="ltx_td"></td>
<td id="S4.T2.38.38.42.3.6" class="ltx_td"></td>
<td id="S4.T2.38.38.42.3.7" class="ltx_td"></td>
<td id="S4.T2.38.38.42.3.8" class="ltx_td"></td>
<td id="S4.T2.38.38.42.3.9" class="ltx_td"></td>
<td id="S4.T2.38.38.42.3.10" class="ltx_td"></td>
</tr>
<tr id="S4.T2.33.33.33" class="ltx_tr">
<td id="S4.T2.33.33.33.2" class="ltx_td ltx_align_right">
<span id="S4.T2.33.33.33.2.1" class="ltx_text" style="font-size:90%;">SyncFusion</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.33.33.33.2.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S4.T2.33.33.33.2.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.33.33.33.3" class="ltx_td ltx_align_right"><span id="S4.T2.33.33.33.3.1" class="ltx_text" style="font-size:90%;">81.6</span></td>
<td id="S4.T2.33.33.33.4" class="ltx_td ltx_align_right"><span id="S4.T2.33.33.33.4.1" class="ltx_text" style="font-size:90%;">424</span></td>
<td id="S4.T2.33.33.33.5" class="ltx_td ltx_align_right"><span id="S4.T2.33.33.33.5.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.33.33.33.6" class="ltx_td ltx_align_right"><span id="S4.T2.33.33.33.6.1" class="ltx_text" style="font-size:90%;">0.0292</span></td>
<td id="S4.T2.33.33.33.7" class="ltx_td ltx_align_right"><span id="S4.T2.33.33.33.7.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.33.33.33.1" class="ltx_td ltx_align_right">
<sup id="S4.T2.33.33.33.1.1" class="ltx_sup"><span id="S4.T2.33.33.33.1.1.1" class="ltx_text" style="font-size:90%;">+</span></sup><span id="S4.T2.33.33.33.1.2" class="ltx_text" style="font-size:90%;">0.529</span>
</td>
<td id="S4.T2.33.33.33.8" class="ltx_td ltx_align_right"><span id="S4.T2.33.33.33.8.1" class="ltx_text" style="font-size:90%;">5.11</span></td>
<td id="S4.T2.33.33.33.9" class="ltx_td ltx_align_right"><span id="S4.T2.33.33.33.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.33.33.33.10" class="ltx_td ltx_nopad_r ltx_align_right"><span id="S4.T2.33.33.33.10.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T2.34.34.34" class="ltx_tr">
<td id="S4.T2.34.34.34.1" class="ltx_td ltx_align_right">
<span id="S4.T2.34.34.34.1.1" class="ltx_text" style="font-size:90%;">Video-Foley</span><sup id="S4.T2.34.34.34.1.2" class="ltx_sup"><span id="S4.T2.34.34.34.1.2.1" class="ltx_text" style="font-size:90%;">⋆</span></sup><span id="S4.T2.34.34.34.1.3" class="ltx_text" style="font-size:90%;"> (Ours)</span>
</td>
<td id="S4.T2.34.34.34.2" class="ltx_td ltx_align_right"><span id="S4.T2.34.34.34.2.1" class="ltx_text" style="font-size:90%;">66.8</span></td>
<td id="S4.T2.34.34.34.3" class="ltx_td ltx_align_right"><span id="S4.T2.34.34.34.3.1" class="ltx_text" style="font-size:90%;">451</span></td>
<td id="S4.T2.34.34.34.4" class="ltx_td ltx_align_right"><span id="S4.T2.34.34.34.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.34.34.34.5" class="ltx_td ltx_align_right"><span id="S4.T2.34.34.34.5.1" class="ltx_text" style="font-size:90%;">0.0103</span></td>
<td id="S4.T2.34.34.34.6" class="ltx_td ltx_align_right"><span id="S4.T2.34.34.34.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.34.34.34.7" class="ltx_td ltx_align_right"><span id="S4.T2.34.34.34.7.1" class="ltx_text" style="font-size:90%;">0.476</span></td>
<td id="S4.T2.34.34.34.8" class="ltx_td ltx_align_right"><span id="S4.T2.34.34.34.8.1" class="ltx_text" style="font-size:90%;">3.28</span></td>
<td id="S4.T2.34.34.34.9" class="ltx_td ltx_align_right"><span id="S4.T2.34.34.34.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T2.34.34.34.10" class="ltx_td ltx_nopad_r ltx_align_right"><span id="S4.T2.34.34.34.10.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T2.38.38.38" class="ltx_tr">
<td id="S4.T2.38.38.38.5" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">
<span id="S4.T2.38.38.38.5.1" class="ltx_text" style="font-size:90%;">Text-to-Audio</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.38.38.38.5.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="S4.T2.38.38.38.5.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T2.38.38.38.6" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S4.T2.38.38.38.6.1" class="ltx_text" style="font-size:90%;">59.8</span></td>
<td id="S4.T2.38.38.38.7" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S4.T2.38.38.38.7.1" class="ltx_text" style="font-size:90%;">397</span></td>
<td id="S4.T2.35.35.35.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">
<span id="S4.T2.35.35.35.1.2" class="ltx_text" style="font-size:90%;">2.39</span><span id="S4.T2.35.35.35.1.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.35.35.35.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.35.35.35.1.1.m1.1a"><mo id="S4.T2.35.35.35.1.1.m1.1.1" xref="S4.T2.35.35.35.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.35.35.35.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.35.35.35.1.1.m1.1.1.cmml" xref="S4.T2.35.35.35.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.35.35.35.1.1.m1.1c">\pm</annotation></semantics></math>0.13)</span>
</td>
<td id="S4.T2.38.38.38.8" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S4.T2.38.38.38.8.1" class="ltx_text" style="font-size:90%;">0.0217</span></td>
<td id="S4.T2.36.36.36.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">
<span id="S4.T2.36.36.36.2.2" class="ltx_text" style="font-size:90%;">2.00</span><span id="S4.T2.36.36.36.2.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.36.36.36.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.36.36.36.2.1.m1.1a"><mo id="S4.T2.36.36.36.2.1.m1.1.1" xref="S4.T2.36.36.36.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.36.36.36.2.1.m1.1b"><csymbol cd="latexml" id="S4.T2.36.36.36.2.1.m1.1.1.cmml" xref="S4.T2.36.36.36.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.36.36.36.2.1.m1.1c">\pm</annotation></semantics></math>0.13)</span>
</td>
<td id="S4.T2.38.38.38.9" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S4.T2.38.38.38.9.1" class="ltx_text" style="font-size:90%;">0.443</span></td>
<td id="S4.T2.38.38.38.10" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S4.T2.38.38.38.10.1" class="ltx_text" style="font-size:90%;">2.67</span></td>
<td id="S4.T2.37.37.37.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">
<span id="S4.T2.37.37.37.3.2" class="ltx_text" style="font-size:90%;">2.78</span><span id="S4.T2.37.37.37.3.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.37.37.37.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.37.37.37.3.1.m1.1a"><mo id="S4.T2.37.37.37.3.1.m1.1.1" xref="S4.T2.37.37.37.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.37.37.37.3.1.m1.1b"><csymbol cd="latexml" id="S4.T2.37.37.37.3.1.m1.1.1.cmml" xref="S4.T2.37.37.37.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.37.37.37.3.1.m1.1c">\pm</annotation></semantics></math>0.16)</span>
</td>
<td id="S4.T2.38.38.38.4" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb ltx_border_t">
<span id="S4.T2.38.38.38.4.2" class="ltx_text" style="font-size:90%;">3.21</span><span id="S4.T2.38.38.38.4.1" class="ltx_text" style="font-size:70%;">(<math id="S4.T2.38.38.38.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.38.38.38.4.1.m1.1a"><mo id="S4.T2.38.38.38.4.1.m1.1.1" xref="S4.T2.38.38.38.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.38.38.38.4.1.m1.1b"><csymbol cd="latexml" id="S4.T2.38.38.38.4.1.m1.1.1.cmml" xref="S4.T2.38.38.38.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.38.38.38.4.1.m1.1c">\pm</annotation></semantics></math>0.17)</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.82.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>Performance of the proposed Video-Foley and other video-to-sound models on <span id="S4.T2.83.2" class="ltx_text ltx_font_italic">Greatest Hits</span> testset. <math id="S4.T2.48.m1.1" class="ltx_Math" alttext="av" display="inline"><semantics id="S4.T2.48.m1.1b"><mrow id="S4.T2.48.m1.1.1" xref="S4.T2.48.m1.1.1.cmml"><mi id="S4.T2.48.m1.1.1.2" xref="S4.T2.48.m1.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.T2.48.m1.1.1.1" xref="S4.T2.48.m1.1.1.1.cmml">​</mo><mi id="S4.T2.48.m1.1.1.3" xref="S4.T2.48.m1.1.1.3.cmml">v</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.48.m1.1c"><apply id="S4.T2.48.m1.1.1.cmml" xref="S4.T2.48.m1.1.1"><times id="S4.T2.48.m1.1.1.1.cmml" xref="S4.T2.48.m1.1.1.1"></times><ci id="S4.T2.48.m1.1.1.2.cmml" xref="S4.T2.48.m1.1.1.2">𝑎</ci><ci id="S4.T2.48.m1.1.1.3.cmml" xref="S4.T2.48.m1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.48.m1.1d">av</annotation></semantics></math>: audio-video paired prompt used, <sup id="S4.T2.84.3" class="ltx_sup">+</sup>: same CLAP model for train and evaluation. Regarding train data, †: <span id="S4.T2.85.4" class="ltx_text ltx_font_italic">VGGSound</span> (<math id="S4.T2.50.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.50.m3.1b"><mo id="S4.T2.50.m3.1.1" xref="S4.T2.50.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.50.m3.1c"><csymbol cd="latexml" id="S4.T2.50.m3.1.1.cmml" xref="S4.T2.50.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.50.m3.1d">\sim</annotation></semantics></math>0.4k hr), <math id="S4.T2.51.m4.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S4.T2.51.m4.1b"><mo id="S4.T2.51.m4.1.1" xref="S4.T2.51.m4.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S4.T2.51.m4.1c"><ci id="S4.T2.51.m4.1.1.cmml" xref="S4.T2.51.m4.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.51.m4.1d">\ddagger</annotation></semantics></math>: <span id="S4.T2.86.5" class="ltx_text ltx_font_italic">VGGSound, AudioSet</span> (<math id="S4.T2.52.m5.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.52.m5.1b"><mo id="S4.T2.52.m5.1.1" xref="S4.T2.52.m5.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.52.m5.1c"><csymbol cd="latexml" id="S4.T2.52.m5.1.1.cmml" xref="S4.T2.52.m5.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.52.m5.1d">\sim</annotation></semantics></math>1.3k hr), <math id="S4.T2.53.m6.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S4.T2.53.m6.1b"><mo id="S4.T2.53.m6.1.1" xref="S4.T2.53.m6.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="S4.T2.53.m6.1c"><ci id="S4.T2.53.m6.1.1.cmml" xref="S4.T2.53.m6.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.53.m6.1d">\star</annotation></semantics></math>: <span id="S4.T2.87.6" class="ltx_text ltx_font_italic">Greatest Hits</span> trainset for Video2RMS (<math id="S4.T2.54.m7.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.54.m7.1b"><mo id="S4.T2.54.m7.1.1" xref="S4.T2.54.m7.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.54.m7.1c"><csymbol cd="latexml" id="S4.T2.54.m7.1.1.cmml" xref="S4.T2.54.m7.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.54.m7.1d">\sim</annotation></semantics></math>6 hr) and <span id="S4.T2.88.7" class="ltx_text ltx_font_italic">FreeSound</span> dataset for RMS2Sound (<math id="S4.T2.55.m8.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.55.m8.1b"><mo id="S4.T2.55.m8.1.1" xref="S4.T2.55.m8.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.55.m8.1c"><csymbol cd="latexml" id="S4.T2.55.m8.1.1.cmml" xref="S4.T2.55.m8.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.55.m8.1d">\sim</annotation></semantics></math>6k hr), otherwise: <span id="S4.T2.89.8" class="ltx_text ltx_font_italic">Greatest Hits</span> trainset (<math id="S4.T2.56.m9.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T2.56.m9.1b"><mo id="S4.T2.56.m9.1.1" xref="S4.T2.56.m9.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.56.m9.1c"><csymbol cd="latexml" id="S4.T2.56.m9.1.1.cmml" xref="S4.T2.56.m9.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.56.m9.1d">\sim</annotation></semantics></math>6 hr).</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text" style="font-size:90%;">The number of bins for the RMS discretization is a critical parameter that significantly affects both Video2RMS and RMS2Sound. To determine the optimal value, we conducted an ablation study, as presented in Figure </span><a href="#S4.F2" title="Figure 2 ‣ 4.1 Analysis on Video2RMS and RMS2Sound ‣ 4 Result ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S4.SS1.p2.1.2" class="ltx_text" style="font-size:90%;">. In Video2RMS, we identified a trade-off between performance and computational cost, as shown on the left; more bins improve temporal synchrony but require more model parameters. As shown on the right, both temporal alignment performance and audio quality in RMS2Sound saturate after bins greater than 64. At 64 bins, we found no performance drop in the quantitative measures when using discretized RMS instead of continuous RMS.
Therefore, we set the discretization bins to 64. It is worth noting that the vanilla text-to-audio model without RMS conditioning lagged in both E-L1 and FAD metrics. This implies that RMS conditioning, which aligns with the semantics of the given prompt, helps the model generate higher-quality audio, even when the text-to-audio parameters are frozen.</span></p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Analysis on Video-to-Sound</h3>

<figure id="S4.F3" class="ltx_figure">
<div id="S4.F3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:278.4pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-279.7pt,224.1pt) scale(0.382776566309501,0.382776566309501) ;"><img src="/html/2408.11915/assets/Fig/fig_action_B_rms.png" id="S4.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="1254" height="1005" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.5.1.1" class="ltx_text ltx_font_bold">Fig. 3</span>: </span>Controlling timbre and energy transition: Video-Foley generates hit and scratch sounds at desired positions using RMS guidance.</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Quantitative Study</span><span id="S4.SS2.p1.1.2" class="ltx_text" style="font-size:90%;">
Table </span><a href="#S4.T2" title="Table 2 ‣ 4.1 Analysis on Video2RMS and RMS2Sound ‣ 4 Result ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S4.SS2.p1.1.3" class="ltx_text" style="font-size:90%;"> compares the performance of various video-to-sound systems on the GreatestHits test set.
Video-Foley achieved state-of-the-art performance on all objective metrics as well as the human MOS. Notably, it showed a significant performance gap in temporal alignment and semantic material alignment compared to the audio-visual cued model (CondFoleyGen) and the onset-based model (SyncFusion). This suggests the RMS conditioning is superior for video-to-sound generation, because it conveys both timing and intensity dynamics, providing more detailed information than simple timestamps. Furthermore, this temporal feature can imply the timbre and nuance of the sound through its curve shape, complementing the semantic prompt.
Diff-Foley, despite using temporal information for audio-visual joint space training, lagged in performance due to poorer temporal alignment granularity (4fps) and the frequent generation of visually irrelevant sounds, likely caused by noisy in-the-wild training sets.
In every aspect, including audio quality, Video-Foley also outperforms AudioLDM</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p1.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="S4.SS2.p1.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p1.1.6" class="ltx_text" style="font-size:90%;">, the frozen text-to-audio model in RMS2Sound. This suggests that an appropriate RMS condition, well matched with the prompt, can help the model generate higher fidelity audio, consistent with the results in Figure </span><a href="#S4.F2" title="Figure 2 ‣ 4.1 Analysis on Video2RMS and RMS2Sound ‣ 4 Result ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S4.SS2.p1.1.7" class="ltx_text" style="font-size:90%;">.
Video-Foley and SyncFusion, trained exclusively with audio prompts, perform better with audio prompts than text. The complexity of describing multiple sound events over 10 seconds with text versus audio may also contribute to this trend.</span></p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div id="S4.F4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:280pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-277.2pt,223.4pt) scale(0.384925271532663,0.384925271532663) ;"><img src="/html/2408.11915/assets/Fig/fig_intensity_B_rms.png" id="S4.F4.1.g1" class="ltx_graphics ltx_img_landscape" width="1247" height="1005" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.5.1.1" class="ltx_text ltx_font_bold">Fig. 4</span>: </span>Controlling intensity and nuance: Video-Foley predicts different levels and shapes of the RMS curve for each sound event.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Qualitative Study</span><span id="S4.SS2.p2.1.2" class="ltx_text" style="font-size:90%;">
Extensive case studies were conducted to demonstrate the performance and controllability of Video-Foley. Our analysis underscores that the intensity level and energy transition in RMS are often intertwined with the timbre and nuance of sound, consistent with the findings of the previous study</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p2.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S4.SS2.p2.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p2.1.5" class="ltx_text" style="font-size:90%;">. We plot the mel-spectrogram and normalized RMS of the generated audio from each model.
Figure </span><a href="#S4.F3" title="Figure 3 ‣ 4.2 Analysis on Video-to-Sound ‣ 4 Result ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S4.SS2.p2.1.6" class="ltx_text" style="font-size:90%;"> shows the synergy of complex prompts with RMS. Only Video-Foley generates hit or scratch sounds at the right time. Our model can distinguish the timing and type of each sound event through RMS, even for complex audio or text prompts with multiple events. Onset-based models only predict when to make a sound but cannot distinguish different timbres for each event. In contrast, ours can control both the timing and the corresponding timbre by modifying the RMS.
Figure </span><a href="#S4.F4" title="Figure 4 ‣ 4.2 Analysis on Video-to-Sound ‣ 4 Result ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S4.SS2.p2.1.7" class="ltx_text" style="font-size:90%;"> illustrates the controllability and high audio-visual alignment of Video-Foley. Only ours effectively predicts and recommends the appropriate level and transition curve of RMS, ensuring synchronization with the input video. This includes not only timing but also the intensity and nuance of sound events.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text" style="font-size:90%;">We propose Video-Foley, a two-stage video-to-sound model using RMS as a temporal feature. Our quantitative and qualitative studies demonstrate that RMS conditioning enhances both temporal and semantic audio-visual synchrony while ensuring high controllability, due to its synergy with audio or text prompts.
We believe RMS is an effective control feature, as shown in T-Foley</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S5.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.p1.1.4" class="ltx_text" style="font-size:90%;">. Video2RMS may provide an excellent initial condition for creators to shape desired sound.
More case studies and control examples are provided on our accompanying website.
We plan to extend our work to a large-scale, in-the-wild dataset.</span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Keunwoo Choi, Sangshin Oh, Minsung Kang, and Brian McFee,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">“A proposal for foley sound synthesis challenge,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2207.10760</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Peihao Chen, Yang Zhang, Mingkui Tan, Hongdong Xiao, Deng Huang, and Chuang Gan,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">“Generating visually aligned sound from videos,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Image Processing</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, vol. 29, pp. 8292–8302, 2020.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Vladimir Iashin and Esa Rahtu,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">“Taming visually guided sound generation,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The 32st British Machine Vision Virtual Conference</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">. BMVA Press, 2021.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Chenye Cui, Zhou Zhao, Yi Ren, Jinglin Liu, Rongjie Huang, Feiyang Chen, Zhefeng Wang, Baoxing Huai, and Fei Wu,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">“Varietysound: Timbre-controllable video to sound generation via unsupervised information disentanglement,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2023 IEEE International Conference on Acoustics, Speech and Signal Processing</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2023, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Yuexi Du, Ziyang Chen, Justin Salamon, Bryan Russell, and Andrew Owens,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">“Conditional generation of audio from video via foley analogies,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 2426–2436.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Simian Luo, Chuanhao Yan, Chenxu Hu, and Hang Zhao,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">“Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">, vol. 36, 2024.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Marco Comunità, Riccardo F Gramaccioni, Emilian Postolache, Emanuele Rodolà, Danilo Comminiello, and Joshua D Reiss,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">“Syncfusion: Multimodal onset-synchronized video-to-audio foley synthesis,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2024 IEEE International Conference on Acoustics, Speech and Signal Processing</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2024, pp. 936–940.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Zhifeng Xie, Shengye Yu, Qile He, and Mengtian Li,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">“Sonicvisionlm: Playing sound with vision language models,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, 2024, pp. 26866–26875.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Yoonjin Chung*, Junwon Lee*, and Juhan Nam,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">“T-foley: A controllable waveform-domain diffusion model for temporal-event-guided foley sound synthesis,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2024 IEEE International Conference on Acoustics, Speech and Signal Processing</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2024.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Aaron Van Den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu, et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">“Wavenet: A generative model for raw audio,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1609.03499</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, vol. 12, 2016.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Sangeun Kum and Juhan Nam,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">“Joint detection and classification of singing voice melody using convolutional recurrent neural networks,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Applied Sciences</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, vol. 9, no. 7, pp. 1324, 2019.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Sergey Ioffe and Christian Szegedy,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">“Batch normalization: Accelerating deep network training by reducing internal covariate shift,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International conference on machine learning</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">. pmlr, 2015, pp. 448–456.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Benjamin Elizalde, Soham Deshmukh, Mahmoud Al Ismail, and Huaming Wang,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">“Clap learning audio concepts from natural language supervision,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2023 IEEE International Conference on Acoustics, Speech and Signal Processing</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2023, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">“Adding conditional control to text-to-image diffusion models,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 3836–3847.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Andrew Owens, Phillip Isola, Josh McDermott, Antonio Torralba, Edward H Adelson, and William T Freeman,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">“Visually indicated sounds,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, 2016, pp. 2405–2413.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Xinhao Mei, Chutong Meng, Haohe Liu, Qiuqiang Kong, Tom Ko, Chengqi Zhao, Mark D Plumbley, Yuexian Zou, and Wenwu Wang,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">“Wavcaps: A chatgpt-assisted weakly-labelled audio captioning dataset for audio-language multimodal research,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, and Mark D Plumbley,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">“Audioldm: text-to-audio generation with latent diffusion models,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 40th International Conference on Machine Learning</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 21450–21474.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Kevin Kilgour, Mauricio Zuluaga, Dominik Roblek, and Matthew Sharifi,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">“Frechet audio distance: A metric for evaluating music enhancement algorithms,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1812.08466</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Modan Tailleur*, Junwon Lee*, Mathieu Lagrange, Keunwoo Choi, Laurie M Heller, Keisuke Imoto, and Yuki Okamoto,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">“Correlation of frechet audio distance with human perception of environmental audio is embedding dependant,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2024 32nd European Signal Processing Conference (EUSIPCO)</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2024.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Qiuqiang Kong, Yin Cao, Turab Iqbal, Yuxuan Wang, Wenwu Wang, and Mark D Plumbley,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">“Panns: Large-scale pretrained audio neural networks for audio pattern recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:90%;">, vol. 28, pp. 2880–2894, 2020.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Lucas Goncalves, Prashant Mathur, Chandrashekhar Lavania, Metehan Cekic, Marcello Federico, and Kyu J Han,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">“Peavs: Perceptual evaluation of audio-visual synchrony grounded in viewers’ opinion scores,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2404.07336</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Shawn Hershey, Sourish Chaudhuri, Daniel PW Ellis, Jort F Gemmeke, Aren Jansen, R Channing Moore, Manoj Plakal, Devin Platt, Rif A Saurous, Bryan Seybold, et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">“Cnn architectures for large-scale audio classification,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE International Conference on Acoustics, Speech and Signal Processing</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2017, pp. 131–135.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Joao Carreira and Andrew Zisserman,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">“Quo vadis, action recognition? a new model and the kinetics dataset,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, 2017, pp. 6299–6308.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, and Shlomo Dubnov,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">“Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2023 IEEE International Conference on Acoustics, Speech and Signal Processing</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2023, pp. 1–5.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Subjectivity in Onset Annotation</h2>

<figure id="A1.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F5.1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="A1.F5.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:303.5pt;height:175.9pt;vertical-align:-0.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-354.2pt,204.9pt) scale(0.299966307860384,0.299966307860384) ;"><img src="/html/2408.11915/assets/Fig/onset1.png" id="A1.F5.1.1.g1" class="ltx_graphics ltx_img_landscape" width="1396" height="810" alt="Refer to caption">
</span></div>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F5.2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="A1.F5.2.1" class="ltx_inline-block ltx_transformed_outer" style="width:303.5pt;height:175.9pt;vertical-align:-0.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-354.2pt,204.9pt) scale(0.299966307860384,0.299966307860384) ;"><img src="/html/2408.11915/assets/Fig/onset2.png" id="A1.F5.2.1.g1" class="ltx_graphics ltx_img_landscape" width="1396" height="810" alt="Refer to caption">
</span></div>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F5.3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="A1.F5.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:303.5pt;height:175.6pt;vertical-align:-0.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-354.9pt,205.0pt) scale(0.299538445294358,0.299538445294358) ;"><img src="/html/2408.11915/assets/Fig/onset3.png" id="A1.F5.3.1.g1" class="ltx_graphics ltx_img_landscape" width="1398" height="810" alt="Refer to caption">
</span></div>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F5.4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="A1.F5.4.1" class="ltx_inline-block ltx_transformed_outer" style="width:303.5pt;height:175.8pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-155.4pt,89.8pt) scale(0.494027655471815,0.494027655471815) ;"><img src="/html/2408.11915/assets/Fig/onset_dirt_hit.png" id="A1.F5.4.1.g1" class="ltx_graphics ltx_img_landscape" width="846" height="491" alt="Refer to caption">
</span></div>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F5.5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="A1.F5.5.1" class="ltx_inline-block ltx_transformed_outer" style="width:303.5pt;height:172.4pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-161.6pt,91.5pt) scale(0.484342535451375,0.484342535451375) ;"><img src="/html/2408.11915/assets/Fig/onset_water_scratch.png" id="A1.F5.5.1.g1" class="ltx_graphics ltx_img_landscape" width="863" height="491" alt="Refer to caption">
</span></div>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A1.F5.11.1.1" class="ltx_text ltx_font_bold">Fig. 5</span>: </span>Onset annotation examples in <span id="A1.F5.12.2" class="ltx_text ltx_font_italic">Greatest Hits</span> dataset. The blue curve shows the absolute amplitude of the waveform, and the red vertical line indicates the onset annotation timestamp.</figcaption>
</figure>
<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p"><span id="A1.p1.1.1" class="ltx_text" style="font-size:90%;">We emphasize that onset annotation is highly subjective and lacks a systematic approach to define it, affecting the quality of the annotations. For some sound events, such as scratching sounds with multiple adjacent attacks or water, wind, and instrument sounds with slow attacks, it can be challenging to define an onset timestamp that aligns with both the waveform envelope and human perception. In other words, humans may not perceive the sound’s starting point as the moment it actually begins to sonify. This could be critical in video-to-sound generation, where precise temporal synchrony is essential. It could potentially degrade model performance and make timestamp-based evaluation unreliable.
Figure </span><a href="#A1.F5" title="Figure 5 ‣ Appendix A Subjectivity in Onset Annotation ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="A1.p1.1.2" class="ltx_text" style="font-size:90%;"> demonstrates examples from the </span><span id="A1.p1.1.3" class="ltx_text ltx_font_italic" style="font-size:90%;">Greatest Hits</span><span id="A1.p1.1.4" class="ltx_text" style="font-size:90%;"> dataset highlighting the subjectivity of onset annotation. In the dataset, annotations for each sound event are provided, including the onset timestamp, material, action, and reaction. It is important to note that these annotations were manually performed by humans during the dataset’s construction.
Therefore, utilizing onset annotation involves both labor costs and handling subjectivity issues.</span></p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Details in Video-Foley</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Video2RMS</h3>

<section id="A2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">B.1.1 </span>Details</h4>

<div id="A2.SS1.SSS1.p1" class="ltx_para">
<p id="A2.SS1.SSS1.p1.1" class="ltx_p"><span id="A2.SS1.SSS1.p1.1.1" class="ltx_text" style="font-size:90%;">For optical flow extraction, pretrained RAFT (</span><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter ltx_ref_self" style="font-size:90%;">Raft_Large_Weights.C_T_SKHT_V2</span><span id="A2.SS1.SSS1.p1.1.2" class="ltx_text" style="font-size:90%;">) in pytorch was used.</span><span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://pytorch.org/vision/main/models/generated/torchvision.models.optical_flow.raft_large.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://pytorch.org/vision/main/models/generated/torchvision.models.optical_flow.raft_large.html</a></span></span></span><span id="A2.SS1.SSS1.p1.1.3" class="ltx_text" style="font-size:90%;"> The checkpoint was pre-trained on FlyingChairs, FlyingThings3D and finetuned on Sintel.
RMS was calculated from the audio waveform with a 512 window size and a 128 hop length, following the configuration in T-Foley</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A2.SS1.SSS1.p1.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="A2.SS1.SSS1.p1.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A2.SS1.SSS1.p1.1.6" class="ltx_text" style="font-size:90%;">. By padding </span><math id="A2.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="(512-128)/2" display="inline"><semantics id="A2.SS1.SSS1.p1.1.m1.1a"><mrow id="A2.SS1.SSS1.p1.1.m1.1.1" xref="A2.SS1.SSS1.p1.1.m1.1.1.cmml"><mrow id="A2.SS1.SSS1.p1.1.m1.1.1.1.1" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.2" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.cmml"><mn mathsize="90%" id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.2" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.2.cmml">512</mn><mo mathsize="90%" id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.1" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.1.cmml">−</mo><mn mathsize="90%" id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.3" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.3.cmml">128</mn></mrow><mo maxsize="90%" minsize="90%" id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.3" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo maxsize="90%" minsize="90%" stretchy="true" symmetric="true" id="A2.SS1.SSS1.p1.1.m1.1.1.2" xref="A2.SS1.SSS1.p1.1.m1.1.1.2.cmml">/</mo><mn mathsize="90%" id="A2.SS1.SSS1.p1.1.m1.1.1.3" xref="A2.SS1.SSS1.p1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.SSS1.p1.1.m1.1b"><apply id="A2.SS1.SSS1.p1.1.m1.1.1.cmml" xref="A2.SS1.SSS1.p1.1.m1.1.1"><divide id="A2.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="A2.SS1.SSS1.p1.1.m1.1.1.2"></divide><apply id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.cmml" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1"><minus id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.1"></minus><cn type="integer" id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.2">512</cn><cn type="integer" id="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.3.cmml" xref="A2.SS1.SSS1.p1.1.m1.1.1.1.1.1.3">128</cn></apply><cn type="integer" id="A2.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="A2.SS1.SSS1.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.SSS1.p1.1.m1.1c">(512-128)/2</annotation></semantics></math><span id="A2.SS1.SSS1.p1.1.7" class="ltx_text" style="font-size:90%;"> values at both ends of the waveform in reflect mode, we obtained 1250 frames.
The model was trained with a batch size of 512 using Adam optimizer.</span></p>
</div>
</section>
<section id="A2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">B.1.2 </span>Architecture</h4>

<div id="A2.SS1.SSS2.p1" class="ltx_para">
<p id="A2.SS1.SSS2.p1.1" class="ltx_p"><span id="A2.SS1.SSS2.p1.1.1" class="ltx_text" style="font-size:90%;">The model architecture of Video2RMS utilizes a BN-Inception</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A2.SS1.SSS2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib12" title="" class="ltx_ref">12</a><span id="A2.SS1.SSS2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A2.SS1.SSS2.p1.1.4" class="ltx_text" style="font-size:90%;"> network pretrained on ImageNet</span><span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://yjxiong.blob.core.windows.net/models/bn_inception-9f5701afb96c8044.pth" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://yjxiong.blob.core.windows.net/models/bn_inception-9f5701afb96c8044.pth</a></span></span></span><span id="A2.SS1.SSS2.p1.1.5" class="ltx_text" style="font-size:90%;">, 1D-convolutional blocks, Bi-LSTM layers, and a linear projection head. A similar architecture has been used in RegNet</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A2.SS1.SSS2.p1.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="A2.SS1.SSS2.p1.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A2.SS1.SSS2.p1.1.8" class="ltx_text" style="font-size:90%;">, but it served as a hidden embedding extractor for the GAN generator. VarietySound</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A2.SS1.SSS2.p1.1.9.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="A2.SS1.SSS2.p1.1.10.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A2.SS1.SSS2.p1.1.11" class="ltx_text" style="font-size:90%;"> also employed a similar architecture to extract temporal features, but only used RGB images as input. SpecVQGAN</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A2.SS1.SSS2.p1.1.12.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="A2.SS1.SSS2.p1.1.13.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A2.SS1.SSS2.p1.1.14" class="ltx_text" style="font-size:90%;"> experimented with both pretrained BN-Inception (using RGB images and optical flow input) and ResNet (using RGB images input) to extract the conditioning features for the transformer generator. However, none of these models were explicitly trained by their final output nor used for classification. Additionally, the input video frame rate for these models was 21.5 fps, whereas ours is 30 fps, matching the commercial standard.</span></p>
</div>
<div id="A2.SS1.SSS2.p2" class="ltx_para">
<p id="A2.SS1.SSS2.p2.1" class="ltx_p"><span id="A2.SS1.SSS2.p2.1.1" class="ltx_text" style="font-size:90%;">Onset/offset detection models</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A2.SS1.SSS2.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="A2.SS1.SSS2.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A2.SS1.SSS2.p2.1.4" class="ltx_text" style="font-size:90%;"> perform binary classification for each video frame, typically utilizing a ResNet(2+1)D network followed by an MLP layer. These models use RGB images as input and do not incorporate optical flow. Moreover, the ResNet(2+1)D network is trained, while our pretrained BN-Inception is frozen. Lastly, their video frame rate is significantly lower (15 fps) compared to ours.</span></p>
</div>
</section>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>RMS2Sound</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p"><span id="A2.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">We utilize the </span><span id="A2.SS2.p1.1.2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">‘audioldm-s-full’</span><span id="A2.SS2.p1.1.3" class="ltx_text" style="font-size:90%;"> checkpoint from the official repository. To maintain training consistency, we adhere to the original AudioLDM configuration (e.g. audio normalization).
The window length and hop length are set to 1024 and 160, respectively.
By padding </span><math id="A2.SS2.p1.1.m1.1" class="ltx_Math" alttext="(1024-160)/2" display="inline"><semantics id="A2.SS2.p1.1.m1.1a"><mrow id="A2.SS2.p1.1.m1.1.1" xref="A2.SS2.p1.1.m1.1.1.cmml"><mrow id="A2.SS2.p1.1.m1.1.1.1.1" xref="A2.SS2.p1.1.m1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="A2.SS2.p1.1.m1.1.1.1.1.2" xref="A2.SS2.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A2.SS2.p1.1.m1.1.1.1.1.1" xref="A2.SS2.p1.1.m1.1.1.1.1.1.cmml"><mn mathsize="90%" id="A2.SS2.p1.1.m1.1.1.1.1.1.2" xref="A2.SS2.p1.1.m1.1.1.1.1.1.2.cmml">1024</mn><mo mathsize="90%" id="A2.SS2.p1.1.m1.1.1.1.1.1.1" xref="A2.SS2.p1.1.m1.1.1.1.1.1.1.cmml">−</mo><mn mathsize="90%" id="A2.SS2.p1.1.m1.1.1.1.1.1.3" xref="A2.SS2.p1.1.m1.1.1.1.1.1.3.cmml">160</mn></mrow><mo maxsize="90%" minsize="90%" id="A2.SS2.p1.1.m1.1.1.1.1.3" xref="A2.SS2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo maxsize="90%" minsize="90%" stretchy="true" symmetric="true" id="A2.SS2.p1.1.m1.1.1.2" xref="A2.SS2.p1.1.m1.1.1.2.cmml">/</mo><mn mathsize="90%" id="A2.SS2.p1.1.m1.1.1.3" xref="A2.SS2.p1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.1.m1.1b"><apply id="A2.SS2.p1.1.m1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1"><divide id="A2.SS2.p1.1.m1.1.1.2.cmml" xref="A2.SS2.p1.1.m1.1.1.2"></divide><apply id="A2.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1.1.1"><minus id="A2.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1.1.1.1.1"></minus><cn type="integer" id="A2.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="A2.SS2.p1.1.m1.1.1.1.1.1.2">1024</cn><cn type="integer" id="A2.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="A2.SS2.p1.1.m1.1.1.1.1.1.3">160</cn></apply><cn type="integer" id="A2.SS2.p1.1.m1.1.1.3.cmml" xref="A2.SS2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.1.m1.1c">(1024-160)/2</annotation></semantics></math><span id="A2.SS2.p1.1.4" class="ltx_text" style="font-size:90%;"> values at both ends of the waveform in reflect mode, we obtained 1024 frames.
When using the predicted RMS from Video2RMS, nearest-neighbor interpolation is applied to match the feature size. The generated audio duration is 10.24 seconds. We only use Classifier-Free Guidance (CFG) for prompting and do not apply it to RMS conditions, as we did not observe meaningful performance improvements. The CFG is formulated as follows:</span></p>
<table id="A2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A2.E5.m1.63" class="ltx_math_unparsed" alttext="\begin{split}&amp;\hat{f}(z_{t},t,C(x),R(x))\\
&amp;\quad\quad\quad=\omega f(z_{t},t,C(x),R(x))+(1-\omega)f(z_{t},t,R(x))\end{split}" display="block"><semantics id="A2.E5.m1.63a"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="A2.E5.m1.63.63.9"><mtr id="A2.E5.m1.63.63.9a"><mtd id="A2.E5.m1.63.63.9b"></mtd><mtd class="ltx_align_left" columnalign="left" id="A2.E5.m1.63.63.9c"><mrow id="A2.E5.m1.57.57.3.57.20.20"><mover accent="true" id="A2.E5.m1.1.1.1.1.1.1"><mi mathsize="90%" id="A2.E5.m1.1.1.1.1.1.1.2">f</mi><mo mathsize="90%" id="A2.E5.m1.1.1.1.1.1.1.1">^</mo></mover><mo lspace="0em" rspace="0em" id="A2.E5.m1.57.57.3.57.20.20.21">​</mo><mrow id="A2.E5.m1.57.57.3.57.20.20.20.3"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.2.2.2.2.2.2">(</mo><msub id="A2.E5.m1.55.55.1.55.18.18.18.1.1"><mi mathsize="90%" id="A2.E5.m1.3.3.3.3.3.3">z</mi><mi mathsize="90%" id="A2.E5.m1.4.4.4.4.4.4.1">t</mi></msub><mo mathsize="90%" id="A2.E5.m1.5.5.5.5.5.5">,</mo><mi mathsize="90%" id="A2.E5.m1.6.6.6.6.6.6">t</mi><mo mathsize="90%" id="A2.E5.m1.7.7.7.7.7.7">,</mo><mrow id="A2.E5.m1.56.56.2.56.19.19.19.2.2"><mi mathsize="90%" id="A2.E5.m1.8.8.8.8.8.8">C</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.56.56.2.56.19.19.19.2.2.1">​</mo><mrow id="A2.E5.m1.56.56.2.56.19.19.19.2.2.2"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.9.9.9.9.9.9">(</mo><mi mathsize="90%" id="A2.E5.m1.10.10.10.10.10.10">x</mi><mo maxsize="90%" minsize="90%" id="A2.E5.m1.11.11.11.11.11.11">)</mo></mrow></mrow><mo mathsize="90%" id="A2.E5.m1.12.12.12.12.12.12">,</mo><mrow id="A2.E5.m1.57.57.3.57.20.20.20.3.3"><mi mathsize="90%" id="A2.E5.m1.13.13.13.13.13.13">R</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.57.57.3.57.20.20.20.3.3.1">​</mo><mrow id="A2.E5.m1.57.57.3.57.20.20.20.3.3.2"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.14.14.14.14.14.14">(</mo><mi mathsize="90%" id="A2.E5.m1.15.15.15.15.15.15">x</mi><mo maxsize="90%" minsize="90%" id="A2.E5.m1.16.16.16.16.16.16">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="A2.E5.m1.17.17.17.17.17.17">)</mo></mrow></mrow></mtd></mtr><mtr id="A2.E5.m1.63.63.9d"><mtd id="A2.E5.m1.63.63.9e"></mtd><mtd class="ltx_align_left" columnalign="left" id="A2.E5.m1.63.63.9f"><mrow id="A2.E5.m1.63.63.9.63.43.43"><mi id="A2.E5.m1.63.63.9.63.43.43.44"></mi><mo lspace="2.978em" mathsize="90%" id="A2.E5.m1.18.18.18.1.1.1">=</mo><mrow id="A2.E5.m1.63.63.9.63.43.43.43"><mrow id="A2.E5.m1.60.60.6.60.40.40.40.3"><mi mathsize="90%" id="A2.E5.m1.19.19.19.2.2.2">ω</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.60.60.6.60.40.40.40.3.4">​</mo><mi mathsize="90%" id="A2.E5.m1.20.20.20.3.3.3">f</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.60.60.6.60.40.40.40.3.4a">​</mo><mrow id="A2.E5.m1.60.60.6.60.40.40.40.3.3.3"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.21.21.21.4.4.4">(</mo><msub id="A2.E5.m1.58.58.4.58.38.38.38.1.1.1.1"><mi mathsize="90%" id="A2.E5.m1.22.22.22.5.5.5">z</mi><mi mathsize="90%" id="A2.E5.m1.23.23.23.6.6.6.1">t</mi></msub><mo mathsize="90%" id="A2.E5.m1.24.24.24.7.7.7">,</mo><mi mathsize="90%" id="A2.E5.m1.25.25.25.8.8.8">t</mi><mo mathsize="90%" id="A2.E5.m1.26.26.26.9.9.9">,</mo><mrow id="A2.E5.m1.59.59.5.59.39.39.39.2.2.2.2"><mi mathsize="90%" id="A2.E5.m1.27.27.27.10.10.10">C</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.59.59.5.59.39.39.39.2.2.2.2.1">​</mo><mrow id="A2.E5.m1.59.59.5.59.39.39.39.2.2.2.2.2"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.28.28.28.11.11.11">(</mo><mi mathsize="90%" id="A2.E5.m1.29.29.29.12.12.12">x</mi><mo maxsize="90%" minsize="90%" id="A2.E5.m1.30.30.30.13.13.13">)</mo></mrow></mrow><mo mathsize="90%" id="A2.E5.m1.31.31.31.14.14.14">,</mo><mrow id="A2.E5.m1.60.60.6.60.40.40.40.3.3.3.3"><mi mathsize="90%" id="A2.E5.m1.32.32.32.15.15.15">R</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.60.60.6.60.40.40.40.3.3.3.3.1">​</mo><mrow id="A2.E5.m1.60.60.6.60.40.40.40.3.3.3.3.2"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.33.33.33.16.16.16">(</mo><mi mathsize="90%" id="A2.E5.m1.34.34.34.17.17.17">x</mi><mo maxsize="90%" minsize="90%" id="A2.E5.m1.35.35.35.18.18.18">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="A2.E5.m1.36.36.36.19.19.19">)</mo></mrow></mrow><mo mathsize="90%" id="A2.E5.m1.37.37.37.20.20.20">+</mo><mrow id="A2.E5.m1.63.63.9.63.43.43.43.6"><mrow id="A2.E5.m1.61.61.7.61.41.41.41.4.1.1"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.38.38.38.21.21.21">(</mo><mrow id="A2.E5.m1.61.61.7.61.41.41.41.4.1.1.1"><mn mathsize="90%" id="A2.E5.m1.39.39.39.22.22.22">1</mn><mo mathsize="90%" id="A2.E5.m1.40.40.40.23.23.23">−</mo><mi mathsize="90%" id="A2.E5.m1.41.41.41.24.24.24">ω</mi></mrow><mo maxsize="90%" minsize="90%" id="A2.E5.m1.42.42.42.25.25.25">)</mo></mrow><mo lspace="0em" rspace="0em" id="A2.E5.m1.63.63.9.63.43.43.43.6.4">​</mo><mi mathsize="90%" id="A2.E5.m1.43.43.43.26.26.26">f</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.63.63.9.63.43.43.43.6.4a">​</mo><mrow id="A2.E5.m1.63.63.9.63.43.43.43.6.3.2"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.44.44.44.27.27.27">(</mo><msub id="A2.E5.m1.62.62.8.62.42.42.42.5.2.1.1"><mi mathsize="90%" id="A2.E5.m1.45.45.45.28.28.28">z</mi><mi mathsize="90%" id="A2.E5.m1.46.46.46.29.29.29.1">t</mi></msub><mo mathsize="90%" id="A2.E5.m1.47.47.47.30.30.30">,</mo><mi mathsize="90%" id="A2.E5.m1.48.48.48.31.31.31">t</mi><mo mathsize="90%" id="A2.E5.m1.49.49.49.32.32.32">,</mo><mrow id="A2.E5.m1.63.63.9.63.43.43.43.6.3.2.2"><mi mathsize="90%" id="A2.E5.m1.50.50.50.33.33.33">R</mi><mo lspace="0em" rspace="0em" id="A2.E5.m1.63.63.9.63.43.43.43.6.3.2.2.1">​</mo><mrow id="A2.E5.m1.63.63.9.63.43.43.43.6.3.2.2.2"><mo maxsize="90%" minsize="90%" id="A2.E5.m1.51.51.51.34.34.34">(</mo><mi mathsize="90%" id="A2.E5.m1.52.52.52.35.35.35">x</mi><mo maxsize="90%" minsize="90%" id="A2.E5.m1.53.53.53.36.36.36">)</mo></mrow></mrow><mo maxsize="90%" minsize="90%" id="A2.E5.m1.54.54.54.37.37.37">)</mo></mrow></mrow></mrow></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex" id="A2.E5.m1.63b">\begin{split}&amp;\hat{f}(z_{t},t,C(x),R(x))\\
&amp;\quad\quad\quad=\omega f(z_{t},t,C(x),R(x))+(1-\omega)f(z_{t},t,R(x))\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="A2.SS2.p1.12" class="ltx_p"><span id="A2.SS2.p1.12.1" class="ltx_text" style="font-size:90%;">where </span><math id="A2.SS2.p1.2.m1.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="A2.SS2.p1.2.m1.1a"><mi mathsize="90%" id="A2.SS2.p1.2.m1.1.1" xref="A2.SS2.p1.2.m1.1.1.cmml">ω</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.2.m1.1b"><ci id="A2.SS2.p1.2.m1.1.1.cmml" xref="A2.SS2.p1.2.m1.1.1">𝜔</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.2.m1.1c">\omega</annotation></semantics></math><span id="A2.SS2.p1.12.2" class="ltx_text" style="font-size:90%;"> is a guidance scale, </span><math id="A2.SS2.p1.3.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="A2.SS2.p1.3.m2.1a"><mi mathsize="90%" id="A2.SS2.p1.3.m2.1.1" xref="A2.SS2.p1.3.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.3.m2.1b"><ci id="A2.SS2.p1.3.m2.1.1.cmml" xref="A2.SS2.p1.3.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.3.m2.1c">z</annotation></semantics></math><span id="A2.SS2.p1.12.3" class="ltx_text" style="font-size:90%;"> is a latent representation of </span><math id="A2.SS2.p1.4.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="A2.SS2.p1.4.m3.1a"><mi mathsize="90%" id="A2.SS2.p1.4.m3.1.1" xref="A2.SS2.p1.4.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.4.m3.1b"><ci id="A2.SS2.p1.4.m3.1.1.cmml" xref="A2.SS2.p1.4.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.4.m3.1c">x</annotation></semantics></math><span id="A2.SS2.p1.12.4" class="ltx_text" style="font-size:90%;"> encoded with a variational autoencoder (VAE), </span><math id="A2.SS2.p1.5.m4.1" class="ltx_Math" alttext="z_{t}" display="inline"><semantics id="A2.SS2.p1.5.m4.1a"><msub id="A2.SS2.p1.5.m4.1.1" xref="A2.SS2.p1.5.m4.1.1.cmml"><mi mathsize="90%" id="A2.SS2.p1.5.m4.1.1.2" xref="A2.SS2.p1.5.m4.1.1.2.cmml">z</mi><mi mathsize="90%" id="A2.SS2.p1.5.m4.1.1.3" xref="A2.SS2.p1.5.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.5.m4.1b"><apply id="A2.SS2.p1.5.m4.1.1.cmml" xref="A2.SS2.p1.5.m4.1.1"><csymbol cd="ambiguous" id="A2.SS2.p1.5.m4.1.1.1.cmml" xref="A2.SS2.p1.5.m4.1.1">subscript</csymbol><ci id="A2.SS2.p1.5.m4.1.1.2.cmml" xref="A2.SS2.p1.5.m4.1.1.2">𝑧</ci><ci id="A2.SS2.p1.5.m4.1.1.3.cmml" xref="A2.SS2.p1.5.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.5.m4.1c">z_{t}</annotation></semantics></math><span id="A2.SS2.p1.12.5" class="ltx_text" style="font-size:90%;"> is </span><math id="A2.SS2.p1.6.m5.1" class="ltx_Math" alttext="z" display="inline"><semantics id="A2.SS2.p1.6.m5.1a"><mi mathsize="90%" id="A2.SS2.p1.6.m5.1.1" xref="A2.SS2.p1.6.m5.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.6.m5.1b"><ci id="A2.SS2.p1.6.m5.1.1.cmml" xref="A2.SS2.p1.6.m5.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.6.m5.1c">z</annotation></semantics></math><span id="A2.SS2.p1.12.6" class="ltx_text" style="font-size:90%;"> with </span><math id="A2.SS2.p1.7.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="A2.SS2.p1.7.m6.1a"><mi mathsize="90%" id="A2.SS2.p1.7.m6.1.1" xref="A2.SS2.p1.7.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.7.m6.1b"><ci id="A2.SS2.p1.7.m6.1.1.cmml" xref="A2.SS2.p1.7.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.7.m6.1c">t</annotation></semantics></math><span id="A2.SS2.p1.12.7" class="ltx_text" style="font-size:90%;"> times noise added, </span><math id="A2.SS2.p1.8.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.SS2.p1.8.m7.1a"><mi mathsize="90%" id="A2.SS2.p1.8.m7.1.1" xref="A2.SS2.p1.8.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.8.m7.1b"><ci id="A2.SS2.p1.8.m7.1.1.cmml" xref="A2.SS2.p1.8.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.8.m7.1c">C</annotation></semantics></math><span id="A2.SS2.p1.12.8" class="ltx_text" style="font-size:90%;"> is the CLAP encoder, and </span><math id="A2.SS2.p1.9.m8.1" class="ltx_Math" alttext="R" display="inline"><semantics id="A2.SS2.p1.9.m8.1a"><mi mathsize="90%" id="A2.SS2.p1.9.m8.1.1" xref="A2.SS2.p1.9.m8.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.9.m8.1b"><ci id="A2.SS2.p1.9.m8.1.1.cmml" xref="A2.SS2.p1.9.m8.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.9.m8.1c">R</annotation></semantics></math><span id="A2.SS2.p1.12.9" class="ltx_text" style="font-size:90%;"> is the RMS calculation. Note that a learned null embedding is used instead when CLAP embedding </span><math id="A2.SS2.p1.10.m9.1" class="ltx_Math" alttext="C(\cdot)" display="inline"><semantics id="A2.SS2.p1.10.m9.1a"><mrow id="A2.SS2.p1.10.m9.1.2" xref="A2.SS2.p1.10.m9.1.2.cmml"><mi mathsize="90%" id="A2.SS2.p1.10.m9.1.2.2" xref="A2.SS2.p1.10.m9.1.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="A2.SS2.p1.10.m9.1.2.1" xref="A2.SS2.p1.10.m9.1.2.1.cmml">​</mo><mrow id="A2.SS2.p1.10.m9.1.2.3.2" xref="A2.SS2.p1.10.m9.1.2.cmml"><mo maxsize="90%" minsize="90%" id="A2.SS2.p1.10.m9.1.2.3.2.1" xref="A2.SS2.p1.10.m9.1.2.cmml">(</mo><mo lspace="0em" mathsize="90%" rspace="0em" id="A2.SS2.p1.10.m9.1.1" xref="A2.SS2.p1.10.m9.1.1.cmml">⋅</mo><mo maxsize="90%" minsize="90%" id="A2.SS2.p1.10.m9.1.2.3.2.2" xref="A2.SS2.p1.10.m9.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.10.m9.1b"><apply id="A2.SS2.p1.10.m9.1.2.cmml" xref="A2.SS2.p1.10.m9.1.2"><times id="A2.SS2.p1.10.m9.1.2.1.cmml" xref="A2.SS2.p1.10.m9.1.2.1"></times><ci id="A2.SS2.p1.10.m9.1.2.2.cmml" xref="A2.SS2.p1.10.m9.1.2.2">𝐶</ci><ci id="A2.SS2.p1.10.m9.1.1.cmml" xref="A2.SS2.p1.10.m9.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.10.m9.1c">C(\cdot)</annotation></semantics></math><span id="A2.SS2.p1.12.10" class="ltx_text" style="font-size:90%;"> is not given to the model </span><math id="A2.SS2.p1.11.m10.1" class="ltx_Math" alttext="f" display="inline"><semantics id="A2.SS2.p1.11.m10.1a"><mi mathsize="90%" id="A2.SS2.p1.11.m10.1.1" xref="A2.SS2.p1.11.m10.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.11.m10.1b"><ci id="A2.SS2.p1.11.m10.1.1.cmml" xref="A2.SS2.p1.11.m10.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.11.m10.1c">f</annotation></semantics></math><span id="A2.SS2.p1.12.11" class="ltx_text" style="font-size:90%;">.
In our experiment, </span><math id="A2.SS2.p1.12.m11.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="A2.SS2.p1.12.m11.1a"><mi mathsize="90%" id="A2.SS2.p1.12.m11.1.1" xref="A2.SS2.p1.12.m11.1.1.cmml">ω</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.12.m11.1b"><ci id="A2.SS2.p1.12.m11.1.1.cmml" xref="A2.SS2.p1.12.m11.1.1">𝜔</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.12.m11.1c">\omega</annotation></semantics></math><span id="A2.SS2.p1.12.12" class="ltx_text" style="font-size:90%;"> is fixed to 3.5.</span></p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Metric for Objective Evaluation</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.2" class="ltx_p"><span id="A3.p1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Frechet Distance</span><span id="A3.p1.2.2" class="ltx_text" style="font-size:90%;"> When reference set embeddings </span><math id="A3.p1.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="A3.p1.1.m1.1a"><mi mathsize="90%" id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><ci id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">r</annotation></semantics></math><span id="A3.p1.2.3" class="ltx_text" style="font-size:90%;"> and a generated set embeddings </span><math id="A3.p1.2.m2.1" class="ltx_Math" alttext="g" display="inline"><semantics id="A3.p1.2.m2.1a"><mi mathsize="90%" id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b"><ci id="A3.p1.2.m2.1.1.cmml" xref="A3.p1.2.m2.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">g</annotation></semantics></math><span id="A3.p1.2.4" class="ltx_text" style="font-size:90%;"> are given, we calculate the FAD as follows:</span></p>
<table id="A3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A3.E6.m1.4" class="ltx_Math" alttext="\text{FAD}(r,g)=\left\|\mu_{r}-\mu_{g}\right\|_{2}+\text{tr}\left(\Sigma_{r}+\Sigma_{g}-2\sqrt{\Sigma_{r}\Sigma_{g}}\right)" display="block"><semantics id="A3.E6.m1.4a"><mrow id="A3.E6.m1.4.4" xref="A3.E6.m1.4.4.cmml"><mrow id="A3.E6.m1.4.4.4" xref="A3.E6.m1.4.4.4.cmml"><mtext mathsize="90%" id="A3.E6.m1.4.4.4.2" xref="A3.E6.m1.4.4.4.2a.cmml">FAD</mtext><mo lspace="0em" rspace="0em" id="A3.E6.m1.4.4.4.1" xref="A3.E6.m1.4.4.4.1.cmml">​</mo><mrow id="A3.E6.m1.4.4.4.3.2" xref="A3.E6.m1.4.4.4.3.1.cmml"><mo maxsize="90%" minsize="90%" id="A3.E6.m1.4.4.4.3.2.1" xref="A3.E6.m1.4.4.4.3.1.cmml">(</mo><mi mathsize="90%" id="A3.E6.m1.1.1" xref="A3.E6.m1.1.1.cmml">r</mi><mo mathsize="90%" id="A3.E6.m1.4.4.4.3.2.2" xref="A3.E6.m1.4.4.4.3.1.cmml">,</mo><mi mathsize="90%" id="A3.E6.m1.2.2" xref="A3.E6.m1.2.2.cmml">g</mi><mo maxsize="90%" minsize="90%" id="A3.E6.m1.4.4.4.3.2.3" xref="A3.E6.m1.4.4.4.3.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="A3.E6.m1.4.4.3" xref="A3.E6.m1.4.4.3.cmml">=</mo><mrow id="A3.E6.m1.4.4.2" xref="A3.E6.m1.4.4.2.cmml"><msub id="A3.E6.m1.3.3.1.1" xref="A3.E6.m1.3.3.1.1.cmml"><mrow id="A3.E6.m1.3.3.1.1.1.1" xref="A3.E6.m1.3.3.1.1.1.2.cmml"><mo id="A3.E6.m1.3.3.1.1.1.1.2" xref="A3.E6.m1.3.3.1.1.1.2.1.cmml">‖</mo><mrow id="A3.E6.m1.3.3.1.1.1.1.1" xref="A3.E6.m1.3.3.1.1.1.1.1.cmml"><msub id="A3.E6.m1.3.3.1.1.1.1.1.2" xref="A3.E6.m1.3.3.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="A3.E6.m1.3.3.1.1.1.1.1.2.2" xref="A3.E6.m1.3.3.1.1.1.1.1.2.2.cmml">μ</mi><mi mathsize="90%" id="A3.E6.m1.3.3.1.1.1.1.1.2.3" xref="A3.E6.m1.3.3.1.1.1.1.1.2.3.cmml">r</mi></msub><mo mathsize="90%" id="A3.E6.m1.3.3.1.1.1.1.1.1" xref="A3.E6.m1.3.3.1.1.1.1.1.1.cmml">−</mo><msub id="A3.E6.m1.3.3.1.1.1.1.1.3" xref="A3.E6.m1.3.3.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="A3.E6.m1.3.3.1.1.1.1.1.3.2" xref="A3.E6.m1.3.3.1.1.1.1.1.3.2.cmml">μ</mi><mi mathsize="90%" id="A3.E6.m1.3.3.1.1.1.1.1.3.3" xref="A3.E6.m1.3.3.1.1.1.1.1.3.3.cmml">g</mi></msub></mrow><mo id="A3.E6.m1.3.3.1.1.1.1.3" xref="A3.E6.m1.3.3.1.1.1.2.1.cmml">‖</mo></mrow><mn mathsize="90%" id="A3.E6.m1.3.3.1.1.3" xref="A3.E6.m1.3.3.1.1.3.cmml">2</mn></msub><mo mathsize="90%" id="A3.E6.m1.4.4.2.3" xref="A3.E6.m1.4.4.2.3.cmml">+</mo><mrow id="A3.E6.m1.4.4.2.2" xref="A3.E6.m1.4.4.2.2.cmml"><mtext mathsize="90%" id="A3.E6.m1.4.4.2.2.3" xref="A3.E6.m1.4.4.2.2.3a.cmml">tr</mtext><mo lspace="0em" rspace="0em" id="A3.E6.m1.4.4.2.2.2" xref="A3.E6.m1.4.4.2.2.2.cmml">​</mo><mrow id="A3.E6.m1.4.4.2.2.1.1" xref="A3.E6.m1.4.4.2.2.1.1.1.cmml"><mo id="A3.E6.m1.4.4.2.2.1.1.2" xref="A3.E6.m1.4.4.2.2.1.1.1.cmml">(</mo><mrow id="A3.E6.m1.4.4.2.2.1.1.1" xref="A3.E6.m1.4.4.2.2.1.1.1.cmml"><mrow id="A3.E6.m1.4.4.2.2.1.1.1.2" xref="A3.E6.m1.4.4.2.2.1.1.1.2.cmml"><msub id="A3.E6.m1.4.4.2.2.1.1.1.2.2" xref="A3.E6.m1.4.4.2.2.1.1.1.2.2.cmml"><mi mathsize="90%" mathvariant="normal" id="A3.E6.m1.4.4.2.2.1.1.1.2.2.2" xref="A3.E6.m1.4.4.2.2.1.1.1.2.2.2.cmml">Σ</mi><mi mathsize="90%" id="A3.E6.m1.4.4.2.2.1.1.1.2.2.3" xref="A3.E6.m1.4.4.2.2.1.1.1.2.2.3.cmml">r</mi></msub><mo mathsize="90%" id="A3.E6.m1.4.4.2.2.1.1.1.2.1" xref="A3.E6.m1.4.4.2.2.1.1.1.2.1.cmml">+</mo><msub id="A3.E6.m1.4.4.2.2.1.1.1.2.3" xref="A3.E6.m1.4.4.2.2.1.1.1.2.3.cmml"><mi mathsize="90%" mathvariant="normal" id="A3.E6.m1.4.4.2.2.1.1.1.2.3.2" xref="A3.E6.m1.4.4.2.2.1.1.1.2.3.2.cmml">Σ</mi><mi mathsize="90%" id="A3.E6.m1.4.4.2.2.1.1.1.2.3.3" xref="A3.E6.m1.4.4.2.2.1.1.1.2.3.3.cmml">g</mi></msub></mrow><mo mathsize="90%" id="A3.E6.m1.4.4.2.2.1.1.1.1" xref="A3.E6.m1.4.4.2.2.1.1.1.1.cmml">−</mo><mrow id="A3.E6.m1.4.4.2.2.1.1.1.3" xref="A3.E6.m1.4.4.2.2.1.1.1.3.cmml"><mn mathsize="90%" id="A3.E6.m1.4.4.2.2.1.1.1.3.2" xref="A3.E6.m1.4.4.2.2.1.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="A3.E6.m1.4.4.2.2.1.1.1.3.1" xref="A3.E6.m1.4.4.2.2.1.1.1.3.1.cmml">​</mo><msqrt id="A3.E6.m1.4.4.2.2.1.1.1.3.3" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.cmml"><mrow id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.cmml"><msub id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.cmml"><mi mathsize="90%" mathvariant="normal" id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.2" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.2.cmml">Σ</mi><mi mathsize="90%" id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.3" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.3.cmml">r</mi></msub><mo lspace="0em" rspace="0em" id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.1" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.1.cmml">​</mo><msub id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.cmml"><mi mathsize="90%" mathvariant="normal" id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.2" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.2.cmml">Σ</mi><mi mathsize="90%" id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.3" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.3.cmml">g</mi></msub></mrow></msqrt></mrow></mrow><mo id="A3.E6.m1.4.4.2.2.1.1.3" xref="A3.E6.m1.4.4.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.E6.m1.4b"><apply id="A3.E6.m1.4.4.cmml" xref="A3.E6.m1.4.4"><eq id="A3.E6.m1.4.4.3.cmml" xref="A3.E6.m1.4.4.3"></eq><apply id="A3.E6.m1.4.4.4.cmml" xref="A3.E6.m1.4.4.4"><times id="A3.E6.m1.4.4.4.1.cmml" xref="A3.E6.m1.4.4.4.1"></times><ci id="A3.E6.m1.4.4.4.2a.cmml" xref="A3.E6.m1.4.4.4.2"><mtext mathsize="90%" id="A3.E6.m1.4.4.4.2.cmml" xref="A3.E6.m1.4.4.4.2">FAD</mtext></ci><interval closure="open" id="A3.E6.m1.4.4.4.3.1.cmml" xref="A3.E6.m1.4.4.4.3.2"><ci id="A3.E6.m1.1.1.cmml" xref="A3.E6.m1.1.1">𝑟</ci><ci id="A3.E6.m1.2.2.cmml" xref="A3.E6.m1.2.2">𝑔</ci></interval></apply><apply id="A3.E6.m1.4.4.2.cmml" xref="A3.E6.m1.4.4.2"><plus id="A3.E6.m1.4.4.2.3.cmml" xref="A3.E6.m1.4.4.2.3"></plus><apply id="A3.E6.m1.3.3.1.1.cmml" xref="A3.E6.m1.3.3.1.1"><csymbol cd="ambiguous" id="A3.E6.m1.3.3.1.1.2.cmml" xref="A3.E6.m1.3.3.1.1">subscript</csymbol><apply id="A3.E6.m1.3.3.1.1.1.2.cmml" xref="A3.E6.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="A3.E6.m1.3.3.1.1.1.2.1.cmml" xref="A3.E6.m1.3.3.1.1.1.1.2">norm</csymbol><apply id="A3.E6.m1.3.3.1.1.1.1.1.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1"><minus id="A3.E6.m1.3.3.1.1.1.1.1.1.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.1"></minus><apply id="A3.E6.m1.3.3.1.1.1.1.1.2.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.E6.m1.3.3.1.1.1.1.1.2.1.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.2">subscript</csymbol><ci id="A3.E6.m1.3.3.1.1.1.1.1.2.2.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.2.2">𝜇</ci><ci id="A3.E6.m1.3.3.1.1.1.1.1.2.3.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.2.3">𝑟</ci></apply><apply id="A3.E6.m1.3.3.1.1.1.1.1.3.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A3.E6.m1.3.3.1.1.1.1.1.3.1.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="A3.E6.m1.3.3.1.1.1.1.1.3.2.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.3.2">𝜇</ci><ci id="A3.E6.m1.3.3.1.1.1.1.1.3.3.cmml" xref="A3.E6.m1.3.3.1.1.1.1.1.3.3">𝑔</ci></apply></apply></apply><cn type="integer" id="A3.E6.m1.3.3.1.1.3.cmml" xref="A3.E6.m1.3.3.1.1.3">2</cn></apply><apply id="A3.E6.m1.4.4.2.2.cmml" xref="A3.E6.m1.4.4.2.2"><times id="A3.E6.m1.4.4.2.2.2.cmml" xref="A3.E6.m1.4.4.2.2.2"></times><ci id="A3.E6.m1.4.4.2.2.3a.cmml" xref="A3.E6.m1.4.4.2.2.3"><mtext mathsize="90%" id="A3.E6.m1.4.4.2.2.3.cmml" xref="A3.E6.m1.4.4.2.2.3">tr</mtext></ci><apply id="A3.E6.m1.4.4.2.2.1.1.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1"><minus id="A3.E6.m1.4.4.2.2.1.1.1.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.1"></minus><apply id="A3.E6.m1.4.4.2.2.1.1.1.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2"><plus id="A3.E6.m1.4.4.2.2.1.1.1.2.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.1"></plus><apply id="A3.E6.m1.4.4.2.2.1.1.1.2.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="A3.E6.m1.4.4.2.2.1.1.1.2.2.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.2">subscript</csymbol><ci id="A3.E6.m1.4.4.2.2.1.1.1.2.2.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.2.2">Σ</ci><ci id="A3.E6.m1.4.4.2.2.1.1.1.2.2.3.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.2.3">𝑟</ci></apply><apply id="A3.E6.m1.4.4.2.2.1.1.1.2.3.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.3"><csymbol cd="ambiguous" id="A3.E6.m1.4.4.2.2.1.1.1.2.3.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.3">subscript</csymbol><ci id="A3.E6.m1.4.4.2.2.1.1.1.2.3.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.3.2">Σ</ci><ci id="A3.E6.m1.4.4.2.2.1.1.1.2.3.3.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.2.3.3">𝑔</ci></apply></apply><apply id="A3.E6.m1.4.4.2.2.1.1.1.3.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3"><times id="A3.E6.m1.4.4.2.2.1.1.1.3.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.1"></times><cn type="integer" id="A3.E6.m1.4.4.2.2.1.1.1.3.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.2">2</cn><apply id="A3.E6.m1.4.4.2.2.1.1.1.3.3.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3"><root id="A3.E6.m1.4.4.2.2.1.1.1.3.3a.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3"></root><apply id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2"><times id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.1"></times><apply id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2"><csymbol cd="ambiguous" id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2">subscript</csymbol><ci id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.2">Σ</ci><ci id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.3.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.2.3">𝑟</ci></apply><apply id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.1.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3">subscript</csymbol><ci id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.2.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.2">Σ</ci><ci id="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.3.cmml" xref="A3.E6.m1.4.4.2.2.1.1.1.3.3.2.3.3">𝑔</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.E6.m1.4c">\text{FAD}(r,g)=\left\|\mu_{r}-\mu_{g}\right\|_{2}+\text{tr}\left(\Sigma_{r}+\Sigma_{g}-2\sqrt{\Sigma_{r}\Sigma_{g}}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="A3.p1.5" class="ltx_p"><span id="A3.p1.5.1" class="ltx_text" style="font-size:90%;">where </span><math id="A3.p1.3.m1.1" class="ltx_Math" alttext="\mu_{x}" display="inline"><semantics id="A3.p1.3.m1.1a"><msub id="A3.p1.3.m1.1.1" xref="A3.p1.3.m1.1.1.cmml"><mi mathsize="90%" id="A3.p1.3.m1.1.1.2" xref="A3.p1.3.m1.1.1.2.cmml">μ</mi><mi mathsize="90%" id="A3.p1.3.m1.1.1.3" xref="A3.p1.3.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.3.m1.1b"><apply id="A3.p1.3.m1.1.1.cmml" xref="A3.p1.3.m1.1.1"><csymbol cd="ambiguous" id="A3.p1.3.m1.1.1.1.cmml" xref="A3.p1.3.m1.1.1">subscript</csymbol><ci id="A3.p1.3.m1.1.1.2.cmml" xref="A3.p1.3.m1.1.1.2">𝜇</ci><ci id="A3.p1.3.m1.1.1.3.cmml" xref="A3.p1.3.m1.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.3.m1.1c">\mu_{x}</annotation></semantics></math><span id="A3.p1.5.2" class="ltx_text" style="font-size:90%;"> and </span><math id="A3.p1.4.m2.1" class="ltx_Math" alttext="\Sigma_{x}" display="inline"><semantics id="A3.p1.4.m2.1a"><msub id="A3.p1.4.m2.1.1" xref="A3.p1.4.m2.1.1.cmml"><mi mathsize="90%" mathvariant="normal" id="A3.p1.4.m2.1.1.2" xref="A3.p1.4.m2.1.1.2.cmml">Σ</mi><mi mathsize="90%" id="A3.p1.4.m2.1.1.3" xref="A3.p1.4.m2.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.4.m2.1b"><apply id="A3.p1.4.m2.1.1.cmml" xref="A3.p1.4.m2.1.1"><csymbol cd="ambiguous" id="A3.p1.4.m2.1.1.1.cmml" xref="A3.p1.4.m2.1.1">subscript</csymbol><ci id="A3.p1.4.m2.1.1.2.cmml" xref="A3.p1.4.m2.1.1.2">Σ</ci><ci id="A3.p1.4.m2.1.1.3.cmml" xref="A3.p1.4.m2.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.4.m2.1c">\Sigma_{x}</annotation></semantics></math><span id="A3.p1.5.3" class="ltx_text" style="font-size:90%;"> are the mean and covariance matrix of the distribution </span><math id="A3.p1.5.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="A3.p1.5.m3.1a"><mi mathsize="90%" id="A3.p1.5.m3.1.1" xref="A3.p1.5.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A3.p1.5.m3.1b"><ci id="A3.p1.5.m3.1.1.cmml" xref="A3.p1.5.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.5.m3.1c">x</annotation></semantics></math><span id="A3.p1.5.4" class="ltx_text" style="font-size:90%;">. FAVD is calculated similarly, using the concatenated audio and video embedding.</span></p>
</div>
<div id="A3.p2" class="ltx_para ltx_noindent">
<p id="A3.p2.3" class="ltx_p"><span id="A3.p2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">CLAP score</span><span id="A3.p2.3.2" class="ltx_text" style="font-size:90%;"> First, we extract embeddings from ground-truth </span><math id="A3.p2.1.m1.1" class="ltx_Math" alttext="e" display="inline"><semantics id="A3.p2.1.m1.1a"><mi mathsize="90%" id="A3.p2.1.m1.1.1" xref="A3.p2.1.m1.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="A3.p2.1.m1.1b"><ci id="A3.p2.1.m1.1.1.cmml" xref="A3.p2.1.m1.1.1">𝑒</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.1.m1.1c">e</annotation></semantics></math><span id="A3.p2.3.3" class="ltx_text" style="font-size:90%;"> and generated audio </span><math id="A3.p2.2.m2.1" class="ltx_Math" alttext="\hat{e}" display="inline"><semantics id="A3.p2.2.m2.1a"><mover accent="true" id="A3.p2.2.m2.1.1" xref="A3.p2.2.m2.1.1.cmml"><mi mathsize="90%" id="A3.p2.2.m2.1.1.2" xref="A3.p2.2.m2.1.1.2.cmml">e</mi><mo mathsize="90%" id="A3.p2.2.m2.1.1.1" xref="A3.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="A3.p2.2.m2.1b"><apply id="A3.p2.2.m2.1.1.cmml" xref="A3.p2.2.m2.1.1"><ci id="A3.p2.2.m2.1.1.1.cmml" xref="A3.p2.2.m2.1.1.1">^</ci><ci id="A3.p2.2.m2.1.1.2.cmml" xref="A3.p2.2.m2.1.1.2">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.2.m2.1c">\hat{e}</annotation></semantics></math><span id="A3.p2.3.4" class="ltx_text" style="font-size:90%;"> in the audio-text joint embedding space of CLAP. Then, the cosine distance between the two embedding vectors </span><math id="A3.p2.3.m3.3" class="ltx_Math" alttext="\cos(e,\hat{e})" display="inline"><semantics id="A3.p2.3.m3.3a"><mrow id="A3.p2.3.m3.3.4.2" xref="A3.p2.3.m3.3.4.1.cmml"><mi mathsize="90%" id="A3.p2.3.m3.1.1" xref="A3.p2.3.m3.1.1.cmml">cos</mi><mo id="A3.p2.3.m3.3.4.2a" xref="A3.p2.3.m3.3.4.1.cmml">⁡</mo><mrow id="A3.p2.3.m3.3.4.2.1" xref="A3.p2.3.m3.3.4.1.cmml"><mo maxsize="90%" minsize="90%" id="A3.p2.3.m3.3.4.2.1.1" xref="A3.p2.3.m3.3.4.1.cmml">(</mo><mi mathsize="90%" id="A3.p2.3.m3.2.2" xref="A3.p2.3.m3.2.2.cmml">e</mi><mo mathsize="90%" id="A3.p2.3.m3.3.4.2.1.2" xref="A3.p2.3.m3.3.4.1.cmml">,</mo><mover accent="true" id="A3.p2.3.m3.3.3" xref="A3.p2.3.m3.3.3.cmml"><mi mathsize="90%" id="A3.p2.3.m3.3.3.2" xref="A3.p2.3.m3.3.3.2.cmml">e</mi><mo mathsize="90%" id="A3.p2.3.m3.3.3.1" xref="A3.p2.3.m3.3.3.1.cmml">^</mo></mover><mo maxsize="90%" minsize="90%" id="A3.p2.3.m3.3.4.2.1.3" xref="A3.p2.3.m3.3.4.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.p2.3.m3.3b"><apply id="A3.p2.3.m3.3.4.1.cmml" xref="A3.p2.3.m3.3.4.2"><cos id="A3.p2.3.m3.1.1.cmml" xref="A3.p2.3.m3.1.1"></cos><ci id="A3.p2.3.m3.2.2.cmml" xref="A3.p2.3.m3.2.2">𝑒</ci><apply id="A3.p2.3.m3.3.3.cmml" xref="A3.p2.3.m3.3.3"><ci id="A3.p2.3.m3.3.3.1.cmml" xref="A3.p2.3.m3.3.3.1">^</ci><ci id="A3.p2.3.m3.3.3.2.cmml" xref="A3.p2.3.m3.3.3.2">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.3.m3.3c">\cos(e,\hat{e})</annotation></semantics></math><span id="A3.p2.3.5" class="ltx_text" style="font-size:90%;"> is measured.</span></p>
</div>
<div id="A3.p3" class="ltx_para ltx_noindent">
<p id="A3.p3.4" class="ltx_p"><span id="A3.p3.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">E-L1</span><span id="A3.p3.4.2" class="ltx_text" style="font-size:90%;"> E-L1(Event-L1) which is proposed in T-Foley</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.p3.4.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="A3.p3.4.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A3.p3.4.5" class="ltx_text" style="font-size:90%;"> is defined as the following:</span></p>
<table id="A3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A3.E7.m1.1" class="ltx_Math" alttext="E\text{-}L1={1\over k}\displaystyle\Sigma_{i=1}^{k}||E_{i}-\hat{E}_{i}||" display="block"><semantics id="A3.E7.m1.1a"><mrow id="A3.E7.m1.1.1" xref="A3.E7.m1.1.1.cmml"><mrow id="A3.E7.m1.1.1.3" xref="A3.E7.m1.1.1.3.cmml"><mi mathsize="90%" id="A3.E7.m1.1.1.3.2" xref="A3.E7.m1.1.1.3.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="A3.E7.m1.1.1.3.1" xref="A3.E7.m1.1.1.3.1.cmml">​</mo><mtext mathsize="90%" id="A3.E7.m1.1.1.3.3" xref="A3.E7.m1.1.1.3.3a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="A3.E7.m1.1.1.3.1a" xref="A3.E7.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="A3.E7.m1.1.1.3.4" xref="A3.E7.m1.1.1.3.4.cmml">L</mi><mo lspace="0em" rspace="0em" id="A3.E7.m1.1.1.3.1b" xref="A3.E7.m1.1.1.3.1.cmml">​</mo><mn mathsize="90%" id="A3.E7.m1.1.1.3.5" xref="A3.E7.m1.1.1.3.5.cmml">1</mn></mrow><mo mathsize="90%" id="A3.E7.m1.1.1.2" xref="A3.E7.m1.1.1.2.cmml">=</mo><mrow id="A3.E7.m1.1.1.1" xref="A3.E7.m1.1.1.1.cmml"><mfrac id="A3.E7.m1.1.1.1.3" xref="A3.E7.m1.1.1.1.3.cmml"><mn mathsize="90%" id="A3.E7.m1.1.1.1.3.2" xref="A3.E7.m1.1.1.1.3.2.cmml">1</mn><mi mathsize="90%" id="A3.E7.m1.1.1.1.3.3" xref="A3.E7.m1.1.1.1.3.3.cmml">k</mi></mfrac><mo lspace="0em" rspace="0em" id="A3.E7.m1.1.1.1.2" xref="A3.E7.m1.1.1.1.2.cmml">​</mo><msubsup id="A3.E7.m1.1.1.1.4" xref="A3.E7.m1.1.1.1.4.cmml"><mi mathsize="90%" mathvariant="normal" id="A3.E7.m1.1.1.1.4.2.2" xref="A3.E7.m1.1.1.1.4.2.2.cmml">Σ</mi><mrow id="A3.E7.m1.1.1.1.4.2.3" xref="A3.E7.m1.1.1.1.4.2.3.cmml"><mi mathsize="90%" id="A3.E7.m1.1.1.1.4.2.3.2" xref="A3.E7.m1.1.1.1.4.2.3.2.cmml">i</mi><mo mathsize="90%" id="A3.E7.m1.1.1.1.4.2.3.1" xref="A3.E7.m1.1.1.1.4.2.3.1.cmml">=</mo><mn mathsize="90%" id="A3.E7.m1.1.1.1.4.2.3.3" xref="A3.E7.m1.1.1.1.4.2.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="A3.E7.m1.1.1.1.4.3" xref="A3.E7.m1.1.1.1.4.3.cmml">k</mi></msubsup><mo lspace="0em" rspace="0em" id="A3.E7.m1.1.1.1.2a" xref="A3.E7.m1.1.1.1.2.cmml">​</mo><mrow id="A3.E7.m1.1.1.1.1.1" xref="A3.E7.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="A3.E7.m1.1.1.1.1.1.2" xref="A3.E7.m1.1.1.1.1.2.1.cmml">‖</mo><mrow id="A3.E7.m1.1.1.1.1.1.1" xref="A3.E7.m1.1.1.1.1.1.1.cmml"><msub id="A3.E7.m1.1.1.1.1.1.1.2" xref="A3.E7.m1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="A3.E7.m1.1.1.1.1.1.1.2.2" xref="A3.E7.m1.1.1.1.1.1.1.2.2.cmml">E</mi><mi mathsize="90%" id="A3.E7.m1.1.1.1.1.1.1.2.3" xref="A3.E7.m1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo mathsize="90%" id="A3.E7.m1.1.1.1.1.1.1.1" xref="A3.E7.m1.1.1.1.1.1.1.1.cmml">−</mo><msub id="A3.E7.m1.1.1.1.1.1.1.3" xref="A3.E7.m1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="A3.E7.m1.1.1.1.1.1.1.3.2" xref="A3.E7.m1.1.1.1.1.1.1.3.2.cmml"><mi mathsize="90%" id="A3.E7.m1.1.1.1.1.1.1.3.2.2" xref="A3.E7.m1.1.1.1.1.1.1.3.2.2.cmml">E</mi><mo mathsize="90%" id="A3.E7.m1.1.1.1.1.1.1.3.2.1" xref="A3.E7.m1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mi mathsize="90%" id="A3.E7.m1.1.1.1.1.1.1.3.3" xref="A3.E7.m1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="A3.E7.m1.1.1.1.1.1.3" xref="A3.E7.m1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.E7.m1.1b"><apply id="A3.E7.m1.1.1.cmml" xref="A3.E7.m1.1.1"><eq id="A3.E7.m1.1.1.2.cmml" xref="A3.E7.m1.1.1.2"></eq><apply id="A3.E7.m1.1.1.3.cmml" xref="A3.E7.m1.1.1.3"><times id="A3.E7.m1.1.1.3.1.cmml" xref="A3.E7.m1.1.1.3.1"></times><ci id="A3.E7.m1.1.1.3.2.cmml" xref="A3.E7.m1.1.1.3.2">𝐸</ci><ci id="A3.E7.m1.1.1.3.3a.cmml" xref="A3.E7.m1.1.1.3.3"><mtext mathsize="90%" id="A3.E7.m1.1.1.3.3.cmml" xref="A3.E7.m1.1.1.3.3">-</mtext></ci><ci id="A3.E7.m1.1.1.3.4.cmml" xref="A3.E7.m1.1.1.3.4">𝐿</ci><cn type="integer" id="A3.E7.m1.1.1.3.5.cmml" xref="A3.E7.m1.1.1.3.5">1</cn></apply><apply id="A3.E7.m1.1.1.1.cmml" xref="A3.E7.m1.1.1.1"><times id="A3.E7.m1.1.1.1.2.cmml" xref="A3.E7.m1.1.1.1.2"></times><apply id="A3.E7.m1.1.1.1.3.cmml" xref="A3.E7.m1.1.1.1.3"><divide id="A3.E7.m1.1.1.1.3.1.cmml" xref="A3.E7.m1.1.1.1.3"></divide><cn type="integer" id="A3.E7.m1.1.1.1.3.2.cmml" xref="A3.E7.m1.1.1.1.3.2">1</cn><ci id="A3.E7.m1.1.1.1.3.3.cmml" xref="A3.E7.m1.1.1.1.3.3">𝑘</ci></apply><apply id="A3.E7.m1.1.1.1.4.cmml" xref="A3.E7.m1.1.1.1.4"><csymbol cd="ambiguous" id="A3.E7.m1.1.1.1.4.1.cmml" xref="A3.E7.m1.1.1.1.4">superscript</csymbol><apply id="A3.E7.m1.1.1.1.4.2.cmml" xref="A3.E7.m1.1.1.1.4"><csymbol cd="ambiguous" id="A3.E7.m1.1.1.1.4.2.1.cmml" xref="A3.E7.m1.1.1.1.4">subscript</csymbol><ci id="A3.E7.m1.1.1.1.4.2.2.cmml" xref="A3.E7.m1.1.1.1.4.2.2">Σ</ci><apply id="A3.E7.m1.1.1.1.4.2.3.cmml" xref="A3.E7.m1.1.1.1.4.2.3"><eq id="A3.E7.m1.1.1.1.4.2.3.1.cmml" xref="A3.E7.m1.1.1.1.4.2.3.1"></eq><ci id="A3.E7.m1.1.1.1.4.2.3.2.cmml" xref="A3.E7.m1.1.1.1.4.2.3.2">𝑖</ci><cn type="integer" id="A3.E7.m1.1.1.1.4.2.3.3.cmml" xref="A3.E7.m1.1.1.1.4.2.3.3">1</cn></apply></apply><ci id="A3.E7.m1.1.1.1.4.3.cmml" xref="A3.E7.m1.1.1.1.4.3">𝑘</ci></apply><apply id="A3.E7.m1.1.1.1.1.2.cmml" xref="A3.E7.m1.1.1.1.1.1"><csymbol cd="latexml" id="A3.E7.m1.1.1.1.1.2.1.cmml" xref="A3.E7.m1.1.1.1.1.1.2">norm</csymbol><apply id="A3.E7.m1.1.1.1.1.1.1.cmml" xref="A3.E7.m1.1.1.1.1.1.1"><minus id="A3.E7.m1.1.1.1.1.1.1.1.cmml" xref="A3.E7.m1.1.1.1.1.1.1.1"></minus><apply id="A3.E7.m1.1.1.1.1.1.1.2.cmml" xref="A3.E7.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.E7.m1.1.1.1.1.1.1.2.1.cmml" xref="A3.E7.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="A3.E7.m1.1.1.1.1.1.1.2.2.cmml" xref="A3.E7.m1.1.1.1.1.1.1.2.2">𝐸</ci><ci id="A3.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="A3.E7.m1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="A3.E7.m1.1.1.1.1.1.1.3.cmml" xref="A3.E7.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A3.E7.m1.1.1.1.1.1.1.3.1.cmml" xref="A3.E7.m1.1.1.1.1.1.1.3">subscript</csymbol><apply id="A3.E7.m1.1.1.1.1.1.1.3.2.cmml" xref="A3.E7.m1.1.1.1.1.1.1.3.2"><ci id="A3.E7.m1.1.1.1.1.1.1.3.2.1.cmml" xref="A3.E7.m1.1.1.1.1.1.1.3.2.1">^</ci><ci id="A3.E7.m1.1.1.1.1.1.1.3.2.2.cmml" xref="A3.E7.m1.1.1.1.1.1.1.3.2.2">𝐸</ci></apply><ci id="A3.E7.m1.1.1.1.1.1.1.3.3.cmml" xref="A3.E7.m1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.E7.m1.1c">E\text{-}L1={1\over k}\displaystyle\Sigma_{i=1}^{k}||E_{i}-\hat{E}_{i}||</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="A3.p3.3" class="ltx_p"><span id="A3.p3.3.1" class="ltx_text" style="font-size:90%;">where </span><math id="A3.p3.1.m1.1" class="ltx_Math" alttext="E_{i}" display="inline"><semantics id="A3.p3.1.m1.1a"><msub id="A3.p3.1.m1.1.1" xref="A3.p3.1.m1.1.1.cmml"><mi mathsize="90%" id="A3.p3.1.m1.1.1.2" xref="A3.p3.1.m1.1.1.2.cmml">E</mi><mi mathsize="90%" id="A3.p3.1.m1.1.1.3" xref="A3.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p3.1.m1.1b"><apply id="A3.p3.1.m1.1.1.cmml" xref="A3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="A3.p3.1.m1.1.1.1.cmml" xref="A3.p3.1.m1.1.1">subscript</csymbol><ci id="A3.p3.1.m1.1.1.2.cmml" xref="A3.p3.1.m1.1.1.2">𝐸</ci><ci id="A3.p3.1.m1.1.1.3.cmml" xref="A3.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p3.1.m1.1c">E_{i}</annotation></semantics></math><span id="A3.p3.3.2" class="ltx_text" style="font-size:90%;"> is the ground-truth event feature of </span><math id="A3.p3.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="A3.p3.2.m2.1a"><mi mathsize="90%" id="A3.p3.2.m2.1.1" xref="A3.p3.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A3.p3.2.m2.1b"><ci id="A3.p3.2.m2.1.1.cmml" xref="A3.p3.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p3.2.m2.1c">i</annotation></semantics></math><span id="A3.p3.3.3" class="ltx_text" style="font-size:90%;">-th frame, and </span><math id="A3.p3.3.m3.1" class="ltx_Math" alttext="\hat{E}_{i}" display="inline"><semantics id="A3.p3.3.m3.1a"><msub id="A3.p3.3.m3.1.1" xref="A3.p3.3.m3.1.1.cmml"><mover accent="true" id="A3.p3.3.m3.1.1.2" xref="A3.p3.3.m3.1.1.2.cmml"><mi mathsize="90%" id="A3.p3.3.m3.1.1.2.2" xref="A3.p3.3.m3.1.1.2.2.cmml">E</mi><mo mathsize="90%" id="A3.p3.3.m3.1.1.2.1" xref="A3.p3.3.m3.1.1.2.1.cmml">^</mo></mover><mi mathsize="90%" id="A3.p3.3.m3.1.1.3" xref="A3.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p3.3.m3.1b"><apply id="A3.p3.3.m3.1.1.cmml" xref="A3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="A3.p3.3.m3.1.1.1.cmml" xref="A3.p3.3.m3.1.1">subscript</csymbol><apply id="A3.p3.3.m3.1.1.2.cmml" xref="A3.p3.3.m3.1.1.2"><ci id="A3.p3.3.m3.1.1.2.1.cmml" xref="A3.p3.3.m3.1.1.2.1">^</ci><ci id="A3.p3.3.m3.1.1.2.2.cmml" xref="A3.p3.3.m3.1.1.2.2">𝐸</ci></apply><ci id="A3.p3.3.m3.1.1.3.cmml" xref="A3.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p3.3.m3.1c">\hat{E}_{i}</annotation></semantics></math><span id="A3.p3.3.4" class="ltx_text" style="font-size:90%;"> is the predicted one. In this paper, RMS is the temporal event feature. For evaluating Video2RMS, E-L1 between the predicted RMS and the ground-truth RMS is measured. In the case of Video-Foley, E-L1 between the RMS extracted from generated audio and ground-truth audio is considered.</span></p>
</div>
<div id="A3.p4" class="ltx_para ltx_noindent">
<p id="A3.p4.1" class="ltx_p"><span id="A3.p4.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">PEAVS</span><span id="A3.p4.1.2" class="ltx_text" style="font-size:90%;">
We found a lack of standardized metrics to measure temporal synchrony in video-audio pairs. While proposing E-L1, we also considered using PEAVS</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.p4.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="A3.p4.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A3.p4.1.5" class="ltx_text" style="font-size:90%;">. PEAVS is calculated by a neural model trained to estimate human opinion scores on audio-visual synchrony through regression to maximize correlation with human perception. However, we found that PEAVS poorly aligns with the MOS (Mean Opinion Score) we measured, as shown in Table </span><a href="#A3.T3" title="Table 3 ‣ Appendix C Metric for Objective Evaluation ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="A3.p4.1.6" class="ltx_text" style="font-size:90%;">. We suspect two main reasons for this discrepancy.
First is the limited scope of training data. Only 200 videos from the AudioSet evaluation split were used as the source of training data. Even though this resulted in 18.2K videos after applying nine synchrony-related distortions at various levels, the training data still represents a very small portion of the entire AudioSet. Therefore, it cannot cover the wide range of in-the-wild video distributions. It may not generalize well to our Greatest Hits data, which features very specific sound events (e.g., hitting or scratching something with a wooden drumstick).
Second, the quality of the source audio-visual pairs. AudioSet originates from YouTube videos, which often have poor audio and visual quality and frequently contain off-screen sounds irrelevant to the visual part. This may lead the model to predict better scores when it receives generated audio with poor quality or irrelevant noises. In Table </span><a href="#A3.T3" title="Table 3 ‣ Appendix C Metric for Objective Evaluation ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="A3.p4.1.7" class="ltx_text" style="font-size:90%;">, Diff-Foley received a high PEAVS score despite performing poorly in the human MOS score.</span></p>
</div>
<figure id="A3.T3" class="ltx_table">
<div id="A3.T3.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:260.2pt;height:246.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(6.6pt,-6.3pt) scale(1.05344149885353,1.05344149885353) ;">
<table id="A3.T3.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T3.2.2.2" class="ltx_tr">
<th id="A3.T3.2.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="A3.T3.2.2.2.3.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="A3.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<span id="A3.T3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">PEAVS </span><math id="A3.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A3.T3.1.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="A3.T3.1.1.1.1.m1.1.1" xref="A3.T3.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.1.1.1.1.m1.1b"><ci id="A3.T3.1.1.1.1.m1.1.1.cmml" xref="A3.T3.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="A3.T3.2.2.2.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<span id="A3.T3.2.2.2.2.1" class="ltx_text" style="font-size:90%;">MOS </span><math id="A3.T3.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A3.T3.2.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="A3.T3.2.2.2.2.m1.1.1" xref="A3.T3.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.2.2.2.2.m1.1b"><ci id="A3.T3.2.2.2.2.m1.1.1.cmml" xref="A3.T3.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</th>
</tr>
<tr id="A3.T3.7.7.8.1" class="ltx_tr">
<th id="A3.T3.7.7.8.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="A3.T3.7.7.8.1.1.1" class="ltx_text" style="font-size:90%;">Ground Truth</span></th>
<th id="A3.T3.7.7.8.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="A3.T3.7.7.8.1.2.1" class="ltx_text" style="font-size:90%;">1.81</span></th>
<th id="A3.T3.7.7.8.1.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="A3.T3.7.7.8.1.3.1" class="ltx_text" style="font-size:90%;">4.83(±0.06)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T3.7.7.9.1" class="ltx_tr">
<th id="A3.T3.7.7.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="A3.T3.7.7.9.1.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">No Prompt</span></th>
<td id="A3.T3.7.7.9.1.2" class="ltx_td ltx_border_t"></td>
<td id="A3.T3.7.7.9.1.3" class="ltx_td ltx_nopad_r ltx_border_t"></td>
</tr>
<tr id="A3.T3.3.3.3" class="ltx_tr">
<th id="A3.T3.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A3.T3.3.3.3.1.1" class="ltx_text" style="font-size:90%;">SpecVQGAN</span><sup id="A3.T3.3.3.3.1.2" class="ltx_sup"><span id="A3.T3.3.3.3.1.2.1" class="ltx_text" style="font-size:90%;">†</span></sup><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.T3.3.3.3.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="A3.T3.3.3.3.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="A3.T3.3.3.3.2" class="ltx_td ltx_align_left"><span id="A3.T3.3.3.3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">2.64</span></td>
<td id="A3.T3.3.3.3.3" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A3.T3.3.3.3.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="A3.T3.4.4.4" class="ltx_tr">
<th id="A3.T3.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A3.T3.4.4.4.1.1" class="ltx_text" style="font-size:90%;">Diff-Foley</span><sup id="A3.T3.4.4.4.1.2" class="ltx_sup"><span id="A3.T3.4.4.4.1.2.1" class="ltx_text" style="font-size:90%;">‡</span></sup><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.T3.4.4.4.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="A3.T3.4.4.4.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="A3.T3.4.4.4.2" class="ltx_td ltx_align_left"><span id="A3.T3.4.4.4.2.1" class="ltx_text" style="font-size:90%;">2.25</span></td>
<td id="A3.T3.4.4.4.3" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A3.T3.4.4.4.3.1" class="ltx_text" style="font-size:90%;">1.86(±0.14)</span></td>
</tr>
<tr id="A3.T3.7.7.10.2" class="ltx_tr">
<th id="A3.T3.7.7.10.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A3.T3.7.7.10.2.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Audio Prompt</span></th>
<td id="A3.T3.7.7.10.2.2" class="ltx_td"></td>
<td id="A3.T3.7.7.10.2.3" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="A3.T3.5.5.5" class="ltx_tr">
<th id="A3.T3.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A3.T3.5.5.5.1.1" class="ltx_text" style="font-size:90%;">CondFoleyGen</span><sup id="A3.T3.5.5.5.1.2" class="ltx_sup"><span id="A3.T3.5.5.5.1.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">av</span></sup><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.T3.5.5.5.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="A3.T3.5.5.5.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="A3.T3.5.5.5.2" class="ltx_td ltx_align_left"><span id="A3.T3.5.5.5.2.1" class="ltx_text" style="font-size:90%;">1.80</span></td>
<td id="A3.T3.5.5.5.3" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A3.T3.5.5.5.3.1" class="ltx_text" style="font-size:90%;">1.93(±0.13)</span></td>
</tr>
<tr id="A3.T3.7.7.11.3" class="ltx_tr">
<th id="A3.T3.7.7.11.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A3.T3.7.7.11.3.1.1" class="ltx_text" style="font-size:90%;">SyncFusion</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.T3.7.7.11.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="A3.T3.7.7.11.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="A3.T3.7.7.11.3.2" class="ltx_td ltx_align_left"><span id="A3.T3.7.7.11.3.2.1" class="ltx_text" style="font-size:90%;">2.21</span></td>
<td id="A3.T3.7.7.11.3.3" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A3.T3.7.7.11.3.3.1" class="ltx_text" style="font-size:90%;">3.10(±0.19)</span></td>
</tr>
<tr id="A3.T3.6.6.6" class="ltx_tr">
<th id="A3.T3.6.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A3.T3.6.6.6.1.1" class="ltx_text" style="font-size:90%;">Video-Foley</span><sup id="A3.T3.6.6.6.1.2" class="ltx_sup"><span id="A3.T3.6.6.6.1.2.1" class="ltx_text" style="font-size:90%;">⋆</span></sup><span id="A3.T3.6.6.6.1.3" class="ltx_text" style="font-size:90%;"> (Ours)</span>
</th>
<td id="A3.T3.6.6.6.2" class="ltx_td ltx_align_left"><span id="A3.T3.6.6.6.2.1" class="ltx_text" style="font-size:90%;">1.70</span></td>
<td id="A3.T3.6.6.6.3" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A3.T3.6.6.6.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.40(±0.11)</span></td>
</tr>
<tr id="A3.T3.7.7.12.4" class="ltx_tr">
<th id="A3.T3.7.7.12.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A3.T3.7.7.12.4.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Text Prompt</span></th>
<td id="A3.T3.7.7.12.4.2" class="ltx_td"></td>
<td id="A3.T3.7.7.12.4.3" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="A3.T3.7.7.13.5" class="ltx_tr">
<th id="A3.T3.7.7.13.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A3.T3.7.7.13.5.1.1" class="ltx_text" style="font-size:90%;">SyncFusion</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.T3.7.7.13.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="A3.T3.7.7.13.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="A3.T3.7.7.13.5.2" class="ltx_td ltx_align_left"><span id="A3.T3.7.7.13.5.2.1" class="ltx_text" style="font-size:90%;">2.31</span></td>
<td id="A3.T3.7.7.13.5.3" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A3.T3.7.7.13.5.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="A3.T3.7.7.7" class="ltx_tr">
<th id="A3.T3.7.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A3.T3.7.7.7.1.1" class="ltx_text" style="font-size:90%;">Video-Foley</span><sup id="A3.T3.7.7.7.1.2" class="ltx_sup"><span id="A3.T3.7.7.7.1.2.1" class="ltx_text" style="font-size:90%;">⋆</span></sup><span id="A3.T3.7.7.7.1.3" class="ltx_text" style="font-size:90%;"> (Ours)</span>
</th>
<td id="A3.T3.7.7.7.2" class="ltx_td ltx_align_left"><span id="A3.T3.7.7.7.2.1" class="ltx_text" style="font-size:90%;">2.27</span></td>
<td id="A3.T3.7.7.7.3" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A3.T3.7.7.7.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="A3.T3.7.7.14.6" class="ltx_tr">
<th id="A3.T3.7.7.14.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<span id="A3.T3.7.7.14.6.1.1" class="ltx_text" style="font-size:90%;">Text-to-Audio</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.T3.7.7.14.6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="A3.T3.7.7.14.6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="A3.T3.7.7.14.6.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="A3.T3.7.7.14.6.2.1" class="ltx_text" style="font-size:90%;">1.82</span></td>
<td id="A3.T3.7.7.14.6.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t"><span id="A3.T3.7.7.14.6.3.1" class="ltx_text" style="font-size:90%;">2.00(±0.13)</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="A3.T3.11.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>Comparison between PEAVS and MOS for Temporal Alignment</figcaption>
</figure>
<div id="A3.p5" class="ltx_para ltx_noindent">
<p id="A3.p5.1" class="ltx_p"><span id="A3.p5.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Onset Metrics</span><span id="A3.p5.1.2" class="ltx_text" style="font-size:90%;">
Onset metrics, Onset Acc (accuracy) and Onset AP (average precision), were measured following the protocol in CondFoleyGen</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A3.p5.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="A3.p5.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A3.p5.1.5" class="ltx_text" style="font-size:90%;">. These metrics were calculated with a tolerance of ±0.1 seconds after applying non-maximum suppression with a window length of 50 ms based on the onset prediction confidence. Moreover, all metrics excluded true-negative cases (both predicted and labeled outputs being non-onset) due to the label imbalance in the dataset: onset labels are much sparser than non-onset labels in a video. This imbalance incentivizes the model to predict non-onset more frequently. Consequently, including all true-negative cases may overrate and exaggerate the model’s performance, making it distinct from actual perceptual performance and ultimately inaccurate.</span></p>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Subjective Human Evaluation</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p"><span id="A4.p1.1.1" class="ltx_text" style="font-size:90%;">In the qualitative evaluation, we aimed to compare the performance of video-to-sound systems on various video inputs that include diverse contextual information. To achieve this, we created 12 evaluation questions by selecting cases that combine the ‘material’ and ‘action’ categories from the Greatest Hits test dataset. Each question presented the ground truth audio and the audio generated by Video-Foley, SyncFusion, DiffFoley, CondFoleyGen, and AudioLDM in a random order. Specifically, from the dataset’s 18 ‘material’ categories, we excluded ‘None’ and selected six ‘{material}-scratch’ cases where the sound characteristics significantly change by scratching actions. These cases included </span><span id="A4.p1.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">plastic-scratch</span><span id="A4.p1.1.3" class="ltx_text" style="font-size:90%;">, </span><span id="A4.p1.1.4" class="ltx_text ltx_font_italic" style="font-size:90%;">rock-scratch</span><span id="A4.p1.1.5" class="ltx_text" style="font-size:90%;">, </span><span id="A4.p1.1.6" class="ltx_text ltx_font_italic" style="font-size:90%;">dirt-scratch</span><span id="A4.p1.1.7" class="ltx_text" style="font-size:90%;">, </span><span id="A4.p1.1.8" class="ltx_text ltx_font_italic" style="font-size:90%;">drywall-scratch</span><span id="A4.p1.1.9" class="ltx_text" style="font-size:90%;">, </span><span id="A4.p1.1.10" class="ltx_text ltx_font_italic" style="font-size:90%;">gravel-scratch</span><span id="A4.p1.1.11" class="ltx_text" style="font-size:90%;">, and </span><span id="A4.p1.1.12" class="ltx_text ltx_font_italic" style="font-size:90%;">grass-scratch</span><span id="A4.p1.1.13" class="ltx_text" style="font-size:90%;">. Subsequently, we selected six ‘{material}-hit’ cases from the remaining material categories where the sound characteristics notably change by hitting actions. These cases included </span><span id="A4.p1.1.14" class="ltx_text ltx_font_italic" style="font-size:90%;">carpet-hit</span><span id="A4.p1.1.15" class="ltx_text" style="font-size:90%;">, </span><span id="A4.p1.1.16" class="ltx_text ltx_font_italic" style="font-size:90%;">ceramic-hit</span><span id="A4.p1.1.17" class="ltx_text" style="font-size:90%;">, </span><span id="A4.p1.1.18" class="ltx_text ltx_font_italic" style="font-size:90%;">metal-hit</span><span id="A4.p1.1.19" class="ltx_text" style="font-size:90%;">, </span><span id="A4.p1.1.20" class="ltx_text ltx_font_italic" style="font-size:90%;">water-hit</span><span id="A4.p1.1.21" class="ltx_text" style="font-size:90%;">, </span><span id="A4.p1.1.22" class="ltx_text ltx_font_italic" style="font-size:90%;">wood-hit</span><span id="A4.p1.1.23" class="ltx_text" style="font-size:90%;">, and </span><span id="A4.p1.1.24" class="ltx_text ltx_font_italic" style="font-size:90%;">leaf-hit</span><span id="A4.p1.1.25" class="ltx_text" style="font-size:90%;">. To standardize the length of the sample videos and control evaluator fatigue, we trimmed each video to 4 seconds from the starting point.</span></p>
</div>
<figure id="A4.F6" class="ltx_figure">
<div id="A4.F6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:236.3pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-55.3pt,30.0pt) scale(0.796812740067158,0.796812740067158) ;"><img src="/html/2408.11915/assets/Fig/mos_eval_01.png" id="A4.F6.1.g1" class="ltx_graphics ltx_img_landscape" width="753" height="409" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A4.F6.5.1.1" class="ltx_text ltx_font_bold">Fig. 6</span>: </span>Guidelines for evaluation elements</figcaption>
</figure>
<figure id="A4.F7" class="ltx_figure">
<div id="A4.F7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:330.5pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-88.2pt,67.1pt) scale(0.710900464448873,0.710900464448873) ;"><img src="/html/2408.11915/assets/Fig/mos_eval_02.png" id="A4.F7.1.g1" class="ltx_graphics ltx_img_landscape" width="844" height="642" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A4.F7.5.1.1" class="ltx_text ltx_font_bold">Fig. 7</span>: </span>Explanation of Likert scale scores and video examples for each evaluation criterion</figcaption>
</figure>
<div id="A4.p2" class="ltx_para">
<p id="A4.p2.1" class="ltx_p"><span id="A4.p2.1.1" class="ltx_text" style="font-size:90%;">Considering that the names of qualitative evaluation criteria related to sound elements can be interpreted differently based on the evaluator’s experience, expectations, and preferences, we provided pre-experiment guidelines as shown in Figure </span><a href="#A4.F6" title="Figure 6 ‣ Appendix D Subjective Human Evaluation ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="A4.p2.1.2" class="ltx_text" style="font-size:90%;">. We redefined and introduced the criteria for </span><span id="A4.p2.1.3" class="ltx_text ltx_font_italic" style="font-size:90%;">Material/Action Alignment</span><span id="A4.p2.1.4" class="ltx_text" style="font-size:90%;"> as </span><span id="A4.p2.1.5" class="ltx_text ltx_font_italic" style="font-size:90%;">Semantic Alignment: Material Type</span><span id="A4.p2.1.6" class="ltx_text" style="font-size:90%;"> and </span><span id="A4.p2.1.7" class="ltx_text ltx_font_italic" style="font-size:90%;">Semantic Alignment: Action Type</span><span id="A4.p2.1.8" class="ltx_text" style="font-size:90%;"> to clearly distinguish them from </span><span id="A4.p2.1.9" class="ltx_text ltx_font_italic" style="font-size:90%;">Temporal Alignment</span><span id="A4.p2.1.10" class="ltx_text" style="font-size:90%;"> during the evaluation. We also provided textual guidelines on the evaluation elements and precautions for the four criteria. This included a detailed explanation of the situations corresponding to each point on the Likert scale regarding that each evaluator may interpret the points of the Likert scale differently. Additionally, considering that it might be difficult to fully understand the evaluation elements and criteria for sound and video alignment based solely on text, we provided video sample examples corresponding to the lowest and highest scores for the four evaluation elements. Refer to an example in Figure </span><a href="#A4.F7" title="Figure 7 ‣ Appendix D Subjective Human Evaluation ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">7</span></a><span id="A4.p2.1.11" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Ablation Study for Video2RMS</h2>

<section id="A5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Ablation Study on Using Onset Annotations</h3>

<div id="A5.SS1.p1" class="ltx_para">
<p id="A5.SS1.p1.1" class="ltx_p"><span id="A5.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">To examine the impact of the onset label, onset joint training was conducted. An additional binary cross-entropy term, scaled by a factor of </span><math id="A5.SS1.p1.1.m1.1" class="ltx_Math" alttext="1e^{-3}" display="inline"><semantics id="A5.SS1.p1.1.m1.1a"><mrow id="A5.SS1.p1.1.m1.1.1" xref="A5.SS1.p1.1.m1.1.1.cmml"><mn mathsize="90%" id="A5.SS1.p1.1.m1.1.1.2" xref="A5.SS1.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A5.SS1.p1.1.m1.1.1.1" xref="A5.SS1.p1.1.m1.1.1.1.cmml">​</mo><msup id="A5.SS1.p1.1.m1.1.1.3" xref="A5.SS1.p1.1.m1.1.1.3.cmml"><mi mathsize="90%" id="A5.SS1.p1.1.m1.1.1.3.2" xref="A5.SS1.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="A5.SS1.p1.1.m1.1.1.3.3" xref="A5.SS1.p1.1.m1.1.1.3.3.cmml"><mo mathsize="90%" id="A5.SS1.p1.1.m1.1.1.3.3a" xref="A5.SS1.p1.1.m1.1.1.3.3.cmml">−</mo><mn mathsize="90%" id="A5.SS1.p1.1.m1.1.1.3.3.2" xref="A5.SS1.p1.1.m1.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.1.m1.1b"><apply id="A5.SS1.p1.1.m1.1.1.cmml" xref="A5.SS1.p1.1.m1.1.1"><times id="A5.SS1.p1.1.m1.1.1.1.cmml" xref="A5.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="A5.SS1.p1.1.m1.1.1.2.cmml" xref="A5.SS1.p1.1.m1.1.1.2">1</cn><apply id="A5.SS1.p1.1.m1.1.1.3.cmml" xref="A5.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A5.SS1.p1.1.m1.1.1.3.1.cmml" xref="A5.SS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="A5.SS1.p1.1.m1.1.1.3.2.cmml" xref="A5.SS1.p1.1.m1.1.1.3.2">𝑒</ci><apply id="A5.SS1.p1.1.m1.1.1.3.3.cmml" xref="A5.SS1.p1.1.m1.1.1.3.3"><minus id="A5.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="A5.SS1.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="A5.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="A5.SS1.p1.1.m1.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.1.m1.1c">1e^{-3}</annotation></semantics></math><span id="A5.SS1.p1.1.2" class="ltx_text" style="font-size:90%;">, was added to the loss function. An extra branch head with a linear projection layer was added to the model after the LSTM layer. Onset timestamp annotations provided in the Greatest Hits dataset were only used as labels for supervision. We used onset-related metrics following previous work</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A5.SS1.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="A5.SS1.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A5.SS1.p1.1.5" class="ltx_text" style="font-size:90%;"> (refer to Section </span><a href="#A3" title="Appendix C Metric for Objective Evaluation ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">C</span></a><span id="A5.SS1.p1.1.6" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="A5.SS1.p2" class="ltx_para">
<p id="A5.SS1.p2.1" class="ltx_p"><span id="A5.SS1.p2.1.1" class="ltx_text" style="font-size:90%;">Table </span><a href="#A5.T4" title="Table 4 ‣ E.1 Ablation Study on Using Onset Annotations ‣ Appendix E Ablation Study for Video2RMS ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="A5.SS1.p2.1.2" class="ltx_text" style="font-size:90%;"> demonstrates the performance of the Video2RMS model along with the previous Video2Onset model</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A5.SS1.p2.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="A5.SS1.p2.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A5.SS1.p2.1.5" class="ltx_text" style="font-size:90%;">.
Additional onset supervision does not benefit RMS prediction. There was no significant improvement in RMS prediction (i.e. E-L1 and accuracy), while the onset prediction performance increased significantly in both accuracy and average precision. This suggests that RMS, despite not requiring any manual annotation, could aid the onset prediction that relies on labeled data.
In addition, our BN-Inception-based model
and the ResNet(2+1)D-based model</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A5.SS1.p2.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="A5.SS1.p2.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="A5.SS1.p2.1.8" class="ltx_text" style="font-size:90%;">
have comparable overall performance in the Video2Onset detection task. Our model shows better precision and lower recall, likely due to the optical flow input and global sequential modeling. Refer to Section </span><a href="#A2.SS1" title="B.1 Video2RMS ‣ Appendix B Details in Video-Foley ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">B.1</span></a><span id="A5.SS1.p2.1.9" class="ltx_text" style="font-size:90%;"> for further details.</span></p>
</div>
<figure id="A5.T4" class="ltx_table">
<div id="A5.T4.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:105.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-5.2pt,1.3pt) scale(0.976477142399349,0.976477142399349) ;">
<table id="A5.T4.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A5.T4.4.4.4" class="ltx_tr">
<th id="A5.T4.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="A5.T4.4.4.4.5.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="A5.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<span id="A5.T4.1.1.1.1.1" class="ltx_text" style="font-size:90%;">E-L1 </span><math id="A5.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T4.1.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="A5.T4.1.1.1.1.m1.1.1" xref="A5.T4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T4.1.1.1.1.m1.1b"><ci id="A5.T4.1.1.1.1.m1.1.1.cmml" xref="A5.T4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="A5.T4.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="A5.T4.2.2.2.2.1" class="ltx_text" style="font-size:90%;">Acc </span><math id="A5.T4.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T4.2.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="A5.T4.2.2.2.2.m1.1.1" xref="A5.T4.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T4.2.2.2.2.m1.1b"><ci id="A5.T4.2.2.2.2.m1.1.1.cmml" xref="A5.T4.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T4.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="A5.T4.4.4.4.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="A5.T4.4.4.4.6.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="A5.T4.3.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<span id="A5.T4.3.3.3.3.1" class="ltx_text" style="font-size:90%;">Onset Acc </span><math id="A5.T4.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T4.3.3.3.3.m1.1a"><mo mathsize="90%" stretchy="false" id="A5.T4.3.3.3.3.m1.1.1" xref="A5.T4.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T4.3.3.3.3.m1.1b"><ci id="A5.T4.3.3.3.3.m1.1.1.cmml" xref="A5.T4.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T4.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="A5.T4.4.4.4.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<span id="A5.T4.4.4.4.4.1" class="ltx_text" style="font-size:90%;">Onset AP </span><math id="A5.T4.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T4.4.4.4.4.m1.1a"><mo mathsize="90%" stretchy="false" id="A5.T4.4.4.4.4.m1.1.1" xref="A5.T4.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T4.4.4.4.4.m1.1b"><ci id="A5.T4.4.4.4.4.m1.1.1.cmml" xref="A5.T4.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T4.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A5.T4.7.7.8.1" class="ltx_tr">
<th id="A5.T4.7.7.8.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="A5.T4.7.7.8.1.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Video2RMS</span></th>
<td id="A5.T4.7.7.8.1.2" class="ltx_td ltx_border_t"></td>
<td id="A5.T4.7.7.8.1.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<th id="A5.T4.7.7.8.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="A5.T4.7.7.8.1.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Video2Onset</span></th>
<td id="A5.T4.7.7.8.1.5" class="ltx_td ltx_border_t"></td>
<td id="A5.T4.7.7.8.1.6" class="ltx_td ltx_nopad_r ltx_border_t"></td>
</tr>
<tr id="A5.T4.5.5.5" class="ltx_tr">
<th id="A5.T4.5.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A5.T4.5.5.5.2.1" class="ltx_text" style="font-size:90%;">disc. RMS (g.t.)</span></th>
<td id="A5.T4.5.5.5.3" class="ltx_td ltx_align_left"><span id="A5.T4.5.5.5.3.1" class="ltx_text" style="font-size:90%;">0.00243</span></td>
<td id="A5.T4.5.5.5.4" class="ltx_td ltx_align_left ltx_border_r"><span id="A5.T4.5.5.5.4.1" class="ltx_text" style="font-size:90%;">1</span></td>
<th id="A5.T4.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A5.T4.5.5.5.1.1" class="ltx_text" style="font-size:90%;">SyncFusion </span><sup id="A5.T4.5.5.5.1.2" class="ltx_sup"><span id="A5.T4.5.5.5.1.2.1" class="ltx_text" style="font-size:90%;">†</span></sup><span id="A5.T4.5.5.5.1.3" class="ltx_text" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A5.T4.5.5.5.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="A5.T4.5.5.5.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="A5.T4.5.5.5.5" class="ltx_td ltx_align_left"><span id="A5.T4.5.5.5.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.484</span></td>
<td id="A5.T4.5.5.5.6" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A5.T4.5.5.5.6.1" class="ltx_text" style="font-size:90%;">0.501</span></td>
</tr>
<tr id="A5.T4.7.7.9.2" class="ltx_tr">
<th id="A5.T4.7.7.9.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A5.T4.7.7.9.2.1.1" class="ltx_text" style="font-size:90%;">Video-Foley RMS (Ours)</span></th>
<td id="A5.T4.7.7.9.2.2" class="ltx_td ltx_align_left"><span id="A5.T4.7.7.9.2.2.1" class="ltx_text" style="font-size:90%;">0.0450</span></td>
<td id="A5.T4.7.7.9.2.3" class="ltx_td ltx_align_left ltx_border_r"><span id="A5.T4.7.7.9.2.3.1" class="ltx_text" style="font-size:90%;">0.0116</span></td>
<th id="A5.T4.7.7.9.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A5.T4.7.7.9.2.4.1" class="ltx_text" style="font-size:90%;">Video-Foley onset</span></th>
<td id="A5.T4.7.7.9.2.5" class="ltx_td ltx_align_left"><span id="A5.T4.7.7.9.2.5.1" class="ltx_text" style="font-size:90%;">0.359</span></td>
<td id="A5.T4.7.7.9.2.6" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A5.T4.7.7.9.2.6.1" class="ltx_text" style="font-size:90%;">0.653</span></td>
</tr>
<tr id="A5.T4.7.7.7" class="ltx_tr">
<th id="A5.T4.6.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A5.T4.6.6.6.1.1" class="ltx_text" style="font-size:90%;">w/ onset joint train</span><sup id="A5.T4.6.6.6.1.2" class="ltx_sup"><span id="A5.T4.6.6.6.1.2.1" class="ltx_text" style="font-size:90%;">⋆</span></sup>
</th>
<td id="A5.T4.7.7.7.3" class="ltx_td ltx_align_left"><span id="A5.T4.7.7.7.3.1" class="ltx_text" style="font-size:90%;">0.0448</span></td>
<td id="A5.T4.7.7.7.4" class="ltx_td ltx_align_left ltx_border_r"><span id="A5.T4.7.7.7.4.1" class="ltx_text" style="font-size:90%;">0.0118</span></td>
<th id="A5.T4.7.7.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="A5.T4.7.7.7.2.1" class="ltx_text" style="font-size:90%;">w/ RMS joint train</span><sup id="A5.T4.7.7.7.2.2" class="ltx_sup"><span id="A5.T4.7.7.7.2.2.1" class="ltx_text" style="font-size:90%;">⋆</span></sup>
</th>
<td id="A5.T4.7.7.7.5" class="ltx_td ltx_align_left"><span id="A5.T4.7.7.7.5.1" class="ltx_text" style="font-size:90%;">0.387</span></td>
<td id="A5.T4.7.7.7.6" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A5.T4.7.7.7.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.837</span></td>
</tr>
<tr id="A5.T4.7.7.10.3" class="ltx_tr">
<th id="A5.T4.7.7.10.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="A5.T4.7.7.10.3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">w/ label smoothing</span></th>
<td id="A5.T4.7.7.10.3.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="A5.T4.7.7.10.3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.0431</span></td>
<td id="A5.T4.7.7.10.3.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A5.T4.7.7.10.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.0128</span></td>
<th id="A5.T4.7.7.10.3.4" class="ltx_td ltx_th ltx_th_row ltx_border_bb"></th>
<td id="A5.T4.7.7.10.3.5" class="ltx_td ltx_border_bb"></td>
<td id="A5.T4.7.7.10.3.6" class="ltx_td ltx_nopad_r ltx_border_bb"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="A5.T4.22.1.1" class="ltx_text ltx_font_bold">Table 4</span>: </span>Performance of Video2RMS module. <sup id="A5.T4.23.2" class="ltx_sup">†</sup>: Reproduced to match our setting, disc.: discretized, g.t.: ground-truth, <sup id="A5.T4.24.3" class="ltx_sup">⋆</sup>: identical model. Onset metrics measured with a tolerance of <math id="A5.T4.13.m3.1" class="ltx_Math" alttext="\pm 0.1" display="inline"><semantics id="A5.T4.13.m3.1b"><mrow id="A5.T4.13.m3.1.1" xref="A5.T4.13.m3.1.1.cmml"><mo id="A5.T4.13.m3.1.1b" xref="A5.T4.13.m3.1.1.cmml">±</mo><mn id="A5.T4.13.m3.1.1.2" xref="A5.T4.13.m3.1.1.2.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.T4.13.m3.1c"><apply id="A5.T4.13.m3.1.1.cmml" xref="A5.T4.13.m3.1.1"><csymbol cd="latexml" id="A5.T4.13.m3.1.1.1.cmml" xref="A5.T4.13.m3.1.1">plus-or-minus</csymbol><cn type="float" id="A5.T4.13.m3.1.1.2.cmml" xref="A5.T4.13.m3.1.1.2">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T4.13.m3.1d">\pm 0.1</annotation></semantics></math>s.</figcaption>
</figure>
</section>
<section id="A5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Ablation Study on Label Smoothing</h3>

<div id="A5.SS2.p1" class="ltx_para">
<p id="A5.SS2.p1.3" class="ltx_p"><span id="A5.SS2.p1.3.1" class="ltx_text" style="font-size:90%;">Figure </span><a href="#A5.F8" title="Figure 8 ‣ E.2 Ablation Study on Label Smoothing ‣ Appendix E Ablation Study for Video2RMS ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">8</span></a><span id="A5.SS2.p1.3.2" class="ltx_text" style="font-size:90%;"> illustrates the performance of Video2RMS with different label smoothing window sizes </span><math id="A5.SS2.p1.1.m1.1" class="ltx_Math" alttext="W" display="inline"><semantics id="A5.SS2.p1.1.m1.1a"><mi mathsize="90%" id="A5.SS2.p1.1.m1.1.1" xref="A5.SS2.p1.1.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.1.m1.1b"><ci id="A5.SS2.p1.1.m1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.1.m1.1c">W</annotation></semantics></math><span id="A5.SS2.p1.3.3" class="ltx_text" style="font-size:90%;">. We found that </span><math id="A5.SS2.p1.2.m2.1" class="ltx_Math" alttext="W=2" display="inline"><semantics id="A5.SS2.p1.2.m2.1a"><mrow id="A5.SS2.p1.2.m2.1.1" xref="A5.SS2.p1.2.m2.1.1.cmml"><mi mathsize="90%" id="A5.SS2.p1.2.m2.1.1.2" xref="A5.SS2.p1.2.m2.1.1.2.cmml">W</mi><mo mathsize="90%" id="A5.SS2.p1.2.m2.1.1.1" xref="A5.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn mathsize="90%" id="A5.SS2.p1.2.m2.1.1.3" xref="A5.SS2.p1.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.2.m2.1b"><apply id="A5.SS2.p1.2.m2.1.1.cmml" xref="A5.SS2.p1.2.m2.1.1"><eq id="A5.SS2.p1.2.m2.1.1.1.cmml" xref="A5.SS2.p1.2.m2.1.1.1"></eq><ci id="A5.SS2.p1.2.m2.1.1.2.cmml" xref="A5.SS2.p1.2.m2.1.1.2">𝑊</ci><cn type="integer" id="A5.SS2.p1.2.m2.1.1.3.cmml" xref="A5.SS2.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.2.m2.1c">W=2</annotation></semantics></math><span id="A5.SS2.p1.3.4" class="ltx_text" style="font-size:90%;"> offers the best balance between E-L1 and accuracy. For larger window sizes, the model produces more jitter in the RMS curve. Although performance saturates after </span><math id="A5.SS2.p1.3.m3.1" class="ltx_Math" alttext="W=10" display="inline"><semantics id="A5.SS2.p1.3.m3.1a"><mrow id="A5.SS2.p1.3.m3.1.1" xref="A5.SS2.p1.3.m3.1.1.cmml"><mi mathsize="90%" id="A5.SS2.p1.3.m3.1.1.2" xref="A5.SS2.p1.3.m3.1.1.2.cmml">W</mi><mo mathsize="90%" id="A5.SS2.p1.3.m3.1.1.1" xref="A5.SS2.p1.3.m3.1.1.1.cmml">=</mo><mn mathsize="90%" id="A5.SS2.p1.3.m3.1.1.3" xref="A5.SS2.p1.3.m3.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.3.m3.1b"><apply id="A5.SS2.p1.3.m3.1.1.cmml" xref="A5.SS2.p1.3.m3.1.1"><eq id="A5.SS2.p1.3.m3.1.1.1.cmml" xref="A5.SS2.p1.3.m3.1.1.1"></eq><ci id="A5.SS2.p1.3.m3.1.1.2.cmml" xref="A5.SS2.p1.3.m3.1.1.2">𝑊</ci><cn type="integer" id="A5.SS2.p1.3.m3.1.1.3.cmml" xref="A5.SS2.p1.3.m3.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.3.m3.1c">W=10</annotation></semantics></math><span id="A5.SS2.p1.3.5" class="ltx_text" style="font-size:90%;"> with higher accuracy, this results in a spikier RMS curve and a higher E-L1 value, indicating poorer overall performance. Nevertheless, using Gaussian label smoothing consistently improved performance regardless of the window size.</span></p>
</div>
<figure id="A5.F8" class="ltx_figure">
<div id="A5.F8.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:325.2pt;height:193.5pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-106.6pt,63.2pt) scale(0.604026839931466,0.604026839931466) ;"><img src="/html/2408.11915/assets/Fig/gls_ablation.png" id="A5.F8.1.g1" class="ltx_graphics ltx_img_landscape" width="745" height="442" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A5.F8.5.1.1" class="ltx_text ltx_font_bold">Fig. 8</span>: </span>Ablation study on window size of label smoothing in Video2RMS</figcaption>
</figure>
</section>
</section>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Ablation Study for RMS2Sound</h2>

<figure id="A6.T5" class="ltx_table">
<div id="A6.T5.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:207pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(37.7pt,-22.5pt) scale(1.27770417852897,1.27770417852897) ;">
<table id="A6.T5.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A6.T5.2.1.1.1" class="ltx_tr">
<th id="A6.T5.2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A6.T5.2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="A6.T5.2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A6.T5.2.1.1.1.2.1" class="ltx_text" style="font-size:90%;">FAD-P↓</span></th>
<th id="A6.T5.2.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A6.T5.2.1.1.1.3.1" class="ltx_text" style="font-size:90%;">FAD-C↓</span></th>
<th id="A6.T5.2.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A6.T5.2.1.1.1.4.1" class="ltx_text" style="font-size:90%;">CLAP↑</span></th>
<th id="A6.T5.2.1.1.1.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="A6.T5.2.1.1.1.5.1" class="ltx_text" style="font-size:90%;">E-L1↓</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A6.T5.2.1.2.1" class="ltx_tr">
<td id="A6.T5.2.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A6.T5.2.1.2.1.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Audio Prompt</span></td>
<td id="A6.T5.2.1.2.1.2" class="ltx_td ltx_border_t"></td>
<td id="A6.T5.2.1.2.1.3" class="ltx_td ltx_border_t"></td>
<td id="A6.T5.2.1.2.1.4" class="ltx_td ltx_border_t"></td>
<td id="A6.T5.2.1.2.1.5" class="ltx_td ltx_nopad_r ltx_border_t"></td>
</tr>
<tr id="A6.T5.2.1.3.2" class="ltx_tr">
<td id="A6.T5.2.1.3.2.1" class="ltx_td ltx_align_left">
<span id="A6.T5.2.1.3.2.1.1" class="ltx_text" style="font-size:90%;">w/o RMS</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A6.T5.2.1.3.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="A6.T5.2.1.3.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="A6.T5.2.1.3.2.2" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.3.2.2.1" class="ltx_text" style="font-size:90%;">29.0</span></td>
<td id="A6.T5.2.1.3.2.3" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.3.2.3.1" class="ltx_text" style="font-size:90%;">194</span></td>
<td id="A6.T5.2.1.3.2.4" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.3.2.4.1" class="ltx_text" style="font-size:90%;">0.619</span></td>
<td id="A6.T5.2.1.3.2.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A6.T5.2.1.3.2.5.1" class="ltx_text" style="font-size:90%;">0.02076</span></td>
</tr>
<tr id="A6.T5.2.1.4.3" class="ltx_tr">
<td id="A6.T5.2.1.4.3.1" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.4.3.1.1" class="ltx_text" style="font-size:90%;">disc. RMS</span></td>
<td id="A6.T5.2.1.4.3.2" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.4.3.2.1" class="ltx_text" style="font-size:90%;">21.6</span></td>
<td id="A6.T5.2.1.4.3.3" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.4.3.3.1" class="ltx_text" style="font-size:90%;">154</span></td>
<td id="A6.T5.2.1.4.3.4" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.4.3.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.686</span></td>
<td id="A6.T5.2.1.4.3.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A6.T5.2.1.4.3.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.00348</span></td>
</tr>
<tr id="A6.T5.2.1.5.4" class="ltx_tr">
<td id="A6.T5.2.1.5.4.1" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.5.4.1.1" class="ltx_text" style="font-size:90%;">cont. RMS</span></td>
<td id="A6.T5.2.1.5.4.2" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.5.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">19.9</span></td>
<td id="A6.T5.2.1.5.4.3" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">152</span></td>
<td id="A6.T5.2.1.5.4.4" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.5.4.4.1" class="ltx_text" style="font-size:90%;">0.657</span></td>
<td id="A6.T5.2.1.5.4.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A6.T5.2.1.5.4.5.1" class="ltx_text" style="font-size:90%;">0.00361</span></td>
</tr>
<tr id="A6.T5.2.1.6.5" class="ltx_tr">
<td id="A6.T5.2.1.6.5.1" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.6.5.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#808080;">Text Prompt</span></td>
<td id="A6.T5.2.1.6.5.2" class="ltx_td"></td>
<td id="A6.T5.2.1.6.5.3" class="ltx_td"></td>
<td id="A6.T5.2.1.6.5.4" class="ltx_td"></td>
<td id="A6.T5.2.1.6.5.5" class="ltx_td ltx_nopad_r"></td>
</tr>
<tr id="A6.T5.2.1.7.6" class="ltx_tr">
<td id="A6.T5.2.1.7.6.1" class="ltx_td ltx_align_left">
<span id="A6.T5.2.1.7.6.1.1" class="ltx_text" style="font-size:90%;">w/o RMS</span><cite class="ltx_cite ltx_citemacro_cite"><span id="A6.T5.2.1.7.6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="A6.T5.2.1.7.6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="A6.T5.2.1.7.6.2" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.7.6.2.1" class="ltx_text" style="font-size:90%;">59.8</span></td>
<td id="A6.T5.2.1.7.6.3" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.7.6.3.1" class="ltx_text" style="font-size:90%;">397</span></td>
<td id="A6.T5.2.1.7.6.4" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.7.6.4.1" class="ltx_text" style="font-size:90%;">0.443</span></td>
<td id="A6.T5.2.1.7.6.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A6.T5.2.1.7.6.5.1" class="ltx_text" style="font-size:90%;">0.0276</span></td>
</tr>
<tr id="A6.T5.2.1.8.7" class="ltx_tr">
<td id="A6.T5.2.1.8.7.1" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.8.7.1.1" class="ltx_text" style="font-size:90%;">disc. RMS</span></td>
<td id="A6.T5.2.1.8.7.2" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.8.7.2.1" class="ltx_text" style="font-size:90%;">46.8</span></td>
<td id="A6.T5.2.1.8.7.3" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.8.7.3.1" class="ltx_text" style="font-size:90%;">333</span></td>
<td id="A6.T5.2.1.8.7.4" class="ltx_td ltx_align_left"><span id="A6.T5.2.1.8.7.4.1" class="ltx_text" style="font-size:90%;">0.504</span></td>
<td id="A6.T5.2.1.8.7.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="A6.T5.2.1.8.7.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.00496</span></td>
</tr>
<tr id="A6.T5.2.1.9.8" class="ltx_tr">
<td id="A6.T5.2.1.9.8.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="A6.T5.2.1.9.8.1.1" class="ltx_text" style="font-size:90%;">cont. RMS</span></td>
<td id="A6.T5.2.1.9.8.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="A6.T5.2.1.9.8.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">44.6</span></td>
<td id="A6.T5.2.1.9.8.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="A6.T5.2.1.9.8.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">323</span></td>
<td id="A6.T5.2.1.9.8.4" class="ltx_td ltx_align_left ltx_border_bb"><span id="A6.T5.2.1.9.8.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.531</span></td>
<td id="A6.T5.2.1.9.8.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb"><span id="A6.T5.2.1.9.8.5.1" class="ltx_text" style="font-size:90%;">0.00498</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="A6.T5.5.1.1" class="ltx_text ltx_font_bold">Table 5</span>: </span>Performance of RMS2Sound module. w/o RMS: pretrained AudioLDM without RMS condition, disc. RMS: discretized RMS in 64 bins, cont. RMS: continuous RMS.</figcaption>
</figure>
<div id="A6.p1" class="ltx_para">
<p id="A6.p1.1" class="ltx_p"><span id="A6.p1.1.1" class="ltx_text" style="font-size:90%;">Table </span><a href="#A6.T5" title="Table 5 ‣ Appendix F Ablation Study for RMS2Sound ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="A6.p1.1.2" class="ltx_text" style="font-size:90%;"> summarizes the performance of RMS2Sound on audio and text prompts with ground-truth RMS conditions. The discretized RMS performed comparably to the original continuous RMS in terms of audio quality, semantic similarity, and temporal alignment. In contrast, the vanilla text-to-audio model without RMS conditioning (AudioLDM) underperformed in every metric. This supports our assumption that realistic RMS conditions enhance the overall quality of generated audio.</span></p>
</div>
</section>
<section id="A7" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Inference for Other Models</h2>

<div id="A7.p1" class="ltx_para">
<p id="A7.p1.1" class="ltx_p"><span id="A7.p1.1.1" class="ltx_text" style="font-size:90%;">Although some models (i.e., SpecVQGAN and Diff-Foley) do not receive semantic prompts, we included them in the evaluation to compare the performance mainly on temporal alignment. Detailed methods to match the inference settings of different models are explained in the following paragraphs.</span></p>
</div>
<div id="A7.p2" class="ltx_para ltx_noindent">
<p id="A7.p2.1" class="ltx_p"><span id="A7.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">SpecVQGAN<cite class="ltx_cite ltx_citemacro_cite"><span id="A7.p2.1.1.1.1" class="ltx_text ltx_font_medium">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="A7.p2.1.1.2.2" class="ltx_text ltx_font_medium">]</span></cite></span><span id="A7.p2.1.2" class="ltx_text" style="font-size:90%;"> SpecVQGAN generates 10 seconds of audio from 21.5 fps video. We utilize the official code and checkpoint. The model </span><span id="A7.p2.1.3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">‘2021-07-30T21-34-25_vggsound_transformer’</span><span id="A7.p2.1.4" class="ltx_text" style="font-size:90%;"> was used.</span></p>
</div>
<div id="A7.p3" class="ltx_para ltx_noindent">
<p id="A7.p3.1" class="ltx_p"><span id="A7.p3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Diff-Foley<cite class="ltx_cite ltx_citemacro_cite"><span id="A7.p3.1.1.1.1" class="ltx_text ltx_font_medium">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="A7.p3.1.1.2.2" class="ltx_text ltx_font_medium">]</span></cite></span><span id="A7.p3.1.2" class="ltx_text" style="font-size:90%;">
Official code and checkpoint were used. As Diff-Foley generates 8-second audio from 4fps video, we made two inferences: one with video frames from 0-8 seconds and another from 2-10 seconds. We then concatenated the entire first segment with the latter 2 seconds of the second segment to produce a 10-second audio. We used the official repository’s default settings for inference (4.5 classifier-free guidance scale, 50 classifier guidance scale, 25 steps with DPM Solver).</span></p>
</div>
<div id="A7.p4" class="ltx_para ltx_noindent">
<p id="A7.p4.2" class="ltx_p"><span id="A7.p4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">CondFoleyGen<cite class="ltx_cite ltx_citemacro_cite"><span id="A7.p4.2.1.1.1" class="ltx_text ltx_font_medium">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="A7.p4.2.1.2.2" class="ltx_text ltx_font_medium">]</span></cite></span><span id="A7.p4.2.2" class="ltx_text" style="font-size:90%;"> We use the official code and checkpoint of CondFoleyGen. Although CondFoleyGen generates 2 seconds of audio from 15fps video, the official code was implemented to generate multiples of 2 seconds of audio by adjusting the parameter </span><math id="A7.p4.1.m1.1" class="ltx_Math" alttext="W\_scale" display="inline"><semantics id="A7.p4.1.m1.1a"><mrow id="A7.p4.1.m1.1.1" xref="A7.p4.1.m1.1.1.cmml"><mi mathsize="90%" id="A7.p4.1.m1.1.1.2" xref="A7.p4.1.m1.1.1.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="A7.p4.1.m1.1.1.1" xref="A7.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" mathvariant="normal" id="A7.p4.1.m1.1.1.3" xref="A7.p4.1.m1.1.1.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="A7.p4.1.m1.1.1.1a" xref="A7.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.1.m1.1.1.4" xref="A7.p4.1.m1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A7.p4.1.m1.1.1.1b" xref="A7.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.1.m1.1.1.5" xref="A7.p4.1.m1.1.1.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="A7.p4.1.m1.1.1.1c" xref="A7.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.1.m1.1.1.6" xref="A7.p4.1.m1.1.1.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="A7.p4.1.m1.1.1.1d" xref="A7.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.1.m1.1.1.7" xref="A7.p4.1.m1.1.1.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="A7.p4.1.m1.1.1.1e" xref="A7.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.1.m1.1.1.8" xref="A7.p4.1.m1.1.1.8.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="A7.p4.1.m1.1b"><apply id="A7.p4.1.m1.1.1.cmml" xref="A7.p4.1.m1.1.1"><times id="A7.p4.1.m1.1.1.1.cmml" xref="A7.p4.1.m1.1.1.1"></times><ci id="A7.p4.1.m1.1.1.2.cmml" xref="A7.p4.1.m1.1.1.2">𝑊</ci><ci id="A7.p4.1.m1.1.1.3.cmml" xref="A7.p4.1.m1.1.1.3">_</ci><ci id="A7.p4.1.m1.1.1.4.cmml" xref="A7.p4.1.m1.1.1.4">𝑠</ci><ci id="A7.p4.1.m1.1.1.5.cmml" xref="A7.p4.1.m1.1.1.5">𝑐</ci><ci id="A7.p4.1.m1.1.1.6.cmml" xref="A7.p4.1.m1.1.1.6">𝑎</ci><ci id="A7.p4.1.m1.1.1.7.cmml" xref="A7.p4.1.m1.1.1.7">𝑙</ci><ci id="A7.p4.1.m1.1.1.8.cmml" xref="A7.p4.1.m1.1.1.8">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.p4.1.m1.1c">W\_scale</annotation></semantics></math><span id="A7.p4.2.3" class="ltx_text" style="font-size:90%;">. We set </span><math id="A7.p4.2.m2.1" class="ltx_Math" alttext="W\_scale" display="inline"><semantics id="A7.p4.2.m2.1a"><mrow id="A7.p4.2.m2.1.1" xref="A7.p4.2.m2.1.1.cmml"><mi mathsize="90%" id="A7.p4.2.m2.1.1.2" xref="A7.p4.2.m2.1.1.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="A7.p4.2.m2.1.1.1" xref="A7.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" mathvariant="normal" id="A7.p4.2.m2.1.1.3" xref="A7.p4.2.m2.1.1.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="A7.p4.2.m2.1.1.1a" xref="A7.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.2.m2.1.1.4" xref="A7.p4.2.m2.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="A7.p4.2.m2.1.1.1b" xref="A7.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.2.m2.1.1.5" xref="A7.p4.2.m2.1.1.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="A7.p4.2.m2.1.1.1c" xref="A7.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.2.m2.1.1.6" xref="A7.p4.2.m2.1.1.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="A7.p4.2.m2.1.1.1d" xref="A7.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.2.m2.1.1.7" xref="A7.p4.2.m2.1.1.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="A7.p4.2.m2.1.1.1e" xref="A7.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="A7.p4.2.m2.1.1.8" xref="A7.p4.2.m2.1.1.8.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="A7.p4.2.m2.1b"><apply id="A7.p4.2.m2.1.1.cmml" xref="A7.p4.2.m2.1.1"><times id="A7.p4.2.m2.1.1.1.cmml" xref="A7.p4.2.m2.1.1.1"></times><ci id="A7.p4.2.m2.1.1.2.cmml" xref="A7.p4.2.m2.1.1.2">𝑊</ci><ci id="A7.p4.2.m2.1.1.3.cmml" xref="A7.p4.2.m2.1.1.3">_</ci><ci id="A7.p4.2.m2.1.1.4.cmml" xref="A7.p4.2.m2.1.1.4">𝑠</ci><ci id="A7.p4.2.m2.1.1.5.cmml" xref="A7.p4.2.m2.1.1.5">𝑐</ci><ci id="A7.p4.2.m2.1.1.6.cmml" xref="A7.p4.2.m2.1.1.6">𝑎</ci><ci id="A7.p4.2.m2.1.1.7.cmml" xref="A7.p4.2.m2.1.1.7">𝑙</ci><ci id="A7.p4.2.m2.1.1.8.cmml" xref="A7.p4.2.m2.1.1.8">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.p4.2.m2.1c">W\_scale</annotation></semantics></math><span id="A7.p4.2.4" class="ltx_text" style="font-size:90%;"> to 5 to generate 10 seconds of audio. The model trained with the Greatest Hits dataset was used.</span></p>
</div>
<div id="A7.p5" class="ltx_para ltx_noindent">
<p id="A7.p5.1" class="ltx_p"><span id="A7.p5.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">SyncFusion<cite class="ltx_cite ltx_citemacro_cite"><span id="A7.p5.1.1.1.1" class="ltx_text ltx_font_medium">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="A7.p5.1.1.2.2" class="ltx_text ltx_font_medium">]</span></cite></span><span id="A7.p5.1.2" class="ltx_text" style="font-size:90%;">
SyncFusion was trained to generate 5.46 seconds of audio from 15fps video. Using the official code and model checkpoint without augmentation, we generated 5-second audio clips and concatenated them. For text prompts, we used the same text as Video-Foley. Default settings for inference were followed (150 steps with the DDIM sampler).</span></p>
</div>
</section>
<section id="A8" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Additional Case Study on Video-Foley</h2>

<figure id="A8.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A8.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/fig_action_A_rms.png" id="A8.F9.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="699" height="563" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A8.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/fig_action_C_rms.png" id="A8.F9.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="699" height="563" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A8.F9.4.1.1" class="ltx_text ltx_font_bold">Fig. 9</span>: </span>Controlling timbre and energy transition: Video-Foley generates hit and scratch sound events at desired positions using RMS guidance.</figcaption>
</figure>
<div id="A8.p1" class="ltx_para">
<p id="A8.p1.1" class="ltx_p"><span id="A8.p1.1.1" class="ltx_text" style="font-size:90%;">As an extension of Section </span><a href="#S4.SS2" title="4.2 Analysis on Video-to-Sound ‣ 4 Result ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4.2</span></a><span id="A8.p1.1.2" class="ltx_text" style="font-size:90%;">, we provide additional demonstrations to highlight the performance of Video-Foley. Figures </span><a href="#A8.F9.sf1" title="In Figure 9 ‣ Appendix H Additional Case Study on Video-Foley ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">9(a)</span></a><span id="A8.p1.1.3" class="ltx_text" style="font-size:90%;"> and </span><a href="#A8.F9.sf2" title="In Figure 9 ‣ Appendix H Additional Case Study on Video-Foley ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">9(b)</span></a><span id="A8.p1.1.4" class="ltx_text" style="font-size:90%;"> show examples where Video-Foley successfully predicts the RMS curve for sound events with different timbres, generating synchronized scratching and hitting sounds. Figure </span><a href="#A9.F10" title="Figure 10 ‣ Appendix I Unlocking the Potential of RMS-ControlNet ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">10</span></a><span id="A8.p1.1.5" class="ltx_text" style="font-size:90%;"> illustrates how Video-Foley recommends the appropriate intensity for each sound event, accurately reflecting the video’s nuance to generate sound. These capabilities are due to Video2RMS’s ability to distinguish action types (e.g., hit and scratch), timing, and intensity and predict their corresponding energy transitions, and RMS2Sound’s ability to generate appropriate timbre and nuance at the corresponding timings. Additionally, RMS helps enhance temporal alignment. Figure </span><a href="#A9.F11" title="Figure 11 ‣ Appendix I Unlocking the Potential of RMS-ControlNet ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">11</span></a><span id="A8.p1.1.6" class="ltx_text" style="font-size:90%;"> demonstrates Video-Foley generating hitting sounds synchronized with the video in terms of start and end timing, all without using any human annotation. Refer to Section </span><a href="#A5.SS1" title="E.1 Ablation Study on Using Onset Annotations ‣ Appendix E Ablation Study for Video2RMS ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">E.1</span></a><span id="A8.p1.1.7" class="ltx_text" style="font-size:90%;"> for the impact of RMS joint training on the Video2Onset task.</span></p>
</div>
</section>
<section id="A9" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix I </span>Unlocking the Potential of RMS-ControlNet</h2>

<figure id="A9.F10" class="ltx_figure">
<div id="A9.F10.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:297.5pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-266.3pt,214.6pt) scale(0.408984483037553,0.408984483037553) ;"><img src="/html/2408.11915/assets/Fig/fig_intensity_A_rms.png" id="A9.F10.1.g1" class="ltx_graphics ltx_img_landscape" width="1247" height="1005" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A9.F10.5.1.1" class="ltx_text ltx_font_bold">Fig. 10</span>: </span>Controlling intensity and nuance: Video-Foley predicts different levels and shapes of the RMS curve for each sound event.</figcaption>
</figure>
<figure id="A9.F11" class="ltx_figure">
<div id="A9.F11.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:297.5pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-266.3pt,214.6pt) scale(0.408984483037553,0.408984483037553) ;"><img src="/html/2408.11915/assets/Fig/fig_07_rms.png" id="A9.F11.1.g1" class="ltx_graphics ltx_img_landscape" width="1247" height="1005" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A9.F11.5.1.1" class="ltx_text ltx_font_bold">Fig. 11</span>: </span>Controlling temporal alignment: Video-Foley predicts the most accurate start and end timing for each sound event.</figcaption>
</figure>
<figure id="A9.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A9.F12.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/fig_rms_1_rms.png" id="A9.F12.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="699" height="539" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A9.F12.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/fig_rms_2_rms.png" id="A9.F12.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="699" height="539" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A9.F12.4.1.1" class="ltx_text ltx_font_bold">Fig. 12</span>: </span>Controlling energy transition: RMS-ControlNet can guide the temporal dynamics of sound intensity through RMS while reflecting the given semantic text prompt.</figcaption>
</figure>
<div id="A9.p1" class="ltx_para">
<p id="A9.p1.1" class="ltx_p"><span id="A9.p1.1.1" class="ltx_text" style="font-size:90%;">RMS-ControlNet, trained for additional temporal event guidance with RMS condition on top of the pretrained Text-to-Audio model (AudioLDM), shows great potential in controllable audio generation tasks.
We provide demos to showcase its high controllability, which prior TTA models were not able to achieve.</span></p>
</div>
<div id="A9.p2" class="ltx_para">
<p id="A9.p2.1" class="ltx_p"><span id="A9.p2.1.1" class="ltx_text" style="font-size:90%;">Figure </span><a href="#A9.F12" title="Figure 12 ‣ Appendix I Unlocking the Potential of RMS-ControlNet ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">12</span></a><span id="A9.p2.1.2" class="ltx_text" style="font-size:90%;"> shows how RMS can be simply and intuitively used for temporal guidance, including timing, nuance, and locational information. With the same text prompt, RMS-ControlNet guides AudioLDM to generate audio that matches different input RMS conditions (A-shaped, monotonic decrease, monotonic increase, and V-shaped) while maintaining audio semantics. Such intensity dynamics are often used in Foley sound generation, which current text-to-audio models struggle to reflect with sufficient temporal accuracy.
Figure </span><a href="#A9.F13" title="Figure 13 ‣ Appendix I Unlocking the Potential of RMS-ControlNet ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">13</span></a><span id="A9.p2.1.3" class="ltx_text" style="font-size:90%;"> shows how text prompt can adjust audio semantics along with RMS guidance. Using the same input RMS, users can control audio semantics such as the sound source and timbre (Figure </span><a href="#A9.F13.sf1" title="In Figure 13 ‣ Appendix I Unlocking the Potential of RMS-ControlNet ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">13(a)</span></a><span id="A9.p2.1.4" class="ltx_text" style="font-size:90%;"> &amp; </span><a href="#A9.F13.sf2" title="In Figure 13 ‣ Appendix I Unlocking the Potential of RMS-ControlNet ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">13(b)</span></a><span id="A9.p2.1.5" class="ltx_text" style="font-size:90%;">) and timbre and nuance (Figure </span><a href="#A9.F13.sf3" title="In Figure 13 ‣ Appendix I Unlocking the Potential of RMS-ControlNet ‣ Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">13(c)</span></a><span id="A9.p2.1.6" class="ltx_text" style="font-size:90%;">). This highlights RMS-ControlNet’s ability to guarantee high controllability in RMS guidance for timing and intensity while preserving the power in text-to-audio generation.</span></p>
</div>
<figure id="A9.F13" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A9.F13.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/fig_video_game2_rms.png" id="A9.F13.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="699" height="516" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A9.F13.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/fig_video_guitar_rms.png" id="A9.F13.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="699" height="516" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A9.F13.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.11915/assets/Fig/fig_video_dog_rms.png" id="A9.F13.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="699" height="517" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="A9.F13.4.1.1" class="ltx_text ltx_font_bold">Fig. 13</span>: </span>Controlling timbre and nuance: RMS-ControlNet can guide the sound source and timbre through a text prompt while controlling timing and intensity through RMS conditions.</figcaption>
</figure>
</section>
<section id="A10" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix J </span>Broader Impact</h2>

<div id="A10.p1" class="ltx_para">
<p id="A10.p1.1" class="ltx_p"><span id="A10.p1.1.1" class="ltx_text" style="font-size:90%;">The broader impact of this research project extends across multiple domains, offering significant advancements in both video-to-sound generation and controllable audio generation. In the entertainment industry, particularly in film, gaming, and virtual reality, our work can greatly enhance the efficiency and creativity of Foley sound production, reducing the manual effort required while ensuring precise synchronization of audio with visual elements. This could lead to more immersive and accessible content creation, enabling smaller studios and independent creators to produce high-quality multimedia experiences.</span></p>
</div>
<div id="A10.p2" class="ltx_para">
<p id="A10.p2.1" class="ltx_p"><span id="A10.p2.1.1" class="ltx_text" style="font-size:90%;">In the field of controllable audio generation, our approach offers a new level of precision and flexibility, empowering users to tailor audio outputs to specific needs, whether for artistic expression, accessibility, or adaptive technology. For instance, this technology could be used to create more realistic soundscapes in virtual environments, improve auditory cues for visually impaired users, or generate educational content with dynamic and contextually relevant audio.</span></p>
</div>
<div id="A10.p3" class="ltx_para">
<p id="A10.p3.1" class="ltx_p"><span id="A10.p3.1.1" class="ltx_text" style="font-size:90%;">However, the ethical implications of this technology must be carefully considered. The ability to generate highly realistic audio synchronized with video raises concerns related to deepfakes and the potential misuse of this technology for creating deceptive or harmful content. Such misuse could have serious implications for privacy, misinformation, and human rights, as it could be employed to fabricate audio-visual evidence or manipulate public perception.</span></p>
</div>
<div id="A10.p4" class="ltx_para">
<p id="A10.p4.1" class="ltx_p"><span id="A10.p4.1.1" class="ltx_text" style="font-size:90%;">To mitigate these risks, it is crucial to establish ethical guidelines and promote responsible use of this technology. Developers and users should be aware of the potential for abuse and work towards implementing safeguards to prevent unauthorized or malicious use. Additionally, ongoing dialogue with policymakers, ethicists, and the public is essential to ensure that the benefits of this technology are realized while minimizing the potential for harm, ultimately protecting individual rights and maintaining public trust.</span></p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.11914" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.11915" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.11915">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.11915" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.11916" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 12:10:36 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
