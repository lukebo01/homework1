<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.08011] An inclusive review on deep learning techniques and their scope in handwriting recognition</title><meta property="og:description" content="Deep learning expresses a category of machine learning algorithms that have the capability to combine raw inputs into intermediate features layers. These deep learning algorithms have demonstrated great results in diff…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="An inclusive review on deep learning techniques and their scope in handwriting recognition">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="An inclusive review on deep learning techniques and their scope in handwriting recognition">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.08011">

<!--Generated on Sun May  5 16:32:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">An inclusive review on deep learning techniques and their scope in handwriting recognition</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <a target="_blank" href="https://orcid.org/0000-0000-0000-0000" title="" class="ltx_ref ltx_href"><img src="/html/2404.08011/assets/x1.png" id="id1.1.1.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"> Sukhdeep Singh</a>
<br class="ltx_break">D.M. College (Affiliated to Panjab University, Chandigarh)
<br class="ltx_break">Moga, Punjab, India
<br class="ltx_break"><span id="id4.4.id1" class="ltx_text ltx_font_typewriter">sukha13@ymail.com</span> 
<br class="ltx_break">&amp;<a target="_blank" href="https://orcid.org/0000-0000-0000-0000" title="" class="ltx_ref ltx_href"><img src="/html/2404.08011/assets/x1.png" id="id2.2.2.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"> Sudhir Rohilla</a> 
<br class="ltx_break">Department of Computer Science
<br class="ltx_break">Gopichand Arya Mahila College
<br class="ltx_break">Abohar, Punjab, India
<br class="ltx_break"><span id="id5.5.id2" class="ltx_text ltx_font_typewriter">rohilla2209@gmail.com</span> 
<br class="ltx_break">&amp;<a target="_blank" href="https://orcid.org/0000-0000-0000-0000" title="" class="ltx_ref ltx_href"><img src="/html/2404.08011/assets/x1.png" id="id3.3.3.g1" class="ltx_graphics ltx_img_square" width="5" height="5" alt="[Uncaptioned image]"> Anuj Sharma</a> 
<br class="ltx_break">Department of Computer Science and Applications
<br class="ltx_break">Panjab University, Chandigarh, India
<br class="ltx_break"><span id="id6.6.id3" class="ltx_text ltx_font_typewriter">anujs@pu.ac.in</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">Deep learning expresses a category of machine learning algorithms that have the capability to combine raw inputs into intermediate features layers. These deep learning algorithms have demonstrated great results in different fields. Deep learning has particularly witnessed for a great achievement of human level performance across a number of domains in computer vision and pattern recognition. For the achievement of state-of-the-art performances in diverse domains, the deep learning used different architectures and these architectures used activation functions to perform various computations between hidden and output layers of any architecture. This paper presents a survey on the existing studies of deep learning in handwriting recognition field. Even though the recent progress indicates that the deep learning methods has provided valuable means for speeding up or proving accurate results in handwriting recognition, but following from the extensive literature survey, the present study finds that the deep learning has yet to revolutionize more and has to resolve many of the most pressing challenges in this field, but promising advances have been made on the prior state of the art. Additionally, an inadequate availability of labelled data to train presents problems in this domain. Nevertheless, the present handwriting recognition survey foresees deep learning enabling changes at both bench and bedside with the potential to transform several domains as image processing, speech recognition, computer vision, machine translation, robotics and control, medical imaging, medical information processing, bio-informatics, natural language processing, cyber security, and many others.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.5" class="ltx_p"><em id="p1.5.1" class="ltx_emph ltx_font_bold ltx_font_italic">Keywords</em> Deep learning  <math id="p1.1.m1.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.1.m1.1a"><mo id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p1.1.m1.1b"><ci id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.1.m1.1c">\cdot</annotation></semantics></math>
Classification  <math id="p1.2.m2.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.2.m2.1a"><mo id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p1.2.m2.1b"><ci id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.2.m2.1c">\cdot</annotation></semantics></math>
Handwriting Recognition  <math id="p1.3.m3.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.3.m3.1a"><mo id="p1.3.m3.1.1" xref="p1.3.m3.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p1.3.m3.1b"><ci id="p1.3.m3.1.1.cmml" xref="p1.3.m3.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.3.m3.1c">\cdot</annotation></semantics></math>
CNN  <math id="p1.4.m4.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.4.m4.1a"><mo id="p1.4.m4.1.1" xref="p1.4.m4.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p1.4.m4.1b"><ci id="p1.4.m4.1.1.cmml" xref="p1.4.m4.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.4.m4.1c">\cdot</annotation></semantics></math>
RNN  <math id="p1.5.m5.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.5.m5.1a"><mo id="p1.5.m5.1.1" xref="p1.5.m5.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="p1.5.m5.1b"><ci id="p1.5.m5.1.1.cmml" xref="p1.5.m5.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.5.m5.1c">\cdot</annotation></semantics></math>
LSTM</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">The intelligent act with synthesis and analysis of computational agents represents Artificial Intelligence (AI). Here, an agent is who completes the signed goal with various learning techniques and training of data. The agent when computationally represented, it is called computational agent <cite class="ltx_cite ltx_citemacro_cite">David L. Poole (<a href="#bib.bib1" title="" class="ltx_ref">2010</a>); Elaine Rich (<a href="#bib.bib2" title="" class="ltx_ref">2010</a>)</cite>. The artificial intelligence has made our life very exciting with state-of-the-art research in this area. However, the research in AI regularly demands new paradigms that could further help in error-free AI systems. The AI has many areas of research such as machine learning, data mining, intelligent tutoring, case-based reasoning, multi-agent planning, scheduling, uncertain reasoning, natural language understanding and translation, vision, virtual reality, games, robotics and other topics <cite class="ltx_cite ltx_citemacro_cite">Zawacki-Richter et al. (<a href="#bib.bib3" title="" class="ltx_ref">2019</a>); Chen et al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>); Nilsson (<a href="#bib.bib5" title="" class="ltx_ref">2010</a>); Goodrich and Schultz (<a href="#bib.bib6" title="" class="ltx_ref">2007</a>); Buczak and Guven (<a href="#bib.bib7" title="" class="ltx_ref">2016</a>); Bahrammirzaee (<a href="#bib.bib8" title="" class="ltx_ref">2010</a>); Bengio et al. (<a href="#bib.bib9" title="" class="ltx_ref">2013</a>); Brougham and Haar (<a href="#bib.bib10" title="" class="ltx_ref">2018</a>); Corvalan (<a href="#bib.bib11" title="" class="ltx_ref">2018</a>); Ghahramani (<a href="#bib.bib12" title="" class="ltx_ref">2015</a>); <a href="#bib.bib13" title="" class="ltx_ref">Castelvecchi </a></cite>. The one of today’s popular research fields in AI is Machine Learning (ML). The machine learning mainly includes intelligent system development using training of data. Therefore, the ML based system model developed with train data further decides the nature of future data as test data. The common techniques of machine learning are data understanding, regression, clustering, classification, dimension reduction, deep learning, big data, online learning etc <cite class="ltx_cite ltx_citemacro_cite">McDonald (<a href="#bib.bib14" title="" class="ltx_ref">1989</a>); Musumeci et al. (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>); Bishop (<a href="#bib.bib16" title="" class="ltx_ref">2006</a>); Chapelle et al. (<a href="#bib.bib17" title="" class="ltx_ref">2006</a>); Collobert et al. (<a href="#bib.bib18" title="" class="ltx_ref">2011</a>); <a href="#bib.bib19" title="" class="ltx_ref">Du et al. </a>; Freund and Schapire (<a href="#bib.bib20" title="" class="ltx_ref">1997</a>); Grira et al. (<a href="#bib.bib21" title="" class="ltx_ref">2004</a>); Guyon and Elisseeff (<a href="#bib.bib22" title="" class="ltx_ref">2006</a>); LeCun et al. (<a href="#bib.bib23" title="" class="ltx_ref">2015a</a>); Pedregosa et al. (<a href="#bib.bib24" title="" class="ltx_ref">2011</a>); Vapnik (<a href="#bib.bib25" title="" class="ltx_ref">1998</a>)</cite>. Here, each ML technique offers uniqueness in terms of data handling, feature computation and respective output. Data understanding is data normalization and processing of data; regression is promising statistical area to understand continuous type of data; clustering allow class formation of data; classification distinguish data for various classes; dimension reduction reduce feature size of data and retain useful information for data; deep learning is promising data classification and understanding area; big data is dedicated to handle large amount of data using established scientific methods; online learning refers to handle data as it comes and not in conventional batch mode. The recent research in ML suggests that deep learning is one of the promising techniques to achieve high accuracy results. Therefore, deep learning studied by many scientists in recent past and it has been observed that suitable literature of deep learning always helps for readers working in this area. Especially, suitable review of deep learning two popular methods as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) will be meaningful from research and development point of view <cite class="ltx_cite ltx_citemacro_cite">Abdel-Hamid et al. (<a href="#bib.bib26" title="" class="ltx_ref">2014</a>); Cho et al. (<a href="#bib.bib27" title="" class="ltx_ref">2014</a>); Zhao et al. (<a href="#bib.bib28" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">In machine learning, representational learning allow automatically appropriate way to represent data. Deep learning is one such technique which includes representation learning feature. The progression of learned transformation helps deep learning to achieve automatic representation of data. This has been realised in recent past that deep learning-based applications achieved promising results for large amount of data problem, which were not possible to automate data representation before deep learning techniques. The popular deep learning model and its practical implementation based quintessential example is deep network. These deep networks are inspired from common machine learning technique as multilayer perceptron which is a common neural network algorithm. The depth of deep network as a computer program is organised in such a way that each layer meant for a specific purpose and it could recall other layers’ computer memory when working in parallel. This way, the network with more depth allows many instructions in a sequence. The two approaches of deep networks as CNN and RNN proved state-of-the-art results in recent past. Further, LSTM and BLSTM are two particular forms of RNN. The two competitive techniques as CNN and RNN share many commonalities in working, however, they do differ in suitability of various types of data. Interestingly, hybrid technique using CNN and RNN is another feasible technique with promising results.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">In literature, we find many studies that include the working of CNN and RNN. However, overall working of CNN and RNN with their architecture, mathematical formulation and implementation from review point of view needs attention and is presented in this paper. This paper has been presented with updated literature information and focused on theory as well as the implementation of deep networks. This review is aiming to answer the question of the working of deep networks, CNN and RNN, and their performance in handwriting recognition in recent past with the availability of latest system configurations. As a result, we highlight in summary the following contributions as: (i) deep networks outperform in handwriting recognition, (ii) the CNN and RNN results in state-of-the-art results for real life challenging datasets, (iii) the architecture of deep networks offers enormous scope to researchers to enhance its architecture, and further offer many areas of research to improve deep networks. Moreover, this paper also presents general observations of deep networks and their applications in handwriting recognition based on suitable findings from literature work. In this manner, it has been analysed that deep networks solely justify deep learning representative to real life handwriting recognition applications. This analysis is based on the results discussed in this paper using benchmark datasets with variants of deep learning approaches.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">This paper maintains continuity as deep networks, CNN and RNN, architectures and DL results for handwriting recognition in a sequence for better understanding from the reader’s point of view. The rest of the paper is organized as follows. This article describes the deep networks’ fundamentals and evolution in section 2. The section 3 demonstrates different deep learning architectures. The section 4 presents existing literature results using deep networks as CNN and RNN in handwriting recognition. The section 6 presents the general observations based on literature finding for CNN and RNN. The last section 7 concludes this article with findings and scope of future work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Deep Forward Networks</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">Deep learning quintessential are forward networks and forward networks are commonly called deep forward networks. The forward networks are also known as multi-layer perceptron as it follows multiple layers architecture using perceptron concept. The CNN and RNN are the emergent variants of deep learning framework based on neural networks. Therefore, prior understanding of neural networks is important in this review to know how neural networks work and CNN or RNN based on neural networks. Before the introduction of deep neural networks, this section illustrates the evolution of neural networks with common benchmark algorithms of literature including most preferred backpropagation algorithm.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">In early works, McCulloch and Pitts neuron was designed in 1943, it mainly included the combination of logic functions with the concept of threshold <cite class="ltx_cite ltx_citemacro_cite">McCulloch and Pitts (<a href="#bib.bib29" title="" class="ltx_ref">1943</a>)</cite>. The Hebb network was designed in 1949, which included two active neurons simultaneously with their strong inter-connections <cite class="ltx_cite ltx_citemacro_cite">Hebb (<a href="#bib.bib30" title="" class="ltx_ref">1949</a>)</cite>. One major contribution was perceptron model in 1958 by Rossenblatt, which included weights in connection path with their adjustment <cite class="ltx_cite ltx_citemacro_cite">Rossenblatt (<a href="#bib.bib31" title="" class="ltx_ref">1958</a>)</cite>. In 1960, Adaline network was built with the ability to reduce difference between net input weights and out weights and resulted in minimizing the mean error rates <cite class="ltx_cite ltx_citemacro_cite">Windrow and Hoff (<a href="#bib.bib32" title="" class="ltx_ref">1960</a>)</cite>. One major development noticed for unsupervised learning in 1982, Kohonen introduced Kohonen self-organizing maps where inputs were clustered together to form output neurons <cite class="ltx_cite ltx_citemacro_cite">Kohonen (<a href="#bib.bib33" title="" class="ltx_ref">1982</a>)</cite>. This work was among initial findings to understand neural networks in supervised and unsupervised areas. One such study with fixed weights was done for Hopfield networks to act as associative memory nets <cite class="ltx_cite ltx_citemacro_cite">Hopfield (<a href="#bib.bib34" title="" class="ltx_ref">1982</a>)</cite>. In 1986, a complete neural network algorithm, with forward and backward ability to update weights and based on Multi-Layer Perceptron (MLP), was introduced as backpropagation algorithm <cite class="ltx_cite ltx_citemacro_cite">Rumelhart et al. (<a href="#bib.bib35" title="" class="ltx_ref">1986</a>)</cite>. This backpropagation algorithm was a complete multi-layer perceptron technique. This architecture included input, hidden and output layers, forward moves to update weights and backward moves to improve weights with propagated error information at output unit in each iteration. After backpropagation, neural networks witnessed many improvements subject to the nature of problem. Few networks were adaptive resonance theory, radial basis functions, neocognition until 1990 <cite class="ltx_cite ltx_citemacro_cite">Carpenter and Grossberg (<a href="#bib.bib36" title="" class="ltx_ref">1988</a>); Broomhead and Lowe (<a href="#bib.bib37" title="" class="ltx_ref">1988</a>); Fukushima (<a href="#bib.bib38" title="" class="ltx_ref">2010</a>)</cite>. The main development with state-of-the-art results were reported with MLP until the introduction of convolution networks in 2000.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">The MLP or deep forward network is a massively parallel distributed processor made up of simple processing units, which has a natural propensity for storing experiential knowledge and making it available for use <cite class="ltx_cite ltx_citemacro_cite">Haykin (<a href="#bib.bib39" title="" class="ltx_ref">1998</a>)</cite>. It is a directed graph consisting of nodes with interconnecting synaptic and activation links with main properties as: each neuron is represented by a set of linear synaptic links with bias, and a possibly nonlinear activation link; the synaptic links of a neuron weight to their respective input signals; the weighted sum of the input signals defines the induced local field of the current neuron; thus, the activation link squashes the induced local field of the neuron to produce an output. The presence of one or more layers between input and output layers are called hidden layers and nodes of corresponding layers are hidden neurons. This enhances system learning capability and is referred as multi-layer networks and results in MLP. The major characteristics of MLP include: the model of each neuron in network includes nonlinear activation function; the network includes multiple hidden layers that enable network to learn complex tasks by progressively extracting more meaningful features by minimizing errors at output layer; the network exhibits high degree of connectivity determined by synapses of network and a change in network require change in synaptic connections or their weights. The working of MLP has been presented in <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig1</span>, where input layer includes three nodes, two hidden layers with three nodes each and output layer with two nodes. In figure <a href="#S2.F1" title="Figure 1 ‣ 2 Deep Forward Networks ‣ An inclusive review on deep learning techniques and their scope in handwriting recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, forward move is shown with connected lines and backward moves with dotted lines. The input layer includes initialized values that are processed with weight vectors and each hidden layer node is updated in forward manner. The output layer computes final value and error is computed subject to target value against output value. Therefore, error values decide to move backward in order to minimize error values. This results in many iterations until the expected value of error is achieved. This way, it includes the computation of the function signal appearing at the output neuron, a continuous nonlinear function of input signal and synaptic weight associated with that neuron. Also, the computation of an estimate of gradient vector which is needed for backward pass of the network.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2404.08011/assets/MLParchitecture.jpg" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="224" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of multi layer perceptron technique</figcaption>
</figure>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.5" class="ltx_p">The MLP algorithm includes three major steps as forward computation, backward computation and weight updating. The working of these steps has been presented with an instance of one hidden layer to another consecutive hidden layer for neuron <math id="S2.p4.1.m1.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p4.1.m1.1a"><mi id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><ci id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">j</annotation></semantics></math> to neuron <math id="S2.p4.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p4.2.m2.1a"><mi id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.1b"><ci id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.1c">k</annotation></semantics></math>. The details of MLP including derivations have been studied extensively in literature. According to <cite class="ltx_cite ltx_citemacro_cite">Haykin (<a href="#bib.bib39" title="" class="ltx_ref">1998</a>)</cite>, for an MLP, the first step as forward computation results in output as <math id="S2.p4.3.m3.1" class="ltx_Math" alttext="y_{j}^{(l)}" display="inline"><semantics id="S2.p4.3.m3.1a"><msubsup id="S2.p4.3.m3.1.2" xref="S2.p4.3.m3.1.2.cmml"><mi id="S2.p4.3.m3.1.2.2.2" xref="S2.p4.3.m3.1.2.2.2.cmml">y</mi><mi id="S2.p4.3.m3.1.2.2.3" xref="S2.p4.3.m3.1.2.2.3.cmml">j</mi><mrow id="S2.p4.3.m3.1.1.1.3" xref="S2.p4.3.m3.1.2.cmml"><mo stretchy="false" id="S2.p4.3.m3.1.1.1.3.1" xref="S2.p4.3.m3.1.2.cmml">(</mo><mi id="S2.p4.3.m3.1.1.1.1" xref="S2.p4.3.m3.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.p4.3.m3.1.1.1.3.2" xref="S2.p4.3.m3.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.p4.3.m3.1b"><apply id="S2.p4.3.m3.1.2.cmml" xref="S2.p4.3.m3.1.2"><csymbol cd="ambiguous" id="S2.p4.3.m3.1.2.1.cmml" xref="S2.p4.3.m3.1.2">superscript</csymbol><apply id="S2.p4.3.m3.1.2.2.cmml" xref="S2.p4.3.m3.1.2"><csymbol cd="ambiguous" id="S2.p4.3.m3.1.2.2.1.cmml" xref="S2.p4.3.m3.1.2">subscript</csymbol><ci id="S2.p4.3.m3.1.2.2.2.cmml" xref="S2.p4.3.m3.1.2.2.2">𝑦</ci><ci id="S2.p4.3.m3.1.2.2.3.cmml" xref="S2.p4.3.m3.1.2.2.3">𝑗</ci></apply><ci id="S2.p4.3.m3.1.1.1.1.cmml" xref="S2.p4.3.m3.1.1.1.1">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.3.m3.1c">y_{j}^{(l)}</annotation></semantics></math> for neuron <math id="S2.p4.4.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p4.4.m4.1a"><mi id="S2.p4.4.m4.1.1" xref="S2.p4.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p4.4.m4.1b"><ci id="S2.p4.4.m4.1.1.cmml" xref="S2.p4.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.4.m4.1c">j</annotation></semantics></math> in layer <math id="S2.p4.5.m5.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.p4.5.m5.1a"><mi id="S2.p4.5.m5.1.1" xref="S2.p4.5.m5.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.p4.5.m5.1b"><ci id="S2.p4.5.m5.1.1.cmml" xref="S2.p4.5.m5.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.5.m5.1c">l</annotation></semantics></math> using:</p>
</div>
<div id="S2.3" class="ltx_logical-block">
<div id="S2.3.p1" class="ltx_para">
<p id="S2.1.1" class="ltx_p ltx_align_center"><math id="S2.1.1.m1.6" class="ltx_Math" alttext="v_{j}^{(l)}(n)=\sum_{i=0}^{m_{0}}w_{ji}^{(l)}(n)y_{i}^{(l-1)}(n)" display="inline"><semantics id="S2.1.1.m1.6a"><mrow id="S2.1.1.m1.6.7" xref="S2.1.1.m1.6.7.cmml"><mrow id="S2.1.1.m1.6.7.2" xref="S2.1.1.m1.6.7.2.cmml"><msubsup id="S2.1.1.m1.6.7.2.2" xref="S2.1.1.m1.6.7.2.2.cmml"><mi id="S2.1.1.m1.6.7.2.2.2.2" xref="S2.1.1.m1.6.7.2.2.2.2.cmml">v</mi><mi id="S2.1.1.m1.6.7.2.2.2.3" xref="S2.1.1.m1.6.7.2.2.2.3.cmml">j</mi><mrow id="S2.1.1.m1.1.1.1.3" xref="S2.1.1.m1.6.7.2.2.cmml"><mo stretchy="false" id="S2.1.1.m1.1.1.1.3.1" xref="S2.1.1.m1.6.7.2.2.cmml">(</mo><mi id="S2.1.1.m1.1.1.1.1" xref="S2.1.1.m1.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.1.1.m1.1.1.1.3.2" xref="S2.1.1.m1.6.7.2.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.1.1.m1.6.7.2.1" xref="S2.1.1.m1.6.7.2.1.cmml">​</mo><mrow id="S2.1.1.m1.6.7.2.3.2" xref="S2.1.1.m1.6.7.2.cmml"><mo stretchy="false" id="S2.1.1.m1.6.7.2.3.2.1" xref="S2.1.1.m1.6.7.2.cmml">(</mo><mi id="S2.1.1.m1.4.4" xref="S2.1.1.m1.4.4.cmml">n</mi><mo stretchy="false" id="S2.1.1.m1.6.7.2.3.2.2" xref="S2.1.1.m1.6.7.2.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S2.1.1.m1.6.7.1" xref="S2.1.1.m1.6.7.1.cmml">=</mo><mrow id="S2.1.1.m1.6.7.3" xref="S2.1.1.m1.6.7.3.cmml"><msubsup id="S2.1.1.m1.6.7.3.1" xref="S2.1.1.m1.6.7.3.1.cmml"><mo id="S2.1.1.m1.6.7.3.1.2.2" xref="S2.1.1.m1.6.7.3.1.2.2.cmml">∑</mo><mrow id="S2.1.1.m1.6.7.3.1.2.3" xref="S2.1.1.m1.6.7.3.1.2.3.cmml"><mi id="S2.1.1.m1.6.7.3.1.2.3.2" xref="S2.1.1.m1.6.7.3.1.2.3.2.cmml">i</mi><mo id="S2.1.1.m1.6.7.3.1.2.3.1" xref="S2.1.1.m1.6.7.3.1.2.3.1.cmml">=</mo><mn id="S2.1.1.m1.6.7.3.1.2.3.3" xref="S2.1.1.m1.6.7.3.1.2.3.3.cmml">0</mn></mrow><msub id="S2.1.1.m1.6.7.3.1.3" xref="S2.1.1.m1.6.7.3.1.3.cmml"><mi id="S2.1.1.m1.6.7.3.1.3.2" xref="S2.1.1.m1.6.7.3.1.3.2.cmml">m</mi><mn id="S2.1.1.m1.6.7.3.1.3.3" xref="S2.1.1.m1.6.7.3.1.3.3.cmml">0</mn></msub></msubsup><mrow id="S2.1.1.m1.6.7.3.2" xref="S2.1.1.m1.6.7.3.2.cmml"><msubsup id="S2.1.1.m1.6.7.3.2.2" xref="S2.1.1.m1.6.7.3.2.2.cmml"><mi id="S2.1.1.m1.6.7.3.2.2.2.2" xref="S2.1.1.m1.6.7.3.2.2.2.2.cmml">w</mi><mrow id="S2.1.1.m1.6.7.3.2.2.2.3" xref="S2.1.1.m1.6.7.3.2.2.2.3.cmml"><mi id="S2.1.1.m1.6.7.3.2.2.2.3.2" xref="S2.1.1.m1.6.7.3.2.2.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S2.1.1.m1.6.7.3.2.2.2.3.1" xref="S2.1.1.m1.6.7.3.2.2.2.3.1.cmml">​</mo><mi id="S2.1.1.m1.6.7.3.2.2.2.3.3" xref="S2.1.1.m1.6.7.3.2.2.2.3.3.cmml">i</mi></mrow><mrow id="S2.1.1.m1.2.2.1.3" xref="S2.1.1.m1.6.7.3.2.2.cmml"><mo stretchy="false" id="S2.1.1.m1.2.2.1.3.1" xref="S2.1.1.m1.6.7.3.2.2.cmml">(</mo><mi id="S2.1.1.m1.2.2.1.1" xref="S2.1.1.m1.2.2.1.1.cmml">l</mi><mo stretchy="false" id="S2.1.1.m1.2.2.1.3.2" xref="S2.1.1.m1.6.7.3.2.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.1.1.m1.6.7.3.2.1" xref="S2.1.1.m1.6.7.3.2.1.cmml">​</mo><mrow id="S2.1.1.m1.6.7.3.2.3.2" xref="S2.1.1.m1.6.7.3.2.cmml"><mo stretchy="false" id="S2.1.1.m1.6.7.3.2.3.2.1" xref="S2.1.1.m1.6.7.3.2.cmml">(</mo><mi id="S2.1.1.m1.5.5" xref="S2.1.1.m1.5.5.cmml">n</mi><mo stretchy="false" id="S2.1.1.m1.6.7.3.2.3.2.2" xref="S2.1.1.m1.6.7.3.2.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.1.1.m1.6.7.3.2.1a" xref="S2.1.1.m1.6.7.3.2.1.cmml">​</mo><msubsup id="S2.1.1.m1.6.7.3.2.4" xref="S2.1.1.m1.6.7.3.2.4.cmml"><mi id="S2.1.1.m1.6.7.3.2.4.2.2" xref="S2.1.1.m1.6.7.3.2.4.2.2.cmml">y</mi><mi id="S2.1.1.m1.6.7.3.2.4.2.3" xref="S2.1.1.m1.6.7.3.2.4.2.3.cmml">i</mi><mrow id="S2.1.1.m1.3.3.1.1" xref="S2.1.1.m1.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.1.1.m1.3.3.1.1.2" xref="S2.1.1.m1.3.3.1.1.1.cmml">(</mo><mrow id="S2.1.1.m1.3.3.1.1.1" xref="S2.1.1.m1.3.3.1.1.1.cmml"><mi id="S2.1.1.m1.3.3.1.1.1.2" xref="S2.1.1.m1.3.3.1.1.1.2.cmml">l</mi><mo id="S2.1.1.m1.3.3.1.1.1.1" xref="S2.1.1.m1.3.3.1.1.1.1.cmml">−</mo><mn id="S2.1.1.m1.3.3.1.1.1.3" xref="S2.1.1.m1.3.3.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.1.1.m1.3.3.1.1.3" xref="S2.1.1.m1.3.3.1.1.1.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.1.1.m1.6.7.3.2.1b" xref="S2.1.1.m1.6.7.3.2.1.cmml">​</mo><mrow id="S2.1.1.m1.6.7.3.2.5.2" xref="S2.1.1.m1.6.7.3.2.cmml"><mo stretchy="false" id="S2.1.1.m1.6.7.3.2.5.2.1" xref="S2.1.1.m1.6.7.3.2.cmml">(</mo><mi id="S2.1.1.m1.6.6" xref="S2.1.1.m1.6.6.cmml">n</mi><mo stretchy="false" id="S2.1.1.m1.6.7.3.2.5.2.2" xref="S2.1.1.m1.6.7.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.1.1.m1.6b"><apply id="S2.1.1.m1.6.7.cmml" xref="S2.1.1.m1.6.7"><eq id="S2.1.1.m1.6.7.1.cmml" xref="S2.1.1.m1.6.7.1"></eq><apply id="S2.1.1.m1.6.7.2.cmml" xref="S2.1.1.m1.6.7.2"><times id="S2.1.1.m1.6.7.2.1.cmml" xref="S2.1.1.m1.6.7.2.1"></times><apply id="S2.1.1.m1.6.7.2.2.cmml" xref="S2.1.1.m1.6.7.2.2"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.2.2.1.cmml" xref="S2.1.1.m1.6.7.2.2">superscript</csymbol><apply id="S2.1.1.m1.6.7.2.2.2.cmml" xref="S2.1.1.m1.6.7.2.2"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.2.2.2.1.cmml" xref="S2.1.1.m1.6.7.2.2">subscript</csymbol><ci id="S2.1.1.m1.6.7.2.2.2.2.cmml" xref="S2.1.1.m1.6.7.2.2.2.2">𝑣</ci><ci id="S2.1.1.m1.6.7.2.2.2.3.cmml" xref="S2.1.1.m1.6.7.2.2.2.3">𝑗</ci></apply><ci id="S2.1.1.m1.1.1.1.1.cmml" xref="S2.1.1.m1.1.1.1.1">𝑙</ci></apply><ci id="S2.1.1.m1.4.4.cmml" xref="S2.1.1.m1.4.4">𝑛</ci></apply><apply id="S2.1.1.m1.6.7.3.cmml" xref="S2.1.1.m1.6.7.3"><apply id="S2.1.1.m1.6.7.3.1.cmml" xref="S2.1.1.m1.6.7.3.1"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.3.1.1.cmml" xref="S2.1.1.m1.6.7.3.1">superscript</csymbol><apply id="S2.1.1.m1.6.7.3.1.2.cmml" xref="S2.1.1.m1.6.7.3.1"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.3.1.2.1.cmml" xref="S2.1.1.m1.6.7.3.1">subscript</csymbol><sum id="S2.1.1.m1.6.7.3.1.2.2.cmml" xref="S2.1.1.m1.6.7.3.1.2.2"></sum><apply id="S2.1.1.m1.6.7.3.1.2.3.cmml" xref="S2.1.1.m1.6.7.3.1.2.3"><eq id="S2.1.1.m1.6.7.3.1.2.3.1.cmml" xref="S2.1.1.m1.6.7.3.1.2.3.1"></eq><ci id="S2.1.1.m1.6.7.3.1.2.3.2.cmml" xref="S2.1.1.m1.6.7.3.1.2.3.2">𝑖</ci><cn type="integer" id="S2.1.1.m1.6.7.3.1.2.3.3.cmml" xref="S2.1.1.m1.6.7.3.1.2.3.3">0</cn></apply></apply><apply id="S2.1.1.m1.6.7.3.1.3.cmml" xref="S2.1.1.m1.6.7.3.1.3"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.3.1.3.1.cmml" xref="S2.1.1.m1.6.7.3.1.3">subscript</csymbol><ci id="S2.1.1.m1.6.7.3.1.3.2.cmml" xref="S2.1.1.m1.6.7.3.1.3.2">𝑚</ci><cn type="integer" id="S2.1.1.m1.6.7.3.1.3.3.cmml" xref="S2.1.1.m1.6.7.3.1.3.3">0</cn></apply></apply><apply id="S2.1.1.m1.6.7.3.2.cmml" xref="S2.1.1.m1.6.7.3.2"><times id="S2.1.1.m1.6.7.3.2.1.cmml" xref="S2.1.1.m1.6.7.3.2.1"></times><apply id="S2.1.1.m1.6.7.3.2.2.cmml" xref="S2.1.1.m1.6.7.3.2.2"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.3.2.2.1.cmml" xref="S2.1.1.m1.6.7.3.2.2">superscript</csymbol><apply id="S2.1.1.m1.6.7.3.2.2.2.cmml" xref="S2.1.1.m1.6.7.3.2.2"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.3.2.2.2.1.cmml" xref="S2.1.1.m1.6.7.3.2.2">subscript</csymbol><ci id="S2.1.1.m1.6.7.3.2.2.2.2.cmml" xref="S2.1.1.m1.6.7.3.2.2.2.2">𝑤</ci><apply id="S2.1.1.m1.6.7.3.2.2.2.3.cmml" xref="S2.1.1.m1.6.7.3.2.2.2.3"><times id="S2.1.1.m1.6.7.3.2.2.2.3.1.cmml" xref="S2.1.1.m1.6.7.3.2.2.2.3.1"></times><ci id="S2.1.1.m1.6.7.3.2.2.2.3.2.cmml" xref="S2.1.1.m1.6.7.3.2.2.2.3.2">𝑗</ci><ci id="S2.1.1.m1.6.7.3.2.2.2.3.3.cmml" xref="S2.1.1.m1.6.7.3.2.2.2.3.3">𝑖</ci></apply></apply><ci id="S2.1.1.m1.2.2.1.1.cmml" xref="S2.1.1.m1.2.2.1.1">𝑙</ci></apply><ci id="S2.1.1.m1.5.5.cmml" xref="S2.1.1.m1.5.5">𝑛</ci><apply id="S2.1.1.m1.6.7.3.2.4.cmml" xref="S2.1.1.m1.6.7.3.2.4"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.3.2.4.1.cmml" xref="S2.1.1.m1.6.7.3.2.4">superscript</csymbol><apply id="S2.1.1.m1.6.7.3.2.4.2.cmml" xref="S2.1.1.m1.6.7.3.2.4"><csymbol cd="ambiguous" id="S2.1.1.m1.6.7.3.2.4.2.1.cmml" xref="S2.1.1.m1.6.7.3.2.4">subscript</csymbol><ci id="S2.1.1.m1.6.7.3.2.4.2.2.cmml" xref="S2.1.1.m1.6.7.3.2.4.2.2">𝑦</ci><ci id="S2.1.1.m1.6.7.3.2.4.2.3.cmml" xref="S2.1.1.m1.6.7.3.2.4.2.3">𝑖</ci></apply><apply id="S2.1.1.m1.3.3.1.1.1.cmml" xref="S2.1.1.m1.3.3.1.1"><minus id="S2.1.1.m1.3.3.1.1.1.1.cmml" xref="S2.1.1.m1.3.3.1.1.1.1"></minus><ci id="S2.1.1.m1.3.3.1.1.1.2.cmml" xref="S2.1.1.m1.3.3.1.1.1.2">𝑙</ci><cn type="integer" id="S2.1.1.m1.3.3.1.1.1.3.cmml" xref="S2.1.1.m1.3.3.1.1.1.3">1</cn></apply></apply><ci id="S2.1.1.m1.6.6.cmml" xref="S2.1.1.m1.6.6">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.1.1.m1.6c">v_{j}^{(l)}(n)=\sum_{i=0}^{m_{0}}w_{ji}^{(l)}(n)y_{i}^{(l-1)}(n)</annotation></semantics></math>;</p>
<p id="S2.2.2" class="ltx_p ltx_align_center"><math id="S2.2.2.m1.3" class="ltx_Math" alttext="y_{j}^{(l)}=\phi_{j}(v_{j}(n))" display="inline"><semantics id="S2.2.2.m1.3a"><mrow id="S2.2.2.m1.3.3" xref="S2.2.2.m1.3.3.cmml"><msubsup id="S2.2.2.m1.3.3.3" xref="S2.2.2.m1.3.3.3.cmml"><mi id="S2.2.2.m1.3.3.3.2.2" xref="S2.2.2.m1.3.3.3.2.2.cmml">y</mi><mi id="S2.2.2.m1.3.3.3.2.3" xref="S2.2.2.m1.3.3.3.2.3.cmml">j</mi><mrow id="S2.2.2.m1.1.1.1.3" xref="S2.2.2.m1.3.3.3.cmml"><mo stretchy="false" id="S2.2.2.m1.1.1.1.3.1" xref="S2.2.2.m1.3.3.3.cmml">(</mo><mi id="S2.2.2.m1.1.1.1.1" xref="S2.2.2.m1.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.2.2.m1.1.1.1.3.2" xref="S2.2.2.m1.3.3.3.cmml">)</mo></mrow></msubsup><mo id="S2.2.2.m1.3.3.2" xref="S2.2.2.m1.3.3.2.cmml">=</mo><mrow id="S2.2.2.m1.3.3.1" xref="S2.2.2.m1.3.3.1.cmml"><msub id="S2.2.2.m1.3.3.1.3" xref="S2.2.2.m1.3.3.1.3.cmml"><mi id="S2.2.2.m1.3.3.1.3.2" xref="S2.2.2.m1.3.3.1.3.2.cmml">ϕ</mi><mi id="S2.2.2.m1.3.3.1.3.3" xref="S2.2.2.m1.3.3.1.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.2.2.m1.3.3.1.2" xref="S2.2.2.m1.3.3.1.2.cmml">​</mo><mrow id="S2.2.2.m1.3.3.1.1.1" xref="S2.2.2.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.2.2.m1.3.3.1.1.1.2" xref="S2.2.2.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S2.2.2.m1.3.3.1.1.1.1" xref="S2.2.2.m1.3.3.1.1.1.1.cmml"><msub id="S2.2.2.m1.3.3.1.1.1.1.2" xref="S2.2.2.m1.3.3.1.1.1.1.2.cmml"><mi id="S2.2.2.m1.3.3.1.1.1.1.2.2" xref="S2.2.2.m1.3.3.1.1.1.1.2.2.cmml">v</mi><mi id="S2.2.2.m1.3.3.1.1.1.1.2.3" xref="S2.2.2.m1.3.3.1.1.1.1.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.2.2.m1.3.3.1.1.1.1.1" xref="S2.2.2.m1.3.3.1.1.1.1.1.cmml">​</mo><mrow id="S2.2.2.m1.3.3.1.1.1.1.3.2" xref="S2.2.2.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.2.2.m1.3.3.1.1.1.1.3.2.1" xref="S2.2.2.m1.3.3.1.1.1.1.cmml">(</mo><mi id="S2.2.2.m1.2.2" xref="S2.2.2.m1.2.2.cmml">n</mi><mo stretchy="false" id="S2.2.2.m1.3.3.1.1.1.1.3.2.2" xref="S2.2.2.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.2.2.m1.3.3.1.1.1.3" xref="S2.2.2.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.2.2.m1.3b"><apply id="S2.2.2.m1.3.3.cmml" xref="S2.2.2.m1.3.3"><eq id="S2.2.2.m1.3.3.2.cmml" xref="S2.2.2.m1.3.3.2"></eq><apply id="S2.2.2.m1.3.3.3.cmml" xref="S2.2.2.m1.3.3.3"><csymbol cd="ambiguous" id="S2.2.2.m1.3.3.3.1.cmml" xref="S2.2.2.m1.3.3.3">superscript</csymbol><apply id="S2.2.2.m1.3.3.3.2.cmml" xref="S2.2.2.m1.3.3.3"><csymbol cd="ambiguous" id="S2.2.2.m1.3.3.3.2.1.cmml" xref="S2.2.2.m1.3.3.3">subscript</csymbol><ci id="S2.2.2.m1.3.3.3.2.2.cmml" xref="S2.2.2.m1.3.3.3.2.2">𝑦</ci><ci id="S2.2.2.m1.3.3.3.2.3.cmml" xref="S2.2.2.m1.3.3.3.2.3">𝑗</ci></apply><ci id="S2.2.2.m1.1.1.1.1.cmml" xref="S2.2.2.m1.1.1.1.1">𝑙</ci></apply><apply id="S2.2.2.m1.3.3.1.cmml" xref="S2.2.2.m1.3.3.1"><times id="S2.2.2.m1.3.3.1.2.cmml" xref="S2.2.2.m1.3.3.1.2"></times><apply id="S2.2.2.m1.3.3.1.3.cmml" xref="S2.2.2.m1.3.3.1.3"><csymbol cd="ambiguous" id="S2.2.2.m1.3.3.1.3.1.cmml" xref="S2.2.2.m1.3.3.1.3">subscript</csymbol><ci id="S2.2.2.m1.3.3.1.3.2.cmml" xref="S2.2.2.m1.3.3.1.3.2">italic-ϕ</ci><ci id="S2.2.2.m1.3.3.1.3.3.cmml" xref="S2.2.2.m1.3.3.1.3.3">𝑗</ci></apply><apply id="S2.2.2.m1.3.3.1.1.1.1.cmml" xref="S2.2.2.m1.3.3.1.1.1"><times id="S2.2.2.m1.3.3.1.1.1.1.1.cmml" xref="S2.2.2.m1.3.3.1.1.1.1.1"></times><apply id="S2.2.2.m1.3.3.1.1.1.1.2.cmml" xref="S2.2.2.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.2.2.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.2.2.m1.3.3.1.1.1.1.2">subscript</csymbol><ci id="S2.2.2.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.2.2.m1.3.3.1.1.1.1.2.2">𝑣</ci><ci id="S2.2.2.m1.3.3.1.1.1.1.2.3.cmml" xref="S2.2.2.m1.3.3.1.1.1.1.2.3">𝑗</ci></apply><ci id="S2.2.2.m1.2.2.cmml" xref="S2.2.2.m1.2.2">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.2.2.m1.3c">y_{j}^{(l)}=\phi_{j}(v_{j}(n))</annotation></semantics></math></p>
</div>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.2" class="ltx_p">The forward computation is performed in forward direction until the output layer neuron value is not computed. In backward computation, gradient value is computed for neuron <math id="S2.p5.1.m1.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p5.1.m1.1a"><mi id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><ci id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">j</annotation></semantics></math> in hidden layer <math id="S2.p5.2.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.p5.2.m2.1a"><mi id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><ci id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">l</annotation></semantics></math> as:</p>
<p id="S2.p5.5.3" class="ltx_p ltx_align_center"><math id="S2.p5.3.1.m1.6" class="ltx_Math" alttext="\delta_{j}^{(l)}(n)=e_{j}^{(L)}(n)\phi_{j}^{{}^{\prime}}(v_{j}^{L}(n))" display="inline"><semantics id="S2.p5.3.1.m1.6a"><mrow id="S2.p5.3.1.m1.6.6" xref="S2.p5.3.1.m1.6.6.cmml"><mrow id="S2.p5.3.1.m1.6.6.3" xref="S2.p5.3.1.m1.6.6.3.cmml"><msubsup id="S2.p5.3.1.m1.6.6.3.2" xref="S2.p5.3.1.m1.6.6.3.2.cmml"><mi id="S2.p5.3.1.m1.6.6.3.2.2.2" xref="S2.p5.3.1.m1.6.6.3.2.2.2.cmml">δ</mi><mi id="S2.p5.3.1.m1.6.6.3.2.2.3" xref="S2.p5.3.1.m1.6.6.3.2.2.3.cmml">j</mi><mrow id="S2.p5.3.1.m1.1.1.1.3" xref="S2.p5.3.1.m1.6.6.3.2.cmml"><mo stretchy="false" id="S2.p5.3.1.m1.1.1.1.3.1" xref="S2.p5.3.1.m1.6.6.3.2.cmml">(</mo><mi id="S2.p5.3.1.m1.1.1.1.1" xref="S2.p5.3.1.m1.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.3.1.m1.1.1.1.3.2" xref="S2.p5.3.1.m1.6.6.3.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.3.1.m1.6.6.3.1" xref="S2.p5.3.1.m1.6.6.3.1.cmml">​</mo><mrow id="S2.p5.3.1.m1.6.6.3.3.2" xref="S2.p5.3.1.m1.6.6.3.cmml"><mo stretchy="false" id="S2.p5.3.1.m1.6.6.3.3.2.1" xref="S2.p5.3.1.m1.6.6.3.cmml">(</mo><mi id="S2.p5.3.1.m1.3.3" xref="S2.p5.3.1.m1.3.3.cmml">n</mi><mo stretchy="false" id="S2.p5.3.1.m1.6.6.3.3.2.2" xref="S2.p5.3.1.m1.6.6.3.cmml">)</mo></mrow></mrow><mo id="S2.p5.3.1.m1.6.6.2" xref="S2.p5.3.1.m1.6.6.2.cmml">=</mo><mrow id="S2.p5.3.1.m1.6.6.1" xref="S2.p5.3.1.m1.6.6.1.cmml"><msubsup id="S2.p5.3.1.m1.6.6.1.3" xref="S2.p5.3.1.m1.6.6.1.3.cmml"><mi id="S2.p5.3.1.m1.6.6.1.3.2.2" xref="S2.p5.3.1.m1.6.6.1.3.2.2.cmml">e</mi><mi id="S2.p5.3.1.m1.6.6.1.3.2.3" xref="S2.p5.3.1.m1.6.6.1.3.2.3.cmml">j</mi><mrow id="S2.p5.3.1.m1.2.2.1.3" xref="S2.p5.3.1.m1.6.6.1.3.cmml"><mo stretchy="false" id="S2.p5.3.1.m1.2.2.1.3.1" xref="S2.p5.3.1.m1.6.6.1.3.cmml">(</mo><mi id="S2.p5.3.1.m1.2.2.1.1" xref="S2.p5.3.1.m1.2.2.1.1.cmml">L</mi><mo stretchy="false" id="S2.p5.3.1.m1.2.2.1.3.2" xref="S2.p5.3.1.m1.6.6.1.3.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.3.1.m1.6.6.1.2" xref="S2.p5.3.1.m1.6.6.1.2.cmml">​</mo><mrow id="S2.p5.3.1.m1.6.6.1.4.2" xref="S2.p5.3.1.m1.6.6.1.cmml"><mo stretchy="false" id="S2.p5.3.1.m1.6.6.1.4.2.1" xref="S2.p5.3.1.m1.6.6.1.cmml">(</mo><mi id="S2.p5.3.1.m1.4.4" xref="S2.p5.3.1.m1.4.4.cmml">n</mi><mo stretchy="false" id="S2.p5.3.1.m1.6.6.1.4.2.2" xref="S2.p5.3.1.m1.6.6.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.p5.3.1.m1.6.6.1.2a" xref="S2.p5.3.1.m1.6.6.1.2.cmml">​</mo><msubsup id="S2.p5.3.1.m1.6.6.1.5" xref="S2.p5.3.1.m1.6.6.1.5.cmml"><mi id="S2.p5.3.1.m1.6.6.1.5.2.2" xref="S2.p5.3.1.m1.6.6.1.5.2.2.cmml">ϕ</mi><mi id="S2.p5.3.1.m1.6.6.1.5.2.3" xref="S2.p5.3.1.m1.6.6.1.5.2.3.cmml">j</mi><msup id="S2.p5.3.1.m1.6.6.1.5.3" xref="S2.p5.3.1.m1.6.6.1.5.3.cmml"><mi id="S2.p5.3.1.m1.6.6.1.5.3a" xref="S2.p5.3.1.m1.6.6.1.5.3.cmml"></mi><mo id="S2.p5.3.1.m1.6.6.1.5.3.1" xref="S2.p5.3.1.m1.6.6.1.5.3.1.cmml">′</mo></msup></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.3.1.m1.6.6.1.2b" xref="S2.p5.3.1.m1.6.6.1.2.cmml">​</mo><mrow id="S2.p5.3.1.m1.6.6.1.1.1" xref="S2.p5.3.1.m1.6.6.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.3.1.m1.6.6.1.1.1.2" xref="S2.p5.3.1.m1.6.6.1.1.1.1.cmml">(</mo><mrow id="S2.p5.3.1.m1.6.6.1.1.1.1" xref="S2.p5.3.1.m1.6.6.1.1.1.1.cmml"><msubsup id="S2.p5.3.1.m1.6.6.1.1.1.1.2" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2.cmml"><mi id="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.2" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.2.cmml">v</mi><mi id="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.3" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.3.cmml">j</mi><mi id="S2.p5.3.1.m1.6.6.1.1.1.1.2.3" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2.3.cmml">L</mi></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.3.1.m1.6.6.1.1.1.1.1" xref="S2.p5.3.1.m1.6.6.1.1.1.1.1.cmml">​</mo><mrow id="S2.p5.3.1.m1.6.6.1.1.1.1.3.2" xref="S2.p5.3.1.m1.6.6.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.3.1.m1.6.6.1.1.1.1.3.2.1" xref="S2.p5.3.1.m1.6.6.1.1.1.1.cmml">(</mo><mi id="S2.p5.3.1.m1.5.5" xref="S2.p5.3.1.m1.5.5.cmml">n</mi><mo stretchy="false" id="S2.p5.3.1.m1.6.6.1.1.1.1.3.2.2" xref="S2.p5.3.1.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.p5.3.1.m1.6.6.1.1.1.3" xref="S2.p5.3.1.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.3.1.m1.6b"><apply id="S2.p5.3.1.m1.6.6.cmml" xref="S2.p5.3.1.m1.6.6"><eq id="S2.p5.3.1.m1.6.6.2.cmml" xref="S2.p5.3.1.m1.6.6.2"></eq><apply id="S2.p5.3.1.m1.6.6.3.cmml" xref="S2.p5.3.1.m1.6.6.3"><times id="S2.p5.3.1.m1.6.6.3.1.cmml" xref="S2.p5.3.1.m1.6.6.3.1"></times><apply id="S2.p5.3.1.m1.6.6.3.2.cmml" xref="S2.p5.3.1.m1.6.6.3.2"><csymbol cd="ambiguous" id="S2.p5.3.1.m1.6.6.3.2.1.cmml" xref="S2.p5.3.1.m1.6.6.3.2">superscript</csymbol><apply id="S2.p5.3.1.m1.6.6.3.2.2.cmml" xref="S2.p5.3.1.m1.6.6.3.2"><csymbol cd="ambiguous" id="S2.p5.3.1.m1.6.6.3.2.2.1.cmml" xref="S2.p5.3.1.m1.6.6.3.2">subscript</csymbol><ci id="S2.p5.3.1.m1.6.6.3.2.2.2.cmml" xref="S2.p5.3.1.m1.6.6.3.2.2.2">𝛿</ci><ci id="S2.p5.3.1.m1.6.6.3.2.2.3.cmml" xref="S2.p5.3.1.m1.6.6.3.2.2.3">𝑗</ci></apply><ci id="S2.p5.3.1.m1.1.1.1.1.cmml" xref="S2.p5.3.1.m1.1.1.1.1">𝑙</ci></apply><ci id="S2.p5.3.1.m1.3.3.cmml" xref="S2.p5.3.1.m1.3.3">𝑛</ci></apply><apply id="S2.p5.3.1.m1.6.6.1.cmml" xref="S2.p5.3.1.m1.6.6.1"><times id="S2.p5.3.1.m1.6.6.1.2.cmml" xref="S2.p5.3.1.m1.6.6.1.2"></times><apply id="S2.p5.3.1.m1.6.6.1.3.cmml" xref="S2.p5.3.1.m1.6.6.1.3"><csymbol cd="ambiguous" id="S2.p5.3.1.m1.6.6.1.3.1.cmml" xref="S2.p5.3.1.m1.6.6.1.3">superscript</csymbol><apply id="S2.p5.3.1.m1.6.6.1.3.2.cmml" xref="S2.p5.3.1.m1.6.6.1.3"><csymbol cd="ambiguous" id="S2.p5.3.1.m1.6.6.1.3.2.1.cmml" xref="S2.p5.3.1.m1.6.6.1.3">subscript</csymbol><ci id="S2.p5.3.1.m1.6.6.1.3.2.2.cmml" xref="S2.p5.3.1.m1.6.6.1.3.2.2">𝑒</ci><ci id="S2.p5.3.1.m1.6.6.1.3.2.3.cmml" xref="S2.p5.3.1.m1.6.6.1.3.2.3">𝑗</ci></apply><ci id="S2.p5.3.1.m1.2.2.1.1.cmml" xref="S2.p5.3.1.m1.2.2.1.1">𝐿</ci></apply><ci id="S2.p5.3.1.m1.4.4.cmml" xref="S2.p5.3.1.m1.4.4">𝑛</ci><apply id="S2.p5.3.1.m1.6.6.1.5.cmml" xref="S2.p5.3.1.m1.6.6.1.5"><csymbol cd="ambiguous" id="S2.p5.3.1.m1.6.6.1.5.1.cmml" xref="S2.p5.3.1.m1.6.6.1.5">superscript</csymbol><apply id="S2.p5.3.1.m1.6.6.1.5.2.cmml" xref="S2.p5.3.1.m1.6.6.1.5"><csymbol cd="ambiguous" id="S2.p5.3.1.m1.6.6.1.5.2.1.cmml" xref="S2.p5.3.1.m1.6.6.1.5">subscript</csymbol><ci id="S2.p5.3.1.m1.6.6.1.5.2.2.cmml" xref="S2.p5.3.1.m1.6.6.1.5.2.2">italic-ϕ</ci><ci id="S2.p5.3.1.m1.6.6.1.5.2.3.cmml" xref="S2.p5.3.1.m1.6.6.1.5.2.3">𝑗</ci></apply><apply id="S2.p5.3.1.m1.6.6.1.5.3.cmml" xref="S2.p5.3.1.m1.6.6.1.5.3"><ci id="S2.p5.3.1.m1.6.6.1.5.3.1.cmml" xref="S2.p5.3.1.m1.6.6.1.5.3.1">′</ci></apply></apply><apply id="S2.p5.3.1.m1.6.6.1.1.1.1.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1"><times id="S2.p5.3.1.m1.6.6.1.1.1.1.1.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1.1.1"></times><apply id="S2.p5.3.1.m1.6.6.1.1.1.1.2.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p5.3.1.m1.6.6.1.1.1.1.2.1.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2">superscript</csymbol><apply id="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.1.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2">subscript</csymbol><ci id="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.2.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.2">𝑣</ci><ci id="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.3.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2.2.3">𝑗</ci></apply><ci id="S2.p5.3.1.m1.6.6.1.1.1.1.2.3.cmml" xref="S2.p5.3.1.m1.6.6.1.1.1.1.2.3">𝐿</ci></apply><ci id="S2.p5.3.1.m1.5.5.cmml" xref="S2.p5.3.1.m1.5.5">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.1.m1.6c">\delta_{j}^{(l)}(n)=e_{j}^{(L)}(n)\phi_{j}^{{}^{\prime}}(v_{j}^{L}(n))</annotation></semantics></math>, for neuron <math id="S2.p5.4.2.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p5.4.2.m2.1a"><mi id="S2.p5.4.2.m2.1.1" xref="S2.p5.4.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p5.4.2.m2.1b"><ci id="S2.p5.4.2.m2.1.1.cmml" xref="S2.p5.4.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.4.2.m2.1c">j</annotation></semantics></math> in output layer <math id="S2.p5.5.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.p5.5.3.m3.1a"><mi id="S2.p5.5.3.m3.1.1" xref="S2.p5.5.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p5.5.3.m3.1b"><ci id="S2.p5.5.3.m3.1.1.cmml" xref="S2.p5.5.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.5.3.m3.1c">L</annotation></semantics></math>;</p>
<p id="S2.p5.6.4" class="ltx_p ltx_align_center"><math id="S2.p5.6.4.m1.8" class="ltx_Math" alttext="\delta_{j}^{(l)}(n)=\phi_{j}^{{}^{\prime}}(v_{j}^{l}(n))\sum_{k}\delta_{k}^{(l+1)}(n)w_{kj}^{(l+1)}(n)" display="inline"><semantics id="S2.p5.6.4.m1.8a"><mrow id="S2.p5.6.4.m1.8.8" xref="S2.p5.6.4.m1.8.8.cmml"><mrow id="S2.p5.6.4.m1.8.8.3" xref="S2.p5.6.4.m1.8.8.3.cmml"><msubsup id="S2.p5.6.4.m1.8.8.3.2" xref="S2.p5.6.4.m1.8.8.3.2.cmml"><mi id="S2.p5.6.4.m1.8.8.3.2.2.2" xref="S2.p5.6.4.m1.8.8.3.2.2.2.cmml">δ</mi><mi id="S2.p5.6.4.m1.8.8.3.2.2.3" xref="S2.p5.6.4.m1.8.8.3.2.2.3.cmml">j</mi><mrow id="S2.p5.6.4.m1.1.1.1.3" xref="S2.p5.6.4.m1.8.8.3.2.cmml"><mo stretchy="false" id="S2.p5.6.4.m1.1.1.1.3.1" xref="S2.p5.6.4.m1.8.8.3.2.cmml">(</mo><mi id="S2.p5.6.4.m1.1.1.1.1" xref="S2.p5.6.4.m1.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.6.4.m1.1.1.1.3.2" xref="S2.p5.6.4.m1.8.8.3.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.6.4.m1.8.8.3.1" xref="S2.p5.6.4.m1.8.8.3.1.cmml">​</mo><mrow id="S2.p5.6.4.m1.8.8.3.3.2" xref="S2.p5.6.4.m1.8.8.3.cmml"><mo stretchy="false" id="S2.p5.6.4.m1.8.8.3.3.2.1" xref="S2.p5.6.4.m1.8.8.3.cmml">(</mo><mi id="S2.p5.6.4.m1.4.4" xref="S2.p5.6.4.m1.4.4.cmml">n</mi><mo stretchy="false" id="S2.p5.6.4.m1.8.8.3.3.2.2" xref="S2.p5.6.4.m1.8.8.3.cmml">)</mo></mrow></mrow><mo id="S2.p5.6.4.m1.8.8.2" xref="S2.p5.6.4.m1.8.8.2.cmml">=</mo><mrow id="S2.p5.6.4.m1.8.8.1" xref="S2.p5.6.4.m1.8.8.1.cmml"><msubsup id="S2.p5.6.4.m1.8.8.1.3" xref="S2.p5.6.4.m1.8.8.1.3.cmml"><mi id="S2.p5.6.4.m1.8.8.1.3.2.2" xref="S2.p5.6.4.m1.8.8.1.3.2.2.cmml">ϕ</mi><mi id="S2.p5.6.4.m1.8.8.1.3.2.3" xref="S2.p5.6.4.m1.8.8.1.3.2.3.cmml">j</mi><msup id="S2.p5.6.4.m1.8.8.1.3.3" xref="S2.p5.6.4.m1.8.8.1.3.3.cmml"><mi id="S2.p5.6.4.m1.8.8.1.3.3a" xref="S2.p5.6.4.m1.8.8.1.3.3.cmml"></mi><mo id="S2.p5.6.4.m1.8.8.1.3.3.1" xref="S2.p5.6.4.m1.8.8.1.3.3.1.cmml">′</mo></msup></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.6.4.m1.8.8.1.2" xref="S2.p5.6.4.m1.8.8.1.2.cmml">​</mo><mrow id="S2.p5.6.4.m1.8.8.1.1.1" xref="S2.p5.6.4.m1.8.8.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.6.4.m1.8.8.1.1.1.2" xref="S2.p5.6.4.m1.8.8.1.1.1.1.cmml">(</mo><mrow id="S2.p5.6.4.m1.8.8.1.1.1.1" xref="S2.p5.6.4.m1.8.8.1.1.1.1.cmml"><msubsup id="S2.p5.6.4.m1.8.8.1.1.1.1.2" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2.cmml"><mi id="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.2" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.2.cmml">v</mi><mi id="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.3" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.3.cmml">j</mi><mi id="S2.p5.6.4.m1.8.8.1.1.1.1.2.3" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2.3.cmml">l</mi></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.6.4.m1.8.8.1.1.1.1.1" xref="S2.p5.6.4.m1.8.8.1.1.1.1.1.cmml">​</mo><mrow id="S2.p5.6.4.m1.8.8.1.1.1.1.3.2" xref="S2.p5.6.4.m1.8.8.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.6.4.m1.8.8.1.1.1.1.3.2.1" xref="S2.p5.6.4.m1.8.8.1.1.1.1.cmml">(</mo><mi id="S2.p5.6.4.m1.5.5" xref="S2.p5.6.4.m1.5.5.cmml">n</mi><mo stretchy="false" id="S2.p5.6.4.m1.8.8.1.1.1.1.3.2.2" xref="S2.p5.6.4.m1.8.8.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.p5.6.4.m1.8.8.1.1.1.3" xref="S2.p5.6.4.m1.8.8.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.p5.6.4.m1.8.8.1.2a" xref="S2.p5.6.4.m1.8.8.1.2.cmml">​</mo><mrow id="S2.p5.6.4.m1.8.8.1.4" xref="S2.p5.6.4.m1.8.8.1.4.cmml"><msub id="S2.p5.6.4.m1.8.8.1.4.1" xref="S2.p5.6.4.m1.8.8.1.4.1.cmml"><mo id="S2.p5.6.4.m1.8.8.1.4.1.2" xref="S2.p5.6.4.m1.8.8.1.4.1.2.cmml">∑</mo><mi id="S2.p5.6.4.m1.8.8.1.4.1.3" xref="S2.p5.6.4.m1.8.8.1.4.1.3.cmml">k</mi></msub><mrow id="S2.p5.6.4.m1.8.8.1.4.2" xref="S2.p5.6.4.m1.8.8.1.4.2.cmml"><msubsup id="S2.p5.6.4.m1.8.8.1.4.2.2" xref="S2.p5.6.4.m1.8.8.1.4.2.2.cmml"><mi id="S2.p5.6.4.m1.8.8.1.4.2.2.2.2" xref="S2.p5.6.4.m1.8.8.1.4.2.2.2.2.cmml">δ</mi><mi id="S2.p5.6.4.m1.8.8.1.4.2.2.2.3" xref="S2.p5.6.4.m1.8.8.1.4.2.2.2.3.cmml">k</mi><mrow id="S2.p5.6.4.m1.2.2.1.1" xref="S2.p5.6.4.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.p5.6.4.m1.2.2.1.1.2" xref="S2.p5.6.4.m1.2.2.1.1.1.cmml">(</mo><mrow id="S2.p5.6.4.m1.2.2.1.1.1" xref="S2.p5.6.4.m1.2.2.1.1.1.cmml"><mi id="S2.p5.6.4.m1.2.2.1.1.1.2" xref="S2.p5.6.4.m1.2.2.1.1.1.2.cmml">l</mi><mo id="S2.p5.6.4.m1.2.2.1.1.1.1" xref="S2.p5.6.4.m1.2.2.1.1.1.1.cmml">+</mo><mn id="S2.p5.6.4.m1.2.2.1.1.1.3" xref="S2.p5.6.4.m1.2.2.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.p5.6.4.m1.2.2.1.1.3" xref="S2.p5.6.4.m1.2.2.1.1.1.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.6.4.m1.8.8.1.4.2.1" xref="S2.p5.6.4.m1.8.8.1.4.2.1.cmml">​</mo><mrow id="S2.p5.6.4.m1.8.8.1.4.2.3.2" xref="S2.p5.6.4.m1.8.8.1.4.2.cmml"><mo stretchy="false" id="S2.p5.6.4.m1.8.8.1.4.2.3.2.1" xref="S2.p5.6.4.m1.8.8.1.4.2.cmml">(</mo><mi id="S2.p5.6.4.m1.6.6" xref="S2.p5.6.4.m1.6.6.cmml">n</mi><mo stretchy="false" id="S2.p5.6.4.m1.8.8.1.4.2.3.2.2" xref="S2.p5.6.4.m1.8.8.1.4.2.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.p5.6.4.m1.8.8.1.4.2.1a" xref="S2.p5.6.4.m1.8.8.1.4.2.1.cmml">​</mo><msubsup id="S2.p5.6.4.m1.8.8.1.4.2.4" xref="S2.p5.6.4.m1.8.8.1.4.2.4.cmml"><mi id="S2.p5.6.4.m1.8.8.1.4.2.4.2.2" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.2.cmml">w</mi><mrow id="S2.p5.6.4.m1.8.8.1.4.2.4.2.3" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.cmml"><mi id="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.2" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.1" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.1.cmml">​</mo><mi id="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.3" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.3.cmml">j</mi></mrow><mrow id="S2.p5.6.4.m1.3.3.1.1" xref="S2.p5.6.4.m1.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.p5.6.4.m1.3.3.1.1.2" xref="S2.p5.6.4.m1.3.3.1.1.1.cmml">(</mo><mrow id="S2.p5.6.4.m1.3.3.1.1.1" xref="S2.p5.6.4.m1.3.3.1.1.1.cmml"><mi id="S2.p5.6.4.m1.3.3.1.1.1.2" xref="S2.p5.6.4.m1.3.3.1.1.1.2.cmml">l</mi><mo id="S2.p5.6.4.m1.3.3.1.1.1.1" xref="S2.p5.6.4.m1.3.3.1.1.1.1.cmml">+</mo><mn id="S2.p5.6.4.m1.3.3.1.1.1.3" xref="S2.p5.6.4.m1.3.3.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.p5.6.4.m1.3.3.1.1.3" xref="S2.p5.6.4.m1.3.3.1.1.1.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.6.4.m1.8.8.1.4.2.1b" xref="S2.p5.6.4.m1.8.8.1.4.2.1.cmml">​</mo><mrow id="S2.p5.6.4.m1.8.8.1.4.2.5.2" xref="S2.p5.6.4.m1.8.8.1.4.2.cmml"><mo stretchy="false" id="S2.p5.6.4.m1.8.8.1.4.2.5.2.1" xref="S2.p5.6.4.m1.8.8.1.4.2.cmml">(</mo><mi id="S2.p5.6.4.m1.7.7" xref="S2.p5.6.4.m1.7.7.cmml">n</mi><mo stretchy="false" id="S2.p5.6.4.m1.8.8.1.4.2.5.2.2" xref="S2.p5.6.4.m1.8.8.1.4.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.6.4.m1.8b"><apply id="S2.p5.6.4.m1.8.8.cmml" xref="S2.p5.6.4.m1.8.8"><eq id="S2.p5.6.4.m1.8.8.2.cmml" xref="S2.p5.6.4.m1.8.8.2"></eq><apply id="S2.p5.6.4.m1.8.8.3.cmml" xref="S2.p5.6.4.m1.8.8.3"><times id="S2.p5.6.4.m1.8.8.3.1.cmml" xref="S2.p5.6.4.m1.8.8.3.1"></times><apply id="S2.p5.6.4.m1.8.8.3.2.cmml" xref="S2.p5.6.4.m1.8.8.3.2"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.3.2.1.cmml" xref="S2.p5.6.4.m1.8.8.3.2">superscript</csymbol><apply id="S2.p5.6.4.m1.8.8.3.2.2.cmml" xref="S2.p5.6.4.m1.8.8.3.2"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.3.2.2.1.cmml" xref="S2.p5.6.4.m1.8.8.3.2">subscript</csymbol><ci id="S2.p5.6.4.m1.8.8.3.2.2.2.cmml" xref="S2.p5.6.4.m1.8.8.3.2.2.2">𝛿</ci><ci id="S2.p5.6.4.m1.8.8.3.2.2.3.cmml" xref="S2.p5.6.4.m1.8.8.3.2.2.3">𝑗</ci></apply><ci id="S2.p5.6.4.m1.1.1.1.1.cmml" xref="S2.p5.6.4.m1.1.1.1.1">𝑙</ci></apply><ci id="S2.p5.6.4.m1.4.4.cmml" xref="S2.p5.6.4.m1.4.4">𝑛</ci></apply><apply id="S2.p5.6.4.m1.8.8.1.cmml" xref="S2.p5.6.4.m1.8.8.1"><times id="S2.p5.6.4.m1.8.8.1.2.cmml" xref="S2.p5.6.4.m1.8.8.1.2"></times><apply id="S2.p5.6.4.m1.8.8.1.3.cmml" xref="S2.p5.6.4.m1.8.8.1.3"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.3.1.cmml" xref="S2.p5.6.4.m1.8.8.1.3">superscript</csymbol><apply id="S2.p5.6.4.m1.8.8.1.3.2.cmml" xref="S2.p5.6.4.m1.8.8.1.3"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.3.2.1.cmml" xref="S2.p5.6.4.m1.8.8.1.3">subscript</csymbol><ci id="S2.p5.6.4.m1.8.8.1.3.2.2.cmml" xref="S2.p5.6.4.m1.8.8.1.3.2.2">italic-ϕ</ci><ci id="S2.p5.6.4.m1.8.8.1.3.2.3.cmml" xref="S2.p5.6.4.m1.8.8.1.3.2.3">𝑗</ci></apply><apply id="S2.p5.6.4.m1.8.8.1.3.3.cmml" xref="S2.p5.6.4.m1.8.8.1.3.3"><ci id="S2.p5.6.4.m1.8.8.1.3.3.1.cmml" xref="S2.p5.6.4.m1.8.8.1.3.3.1">′</ci></apply></apply><apply id="S2.p5.6.4.m1.8.8.1.1.1.1.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1"><times id="S2.p5.6.4.m1.8.8.1.1.1.1.1.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1.1.1"></times><apply id="S2.p5.6.4.m1.8.8.1.1.1.1.2.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.1.1.1.2.1.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2">superscript</csymbol><apply id="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.1.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2">subscript</csymbol><ci id="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.2.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.2">𝑣</ci><ci id="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.3.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2.2.3">𝑗</ci></apply><ci id="S2.p5.6.4.m1.8.8.1.1.1.1.2.3.cmml" xref="S2.p5.6.4.m1.8.8.1.1.1.1.2.3">𝑙</ci></apply><ci id="S2.p5.6.4.m1.5.5.cmml" xref="S2.p5.6.4.m1.5.5">𝑛</ci></apply><apply id="S2.p5.6.4.m1.8.8.1.4.cmml" xref="S2.p5.6.4.m1.8.8.1.4"><apply id="S2.p5.6.4.m1.8.8.1.4.1.cmml" xref="S2.p5.6.4.m1.8.8.1.4.1"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.4.1.1.cmml" xref="S2.p5.6.4.m1.8.8.1.4.1">subscript</csymbol><sum id="S2.p5.6.4.m1.8.8.1.4.1.2.cmml" xref="S2.p5.6.4.m1.8.8.1.4.1.2"></sum><ci id="S2.p5.6.4.m1.8.8.1.4.1.3.cmml" xref="S2.p5.6.4.m1.8.8.1.4.1.3">𝑘</ci></apply><apply id="S2.p5.6.4.m1.8.8.1.4.2.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2"><times id="S2.p5.6.4.m1.8.8.1.4.2.1.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.1"></times><apply id="S2.p5.6.4.m1.8.8.1.4.2.2.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.2"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.4.2.2.1.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.2">superscript</csymbol><apply id="S2.p5.6.4.m1.8.8.1.4.2.2.2.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.2"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.4.2.2.2.1.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.2">subscript</csymbol><ci id="S2.p5.6.4.m1.8.8.1.4.2.2.2.2.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.2.2.2">𝛿</ci><ci id="S2.p5.6.4.m1.8.8.1.4.2.2.2.3.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.2.2.3">𝑘</ci></apply><apply id="S2.p5.6.4.m1.2.2.1.1.1.cmml" xref="S2.p5.6.4.m1.2.2.1.1"><plus id="S2.p5.6.4.m1.2.2.1.1.1.1.cmml" xref="S2.p5.6.4.m1.2.2.1.1.1.1"></plus><ci id="S2.p5.6.4.m1.2.2.1.1.1.2.cmml" xref="S2.p5.6.4.m1.2.2.1.1.1.2">𝑙</ci><cn type="integer" id="S2.p5.6.4.m1.2.2.1.1.1.3.cmml" xref="S2.p5.6.4.m1.2.2.1.1.1.3">1</cn></apply></apply><ci id="S2.p5.6.4.m1.6.6.cmml" xref="S2.p5.6.4.m1.6.6">𝑛</ci><apply id="S2.p5.6.4.m1.8.8.1.4.2.4.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.4.2.4.1.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4">superscript</csymbol><apply id="S2.p5.6.4.m1.8.8.1.4.2.4.2.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4"><csymbol cd="ambiguous" id="S2.p5.6.4.m1.8.8.1.4.2.4.2.1.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4">subscript</csymbol><ci id="S2.p5.6.4.m1.8.8.1.4.2.4.2.2.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.2">𝑤</ci><apply id="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.3"><times id="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.1.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.1"></times><ci id="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.2.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.2">𝑘</ci><ci id="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.3.cmml" xref="S2.p5.6.4.m1.8.8.1.4.2.4.2.3.3">𝑗</ci></apply></apply><apply id="S2.p5.6.4.m1.3.3.1.1.1.cmml" xref="S2.p5.6.4.m1.3.3.1.1"><plus id="S2.p5.6.4.m1.3.3.1.1.1.1.cmml" xref="S2.p5.6.4.m1.3.3.1.1.1.1"></plus><ci id="S2.p5.6.4.m1.3.3.1.1.1.2.cmml" xref="S2.p5.6.4.m1.3.3.1.1.1.2">𝑙</ci><cn type="integer" id="S2.p5.6.4.m1.3.3.1.1.1.3.cmml" xref="S2.p5.6.4.m1.3.3.1.1.1.3">1</cn></apply></apply><ci id="S2.p5.6.4.m1.7.7.cmml" xref="S2.p5.6.4.m1.7.7">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.6.4.m1.8c">\delta_{j}^{(l)}(n)=\phi_{j}^{{}^{\prime}}(v_{j}^{l}(n))\sum_{k}\delta_{k}^{(l+1)}(n)w_{kj}^{(l+1)}(n)</annotation></semantics></math></p>
<p id="S2.p5.7" class="ltx_p">For one forward and backward computation, it completes one iteration and updates the weight for next iteration. The adjustment of the synaptic weights of network in layer <math id="S2.p5.7.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.p5.7.m1.1a"><mi id="S2.p5.7.m1.1.1" xref="S2.p5.7.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.p5.7.m1.1b"><ci id="S2.p5.7.m1.1.1.cmml" xref="S2.p5.7.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.7.m1.1c">l</annotation></semantics></math> is computed as:</p>
<p id="S2.p5.8.1" class="ltx_p ltx_align_center"><math id="S2.p5.8.1.m1.10" class="ltx_Math" alttext="w_{ji}^{(l)}(n+1)=w_{ji}^{(l)}(n)+\alpha[w_{ji}^{(l)}(n-1)]+\eta\delta_{j}^{(l)}(n)y_{i}^{(l-1)}(n)" display="inline"><semantics id="S2.p5.8.1.m1.10a"><mrow id="S2.p5.8.1.m1.10.10" xref="S2.p5.8.1.m1.10.10.cmml"><mrow id="S2.p5.8.1.m1.9.9.1" xref="S2.p5.8.1.m1.9.9.1.cmml"><msubsup id="S2.p5.8.1.m1.9.9.1.3" xref="S2.p5.8.1.m1.9.9.1.3.cmml"><mi id="S2.p5.8.1.m1.9.9.1.3.2.2" xref="S2.p5.8.1.m1.9.9.1.3.2.2.cmml">w</mi><mrow id="S2.p5.8.1.m1.9.9.1.3.2.3" xref="S2.p5.8.1.m1.9.9.1.3.2.3.cmml"><mi id="S2.p5.8.1.m1.9.9.1.3.2.3.2" xref="S2.p5.8.1.m1.9.9.1.3.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.9.9.1.3.2.3.1" xref="S2.p5.8.1.m1.9.9.1.3.2.3.1.cmml">​</mo><mi id="S2.p5.8.1.m1.9.9.1.3.2.3.3" xref="S2.p5.8.1.m1.9.9.1.3.2.3.3.cmml">i</mi></mrow><mrow id="S2.p5.8.1.m1.1.1.1.3" xref="S2.p5.8.1.m1.9.9.1.3.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.1.1.1.3.1" xref="S2.p5.8.1.m1.9.9.1.3.cmml">(</mo><mi id="S2.p5.8.1.m1.1.1.1.1" xref="S2.p5.8.1.m1.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.8.1.m1.1.1.1.3.2" xref="S2.p5.8.1.m1.9.9.1.3.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.9.9.1.2" xref="S2.p5.8.1.m1.9.9.1.2.cmml">​</mo><mrow id="S2.p5.8.1.m1.9.9.1.1.1" xref="S2.p5.8.1.m1.9.9.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.9.9.1.1.1.2" xref="S2.p5.8.1.m1.9.9.1.1.1.1.cmml">(</mo><mrow id="S2.p5.8.1.m1.9.9.1.1.1.1" xref="S2.p5.8.1.m1.9.9.1.1.1.1.cmml"><mi id="S2.p5.8.1.m1.9.9.1.1.1.1.2" xref="S2.p5.8.1.m1.9.9.1.1.1.1.2.cmml">n</mi><mo id="S2.p5.8.1.m1.9.9.1.1.1.1.1" xref="S2.p5.8.1.m1.9.9.1.1.1.1.1.cmml">+</mo><mn id="S2.p5.8.1.m1.9.9.1.1.1.1.3" xref="S2.p5.8.1.m1.9.9.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.p5.8.1.m1.9.9.1.1.1.3" xref="S2.p5.8.1.m1.9.9.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.p5.8.1.m1.10.10.3" xref="S2.p5.8.1.m1.10.10.3.cmml">=</mo><mrow id="S2.p5.8.1.m1.10.10.2" xref="S2.p5.8.1.m1.10.10.2.cmml"><mrow id="S2.p5.8.1.m1.10.10.2.3" xref="S2.p5.8.1.m1.10.10.2.3.cmml"><msubsup id="S2.p5.8.1.m1.10.10.2.3.2" xref="S2.p5.8.1.m1.10.10.2.3.2.cmml"><mi id="S2.p5.8.1.m1.10.10.2.3.2.2.2" xref="S2.p5.8.1.m1.10.10.2.3.2.2.2.cmml">w</mi><mrow id="S2.p5.8.1.m1.10.10.2.3.2.2.3" xref="S2.p5.8.1.m1.10.10.2.3.2.2.3.cmml"><mi id="S2.p5.8.1.m1.10.10.2.3.2.2.3.2" xref="S2.p5.8.1.m1.10.10.2.3.2.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.3.2.2.3.1" xref="S2.p5.8.1.m1.10.10.2.3.2.2.3.1.cmml">​</mo><mi id="S2.p5.8.1.m1.10.10.2.3.2.2.3.3" xref="S2.p5.8.1.m1.10.10.2.3.2.2.3.3.cmml">i</mi></mrow><mrow id="S2.p5.8.1.m1.2.2.1.3" xref="S2.p5.8.1.m1.10.10.2.3.2.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.2.2.1.3.1" xref="S2.p5.8.1.m1.10.10.2.3.2.cmml">(</mo><mi id="S2.p5.8.1.m1.2.2.1.1" xref="S2.p5.8.1.m1.2.2.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.8.1.m1.2.2.1.3.2" xref="S2.p5.8.1.m1.10.10.2.3.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.3.1" xref="S2.p5.8.1.m1.10.10.2.3.1.cmml">​</mo><mrow id="S2.p5.8.1.m1.10.10.2.3.3.2" xref="S2.p5.8.1.m1.10.10.2.3.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.3.3.2.1" xref="S2.p5.8.1.m1.10.10.2.3.cmml">(</mo><mi id="S2.p5.8.1.m1.6.6" xref="S2.p5.8.1.m1.6.6.cmml">n</mi><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.3.3.2.2" xref="S2.p5.8.1.m1.10.10.2.3.cmml">)</mo></mrow></mrow><mo id="S2.p5.8.1.m1.10.10.2.2" xref="S2.p5.8.1.m1.10.10.2.2.cmml">+</mo><mrow id="S2.p5.8.1.m1.10.10.2.1" xref="S2.p5.8.1.m1.10.10.2.1.cmml"><mi id="S2.p5.8.1.m1.10.10.2.1.3" xref="S2.p5.8.1.m1.10.10.2.1.3.cmml">α</mi><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.1.2" xref="S2.p5.8.1.m1.10.10.2.1.2.cmml">​</mo><mrow id="S2.p5.8.1.m1.10.10.2.1.1.1" xref="S2.p5.8.1.m1.10.10.2.1.1.2.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.1.1.1.2" xref="S2.p5.8.1.m1.10.10.2.1.1.2.1.cmml">[</mo><mrow id="S2.p5.8.1.m1.10.10.2.1.1.1.1" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.cmml"><msubsup id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.cmml"><mi id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.2" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.2.cmml">w</mi><mrow id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.cmml"><mi id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.2" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.1" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.1.cmml">​</mo><mi id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.3" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.3.cmml">i</mi></mrow><mrow id="S2.p5.8.1.m1.3.3.1.3" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.3.3.1.3.1" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.cmml">(</mo><mi id="S2.p5.8.1.m1.3.3.1.1" xref="S2.p5.8.1.m1.3.3.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.8.1.m1.3.3.1.3.2" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.1.1.1.1.2" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.2.cmml">​</mo><mrow id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.2" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.cmml"><mi id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.2" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.2.cmml">n</mi><mo id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.1" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.3" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.3" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.1.1.1.3" xref="S2.p5.8.1.m1.10.10.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.p5.8.1.m1.10.10.2.2a" xref="S2.p5.8.1.m1.10.10.2.2.cmml">+</mo><mrow id="S2.p5.8.1.m1.10.10.2.4" xref="S2.p5.8.1.m1.10.10.2.4.cmml"><mi id="S2.p5.8.1.m1.10.10.2.4.2" xref="S2.p5.8.1.m1.10.10.2.4.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.4.1" xref="S2.p5.8.1.m1.10.10.2.4.1.cmml">​</mo><msubsup id="S2.p5.8.1.m1.10.10.2.4.3" xref="S2.p5.8.1.m1.10.10.2.4.3.cmml"><mi id="S2.p5.8.1.m1.10.10.2.4.3.2.2" xref="S2.p5.8.1.m1.10.10.2.4.3.2.2.cmml">δ</mi><mi id="S2.p5.8.1.m1.10.10.2.4.3.2.3" xref="S2.p5.8.1.m1.10.10.2.4.3.2.3.cmml">j</mi><mrow id="S2.p5.8.1.m1.4.4.1.3" xref="S2.p5.8.1.m1.10.10.2.4.3.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.4.4.1.3.1" xref="S2.p5.8.1.m1.10.10.2.4.3.cmml">(</mo><mi id="S2.p5.8.1.m1.4.4.1.1" xref="S2.p5.8.1.m1.4.4.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.8.1.m1.4.4.1.3.2" xref="S2.p5.8.1.m1.10.10.2.4.3.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.4.1a" xref="S2.p5.8.1.m1.10.10.2.4.1.cmml">​</mo><mrow id="S2.p5.8.1.m1.10.10.2.4.4.2" xref="S2.p5.8.1.m1.10.10.2.4.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.4.4.2.1" xref="S2.p5.8.1.m1.10.10.2.4.cmml">(</mo><mi id="S2.p5.8.1.m1.7.7" xref="S2.p5.8.1.m1.7.7.cmml">n</mi><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.4.4.2.2" xref="S2.p5.8.1.m1.10.10.2.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.4.1b" xref="S2.p5.8.1.m1.10.10.2.4.1.cmml">​</mo><msubsup id="S2.p5.8.1.m1.10.10.2.4.5" xref="S2.p5.8.1.m1.10.10.2.4.5.cmml"><mi id="S2.p5.8.1.m1.10.10.2.4.5.2.2" xref="S2.p5.8.1.m1.10.10.2.4.5.2.2.cmml">y</mi><mi id="S2.p5.8.1.m1.10.10.2.4.5.2.3" xref="S2.p5.8.1.m1.10.10.2.4.5.2.3.cmml">i</mi><mrow id="S2.p5.8.1.m1.5.5.1.1" xref="S2.p5.8.1.m1.5.5.1.1.1.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.5.5.1.1.2" xref="S2.p5.8.1.m1.5.5.1.1.1.cmml">(</mo><mrow id="S2.p5.8.1.m1.5.5.1.1.1" xref="S2.p5.8.1.m1.5.5.1.1.1.cmml"><mi id="S2.p5.8.1.m1.5.5.1.1.1.2" xref="S2.p5.8.1.m1.5.5.1.1.1.2.cmml">l</mi><mo id="S2.p5.8.1.m1.5.5.1.1.1.1" xref="S2.p5.8.1.m1.5.5.1.1.1.1.cmml">−</mo><mn id="S2.p5.8.1.m1.5.5.1.1.1.3" xref="S2.p5.8.1.m1.5.5.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.p5.8.1.m1.5.5.1.1.3" xref="S2.p5.8.1.m1.5.5.1.1.1.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.8.1.m1.10.10.2.4.1c" xref="S2.p5.8.1.m1.10.10.2.4.1.cmml">​</mo><mrow id="S2.p5.8.1.m1.10.10.2.4.6.2" xref="S2.p5.8.1.m1.10.10.2.4.cmml"><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.4.6.2.1" xref="S2.p5.8.1.m1.10.10.2.4.cmml">(</mo><mi id="S2.p5.8.1.m1.8.8" xref="S2.p5.8.1.m1.8.8.cmml">n</mi><mo stretchy="false" id="S2.p5.8.1.m1.10.10.2.4.6.2.2" xref="S2.p5.8.1.m1.10.10.2.4.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.8.1.m1.10b"><apply id="S2.p5.8.1.m1.10.10.cmml" xref="S2.p5.8.1.m1.10.10"><eq id="S2.p5.8.1.m1.10.10.3.cmml" xref="S2.p5.8.1.m1.10.10.3"></eq><apply id="S2.p5.8.1.m1.9.9.1.cmml" xref="S2.p5.8.1.m1.9.9.1"><times id="S2.p5.8.1.m1.9.9.1.2.cmml" xref="S2.p5.8.1.m1.9.9.1.2"></times><apply id="S2.p5.8.1.m1.9.9.1.3.cmml" xref="S2.p5.8.1.m1.9.9.1.3"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.9.9.1.3.1.cmml" xref="S2.p5.8.1.m1.9.9.1.3">superscript</csymbol><apply id="S2.p5.8.1.m1.9.9.1.3.2.cmml" xref="S2.p5.8.1.m1.9.9.1.3"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.9.9.1.3.2.1.cmml" xref="S2.p5.8.1.m1.9.9.1.3">subscript</csymbol><ci id="S2.p5.8.1.m1.9.9.1.3.2.2.cmml" xref="S2.p5.8.1.m1.9.9.1.3.2.2">𝑤</ci><apply id="S2.p5.8.1.m1.9.9.1.3.2.3.cmml" xref="S2.p5.8.1.m1.9.9.1.3.2.3"><times id="S2.p5.8.1.m1.9.9.1.3.2.3.1.cmml" xref="S2.p5.8.1.m1.9.9.1.3.2.3.1"></times><ci id="S2.p5.8.1.m1.9.9.1.3.2.3.2.cmml" xref="S2.p5.8.1.m1.9.9.1.3.2.3.2">𝑗</ci><ci id="S2.p5.8.1.m1.9.9.1.3.2.3.3.cmml" xref="S2.p5.8.1.m1.9.9.1.3.2.3.3">𝑖</ci></apply></apply><ci id="S2.p5.8.1.m1.1.1.1.1.cmml" xref="S2.p5.8.1.m1.1.1.1.1">𝑙</ci></apply><apply id="S2.p5.8.1.m1.9.9.1.1.1.1.cmml" xref="S2.p5.8.1.m1.9.9.1.1.1"><plus id="S2.p5.8.1.m1.9.9.1.1.1.1.1.cmml" xref="S2.p5.8.1.m1.9.9.1.1.1.1.1"></plus><ci id="S2.p5.8.1.m1.9.9.1.1.1.1.2.cmml" xref="S2.p5.8.1.m1.9.9.1.1.1.1.2">𝑛</ci><cn type="integer" id="S2.p5.8.1.m1.9.9.1.1.1.1.3.cmml" xref="S2.p5.8.1.m1.9.9.1.1.1.1.3">1</cn></apply></apply><apply id="S2.p5.8.1.m1.10.10.2.cmml" xref="S2.p5.8.1.m1.10.10.2"><plus id="S2.p5.8.1.m1.10.10.2.2.cmml" xref="S2.p5.8.1.m1.10.10.2.2"></plus><apply id="S2.p5.8.1.m1.10.10.2.3.cmml" xref="S2.p5.8.1.m1.10.10.2.3"><times id="S2.p5.8.1.m1.10.10.2.3.1.cmml" xref="S2.p5.8.1.m1.10.10.2.3.1"></times><apply id="S2.p5.8.1.m1.10.10.2.3.2.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.10.10.2.3.2.1.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2">superscript</csymbol><apply id="S2.p5.8.1.m1.10.10.2.3.2.2.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.10.10.2.3.2.2.1.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2">subscript</csymbol><ci id="S2.p5.8.1.m1.10.10.2.3.2.2.2.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2.2.2">𝑤</ci><apply id="S2.p5.8.1.m1.10.10.2.3.2.2.3.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2.2.3"><times id="S2.p5.8.1.m1.10.10.2.3.2.2.3.1.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2.2.3.1"></times><ci id="S2.p5.8.1.m1.10.10.2.3.2.2.3.2.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2.2.3.2">𝑗</ci><ci id="S2.p5.8.1.m1.10.10.2.3.2.2.3.3.cmml" xref="S2.p5.8.1.m1.10.10.2.3.2.2.3.3">𝑖</ci></apply></apply><ci id="S2.p5.8.1.m1.2.2.1.1.cmml" xref="S2.p5.8.1.m1.2.2.1.1">𝑙</ci></apply><ci id="S2.p5.8.1.m1.6.6.cmml" xref="S2.p5.8.1.m1.6.6">𝑛</ci></apply><apply id="S2.p5.8.1.m1.10.10.2.1.cmml" xref="S2.p5.8.1.m1.10.10.2.1"><times id="S2.p5.8.1.m1.10.10.2.1.2.cmml" xref="S2.p5.8.1.m1.10.10.2.1.2"></times><ci id="S2.p5.8.1.m1.10.10.2.1.3.cmml" xref="S2.p5.8.1.m1.10.10.2.1.3">𝛼</ci><apply id="S2.p5.8.1.m1.10.10.2.1.1.2.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1"><csymbol cd="latexml" id="S2.p5.8.1.m1.10.10.2.1.1.2.1.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.2">delimited-[]</csymbol><apply id="S2.p5.8.1.m1.10.10.2.1.1.1.1.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1"><times id="S2.p5.8.1.m1.10.10.2.1.1.1.1.2.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.2"></times><apply id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.1.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3">superscript</csymbol><apply id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.1.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3">subscript</csymbol><ci id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.2.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.2">𝑤</ci><apply id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3"><times id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.1.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.1"></times><ci id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.2.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.2">𝑗</ci><ci id="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.3.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.3.2.3.3">𝑖</ci></apply></apply><ci id="S2.p5.8.1.m1.3.3.1.1.cmml" xref="S2.p5.8.1.m1.3.3.1.1">𝑙</ci></apply><apply id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1"><minus id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.1.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.1"></minus><ci id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.2.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.3.cmml" xref="S2.p5.8.1.m1.10.10.2.1.1.1.1.1.1.1.3">1</cn></apply></apply></apply></apply><apply id="S2.p5.8.1.m1.10.10.2.4.cmml" xref="S2.p5.8.1.m1.10.10.2.4"><times id="S2.p5.8.1.m1.10.10.2.4.1.cmml" xref="S2.p5.8.1.m1.10.10.2.4.1"></times><ci id="S2.p5.8.1.m1.10.10.2.4.2.cmml" xref="S2.p5.8.1.m1.10.10.2.4.2">𝜂</ci><apply id="S2.p5.8.1.m1.10.10.2.4.3.cmml" xref="S2.p5.8.1.m1.10.10.2.4.3"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.10.10.2.4.3.1.cmml" xref="S2.p5.8.1.m1.10.10.2.4.3">superscript</csymbol><apply id="S2.p5.8.1.m1.10.10.2.4.3.2.cmml" xref="S2.p5.8.1.m1.10.10.2.4.3"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.10.10.2.4.3.2.1.cmml" xref="S2.p5.8.1.m1.10.10.2.4.3">subscript</csymbol><ci id="S2.p5.8.1.m1.10.10.2.4.3.2.2.cmml" xref="S2.p5.8.1.m1.10.10.2.4.3.2.2">𝛿</ci><ci id="S2.p5.8.1.m1.10.10.2.4.3.2.3.cmml" xref="S2.p5.8.1.m1.10.10.2.4.3.2.3">𝑗</ci></apply><ci id="S2.p5.8.1.m1.4.4.1.1.cmml" xref="S2.p5.8.1.m1.4.4.1.1">𝑙</ci></apply><ci id="S2.p5.8.1.m1.7.7.cmml" xref="S2.p5.8.1.m1.7.7">𝑛</ci><apply id="S2.p5.8.1.m1.10.10.2.4.5.cmml" xref="S2.p5.8.1.m1.10.10.2.4.5"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.10.10.2.4.5.1.cmml" xref="S2.p5.8.1.m1.10.10.2.4.5">superscript</csymbol><apply id="S2.p5.8.1.m1.10.10.2.4.5.2.cmml" xref="S2.p5.8.1.m1.10.10.2.4.5"><csymbol cd="ambiguous" id="S2.p5.8.1.m1.10.10.2.4.5.2.1.cmml" xref="S2.p5.8.1.m1.10.10.2.4.5">subscript</csymbol><ci id="S2.p5.8.1.m1.10.10.2.4.5.2.2.cmml" xref="S2.p5.8.1.m1.10.10.2.4.5.2.2">𝑦</ci><ci id="S2.p5.8.1.m1.10.10.2.4.5.2.3.cmml" xref="S2.p5.8.1.m1.10.10.2.4.5.2.3">𝑖</ci></apply><apply id="S2.p5.8.1.m1.5.5.1.1.1.cmml" xref="S2.p5.8.1.m1.5.5.1.1"><minus id="S2.p5.8.1.m1.5.5.1.1.1.1.cmml" xref="S2.p5.8.1.m1.5.5.1.1.1.1"></minus><ci id="S2.p5.8.1.m1.5.5.1.1.1.2.cmml" xref="S2.p5.8.1.m1.5.5.1.1.1.2">𝑙</ci><cn type="integer" id="S2.p5.8.1.m1.5.5.1.1.1.3.cmml" xref="S2.p5.8.1.m1.5.5.1.1.1.3">1</cn></apply></apply><ci id="S2.p5.8.1.m1.8.8.cmml" xref="S2.p5.8.1.m1.8.8">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.8.1.m1.10c">w_{ji}^{(l)}(n+1)=w_{ji}^{(l)}(n)+\alpha[w_{ji}^{(l)}(n-1)]+\eta\delta_{j}^{(l)}(n)y_{i}^{(l-1)}(n)</annotation></semantics></math></p>
<p id="S2.p5.26" class="ltx_p">In above three steps of MLP, <math id="S2.p5.9.m1.1" class="ltx_Math" alttext="w_{ji}" display="inline"><semantics id="S2.p5.9.m1.1a"><msub id="S2.p5.9.m1.1.1" xref="S2.p5.9.m1.1.1.cmml"><mi id="S2.p5.9.m1.1.1.2" xref="S2.p5.9.m1.1.1.2.cmml">w</mi><mrow id="S2.p5.9.m1.1.1.3" xref="S2.p5.9.m1.1.1.3.cmml"><mi id="S2.p5.9.m1.1.1.3.2" xref="S2.p5.9.m1.1.1.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S2.p5.9.m1.1.1.3.1" xref="S2.p5.9.m1.1.1.3.1.cmml">​</mo><mi id="S2.p5.9.m1.1.1.3.3" xref="S2.p5.9.m1.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p5.9.m1.1b"><apply id="S2.p5.9.m1.1.1.cmml" xref="S2.p5.9.m1.1.1"><csymbol cd="ambiguous" id="S2.p5.9.m1.1.1.1.cmml" xref="S2.p5.9.m1.1.1">subscript</csymbol><ci id="S2.p5.9.m1.1.1.2.cmml" xref="S2.p5.9.m1.1.1.2">𝑤</ci><apply id="S2.p5.9.m1.1.1.3.cmml" xref="S2.p5.9.m1.1.1.3"><times id="S2.p5.9.m1.1.1.3.1.cmml" xref="S2.p5.9.m1.1.1.3.1"></times><ci id="S2.p5.9.m1.1.1.3.2.cmml" xref="S2.p5.9.m1.1.1.3.2">𝑗</ci><ci id="S2.p5.9.m1.1.1.3.3.cmml" xref="S2.p5.9.m1.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.9.m1.1c">w_{ji}</annotation></semantics></math> is the weight from <math id="S2.p5.10.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.p5.10.m2.1a"><mi id="S2.p5.10.m2.1.1" xref="S2.p5.10.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.p5.10.m2.1b"><ci id="S2.p5.10.m2.1.1.cmml" xref="S2.p5.10.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.10.m2.1c">i</annotation></semantics></math> to <math id="S2.p5.11.m3.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p5.11.m3.1a"><mi id="S2.p5.11.m3.1.1" xref="S2.p5.11.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p5.11.m3.1b"><ci id="S2.p5.11.m3.1.1.cmml" xref="S2.p5.11.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.11.m3.1c">j</annotation></semantics></math>; <math id="S2.p5.12.m4.2" class="ltx_Math" alttext="v_{j}^{(l)}(n)" display="inline"><semantics id="S2.p5.12.m4.2a"><mrow id="S2.p5.12.m4.2.3" xref="S2.p5.12.m4.2.3.cmml"><msubsup id="S2.p5.12.m4.2.3.2" xref="S2.p5.12.m4.2.3.2.cmml"><mi id="S2.p5.12.m4.2.3.2.2.2" xref="S2.p5.12.m4.2.3.2.2.2.cmml">v</mi><mi id="S2.p5.12.m4.2.3.2.2.3" xref="S2.p5.12.m4.2.3.2.2.3.cmml">j</mi><mrow id="S2.p5.12.m4.1.1.1.3" xref="S2.p5.12.m4.2.3.2.cmml"><mo stretchy="false" id="S2.p5.12.m4.1.1.1.3.1" xref="S2.p5.12.m4.2.3.2.cmml">(</mo><mi id="S2.p5.12.m4.1.1.1.1" xref="S2.p5.12.m4.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.12.m4.1.1.1.3.2" xref="S2.p5.12.m4.2.3.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.12.m4.2.3.1" xref="S2.p5.12.m4.2.3.1.cmml">​</mo><mrow id="S2.p5.12.m4.2.3.3.2" xref="S2.p5.12.m4.2.3.cmml"><mo stretchy="false" id="S2.p5.12.m4.2.3.3.2.1" xref="S2.p5.12.m4.2.3.cmml">(</mo><mi id="S2.p5.12.m4.2.2" xref="S2.p5.12.m4.2.2.cmml">n</mi><mo stretchy="false" id="S2.p5.12.m4.2.3.3.2.2" xref="S2.p5.12.m4.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.12.m4.2b"><apply id="S2.p5.12.m4.2.3.cmml" xref="S2.p5.12.m4.2.3"><times id="S2.p5.12.m4.2.3.1.cmml" xref="S2.p5.12.m4.2.3.1"></times><apply id="S2.p5.12.m4.2.3.2.cmml" xref="S2.p5.12.m4.2.3.2"><csymbol cd="ambiguous" id="S2.p5.12.m4.2.3.2.1.cmml" xref="S2.p5.12.m4.2.3.2">superscript</csymbol><apply id="S2.p5.12.m4.2.3.2.2.cmml" xref="S2.p5.12.m4.2.3.2"><csymbol cd="ambiguous" id="S2.p5.12.m4.2.3.2.2.1.cmml" xref="S2.p5.12.m4.2.3.2">subscript</csymbol><ci id="S2.p5.12.m4.2.3.2.2.2.cmml" xref="S2.p5.12.m4.2.3.2.2.2">𝑣</ci><ci id="S2.p5.12.m4.2.3.2.2.3.cmml" xref="S2.p5.12.m4.2.3.2.2.3">𝑗</ci></apply><ci id="S2.p5.12.m4.1.1.1.1.cmml" xref="S2.p5.12.m4.1.1.1.1">𝑙</ci></apply><ci id="S2.p5.12.m4.2.2.cmml" xref="S2.p5.12.m4.2.2">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.12.m4.2c">v_{j}^{(l)}(n)</annotation></semantics></math> is neuron <math id="S2.p5.13.m5.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p5.13.m5.1a"><mi id="S2.p5.13.m5.1.1" xref="S2.p5.13.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p5.13.m5.1b"><ci id="S2.p5.13.m5.1.1.cmml" xref="S2.p5.13.m5.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.13.m5.1c">j</annotation></semantics></math> in layer <math id="S2.p5.14.m6.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.p5.14.m6.1a"><mi id="S2.p5.14.m6.1.1" xref="S2.p5.14.m6.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.p5.14.m6.1b"><ci id="S2.p5.14.m6.1.1.cmml" xref="S2.p5.14.m6.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.14.m6.1c">l</annotation></semantics></math>; <math id="S2.p5.15.m7.1" class="ltx_Math" alttext="y_{j}^{(l)}" display="inline"><semantics id="S2.p5.15.m7.1a"><msubsup id="S2.p5.15.m7.1.2" xref="S2.p5.15.m7.1.2.cmml"><mi id="S2.p5.15.m7.1.2.2.2" xref="S2.p5.15.m7.1.2.2.2.cmml">y</mi><mi id="S2.p5.15.m7.1.2.2.3" xref="S2.p5.15.m7.1.2.2.3.cmml">j</mi><mrow id="S2.p5.15.m7.1.1.1.3" xref="S2.p5.15.m7.1.2.cmml"><mo stretchy="false" id="S2.p5.15.m7.1.1.1.3.1" xref="S2.p5.15.m7.1.2.cmml">(</mo><mi id="S2.p5.15.m7.1.1.1.1" xref="S2.p5.15.m7.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.15.m7.1.1.1.3.2" xref="S2.p5.15.m7.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.p5.15.m7.1b"><apply id="S2.p5.15.m7.1.2.cmml" xref="S2.p5.15.m7.1.2"><csymbol cd="ambiguous" id="S2.p5.15.m7.1.2.1.cmml" xref="S2.p5.15.m7.1.2">superscript</csymbol><apply id="S2.p5.15.m7.1.2.2.cmml" xref="S2.p5.15.m7.1.2"><csymbol cd="ambiguous" id="S2.p5.15.m7.1.2.2.1.cmml" xref="S2.p5.15.m7.1.2">subscript</csymbol><ci id="S2.p5.15.m7.1.2.2.2.cmml" xref="S2.p5.15.m7.1.2.2.2">𝑦</ci><ci id="S2.p5.15.m7.1.2.2.3.cmml" xref="S2.p5.15.m7.1.2.2.3">𝑗</ci></apply><ci id="S2.p5.15.m7.1.1.1.1.cmml" xref="S2.p5.15.m7.1.1.1.1">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.15.m7.1c">y_{j}^{(l)}</annotation></semantics></math> is output of neuron <math id="S2.p5.16.m8.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p5.16.m8.1a"><mi id="S2.p5.16.m8.1.1" xref="S2.p5.16.m8.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p5.16.m8.1b"><ci id="S2.p5.16.m8.1.1.cmml" xref="S2.p5.16.m8.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.16.m8.1c">j</annotation></semantics></math> in layer <math id="S2.p5.17.m9.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.p5.17.m9.1a"><mi id="S2.p5.17.m9.1.1" xref="S2.p5.17.m9.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.p5.17.m9.1b"><ci id="S2.p5.17.m9.1.1.cmml" xref="S2.p5.17.m9.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.17.m9.1c">l</annotation></semantics></math>; <math id="S2.p5.18.m10.2" class="ltx_Math" alttext="\delta_{j}^{(l)}(n)" display="inline"><semantics id="S2.p5.18.m10.2a"><mrow id="S2.p5.18.m10.2.3" xref="S2.p5.18.m10.2.3.cmml"><msubsup id="S2.p5.18.m10.2.3.2" xref="S2.p5.18.m10.2.3.2.cmml"><mi id="S2.p5.18.m10.2.3.2.2.2" xref="S2.p5.18.m10.2.3.2.2.2.cmml">δ</mi><mi id="S2.p5.18.m10.2.3.2.2.3" xref="S2.p5.18.m10.2.3.2.2.3.cmml">j</mi><mrow id="S2.p5.18.m10.1.1.1.3" xref="S2.p5.18.m10.2.3.2.cmml"><mo stretchy="false" id="S2.p5.18.m10.1.1.1.3.1" xref="S2.p5.18.m10.2.3.2.cmml">(</mo><mi id="S2.p5.18.m10.1.1.1.1" xref="S2.p5.18.m10.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.p5.18.m10.1.1.1.3.2" xref="S2.p5.18.m10.2.3.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.18.m10.2.3.1" xref="S2.p5.18.m10.2.3.1.cmml">​</mo><mrow id="S2.p5.18.m10.2.3.3.2" xref="S2.p5.18.m10.2.3.cmml"><mo stretchy="false" id="S2.p5.18.m10.2.3.3.2.1" xref="S2.p5.18.m10.2.3.cmml">(</mo><mi id="S2.p5.18.m10.2.2" xref="S2.p5.18.m10.2.2.cmml">n</mi><mo stretchy="false" id="S2.p5.18.m10.2.3.3.2.2" xref="S2.p5.18.m10.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.18.m10.2b"><apply id="S2.p5.18.m10.2.3.cmml" xref="S2.p5.18.m10.2.3"><times id="S2.p5.18.m10.2.3.1.cmml" xref="S2.p5.18.m10.2.3.1"></times><apply id="S2.p5.18.m10.2.3.2.cmml" xref="S2.p5.18.m10.2.3.2"><csymbol cd="ambiguous" id="S2.p5.18.m10.2.3.2.1.cmml" xref="S2.p5.18.m10.2.3.2">superscript</csymbol><apply id="S2.p5.18.m10.2.3.2.2.cmml" xref="S2.p5.18.m10.2.3.2"><csymbol cd="ambiguous" id="S2.p5.18.m10.2.3.2.2.1.cmml" xref="S2.p5.18.m10.2.3.2">subscript</csymbol><ci id="S2.p5.18.m10.2.3.2.2.2.cmml" xref="S2.p5.18.m10.2.3.2.2.2">𝛿</ci><ci id="S2.p5.18.m10.2.3.2.2.3.cmml" xref="S2.p5.18.m10.2.3.2.2.3">𝑗</ci></apply><ci id="S2.p5.18.m10.1.1.1.1.cmml" xref="S2.p5.18.m10.1.1.1.1">𝑙</ci></apply><ci id="S2.p5.18.m10.2.2.cmml" xref="S2.p5.18.m10.2.2">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.18.m10.2c">\delta_{j}^{(l)}(n)</annotation></semantics></math> is gradient for neuron <math id="S2.p5.19.m11.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p5.19.m11.1a"><mi id="S2.p5.19.m11.1.1" xref="S2.p5.19.m11.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p5.19.m11.1b"><ci id="S2.p5.19.m11.1.1.cmml" xref="S2.p5.19.m11.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.19.m11.1c">j</annotation></semantics></math> in layer <math id="S2.p5.20.m12.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.p5.20.m12.1a"><mi id="S2.p5.20.m12.1.1" xref="S2.p5.20.m12.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.p5.20.m12.1b"><ci id="S2.p5.20.m12.1.1.cmml" xref="S2.p5.20.m12.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.20.m12.1c">l</annotation></semantics></math>; <math id="S2.p5.21.m13.2" class="ltx_Math" alttext="e_{j}^{(L)}(n)" display="inline"><semantics id="S2.p5.21.m13.2a"><mrow id="S2.p5.21.m13.2.3" xref="S2.p5.21.m13.2.3.cmml"><msubsup id="S2.p5.21.m13.2.3.2" xref="S2.p5.21.m13.2.3.2.cmml"><mi id="S2.p5.21.m13.2.3.2.2.2" xref="S2.p5.21.m13.2.3.2.2.2.cmml">e</mi><mi id="S2.p5.21.m13.2.3.2.2.3" xref="S2.p5.21.m13.2.3.2.2.3.cmml">j</mi><mrow id="S2.p5.21.m13.1.1.1.3" xref="S2.p5.21.m13.2.3.2.cmml"><mo stretchy="false" id="S2.p5.21.m13.1.1.1.3.1" xref="S2.p5.21.m13.2.3.2.cmml">(</mo><mi id="S2.p5.21.m13.1.1.1.1" xref="S2.p5.21.m13.1.1.1.1.cmml">L</mi><mo stretchy="false" id="S2.p5.21.m13.1.1.1.3.2" xref="S2.p5.21.m13.2.3.2.cmml">)</mo></mrow></msubsup><mo lspace="0em" rspace="0em" id="S2.p5.21.m13.2.3.1" xref="S2.p5.21.m13.2.3.1.cmml">​</mo><mrow id="S2.p5.21.m13.2.3.3.2" xref="S2.p5.21.m13.2.3.cmml"><mo stretchy="false" id="S2.p5.21.m13.2.3.3.2.1" xref="S2.p5.21.m13.2.3.cmml">(</mo><mi id="S2.p5.21.m13.2.2" xref="S2.p5.21.m13.2.2.cmml">n</mi><mo stretchy="false" id="S2.p5.21.m13.2.3.3.2.2" xref="S2.p5.21.m13.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.21.m13.2b"><apply id="S2.p5.21.m13.2.3.cmml" xref="S2.p5.21.m13.2.3"><times id="S2.p5.21.m13.2.3.1.cmml" xref="S2.p5.21.m13.2.3.1"></times><apply id="S2.p5.21.m13.2.3.2.cmml" xref="S2.p5.21.m13.2.3.2"><csymbol cd="ambiguous" id="S2.p5.21.m13.2.3.2.1.cmml" xref="S2.p5.21.m13.2.3.2">superscript</csymbol><apply id="S2.p5.21.m13.2.3.2.2.cmml" xref="S2.p5.21.m13.2.3.2"><csymbol cd="ambiguous" id="S2.p5.21.m13.2.3.2.2.1.cmml" xref="S2.p5.21.m13.2.3.2">subscript</csymbol><ci id="S2.p5.21.m13.2.3.2.2.2.cmml" xref="S2.p5.21.m13.2.3.2.2.2">𝑒</ci><ci id="S2.p5.21.m13.2.3.2.2.3.cmml" xref="S2.p5.21.m13.2.3.2.2.3">𝑗</ci></apply><ci id="S2.p5.21.m13.1.1.1.1.cmml" xref="S2.p5.21.m13.1.1.1.1">𝐿</ci></apply><ci id="S2.p5.21.m13.2.2.cmml" xref="S2.p5.21.m13.2.2">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.21.m13.2c">e_{j}^{(L)}(n)</annotation></semantics></math> is error signal at layer <math id="S2.p5.22.m14.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.p5.22.m14.1a"><mi id="S2.p5.22.m14.1.1" xref="S2.p5.22.m14.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p5.22.m14.1b"><ci id="S2.p5.22.m14.1.1.cmml" xref="S2.p5.22.m14.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.22.m14.1c">L</annotation></semantics></math> for neuron <math id="S2.p5.23.m15.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.p5.23.m15.1a"><mi id="S2.p5.23.m15.1.1" xref="S2.p5.23.m15.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.p5.23.m15.1b"><ci id="S2.p5.23.m15.1.1.cmml" xref="S2.p5.23.m15.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.23.m15.1c">j</annotation></semantics></math>; <math id="S2.p5.24.m16.1" class="ltx_Math" alttext="\phi_{j}^{{}^{\prime}}" display="inline"><semantics id="S2.p5.24.m16.1a"><msubsup id="S2.p5.24.m16.1.1" xref="S2.p5.24.m16.1.1.cmml"><mi id="S2.p5.24.m16.1.1.2.2" xref="S2.p5.24.m16.1.1.2.2.cmml">ϕ</mi><mi id="S2.p5.24.m16.1.1.2.3" xref="S2.p5.24.m16.1.1.2.3.cmml">j</mi><msup id="S2.p5.24.m16.1.1.3" xref="S2.p5.24.m16.1.1.3.cmml"><mi id="S2.p5.24.m16.1.1.3a" xref="S2.p5.24.m16.1.1.3.cmml"></mi><mo id="S2.p5.24.m16.1.1.3.1" xref="S2.p5.24.m16.1.1.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S2.p5.24.m16.1b"><apply id="S2.p5.24.m16.1.1.cmml" xref="S2.p5.24.m16.1.1"><csymbol cd="ambiguous" id="S2.p5.24.m16.1.1.1.cmml" xref="S2.p5.24.m16.1.1">superscript</csymbol><apply id="S2.p5.24.m16.1.1.2.cmml" xref="S2.p5.24.m16.1.1"><csymbol cd="ambiguous" id="S2.p5.24.m16.1.1.2.1.cmml" xref="S2.p5.24.m16.1.1">subscript</csymbol><ci id="S2.p5.24.m16.1.1.2.2.cmml" xref="S2.p5.24.m16.1.1.2.2">italic-ϕ</ci><ci id="S2.p5.24.m16.1.1.2.3.cmml" xref="S2.p5.24.m16.1.1.2.3">𝑗</ci></apply><apply id="S2.p5.24.m16.1.1.3.cmml" xref="S2.p5.24.m16.1.1.3"><ci id="S2.p5.24.m16.1.1.3.1.cmml" xref="S2.p5.24.m16.1.1.3.1">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.24.m16.1c">\phi_{j}^{{}^{\prime}}</annotation></semantics></math> is differentiation of activation function; <math id="S2.p5.25.m17.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.p5.25.m17.1a"><mi id="S2.p5.25.m17.1.1" xref="S2.p5.25.m17.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S2.p5.25.m17.1b"><ci id="S2.p5.25.m17.1.1.cmml" xref="S2.p5.25.m17.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.25.m17.1c">\eta</annotation></semantics></math> and <math id="S2.p5.26.m18.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.p5.26.m18.1a"><mi id="S2.p5.26.m18.1.1" xref="S2.p5.26.m18.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.p5.26.m18.1b"><ci id="S2.p5.26.m18.1.1.cmml" xref="S2.p5.26.m18.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.26.m18.1c">\alpha</annotation></semantics></math> are the learning rate and momentum constant respectively.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Deep Learning Architecture</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">The pattern recognition field has started using DL architectures extensively and image recognition <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky et al. (<a href="#bib.bib40" title="" class="ltx_ref">2012</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Szegedy et al. (<a href="#bib.bib41" title="" class="ltx_ref">2015a</a>)</cite> has also attained good performance for recognizing faces <cite class="ltx_cite ltx_citemacro_cite">Taigman et al. (<a href="#bib.bib42" title="" class="ltx_ref">2014</a>)</cite>, text recognition <cite class="ltx_cite ltx_citemacro_cite">Simard et al. (<a href="#bib.bib43" title="" class="ltx_ref">2003</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Ciresan et al. (<a href="#bib.bib44" title="" class="ltx_ref">2011</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Ciregan et al. (<a href="#bib.bib45" title="" class="ltx_ref">2012</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib46" title="" class="ltx_ref">2012</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Goodfellow et al. (<a href="#bib.bib47" title="" class="ltx_ref">2013</a>)</cite> and estimation of human poses <cite class="ltx_cite ltx_citemacro_cite">Tompson et al. (<a href="#bib.bib48" title="" class="ltx_ref">2014</a>)</cite>. Deep learning, either uses deep architectures of learning or hierarchical learning approaches, is a class of machine learning developed mostly after 2006. The DL architectures have basically made alteration of the traditional form of pattern recognition and have contributed a major development in various handwriting recognition tasks too. The traditional ML approaches perform better for lesser amounts of input data. When the data size increases beyond a certain limit, the performance of traditional machine learning approaches becomes steady, whereas deep learning performance increases with respect to the increment of data size. The key breakthrough of DL is that these models can perform feature extraction and classification automatically. Deep learning architectures with more than one hidden layer are referred to as multilayer perceptron. These architectures include deep feed forward neural network, CNN, RNN, LSTM and the deep generative models as deep belief networks, deep Boltzmann machines, generative adversarial networks <cite class="ltx_cite ltx_citemacro_cite">LeCun et al. (<a href="#bib.bib49" title="" class="ltx_ref">2015b</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Goodfellow et al. (<a href="#bib.bib50" title="" class="ltx_ref">2016</a>)</cite>. Deep learning architectures include to learn patterns in data, mapping of input function to outputs and many more, and it can be attained with specialized architectures only. Among DL architectures, the CNN and RNN: LSTM and BLSTM are the most commonly used vital architectures. LSTM and BLSTM are particularly designed for data in sequential form, have been used in the studies of pattern and handwriting recognition. One of the key problems with the RNN deep network is that the hidden layers are influenced by the input layer and consequently the output layer goes on decaying as it cycles through the network’s recurrent connections, and this problem is known as vanishing gradient problem <cite class="ltx_cite ltx_citemacro_cite">Bengio et al. (<a href="#bib.bib51" title="" class="ltx_ref">1994</a>)</cite>. Such problem becomes a cause for an incomplete range of contextual information access by RNN, and the contextual information cannot be retained for a longer period of time by an architecture of RNN.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Convolutional Neural Network</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">Among different models of DL, the CNN is largely used for the recognition of images. The CNN is a special form of multi-layer NN. Like other networks, CNNs also make the use of back propagation algorithms for training, and the distinction lies in their architectures <cite class="ltx_cite ltx_citemacro_cite">Lecun et al. (<a href="#bib.bib52" title="" class="ltx_ref">1998</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Simard et al. (<a href="#bib.bib43" title="" class="ltx_ref">2003</a>)</cite>. The CNN is very well suited to represent the structure of an image, as there is a strong relationship of image pixels to their neighbouring pixels and have very small correlation with far away pixels. Furthermore, the CNN’s strategy of weight sharing ensures that the similar properties as texture and brightness can be shared by different parts of an image. CNN can efficiently extract and abstract 2D features. The shape variations can be effectively absorbed by the CNN max-pooling layer. Further, the involvement of CNN with less parameters than a similar sized fully connected network has been made possible by sparse connection with tied weights. Most considerably, the gradient-based learning algorithm can train the CNN and the CNN suffers less from the diminishing gradient problem. The recognition of text using CNN is more tricky and tough task than image recognition since the characters and words can have different appearances according to distinct writers, writing styles and writing surfaces. Simply by employing DL techniques, the promising results can be attained for pattern recognition. Nonetheless, with the intention of getting best results in the area of pattern recognition using DL, there are some other challenges that need to be dealt for DL as it is always required to choose the most appropriate DL framework for pattern recognition. As an illustration, for handwriting recognition, CNN was initially used in digits recognition <cite class="ltx_cite ltx_citemacro_cite">LeCun et al. (<a href="#bib.bib53" title="" class="ltx_ref">1998</a>)</cite>. Then CNN and its variants are progressively used in various other handwriting recognition applications. The CNN is the most successful model for image analysis. Since late seventies, the work on CNNs has been done <cite class="ltx_cite ltx_citemacro_cite">Fukushima and Miyake (<a href="#bib.bib54" title="" class="ltx_ref">1982</a>)</cite> and these were already applied for image analysis in medical field in 1995 <cite class="ltx_cite ltx_citemacro_cite">Lo et al. (<a href="#bib.bib55" title="" class="ltx_ref">1995</a>)</cite>. The CNNs were first successfully applied in real-world application in LeNet <cite class="ltx_cite ltx_citemacro_cite">LeCun et al. (<a href="#bib.bib53" title="" class="ltx_ref">1998</a>)</cite> for recognition of handwritten digits. Regardless of CNNs initial achievement, its use did not get momentum until several new techniques were developed to train deep networks efficiently, and advancements were made in core computing systems. The watershed was a contribution <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky et al. (<a href="#bib.bib40" title="" class="ltx_ref">2012</a>)</cite> to the ImageNet challenge in 2012 and the CNN AlexNet won that competition by a huge margin. In recent years, further development has been done using related but deeper architectures <cite class="ltx_cite ltx_citemacro_cite">Russakovsky et al. (<a href="#bib.bib56" title="" class="ltx_ref">2015</a>)</cite>. Deep convolution networks have become a technique of choice in computer vision.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>CNN Architecture</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.2" class="ltx_p">The architecture of CNN comprises two main components as extraction of features and classification. To extract features, CNN’s each layer obtains the output from its immediately preceding layer as an input and then it delivers the current output as an input to the instant next layer, where classifier builds the expected outputs associated with the input data. The figure <a href="#S3.F2" title="Figure 2 ‣ 3.1.1 CNN Architecture ‣ 3.1 Convolutional Neural Network ‣ 3 Deep Learning Architecture ‣ An inclusive review on deep learning techniques and their scope in handwriting recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the basic architecture of CNN. Generally, the architecture of CNN has two fundamental layers as: convolution layer and pooling layer <cite class="ltx_cite ltx_citemacro_cite">LeCun et al. (<a href="#bib.bib53" title="" class="ltx_ref">1998</a>)</cite>. Convolution layer’s each node carries out the convolution operation on the input nodes and does feature extraction from input. The max-pooling layer performs feature extraction using average/maximum operation on input nodes. The output of <math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="{{n-1}^{th}}" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mrow id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml">n</mi><mo id="S3.SS1.SSS1.p1.1.m1.1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml">−</mo><msup id="S3.SS1.SSS1.p1.1.m1.1.1.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml"><mn id="S3.SS1.SSS1.p1.1.m1.1.1.3.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.2.cmml">1</mn><mrow id="S3.SS1.SSS1.p1.1.m1.1.1.3.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.3.cmml">h</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><apply id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1"><minus id="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.1"></minus><ci id="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.2">𝑛</ci><apply id="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S3.SS1.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.2">1</cn><apply id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3"><times id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.1"></times><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.2">𝑡</ci><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.3">ℎ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">{{n-1}^{th}}</annotation></semantics></math> layer is used as an input to <math id="S3.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="{{n}^{th}}" display="inline"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><msup id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml">n</mi><mrow id="S3.SS1.SSS1.p1.2.m2.1.1.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS1.p1.2.m2.1.1.3.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS1.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><apply id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2">𝑛</ci><apply id="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3"><times id="S3.SS1.SSS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS1.SSS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.2">𝑡</ci><ci id="S3.SS1.SSS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">{{n}^{th}}</annotation></semantics></math> layer, where the inputs go through kernels set trailed by ReLU the nonlinear function. The advanced architectures of CNN make use of a stack of convolutional layers and max-pooling layers followed by completely connected and softmax layer at the end. Largely an efficient architecture of the CNN can be built using basic components as convolution layer, pooling layer, softmax layer and fully connected layer.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2404.08011/assets/CNNarchitecture.jpg" id="S3.F2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="301" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Basic architecture of CNN</figcaption>
</figure>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Recurrent neural network</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">The RNN is a type of DL networks in which connections in nodes form a directed graph along a temporal sequence and it allows the demonstration of temporal dynamic behaviour. Feed forward NN is also used to derive an RNN and variable length sequences of inputs can be processed by using the internal state of an RNN. This feature of an RNN makes it applicable to various unsegmented tasks as speech recognition <cite class="ltx_cite ltx_citemacro_cite">Sak et al. (<a href="#bib.bib57" title="" class="ltx_ref">2014</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Li and Wu (<a href="#bib.bib58" title="" class="ltx_ref">2015</a>)</cite> and connected handwriting recognition <cite class="ltx_cite ltx_citemacro_cite">Graves et al. (<a href="#bib.bib59" title="" class="ltx_ref">2009</a>)</cite>. An RNN term refers to two major network classes having similar general structure, in which one RNN is a directed acyclic graph and a strictly feed forward neural network can unroll and replace it, and the second RNN is also a directed cyclic graph but it cannot be unrolled. Both of these RNNs can have extra stored states, and the storage can be directly controlled by an RNN. The storage can also be replaced by other networks or graphs, if it includes time delays or has feedback loops. These controlled states are called gated states and memories, and these are also a part of LSTMs and gated recurrent units.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>RNN Architecture</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">The RNNs are distinctive by the operations over a sequence of vectors over time are permitted by them. There are different architectures of RNN with respective to the applications. The figure <a href="#S3.F3" title="Figure 3 ‣ 3.2.1 RNN Architecture ‣ 3.2 Recurrent neural network ‣ 3 Deep Learning Architecture ‣ An inclusive review on deep learning techniques and their scope in handwriting recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> represents various architectures of RNN. These architectures can be categorized as: one to one, one to many, many to one and many to many.
<br class="ltx_break">
<br class="ltx_break"><span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_bold">One to one:</span> It is a standard mode to classify without RNN and mostly used in image classification.
<br class="ltx_break"><span id="S3.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_bold">One to many:</span> It takes an input and gives a sequence of outputs, and it has been successfully used in image captioning problems where a set of words output is required for a single image input.
<br class="ltx_break"><span id="S3.SS2.SSS1.p1.1.3" class="ltx_text ltx_font_bold">Many to one</span>: It has a sequence of inputs and gives one output only. It is most commonly used in those problems where inputs are in the form of sentences or words set and output is a positive/negative expression.
<br class="ltx_break"><span id="S3.SS2.SSS1.p1.1.4" class="ltx_text ltx_font_bold">Many to many:</span> It produces a sequence of outputs for a sequence of inputs and it is most commonly used in machine translation and video classification problems. 
<br class="ltx_break"></p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">In machine translation problems, a sequence of words in one language is given as an input to a machine and translated to a sequence of words in other language. In video classification problems, video frames are taken as an input and each frame of the video is labelled as an output. 
<br class="ltx_break"></p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2404.08011/assets/RNNarchitectures.jpg" id="S3.F3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="370" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The different architectures of RNN (a) One to one (b) Many to one (c) One to many (d) Many to many (e) Many to many.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Long Short Term Memory</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">An LSTM <cite class="ltx_cite ltx_citemacro_cite">Hochreiter and Schmidhuber (<a href="#bib.bib60" title="" class="ltx_ref">1997</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Graves et al. (<a href="#bib.bib59" title="" class="ltx_ref">2009</a>)</cite> is a particular form of RNN architecture that is specially created to overcome the problem of vanishing gradient <cite class="ltx_cite ltx_citemacro_cite">Bengio et al. (<a href="#bib.bib51" title="" class="ltx_ref">1994</a>)</cite>. An LSTM hidden layer comprises the recurrently connected memory blocks, in which each block has one or more recurrently connected memory cells, and three multiplicative gates (input, output, and forget gates) are used to activate and control it. These three gates make it feasible to store and access the contextual information over a long time period. More particularly, the activation of cell is not overwritten by new inputs until the input gate is closed. Similarly, as long the output gate remains open, the cell activation is accessible to the rest network and the forget gate controls the recurrent connection of the cell. Like CNN architecture, every LSTM layer can have multiple forward and backward layers; multiple feature maps at the output layer; and max-pooling sub-sampling is used to stack multiple LSTM layers.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>LSTM Architecture</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">LSTM is an RNN architecture that takes into account the values over arbitrary intervals. LSTM is suitable for classification, processing and prediction of time series given time lags of unknown duration. Back propagation through time training algorithm is used to update weights in LSTM.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS3.p2.1" class="ltx_p">In last few years, there have been various advanced approaches developed for LSTM. The figure <a href="#S3.F4" title="Figure 4 ‣ 3.2.3 LSTM Architecture ‣ 3.2 Recurrent neural network ‣ 3 Deep Learning Architecture ‣ An inclusive review on deep learning techniques and their scope in handwriting recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the diagram of LSTM. The main scheme for LSTM is the cell state called gates. LSTM can add and remove information to the gates. An input gate, output gate and forget gate are defined as following:</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2404.08011/assets/LSTMfig.jpg" id="S3.F4.g1" class="ltx_graphics ltx_img_landscape" width="538" height="306" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Diagram for LSTM</figcaption>
</figure>
<div id="S3.SS2.SSS3.56" class="ltx_logical-block">
<div id="S3.SS2.SSS3.56.p1" class="ltx_para">
<p id="S3.SS2.SSS3.11.11" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.1.1.m1.1" class="ltx_Math" alttext="{{f_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.1.1.m1.1a"><msub id="S3.SS2.SSS3.1.1.m1.1.1" xref="S3.SS2.SSS3.1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.1.1.m1.1.1.2" xref="S3.SS2.SSS3.1.1.m1.1.1.2.cmml">f</mi><mi id="S3.SS2.SSS3.1.1.m1.1.1.3" xref="S3.SS2.SSS3.1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.1.1.m1.1b"><apply id="S3.SS2.SSS3.1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.1.1.m1.1.1.2">𝑓</ci><ci id="S3.SS2.SSS3.1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.1.1.m1.1c">{{f_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.2.2.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.2.2.m2.1a"><mo id="S3.SS2.SSS3.2.2.m2.1.1" xref="S3.SS2.SSS3.2.2.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.2.2.m2.1b"><eq id="S3.SS2.SSS3.2.2.m2.1.1.cmml" xref="S3.SS2.SSS3.2.2.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.2.2.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.3.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS3.3.3.m3.1a"><mi id="S3.SS2.SSS3.3.3.m3.1.1" xref="S3.SS2.SSS3.3.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.3.3.m3.1b"><ci id="S3.SS2.SSS3.3.3.m3.1.1.cmml" xref="S3.SS2.SSS3.3.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.3.3.m3.1c">\alpha</annotation></semantics></math> <math id="S3.SS2.SSS3.4.4.m4.1" class="ltx_Math" alttext="(" display="inline"><semantics id="S3.SS2.SSS3.4.4.m4.1a"><mo stretchy="false" id="S3.SS2.SSS3.4.4.m4.1.1" xref="S3.SS2.SSS3.4.4.m4.1.1.cmml">(</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.4.4.m4.1b"><ci id="S3.SS2.SSS3.4.4.m4.1.1.cmml" xref="S3.SS2.SSS3.4.4.m4.1.1">(</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.4.4.m4.1c">(</annotation></semantics></math> <math id="S3.SS2.SSS3.5.5.m5.1" class="ltx_Math" alttext="{{W_{f}}}." display="inline"><semantics id="S3.SS2.SSS3.5.5.m5.1a"><mrow id="S3.SS2.SSS3.5.5.m5.1.1.1" xref="S3.SS2.SSS3.5.5.m5.1.1.1.1.cmml"><msub id="S3.SS2.SSS3.5.5.m5.1.1.1.1" xref="S3.SS2.SSS3.5.5.m5.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.5.5.m5.1.1.1.1.2" xref="S3.SS2.SSS3.5.5.m5.1.1.1.1.2.cmml">W</mi><mi id="S3.SS2.SSS3.5.5.m5.1.1.1.1.3" xref="S3.SS2.SSS3.5.5.m5.1.1.1.1.3.cmml">f</mi></msub><mo lspace="0em" id="S3.SS2.SSS3.5.5.m5.1.1.1.2" xref="S3.SS2.SSS3.5.5.m5.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.5.5.m5.1b"><apply id="S3.SS2.SSS3.5.5.m5.1.1.1.1.cmml" xref="S3.SS2.SSS3.5.5.m5.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.5.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.5.5.m5.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.5.5.m5.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.5.5.m5.1.1.1.1.2">𝑊</ci><ci id="S3.SS2.SSS3.5.5.m5.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.5.5.m5.1.1.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.5.5.m5.1c">{{W_{f}}}.</annotation></semantics></math> <math id="S3.SS2.SSS3.6.6.m6.1" class="ltx_Math" alttext="[" display="inline"><semantics id="S3.SS2.SSS3.6.6.m6.1a"><mo stretchy="false" id="S3.SS2.SSS3.6.6.m6.1.1" xref="S3.SS2.SSS3.6.6.m6.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.6.6.m6.1b"><ci id="S3.SS2.SSS3.6.6.m6.1.1.cmml" xref="S3.SS2.SSS3.6.6.m6.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.6.6.m6.1c">[</annotation></semantics></math> <math id="S3.SS2.SSS3.7.7.m7.1" class="ltx_Math" alttext="{{h_{t-1}}}" display="inline"><semantics id="S3.SS2.SSS3.7.7.m7.1a"><msub id="S3.SS2.SSS3.7.7.m7.1.1" xref="S3.SS2.SSS3.7.7.m7.1.1.cmml"><mi id="S3.SS2.SSS3.7.7.m7.1.1.2" xref="S3.SS2.SSS3.7.7.m7.1.1.2.cmml">h</mi><mrow id="S3.SS2.SSS3.7.7.m7.1.1.3" xref="S3.SS2.SSS3.7.7.m7.1.1.3.cmml"><mi id="S3.SS2.SSS3.7.7.m7.1.1.3.2" xref="S3.SS2.SSS3.7.7.m7.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.7.7.m7.1.1.3.1" xref="S3.SS2.SSS3.7.7.m7.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.7.7.m7.1.1.3.3" xref="S3.SS2.SSS3.7.7.m7.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.7.7.m7.1b"><apply id="S3.SS2.SSS3.7.7.m7.1.1.cmml" xref="S3.SS2.SSS3.7.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.7.7.m7.1.1.1.cmml" xref="S3.SS2.SSS3.7.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.7.7.m7.1.1.2.cmml" xref="S3.SS2.SSS3.7.7.m7.1.1.2">ℎ</ci><apply id="S3.SS2.SSS3.7.7.m7.1.1.3.cmml" xref="S3.SS2.SSS3.7.7.m7.1.1.3"><minus id="S3.SS2.SSS3.7.7.m7.1.1.3.1.cmml" xref="S3.SS2.SSS3.7.7.m7.1.1.3.1"></minus><ci id="S3.SS2.SSS3.7.7.m7.1.1.3.2.cmml" xref="S3.SS2.SSS3.7.7.m7.1.1.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS3.7.7.m7.1.1.3.3.cmml" xref="S3.SS2.SSS3.7.7.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.7.7.m7.1c">{{h_{t-1}}}</annotation></semantics></math><span id="S3.SS2.SSS3.11.11.1" class="ltx_text ltx_markedasmath">,</span> <math id="S3.SS2.SSS3.9.9.m9.1" class="ltx_Math" alttext="{{x_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.9.9.m9.1a"><msub id="S3.SS2.SSS3.9.9.m9.1.1" xref="S3.SS2.SSS3.9.9.m9.1.1.cmml"><mi id="S3.SS2.SSS3.9.9.m9.1.1.2" xref="S3.SS2.SSS3.9.9.m9.1.1.2.cmml">x</mi><mi id="S3.SS2.SSS3.9.9.m9.1.1.3" xref="S3.SS2.SSS3.9.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.9.9.m9.1b"><apply id="S3.SS2.SSS3.9.9.m9.1.1.cmml" xref="S3.SS2.SSS3.9.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.9.9.m9.1.1.1.cmml" xref="S3.SS2.SSS3.9.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.9.9.m9.1.1.2.cmml" xref="S3.SS2.SSS3.9.9.m9.1.1.2">𝑥</ci><ci id="S3.SS2.SSS3.9.9.m9.1.1.3.cmml" xref="S3.SS2.SSS3.9.9.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.9.9.m9.1c">{{x_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.10.10.m10.1" class="ltx_math_unparsed" alttext="]+" display="inline"><semantics id="S3.SS2.SSS3.10.10.m10.1a"><mrow id="S3.SS2.SSS3.10.10.m10.1b"><mo stretchy="false" id="S3.SS2.SSS3.10.10.m10.1.1">]</mo><mo id="S3.SS2.SSS3.10.10.m10.1.2">+</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.10.10.m10.1c">]+</annotation></semantics></math> <math id="S3.SS2.SSS3.11.11.m11.1" class="ltx_math_unparsed" alttext="{{b_{f}}})," display="inline"><semantics id="S3.SS2.SSS3.11.11.m11.1a"><mrow id="S3.SS2.SSS3.11.11.m11.1b"><msub id="S3.SS2.SSS3.11.11.m11.1.1"><mi id="S3.SS2.SSS3.11.11.m11.1.1.2">b</mi><mi id="S3.SS2.SSS3.11.11.m11.1.1.3">f</mi></msub><mo stretchy="false" id="S3.SS2.SSS3.11.11.m11.1.2">)</mo><mo id="S3.SS2.SSS3.11.11.m11.1.3">,</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.11.11.m11.1c">{{b_{f}}}),</annotation></semantics></math></p>
<p id="S3.SS2.SSS3.22.22" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.12.12.m1.1" class="ltx_Math" alttext="{{i_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.12.12.m1.1a"><msub id="S3.SS2.SSS3.12.12.m1.1.1" xref="S3.SS2.SSS3.12.12.m1.1.1.cmml"><mi id="S3.SS2.SSS3.12.12.m1.1.1.2" xref="S3.SS2.SSS3.12.12.m1.1.1.2.cmml">i</mi><mi id="S3.SS2.SSS3.12.12.m1.1.1.3" xref="S3.SS2.SSS3.12.12.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.12.12.m1.1b"><apply id="S3.SS2.SSS3.12.12.m1.1.1.cmml" xref="S3.SS2.SSS3.12.12.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.12.12.m1.1.1.1.cmml" xref="S3.SS2.SSS3.12.12.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.12.12.m1.1.1.2.cmml" xref="S3.SS2.SSS3.12.12.m1.1.1.2">𝑖</ci><ci id="S3.SS2.SSS3.12.12.m1.1.1.3.cmml" xref="S3.SS2.SSS3.12.12.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.12.12.m1.1c">{{i_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.13.13.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.13.13.m2.1a"><mo id="S3.SS2.SSS3.13.13.m2.1.1" xref="S3.SS2.SSS3.13.13.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.13.13.m2.1b"><eq id="S3.SS2.SSS3.13.13.m2.1.1.cmml" xref="S3.SS2.SSS3.13.13.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.13.13.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.14.14.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS3.14.14.m3.1a"><mi id="S3.SS2.SSS3.14.14.m3.1.1" xref="S3.SS2.SSS3.14.14.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.14.14.m3.1b"><ci id="S3.SS2.SSS3.14.14.m3.1.1.cmml" xref="S3.SS2.SSS3.14.14.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.14.14.m3.1c">\alpha</annotation></semantics></math> <math id="S3.SS2.SSS3.15.15.m4.1" class="ltx_Math" alttext="(" display="inline"><semantics id="S3.SS2.SSS3.15.15.m4.1a"><mo stretchy="false" id="S3.SS2.SSS3.15.15.m4.1.1" xref="S3.SS2.SSS3.15.15.m4.1.1.cmml">(</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.15.15.m4.1b"><ci id="S3.SS2.SSS3.15.15.m4.1.1.cmml" xref="S3.SS2.SSS3.15.15.m4.1.1">(</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.15.15.m4.1c">(</annotation></semantics></math> <math id="S3.SS2.SSS3.16.16.m5.1" class="ltx_Math" alttext="{{W_{i}}}." display="inline"><semantics id="S3.SS2.SSS3.16.16.m5.1a"><mrow id="S3.SS2.SSS3.16.16.m5.1.1.1" xref="S3.SS2.SSS3.16.16.m5.1.1.1.1.cmml"><msub id="S3.SS2.SSS3.16.16.m5.1.1.1.1" xref="S3.SS2.SSS3.16.16.m5.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.16.16.m5.1.1.1.1.2" xref="S3.SS2.SSS3.16.16.m5.1.1.1.1.2.cmml">W</mi><mi id="S3.SS2.SSS3.16.16.m5.1.1.1.1.3" xref="S3.SS2.SSS3.16.16.m5.1.1.1.1.3.cmml">i</mi></msub><mo lspace="0em" id="S3.SS2.SSS3.16.16.m5.1.1.1.2" xref="S3.SS2.SSS3.16.16.m5.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.16.16.m5.1b"><apply id="S3.SS2.SSS3.16.16.m5.1.1.1.1.cmml" xref="S3.SS2.SSS3.16.16.m5.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.16.16.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.16.16.m5.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.16.16.m5.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.16.16.m5.1.1.1.1.2">𝑊</ci><ci id="S3.SS2.SSS3.16.16.m5.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.16.16.m5.1.1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.16.16.m5.1c">{{W_{i}}}.</annotation></semantics></math> <math id="S3.SS2.SSS3.17.17.m6.1" class="ltx_Math" alttext="[" display="inline"><semantics id="S3.SS2.SSS3.17.17.m6.1a"><mo stretchy="false" id="S3.SS2.SSS3.17.17.m6.1.1" xref="S3.SS2.SSS3.17.17.m6.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.17.17.m6.1b"><ci id="S3.SS2.SSS3.17.17.m6.1.1.cmml" xref="S3.SS2.SSS3.17.17.m6.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.17.17.m6.1c">[</annotation></semantics></math> <math id="S3.SS2.SSS3.18.18.m7.1" class="ltx_Math" alttext="{{h_{t-1}}}" display="inline"><semantics id="S3.SS2.SSS3.18.18.m7.1a"><msub id="S3.SS2.SSS3.18.18.m7.1.1" xref="S3.SS2.SSS3.18.18.m7.1.1.cmml"><mi id="S3.SS2.SSS3.18.18.m7.1.1.2" xref="S3.SS2.SSS3.18.18.m7.1.1.2.cmml">h</mi><mrow id="S3.SS2.SSS3.18.18.m7.1.1.3" xref="S3.SS2.SSS3.18.18.m7.1.1.3.cmml"><mi id="S3.SS2.SSS3.18.18.m7.1.1.3.2" xref="S3.SS2.SSS3.18.18.m7.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.18.18.m7.1.1.3.1" xref="S3.SS2.SSS3.18.18.m7.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.18.18.m7.1.1.3.3" xref="S3.SS2.SSS3.18.18.m7.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.18.18.m7.1b"><apply id="S3.SS2.SSS3.18.18.m7.1.1.cmml" xref="S3.SS2.SSS3.18.18.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.18.18.m7.1.1.1.cmml" xref="S3.SS2.SSS3.18.18.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.18.18.m7.1.1.2.cmml" xref="S3.SS2.SSS3.18.18.m7.1.1.2">ℎ</ci><apply id="S3.SS2.SSS3.18.18.m7.1.1.3.cmml" xref="S3.SS2.SSS3.18.18.m7.1.1.3"><minus id="S3.SS2.SSS3.18.18.m7.1.1.3.1.cmml" xref="S3.SS2.SSS3.18.18.m7.1.1.3.1"></minus><ci id="S3.SS2.SSS3.18.18.m7.1.1.3.2.cmml" xref="S3.SS2.SSS3.18.18.m7.1.1.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS3.18.18.m7.1.1.3.3.cmml" xref="S3.SS2.SSS3.18.18.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.18.18.m7.1c">{{h_{t-1}}}</annotation></semantics></math><span id="S3.SS2.SSS3.22.22.1" class="ltx_text ltx_markedasmath">,</span> <math id="S3.SS2.SSS3.20.20.m9.1" class="ltx_Math" alttext="{{x_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.20.20.m9.1a"><msub id="S3.SS2.SSS3.20.20.m9.1.1" xref="S3.SS2.SSS3.20.20.m9.1.1.cmml"><mi id="S3.SS2.SSS3.20.20.m9.1.1.2" xref="S3.SS2.SSS3.20.20.m9.1.1.2.cmml">x</mi><mi id="S3.SS2.SSS3.20.20.m9.1.1.3" xref="S3.SS2.SSS3.20.20.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.20.20.m9.1b"><apply id="S3.SS2.SSS3.20.20.m9.1.1.cmml" xref="S3.SS2.SSS3.20.20.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.20.20.m9.1.1.1.cmml" xref="S3.SS2.SSS3.20.20.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.20.20.m9.1.1.2.cmml" xref="S3.SS2.SSS3.20.20.m9.1.1.2">𝑥</ci><ci id="S3.SS2.SSS3.20.20.m9.1.1.3.cmml" xref="S3.SS2.SSS3.20.20.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.20.20.m9.1c">{{x_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.21.21.m10.1" class="ltx_math_unparsed" alttext="]+" display="inline"><semantics id="S3.SS2.SSS3.21.21.m10.1a"><mrow id="S3.SS2.SSS3.21.21.m10.1b"><mo stretchy="false" id="S3.SS2.SSS3.21.21.m10.1.1">]</mo><mo id="S3.SS2.SSS3.21.21.m10.1.2">+</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.21.21.m10.1c">]+</annotation></semantics></math> <math id="S3.SS2.SSS3.22.22.m11.1" class="ltx_math_unparsed" alttext="{{b_{i}}})," display="inline"><semantics id="S3.SS2.SSS3.22.22.m11.1a"><mrow id="S3.SS2.SSS3.22.22.m11.1b"><msub id="S3.SS2.SSS3.22.22.m11.1.1"><mi id="S3.SS2.SSS3.22.22.m11.1.1.2">b</mi><mi id="S3.SS2.SSS3.22.22.m11.1.1.3">i</mi></msub><mo stretchy="false" id="S3.SS2.SSS3.22.22.m11.1.2">)</mo><mo id="S3.SS2.SSS3.22.22.m11.1.3">,</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.22.22.m11.1c">{{b_{i}}}),</annotation></semantics></math></p>
<p id="S3.SS2.SSS3.32.32" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.23.23.m1.1" class="ltx_Math" alttext="\tilde{{{C_{t}}}}" display="inline"><semantics id="S3.SS2.SSS3.23.23.m1.1a"><mover accent="true" id="S3.SS2.SSS3.23.23.m1.1.1" xref="S3.SS2.SSS3.23.23.m1.1.1.cmml"><msub id="S3.SS2.SSS3.23.23.m1.1.1.2" xref="S3.SS2.SSS3.23.23.m1.1.1.2.cmml"><mi id="S3.SS2.SSS3.23.23.m1.1.1.2.2" xref="S3.SS2.SSS3.23.23.m1.1.1.2.2.cmml">C</mi><mi id="S3.SS2.SSS3.23.23.m1.1.1.2.3" xref="S3.SS2.SSS3.23.23.m1.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS2.SSS3.23.23.m1.1.1.1" xref="S3.SS2.SSS3.23.23.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.23.23.m1.1b"><apply id="S3.SS2.SSS3.23.23.m1.1.1.cmml" xref="S3.SS2.SSS3.23.23.m1.1.1"><ci id="S3.SS2.SSS3.23.23.m1.1.1.1.cmml" xref="S3.SS2.SSS3.23.23.m1.1.1.1">~</ci><apply id="S3.SS2.SSS3.23.23.m1.1.1.2.cmml" xref="S3.SS2.SSS3.23.23.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.23.23.m1.1.1.2.1.cmml" xref="S3.SS2.SSS3.23.23.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS3.23.23.m1.1.1.2.2.cmml" xref="S3.SS2.SSS3.23.23.m1.1.1.2.2">𝐶</ci><ci id="S3.SS2.SSS3.23.23.m1.1.1.2.3.cmml" xref="S3.SS2.SSS3.23.23.m1.1.1.2.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.23.23.m1.1c">\tilde{{{C_{t}}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.24.24.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.24.24.m2.1a"><mo id="S3.SS2.SSS3.24.24.m2.1.1" xref="S3.SS2.SSS3.24.24.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.24.24.m2.1b"><eq id="S3.SS2.SSS3.24.24.m2.1.1.cmml" xref="S3.SS2.SSS3.24.24.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.24.24.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.25.25.m3.1" class="ltx_Math" alttext="\tanh" display="inline"><semantics id="S3.SS2.SSS3.25.25.m3.1a"><mi id="S3.SS2.SSS3.25.25.m3.1.1" xref="S3.SS2.SSS3.25.25.m3.1.1.cmml">tanh</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.25.25.m3.1b"><tanh id="S3.SS2.SSS3.25.25.m3.1.1.cmml" xref="S3.SS2.SSS3.25.25.m3.1.1"></tanh></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.25.25.m3.1c">\tanh</annotation></semantics></math> <math id="S3.SS2.SSS3.26.26.m4.1" class="ltx_Math" alttext="{{W_{C}}}." display="inline"><semantics id="S3.SS2.SSS3.26.26.m4.1a"><mrow id="S3.SS2.SSS3.26.26.m4.1.1.1" xref="S3.SS2.SSS3.26.26.m4.1.1.1.1.cmml"><msub id="S3.SS2.SSS3.26.26.m4.1.1.1.1" xref="S3.SS2.SSS3.26.26.m4.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.26.26.m4.1.1.1.1.2" xref="S3.SS2.SSS3.26.26.m4.1.1.1.1.2.cmml">W</mi><mi id="S3.SS2.SSS3.26.26.m4.1.1.1.1.3" xref="S3.SS2.SSS3.26.26.m4.1.1.1.1.3.cmml">C</mi></msub><mo lspace="0em" id="S3.SS2.SSS3.26.26.m4.1.1.1.2" xref="S3.SS2.SSS3.26.26.m4.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.26.26.m4.1b"><apply id="S3.SS2.SSS3.26.26.m4.1.1.1.1.cmml" xref="S3.SS2.SSS3.26.26.m4.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.26.26.m4.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.26.26.m4.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.26.26.m4.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.26.26.m4.1.1.1.1.2">𝑊</ci><ci id="S3.SS2.SSS3.26.26.m4.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.26.26.m4.1.1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.26.26.m4.1c">{{W_{C}}}.</annotation></semantics></math> <math id="S3.SS2.SSS3.27.27.m5.1" class="ltx_Math" alttext="[" display="inline"><semantics id="S3.SS2.SSS3.27.27.m5.1a"><mo stretchy="false" id="S3.SS2.SSS3.27.27.m5.1.1" xref="S3.SS2.SSS3.27.27.m5.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.27.27.m5.1b"><ci id="S3.SS2.SSS3.27.27.m5.1.1.cmml" xref="S3.SS2.SSS3.27.27.m5.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.27.27.m5.1c">[</annotation></semantics></math> <math id="S3.SS2.SSS3.28.28.m6.1" class="ltx_Math" alttext="{{h_{C-1}}}" display="inline"><semantics id="S3.SS2.SSS3.28.28.m6.1a"><msub id="S3.SS2.SSS3.28.28.m6.1.1" xref="S3.SS2.SSS3.28.28.m6.1.1.cmml"><mi id="S3.SS2.SSS3.28.28.m6.1.1.2" xref="S3.SS2.SSS3.28.28.m6.1.1.2.cmml">h</mi><mrow id="S3.SS2.SSS3.28.28.m6.1.1.3" xref="S3.SS2.SSS3.28.28.m6.1.1.3.cmml"><mi id="S3.SS2.SSS3.28.28.m6.1.1.3.2" xref="S3.SS2.SSS3.28.28.m6.1.1.3.2.cmml">C</mi><mo id="S3.SS2.SSS3.28.28.m6.1.1.3.1" xref="S3.SS2.SSS3.28.28.m6.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.28.28.m6.1.1.3.3" xref="S3.SS2.SSS3.28.28.m6.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.28.28.m6.1b"><apply id="S3.SS2.SSS3.28.28.m6.1.1.cmml" xref="S3.SS2.SSS3.28.28.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.28.28.m6.1.1.1.cmml" xref="S3.SS2.SSS3.28.28.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.28.28.m6.1.1.2.cmml" xref="S3.SS2.SSS3.28.28.m6.1.1.2">ℎ</ci><apply id="S3.SS2.SSS3.28.28.m6.1.1.3.cmml" xref="S3.SS2.SSS3.28.28.m6.1.1.3"><minus id="S3.SS2.SSS3.28.28.m6.1.1.3.1.cmml" xref="S3.SS2.SSS3.28.28.m6.1.1.3.1"></minus><ci id="S3.SS2.SSS3.28.28.m6.1.1.3.2.cmml" xref="S3.SS2.SSS3.28.28.m6.1.1.3.2">𝐶</ci><cn type="integer" id="S3.SS2.SSS3.28.28.m6.1.1.3.3.cmml" xref="S3.SS2.SSS3.28.28.m6.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.28.28.m6.1c">{{h_{C-1}}}</annotation></semantics></math><span id="S3.SS2.SSS3.32.32.1" class="ltx_text ltx_markedasmath">,</span> <math id="S3.SS2.SSS3.30.30.m8.1" class="ltx_Math" alttext="{{x_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.30.30.m8.1a"><msub id="S3.SS2.SSS3.30.30.m8.1.1" xref="S3.SS2.SSS3.30.30.m8.1.1.cmml"><mi id="S3.SS2.SSS3.30.30.m8.1.1.2" xref="S3.SS2.SSS3.30.30.m8.1.1.2.cmml">x</mi><mi id="S3.SS2.SSS3.30.30.m8.1.1.3" xref="S3.SS2.SSS3.30.30.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.30.30.m8.1b"><apply id="S3.SS2.SSS3.30.30.m8.1.1.cmml" xref="S3.SS2.SSS3.30.30.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.30.30.m8.1.1.1.cmml" xref="S3.SS2.SSS3.30.30.m8.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.30.30.m8.1.1.2.cmml" xref="S3.SS2.SSS3.30.30.m8.1.1.2">𝑥</ci><ci id="S3.SS2.SSS3.30.30.m8.1.1.3.cmml" xref="S3.SS2.SSS3.30.30.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.30.30.m8.1c">{{x_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.31.31.m9.1" class="ltx_math_unparsed" alttext="]+" display="inline"><semantics id="S3.SS2.SSS3.31.31.m9.1a"><mrow id="S3.SS2.SSS3.31.31.m9.1b"><mo stretchy="false" id="S3.SS2.SSS3.31.31.m9.1.1">]</mo><mo id="S3.SS2.SSS3.31.31.m9.1.2">+</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.31.31.m9.1c">]+</annotation></semantics></math> <math id="S3.SS2.SSS3.32.32.m10.1" class="ltx_math_unparsed" alttext="{{b_{C}}})," display="inline"><semantics id="S3.SS2.SSS3.32.32.m10.1a"><mrow id="S3.SS2.SSS3.32.32.m10.1b"><msub id="S3.SS2.SSS3.32.32.m10.1.1"><mi id="S3.SS2.SSS3.32.32.m10.1.1.2">b</mi><mi id="S3.SS2.SSS3.32.32.m10.1.1.3">C</mi></msub><mo stretchy="false" id="S3.SS2.SSS3.32.32.m10.1.2">)</mo><mo id="S3.SS2.SSS3.32.32.m10.1.3">,</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.32.32.m10.1c">{{b_{C}}}),</annotation></semantics></math></p>
<p id="S3.SS2.SSS3.39.39" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.33.33.m1.1" class="ltx_Math" alttext="{{{C_{t}}}}" display="inline"><semantics id="S3.SS2.SSS3.33.33.m1.1a"><msub id="S3.SS2.SSS3.33.33.m1.1.1" xref="S3.SS2.SSS3.33.33.m1.1.1.cmml"><mi id="S3.SS2.SSS3.33.33.m1.1.1.2" xref="S3.SS2.SSS3.33.33.m1.1.1.2.cmml">C</mi><mi id="S3.SS2.SSS3.33.33.m1.1.1.3" xref="S3.SS2.SSS3.33.33.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.33.33.m1.1b"><apply id="S3.SS2.SSS3.33.33.m1.1.1.cmml" xref="S3.SS2.SSS3.33.33.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.33.33.m1.1.1.1.cmml" xref="S3.SS2.SSS3.33.33.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.33.33.m1.1.1.2.cmml" xref="S3.SS2.SSS3.33.33.m1.1.1.2">𝐶</ci><ci id="S3.SS2.SSS3.33.33.m1.1.1.3.cmml" xref="S3.SS2.SSS3.33.33.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.33.33.m1.1c">{{{C_{t}}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.34.34.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.34.34.m2.1a"><mo id="S3.SS2.SSS3.34.34.m2.1.1" xref="S3.SS2.SSS3.34.34.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.34.34.m2.1b"><eq id="S3.SS2.SSS3.34.34.m2.1.1.cmml" xref="S3.SS2.SSS3.34.34.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.34.34.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.35.35.m3.1" class="ltx_math_unparsed" alttext="{{f_{t}}}*" display="inline"><semantics id="S3.SS2.SSS3.35.35.m3.1a"><mrow id="S3.SS2.SSS3.35.35.m3.1b"><msub id="S3.SS2.SSS3.35.35.m3.1.1"><mi id="S3.SS2.SSS3.35.35.m3.1.1.2">f</mi><mi id="S3.SS2.SSS3.35.35.m3.1.1.3">t</mi></msub><mo lspace="0.222em" id="S3.SS2.SSS3.35.35.m3.1.2">∗</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.35.35.m3.1c">{{f_{t}}}*</annotation></semantics></math> <math id="S3.SS2.SSS3.36.36.m4.1" class="ltx_Math" alttext="{{C_{t-1}}}" display="inline"><semantics id="S3.SS2.SSS3.36.36.m4.1a"><msub id="S3.SS2.SSS3.36.36.m4.1.1" xref="S3.SS2.SSS3.36.36.m4.1.1.cmml"><mi id="S3.SS2.SSS3.36.36.m4.1.1.2" xref="S3.SS2.SSS3.36.36.m4.1.1.2.cmml">C</mi><mrow id="S3.SS2.SSS3.36.36.m4.1.1.3" xref="S3.SS2.SSS3.36.36.m4.1.1.3.cmml"><mi id="S3.SS2.SSS3.36.36.m4.1.1.3.2" xref="S3.SS2.SSS3.36.36.m4.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.36.36.m4.1.1.3.1" xref="S3.SS2.SSS3.36.36.m4.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.36.36.m4.1.1.3.3" xref="S3.SS2.SSS3.36.36.m4.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.36.36.m4.1b"><apply id="S3.SS2.SSS3.36.36.m4.1.1.cmml" xref="S3.SS2.SSS3.36.36.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.36.36.m4.1.1.1.cmml" xref="S3.SS2.SSS3.36.36.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.36.36.m4.1.1.2.cmml" xref="S3.SS2.SSS3.36.36.m4.1.1.2">𝐶</ci><apply id="S3.SS2.SSS3.36.36.m4.1.1.3.cmml" xref="S3.SS2.SSS3.36.36.m4.1.1.3"><minus id="S3.SS2.SSS3.36.36.m4.1.1.3.1.cmml" xref="S3.SS2.SSS3.36.36.m4.1.1.3.1"></minus><ci id="S3.SS2.SSS3.36.36.m4.1.1.3.2.cmml" xref="S3.SS2.SSS3.36.36.m4.1.1.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS3.36.36.m4.1.1.3.3.cmml" xref="S3.SS2.SSS3.36.36.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.36.36.m4.1c">{{C_{t-1}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.37.37.m5.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S3.SS2.SSS3.37.37.m5.1a"><mo id="S3.SS2.SSS3.37.37.m5.1.1" xref="S3.SS2.SSS3.37.37.m5.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.37.37.m5.1b"><plus id="S3.SS2.SSS3.37.37.m5.1.1.cmml" xref="S3.SS2.SSS3.37.37.m5.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.37.37.m5.1c">+</annotation></semantics></math> <math id="S3.SS2.SSS3.38.38.m6.1" class="ltx_math_unparsed" alttext="{{i_{t}}}*" display="inline"><semantics id="S3.SS2.SSS3.38.38.m6.1a"><mrow id="S3.SS2.SSS3.38.38.m6.1b"><msub id="S3.SS2.SSS3.38.38.m6.1.1"><mi id="S3.SS2.SSS3.38.38.m6.1.1.2">i</mi><mi id="S3.SS2.SSS3.38.38.m6.1.1.3">t</mi></msub><mo lspace="0.222em" id="S3.SS2.SSS3.38.38.m6.1.2">∗</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.38.38.m6.1c">{{i_{t}}}*</annotation></semantics></math> <math id="S3.SS2.SSS3.39.39.m7.1" class="ltx_Math" alttext="\tilde{{{C_{t}}}}," display="inline"><semantics id="S3.SS2.SSS3.39.39.m7.1a"><mrow id="S3.SS2.SSS3.39.39.m7.1.2.2" xref="S3.SS2.SSS3.39.39.m7.1.1.cmml"><mover accent="true" id="S3.SS2.SSS3.39.39.m7.1.1" xref="S3.SS2.SSS3.39.39.m7.1.1.cmml"><msub id="S3.SS2.SSS3.39.39.m7.1.1.2" xref="S3.SS2.SSS3.39.39.m7.1.1.2.cmml"><mi id="S3.SS2.SSS3.39.39.m7.1.1.2.2" xref="S3.SS2.SSS3.39.39.m7.1.1.2.2.cmml">C</mi><mi id="S3.SS2.SSS3.39.39.m7.1.1.2.3" xref="S3.SS2.SSS3.39.39.m7.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS2.SSS3.39.39.m7.1.1.1" xref="S3.SS2.SSS3.39.39.m7.1.1.1.cmml">~</mo></mover><mo id="S3.SS2.SSS3.39.39.m7.1.2.2.1" xref="S3.SS2.SSS3.39.39.m7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.39.39.m7.1b"><apply id="S3.SS2.SSS3.39.39.m7.1.1.cmml" xref="S3.SS2.SSS3.39.39.m7.1.2.2"><ci id="S3.SS2.SSS3.39.39.m7.1.1.1.cmml" xref="S3.SS2.SSS3.39.39.m7.1.1.1">~</ci><apply id="S3.SS2.SSS3.39.39.m7.1.1.2.cmml" xref="S3.SS2.SSS3.39.39.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.39.39.m7.1.1.2.1.cmml" xref="S3.SS2.SSS3.39.39.m7.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS3.39.39.m7.1.1.2.2.cmml" xref="S3.SS2.SSS3.39.39.m7.1.1.2.2">𝐶</ci><ci id="S3.SS2.SSS3.39.39.m7.1.1.2.3.cmml" xref="S3.SS2.SSS3.39.39.m7.1.1.2.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.39.39.m7.1c">\tilde{{{C_{t}}}},</annotation></semantics></math></p>
<p id="S3.SS2.SSS3.50.50" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.40.40.m1.1" class="ltx_Math" alttext="{{O_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.40.40.m1.1a"><msub id="S3.SS2.SSS3.40.40.m1.1.1" xref="S3.SS2.SSS3.40.40.m1.1.1.cmml"><mi id="S3.SS2.SSS3.40.40.m1.1.1.2" xref="S3.SS2.SSS3.40.40.m1.1.1.2.cmml">O</mi><mi id="S3.SS2.SSS3.40.40.m1.1.1.3" xref="S3.SS2.SSS3.40.40.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.40.40.m1.1b"><apply id="S3.SS2.SSS3.40.40.m1.1.1.cmml" xref="S3.SS2.SSS3.40.40.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.40.40.m1.1.1.1.cmml" xref="S3.SS2.SSS3.40.40.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.40.40.m1.1.1.2.cmml" xref="S3.SS2.SSS3.40.40.m1.1.1.2">𝑂</ci><ci id="S3.SS2.SSS3.40.40.m1.1.1.3.cmml" xref="S3.SS2.SSS3.40.40.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.40.40.m1.1c">{{O_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.41.41.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.41.41.m2.1a"><mo id="S3.SS2.SSS3.41.41.m2.1.1" xref="S3.SS2.SSS3.41.41.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.41.41.m2.1b"><eq id="S3.SS2.SSS3.41.41.m2.1.1.cmml" xref="S3.SS2.SSS3.41.41.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.41.41.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.42.42.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS3.42.42.m3.1a"><mi id="S3.SS2.SSS3.42.42.m3.1.1" xref="S3.SS2.SSS3.42.42.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.42.42.m3.1b"><ci id="S3.SS2.SSS3.42.42.m3.1.1.cmml" xref="S3.SS2.SSS3.42.42.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.42.42.m3.1c">\alpha</annotation></semantics></math> <math id="S3.SS2.SSS3.43.43.m4.1" class="ltx_Math" alttext="(" display="inline"><semantics id="S3.SS2.SSS3.43.43.m4.1a"><mo stretchy="false" id="S3.SS2.SSS3.43.43.m4.1.1" xref="S3.SS2.SSS3.43.43.m4.1.1.cmml">(</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.43.43.m4.1b"><ci id="S3.SS2.SSS3.43.43.m4.1.1.cmml" xref="S3.SS2.SSS3.43.43.m4.1.1">(</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.43.43.m4.1c">(</annotation></semantics></math> <math id="S3.SS2.SSS3.44.44.m5.1" class="ltx_Math" alttext="{{W_{O}}}." display="inline"><semantics id="S3.SS2.SSS3.44.44.m5.1a"><mrow id="S3.SS2.SSS3.44.44.m5.1.1.1" xref="S3.SS2.SSS3.44.44.m5.1.1.1.1.cmml"><msub id="S3.SS2.SSS3.44.44.m5.1.1.1.1" xref="S3.SS2.SSS3.44.44.m5.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.44.44.m5.1.1.1.1.2" xref="S3.SS2.SSS3.44.44.m5.1.1.1.1.2.cmml">W</mi><mi id="S3.SS2.SSS3.44.44.m5.1.1.1.1.3" xref="S3.SS2.SSS3.44.44.m5.1.1.1.1.3.cmml">O</mi></msub><mo lspace="0em" id="S3.SS2.SSS3.44.44.m5.1.1.1.2" xref="S3.SS2.SSS3.44.44.m5.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.44.44.m5.1b"><apply id="S3.SS2.SSS3.44.44.m5.1.1.1.1.cmml" xref="S3.SS2.SSS3.44.44.m5.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.44.44.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.44.44.m5.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.44.44.m5.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.44.44.m5.1.1.1.1.2">𝑊</ci><ci id="S3.SS2.SSS3.44.44.m5.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.44.44.m5.1.1.1.1.3">𝑂</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.44.44.m5.1c">{{W_{O}}}.</annotation></semantics></math> <math id="S3.SS2.SSS3.45.45.m6.1" class="ltx_Math" alttext="[" display="inline"><semantics id="S3.SS2.SSS3.45.45.m6.1a"><mo stretchy="false" id="S3.SS2.SSS3.45.45.m6.1.1" xref="S3.SS2.SSS3.45.45.m6.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.45.45.m6.1b"><ci id="S3.SS2.SSS3.45.45.m6.1.1.cmml" xref="S3.SS2.SSS3.45.45.m6.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.45.45.m6.1c">[</annotation></semantics></math> <math id="S3.SS2.SSS3.46.46.m7.1" class="ltx_Math" alttext="{{h_{t-1}}}" display="inline"><semantics id="S3.SS2.SSS3.46.46.m7.1a"><msub id="S3.SS2.SSS3.46.46.m7.1.1" xref="S3.SS2.SSS3.46.46.m7.1.1.cmml"><mi id="S3.SS2.SSS3.46.46.m7.1.1.2" xref="S3.SS2.SSS3.46.46.m7.1.1.2.cmml">h</mi><mrow id="S3.SS2.SSS3.46.46.m7.1.1.3" xref="S3.SS2.SSS3.46.46.m7.1.1.3.cmml"><mi id="S3.SS2.SSS3.46.46.m7.1.1.3.2" xref="S3.SS2.SSS3.46.46.m7.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.46.46.m7.1.1.3.1" xref="S3.SS2.SSS3.46.46.m7.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.46.46.m7.1.1.3.3" xref="S3.SS2.SSS3.46.46.m7.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.46.46.m7.1b"><apply id="S3.SS2.SSS3.46.46.m7.1.1.cmml" xref="S3.SS2.SSS3.46.46.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.46.46.m7.1.1.1.cmml" xref="S3.SS2.SSS3.46.46.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.46.46.m7.1.1.2.cmml" xref="S3.SS2.SSS3.46.46.m7.1.1.2">ℎ</ci><apply id="S3.SS2.SSS3.46.46.m7.1.1.3.cmml" xref="S3.SS2.SSS3.46.46.m7.1.1.3"><minus id="S3.SS2.SSS3.46.46.m7.1.1.3.1.cmml" xref="S3.SS2.SSS3.46.46.m7.1.1.3.1"></minus><ci id="S3.SS2.SSS3.46.46.m7.1.1.3.2.cmml" xref="S3.SS2.SSS3.46.46.m7.1.1.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS3.46.46.m7.1.1.3.3.cmml" xref="S3.SS2.SSS3.46.46.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.46.46.m7.1c">{{h_{t-1}}}</annotation></semantics></math><span id="S3.SS2.SSS3.50.50.1" class="ltx_text ltx_markedasmath">,</span> <math id="S3.SS2.SSS3.48.48.m9.1" class="ltx_Math" alttext="{{x_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.48.48.m9.1a"><msub id="S3.SS2.SSS3.48.48.m9.1.1" xref="S3.SS2.SSS3.48.48.m9.1.1.cmml"><mi id="S3.SS2.SSS3.48.48.m9.1.1.2" xref="S3.SS2.SSS3.48.48.m9.1.1.2.cmml">x</mi><mi id="S3.SS2.SSS3.48.48.m9.1.1.3" xref="S3.SS2.SSS3.48.48.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.48.48.m9.1b"><apply id="S3.SS2.SSS3.48.48.m9.1.1.cmml" xref="S3.SS2.SSS3.48.48.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.48.48.m9.1.1.1.cmml" xref="S3.SS2.SSS3.48.48.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.48.48.m9.1.1.2.cmml" xref="S3.SS2.SSS3.48.48.m9.1.1.2">𝑥</ci><ci id="S3.SS2.SSS3.48.48.m9.1.1.3.cmml" xref="S3.SS2.SSS3.48.48.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.48.48.m9.1c">{{x_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.49.49.m10.1" class="ltx_math_unparsed" alttext="]+" display="inline"><semantics id="S3.SS2.SSS3.49.49.m10.1a"><mrow id="S3.SS2.SSS3.49.49.m10.1b"><mo stretchy="false" id="S3.SS2.SSS3.49.49.m10.1.1">]</mo><mo id="S3.SS2.SSS3.49.49.m10.1.2">+</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.49.49.m10.1c">]+</annotation></semantics></math> <math id="S3.SS2.SSS3.50.50.m11.1" class="ltx_math_unparsed" alttext="{{b_{O}}})," display="inline"><semantics id="S3.SS2.SSS3.50.50.m11.1a"><mrow id="S3.SS2.SSS3.50.50.m11.1b"><msub id="S3.SS2.SSS3.50.50.m11.1.1"><mi id="S3.SS2.SSS3.50.50.m11.1.1.2">b</mi><mi id="S3.SS2.SSS3.50.50.m11.1.1.3">O</mi></msub><mo stretchy="false" id="S3.SS2.SSS3.50.50.m11.1.2">)</mo><mo id="S3.SS2.SSS3.50.50.m11.1.3">,</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.50.50.m11.1c">{{b_{O}}}),</annotation></semantics></math></p>
<p id="S3.SS2.SSS3.55.55" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.51.51.m1.1" class="ltx_Math" alttext="{{{h_{t}}}}" display="inline"><semantics id="S3.SS2.SSS3.51.51.m1.1a"><msub id="S3.SS2.SSS3.51.51.m1.1.1" xref="S3.SS2.SSS3.51.51.m1.1.1.cmml"><mi id="S3.SS2.SSS3.51.51.m1.1.1.2" xref="S3.SS2.SSS3.51.51.m1.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS3.51.51.m1.1.1.3" xref="S3.SS2.SSS3.51.51.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.51.51.m1.1b"><apply id="S3.SS2.SSS3.51.51.m1.1.1.cmml" xref="S3.SS2.SSS3.51.51.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.51.51.m1.1.1.1.cmml" xref="S3.SS2.SSS3.51.51.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.51.51.m1.1.1.2.cmml" xref="S3.SS2.SSS3.51.51.m1.1.1.2">ℎ</ci><ci id="S3.SS2.SSS3.51.51.m1.1.1.3.cmml" xref="S3.SS2.SSS3.51.51.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.51.51.m1.1c">{{{h_{t}}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.52.52.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.52.52.m2.1a"><mo id="S3.SS2.SSS3.52.52.m2.1.1" xref="S3.SS2.SSS3.52.52.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.52.52.m2.1b"><eq id="S3.SS2.SSS3.52.52.m2.1.1.cmml" xref="S3.SS2.SSS3.52.52.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.52.52.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.53.53.m3.1" class="ltx_math_unparsed" alttext="{{O_{t}}}*" display="inline"><semantics id="S3.SS2.SSS3.53.53.m3.1a"><mrow id="S3.SS2.SSS3.53.53.m3.1b"><msub id="S3.SS2.SSS3.53.53.m3.1.1"><mi id="S3.SS2.SSS3.53.53.m3.1.1.2">O</mi><mi id="S3.SS2.SSS3.53.53.m3.1.1.3">t</mi></msub><mo lspace="0.222em" id="S3.SS2.SSS3.53.53.m3.1.2">∗</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.53.53.m3.1c">{{O_{t}}}*</annotation></semantics></math> <math id="S3.SS2.SSS3.54.54.m4.1" class="ltx_Math" alttext="\tanh" display="inline"><semantics id="S3.SS2.SSS3.54.54.m4.1a"><mi id="S3.SS2.SSS3.54.54.m4.1.1" xref="S3.SS2.SSS3.54.54.m4.1.1.cmml">tanh</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.54.54.m4.1b"><tanh id="S3.SS2.SSS3.54.54.m4.1.1.cmml" xref="S3.SS2.SSS3.54.54.m4.1.1"></tanh></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.54.54.m4.1c">\tanh</annotation></semantics></math> <math id="S3.SS2.SSS3.55.55.m5.1" class="ltx_Math" alttext="({{C_{t}}})." display="inline"><semantics id="S3.SS2.SSS3.55.55.m5.1a"><mrow id="S3.SS2.SSS3.55.55.m5.1.1.1"><mrow id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.2" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.2" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.2.cmml">C</mi><mi id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.3" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.3" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" id="S3.SS2.SSS3.55.55.m5.1.1.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.55.55.m5.1b"><apply id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.2">𝐶</ci><ci id="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.55.55.m5.1.1.1.1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.55.55.m5.1c">({{C_{t}}}).</annotation></semantics></math></p>
</div>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS3.p3.1" class="ltx_p">LSTM models are very well accepted for processing of temporal information. There is also little modified version of network with peephole connections <cite class="ltx_cite ltx_citemacro_cite">Gers and Schmidhuber (<a href="#bib.bib61" title="" class="ltx_ref">2000</a>)</cite>. Gated recurrent unit (GRU) comes from more variation of LSTM <cite class="ltx_cite ltx_citemacro_cite">Chung et al. (<a href="#bib.bib62" title="" class="ltx_ref">2014</a>)</cite>. GRUs are very popular among those people who work with recurrent networks. The major reason behind the recognition of GRU is its less computation cost and simple model as shown in figure <a href="#S3.F5" title="Figure 5 ‣ 3.2.3 LSTM Architecture ‣ 3.2 Recurrent neural network ‣ 3 Deep Learning Architecture ‣ An inclusive review on deep learning techniques and their scope in handwriting recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. GRU model is also faster as it needs fewer network parameters. But LSTM provides better results when we have enough data and computational power [174]. So, in term of computation cost, topology and complexity, GRUs are lighter versions of RNN approaches than standard LSTM. The GRU model combines the input and forget gates into a single update gate and unites the cell state and hidden state with other changes. The GRU can be expressed as following:</p>
</div>
<div id="S3.SS2.SSS3.96" class="ltx_logical-block">
<div id="S3.SS2.SSS3.96.p1" class="ltx_para">
<p id="S3.SS2.SSS3.66.10" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.57.1.m1.1" class="ltx_Math" alttext="{{z_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.57.1.m1.1a"><msub id="S3.SS2.SSS3.57.1.m1.1.1" xref="S3.SS2.SSS3.57.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.57.1.m1.1.1.2" xref="S3.SS2.SSS3.57.1.m1.1.1.2.cmml">z</mi><mi id="S3.SS2.SSS3.57.1.m1.1.1.3" xref="S3.SS2.SSS3.57.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.57.1.m1.1b"><apply id="S3.SS2.SSS3.57.1.m1.1.1.cmml" xref="S3.SS2.SSS3.57.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.57.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.57.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.57.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.57.1.m1.1.1.2">𝑧</ci><ci id="S3.SS2.SSS3.57.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.57.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.57.1.m1.1c">{{z_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.58.2.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.58.2.m2.1a"><mo id="S3.SS2.SSS3.58.2.m2.1.1" xref="S3.SS2.SSS3.58.2.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.58.2.m2.1b"><eq id="S3.SS2.SSS3.58.2.m2.1.1.cmml" xref="S3.SS2.SSS3.58.2.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.58.2.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.59.3.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS3.59.3.m3.1a"><mi id="S3.SS2.SSS3.59.3.m3.1.1" xref="S3.SS2.SSS3.59.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.59.3.m3.1b"><ci id="S3.SS2.SSS3.59.3.m3.1.1.cmml" xref="S3.SS2.SSS3.59.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.59.3.m3.1c">\alpha</annotation></semantics></math> <math id="S3.SS2.SSS3.60.4.m4.1" class="ltx_Math" alttext="(" display="inline"><semantics id="S3.SS2.SSS3.60.4.m4.1a"><mo stretchy="false" id="S3.SS2.SSS3.60.4.m4.1.1" xref="S3.SS2.SSS3.60.4.m4.1.1.cmml">(</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.60.4.m4.1b"><ci id="S3.SS2.SSS3.60.4.m4.1.1.cmml" xref="S3.SS2.SSS3.60.4.m4.1.1">(</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.60.4.m4.1c">(</annotation></semantics></math> <math id="S3.SS2.SSS3.61.5.m5.1" class="ltx_Math" alttext="{{W_{z}}}." display="inline"><semantics id="S3.SS2.SSS3.61.5.m5.1a"><mrow id="S3.SS2.SSS3.61.5.m5.1.1.1" xref="S3.SS2.SSS3.61.5.m5.1.1.1.1.cmml"><msub id="S3.SS2.SSS3.61.5.m5.1.1.1.1" xref="S3.SS2.SSS3.61.5.m5.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.61.5.m5.1.1.1.1.2" xref="S3.SS2.SSS3.61.5.m5.1.1.1.1.2.cmml">W</mi><mi id="S3.SS2.SSS3.61.5.m5.1.1.1.1.3" xref="S3.SS2.SSS3.61.5.m5.1.1.1.1.3.cmml">z</mi></msub><mo lspace="0em" id="S3.SS2.SSS3.61.5.m5.1.1.1.2" xref="S3.SS2.SSS3.61.5.m5.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.61.5.m5.1b"><apply id="S3.SS2.SSS3.61.5.m5.1.1.1.1.cmml" xref="S3.SS2.SSS3.61.5.m5.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.61.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.61.5.m5.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.61.5.m5.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.61.5.m5.1.1.1.1.2">𝑊</ci><ci id="S3.SS2.SSS3.61.5.m5.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.61.5.m5.1.1.1.1.3">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.61.5.m5.1c">{{W_{z}}}.</annotation></semantics></math> <math id="S3.SS2.SSS3.62.6.m6.1" class="ltx_Math" alttext="[" display="inline"><semantics id="S3.SS2.SSS3.62.6.m6.1a"><mo stretchy="false" id="S3.SS2.SSS3.62.6.m6.1.1" xref="S3.SS2.SSS3.62.6.m6.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.62.6.m6.1b"><ci id="S3.SS2.SSS3.62.6.m6.1.1.cmml" xref="S3.SS2.SSS3.62.6.m6.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.62.6.m6.1c">[</annotation></semantics></math> <math id="S3.SS2.SSS3.63.7.m7.1" class="ltx_Math" alttext="{{h_{t-1}}}" display="inline"><semantics id="S3.SS2.SSS3.63.7.m7.1a"><msub id="S3.SS2.SSS3.63.7.m7.1.1" xref="S3.SS2.SSS3.63.7.m7.1.1.cmml"><mi id="S3.SS2.SSS3.63.7.m7.1.1.2" xref="S3.SS2.SSS3.63.7.m7.1.1.2.cmml">h</mi><mrow id="S3.SS2.SSS3.63.7.m7.1.1.3" xref="S3.SS2.SSS3.63.7.m7.1.1.3.cmml"><mi id="S3.SS2.SSS3.63.7.m7.1.1.3.2" xref="S3.SS2.SSS3.63.7.m7.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.63.7.m7.1.1.3.1" xref="S3.SS2.SSS3.63.7.m7.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.63.7.m7.1.1.3.3" xref="S3.SS2.SSS3.63.7.m7.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.63.7.m7.1b"><apply id="S3.SS2.SSS3.63.7.m7.1.1.cmml" xref="S3.SS2.SSS3.63.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.63.7.m7.1.1.1.cmml" xref="S3.SS2.SSS3.63.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.63.7.m7.1.1.2.cmml" xref="S3.SS2.SSS3.63.7.m7.1.1.2">ℎ</ci><apply id="S3.SS2.SSS3.63.7.m7.1.1.3.cmml" xref="S3.SS2.SSS3.63.7.m7.1.1.3"><minus id="S3.SS2.SSS3.63.7.m7.1.1.3.1.cmml" xref="S3.SS2.SSS3.63.7.m7.1.1.3.1"></minus><ci id="S3.SS2.SSS3.63.7.m7.1.1.3.2.cmml" xref="S3.SS2.SSS3.63.7.m7.1.1.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS3.63.7.m7.1.1.3.3.cmml" xref="S3.SS2.SSS3.63.7.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.63.7.m7.1c">{{h_{t-1}}}</annotation></semantics></math><span id="S3.SS2.SSS3.66.10.1" class="ltx_text ltx_markedasmath">,</span> <math id="S3.SS2.SSS3.65.9.m9.1" class="ltx_Math" alttext="{{x_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.65.9.m9.1a"><msub id="S3.SS2.SSS3.65.9.m9.1.1" xref="S3.SS2.SSS3.65.9.m9.1.1.cmml"><mi id="S3.SS2.SSS3.65.9.m9.1.1.2" xref="S3.SS2.SSS3.65.9.m9.1.1.2.cmml">x</mi><mi id="S3.SS2.SSS3.65.9.m9.1.1.3" xref="S3.SS2.SSS3.65.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.65.9.m9.1b"><apply id="S3.SS2.SSS3.65.9.m9.1.1.cmml" xref="S3.SS2.SSS3.65.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.65.9.m9.1.1.1.cmml" xref="S3.SS2.SSS3.65.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.65.9.m9.1.1.2.cmml" xref="S3.SS2.SSS3.65.9.m9.1.1.2">𝑥</ci><ci id="S3.SS2.SSS3.65.9.m9.1.1.3.cmml" xref="S3.SS2.SSS3.65.9.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.65.9.m9.1c">{{x_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.66.10.m10.1" class="ltx_math_unparsed" alttext="])," display="inline"><semantics id="S3.SS2.SSS3.66.10.m10.1a"><mrow id="S3.SS2.SSS3.66.10.m10.1b"><mo stretchy="false" id="S3.SS2.SSS3.66.10.m10.1.1">]</mo><mo stretchy="false" id="S3.SS2.SSS3.66.10.m10.1.2">)</mo><mo id="S3.SS2.SSS3.66.10.m10.1.3">,</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.66.10.m10.1c">]),</annotation></semantics></math></p>
<p id="S3.SS2.SSS3.76.20" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.67.11.m1.1" class="ltx_Math" alttext="{{r_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.67.11.m1.1a"><msub id="S3.SS2.SSS3.67.11.m1.1.1" xref="S3.SS2.SSS3.67.11.m1.1.1.cmml"><mi id="S3.SS2.SSS3.67.11.m1.1.1.2" xref="S3.SS2.SSS3.67.11.m1.1.1.2.cmml">r</mi><mi id="S3.SS2.SSS3.67.11.m1.1.1.3" xref="S3.SS2.SSS3.67.11.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.67.11.m1.1b"><apply id="S3.SS2.SSS3.67.11.m1.1.1.cmml" xref="S3.SS2.SSS3.67.11.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.67.11.m1.1.1.1.cmml" xref="S3.SS2.SSS3.67.11.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.67.11.m1.1.1.2.cmml" xref="S3.SS2.SSS3.67.11.m1.1.1.2">𝑟</ci><ci id="S3.SS2.SSS3.67.11.m1.1.1.3.cmml" xref="S3.SS2.SSS3.67.11.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.67.11.m1.1c">{{r_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.68.12.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.68.12.m2.1a"><mo id="S3.SS2.SSS3.68.12.m2.1.1" xref="S3.SS2.SSS3.68.12.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.68.12.m2.1b"><eq id="S3.SS2.SSS3.68.12.m2.1.1.cmml" xref="S3.SS2.SSS3.68.12.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.68.12.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.69.13.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS3.69.13.m3.1a"><mi id="S3.SS2.SSS3.69.13.m3.1.1" xref="S3.SS2.SSS3.69.13.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.69.13.m3.1b"><ci id="S3.SS2.SSS3.69.13.m3.1.1.cmml" xref="S3.SS2.SSS3.69.13.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.69.13.m3.1c">\alpha</annotation></semantics></math> <math id="S3.SS2.SSS3.70.14.m4.1" class="ltx_Math" alttext="(" display="inline"><semantics id="S3.SS2.SSS3.70.14.m4.1a"><mo stretchy="false" id="S3.SS2.SSS3.70.14.m4.1.1" xref="S3.SS2.SSS3.70.14.m4.1.1.cmml">(</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.70.14.m4.1b"><ci id="S3.SS2.SSS3.70.14.m4.1.1.cmml" xref="S3.SS2.SSS3.70.14.m4.1.1">(</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.70.14.m4.1c">(</annotation></semantics></math> <math id="S3.SS2.SSS3.71.15.m5.1" class="ltx_Math" alttext="{{W_{r}}}." display="inline"><semantics id="S3.SS2.SSS3.71.15.m5.1a"><mrow id="S3.SS2.SSS3.71.15.m5.1.1.1" xref="S3.SS2.SSS3.71.15.m5.1.1.1.1.cmml"><msub id="S3.SS2.SSS3.71.15.m5.1.1.1.1" xref="S3.SS2.SSS3.71.15.m5.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.71.15.m5.1.1.1.1.2" xref="S3.SS2.SSS3.71.15.m5.1.1.1.1.2.cmml">W</mi><mi id="S3.SS2.SSS3.71.15.m5.1.1.1.1.3" xref="S3.SS2.SSS3.71.15.m5.1.1.1.1.3.cmml">r</mi></msub><mo lspace="0em" id="S3.SS2.SSS3.71.15.m5.1.1.1.2" xref="S3.SS2.SSS3.71.15.m5.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.71.15.m5.1b"><apply id="S3.SS2.SSS3.71.15.m5.1.1.1.1.cmml" xref="S3.SS2.SSS3.71.15.m5.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.71.15.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.71.15.m5.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.71.15.m5.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.71.15.m5.1.1.1.1.2">𝑊</ci><ci id="S3.SS2.SSS3.71.15.m5.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.71.15.m5.1.1.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.71.15.m5.1c">{{W_{r}}}.</annotation></semantics></math> <math id="S3.SS2.SSS3.72.16.m6.1" class="ltx_Math" alttext="[" display="inline"><semantics id="S3.SS2.SSS3.72.16.m6.1a"><mo stretchy="false" id="S3.SS2.SSS3.72.16.m6.1.1" xref="S3.SS2.SSS3.72.16.m6.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.72.16.m6.1b"><ci id="S3.SS2.SSS3.72.16.m6.1.1.cmml" xref="S3.SS2.SSS3.72.16.m6.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.72.16.m6.1c">[</annotation></semantics></math> <math id="S3.SS2.SSS3.73.17.m7.1" class="ltx_Math" alttext="{{h_{t-1}}}" display="inline"><semantics id="S3.SS2.SSS3.73.17.m7.1a"><msub id="S3.SS2.SSS3.73.17.m7.1.1" xref="S3.SS2.SSS3.73.17.m7.1.1.cmml"><mi id="S3.SS2.SSS3.73.17.m7.1.1.2" xref="S3.SS2.SSS3.73.17.m7.1.1.2.cmml">h</mi><mrow id="S3.SS2.SSS3.73.17.m7.1.1.3" xref="S3.SS2.SSS3.73.17.m7.1.1.3.cmml"><mi id="S3.SS2.SSS3.73.17.m7.1.1.3.2" xref="S3.SS2.SSS3.73.17.m7.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.73.17.m7.1.1.3.1" xref="S3.SS2.SSS3.73.17.m7.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.73.17.m7.1.1.3.3" xref="S3.SS2.SSS3.73.17.m7.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.73.17.m7.1b"><apply id="S3.SS2.SSS3.73.17.m7.1.1.cmml" xref="S3.SS2.SSS3.73.17.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.73.17.m7.1.1.1.cmml" xref="S3.SS2.SSS3.73.17.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.73.17.m7.1.1.2.cmml" xref="S3.SS2.SSS3.73.17.m7.1.1.2">ℎ</ci><apply id="S3.SS2.SSS3.73.17.m7.1.1.3.cmml" xref="S3.SS2.SSS3.73.17.m7.1.1.3"><minus id="S3.SS2.SSS3.73.17.m7.1.1.3.1.cmml" xref="S3.SS2.SSS3.73.17.m7.1.1.3.1"></minus><ci id="S3.SS2.SSS3.73.17.m7.1.1.3.2.cmml" xref="S3.SS2.SSS3.73.17.m7.1.1.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS3.73.17.m7.1.1.3.3.cmml" xref="S3.SS2.SSS3.73.17.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.73.17.m7.1c">{{h_{t-1}}}</annotation></semantics></math><span id="S3.SS2.SSS3.76.20.1" class="ltx_text ltx_markedasmath">,</span> <math id="S3.SS2.SSS3.75.19.m9.1" class="ltx_Math" alttext="{{x_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.75.19.m9.1a"><msub id="S3.SS2.SSS3.75.19.m9.1.1" xref="S3.SS2.SSS3.75.19.m9.1.1.cmml"><mi id="S3.SS2.SSS3.75.19.m9.1.1.2" xref="S3.SS2.SSS3.75.19.m9.1.1.2.cmml">x</mi><mi id="S3.SS2.SSS3.75.19.m9.1.1.3" xref="S3.SS2.SSS3.75.19.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.75.19.m9.1b"><apply id="S3.SS2.SSS3.75.19.m9.1.1.cmml" xref="S3.SS2.SSS3.75.19.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.75.19.m9.1.1.1.cmml" xref="S3.SS2.SSS3.75.19.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.75.19.m9.1.1.2.cmml" xref="S3.SS2.SSS3.75.19.m9.1.1.2">𝑥</ci><ci id="S3.SS2.SSS3.75.19.m9.1.1.3.cmml" xref="S3.SS2.SSS3.75.19.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.75.19.m9.1c">{{x_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.76.20.m10.1" class="ltx_math_unparsed" alttext="])," display="inline"><semantics id="S3.SS2.SSS3.76.20.m10.1a"><mrow id="S3.SS2.SSS3.76.20.m10.1b"><mo stretchy="false" id="S3.SS2.SSS3.76.20.m10.1.1">]</mo><mo stretchy="false" id="S3.SS2.SSS3.76.20.m10.1.2">)</mo><mo id="S3.SS2.SSS3.76.20.m10.1.3">,</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.76.20.m10.1c">]),</annotation></semantics></math></p>
<p id="S3.SS2.SSS3.87.31" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.77.21.m1.1" class="ltx_Math" alttext="\tilde{{{h_{t}}}}" display="inline"><semantics id="S3.SS2.SSS3.77.21.m1.1a"><mover accent="true" id="S3.SS2.SSS3.77.21.m1.1.1" xref="S3.SS2.SSS3.77.21.m1.1.1.cmml"><msub id="S3.SS2.SSS3.77.21.m1.1.1.2" xref="S3.SS2.SSS3.77.21.m1.1.1.2.cmml"><mi id="S3.SS2.SSS3.77.21.m1.1.1.2.2" xref="S3.SS2.SSS3.77.21.m1.1.1.2.2.cmml">h</mi><mi id="S3.SS2.SSS3.77.21.m1.1.1.2.3" xref="S3.SS2.SSS3.77.21.m1.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS2.SSS3.77.21.m1.1.1.1" xref="S3.SS2.SSS3.77.21.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.77.21.m1.1b"><apply id="S3.SS2.SSS3.77.21.m1.1.1.cmml" xref="S3.SS2.SSS3.77.21.m1.1.1"><ci id="S3.SS2.SSS3.77.21.m1.1.1.1.cmml" xref="S3.SS2.SSS3.77.21.m1.1.1.1">~</ci><apply id="S3.SS2.SSS3.77.21.m1.1.1.2.cmml" xref="S3.SS2.SSS3.77.21.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.77.21.m1.1.1.2.1.cmml" xref="S3.SS2.SSS3.77.21.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS3.77.21.m1.1.1.2.2.cmml" xref="S3.SS2.SSS3.77.21.m1.1.1.2.2">ℎ</ci><ci id="S3.SS2.SSS3.77.21.m1.1.1.2.3.cmml" xref="S3.SS2.SSS3.77.21.m1.1.1.2.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.77.21.m1.1c">\tilde{{{h_{t}}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.78.22.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.78.22.m2.1a"><mo id="S3.SS2.SSS3.78.22.m2.1.1" xref="S3.SS2.SSS3.78.22.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.78.22.m2.1b"><eq id="S3.SS2.SSS3.78.22.m2.1.1.cmml" xref="S3.SS2.SSS3.78.22.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.78.22.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.79.23.m3.1" class="ltx_Math" alttext="\tanh" display="inline"><semantics id="S3.SS2.SSS3.79.23.m3.1a"><mi id="S3.SS2.SSS3.79.23.m3.1.1" xref="S3.SS2.SSS3.79.23.m3.1.1.cmml">tanh</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.79.23.m3.1b"><tanh id="S3.SS2.SSS3.79.23.m3.1.1.cmml" xref="S3.SS2.SSS3.79.23.m3.1.1"></tanh></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.79.23.m3.1c">\tanh</annotation></semantics></math> <math id="S3.SS2.SSS3.80.24.m4.1" class="ltx_math_unparsed" alttext="({{W}}." display="inline"><semantics id="S3.SS2.SSS3.80.24.m4.1a"><mrow id="S3.SS2.SSS3.80.24.m4.1b"><mo stretchy="false" id="S3.SS2.SSS3.80.24.m4.1.1">(</mo><mi id="S3.SS2.SSS3.80.24.m4.1.2">W</mi><mo lspace="0em" id="S3.SS2.SSS3.80.24.m4.1.3">.</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.80.24.m4.1c">({{W}}.</annotation></semantics></math> <math id="S3.SS2.SSS3.81.25.m5.1" class="ltx_Math" alttext="[" display="inline"><semantics id="S3.SS2.SSS3.81.25.m5.1a"><mo stretchy="false" id="S3.SS2.SSS3.81.25.m5.1.1" xref="S3.SS2.SSS3.81.25.m5.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.81.25.m5.1b"><ci id="S3.SS2.SSS3.81.25.m5.1.1.cmml" xref="S3.SS2.SSS3.81.25.m5.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.81.25.m5.1c">[</annotation></semantics></math> <math id="S3.SS2.SSS3.82.26.m6.1" class="ltx_Math" alttext="{{r_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.82.26.m6.1a"><msub id="S3.SS2.SSS3.82.26.m6.1.1" xref="S3.SS2.SSS3.82.26.m6.1.1.cmml"><mi id="S3.SS2.SSS3.82.26.m6.1.1.2" xref="S3.SS2.SSS3.82.26.m6.1.1.2.cmml">r</mi><mi id="S3.SS2.SSS3.82.26.m6.1.1.3" xref="S3.SS2.SSS3.82.26.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.82.26.m6.1b"><apply id="S3.SS2.SSS3.82.26.m6.1.1.cmml" xref="S3.SS2.SSS3.82.26.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.82.26.m6.1.1.1.cmml" xref="S3.SS2.SSS3.82.26.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.82.26.m6.1.1.2.cmml" xref="S3.SS2.SSS3.82.26.m6.1.1.2">𝑟</ci><ci id="S3.SS2.SSS3.82.26.m6.1.1.3.cmml" xref="S3.SS2.SSS3.82.26.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.82.26.m6.1c">{{r_{t}}}</annotation></semantics></math><math id="S3.SS2.SSS3.83.27.m7.1" class="ltx_Math" alttext="*" display="inline"><semantics id="S3.SS2.SSS3.83.27.m7.1a"><mo id="S3.SS2.SSS3.83.27.m7.1.1" xref="S3.SS2.SSS3.83.27.m7.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.83.27.m7.1b"><times id="S3.SS2.SSS3.83.27.m7.1.1.cmml" xref="S3.SS2.SSS3.83.27.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.83.27.m7.1c">*</annotation></semantics></math> <math id="S3.SS2.SSS3.84.28.m8.1" class="ltx_Math" alttext="{{h_{t-1}}}," display="inline"><semantics id="S3.SS2.SSS3.84.28.m8.1a"><mrow id="S3.SS2.SSS3.84.28.m8.1.1.1" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.cmml"><msub id="S3.SS2.SSS3.84.28.m8.1.1.1.1" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.84.28.m8.1.1.1.1.2" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.2.cmml">h</mi><mrow id="S3.SS2.SSS3.84.28.m8.1.1.1.1.3" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.2" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.1" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.3" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS2.SSS3.84.28.m8.1.1.1.2" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.84.28.m8.1b"><apply id="S3.SS2.SSS3.84.28.m8.1.1.1.1.cmml" xref="S3.SS2.SSS3.84.28.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.84.28.m8.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.84.28.m8.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.84.28.m8.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.2">ℎ</ci><apply id="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.3"><minus id="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.1"></minus><ci id="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS3.84.28.m8.1.1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.84.28.m8.1c">{{h_{t-1}}},</annotation></semantics></math> <math id="S3.SS2.SSS3.85.29.m9.1" class="ltx_Math" alttext="{{x_{t}}}" display="inline"><semantics id="S3.SS2.SSS3.85.29.m9.1a"><msub id="S3.SS2.SSS3.85.29.m9.1.1" xref="S3.SS2.SSS3.85.29.m9.1.1.cmml"><mi id="S3.SS2.SSS3.85.29.m9.1.1.2" xref="S3.SS2.SSS3.85.29.m9.1.1.2.cmml">x</mi><mi id="S3.SS2.SSS3.85.29.m9.1.1.3" xref="S3.SS2.SSS3.85.29.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.85.29.m9.1b"><apply id="S3.SS2.SSS3.85.29.m9.1.1.cmml" xref="S3.SS2.SSS3.85.29.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.85.29.m9.1.1.1.cmml" xref="S3.SS2.SSS3.85.29.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.85.29.m9.1.1.2.cmml" xref="S3.SS2.SSS3.85.29.m9.1.1.2">𝑥</ci><ci id="S3.SS2.SSS3.85.29.m9.1.1.3.cmml" xref="S3.SS2.SSS3.85.29.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.85.29.m9.1c">{{x_{t}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.86.30.m10.1" class="ltx_math_unparsed" alttext="])" display="inline"><semantics id="S3.SS2.SSS3.86.30.m10.1a"><mrow id="S3.SS2.SSS3.86.30.m10.1b"><mo stretchy="false" id="S3.SS2.SSS3.86.30.m10.1.1">]</mo><mo stretchy="false" id="S3.SS2.SSS3.86.30.m10.1.2">)</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.86.30.m10.1c">])</annotation></semantics></math><span id="S3.SS2.SSS3.87.31.1" class="ltx_text ltx_markedasmath">,</span></p>
<p id="S3.SS2.SSS3.95.39" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS3.88.32.m1.1" class="ltx_Math" alttext="{{{h_{t}}}}" display="inline"><semantics id="S3.SS2.SSS3.88.32.m1.1a"><msub id="S3.SS2.SSS3.88.32.m1.1.1" xref="S3.SS2.SSS3.88.32.m1.1.1.cmml"><mi id="S3.SS2.SSS3.88.32.m1.1.1.2" xref="S3.SS2.SSS3.88.32.m1.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS3.88.32.m1.1.1.3" xref="S3.SS2.SSS3.88.32.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.88.32.m1.1b"><apply id="S3.SS2.SSS3.88.32.m1.1.1.cmml" xref="S3.SS2.SSS3.88.32.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.88.32.m1.1.1.1.cmml" xref="S3.SS2.SSS3.88.32.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.88.32.m1.1.1.2.cmml" xref="S3.SS2.SSS3.88.32.m1.1.1.2">ℎ</ci><ci id="S3.SS2.SSS3.88.32.m1.1.1.3.cmml" xref="S3.SS2.SSS3.88.32.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.88.32.m1.1c">{{{h_{t}}}}</annotation></semantics></math> <math id="S3.SS2.SSS3.89.33.m2.1" class="ltx_Math" alttext="=" display="inline"><semantics id="S3.SS2.SSS3.89.33.m2.1a"><mo id="S3.SS2.SSS3.89.33.m2.1.1" xref="S3.SS2.SSS3.89.33.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.89.33.m2.1b"><eq id="S3.SS2.SSS3.89.33.m2.1.1.cmml" xref="S3.SS2.SSS3.89.33.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.89.33.m2.1c">=</annotation></semantics></math> <math id="S3.SS2.SSS3.90.34.m3.1" class="ltx_Math" alttext="(1-{{z_{t}}})" display="inline"><semantics id="S3.SS2.SSS3.90.34.m3.1a"><mrow id="S3.SS2.SSS3.90.34.m3.1.1.1" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS3.90.34.m3.1.1.1.2" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS3.90.34.m3.1.1.1.1" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.cmml"><mn id="S3.SS2.SSS3.90.34.m3.1.1.1.1.2" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.2.cmml">1</mn><mo id="S3.SS2.SSS3.90.34.m3.1.1.1.1.1" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.1.cmml">−</mo><msub id="S3.SS2.SSS3.90.34.m3.1.1.1.1.3" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.2" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.3" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.SS2.SSS3.90.34.m3.1.1.1.3" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.90.34.m3.1b"><apply id="S3.SS2.SSS3.90.34.m3.1.1.1.1.cmml" xref="S3.SS2.SSS3.90.34.m3.1.1.1"><minus id="S3.SS2.SSS3.90.34.m3.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.1"></minus><cn type="integer" id="S3.SS2.SSS3.90.34.m3.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.2">1</cn><apply id="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.2">𝑧</ci><ci id="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS3.90.34.m3.1.1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.90.34.m3.1c">(1-{{z_{t}}})</annotation></semantics></math><math id="S3.SS2.SSS3.91.35.m4.1" class="ltx_Math" alttext="*" display="inline"><semantics id="S3.SS2.SSS3.91.35.m4.1a"><mo id="S3.SS2.SSS3.91.35.m4.1.1" xref="S3.SS2.SSS3.91.35.m4.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.91.35.m4.1b"><times id="S3.SS2.SSS3.91.35.m4.1.1.cmml" xref="S3.SS2.SSS3.91.35.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.91.35.m4.1c">*</annotation></semantics></math><math id="S3.SS2.SSS3.92.36.m5.1" class="ltx_Math" alttext="{h_{t-1}}" display="inline"><semantics id="S3.SS2.SSS3.92.36.m5.1a"><msub id="S3.SS2.SSS3.92.36.m5.1.1" xref="S3.SS2.SSS3.92.36.m5.1.1.cmml"><mi id="S3.SS2.SSS3.92.36.m5.1.1.2" xref="S3.SS2.SSS3.92.36.m5.1.1.2.cmml">h</mi><mrow id="S3.SS2.SSS3.92.36.m5.1.1.3" xref="S3.SS2.SSS3.92.36.m5.1.1.3.cmml"><mi id="S3.SS2.SSS3.92.36.m5.1.1.3.2" xref="S3.SS2.SSS3.92.36.m5.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.92.36.m5.1.1.3.1" xref="S3.SS2.SSS3.92.36.m5.1.1.3.1.cmml">−</mo><mn id="S3.SS2.SSS3.92.36.m5.1.1.3.3" xref="S3.SS2.SSS3.92.36.m5.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.92.36.m5.1b"><apply id="S3.SS2.SSS3.92.36.m5.1.1.cmml" xref="S3.SS2.SSS3.92.36.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.92.36.m5.1.1.1.cmml" xref="S3.SS2.SSS3.92.36.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.92.36.m5.1.1.2.cmml" xref="S3.SS2.SSS3.92.36.m5.1.1.2">ℎ</ci><apply id="S3.SS2.SSS3.92.36.m5.1.1.3.cmml" xref="S3.SS2.SSS3.92.36.m5.1.1.3"><minus id="S3.SS2.SSS3.92.36.m5.1.1.3.1.cmml" xref="S3.SS2.SSS3.92.36.m5.1.1.3.1"></minus><ci id="S3.SS2.SSS3.92.36.m5.1.1.3.2.cmml" xref="S3.SS2.SSS3.92.36.m5.1.1.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS3.92.36.m5.1.1.3.3.cmml" xref="S3.SS2.SSS3.92.36.m5.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.92.36.m5.1c">{h_{t-1}}</annotation></semantics></math> <math id="S3.SS2.SSS3.93.37.m6.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S3.SS2.SSS3.93.37.m6.1a"><mo id="S3.SS2.SSS3.93.37.m6.1.1" xref="S3.SS2.SSS3.93.37.m6.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.93.37.m6.1b"><plus id="S3.SS2.SSS3.93.37.m6.1.1.cmml" xref="S3.SS2.SSS3.93.37.m6.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.93.37.m6.1c">+</annotation></semantics></math> <math id="S3.SS2.SSS3.94.38.m7.1" class="ltx_Math" alttext="{z_{t}}" display="inline"><semantics id="S3.SS2.SSS3.94.38.m7.1a"><msub id="S3.SS2.SSS3.94.38.m7.1.1" xref="S3.SS2.SSS3.94.38.m7.1.1.cmml"><mi id="S3.SS2.SSS3.94.38.m7.1.1.2" xref="S3.SS2.SSS3.94.38.m7.1.1.2.cmml">z</mi><mi id="S3.SS2.SSS3.94.38.m7.1.1.3" xref="S3.SS2.SSS3.94.38.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.94.38.m7.1b"><apply id="S3.SS2.SSS3.94.38.m7.1.1.cmml" xref="S3.SS2.SSS3.94.38.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.94.38.m7.1.1.1.cmml" xref="S3.SS2.SSS3.94.38.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.94.38.m7.1.1.2.cmml" xref="S3.SS2.SSS3.94.38.m7.1.1.2">𝑧</ci><ci id="S3.SS2.SSS3.94.38.m7.1.1.3.cmml" xref="S3.SS2.SSS3.94.38.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.94.38.m7.1c">{z_{t}}</annotation></semantics></math><math id="S3.SS2.SSS3.95.39.m8.1" class="ltx_Math" alttext="*\tilde{{{h_{t}}}}." display="inline"><semantics id="S3.SS2.SSS3.95.39.m8.1a"><mrow id="S3.SS2.SSS3.95.39.m8.1.1.1" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.cmml"><mrow id="S3.SS2.SSS3.95.39.m8.1.1.1.1" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.95.39.m8.1.1.1.1.2" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.SSS3.95.39.m8.1.1.1.1.1" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.1.cmml">∗</mo><mover accent="true" id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.cmml"><msub id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.cmml"><mi id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.2" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.2.cmml">h</mi><mi id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.3" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.3.cmml">t</mi></msub><mo id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.1" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.1.cmml">~</mo></mover></mrow><mo lspace="0em" id="S3.SS2.SSS3.95.39.m8.1.1.1.2" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.95.39.m8.1b"><apply id="S3.SS2.SSS3.95.39.m8.1.1.1.1.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1"><times id="S3.SS2.SSS3.95.39.m8.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.1"></times><csymbol cd="latexml" id="S3.SS2.SSS3.95.39.m8.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.2">absent</csymbol><apply id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3"><ci id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.1">~</ci><apply id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.1.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2">subscript</csymbol><ci id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.2.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.2">ℎ</ci><ci id="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.3.cmml" xref="S3.SS2.SSS3.95.39.m8.1.1.1.1.3.2.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.95.39.m8.1c">*\tilde{{{h_{t}}}}.</annotation></semantics></math></p>
</div>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2404.08011/assets/GRUfig.jpg" id="S3.F5.g1" class="ltx_graphics ltx_img_landscape" width="538" height="326" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Gated Recurrent Unit</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Bidirectional Long Short Term Memory</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS4.p1.1" class="ltx_p">In most problems of pattern recognition, it is required to access the previous and future contexts at the same time. For instance, in all problems of handwriting recognition, character recognition can be performed by recognizing the characters which appear both to the left and right of it. Further the bidirectional RNNs (BRNNs) <cite class="ltx_cite ltx_citemacro_cite">Schuster and Paliwal (<a href="#bib.bib63" title="" class="ltx_ref">1997</a>)</cite> can be employed to attain the context information in left and right directions along the input sequence. In two different hidden layers of BRNNs, one layer is employed for processing of input sequence in forward direction and the subsequent in backward direction. Since both the hidden layers of BRNN are connected to the same layer of output, so the access of past and future context of every point in the sequence is given by it. BRNNs were effectively used to predict protein structure and speech processing <cite class="ltx_cite ltx_citemacro_cite">Schuster and Paliwal (<a href="#bib.bib63" title="" class="ltx_ref">1997</a>)</cite>, and BRNNs did better than the standard RNNs in different tasks of sequence learning. BLSTM is a combination of LSTM and BRNN.</p>
</div>
</section>
<section id="S3.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.5 </span>BLSTM Architecture</h4>

<div id="S3.SS2.SSS5.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS5.p1.5" class="ltx_p">Bidirectional LSTMs process the input sequences in both directions having two sub layers for consideration of the full input context. The figure <a href="#S3.F6" title="Figure 6 ‣ 3.2.5 BLSTM Architecture ‣ 3.2 Recurrent neural network ‣ 3 Deep Learning Architecture ‣ An inclusive review on deep learning techniques and their scope in handwriting recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> presents the architecture of BLSTM. Two sub layers of BLSTM can compute both forward (<math id="S3.SS2.SSS5.p1.1.m1.1" class="ltx_Math" alttext="\overrightarrow{h}" display="inline"><semantics id="S3.SS2.SSS5.p1.1.m1.1a"><mover accent="true" id="S3.SS2.SSS5.p1.1.m1.1.1" xref="S3.SS2.SSS5.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS5.p1.1.m1.1.1.2" xref="S3.SS2.SSS5.p1.1.m1.1.1.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.p1.1.m1.1.1.1" xref="S3.SS2.SSS5.p1.1.m1.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.1.m1.1b"><apply id="S3.SS2.SSS5.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS5.p1.1.m1.1.1"><ci id="S3.SS2.SSS5.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS5.p1.1.m1.1.1.1">→</ci><ci id="S3.SS2.SSS5.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS5.p1.1.m1.1.1.2">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.1.m1.1c">\overrightarrow{h}</annotation></semantics></math>) and backward (<math id="S3.SS2.SSS5.p1.2.m2.1" class="ltx_Math" alttext="\overleftarrow{h}" display="inline"><semantics id="S3.SS2.SSS5.p1.2.m2.1a"><mover accent="true" id="S3.SS2.SSS5.p1.2.m2.1.1" xref="S3.SS2.SSS5.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS5.p1.2.m2.1.1.2" xref="S3.SS2.SSS5.p1.2.m2.1.1.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.p1.2.m2.1.1.1" xref="S3.SS2.SSS5.p1.2.m2.1.1.1.cmml">←</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.2.m2.1b"><apply id="S3.SS2.SSS5.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1"><ci id="S3.SS2.SSS5.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1.1">←</ci><ci id="S3.SS2.SSS5.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS5.p1.2.m2.1.1.2">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.2.m2.1c">\overleftarrow{h}</annotation></semantics></math>) hidden layers. Both <math id="S3.SS2.SSS5.p1.3.m3.1" class="ltx_Math" alttext="\overrightarrow{h}" display="inline"><semantics id="S3.SS2.SSS5.p1.3.m3.1a"><mover accent="true" id="S3.SS2.SSS5.p1.3.m3.1.1" xref="S3.SS2.SSS5.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS5.p1.3.m3.1.1.2" xref="S3.SS2.SSS5.p1.3.m3.1.1.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.p1.3.m3.1.1.1" xref="S3.SS2.SSS5.p1.3.m3.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.3.m3.1b"><apply id="S3.SS2.SSS5.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS5.p1.3.m3.1.1"><ci id="S3.SS2.SSS5.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS5.p1.3.m3.1.1.1">→</ci><ci id="S3.SS2.SSS5.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS5.p1.3.m3.1.1.2">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.3.m3.1c">\overrightarrow{h}</annotation></semantics></math> and <math id="S3.SS2.SSS5.p1.4.m4.1" class="ltx_Math" alttext="\overleftarrow{h}" display="inline"><semantics id="S3.SS2.SSS5.p1.4.m4.1a"><mover accent="true" id="S3.SS2.SSS5.p1.4.m4.1.1" xref="S3.SS2.SSS5.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS5.p1.4.m4.1.1.2" xref="S3.SS2.SSS5.p1.4.m4.1.1.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.p1.4.m4.1.1.1" xref="S3.SS2.SSS5.p1.4.m4.1.1.1.cmml">←</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.4.m4.1b"><apply id="S3.SS2.SSS5.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS5.p1.4.m4.1.1"><ci id="S3.SS2.SSS5.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS5.p1.4.m4.1.1.1">←</ci><ci id="S3.SS2.SSS5.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS5.p1.4.m4.1.1.2">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.4.m4.1c">\overleftarrow{h}</annotation></semantics></math> are combined for the computation of the output sequence (<math id="S3.SS2.SSS5.p1.5.m5.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS2.SSS5.p1.5.m5.1a"><mi id="S3.SS2.SSS5.p1.5.m5.1.1" xref="S3.SS2.SSS5.p1.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.p1.5.m5.1b"><ci id="S3.SS2.SSS5.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS5.p1.5.m5.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.p1.5.m5.1c">y</annotation></semantics></math>) as following:</p>
</div>
<div id="S3.SS2.SSS5.19" class="ltx_logical-block">
<div id="S3.SS2.SSS5.19.p1" class="ltx_para">
<p id="S3.SS2.SSS5.6.6" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS5.1.1.m1.1" class="ltx_Math" alttext="{\overrightarrow{h}}_{t}" display="inline"><semantics id="S3.SS2.SSS5.1.1.m1.1a"><msub id="S3.SS2.SSS5.1.1.m1.1.1" xref="S3.SS2.SSS5.1.1.m1.1.1.cmml"><mover accent="true" id="S3.SS2.SSS5.1.1.m1.1.1.2" xref="S3.SS2.SSS5.1.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS5.1.1.m1.1.1.2.2" xref="S3.SS2.SSS5.1.1.m1.1.1.2.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.1.1.m1.1.1.2.1" xref="S3.SS2.SSS5.1.1.m1.1.1.2.1.cmml">→</mo></mover><mi id="S3.SS2.SSS5.1.1.m1.1.1.3" xref="S3.SS2.SSS5.1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.1.1.m1.1b"><apply id="S3.SS2.SSS5.1.1.m1.1.1.cmml" xref="S3.SS2.SSS5.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS5.1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS5.1.1.m1.1.1">subscript</csymbol><apply id="S3.SS2.SSS5.1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS5.1.1.m1.1.1.2"><ci id="S3.SS2.SSS5.1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS5.1.1.m1.1.1.2.1">→</ci><ci id="S3.SS2.SSS5.1.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS5.1.1.m1.1.1.2.2">ℎ</ci></apply><ci id="S3.SS2.SSS5.1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS5.1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.1.1.m1.1c">{\overrightarrow{h}}_{t}</annotation></semantics></math> = <math id="S3.SS2.SSS5.2.2.m2.1" class="ltx_math_unparsed" alttext="\mathcal{H}(W_{x\overrightarrow{h}}x_{t}" display="inline"><semantics id="S3.SS2.SSS5.2.2.m2.1a"><mrow id="S3.SS2.SSS5.2.2.m2.1b"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS5.2.2.m2.1.1">ℋ</mi><mrow id="S3.SS2.SSS5.2.2.m2.1.2"><mo stretchy="false" id="S3.SS2.SSS5.2.2.m2.1.2.1">(</mo><msub id="S3.SS2.SSS5.2.2.m2.1.2.2"><mi id="S3.SS2.SSS5.2.2.m2.1.2.2.2">W</mi><mrow id="S3.SS2.SSS5.2.2.m2.1.2.2.3"><mi id="S3.SS2.SSS5.2.2.m2.1.2.2.3.2">x</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.2.2.m2.1.2.2.3.1">​</mo><mover accent="true" id="S3.SS2.SSS5.2.2.m2.1.2.2.3.3"><mi id="S3.SS2.SSS5.2.2.m2.1.2.2.3.3.2">h</mi><mo stretchy="false" id="S3.SS2.SSS5.2.2.m2.1.2.2.3.3.1">→</mo></mover></mrow></msub><msub id="S3.SS2.SSS5.2.2.m2.1.2.3"><mi id="S3.SS2.SSS5.2.2.m2.1.2.3.2">x</mi><mi id="S3.SS2.SSS5.2.2.m2.1.2.3.3">t</mi></msub></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS5.2.2.m2.1c">\mathcal{H}(W_{x\overrightarrow{h}}x_{t}</annotation></semantics></math> <math id="S3.SS2.SSS5.3.3.m3.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S3.SS2.SSS5.3.3.m3.1a"><mo id="S3.SS2.SSS5.3.3.m3.1.1" xref="S3.SS2.SSS5.3.3.m3.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.3.3.m3.1b"><plus id="S3.SS2.SSS5.3.3.m3.1.1.cmml" xref="S3.SS2.SSS5.3.3.m3.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.3.3.m3.1c">+</annotation></semantics></math> <math id="S3.SS2.SSS5.4.4.m4.1" class="ltx_Math" alttext="W_{\overrightarrow{h}\overrightarrow{h}}\overrightarrow{h}_{t-1}" display="inline"><semantics id="S3.SS2.SSS5.4.4.m4.1a"><mrow id="S3.SS2.SSS5.4.4.m4.1.1" xref="S3.SS2.SSS5.4.4.m4.1.1.cmml"><msub id="S3.SS2.SSS5.4.4.m4.1.1.2" xref="S3.SS2.SSS5.4.4.m4.1.1.2.cmml"><mi id="S3.SS2.SSS5.4.4.m4.1.1.2.2" xref="S3.SS2.SSS5.4.4.m4.1.1.2.2.cmml">W</mi><mrow id="S3.SS2.SSS5.4.4.m4.1.1.2.3" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.cmml"><mover accent="true" id="S3.SS2.SSS5.4.4.m4.1.1.2.3.2" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.cmml"><mi id="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.2" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.1" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.1.cmml">→</mo></mover><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.4.4.m4.1.1.2.3.1" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.1.cmml">​</mo><mover accent="true" id="S3.SS2.SSS5.4.4.m4.1.1.2.3.3" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.cmml"><mi id="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.2" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.1" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.1.cmml">→</mo></mover></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.4.4.m4.1.1.1" xref="S3.SS2.SSS5.4.4.m4.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS5.4.4.m4.1.1.3" xref="S3.SS2.SSS5.4.4.m4.1.1.3.cmml"><mover accent="true" id="S3.SS2.SSS5.4.4.m4.1.1.3.2" xref="S3.SS2.SSS5.4.4.m4.1.1.3.2.cmml"><mi id="S3.SS2.SSS5.4.4.m4.1.1.3.2.2" xref="S3.SS2.SSS5.4.4.m4.1.1.3.2.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.4.4.m4.1.1.3.2.1" xref="S3.SS2.SSS5.4.4.m4.1.1.3.2.1.cmml">→</mo></mover><mrow id="S3.SS2.SSS5.4.4.m4.1.1.3.3" xref="S3.SS2.SSS5.4.4.m4.1.1.3.3.cmml"><mi id="S3.SS2.SSS5.4.4.m4.1.1.3.3.2" xref="S3.SS2.SSS5.4.4.m4.1.1.3.3.2.cmml">t</mi><mo id="S3.SS2.SSS5.4.4.m4.1.1.3.3.1" xref="S3.SS2.SSS5.4.4.m4.1.1.3.3.1.cmml">−</mo><mn id="S3.SS2.SSS5.4.4.m4.1.1.3.3.3" xref="S3.SS2.SSS5.4.4.m4.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.4.4.m4.1b"><apply id="S3.SS2.SSS5.4.4.m4.1.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1"><times id="S3.SS2.SSS5.4.4.m4.1.1.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.1"></times><apply id="S3.SS2.SSS5.4.4.m4.1.1.2.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS5.4.4.m4.1.1.2.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS5.4.4.m4.1.1.2.2.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.2">𝑊</ci><apply id="S3.SS2.SSS5.4.4.m4.1.1.2.3.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3"><times id="S3.SS2.SSS5.4.4.m4.1.1.2.3.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.1"></times><apply id="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.2"><ci id="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.1">→</ci><ci id="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.2.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.2.2">ℎ</ci></apply><apply id="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.3"><ci id="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.1">→</ci><ci id="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.2.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.2.3.3.2">ℎ</ci></apply></apply></apply><apply id="S3.SS2.SSS5.4.4.m4.1.1.3.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS5.4.4.m4.1.1.3.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3">subscript</csymbol><apply id="S3.SS2.SSS5.4.4.m4.1.1.3.2.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3.2"><ci id="S3.SS2.SSS5.4.4.m4.1.1.3.2.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3.2.1">→</ci><ci id="S3.SS2.SSS5.4.4.m4.1.1.3.2.2.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3.2.2">ℎ</ci></apply><apply id="S3.SS2.SSS5.4.4.m4.1.1.3.3.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3.3"><minus id="S3.SS2.SSS5.4.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3.3.1"></minus><ci id="S3.SS2.SSS5.4.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS5.4.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.SSS5.4.4.m4.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.4.4.m4.1c">W_{\overrightarrow{h}\overrightarrow{h}}\overrightarrow{h}_{t-1}</annotation></semantics></math> <math id="S3.SS2.SSS5.5.5.m5.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S3.SS2.SSS5.5.5.m5.1a"><mo id="S3.SS2.SSS5.5.5.m5.1.1" xref="S3.SS2.SSS5.5.5.m5.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.5.5.m5.1b"><plus id="S3.SS2.SSS5.5.5.m5.1.1.cmml" xref="S3.SS2.SSS5.5.5.m5.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.5.5.m5.1c">+</annotation></semantics></math> <math id="S3.SS2.SSS5.6.6.m6.1" class="ltx_math_unparsed" alttext="b_{\overrightarrow{h}})" display="inline"><semantics id="S3.SS2.SSS5.6.6.m6.1a"><mrow id="S3.SS2.SSS5.6.6.m6.1b"><msub id="S3.SS2.SSS5.6.6.m6.1.1"><mi id="S3.SS2.SSS5.6.6.m6.1.1.2">b</mi><mover accent="true" id="S3.SS2.SSS5.6.6.m6.1.1.3"><mi id="S3.SS2.SSS5.6.6.m6.1.1.3.2">h</mi><mo stretchy="false" id="S3.SS2.SSS5.6.6.m6.1.1.3.1">→</mo></mover></msub><mo stretchy="false" id="S3.SS2.SSS5.6.6.m6.1.2">)</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS5.6.6.m6.1c">b_{\overrightarrow{h}})</annotation></semantics></math></p>
<p id="S3.SS2.SSS5.12.12" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS5.7.7.m1.1" class="ltx_Math" alttext="{\overleftarrow{h}}_{t}" display="inline"><semantics id="S3.SS2.SSS5.7.7.m1.1a"><msub id="S3.SS2.SSS5.7.7.m1.1.1" xref="S3.SS2.SSS5.7.7.m1.1.1.cmml"><mover accent="true" id="S3.SS2.SSS5.7.7.m1.1.1.2" xref="S3.SS2.SSS5.7.7.m1.1.1.2.cmml"><mi id="S3.SS2.SSS5.7.7.m1.1.1.2.2" xref="S3.SS2.SSS5.7.7.m1.1.1.2.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.7.7.m1.1.1.2.1" xref="S3.SS2.SSS5.7.7.m1.1.1.2.1.cmml">←</mo></mover><mi id="S3.SS2.SSS5.7.7.m1.1.1.3" xref="S3.SS2.SSS5.7.7.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.7.7.m1.1b"><apply id="S3.SS2.SSS5.7.7.m1.1.1.cmml" xref="S3.SS2.SSS5.7.7.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS5.7.7.m1.1.1.1.cmml" xref="S3.SS2.SSS5.7.7.m1.1.1">subscript</csymbol><apply id="S3.SS2.SSS5.7.7.m1.1.1.2.cmml" xref="S3.SS2.SSS5.7.7.m1.1.1.2"><ci id="S3.SS2.SSS5.7.7.m1.1.1.2.1.cmml" xref="S3.SS2.SSS5.7.7.m1.1.1.2.1">←</ci><ci id="S3.SS2.SSS5.7.7.m1.1.1.2.2.cmml" xref="S3.SS2.SSS5.7.7.m1.1.1.2.2">ℎ</ci></apply><ci id="S3.SS2.SSS5.7.7.m1.1.1.3.cmml" xref="S3.SS2.SSS5.7.7.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.7.7.m1.1c">{\overleftarrow{h}}_{t}</annotation></semantics></math> = <math id="S3.SS2.SSS5.8.8.m2.1" class="ltx_math_unparsed" alttext="\mathcal{H}(W_{x\overleftarrow{h}}x_{t}" display="inline"><semantics id="S3.SS2.SSS5.8.8.m2.1a"><mrow id="S3.SS2.SSS5.8.8.m2.1b"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS5.8.8.m2.1.1">ℋ</mi><mrow id="S3.SS2.SSS5.8.8.m2.1.2"><mo stretchy="false" id="S3.SS2.SSS5.8.8.m2.1.2.1">(</mo><msub id="S3.SS2.SSS5.8.8.m2.1.2.2"><mi id="S3.SS2.SSS5.8.8.m2.1.2.2.2">W</mi><mrow id="S3.SS2.SSS5.8.8.m2.1.2.2.3"><mi id="S3.SS2.SSS5.8.8.m2.1.2.2.3.2">x</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.8.8.m2.1.2.2.3.1">​</mo><mover accent="true" id="S3.SS2.SSS5.8.8.m2.1.2.2.3.3"><mi id="S3.SS2.SSS5.8.8.m2.1.2.2.3.3.2">h</mi><mo stretchy="false" id="S3.SS2.SSS5.8.8.m2.1.2.2.3.3.1">←</mo></mover></mrow></msub><msub id="S3.SS2.SSS5.8.8.m2.1.2.3"><mi id="S3.SS2.SSS5.8.8.m2.1.2.3.2">x</mi><mi id="S3.SS2.SSS5.8.8.m2.1.2.3.3">t</mi></msub></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS5.8.8.m2.1c">\mathcal{H}(W_{x\overleftarrow{h}}x_{t}</annotation></semantics></math> <math id="S3.SS2.SSS5.9.9.m3.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S3.SS2.SSS5.9.9.m3.1a"><mo id="S3.SS2.SSS5.9.9.m3.1.1" xref="S3.SS2.SSS5.9.9.m3.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.9.9.m3.1b"><plus id="S3.SS2.SSS5.9.9.m3.1.1.cmml" xref="S3.SS2.SSS5.9.9.m3.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.9.9.m3.1c">+</annotation></semantics></math> <math id="S3.SS2.SSS5.10.10.m4.1" class="ltx_Math" alttext="W_{\overleftarrow{h}\overleftarrow{h}}\overleftarrow{h}_{t+1}" display="inline"><semantics id="S3.SS2.SSS5.10.10.m4.1a"><mrow id="S3.SS2.SSS5.10.10.m4.1.1" xref="S3.SS2.SSS5.10.10.m4.1.1.cmml"><msub id="S3.SS2.SSS5.10.10.m4.1.1.2" xref="S3.SS2.SSS5.10.10.m4.1.1.2.cmml"><mi id="S3.SS2.SSS5.10.10.m4.1.1.2.2" xref="S3.SS2.SSS5.10.10.m4.1.1.2.2.cmml">W</mi><mrow id="S3.SS2.SSS5.10.10.m4.1.1.2.3" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.cmml"><mover accent="true" id="S3.SS2.SSS5.10.10.m4.1.1.2.3.2" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.cmml"><mi id="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.2" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.1" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.1.cmml">←</mo></mover><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.10.10.m4.1.1.2.3.1" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.1.cmml">​</mo><mover accent="true" id="S3.SS2.SSS5.10.10.m4.1.1.2.3.3" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.cmml"><mi id="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.2" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.1" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.1.cmml">←</mo></mover></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.10.10.m4.1.1.1" xref="S3.SS2.SSS5.10.10.m4.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS5.10.10.m4.1.1.3" xref="S3.SS2.SSS5.10.10.m4.1.1.3.cmml"><mover accent="true" id="S3.SS2.SSS5.10.10.m4.1.1.3.2" xref="S3.SS2.SSS5.10.10.m4.1.1.3.2.cmml"><mi id="S3.SS2.SSS5.10.10.m4.1.1.3.2.2" xref="S3.SS2.SSS5.10.10.m4.1.1.3.2.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.10.10.m4.1.1.3.2.1" xref="S3.SS2.SSS5.10.10.m4.1.1.3.2.1.cmml">←</mo></mover><mrow id="S3.SS2.SSS5.10.10.m4.1.1.3.3" xref="S3.SS2.SSS5.10.10.m4.1.1.3.3.cmml"><mi id="S3.SS2.SSS5.10.10.m4.1.1.3.3.2" xref="S3.SS2.SSS5.10.10.m4.1.1.3.3.2.cmml">t</mi><mo id="S3.SS2.SSS5.10.10.m4.1.1.3.3.1" xref="S3.SS2.SSS5.10.10.m4.1.1.3.3.1.cmml">+</mo><mn id="S3.SS2.SSS5.10.10.m4.1.1.3.3.3" xref="S3.SS2.SSS5.10.10.m4.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.10.10.m4.1b"><apply id="S3.SS2.SSS5.10.10.m4.1.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1"><times id="S3.SS2.SSS5.10.10.m4.1.1.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.1"></times><apply id="S3.SS2.SSS5.10.10.m4.1.1.2.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS5.10.10.m4.1.1.2.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS5.10.10.m4.1.1.2.2.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.2">𝑊</ci><apply id="S3.SS2.SSS5.10.10.m4.1.1.2.3.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3"><times id="S3.SS2.SSS5.10.10.m4.1.1.2.3.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.1"></times><apply id="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.2"><ci id="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.1">←</ci><ci id="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.2.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.2.2">ℎ</ci></apply><apply id="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.3"><ci id="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.1">←</ci><ci id="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.2.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.2.3.3.2">ℎ</ci></apply></apply></apply><apply id="S3.SS2.SSS5.10.10.m4.1.1.3.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS5.10.10.m4.1.1.3.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3">subscript</csymbol><apply id="S3.SS2.SSS5.10.10.m4.1.1.3.2.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3.2"><ci id="S3.SS2.SSS5.10.10.m4.1.1.3.2.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3.2.1">←</ci><ci id="S3.SS2.SSS5.10.10.m4.1.1.3.2.2.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3.2.2">ℎ</ci></apply><apply id="S3.SS2.SSS5.10.10.m4.1.1.3.3.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3.3"><plus id="S3.SS2.SSS5.10.10.m4.1.1.3.3.1.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3.3.1"></plus><ci id="S3.SS2.SSS5.10.10.m4.1.1.3.3.2.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS5.10.10.m4.1.1.3.3.3.cmml" xref="S3.SS2.SSS5.10.10.m4.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.10.10.m4.1c">W_{\overleftarrow{h}\overleftarrow{h}}\overleftarrow{h}_{t+1}</annotation></semantics></math> <math id="S3.SS2.SSS5.11.11.m5.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S3.SS2.SSS5.11.11.m5.1a"><mo id="S3.SS2.SSS5.11.11.m5.1.1" xref="S3.SS2.SSS5.11.11.m5.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.11.11.m5.1b"><plus id="S3.SS2.SSS5.11.11.m5.1.1.cmml" xref="S3.SS2.SSS5.11.11.m5.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.11.11.m5.1c">+</annotation></semantics></math> <math id="S3.SS2.SSS5.12.12.m6.1" class="ltx_math_unparsed" alttext="b_{\overleftarrow{h}})" display="inline"><semantics id="S3.SS2.SSS5.12.12.m6.1a"><mrow id="S3.SS2.SSS5.12.12.m6.1b"><msub id="S3.SS2.SSS5.12.12.m6.1.1"><mi id="S3.SS2.SSS5.12.12.m6.1.1.2">b</mi><mover accent="true" id="S3.SS2.SSS5.12.12.m6.1.1.3"><mi id="S3.SS2.SSS5.12.12.m6.1.1.3.2">h</mi><mo stretchy="false" id="S3.SS2.SSS5.12.12.m6.1.1.3.1">←</mo></mover></msub><mo stretchy="false" id="S3.SS2.SSS5.12.12.m6.1.2">)</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS5.12.12.m6.1c">b_{\overleftarrow{h}})</annotation></semantics></math></p>
<p id="S3.SS2.SSS5.18.18" class="ltx_p ltx_align_center"><math id="S3.SS2.SSS5.13.13.m1.1" class="ltx_Math" alttext="{y}_{t}" display="inline"><semantics id="S3.SS2.SSS5.13.13.m1.1a"><msub id="S3.SS2.SSS5.13.13.m1.1.1" xref="S3.SS2.SSS5.13.13.m1.1.1.cmml"><mi id="S3.SS2.SSS5.13.13.m1.1.1.2" xref="S3.SS2.SSS5.13.13.m1.1.1.2.cmml">y</mi><mi id="S3.SS2.SSS5.13.13.m1.1.1.3" xref="S3.SS2.SSS5.13.13.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.13.13.m1.1b"><apply id="S3.SS2.SSS5.13.13.m1.1.1.cmml" xref="S3.SS2.SSS5.13.13.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS5.13.13.m1.1.1.1.cmml" xref="S3.SS2.SSS5.13.13.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS5.13.13.m1.1.1.2.cmml" xref="S3.SS2.SSS5.13.13.m1.1.1.2">𝑦</ci><ci id="S3.SS2.SSS5.13.13.m1.1.1.3.cmml" xref="S3.SS2.SSS5.13.13.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.13.13.m1.1c">{y}_{t}</annotation></semantics></math> = <math id="S3.SS2.SSS5.14.14.m2.1" class="ltx_math_unparsed" alttext="(W_{\overrightarrow{h}y}\overrightarrow{h}_{t}" display="inline"><semantics id="S3.SS2.SSS5.14.14.m2.1a"><mrow id="S3.SS2.SSS5.14.14.m2.1b"><mo stretchy="false" id="S3.SS2.SSS5.14.14.m2.1.1">(</mo><msub id="S3.SS2.SSS5.14.14.m2.1.2"><mi id="S3.SS2.SSS5.14.14.m2.1.2.2">W</mi><mrow id="S3.SS2.SSS5.14.14.m2.1.2.3"><mover accent="true" id="S3.SS2.SSS5.14.14.m2.1.2.3.2"><mi id="S3.SS2.SSS5.14.14.m2.1.2.3.2.2">h</mi><mo stretchy="false" id="S3.SS2.SSS5.14.14.m2.1.2.3.2.1">→</mo></mover><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.14.14.m2.1.2.3.1">​</mo><mi id="S3.SS2.SSS5.14.14.m2.1.2.3.3">y</mi></mrow></msub><msub id="S3.SS2.SSS5.14.14.m2.1.3"><mover accent="true" id="S3.SS2.SSS5.14.14.m2.1.3.2"><mi id="S3.SS2.SSS5.14.14.m2.1.3.2.2">h</mi><mo stretchy="false" id="S3.SS2.SSS5.14.14.m2.1.3.2.1">→</mo></mover><mi id="S3.SS2.SSS5.14.14.m2.1.3.3">t</mi></msub></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS5.14.14.m2.1c">(W_{\overrightarrow{h}y}\overrightarrow{h}_{t}</annotation></semantics></math> <math id="S3.SS2.SSS5.15.15.m3.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S3.SS2.SSS5.15.15.m3.1a"><mo id="S3.SS2.SSS5.15.15.m3.1.1" xref="S3.SS2.SSS5.15.15.m3.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.15.15.m3.1b"><plus id="S3.SS2.SSS5.15.15.m3.1.1.cmml" xref="S3.SS2.SSS5.15.15.m3.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.15.15.m3.1c">+</annotation></semantics></math> <math id="S3.SS2.SSS5.16.16.m4.1" class="ltx_Math" alttext="W_{\overleftarrow{h}y}\overleftarrow{h}_{t}" display="inline"><semantics id="S3.SS2.SSS5.16.16.m4.1a"><mrow id="S3.SS2.SSS5.16.16.m4.1.1" xref="S3.SS2.SSS5.16.16.m4.1.1.cmml"><msub id="S3.SS2.SSS5.16.16.m4.1.1.2" xref="S3.SS2.SSS5.16.16.m4.1.1.2.cmml"><mi id="S3.SS2.SSS5.16.16.m4.1.1.2.2" xref="S3.SS2.SSS5.16.16.m4.1.1.2.2.cmml">W</mi><mrow id="S3.SS2.SSS5.16.16.m4.1.1.2.3" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.cmml"><mover accent="true" id="S3.SS2.SSS5.16.16.m4.1.1.2.3.2" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.cmml"><mi id="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.2" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.1" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.1.cmml">←</mo></mover><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.16.16.m4.1.1.2.3.1" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.SSS5.16.16.m4.1.1.2.3.3" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.3.cmml">y</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS5.16.16.m4.1.1.1" xref="S3.SS2.SSS5.16.16.m4.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS5.16.16.m4.1.1.3" xref="S3.SS2.SSS5.16.16.m4.1.1.3.cmml"><mover accent="true" id="S3.SS2.SSS5.16.16.m4.1.1.3.2" xref="S3.SS2.SSS5.16.16.m4.1.1.3.2.cmml"><mi id="S3.SS2.SSS5.16.16.m4.1.1.3.2.2" xref="S3.SS2.SSS5.16.16.m4.1.1.3.2.2.cmml">h</mi><mo stretchy="false" id="S3.SS2.SSS5.16.16.m4.1.1.3.2.1" xref="S3.SS2.SSS5.16.16.m4.1.1.3.2.1.cmml">←</mo></mover><mi id="S3.SS2.SSS5.16.16.m4.1.1.3.3" xref="S3.SS2.SSS5.16.16.m4.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.16.16.m4.1b"><apply id="S3.SS2.SSS5.16.16.m4.1.1.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1"><times id="S3.SS2.SSS5.16.16.m4.1.1.1.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.1"></times><apply id="S3.SS2.SSS5.16.16.m4.1.1.2.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS5.16.16.m4.1.1.2.1.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS5.16.16.m4.1.1.2.2.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2.2">𝑊</ci><apply id="S3.SS2.SSS5.16.16.m4.1.1.2.3.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3"><times id="S3.SS2.SSS5.16.16.m4.1.1.2.3.1.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.1"></times><apply id="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.2"><ci id="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.1.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.1">←</ci><ci id="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.2.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.2.2">ℎ</ci></apply><ci id="S3.SS2.SSS5.16.16.m4.1.1.2.3.3.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.2.3.3">𝑦</ci></apply></apply><apply id="S3.SS2.SSS5.16.16.m4.1.1.3.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS5.16.16.m4.1.1.3.1.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.3">subscript</csymbol><apply id="S3.SS2.SSS5.16.16.m4.1.1.3.2.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.3.2"><ci id="S3.SS2.SSS5.16.16.m4.1.1.3.2.1.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.3.2.1">←</ci><ci id="S3.SS2.SSS5.16.16.m4.1.1.3.2.2.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.3.2.2">ℎ</ci></apply><ci id="S3.SS2.SSS5.16.16.m4.1.1.3.3.cmml" xref="S3.SS2.SSS5.16.16.m4.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.16.16.m4.1c">W_{\overleftarrow{h}y}\overleftarrow{h}_{t}</annotation></semantics></math> <math id="S3.SS2.SSS5.17.17.m5.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S3.SS2.SSS5.17.17.m5.1a"><mo id="S3.SS2.SSS5.17.17.m5.1.1" xref="S3.SS2.SSS5.17.17.m5.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS5.17.17.m5.1b"><plus id="S3.SS2.SSS5.17.17.m5.1.1.cmml" xref="S3.SS2.SSS5.17.17.m5.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS5.17.17.m5.1c">+</annotation></semantics></math> <math id="S3.SS2.SSS5.18.18.m6.1" class="ltx_math_unparsed" alttext="b_{\overleftarrow{h}})" display="inline"><semantics id="S3.SS2.SSS5.18.18.m6.1a"><mrow id="S3.SS2.SSS5.18.18.m6.1b"><msub id="S3.SS2.SSS5.18.18.m6.1.1"><mi id="S3.SS2.SSS5.18.18.m6.1.1.2">b</mi><mover accent="true" id="S3.SS2.SSS5.18.18.m6.1.1.3"><mi id="S3.SS2.SSS5.18.18.m6.1.1.3.2">h</mi><mo stretchy="false" id="S3.SS2.SSS5.18.18.m6.1.1.3.1">←</mo></mover></msub><mo stretchy="false" id="S3.SS2.SSS5.18.18.m6.1.2">)</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS5.18.18.m6.1c">b_{\overleftarrow{h}})</annotation></semantics></math></p>
</div>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2404.08011/assets/BLSTMarchitecture.jpg" id="S3.F6.g1" class="ltx_graphics ltx_img_landscape" width="598" height="281" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>BLSTM architecture</figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results of CNN and RNN</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Results of CNN in Handwriting Recognition</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">With rapid development of computation techniques, the GPU-accelerated computing techniques have been exploited to train CNNs more efficiently. Nowadays, CNNs have already been successfully applied to handwriting recognition, face detection, behaviour recognition, speech recognition, recommender systems, image classification, and NLP. In deep learning, although CNN classification technique of neural systems is mostly used in image classification or image data, but it has attained good results for handwriting recognition too. The table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab1_HWR_results</span> presents the selected handwriting recognition results using CNN.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results of CNN in Handwriting Recognition</figcaption>
<table id="S4.T1.1" class="ltx_tabular">
<tr id="S4.T1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.1" class="ltx_p" style="width:52.0pt;"><span id="S4.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Script</span></span>
</span>
</td>
<td id="S4.T1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.1.1" class="ltx_p" style="width:65.0pt;"><span id="S4.T1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</td>
<td id="S4.T1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Methodology</span></span>
</span>
</td>
<td id="S4.T1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.1.1" class="ltx_p" style="width:86.7pt;"><span id="S4.T1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</td>
<td id="S4.T1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.1.1" class="ltx_p" style="width:52.0pt;"><span id="S4.T1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Accuracy</span></span>
</span>
</td>
</tr>
<tr id="S4.T1.1.2" class="ltx_tr">
<td id="S4.T1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.2.1.1.1" class="ltx_p" style="width:52.0pt;">Kannada digits</span>
</span>
</td>
<td id="S4.T1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.2.2.1.1" class="ltx_p" style="width:65.0pt;">Gu <cite class="ltx_cite ltx_citemacro_cite">Gu (<a href="#bib.bib64" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.2.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based architecture</span>
</span>
</td>
<td id="S4.T1.1.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.2.4.1.1" class="ltx_p" style="width:86.7pt;">Kannada-MNIST (test set)</span>
</span>
</td>
<td id="S4.T1.1.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.1.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.2.5.1.1" class="ltx_p" style="width:52.0pt;">98.77%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.3" class="ltx_tr">
<td id="S4.T1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.3.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.3.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.3.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.3.4.1.1" class="ltx_p" style="width:86.7pt;">MNIST</span>
</span>
</td>
<td id="S4.T1.1.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.3.5.1.1" class="ltx_p" style="width:52.0pt;">99.68%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.4" class="ltx_tr">
<td id="S4.T1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.4.1.1.1" class="ltx_p" style="width:52.0pt;">Devanagari digits</span>
</span>
</td>
<td id="S4.T1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.4.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.4.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.4.4.1.1" class="ltx_p" style="width:86.7pt;">CMATERdb 3.2.1</span>
</span>
</td>
<td id="S4.T1.1.4.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.4.5.1.1" class="ltx_p" style="width:52.0pt;">97.56%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.5" class="ltx_tr">
<td id="S4.T1.1.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.5.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla digits</span>
</span>
</td>
<td id="S4.T1.1.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.5.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.5.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.5.4.1.1" class="ltx_p" style="width:86.7pt;">CMATERdb 3.1.1</span>
</span>
</td>
<td id="S4.T1.1.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.5.5.1.1" class="ltx_p" style="width:52.0pt;">96.35$</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.6" class="ltx_tr">
<td id="S4.T1.1.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.6.1.1.1" class="ltx_p" style="width:52.0pt;">Telugu digits</span>
</span>
</td>
<td id="S4.T1.1.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.6.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.6.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.6.4.1.1" class="ltx_p" style="width:86.7pt;">CMATERdb 3.4.1</span>
</span>
</td>
<td id="S4.T1.1.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.6.5.1.1" class="ltx_p" style="width:52.0pt;">98.82%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.7" class="ltx_tr">
<td id="S4.T1.1.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.7.1.1.1" class="ltx_p" style="width:52.0pt;">Arabic digits</span>
</span>
</td>
<td id="S4.T1.1.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.7.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.7.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.7.4.1.1" class="ltx_p" style="width:86.7pt;">CMATERdb 3.3.1</span>
</span>
</td>
<td id="S4.T1.1.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.7.5.1.1" class="ltx_p" style="width:52.0pt;">96.53%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.8" class="ltx_tr">
<td id="S4.T1.1.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.8.1.1.1" class="ltx_p" style="width:52.0pt;">Odia digits</span>
</span>
</td>
<td id="S4.T1.1.8.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.8.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.8.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.8.4.1.1" class="ltx_p" style="width:86.7pt;">ISI-Odia</span>
</span>
</td>
<td id="S4.T1.1.8.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.8.5.1.1" class="ltx_p" style="width:52.0pt;">97.76%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.9" class="ltx_tr">
<td id="S4.T1.1.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.9.1.1.1" class="ltx_p" style="width:52.0pt;">Devanagari digits</span>
</span>
</td>
<td id="S4.T1.1.9.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.9.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.9.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.9.4.1.1" class="ltx_p" style="width:86.7pt;">ISI-Devanagari</span>
</span>
</td>
<td id="S4.T1.1.9.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.9.5.1.1" class="ltx_p" style="width:52.0pt;">98.31%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.10" class="ltx_tr">
<td id="S4.T1.1.10.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.10.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla digits</span>
</span>
</td>
<td id="S4.T1.1.10.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.10.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.10.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.10.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.10.4.1.1" class="ltx_p" style="width:86.7pt;">ISI-Bangla</span>
</span>
</td>
<td id="S4.T1.1.10.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.10.5.1.1" class="ltx_p" style="width:52.0pt;">96.70%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.11" class="ltx_tr">
<td id="S4.T1.1.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.11.1.1.1" class="ltx_p" style="width:52.0pt;">Gujarati digits</span>
</span>
</td>
<td id="S4.T1.1.11.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.11.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.11.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.11.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.11.4.1.1" class="ltx_p" style="width:86.7pt;">Gujarati dataset</span>
</span>
</td>
<td id="S4.T1.1.11.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.11.5.1.1" class="ltx_p" style="width:52.0pt;">99.22%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.12" class="ltx_tr">
<td id="S4.T1.1.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.12.1.1.1" class="ltx_p" style="width:52.0pt;">Punjabi digits</span>
</span>
</td>
<td id="S4.T1.1.12.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.12.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.12.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.12.3.1.1" class="ltx_p" style="width:130.1pt;">CNN(2 layers)</span>
</span>
</td>
<td id="S4.T1.1.12.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.12.4.1.1" class="ltx_p" style="width:86.7pt;">Punjabi dataset</span>
</span>
</td>
<td id="S4.T1.1.12.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.12.5.1.1" class="ltx_p" style="width:52.0pt;">99.43%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.13" class="ltx_tr">
<td id="S4.T1.1.13.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.13.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.13.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.13.2.1.1" class="ltx_p" style="width:65.0pt;">Kusetogullari et al. <cite class="ltx_cite ltx_citemacro_cite">Kusetogullari et al. (<a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.13.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.13.3.1.1" class="ltx_p" style="width:130.1pt;">CNN</span>
</span>
</td>
<td id="S4.T1.1.13.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.13.4.1.1" class="ltx_p" style="width:86.7pt;">ARDIS</span>
</span>
</td>
<td id="S4.T1.1.13.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.13.5.1.1" class="ltx_p" style="width:52.0pt;">98.60%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.14" class="ltx_tr">
<td id="S4.T1.1.14.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.14.1.1.1" class="ltx_p" style="width:52.0pt;">Kannada digits</span>
</span>
</td>
<td id="S4.T1.1.14.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.14.2.1.1" class="ltx_p" style="width:65.0pt;">Gati et al. <cite class="ltx_cite ltx_citemacro_cite">GATI et al. (<a href="#bib.bib67" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.14.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.14.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based architecture with skip connections</span>
</span>
</td>
<td id="S4.T1.1.14.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.14.4.1.1" class="ltx_p" style="width:86.7pt;">Kannada-MNIST(Dig-MNIST)</span>
</span>
</td>
<td id="S4.T1.1.14.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.14.5.1.1" class="ltx_p" style="width:52.0pt;">85.02%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.15" class="ltx_tr">
<td id="S4.T1.1.15.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.15.1.1.1" class="ltx_p" style="width:52.0pt;">Gurmukhi strokes</span>
</span>
</td>
<td id="S4.T1.1.15.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.15.2.1.1" class="ltx_p" style="width:65.0pt;">Singh et al. <cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a href="#bib.bib68" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.15.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.15.3.1.1" class="ltx_p" style="width:130.1pt;">CNN, self controlled RDP based features</span>
</span>
</td>
<td id="S4.T1.1.15.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.15.4.1.1" class="ltx_p" style="width:86.7pt;">Gurmukhi</span>
</span>
</td>
<td id="S4.T1.1.15.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.15.5.1.1" class="ltx_p" style="width:52.0pt;">94.13%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.16" class="ltx_tr">
<td id="S4.T1.1.16.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.16.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.16.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.16.2.1.1" class="ltx_p" style="width:65.0pt;">Singh et al. <cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a href="#bib.bib68" title="" class="ltx_ref">2020</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.16.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.16.3.1.1" class="ltx_p" style="width:130.1pt;">CNN, self controlled RDP based features</span>
</span>
</td>
<td id="S4.T1.1.16.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.16.4.1.1" class="ltx_p" style="width:86.7pt;">UNIPEN</span>
</span>
</td>
<td id="S4.T1.1.16.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.16.5.1.1" class="ltx_p" style="width:52.0pt;">93.61%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.17" class="ltx_tr">
<td id="S4.T1.1.17.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.17.1.1.1" class="ltx_p" style="width:52.0pt;">Kannada digits</span>
</span>
</td>
<td id="S4.T1.1.17.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.17.2.1.1" class="ltx_p" style="width:65.0pt;">Prabhu <cite class="ltx_cite ltx_citemacro_cite">Prabhu (<a href="#bib.bib69" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.17.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.17.3.1.1" class="ltx_p" style="width:130.1pt;">End-to-end training using CNN based architecture</span>
</span>
</td>
<td id="S4.T1.1.17.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.17.4.1.1" class="ltx_p" style="width:86.7pt;">Kannada-MNIST (test set)</span>
</span>
</td>
<td id="S4.T1.1.17.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.17.5.1.1" class="ltx_p" style="width:52.0pt;">96.80%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.18" class="ltx_tr">
<td id="S4.T1.1.18.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.18.1.1.1" class="ltx_p" style="width:52.0pt;">Malayalam characters</span>
</span>
</td>
<td id="S4.T1.1.18.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.18.2.1.1" class="ltx_p" style="width:65.0pt;">Manjusha et al. <cite class="ltx_cite ltx_citemacro_cite">Manjusha et al. (<a href="#bib.bib70" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.18.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.18.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based on scattering transform-based wavelet filters as feature extractor and Linear SVM as classifier</span>
</span>
</td>
<td id="S4.T1.1.18.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.18.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.18.4.1.1" class="ltx_p" style="width:86.7pt;">Amrita_MalCharDb</span>
</span>
</td>
<td id="S4.T1.1.18.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.18.5.1.1" class="ltx_p" style="width:52.0pt;">91.05</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.19" class="ltx_tr">
<td id="S4.T1.1.19.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.19.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.19.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.19.2.1.1" class="ltx_p" style="width:65.0pt;">Chowdhury et al.<cite class="ltx_cite ltx_citemacro_cite">Chowdhury et al. (<a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.19.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.19.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based architecture</span>
</span>
</td>
<td id="S4.T1.1.19.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.19.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.19.4.1.1" class="ltx_p" style="width:86.7pt;">MNIST</span>
</span>
</td>
<td id="S4.T1.1.19.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.19.5.1.1" class="ltx_p" style="width:52.0pt;">99.25%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.20" class="ltx_tr">
<td id="S4.T1.1.20.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.20.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla characters</span>
</span>
</td>
<td id="S4.T1.1.20.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.20.2.1.1" class="ltx_p" style="width:65.0pt;">Chowdhury et al.<cite class="ltx_cite ltx_citemacro_cite">Chowdhury et al. (<a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.20.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.20.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based architecture</span>
</span>
</td>
<td id="S4.T1.1.20.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.20.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.20.4.1.1" class="ltx_p" style="width:86.7pt;">Banglalekha-isolated</span>
</span>
</td>
<td id="S4.T1.1.20.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.20.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.20.5.1.1" class="ltx_p" style="width:52.0pt;">91.81%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.21" class="ltx_tr">
<td id="S4.T1.1.21.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.21.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla characters</span>
</span>
</td>
<td id="S4.T1.1.21.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.21.2.1.1" class="ltx_p" style="width:65.0pt;">Chowdhury et al.<cite class="ltx_cite ltx_citemacro_cite">Chowdhury et al. (<a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.21.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.21.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based architecture</span>
</span>
</td>
<td id="S4.T1.1.21.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.21.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.21.4.1.1" class="ltx_p" style="width:86.7pt;">Ekush</span>
</span>
</td>
<td id="S4.T1.1.21.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.21.5.1.1" class="ltx_p" style="width:52.0pt;">95.07%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.22" class="ltx_tr">
<td id="S4.T1.1.22.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.22.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla characters</span>
</span>
</td>
<td id="S4.T1.1.22.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.22.2.1.1" class="ltx_p" style="width:65.0pt;">Chowdhury et al.<cite class="ltx_cite ltx_citemacro_cite">Chowdhury et al. (<a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.22.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.22.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based architecture</span>
</span>
</td>
<td id="S4.T1.1.22.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.22.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.22.4.1.1" class="ltx_p" style="width:86.7pt;">CMATERdb 3.1.2</span>
</span>
</td>
<td id="S4.T1.1.22.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.22.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.22.5.1.1" class="ltx_p" style="width:52.0pt;">93.37%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.23" class="ltx_tr">
<td id="S4.T1.1.23.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.23.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla numerals</span>
</span>
</td>
<td id="S4.T1.1.23.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.23.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta et al. <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib72" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.23.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.23.3.1.1" class="ltx_p" style="width:130.1pt;">Multi-objective optimisation to find the informative regions of character image + CNN features</span>
</span>
</td>
<td id="S4.T1.1.23.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.23.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.23.4.1.1" class="ltx_p" style="width:86.7pt;">Isolated handwritten Bangla numerals</span>
</span>
</td>
<td id="S4.T1.1.23.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.23.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.23.5.1.1" class="ltx_p" style="width:52.0pt;">96.54%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.24" class="ltx_tr">
<td id="S4.T1.1.24.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.24.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla characters</span>
</span>
</td>
<td id="S4.T1.1.24.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.24.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta et al. <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib72" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.24.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.24.3.1.1" class="ltx_p" style="width:130.1pt;">Multi-objective optimisation to find the informative regions of character image + CNN features</span>
</span>
</td>
<td id="S4.T1.1.24.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.24.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.24.4.1.1" class="ltx_p" style="width:86.7pt;">Isolated handwritten Bangla basic characters</span>
</span>
</td>
<td id="S4.T1.1.24.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.24.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.24.5.1.1" class="ltx_p" style="width:52.0pt;">85.19%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.25" class="ltx_tr">
<td id="S4.T1.1.25.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.25.1.1.1" class="ltx_p" style="width:52.0pt;">English numerals</span>
</span>
</td>
<td id="S4.T1.1.25.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.25.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta et al. <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib72" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.25.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.25.3.1.1" class="ltx_p" style="width:130.1pt;">Multi-objective optimisation to find the informative regions of character image + CNN features</span>
</span>
</td>
<td id="S4.T1.1.25.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.25.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.25.4.1.1" class="ltx_p" style="width:86.7pt;">Isolated handwritten English numerals</span>
</span>
</td>
<td id="S4.T1.1.25.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.25.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.25.5.1.1" class="ltx_p" style="width:52.0pt;">97.87%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.26" class="ltx_tr">
<td id="S4.T1.1.26.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.26.1.1.1" class="ltx_p" style="width:52.0pt;">Devanagari characters</span>
</span>
</td>
<td id="S4.T1.1.26.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.26.2.1.1" class="ltx_p" style="width:65.0pt;">Gupta et al. <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib72" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.26.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.26.3.1.1" class="ltx_p" style="width:130.1pt;">Multi-objective optimisation to find the informative regions of character image + CNN features</span>
</span>
</td>
<td id="S4.T1.1.26.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.26.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.26.4.1.1" class="ltx_p" style="width:86.7pt;">Isolated handwritten Devanagari characterss</span>
</span>
</td>
<td id="S4.T1.1.26.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.26.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.26.5.1.1" class="ltx_p" style="width:52.0pt;">87.23%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.27" class="ltx_tr">
<td id="S4.T1.1.27.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.27.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.27.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.27.2.1.1" class="ltx_p" style="width:65.0pt;">Chakraborty et al. <cite class="ltx_cite ltx_citemacro_cite">Chakraborty et al. (<a href="#bib.bib73" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.27.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.27.3.1.1" class="ltx_p" style="width:130.1pt;">feature map reduction in CNN</span>
</span>
</td>
<td id="S4.T1.1.27.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.27.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.27.4.1.1" class="ltx_p" style="width:86.7pt;">MNIST</span>
</span>
</td>
<td id="S4.T1.1.27.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.27.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.27.5.1.1" class="ltx_p" style="width:52.0pt;">99.19%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.28" class="ltx_tr">
<td id="S4.T1.1.28.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.28.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.28.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.28.2.1.1" class="ltx_p" style="width:65.0pt;">Arora and Bhatia <cite class="ltx_cite ltx_citemacro_cite">Arora and Bhatia (<a href="#bib.bib74" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.28.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.28.3.1.1" class="ltx_p" style="width:130.1pt;">CNN, Keras</span>
</span>
</td>
<td id="S4.T1.1.28.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.28.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.28.4.1.1" class="ltx_p" style="width:86.7pt;">MNIST</span>
</span>
</td>
<td id="S4.T1.1.28.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.28.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.28.5.1.1" class="ltx_p" style="width:52.0pt;">95.63%, 99.20%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.29" class="ltx_tr">
<td id="S4.T1.1.29.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.29.1.1.1" class="ltx_p" style="width:52.0pt;">Malayalam characters</span>
</span>
</td>
<td id="S4.T1.1.29.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.29.2.1.1" class="ltx_p" style="width:65.0pt;">Manjusha et al. <cite class="ltx_cite ltx_citemacro_cite">Manjusha et al. (<a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.29.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.29.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based on scattering transform-based wavelet filters (ScatCNN)</span>
</span>
</td>
<td id="S4.T1.1.29.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.29.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.29.4.1.1" class="ltx_p" style="width:86.7pt;">Malayalam_DB</span>
</span>
</td>
<td id="S4.T1.1.29.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.29.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.29.5.1.1" class="ltx_p" style="width:52.0pt;">93.77%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.30" class="ltx_tr">
<td id="S4.T1.1.30.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.30.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.30.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.30.2.1.1" class="ltx_p" style="width:65.0pt;">Manjusha et al. <cite class="ltx_cite ltx_citemacro_cite">Manjusha et al. (<a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.30.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.30.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.30.3.1.1" class="ltx_p" style="width:130.1pt;">ScatCNN</span>
</span>
</td>
<td id="S4.T1.1.30.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.30.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.30.4.1.1" class="ltx_p" style="width:86.7pt;">MNIST</span>
</span>
</td>
<td id="S4.T1.1.30.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.30.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.30.5.1.1" class="ltx_p" style="width:52.0pt;">99.31%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.31" class="ltx_tr">
<td id="S4.T1.1.31.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.31.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla numerals</span>
</span>
</td>
<td id="S4.T1.1.31.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.31.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.31.2.1.1" class="ltx_p" style="width:65.0pt;">Manjusha et al. <cite class="ltx_cite ltx_citemacro_cite">Manjusha et al. (<a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.31.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.31.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.31.3.1.1" class="ltx_p" style="width:130.1pt;">ScatCNN</span>
</span>
</td>
<td id="S4.T1.1.31.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.31.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.31.4.1.1" class="ltx_p" style="width:86.7pt;">ISI</span>
</span>
</td>
<td id="S4.T1.1.31.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.31.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.31.5.1.1" class="ltx_p" style="width:52.0pt;">99.22%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.32" class="ltx_tr">
<td id="S4.T1.1.32.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.32.1.1.1" class="ltx_p" style="width:52.0pt;">Chinese characters</span>
</span>
</td>
<td id="S4.T1.1.32.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.32.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.32.2.1.1" class="ltx_p" style="width:65.0pt;">Manjusha et al. <cite class="ltx_cite ltx_citemacro_cite">Manjusha et al. (<a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.32.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.32.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.32.3.1.1" class="ltx_p" style="width:130.1pt;">ScatCNN</span>
</span>
</td>
<td id="S4.T1.1.32.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.32.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.32.4.1.1" class="ltx_p" style="width:86.7pt;">CASIA HWDB1.1</span>
</span>
</td>
<td id="S4.T1.1.32.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.32.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.32.5.1.1" class="ltx_p" style="width:52.0pt;">92.09%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.33" class="ltx_tr">
<td id="S4.T1.1.33.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.33.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.33.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T1.1.33.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.33.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.33.2.1.1" class="ltx_p" style="width:65.0pt;">Kang et al. <cite class="ltx_cite ltx_citemacro_cite">Kang et al. (<a href="#bib.bib76" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.33.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.33.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.33.3.1.1" class="ltx_p" style="width:130.1pt;">Attention based sequence to sequence model</span>
</span>
</td>
<td id="S4.T1.1.33.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.33.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.33.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T1.1.33.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.33.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.33.5.1.1" class="ltx_p" style="width:52.0pt;">82.55%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.34" class="ltx_tr">
<td id="S4.T1.1.34.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.34.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.34.1.1.1" class="ltx_p" style="width:52.0pt;">English characters</span>
</span>
</td>
<td id="S4.T1.1.34.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.34.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.34.2.1.1" class="ltx_p" style="width:65.0pt;">Kang et al. <cite class="ltx_cite ltx_citemacro_cite">Kang et al. (<a href="#bib.bib76" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.34.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.34.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.34.3.1.1" class="ltx_p" style="width:130.1pt;">Attention based sequence to sequence model</span>
</span>
</td>
<td id="S4.T1.1.34.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.34.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.34.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T1.1.34.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.34.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.34.5.1.1" class="ltx_p" style="width:52.0pt;">93.12%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.35" class="ltx_tr">
<td id="S4.T1.1.35.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.35.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.35.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.35.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.35.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.35.2.1.1" class="ltx_p" style="width:65.0pt;">Sarkhel et al. <cite class="ltx_cite ltx_citemacro_cite">Sarkhel et al. (<a href="#bib.bib77" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.35.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.35.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.35.3.1.1" class="ltx_p" style="width:130.1pt;">A multi-column multi-scale CNN architecture + SVM</span>
</span>
</td>
<td id="S4.T1.1.35.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.35.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.35.4.1.1" class="ltx_p" style="width:86.7pt;">CMATERdb 3.4.1</span>
</span>
</td>
<td id="S4.T1.1.35.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.35.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.35.5.1.1" class="ltx_p" style="width:52.0pt;">99.50%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.36" class="ltx_tr">
<td id="S4.T1.1.36.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.36.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.36.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.36.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.36.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.36.2.1.1" class="ltx_p" style="width:65.0pt;">Sarkhel et al. <cite class="ltx_cite ltx_citemacro_cite">Sarkhel et al. (<a href="#bib.bib77" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.36.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.36.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.36.3.1.1" class="ltx_p" style="width:130.1pt;">A multi-column multi-scale CNN architecture + SVM</span>
</span>
</td>
<td id="S4.T1.1.36.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.36.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.36.4.1.1" class="ltx_p" style="width:86.7pt;">MNIST</span>
</span>
</td>
<td id="S4.T1.1.36.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.36.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.36.5.1.1" class="ltx_p" style="width:52.0pt;">99.74%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.37" class="ltx_tr">
<td id="S4.T1.1.37.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.37.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.37.1.1.1" class="ltx_p" style="width:52.0pt;">English(mostly) words</span>
</span>
</td>
<td id="S4.T1.1.37.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.37.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.37.2.1.1" class="ltx_p" style="width:65.0pt;">Poznanski and Wolf <cite class="ltx_cite ltx_citemacro_cite">Poznanski and Wolf (<a href="#bib.bib78" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.37.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.37.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.37.3.1.1" class="ltx_p" style="width:130.1pt;">CNN-N-Gram</span>
</span>
</td>
<td id="S4.T1.1.37.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.37.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.37.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T1.1.37.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.37.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.37.5.1.1" class="ltx_p" style="width:52.0pt;">93.55%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.38" class="ltx_tr">
<td id="S4.T1.1.38.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.38.1.1.1" class="ltx_p" style="width:52.0pt;">English(mostly) characters</span>
</span>
</td>
<td id="S4.T1.1.38.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.38.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.38.2.1.1" class="ltx_p" style="width:65.0pt;">Poznanski and Wolf <cite class="ltx_cite ltx_citemacro_cite">Poznanski and Wolf (<a href="#bib.bib78" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.38.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.38.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.38.3.1.1" class="ltx_p" style="width:130.1pt;">CNN-N-Gram</span>
</span>
</td>
<td id="S4.T1.1.38.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.38.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.38.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T1.1.38.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.38.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.38.5.1.1" class="ltx_p" style="width:52.0pt;">96.66%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.39" class="ltx_tr">
<td id="S4.T1.1.39.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.39.1.1.1" class="ltx_p" style="width:52.0pt;">French words</span>
</span>
</td>
<td id="S4.T1.1.39.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.39.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.39.2.1.1" class="ltx_p" style="width:65.0pt;">Poznanski and Wolf <cite class="ltx_cite ltx_citemacro_cite">Poznanski and Wolf (<a href="#bib.bib78" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.39.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.39.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.39.3.1.1" class="ltx_p" style="width:130.1pt;">CNN-N-Gram</span>
</span>
</td>
<td id="S4.T1.1.39.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.39.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.39.4.1.1" class="ltx_p" style="width:86.7pt;">RIMES</span>
</span>
</td>
<td id="S4.T1.1.39.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.39.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.39.5.1.1" class="ltx_p" style="width:52.0pt;">93.10%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.40" class="ltx_tr">
<td id="S4.T1.1.40.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.40.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.40.1.1.1" class="ltx_p" style="width:52.0pt;">French characters</span>
</span>
</td>
<td id="S4.T1.1.40.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.40.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.40.2.1.1" class="ltx_p" style="width:65.0pt;">Poznanski and Wolf <cite class="ltx_cite ltx_citemacro_cite">Poznanski and Wolf (<a href="#bib.bib78" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.40.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.40.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.40.3.1.1" class="ltx_p" style="width:130.1pt;">CNN-N-Gram</span>
</span>
</td>
<td id="S4.T1.1.40.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.40.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.40.4.1.1" class="ltx_p" style="width:86.7pt;">RIMES</span>
</span>
</td>
<td id="S4.T1.1.40.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.40.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.40.5.1.1" class="ltx_p" style="width:52.0pt;">98.10%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.41" class="ltx_tr">
<td id="S4.T1.1.41.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.41.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.41.1.1.1" class="ltx_p" style="width:52.0pt;">Hangual</span>
</span>
</td>
<td id="S4.T1.1.41.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.41.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.41.2.1.1" class="ltx_p" style="width:65.0pt;">Kim and Xie <cite class="ltx_cite ltx_citemacro_cite">Kim and Xie (<a href="#bib.bib79" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.41.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.41.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.41.3.1.1" class="ltx_p" style="width:130.1pt;">Deep convolutional neural netwok (DCNN)</span>
</span>
</td>
<td id="S4.T1.1.41.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.41.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.41.4.1.1" class="ltx_p" style="width:86.7pt;">SERI95a and PE92</span>
</span>
</td>
<td id="S4.T1.1.41.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.41.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.41.5.1.1" class="ltx_p" style="width:52.0pt;">95.96%, 92.92%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.42" class="ltx_tr">
<td id="S4.T1.1.42.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.42.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.42.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.42.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.42.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.42.2.1.1" class="ltx_p" style="width:65.0pt;">Wan et al. <cite class="ltx_cite ltx_citemacro_cite">Wan et al. (<a href="#bib.bib80" title="" class="ltx_ref">2013</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.42.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.42.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.42.3.1.1" class="ltx_p" style="width:130.1pt;">CNN based architecture with DropConnect layer</span>
</span>
</td>
<td id="S4.T1.1.42.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.42.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.42.4.1.1" class="ltx_p" style="width:86.7pt;">MNIST</span>
</span>
</td>
<td id="S4.T1.1.42.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.1.42.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.42.5.1.1" class="ltx_p" style="width:52.0pt;">99.79%</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.43" class="ltx_tr">
<td id="S4.T1.1.43.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T1.1.43.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.43.1.1.1" class="ltx_p" style="width:52.0pt;">Roman digits</span>
</span>
</td>
<td id="S4.T1.1.43.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T1.1.43.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.43.2.1.1" class="ltx_p" style="width:65.0pt;">Krizhevsky et al. <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky et al. (<a href="#bib.bib40" title="" class="ltx_ref">2012</a>)</cite></span>
</span>
</td>
<td id="S4.T1.1.43.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T1.1.43.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.43.3.1.1" class="ltx_p" style="width:130.1pt;">CNN, LeNet-5 system</span>
</span>
</td>
<td id="S4.T1.1.43.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T1.1.43.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.43.4.1.1" class="ltx_p" style="width:86.7pt;">MNIST</span>
</span>
</td>
<td id="S4.T1.1.43.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T1.1.43.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.43.5.1.1" class="ltx_p" style="width:52.0pt;">99.10%</span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p">One of the classical models of CNN was the LeNet-5 system. Its accuracy rate on MNIST data-set was above 99%. It was extensively used for identification of handwritten checks on banks, but it could not recognize large images. With the advancement of technology, Graphics Processing Unit (GPU) was developed, then in 2012, Krizhevsky et al. <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky et al. (<a href="#bib.bib40" title="" class="ltx_ref">2012</a>)</cite> employed an efficient GPU supported program for solving ImageNet problem, which also made CNN application popular. Actually, one of the problems of using CNN was that it took much time to train the network because of the many hidden nodes in the network. But the GPUs’ faster parallel computing, overcame this problem too. A CNN based architecture with DropConnect layer was proposed by Wan et al. <cite class="ltx_cite ltx_citemacro_cite">Wan et al. (<a href="#bib.bib80" title="" class="ltx_ref">2013</a>)</cite> in 2013, where they attained 99.79% recognition accuracy for MNIST digits. DropConnect generalizes Hinton et al.’s Dropout <cite class="ltx_cite ltx_citemacro_cite">Hinton et al. (<a href="#bib.bib81" title="" class="ltx_ref">2012</a>)</cite> to the complete connectivity structure of a fully connected neural network (NN) layer. They provided both empirical results and theoretical justification for showing that DropConnect helps to regularize large NN models. As deep convolutional neural netwok (DCNN) comprises many layers, so it can model much more complicated functions than shallow networks. Motivating from DCNN’s great results in various machine learning and pattern recognition problems, in 2015, Kim and Xie <cite class="ltx_cite ltx_citemacro_cite">Kim and Xie (<a href="#bib.bib79" title="" class="ltx_ref">2015</a>)</cite> developed a new recognizer based on deep CNN to improve the Hangual handwrititng recognition performance. They built their own Hangul recognizers based on DCNN and developed various novel techniques for performance and networks training speed improvement. They evaluated their proposed recognizers on image datasets of Hangul, named SERI95a and PE92, where recognition results as 95.96% on SERI95a and 92.92% on PE92 are attained. In 2016, Poznanski and Wolf <cite class="ltx_cite ltx_citemacro_cite">Poznanski and Wolf (<a href="#bib.bib78" title="" class="ltx_ref">2016</a>)</cite> proposed a CNN-N-Gram based system for handwriting recognition, and recognized handwritten English and French words with 93.55% and 93.10% accuracy, respectively. Different persons’ variation in writing styles and single person’s variation in handwriting from time to time, make recognition of the local invariant patterns of a handwritten digit and character difficult. For this purpose, in 2017, Sarkhel et al. <cite class="ltx_cite ltx_citemacro_cite">Sarkhel et al. (<a href="#bib.bib77" title="" class="ltx_ref">2017</a>)</cite> proposed a non-explicit feature based approach, specifically it was a multi-column multi-scale CNN based architecture. Their proposed approach has been validated on different datasets of isolated handwritten digits and characters of Indic scripts, and best results are attained on MNIST dataset that is 99.74% without any data augmentation to the original dataset. Inspired from the deep learning’s role in image classification, in 2018, Arora and Bhatia <cite class="ltx_cite ltx_citemacro_cite">Arora and Bhatia (<a href="#bib.bib74" title="" class="ltx_ref">2018</a>)</cite> used Keras for classification of handwritten images of MNIST dataset. In fact, they used feed forward NN and CNN to extract features and training the model, it used Stochastic Gradient Descent for optimization. In their work, for classification of handwritten digits, it is observed that CNN attained greater accuracy in comparison to feed forward, and CNN obtained 95.63% and 99.20% accuracy for 5 and 20 iterations, respectively. Malayalam handwritten character recognition is very challenging, due to the isomorphic nature of character classes and a large number of character classes. To recognize handwritten Malayalam characters, in 2018, Manjusha et al. <cite class="ltx_cite ltx_citemacro_cite">Manjusha et al. (<a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite> replaced the convolutional feature maps of first layer in CNN architecture with scattering transform-based feature maps, and attained 93.77% as recognition accuracy. Scattering transform can compute stable invariant description of input patterns where it applies a series of wavelet decomposition, modulus and averaging operations. Their proposed hybrid CNN <cite class="ltx_cite ltx_citemacro_cite">Manjusha et al. (<a href="#bib.bib75" title="" class="ltx_ref">2018</a>)</cite> also achieved above 99% recognition accuracy for MNIST digits and ISI Bangla numerals datasets. A convolve, attend and spell, an attention based sequence to sequence model to recognize handwritten words without the use of HTR system’s traditional components, as connectionist temporal classification, language model nor lexicon was presented by Kang et al. <cite class="ltx_cite ltx_citemacro_cite">Kang et al. (<a href="#bib.bib76" title="" class="ltx_ref">2018</a>)</cite> in 2018. It was an end-to-end system that contained an encoder, decoder and attention mechanism, and it outperformed most of the existing best results, and it attained 93.12% character recognition accuracy and 82.55% word recognition accuracy for IAM dataset on word-level. In 2019, Chowdhury et al. <cite class="ltx_cite ltx_citemacro_cite">Chowdhury et al. (<a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite> used CNN to develop a handwritten character recognition model, and attained 99.25% accuracy for MNIST digits and 91.81% accuracy for Banglalekha-isolated characters. In 2019, Gupta et al. <cite class="ltx_cite ltx_citemacro_cite">Gupta et al. (<a href="#bib.bib72" title="" class="ltx_ref">2019</a>)</cite> proposed an opposition based multi-objective optimisation search algorithm to find the informative regions of character images, where they also used CNN features to evaluate the proposed work on different Indic scripts’ isolated units of handwriting and obtained good results for isolated Bangla basic characters, Bangla numerals, English numerals, and isolated Devanagari characters. Considering the research efforts for Malayalam character handwriting recognition, Manjusha et al. <cite class="ltx_cite ltx_citemacro_cite">Manjusha et al. (<a href="#bib.bib70" title="" class="ltx_ref">2019</a>)</cite> developed a handwritten character image database of Malayalam language script in 2019. In their work, recognition experiments were conducted by using different techniques of feature extraction. Among the used feature descriptors, scattering CNN attained the best recognition accuracy of 91.05%. In 2019, Prabhu <cite class="ltx_cite ltx_citemacro_cite">Prabhu (<a href="#bib.bib69" title="" class="ltx_ref">2019</a>)</cite> created a new dataset for handwritten digits of Kannada language, which is called Kannada-MNIST dataset, and attained best results as 96.80% using CNN based architecture. In 2019, Gati et al. <cite class="ltx_cite ltx_citemacro_cite">GATI et al. (<a href="#bib.bib67" title="" class="ltx_ref">2019</a>)</cite> described how great results and performance can be attained on a very challenging Dig-MNIST dataset using a custom-built model based on the skip CNN architecture, where 85.02% recognition accuracy was attained using proposed model trained on Kannada-MNIST and tested on the Dig-MNIST dataset without any pre-processing. In 2019, Chakraborty et al. <cite class="ltx_cite ltx_citemacro_cite">Chakraborty et al. (<a href="#bib.bib73" title="" class="ltx_ref">2019</a>)</cite> proposed for reduction of the feature maps which are used in training the CNN for reduction of computation time and storage space. Experimental results proved that the time requirement for training the CNN decreased with reduction in number of feature maps without affecting the accuracy much, and above 99% accuracy rate was attained for MNIST digit dataset. In 2020, Kusetogullari et al. <cite class="ltx_cite ltx_citemacro_cite">Kusetogullari et al. (<a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite> introduced different datasets of digits in ARDIS, and attained best recognition accuracy for digits using CNN that is 98.60%. A novel self-controlled RDP point based smaller size feature vector approach to recognize online handwriting was proposed by Singh et al. <cite class="ltx_cite ltx_citemacro_cite">Singh et al. (<a href="#bib.bib68" title="" class="ltx_ref">2020</a>)</cite> in 2020, where they employed a CNN based network that trains in a few minutes on a single machine without GPUs due to the use of Conv1Ds, and it attained 94.13% and 93.61% recognition rates for Gurmukhi and UNIPEN datasets, respectively. Recently, in 2021, Gu <cite class="ltx_cite ltx_citemacro_cite">Gu (<a href="#bib.bib64" title="" class="ltx_ref">2021</a>)</cite> proposed a CNN based model to classify the Kannada-MNIST dataset and made analysis of the proposed model performance on training, testing and validation sets. The CNN model was trained on more than 51000 images and it was validated over 9000 images for 30 epochs, where the CNN model attained a testing accuracy of 98.77%, and it outperformed other methods as SVM, logistic regression and a CNN baseline. This study is the evidence for the capability of proposed CNN model, and it also demonstrates the benefit of using a CNN architecture over other classification methods when performing handwritten character recognition jobs. A script independent CNN based system to recognize numerals was developed by Gupta and Bag <cite class="ltx_cite ltx_citemacro_cite">Gupta and Bag (<a href="#bib.bib65" title="" class="ltx_ref">2021</a>)</cite> in 2021, it is a system to recognize handwritten digits written in multi languages and it is independent of fusion where it has just 10 classes corresponding to every numeric digit. This was the first study that addressed the problem of multilingual numerals recognition, where experimental results attained the accuracy of 96.23% for eight Indic scripts collectively. The attained results are promising and demonstrates the hypothesis that multilingual handwritten numeral recognition is void with CNN.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results of RNN in Handwriting Recognition</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">RNNs are very powerful machine learning models and have found use in a wide range of areas where sequential data is dealt. RNNs have been widely used in prediction problems, machine translation, face detection, speech Recognition, OCR based image recognition and handwriting recognition etc. RNNs have received great success when working with sequential data, generally in the field of handwriting recognition. The table <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab2_HWR_results</span> presents the selected handwriting recognition results using RNN.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of RNN in Handwriting Recognition</figcaption>
<table id="S4.T2.1" class="ltx_tabular">
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.1.1.1.1" class="ltx_p" style="width:52.0pt;"><span id="S4.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Script</span></span>
</span>
</td>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.1.2.1.1" class="ltx_p" style="width:65.0pt;"><span id="S4.T2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.1.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T2.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Methodology</span></span>
</span>
</td>
<td id="S4.T2.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.1.4.1.1" class="ltx_p" style="width:86.7pt;"><span id="S4.T2.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</td>
<td id="S4.T2.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.1.5.1.1" class="ltx_p" style="width:52.0pt;"><span id="S4.T2.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Accuracy</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.1.2" class="ltx_tr">
<td id="S4.T2.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.2.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.2.2.1.1" class="ltx_p" style="width:65.0pt;">Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.2.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM with dropout at the topmost hidden layer</span>
</span>
</td>
<td id="S4.T2.1.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.2.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.1.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.2.5.1.1" class="ltx_p" style="width:52.0pt;">60.52%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.3" class="ltx_tr">
<td id="S4.T2.1.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.3.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.3.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.3.2.1.1" class="ltx_p" style="width:65.0pt;">Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.3.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM with dropout at multiple layers</span>
</span>
</td>
<td id="S4.T2.1.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.3.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.3.5.1.1" class="ltx_p" style="width:52.0pt;">68.56%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.4" class="ltx_tr">
<td id="S4.T2.1.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.4.1.1.1" class="ltx_p" style="width:52.0pt;">French words</span>
</span>
</td>
<td id="S4.T2.1.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.4.2.1.1" class="ltx_p" style="width:65.0pt;">Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.4.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM with dropout at the topmost hidden layer</span>
</span>
</td>
<td id="S4.T2.1.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.4.4.1.1" class="ltx_p" style="width:86.7pt;">Rimes</span>
</span>
</td>
<td id="S4.T2.1.4.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.4.5.1.1" class="ltx_p" style="width:52.0pt;">63.97%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.5" class="ltx_tr">
<td id="S4.T2.1.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.5.1.1.1" class="ltx_p" style="width:52.0pt;">French words</span>
</span>
</td>
<td id="S4.T2.1.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.5.2.1.1" class="ltx_p" style="width:65.0pt;">Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.5.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM with dropout at multiple layers</span>
</span>
</td>
<td id="S4.T2.1.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.5.4.1.1" class="ltx_p" style="width:86.7pt;">Rimes</span>
</span>
</td>
<td id="S4.T2.1.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.5.5.1.1" class="ltx_p" style="width:52.0pt;">72.99%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.6" class="ltx_tr">
<td id="S4.T2.1.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.6.1.1.1" class="ltx_p" style="width:52.0pt;">English characters</span>
</span>
</td>
<td id="S4.T2.1.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.6.2.1.1" class="ltx_p" style="width:65.0pt;">Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.6.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM with dropout at the topmost hidden layer</span>
</span>
</td>
<td id="S4.T2.1.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.6.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.6.5.1.1" class="ltx_p" style="width:52.0pt;">81.55%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.7" class="ltx_tr">
<td id="S4.T2.1.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.7.1.1.1" class="ltx_p" style="width:52.0pt;">English characters</span>
</span>
</td>
<td id="S4.T2.1.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.7.2.1.1" class="ltx_p" style="width:65.0pt;">Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.7.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM with dropout at multiple layers</span>
</span>
</td>
<td id="S4.T2.1.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.7.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.7.5.1.1" class="ltx_p" style="width:52.0pt;">86.08%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.8" class="ltx_tr">
<td id="S4.T2.1.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.8.1.1.1" class="ltx_p" style="width:52.0pt;">French characters</span>
</span>
</td>
<td id="S4.T2.1.8.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.8.2.1.1" class="ltx_p" style="width:65.0pt;">Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.8.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM with dropout at the topmost hidden layer</span>
</span>
</td>
<td id="S4.T2.1.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.8.4.1.1" class="ltx_p" style="width:86.7pt;">Rimes</span>
</span>
</td>
<td id="S4.T2.1.8.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.8.5.1.1" class="ltx_p" style="width:52.0pt;">87.83%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.9" class="ltx_tr">
<td id="S4.T2.1.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.9.1.1.1" class="ltx_p" style="width:52.0pt;">French characters</span>
</span>
</td>
<td id="S4.T2.1.9.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.9.2.1.1" class="ltx_p" style="width:65.0pt;">Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.9.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM with dropout at multiple layers</span>
</span>
</td>
<td id="S4.T2.1.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.9.4.1.1" class="ltx_p" style="width:86.7pt;">Rimes</span>
</span>
</td>
<td id="S4.T2.1.9.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.9.5.1.1" class="ltx_p" style="width:52.0pt;">91.38%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.10" class="ltx_tr">
<td id="S4.T2.1.10.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.10.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.10.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.10.2.1.1" class="ltx_p" style="width:65.0pt;">Doetsch et al. <cite class="ltx_cite ltx_citemacro_cite">Doetsch et al. (<a href="#bib.bib83" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.10.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM-RNN</span>
</span>
</td>
<td id="S4.T2.1.10.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.10.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.10.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.10.5.1.1" class="ltx_p" style="width:52.0pt;">87.80%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.11" class="ltx_tr">
<td id="S4.T2.1.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.11.1.1.1" class="ltx_p" style="width:52.0pt;">French words</span>
</span>
</td>
<td id="S4.T2.1.11.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.11.2.1.1" class="ltx_p" style="width:65.0pt;">Doetsch et al. <cite class="ltx_cite ltx_citemacro_cite">Doetsch et al. (<a href="#bib.bib83" title="" class="ltx_ref">2014</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.11.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM-RNN</span>
</span>
</td>
<td id="S4.T2.1.11.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.11.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.11.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.11.5.1.1" class="ltx_p" style="width:52.0pt;">87.10%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.12" class="ltx_tr">
<td id="S4.T2.1.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.12.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla characters</span>
</span>
</td>
<td id="S4.T2.1.12.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.12.2.1.1" class="ltx_p" style="width:65.0pt;">Chollet et al. <cite class="ltx_cite ltx_citemacro_cite">Chollet et al. (<a href="#bib.bib84" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.12.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.12.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM</span>
</span>
</td>
<td id="S4.T2.1.12.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.12.4.1.1" class="ltx_p" style="width:86.7pt;">Banglalekha-isolated</span>
</span>
</td>
<td id="S4.T2.1.12.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.12.5.1.1" class="ltx_p" style="width:52.0pt;">87.41%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.13" class="ltx_tr">
<td id="S4.T2.1.13.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.13.1.1.1" class="ltx_p" style="width:52.0pt;">Bangla characters</span>
</span>
</td>
<td id="S4.T2.1.13.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.13.2.1.1" class="ltx_p" style="width:65.0pt;">Chollet et al. <cite class="ltx_cite ltx_citemacro_cite">Chollet et al. (<a href="#bib.bib84" title="" class="ltx_ref">2015</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.13.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.13.3.1.1" class="ltx_p" style="width:130.1pt;">LSTM</span>
</span>
</td>
<td id="S4.T2.1.13.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.13.4.1.1" class="ltx_p" style="width:86.7pt;">Ekush</span>
</span>
</td>
<td id="S4.T2.1.13.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.13.5.1.1" class="ltx_p" style="width:52.0pt;">93.06%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.14" class="ltx_tr">
<td id="S4.T2.1.14.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.14.1.1.1" class="ltx_p" style="width:52.0pt;">Arabic words</span>
</span>
</td>
<td id="S4.T2.1.14.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.14.2.1.1" class="ltx_p" style="width:65.0pt;">Chherawala et al. <cite class="ltx_cite ltx_citemacro_cite">Chherawala et al. (<a href="#bib.bib85" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.14.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.14.3.1.1" class="ltx_p" style="width:130.1pt;">Weighted Vote Combination of RNN</span>
</span>
</td>
<td id="S4.T2.1.14.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.14.4.1.1" class="ltx_p" style="width:86.7pt;">FN/ENIT</span>
</span>
</td>
<td id="S4.T2.1.14.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.14.5.1.1" class="ltx_p" style="width:52.0pt;">96%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.15" class="ltx_tr">
<td id="S4.T2.1.15.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.15.1.1.1" class="ltx_p" style="width:52.0pt;">French words</span>
</span>
</td>
<td id="S4.T2.1.15.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.15.2.1.1" class="ltx_p" style="width:65.0pt;">Chherawala et al. <cite class="ltx_cite ltx_citemacro_cite">Chherawala et al. (<a href="#bib.bib85" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.15.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.15.3.1.1" class="ltx_p" style="width:130.1pt;">Weighted Vote Combination of RNN</span>
</span>
</td>
<td id="S4.T2.1.15.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.15.4.1.1" class="ltx_p" style="width:86.7pt;">RIMES</span>
</span>
</td>
<td id="S4.T2.1.15.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.15.5.1.1" class="ltx_p" style="width:52.0pt;">95.2%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.16" class="ltx_tr">
<td id="S4.T2.1.16.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.16.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.16.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.16.2.1.1" class="ltx_p" style="width:65.0pt;">Shkarupa et al. <cite class="ltx_cite ltx_citemacro_cite">Shkarupa et al. (<a href="#bib.bib86" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.16.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.16.3.1.1" class="ltx_p" style="width:130.1pt;">CTC+BLSTM</span>
</span>
</td>
<td id="S4.T2.1.16.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.16.4.1.1" class="ltx_p" style="width:86.7pt;">handwritten medieval Latin text</span>
</span>
</td>
<td id="S4.T2.1.16.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.16.5.1.1" class="ltx_p" style="width:52.0pt;">78.10%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.17" class="ltx_tr">
<td id="S4.T2.1.17.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.17.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.17.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.17.2.1.1" class="ltx_p" style="width:65.0pt;">Shkarupa et al. <cite class="ltx_cite ltx_citemacro_cite">Shkarupa et al. (<a href="#bib.bib86" title="" class="ltx_ref">2016</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.17.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.17.3.1.1" class="ltx_p" style="width:130.1pt;">Sequence to sequence+LSTM</span>
</span>
</td>
<td id="S4.T2.1.17.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.17.4.1.1" class="ltx_p" style="width:86.7pt;">handwritten medieval Latin text</span>
</span>
</td>
<td id="S4.T2.1.17.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.17.5.1.1" class="ltx_p" style="width:52.0pt;">72.79%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.18" class="ltx_tr">
<td id="S4.T2.1.18.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.18.1.1.1" class="ltx_p" style="width:52.0pt;">English Words</span>
</span>
</td>
<td id="S4.T2.1.18.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.18.2.1.1" class="ltx_p" style="width:65.0pt;">Wigington et al. <cite class="ltx_cite ltx_citemacro_cite">Wigington et al. (<a href="#bib.bib87" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.18.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.18.3.1.1" class="ltx_p" style="width:130.1pt;">RNN+CTC</span>
</span>
</td>
<td id="S4.T2.1.18.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.18.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.18.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.18.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.18.5.1.1" class="ltx_p" style="width:52.0pt;">80.93%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.19" class="ltx_tr">
<td id="S4.T2.1.19.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.19.1.1.1" class="ltx_p" style="width:52.0pt;">French Words</span>
</span>
</td>
<td id="S4.T2.1.19.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.19.2.1.1" class="ltx_p" style="width:65.0pt;">Wigington et al. <cite class="ltx_cite ltx_citemacro_cite">Wigington et al. (<a href="#bib.bib87" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.19.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.19.3.1.1" class="ltx_p" style="width:130.1pt;">RNN+CTC</span>
</span>
</td>
<td id="S4.T2.1.19.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.19.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.19.4.1.1" class="ltx_p" style="width:86.7pt;">Rimes</span>
</span>
</td>
<td id="S4.T2.1.19.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.19.5.1.1" class="ltx_p" style="width:52.0pt;">88.71%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.20" class="ltx_tr">
<td id="S4.T2.1.20.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.20.1.1.1" class="ltx_p" style="width:52.0pt;">English characters</span>
</span>
</td>
<td id="S4.T2.1.20.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.20.2.1.1" class="ltx_p" style="width:65.0pt;">Wigington et al. <cite class="ltx_cite ltx_citemacro_cite">Wigington et al. (<a href="#bib.bib87" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.20.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.20.3.1.1" class="ltx_p" style="width:130.1pt;">RNN+CTC</span>
</span>
</td>
<td id="S4.T2.1.20.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.20.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.20.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.20.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.20.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.20.5.1.1" class="ltx_p" style="width:52.0pt;">93.93%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.21" class="ltx_tr">
<td id="S4.T2.1.21.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.21.1.1.1" class="ltx_p" style="width:52.0pt;">French characters</span>
</span>
</td>
<td id="S4.T2.1.21.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.21.2.1.1" class="ltx_p" style="width:65.0pt;">Wigington et al. <cite class="ltx_cite ltx_citemacro_cite">Wigington et al. (<a href="#bib.bib87" title="" class="ltx_ref">2017</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.21.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.21.3.1.1" class="ltx_p" style="width:130.1pt;">RNN+CTC</span>
</span>
</td>
<td id="S4.T2.1.21.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.21.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.21.4.1.1" class="ltx_p" style="width:86.7pt;">Rimes</span>
</span>
</td>
<td id="S4.T2.1.21.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.21.5.1.1" class="ltx_p" style="width:52.0pt;">96.91%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.22" class="ltx_tr">
<td id="S4.T2.1.22.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.22.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.22.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.22.2.1.1" class="ltx_p" style="width:65.0pt;">Dutta et al. <cite class="ltx_cite ltx_citemacro_cite">Dutta et al. (<a href="#bib.bib88" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.22.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.22.3.1.1" class="ltx_p" style="width:130.1pt;">Hybrid CNN-RNN network</span>
</span>
</td>
<td id="S4.T2.1.22.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.22.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.22.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.22.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.22.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.22.5.1.1" class="ltx_p" style="width:52.0pt;">87.39%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.23" class="ltx_tr">
<td id="S4.T2.1.23.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.23.1.1.1" class="ltx_p" style="width:52.0pt;">English characters</span>
</span>
</td>
<td id="S4.T2.1.23.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.23.2.1.1" class="ltx_p" style="width:65.0pt;">Dutta et al. <cite class="ltx_cite ltx_citemacro_cite">Dutta et al. (<a href="#bib.bib88" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.23.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.23.3.1.1" class="ltx_p" style="width:130.1pt;">Hybrid CNN-RNN network</span>
</span>
</td>
<td id="S4.T2.1.23.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.23.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.23.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.23.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.23.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.23.5.1.1" class="ltx_p" style="width:52.0pt;">95.12%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.24" class="ltx_tr">
<td id="S4.T2.1.24.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.24.1.1.1" class="ltx_p" style="width:52.0pt;">French words</span>
</span>
</td>
<td id="S4.T2.1.24.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.24.2.1.1" class="ltx_p" style="width:65.0pt;">Dutta et al. <cite class="ltx_cite ltx_citemacro_cite">Dutta et al. (<a href="#bib.bib88" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.24.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.24.3.1.1" class="ltx_p" style="width:130.1pt;">Hybrid CNN-RNN network</span>
</span>
</td>
<td id="S4.T2.1.24.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.24.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.24.4.1.1" class="ltx_p" style="width:86.7pt;">RIMES</span>
</span>
</td>
<td id="S4.T2.1.24.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.24.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.24.5.1.1" class="ltx_p" style="width:52.0pt;">92.96%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.25" class="ltx_tr">
<td id="S4.T2.1.25.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.25.1.1.1" class="ltx_p" style="width:52.0pt;">French characters</span>
</span>
</td>
<td id="S4.T2.1.25.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.25.2.1.1" class="ltx_p" style="width:65.0pt;">Dutta et al. <cite class="ltx_cite ltx_citemacro_cite">Dutta et al. (<a href="#bib.bib88" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.25.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.25.3.1.1" class="ltx_p" style="width:130.1pt;">Hybrid CNN-RNN network</span>
</span>
</td>
<td id="S4.T2.1.25.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.25.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.25.4.1.1" class="ltx_p" style="width:86.7pt;">RIMES</span>
</span>
</td>
<td id="S4.T2.1.25.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.25.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.25.5.1.1" class="ltx_p" style="width:52.0pt;">97.68%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.26" class="ltx_tr">
<td id="S4.T2.1.26.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.26.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.26.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.26.2.1.1" class="ltx_p" style="width:65.0pt;">Dutta et al. <cite class="ltx_cite ltx_citemacro_cite">Dutta et al. (<a href="#bib.bib88" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.26.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.26.3.1.1" class="ltx_p" style="width:130.1pt;">Hybrid CNN-RNN network</span>
</span>
</td>
<td id="S4.T2.1.26.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.26.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.26.4.1.1" class="ltx_p" style="width:86.7pt;">GW</span>
</span>
</td>
<td id="S4.T2.1.26.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.26.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.26.5.1.1" class="ltx_p" style="width:52.0pt;">87.02%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.27" class="ltx_tr">
<td id="S4.T2.1.27.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.27.1.1.1" class="ltx_p" style="width:52.0pt;">English characters</span>
</span>
</td>
<td id="S4.T2.1.27.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.27.2.1.1" class="ltx_p" style="width:65.0pt;">Dutta et al. <cite class="ltx_cite ltx_citemacro_cite">Dutta et al. (<a href="#bib.bib88" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.27.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.27.3.1.1" class="ltx_p" style="width:130.1pt;">Hybrid CNN-RNN network</span>
</span>
</td>
<td id="S4.T2.1.27.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.27.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.27.4.1.1" class="ltx_p" style="width:86.7pt;">GW</span>
</span>
</td>
<td id="S4.T2.1.27.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.27.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.27.5.1.1" class="ltx_p" style="width:52.0pt;">95.71%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.28" class="ltx_tr">
<td id="S4.T2.1.28.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.28.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.28.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.28.2.1.1" class="ltx_p" style="width:65.0pt;">Krishnan et al. <cite class="ltx_cite ltx_citemacro_cite">Krishnan et al. (<a href="#bib.bib89" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.28.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.28.3.1.1" class="ltx_p" style="width:130.1pt;">Convolutional recurrent neural network (CRNN)</span>
</span>
</td>
<td id="S4.T2.1.28.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.28.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.28.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.28.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.28.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.28.5.1.1" class="ltx_p" style="width:52.0pt;">94.90%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.29" class="ltx_tr">
<td id="S4.T2.1.29.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.29.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.29.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.29.2.1.1" class="ltx_p" style="width:65.0pt;">Sueiras et al. <cite class="ltx_cite ltx_citemacro_cite">Sueiras et al. (<a href="#bib.bib90" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.29.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.29.3.1.1" class="ltx_p" style="width:130.1pt;">Sequence to
sequence NN</span>
</span>
</td>
<td id="S4.T2.1.29.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.29.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.29.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.29.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.29.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.29.5.1.1" class="ltx_p" style="width:52.0pt;">87.30%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.30" class="ltx_tr">
<td id="S4.T2.1.30.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.30.1.1.1" class="ltx_p" style="width:52.0pt;">French words</span>
</span>
</td>
<td id="S4.T2.1.30.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.30.2.1.1" class="ltx_p" style="width:65.0pt;">Sueiras et al. <cite class="ltx_cite ltx_citemacro_cite">Sueiras et al. (<a href="#bib.bib90" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.30.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.30.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.30.3.1.1" class="ltx_p" style="width:130.1pt;">Sequence to
sequence NN</span>
</span>
</td>
<td id="S4.T2.1.30.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.30.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.30.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.30.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.30.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.30.5.1.1" class="ltx_p" style="width:52.0pt;">93.40%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.31" class="ltx_tr">
<td id="S4.T2.1.31.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.31.1.1.1" class="ltx_p" style="width:52.0pt;">English characters</span>
</span>
</td>
<td id="S4.T2.1.31.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.31.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.31.2.1.1" class="ltx_p" style="width:65.0pt;">Krishnan et al. <cite class="ltx_cite ltx_citemacro_cite">Krishnan et al. (<a href="#bib.bib89" title="" class="ltx_ref">2018</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.31.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.31.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.31.3.1.1" class="ltx_p" style="width:130.1pt;">CRNN</span>
</span>
</td>
<td id="S4.T2.1.31.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.31.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.31.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.31.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.31.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.31.5.1.1" class="ltx_p" style="width:52.0pt;">97.44%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.32" class="ltx_tr">
<td id="S4.T2.1.32.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.32.1.1.1" class="ltx_p" style="width:52.0pt;">Bengali words</span>
</span>
</td>
<td id="S4.T2.1.32.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.32.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.32.2.1.1" class="ltx_p" style="width:65.0pt;">Ghosh et al. <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al. (<a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.32.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.32.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.32.3.1.1" class="ltx_p" style="width:130.1pt;">BLSTM</span>
</span>
</td>
<td id="S4.T2.1.32.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.32.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.32.4.1.1" class="ltx_p" style="width:86.7pt;">Bengali dataset of 120000 words</span>
</span>
</td>
<td id="S4.T2.1.32.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.32.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.32.5.1.1" class="ltx_p" style="width:52.0pt;">95.24% (lexicon 1K)</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.33" class="ltx_tr">
<td id="S4.T2.1.33.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.33.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.33.1.1.1" class="ltx_p" style="width:52.0pt;">Bengali words</span>
</span>
</td>
<td id="S4.T2.1.33.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.33.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.33.2.1.1" class="ltx_p" style="width:65.0pt;">Ghosh et al. <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al. (<a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.33.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.33.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.33.3.1.1" class="ltx_p" style="width:130.1pt;">BLSTM</span>
</span>
</td>
<td id="S4.T2.1.33.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.33.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.33.4.1.1" class="ltx_p" style="width:86.7pt;">Bengali dataset of 120000 words</span>
</span>
</td>
<td id="S4.T2.1.33.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.33.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.33.5.1.1" class="ltx_p" style="width:52.0pt;">90.78% (lexicon 5K)</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.34" class="ltx_tr">
<td id="S4.T2.1.34.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.34.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.34.1.1.1" class="ltx_p" style="width:52.0pt;">Bengali words</span>
</span>
</td>
<td id="S4.T2.1.34.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.34.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.34.2.1.1" class="ltx_p" style="width:65.0pt;">Ghosh et al. <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al. (<a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.34.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.34.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.34.3.1.1" class="ltx_p" style="width:130.1pt;">BLSTM</span>
</span>
</td>
<td id="S4.T2.1.34.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.34.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.34.4.1.1" class="ltx_p" style="width:86.7pt;">Bengali dataset of 120000 words</span>
</span>
</td>
<td id="S4.T2.1.34.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.34.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.34.5.1.1" class="ltx_p" style="width:52.0pt;">87.38% (lexicon 10K)</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.35" class="ltx_tr">
<td id="S4.T2.1.35.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.35.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.35.1.1.1" class="ltx_p" style="width:52.0pt;">Devanagari words</span>
</span>
</td>
<td id="S4.T2.1.35.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.35.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.35.2.1.1" class="ltx_p" style="width:65.0pt;">Ghosh et al. <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al. (<a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.35.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.35.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.35.3.1.1" class="ltx_p" style="width:130.1pt;">BLSTM</span>
</span>
</td>
<td id="S4.T2.1.35.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.35.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.35.4.1.1" class="ltx_p" style="width:86.7pt;">Bengali dataset of 120000 words</span>
</span>
</td>
<td id="S4.T2.1.35.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.35.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.35.5.1.1" class="ltx_p" style="width:52.0pt;">99.50% (lexicon 1K)</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.36" class="ltx_tr">
<td id="S4.T2.1.36.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.36.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.36.1.1.1" class="ltx_p" style="width:52.0pt;">Devanagari words</span>
</span>
</td>
<td id="S4.T2.1.36.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.36.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.36.2.1.1" class="ltx_p" style="width:65.0pt;">Ghosh et al. <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al. (<a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.36.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.36.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.36.3.1.1" class="ltx_p" style="width:130.1pt;">BLSTM</span>
</span>
</td>
<td id="S4.T2.1.36.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.36.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.36.4.1.1" class="ltx_p" style="width:86.7pt;">Bengali dataset of 120000 words</span>
</span>
</td>
<td id="S4.T2.1.36.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.36.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.36.5.1.1" class="ltx_p" style="width:52.0pt;">96.27% (lexicon 5K)</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.37" class="ltx_tr">
<td id="S4.T2.1.37.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.37.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.37.1.1.1" class="ltx_p" style="width:52.0pt;">Devanagari words</span>
</span>
</td>
<td id="S4.T2.1.37.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.37.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.37.2.1.1" class="ltx_p" style="width:65.0pt;">Ghosh et al. <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al. (<a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.37.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.37.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.37.3.1.1" class="ltx_p" style="width:130.1pt;">BLSTM</span>
</span>
</td>
<td id="S4.T2.1.37.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.37.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.37.4.1.1" class="ltx_p" style="width:86.7pt;">Bengali dataset of 120000 words</span>
</span>
</td>
<td id="S4.T2.1.37.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.37.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.37.5.1.1" class="ltx_p" style="width:52.0pt;">94.34% (lexicon 10K)</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.38" class="ltx_tr">
<td id="S4.T2.1.38.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.38.1.1.1" class="ltx_p" style="width:52.0pt;">English words</span>
</span>
</td>
<td id="S4.T2.1.38.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.38.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.38.2.1.1" class="ltx_p" style="width:65.0pt;">Geetha et al. <cite class="ltx_cite ltx_citemacro_cite">Geetha et al. (<a href="#bib.bib92" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.38.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.38.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.38.3.1.1" class="ltx_p" style="width:130.1pt;">CNN-RNN</span>
</span>
</td>
<td id="S4.T2.1.38.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.38.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.38.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.38.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.38.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.38.5.1.1" class="ltx_p" style="width:52.0pt;">95.20%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.39" class="ltx_tr">
<td id="S4.T2.1.39.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.39.1.1.1" class="ltx_p" style="width:52.0pt;">English characters</span>
</span>
</td>
<td id="S4.T2.1.39.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.39.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.39.2.1.1" class="ltx_p" style="width:65.0pt;">Geetha et al. <cite class="ltx_cite ltx_citemacro_cite">Geetha et al. (<a href="#bib.bib92" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.39.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.39.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.39.3.1.1" class="ltx_p" style="width:130.1pt;">CNN-RNN</span>
</span>
</td>
<td id="S4.T2.1.39.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.39.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.39.4.1.1" class="ltx_p" style="width:86.7pt;">IAM</span>
</span>
</td>
<td id="S4.T2.1.39.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.39.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.39.5.1.1" class="ltx_p" style="width:52.0pt;">97.48%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.40" class="ltx_tr">
<td id="S4.T2.1.40.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.40.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.40.1.1.1" class="ltx_p" style="width:52.0pt;">French words</span>
</span>
</td>
<td id="S4.T2.1.40.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.40.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.40.2.1.1" class="ltx_p" style="width:65.0pt;">Geetha et al. <cite class="ltx_cite ltx_citemacro_cite">Geetha et al. (<a href="#bib.bib92" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.40.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.40.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.40.3.1.1" class="ltx_p" style="width:130.1pt;">CNN-RNN</span>
</span>
</td>
<td id="S4.T2.1.40.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.40.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.40.4.1.1" class="ltx_p" style="width:86.7pt;">RIMES</span>
</span>
</td>
<td id="S4.T2.1.40.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.1.40.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.40.5.1.1" class="ltx_p" style="width:52.0pt;">98.14%</span>
</span>
</td>
</tr>
<tr id="S4.T2.1.41" class="ltx_tr">
<td id="S4.T2.1.41.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T2.1.41.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.41.1.1.1" class="ltx_p" style="width:52.0pt;">French characters</span>
</span>
</td>
<td id="S4.T2.1.41.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T2.1.41.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.41.2.1.1" class="ltx_p" style="width:65.0pt;">Geetha et al. <cite class="ltx_cite ltx_citemacro_cite">Geetha et al. (<a href="#bib.bib92" title="" class="ltx_ref">2021</a>)</cite></span>
</span>
</td>
<td id="S4.T2.1.41.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T2.1.41.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.41.3.1.1" class="ltx_p" style="width:130.1pt;">CNN-RNN</span>
</span>
</td>
<td id="S4.T2.1.41.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T2.1.41.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.41.4.1.1" class="ltx_p" style="width:86.7pt;">RIMES</span>
</span>
</td>
<td id="S4.T2.1.41.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T2.1.41.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.41.5.1.1" class="ltx_p" style="width:52.0pt;">99.35%</span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">In 2014, Pham et al. <cite class="ltx_cite ltx_citemacro_cite">Pham et al. (<a href="#bib.bib82" title="" class="ltx_ref">2014</a>)</cite> presented that the dropout can improve the performance of RNN greatly. The word recognition networks having dropout at the topmost layer improved the character and word recognition by 10% to 20%, and when dropout used with multiple LSTM layers, then it further improved the performance by 30% to 40%. They reported the best results on Rimes dataset as 91.38% and 72.99% for character and word recognition, respectively. The simple RNN was modified by Koutnik et al. <cite class="ltx_cite ltx_citemacro_cite">Koutnik et al. (<a href="#bib.bib93" title="" class="ltx_ref">2014</a>)</cite> in 2014, and introduced a powerful Clockwork RNN (CW-RNN), where hidden layers were divided into different modules and every layer processed the inputs at its own temporal granularity, which made computations over prescribed clock rate only. The CW-RNN reduced the number of parameters of simple RNN, and also improved the speed and performance significantly. For online handwriting recognition, CW-RNN outperformed the simple RNN and LSTM, and improved recognition accuracy by 20% for English sentences. A modified topology for LSTM-RNN that controlled the shape of squashing functions in gating units was demonstrated by Doetsch et al. <cite class="ltx_cite ltx_citemacro_cite">Doetsch et al. (<a href="#bib.bib83" title="" class="ltx_ref">2014</a>)</cite> in 2014. An efficient framework of mini batch training at sequence level in combination with sequence chunking approach was also proposed by them. They evaluated their framework on IAM and RIMES datasets by using GPU based implementation, and it was three times faster in training RNN models which outperformed the state-of-the-art recognition results, where 87.80% and 87.10% recognition accuracies were attained for handwritten words of IAM and RIMES datasets, respectively. In 2015, an image classification system using LSTM with Keras was built and it was applied to handwritten Bangla character datasets, where it achieved 87.41% and 93.06% recognition accuracy for two different datasets of Bangla characters <cite class="ltx_cite ltx_citemacro_cite">Chollet et al. (<a href="#bib.bib84" title="" class="ltx_ref">2015</a>)</cite>. This architecture consisted of one LSTM layer having 128 units, had activation function as ’ReLU’ and recurrent activation function had been set to ’hard sigmoid’. In 2016, Chherawala et al. <cite class="ltx_cite ltx_citemacro_cite">Chherawala et al. (<a href="#bib.bib85" title="" class="ltx_ref">2016</a>)</cite> proposed a novel method to extract the promising features of handwritten word images. They proposed a framework to evaluate feature set based on collaborative setting. In their work, they employed weighted vote combination of RNN classifiers, where particular feature set was used to train every RNN. The major contribution of their study was the quantification of the feature sets’ importance through weight combination, and it also showed their complementarity and strength. They used RNN because of the state-of-the-art results, and provided the first feature set benchmark for RNN classifier. They evaluated different feature sets on different datasets of Arabic and Latin scripts, and attained best accuracies as 96% and 95.2% for IFN/ENIT and RIMES datasets, respectively. For historic handwritten Latin text recognition, two important approaches based on RNN were proposed by Shkarupa et al. <cite class="ltx_cite ltx_citemacro_cite">Shkarupa et al. (<a href="#bib.bib86" title="" class="ltx_ref">2016</a>)</cite> in 2016. Their first approach used connectionist temporal classification (CTC) output layer, and attained 78.10% word level accuracy. The other approach used sequence-to-sequence learning, and attained 72.79% word level accuracy. In their work, when CTC approach was used with BLSTM, it outperformed the sequence-to-sequence based approach used with LSTM. Their proposed system of handwriting recognition considered unsegmented word images as input and provided decoded strings as output. In 2017, Wigington et al. <cite class="ltx_cite ltx_citemacro_cite">Wigington et al. (<a href="#bib.bib87" title="" class="ltx_ref">2017</a>)</cite> presented two data normalization and augmentation techniques, and these were used with CNN and LSTM. These techniques reduced the character error rate and word error rate significantly, and significant results were reported for handwriting recognition tasks. The novel normalization technique was applied to both word and line images. Their proposed approaches attained high accuracies for both characters and words over several existing studies, where IAM dataset character and word level recognition accuracy was reported as 96.97% and 94.39%, respectively. In 2018, Dutta et al. <cite class="ltx_cite ltx_citemacro_cite">Dutta et al. (<a href="#bib.bib88" title="" class="ltx_ref">2018</a>)</cite> proposed a modified CNN-RNN based hybrid architecture and mainly focussed for effective training with: (a) network’s efficient initialization with the use of synthetic data in pretraining, (b) slant correction with image normalization and (iii) domain specific transformation of data and distortion to learn important invariances. In their work, a detailed ablation study for analysis of the contribution of individual module was performed and the results for unconstrained line and word recognition on IAM, RIMES and GW datasets were presented at par literature, where they attained lexicon free word recognition accuracies as 87.39%, 92.96% and 87.02% on these three datasets, respectively. To represent handwritten word images efficiently, an HWNet v2 architecture was presented by Krishnan et al. <cite class="ltx_cite ltx_citemacro_cite">Krishnan et al. (<a href="#bib.bib89" title="" class="ltx_ref">2018</a>)</cite> in 2018. The state-of-the-art attribute embedding was enabled by this work. An end-to-end embedding framework was demonstrated by it, and it used textual representation and synthetic image for learning complementary information to embed text and images. It also improved the word recognition performance using a convolutional recurrent neural network (CRNN) architecture, by using the synthetic data and spatial transformer layer, and attained character and word level accuracies on IAM dataset as 97.44% and 94.90%, respectively. In 2018, a system based on sequence to sequence architecture with convolutional network was proposed by Sueiras et al. <cite class="ltx_cite ltx_citemacro_cite">Sueiras et al. (<a href="#bib.bib90" title="" class="ltx_ref">2018</a>)</cite> to recognize offline handwriting. This model had three major components, where first convolutional network extracted relevant features of the characters present in the word. Then RNN captured the sequential relationships of extracted features. Thirdly, the input word was predicted by decoding the sequence of characters with another RNN. Their proposed system was tested on handwritten words of IAM and RIMES datasets, and attained the recognition accuracy as 87.3% and 93.6%, respectively, where no language model was used and results were attained with closed dictionary. In 2019, Ghosh et al. <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al. (<a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite> presented a new online handwritten word recognition system based on LSTM and BLSTM versions of RNN, and recognized Devanagari and Bengali words in lexicon dependent environment with above 90% (for lexicon size 5K) recognition accuracy. Their proposed approach divided every handwritten word into upper, middle, and lower zones horizontally, and reduces the basic stroke order variations with in a word. Further, they also used various structural and directional features of different zones’ basic strokes of handwritten words. In 2021, Geetha et al. <cite class="ltx_cite ltx_citemacro_cite">Geetha et al. (<a href="#bib.bib92" title="" class="ltx_ref">2021</a>)</cite> proposed a hybrid model to recognize handwritten text by utilizing deep learning that used sequence-to-sequence approach. It used various features of CNN and RNN-LSTM. It used CNN to extract features of handwritten text images. The extracted features were then modelled with a sequence-to-sequence approach and fed in RNN-LSTM to encode the visual features and decoded the sequence of letters present in handwritten image. Their proposed model was tested with IAM and RIMES datasets, where above 95% accuracy was attained using CNN-RNN for handwritten words of English and French.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>General Observations</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">In this section, an analysis of various techniques used for deep learning architectures, and deep learning use in handwriting recognition and other related fields are presented.</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i1.p1.1" class="ltx_p">Deep learning has been effectively used in various emerging fields to solve complex problems of real world with different deep learning architectures. Deep learning architectures employ different activation functions for the achievement of state-of-the-art performances, to perform various computations between the hidden and output layers of deep learning architectures. Further, the advancement in deep learning architectures’ configuration brings new challenges, particularly for the selection of right activation functions to perform in various domains from the classification of objects <cite class="ltx_cite ltx_citemacro_cite">Krizhevsky et al. (<a href="#bib.bib40" title="" class="ltx_ref">2012</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Szegedy et al. (<a href="#bib.bib94" title="" class="ltx_ref">2015b</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a href="#bib.bib95" title="" class="ltx_ref">2015</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Md Noor et al. (<a href="#bib.bib96" title="" class="ltx_ref">2017</a>)</cite>, speech recognition <cite class="ltx_cite ltx_citemacro_cite">Sainath et al. (<a href="#bib.bib97" title="" class="ltx_ref">2015</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Graves et al. (<a href="#bib.bib98" title="" class="ltx_ref">2013</a>)</cite>, segmentation <cite class="ltx_cite ltx_citemacro_cite">Badrinarayanan et al. (<a href="#bib.bib99" title="" class="ltx_ref">2017</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a href="#bib.bib100" title="" class="ltx_ref">2018</a>)</cite>, machine translation <cite class="ltx_cite ltx_citemacro_cite">Vinyals et al. (<a href="#bib.bib101" title="" class="ltx_ref">2014</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Liu and Zhang (<a href="#bib.bib102" title="" class="ltx_ref">2018</a>)</cite>, scene description <cite class="ltx_cite ltx_citemacro_cite">Karpathy and Fei-Fei (<a href="#bib.bib103" title="" class="ltx_ref">2015</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Pinheiro and Collobert (<a href="#bib.bib104" title="" class="ltx_ref">2014</a>)</cite>, weather forecasting <cite class="ltx_cite ltx_citemacro_cite">Grover et al. (<a href="#bib.bib105" title="" class="ltx_ref">2015</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Hossain et al. (<a href="#bib.bib106" title="" class="ltx_ref">2015</a>)</cite>, cancer detection <cite class="ltx_cite ltx_citemacro_cite">Albarqouni et al. (<a href="#bib.bib107" title="" class="ltx_ref">2016</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib108" title="" class="ltx_ref">2016</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Cruz-Roa et al. (<a href="#bib.bib109" title="" class="ltx_ref">2013</a>)</cite>, self-driving cars <cite class="ltx_cite ltx_citemacro_cite">Uçar et al. (<a href="#bib.bib110" title="" class="ltx_ref">2017</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a href="#bib.bib111" title="" class="ltx_ref">2015</a>)</cite> and other adaptive systems. With such challenges, the comparison of present trends in the application of activation functions employed in deep learning, portrays a gap of literature in this direction.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i2.p1.1" class="ltx_p">Deep learning performs most of the things that are familiar to machine learning approaches. Deep learning techniques can be used both in supervised learning based applications that require prediction of one or more outcomes or labels related to each data point in place of regression approaches, as well as in unsupervised learning based applications that need summary, explanation and identification of interesting patterns in a data set in the form of clustering.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i3.p1.1" class="ltx_p">Deep learning techniques surpass the existing state of the art in various studies of healthcare like patient and disease categorization, basic biological study, genomics and treatment development.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i4.p1.1" class="ltx_p">Despite deep learning has dominated over competing machine learning approaches in many fields and made quantitative improvements in predictive performance, deep learning has yet to solve many problems. Deep learning has not completely transformed the study of human disease. It has yet to realize its trans-formative strength and to encourage a strategic inflection point.</p>
</div>
</li>
<li id="S5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i5.p1.1" class="ltx_p">Using deep learning in speech recognition, there have been great performance improvements with error rates dropped from more than 20% to less than 6% and exceeded human performance in the past years <cite class="ltx_cite ltx_citemacro_cite">Xiong et al. (<a href="#bib.bib112" title="" class="ltx_ref">2017</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Saon et al. (<a href="#bib.bib113" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
</li>
<li id="S5.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i6.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i6.p1.1" class="ltx_p">In medical imaging, diabetic macular oedema <cite class="ltx_cite ltx_citemacro_cite">Gulshan et al. (<a href="#bib.bib114" title="" class="ltx_ref">2016</a>)</cite>, diabetic retinopathy <cite class="ltx_cite ltx_citemacro_cite">Gulshan et al. (<a href="#bib.bib114" title="" class="ltx_ref">2016</a>)</cite>, skin lesion <cite class="ltx_cite ltx_citemacro_cite">Esteva et al. (<a href="#bib.bib115" title="" class="ltx_ref">2017</a>)</cite> and tuberculosis <cite class="ltx_cite ltx_citemacro_cite">Lakhani and Sundaram (<a href="#bib.bib116" title="" class="ltx_ref">2017</a>)</cite>, deep learning based classifiers are greatly successful and can be compared to clinical performance. Some of these areas, we have surpassed the lofty bar than others, generally, those that are more similar to the non-biomedical tasks that are now monopolized by deep learning. Deep learning can point experts to the most challenging cases that require manual review, even if the risk of false negatives must be addressed.</p>
</div>
</li>
<li id="S5.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i7.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i7.p1.1" class="ltx_p">Deep learning techniques also prioritize experiments and assist discovery. As an illustration, in chemical screening for discovery of drugs, a deep learning system can successfully identify hundreds of target-specific, active small molecules from an immense search space and it would have great practical value even though its total precision is modest.</p>
</div>
</li>
<li id="S5.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i8.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i8.p1.1" class="ltx_p">The deep neural networks can be built resistant to the adversarial attacks. Further, there is also possibility to design reliable adversarial training methods. Thus, the findings from existing deep learning studies provide motivation for having adversarial robust deep learning models within current reach.</p>
</div>
</li>
<li id="S5.I1.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i9.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i9.p1.1" class="ltx_p">Deep learning has witnessed for a great achievement of human level performance across a number of domains in biomedical science. But deep neural networks as other machine learning algorithms are also prone to errors that are also made by humans most likely, such as miss-classification of adversarial examples <cite class="ltx_cite ltx_citemacro_cite">Szegedy et al. (<a href="#bib.bib117" title="" class="ltx_ref">2013</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Goodfellow et al. (<a href="#bib.bib118" title="" class="ltx_ref">2014</a>)</cite>, and it can be considered that the semantics of the objects presented cannot be completely understood by these algorithms. But the alliance between deep learning algorithms and human experts addresses most of these challenges and can result in better performance than either individually <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib108" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
</li>
<li id="S5.I1.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i10.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i10.p1.1" class="ltx_p">We are confident about deep learning’s future in machine learning. It is certain that the deep learning will surely revolutionize these fields, but given how rapidly these areas are evolving, we are optimistic that its full potential has not been explored yet. There are various challenges beyond improving the training and predictive accuracies. Ongoing research has begun to address most problems in these directions and proved that they are not insuperable.</p>
</div>
</li>
<li id="S5.I1.i11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i11.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i11.p1.1" class="ltx_p">Deep learning provides a flexible way to model data in its natural form, as an illustration, molecular graphs instead of pre-computed bit vectors for drug discovery and longer DNA sequences instead of k-mers for TF binding forecasting. This kind of flexible input feature interpretations have incited creative modelling approaches that are not feasible with rest of machine learning techniques. In forthcoming years, large collections of input data can be summarized into interpretable models by deep learning algorithms, and it will encourage scientists to ask those questions which they do not know how to ask.</p>
</div>
</li>
<li id="S5.I1.i12" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i12.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i12.p1.1" class="ltx_p">Although the deep learning has yet to attain more, existing studies show that it possesses the capability of faster and more reliable results. That power may well trigger a shift away from the currently employed decision support methods, such as support vector machines and k-nearest neighbour, towards deep learning.</p>
</div>
</li>
<li id="S5.I1.i13" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i13.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i13.p1.1" class="ltx_p">Deep leaning training algorithms have a high computational complexity and it results to high run time complexity that translates into a long training time use. After choosing the architecture, there is always a need to adjust the tuning parameters. The model is influenced by both the structure selection and parameter adjustment. So, there is need to have many test runs. Reducing the deep leaning models’ training phase is an active area of research. One of the challenges in deep learning is increasing the training process speed in a parallel distributed processing system <cite class="ltx_cite ltx_citemacro_cite">Chen and Lin (<a href="#bib.bib119" title="" class="ltx_ref">2014</a>)</cite>. As the network for individual processors becomes the bottle neck <cite class="ltx_cite ltx_citemacro_cite">Najafabadi et al. (<a href="#bib.bib120" title="" class="ltx_ref">2015</a>)</cite> then GPUs are used to reduce the network latency <cite class="ltx_cite ltx_citemacro_cite">Bergstra et al. (<a href="#bib.bib121" title="" class="ltx_ref">2011</a>)</cite>.</p>
</div>
</li>
<li id="S5.I1.i14" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i14.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i14.p1.1" class="ltx_p">Deep learning faces certain challenges as: using deep learning for big data analysis, dealing causality in learning, scalability of approaches in deep learning, data generating ability when data does not exist for learning the system, need of energy efficient techniques for special purpose devices, learning from different domains or models together.</p>
</div>
</li>
<li id="S5.I1.i15" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i15.p1" class="ltx_para ltx_noindent">
<p id="S5.I1.i15.p1.1" class="ltx_p">Although, present deep learning models works splendidly in various applications, but the solid theory of deep learning still lacks. It is not mostly known that why and how it works essentially. It is required to make more endeavours to investigate the basic principles of deep learning. In the meantime, it is very worth on exploring how to leverage natural visual perception mechanism for further improvement in the design of deep learning models.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">The recent decade observed an increasingly rapid progress in technology, mainly backed up by the advancements in the area of deep learning and artificial intelligence. The present paper presented various architectures of deep learning and surveyed the current state-of-the-art on deep learning technologies used in handwriting recognition domain. After reviewing so many papers, the present study is able to distil the perfect deep learning methods and architectures for different handwriting recognition tasks and general observations on other related application areas too. The CNN and its derivatives are the out performers in most image analysis areas, and RNN and its derivatives are out performers in dealing with sequence data. Further, an outstanding conclusion can be drawn that the exact architecture of deep learning is an important determinant for finding a good solution in many problems. The present survey not only given a snapshot of the existing deep learning research status in handwriting recognition but also made an effort for identification of the future roadway for intended researchers. The findings indicate that there are remarkable opportunities in the deep learning research and it shows that they will not disappear anytime soon. So, the present study encourages future researchers that are interested in the area to start exploring as it currently seems to be wide open for new studies.
<br class="ltx_break"></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">David L. Poole [2010]</span>
<span class="ltx_bibblock">
Alan K. Mackworth David L. Poole.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence: Foundations of Computational Agents</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press, 2010.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elaine Rich [2010]</span>
<span class="ltx_bibblock">
Shivashankar B. Nair Elaine Rich, Kevin Knight.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence</em>.

</span>
<span class="ltx_bibblock">Tata McGraw Hill, 2010.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zawacki-Richter et al. [2019]</span>
<span class="ltx_bibblock">
Olaf Zawacki-Richter, Victoria I. Marín, Melissa Bond, and Franziska
Gouverneur.

</span>
<span class="ltx_bibblock">Systematic review of research on artificial intelligence applications
in higher education – where are the educators?

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">International Journal of Educational Technology in Higher
Education</em>, 16(1):39, Oct 2019.

</span>
<span class="ltx_bibblock">ISSN 2365-9440.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1186/s41239-019-0171-0" title="" class="ltx_ref ltx_href">10.1186/s41239-019-0171-0</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1186/s41239-019-0171-0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1186/s41239-019-0171-0</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2020]</span>
<span class="ltx_bibblock">
L. Chen, P. Chen, and Z. Lin.

</span>
<span class="ltx_bibblock">Artificial intelligence in education: A review.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 8:75264–75278, 2020.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/ACCESS.2020.2988510" title="" class="ltx_ref ltx_href">10.1109/ACCESS.2020.2988510</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nilsson [2010]</span>
<span class="ltx_bibblock">
Nils J. Nilsson.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">The Quest for Artificial Intelligence: A history of ideas and
achievements</em>.

</span>
<span class="ltx_bibblock">Cambridge University Press, 2010.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodrich and Schultz [2007]</span>
<span class="ltx_bibblock">
Michael A. Goodrich and Alan C. Schultz.

</span>
<span class="ltx_bibblock">Human-robot interaction: A survey.

</span>
<span class="ltx_bibblock">1(3):203–275, January 2007.

</span>
<span class="ltx_bibblock">ISSN 1551-3955.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1561/1100000005" title="" class="ltx_ref ltx_href">10.1561/1100000005</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1561/1100000005" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1561/1100000005</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Buczak and Guven [2016]</span>
<span class="ltx_bibblock">
A. L. Buczak and E. Guven.

</span>
<span class="ltx_bibblock">A survey of data mining and machine learning methods for cyber
security intrusion detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys Tutorials</em>, 18(2):1153–1176, 2016.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/COMST.2015.2494502" title="" class="ltx_ref ltx_href">10.1109/COMST.2015.2494502</a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahrammirzaee [2010]</span>
<span class="ltx_bibblock">
Arash Bahrammirzaee.

</span>
<span class="ltx_bibblock">A comparative survey of artificial intelligence applications in
finance: Artificial neural networks, expert system and hybrid intelligent
systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">International Journal of Neural Computing and Application</em>,
Available online 20 June 2010, 11 2010.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1007/s00521-010-0362-z" title="" class="ltx_ref ltx_href">10.1007/s00521-010-0362-z</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bengio et al. [2013]</span>
<span class="ltx_bibblock">
Y. Bengio, A. Courville, and P. Vincent.

</span>
<span class="ltx_bibblock">Representation learning: A review and new perspectives.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 35(8):1798–1828, 2013.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/TPAMI.2013.50" title="" class="ltx_ref ltx_href">10.1109/TPAMI.2013.50</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brougham and Haar [2018]</span>
<span class="ltx_bibblock">
David Brougham and Jarrod Haar.

</span>
<span class="ltx_bibblock">Smart technology, artificial intelligence, robotics, and algorithms
(stara): Employees’ perceptions of our future workplace.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Journal of Management &amp; Organization</em>, 24(2):239–257, 2018.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1017/jmo.2016.55" title="" class="ltx_ref ltx_href">10.1017/jmo.2016.55</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corvalan [2018]</span>
<span class="ltx_bibblock">
Juan Gustavo Corvalan.

</span>
<span class="ltx_bibblock">Artificial intelligence: Challenges and opportunities-prometea: The
first artificial intelligence of latin america at the service of the justice
system.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Revista de Investigações Constitucionais</em>, 5:295 –
316, 04 2018.

</span>
<span class="ltx_bibblock">ISSN 2359-5639.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="http://www.scielo.br/scielo.php?script=sci_arttext&amp;pid=S2359-56392018000100295&amp;nrm=iso" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.scielo.br/scielo.php?script=sci_arttext&amp;pid=S2359-56392018000100295&amp;nrm=iso</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghahramani [2015]</span>
<span class="ltx_bibblock">
Zoubin Ghahramani.

</span>
<span class="ltx_bibblock">Probabilistic machine learning and artificial intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 521(7553):452–459, May 2015.

</span>
<span class="ltx_bibblock">ISSN 1476-4687.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1038/nature14541" title="" class="ltx_ref ltx_href">10.1038/nature14541</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1038/nature14541" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/nature14541</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
D. Castelvecchi.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McDonald [1989]</span>
<span class="ltx_bibblock">
Carlton McDonald.

</span>
<span class="ltx_bibblock">Machine learning: a survey of current techniques.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence Review</em>, 3(4):243–280, Dec 1989.

</span>
<span class="ltx_bibblock">ISSN 1573-7462.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1007/BF00141197" title="" class="ltx_ref ltx_href">10.1007/BF00141197</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1007/BF00141197" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/BF00141197</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Musumeci et al. [2019]</span>
<span class="ltx_bibblock">
F. Musumeci, C. Rottondi, A. Nag, I. Macaluso, D. Zibar,
M. Ruffini, and M. Tornatore.

</span>
<span class="ltx_bibblock">An overview on application of machine learning techniques in optical
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys Tutorials</em>, 21(2):1383–1408, 2019.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/COMST.2018.2880039" title="" class="ltx_ref ltx_href">10.1109/COMST.2018.2880039</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bishop [2006]</span>
<span class="ltx_bibblock">
C.M. Bishop.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Pattern recognition and machine learning</em>.

</span>
<span class="ltx_bibblock">Springer, 2006.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chapelle et al. [2006]</span>
<span class="ltx_bibblock">
O. Chapelle, B. Schölkopf, and A. Zien.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Semi-supervised learning (1st ed.)</em>.

</span>
<span class="ltx_bibblock">The MIT Press, 2006.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collobert et al. [2011]</span>
<span class="ltx_bibblock">
R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa.

</span>
<span class="ltx_bibblock">Natural language processing (almost) from scratch.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 12:2493–2537, 2011.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J. Du, C.X. Ling, and Z.H. Zhou.

</span>
<span class="ltx_bibblock">When does cotraining work in real data?

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freund and Schapire [1997]</span>
<span class="ltx_bibblock">
Y. Freund and R.E. Schapire.

</span>
<span class="ltx_bibblock">A decision-theoretic generalization of on-line learning and an
application to boosting.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Journal of Computer and System Sciences</em>, 55(1):119–139, 1997.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grira et al. [2004]</span>
<span class="ltx_bibblock">
N. Grira, M. Crucianu, and N. Boujemaa.

</span>
<span class="ltx_bibblock">Unsupervised and semisupervised clustering: A brief survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">In 7th ACM SIGMM international workshop on multimedia
information retrieval</em>, 2004.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guyon and Elisseeff [2006]</span>
<span class="ltx_bibblock">
I. Guyon and A. Elisseeff.

</span>
<span class="ltx_bibblock">An introduction to feature extraction.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Feature extraction</em>, page 1–25, 2006.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. [2015a]</span>
<span class="ltx_bibblock">
Y. LeCun, Y. Bengio, and G. Hinton.

</span>
<span class="ltx_bibblock">Deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 521:436–444, 2015a.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pedregosa et al. [2011]</span>
<span class="ltx_bibblock">
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.

</span>
<span class="ltx_bibblock">Scikit-learn: Machine learning in python.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 12:2825–2830, 2011.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vapnik [1998]</span>
<span class="ltx_bibblock">
V. Vapnik.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Statistical learning theory (Vol. 1)</em>.

</span>
<span class="ltx_bibblock">New York: Wiley, 1998.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdel-Hamid et al. [2014]</span>
<span class="ltx_bibblock">
O. Abdel-Hamid, A. R. Mohamed, L. Deng H. Jiang, G. Penn, and D. Yu.

</span>
<span class="ltx_bibblock">Convolutional neural networks for speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language
Processing</em>, 22(10):1533–1545, 2014.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al. [2014]</span>
<span class="ltx_bibblock">
K. Cho, B. Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and
Yoshua Bengio.

</span>
<span class="ltx_bibblock">Learning phrase representations using rnn encoder-decoder for
statistical machine translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">In The Conference on Empirical Methods in Natural Language
Processing</em>, pages 1724–1734, 2014.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2017]</span>
<span class="ltx_bibblock">
Y. Zhao, X. Jin, and X. Hu.

</span>
<span class="ltx_bibblock">Recurrent convolutional neural networks for speech processing.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">In IEEE International Conference on Acoustics, Speech and
Signal Processing</em>, pages 5300–5304, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCulloch and Pitts [1943]</span>
<span class="ltx_bibblock">
WS. McCulloch and W. Pitts.

</span>
<span class="ltx_bibblock">A logical calculus of the ideas immanent in nervous activity.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Bull Math Biophys</em>, 5, 1943.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hebb [1949]</span>
<span class="ltx_bibblock">
D.O. Hebb.

</span>
<span class="ltx_bibblock">The organization of behavior.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">New York: Wiley &amp; Sons</em>, 1949.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rossenblatt [1958]</span>
<span class="ltx_bibblock">
F. Rossenblatt.

</span>
<span class="ltx_bibblock">The perceptron: A probabilistic model for information storage and
organization in the brain.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Psychological Review</em>, 65(6):386–408,
1958.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Windrow and Hoff [1960]</span>
<span class="ltx_bibblock">
B. Windrow and M.E. Hoff.

</span>
<span class="ltx_bibblock">Adaptive switching circuits.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IRE WESCON Convention Record</em>, 4(96-104), 1960.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kohonen [1982]</span>
<span class="ltx_bibblock">
T. Kohonen.

</span>
<span class="ltx_bibblock">Self-organized formation of topologically correct feature maps.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Biol. Cybern</em>, 43:59–69, 1982.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hopfield [1982]</span>
<span class="ltx_bibblock">
J.J. Hopfield.

</span>
<span class="ltx_bibblock">Neural networks and physical systems with emergent collective
computational abilities.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the National Academy of Sciences of the USA</em>,
79(8):2554–2558, 1982.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rumelhart et al. [1986]</span>
<span class="ltx_bibblock">
D. Rumelhart, G. Hinton, and R. Williams.

</span>
<span class="ltx_bibblock">Learning representations by back-propagating errors.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">nature</em>, 323:533–536, 1986.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carpenter and Grossberg [1988]</span>
<span class="ltx_bibblock">
Gail A. Carpenter and Stephen Grossberg.

</span>
<span class="ltx_bibblock">The art of adaptive pattern recognition by a self-organizing neural
network.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Computer</em>, 21(3):77–88, 1988.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Broomhead and Lowe [1988]</span>
<span class="ltx_bibblock">
D.S. Broomhead and D. Lowe.

</span>
<span class="ltx_bibblock">Multivariable functional interpolation and adaptive networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Complex Systems</em>, 2:321–355, 1988.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fukushima [2010]</span>
<span class="ltx_bibblock">
Kunihiko Fukushima.

</span>
<span class="ltx_bibblock">Neocognitron trained with winner-kill-loser rule.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Neural Netw.</em>, 23(7):926–938, 2010.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haykin [1998]</span>
<span class="ltx_bibblock">
Simon Haykin.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Neural Networks: A Comprehensive Foundation</em>.

</span>
<span class="ltx_bibblock">Prentice Hall PTR, 2nd edition, 1998.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky et al. [2012]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, pages
1097–1105, 2012.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szegedy et al. [2015a]</span>
<span class="ltx_bibblock">
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.

</span>
<span class="ltx_bibblock">Going deeper with convolutions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, June 2015a.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taigman et al. [2014]</span>
<span class="ltx_bibblock">
Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf.

</span>
<span class="ltx_bibblock">Deepface: Closing the gap to human-level performance in face
verification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 1701–1708, 2014.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simard et al. [2003]</span>
<span class="ltx_bibblock">
Patrice Y Simard, David Steinkraus, John C Platt, et al.

</span>
<span class="ltx_bibblock">Best practices for convolutional neural networks applied to visual
document analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">ICDAR</em>, volume 3, 2003.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ciresan et al. [2011]</span>
<span class="ltx_bibblock">
D. C. Ciresan, U. Meier, L. M. Gambardella, and J. Schmidhuber.

</span>
<span class="ltx_bibblock">Convolutional neural network committees for handwritten character
classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">In: Proceedings of the International Conference on Document
Analysis and Recognition</em>, pages 1135 – 1139, 2011.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ciregan et al. [2012]</span>
<span class="ltx_bibblock">
Dan Ciregan, Ueli Meier, and Jürgen Schmidhuber.

</span>
<span class="ltx_bibblock">Multi-column deep neural networks for image classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">2012 IEEE conference on computer vision and pattern
recognition</em>, pages 3642–3649. IEEE, 2012.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2012]</span>
<span class="ltx_bibblock">
Tao Wang, David J Wu, Adam Coates, and Andrew Y Ng.

</span>
<span class="ltx_bibblock">End-to-end text recognition with convolutional neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 21st International Conference on Pattern
Recognition (ICPR2012)</em>, pages 3304–3308. IEEE, 2012.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. [2013]</span>
<span class="ltx_bibblock">
Ian J Goodfellow, Yaroslav Bulatov, Julian Ibarz, Sacha Arnoud, and Vinay Shet.

</span>
<span class="ltx_bibblock">Multi-digit number recognition from street view imagery using deep
convolutional neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6082</em>, 2013.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tompson et al. [2014]</span>
<span class="ltx_bibblock">
Jonathan J Tompson, Arjun Jain, Yann LeCun, and Christoph Bregler.

</span>
<span class="ltx_bibblock">Joint training of a convolutional network and a graphical model for
human pose estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, pages
1799–1807, 2014.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. [2015b]</span>
<span class="ltx_bibblock">
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">nature</em>, 521(7553):436–444,
2015b.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. [2016]</span>
<span class="ltx_bibblock">
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Deep Learning</em>.

</span>
<span class="ltx_bibblock">MIT Press, 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.deeplearningbook.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.deeplearningbook.org</a>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bengio et al. [1994]</span>
<span class="ltx_bibblock">
Y. Bengio, P. Simard, and P. Frasconi.

</span>
<span class="ltx_bibblock">Learning long-term dependencies with gradient descent is difficult.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks</em>, 5(2):157–166, March 1994.

</span>
<span class="ltx_bibblock">ISSN 1045-9227.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/72.279181" title="" class="ltx_ref ltx_href">10.1109/72.279181</a>.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lecun et al. [1998]</span>
<span class="ltx_bibblock">
Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner.

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, 86(11):2278–2324, Nov 1998.

</span>
<span class="ltx_bibblock">ISSN 1558-2256.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/5.726791" title="" class="ltx_ref ltx_href">10.1109/5.726791</a>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. [1998]</span>
<span class="ltx_bibblock">
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner.

</span>
<span class="ltx_bibblock">Gradient-based learning applied to document recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, 86(11):2278–2324, 1998.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fukushima and Miyake [1982]</span>
<span class="ltx_bibblock">
Kunihiko Fukushima and Sei Miyake.

</span>
<span class="ltx_bibblock">Neocognitron: A self-organizing neural network model for a mechanism
of visual pattern recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Competition and cooperation in neural nets</em>, pages 267–285.
Springer, 1982.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lo et al. [1995]</span>
<span class="ltx_bibblock">
S-CB Lo, S-LA Lou, Jyh-Shyan Lin, Matthew T Freedman, Minze V Chien, and
Seong Ki Mun.

</span>
<span class="ltx_bibblock">Artificial convolution neural network techniques and applications for
lung nodule detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on medical imaging</em>, 14(4):711–718, 1995.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Russakovsky et al. [2015]</span>
<span class="ltx_bibblock">
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al.

</span>
<span class="ltx_bibblock">Imagenet large scale visual recognition challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">International journal of computer vision</em>, 115(3):211–252, 2015.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sak et al. [2014]</span>
<span class="ltx_bibblock">
H. Sak, Andrew Senior, and F. Beaufays.

</span>
<span class="ltx_bibblock">Long short-term memory recurrent neural network architectures for
large scale acoustic modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Annual Conference of the International
Speech Communication Association, INTERSPEECH</em>, pages 338–342, 01 2014.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Wu [2015]</span>
<span class="ltx_bibblock">
X. Li and X. Wu.

</span>
<span class="ltx_bibblock">Constructing long short-term memory based deep recurrent neural
networks for large vocabulary speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">2015 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP)</em>, pages 4520–4524, April 2015.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/ICASSP.2015.7178826" title="" class="ltx_ref ltx_href">10.1109/ICASSP.2015.7178826</a>.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. [2009]</span>
<span class="ltx_bibblock">
A. Graves, M. Liwicki, S. Fernández, R. Bertolami, H. Bunke, and
J. Schmidhuber.

</span>
<span class="ltx_bibblock">A novel connectionist system for unconstrained handwriting
recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 31(5):855–868, May 2009.

</span>
<span class="ltx_bibblock">ISSN 0162-8828.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/TPAMI.2008.137" title="" class="ltx_ref ltx_href">10.1109/TPAMI.2008.137</a>.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hochreiter and Schmidhuber [1997]</span>
<span class="ltx_bibblock">
Sepp Hochreiter and Jürgen Schmidhuber.

</span>
<span class="ltx_bibblock">Long short-term memory.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Neural Comput.</em>, 9(8):1735–1780, nov 1997.

</span>
<span class="ltx_bibblock">ISSN 0899-7667.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1162/neco.1997.9.8.1735" title="" class="ltx_ref ltx_href">10.1162/neco.1997.9.8.1735</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1162/neco.1997.9.8.1735" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1162/neco.1997.9.8.1735</a>.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gers and Schmidhuber [2000]</span>
<span class="ltx_bibblock">
Felix A Gers and Jürgen Schmidhuber.

</span>
<span class="ltx_bibblock">Recurrent nets that time and count.

</span>
<span class="ltx_bibblock">In <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE-INNS-ENNS International Joint
Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges
and Perspectives for the New Millennium</em>, volume 3, pages 189–194. IEEE,
2000.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al. [2014]</span>
<span class="ltx_bibblock">
Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Empirical evaluation of gated recurrent neural networks on sequence
modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.3555</em>, 2014.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuster and Paliwal [1997]</span>
<span class="ltx_bibblock">
M. Schuster and K. K. Paliwal.

</span>
<span class="ltx_bibblock">Bidirectional recurrent neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Signal Processing</em>, 45(11):2673–2681, Nov 1997.

</span>
<span class="ltx_bibblock">ISSN 1053-587X.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/78.650093" title="" class="ltx_ref ltx_href">10.1109/78.650093</a>.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu [2021]</span>
<span class="ltx_bibblock">
Emily Xiaoxuan Gu.

</span>
<span class="ltx_bibblock">Convolutional neural network based kannada-mnist classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on Consumer Electronics
and Computer Engineering (ICCECE)</em>, pages 180–185, 2021.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/ICCECE51280.2021.9342474" title="" class="ltx_ref ltx_href">10.1109/ICCECE51280.2021.9342474</a>.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta and Bag [2021]</span>
<span class="ltx_bibblock">
Deepika Gupta and Soumen Bag.

</span>
<span class="ltx_bibblock">Cnn-based multilingual handwritten numeral recognition: A fusion-free
approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em>, 165:113784, 2021.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kusetogullari et al. [2020]</span>
<span class="ltx_bibblock">
Huseyin Kusetogullari, Amir Yavariabdi, Abbas Cheddad, Håkan Grahn, and
Johan Hall.

</span>
<span class="ltx_bibblock">Ardis: a swedish historical handwritten digit dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Neural Computing and Applications</em>, 32(21):16505–16518, 2020.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">GATI et al. [2019]</span>
<span class="ltx_bibblock">
ELVIS S. GATI, BENJAMIN D. NIMO, and ELISHA K. ASIAMAH.

</span>
<span class="ltx_bibblock">Kannada-mnist classification using skip cnn.

</span>
<span class="ltx_bibblock">In <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">2019 16th International Computer Conference on Wavelet
Active Media Technology and Information Processing</em>, pages 245–248, 2019.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/ICCWAMTIP47768.2019.9067521" title="" class="ltx_ref ltx_href">10.1109/ICCWAMTIP47768.2019.9067521</a>.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al. [2020]</span>
<span class="ltx_bibblock">
Sukhdeep Singh, Vinod Kumar Chauhan, and Elisa H Barney Smith.

</span>
<span class="ltx_bibblock">A self controlled rdp approach for feature extraction in online
handwriting recognition using deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">Applied Intelligence</em>, 50(7):2093–2104,
2020.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prabhu [2019]</span>
<span class="ltx_bibblock">
Vinay Uday Prabhu.

</span>
<span class="ltx_bibblock">Kannada-mnist: A new handwritten digits dataset for the kannada
language, 2019.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Manjusha et al. [2019]</span>
<span class="ltx_bibblock">
K. Manjusha, M. Anand Kumar, and K.P. Soman.

</span>
<span class="ltx_bibblock">On developing handwritten character image database for malayalam
language script.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Engineering Science and Technology, an International Journal</em>,
22(2):637–645, 2019.

</span>
<span class="ltx_bibblock">ISSN 2215-0986.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.jestch.2018.10.011" title="" class="ltx_ref ltx_href">https://doi.org/10.1016/j.jestch.2018.10.011</a>.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S2215098618301447" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S2215098618301447</a>.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhury et al. [2019]</span>
<span class="ltx_bibblock">
Rumman Rashid Chowdhury, Mohammad Shahadat Hossain, Raihan ul Islam, Karl
Andersson, and Sazzad Hossain.

</span>
<span class="ltx_bibblock">Bangla handwritten character recognition using convolutional neural
network with data augmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">2019 Joint 8th international conference on informatics,
electronics &amp; vision (ICIEV) and 2019 3rd international conference on
imaging, vision &amp; pattern recognition (icIVPR)</em>, pages 318–323. IEEE, 2019.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. [2019]</span>
<span class="ltx_bibblock">
Anisha Gupta, Ritesh Sarkhel, Nibaran Das, and Mahantapas Kundu.

</span>
<span class="ltx_bibblock">Multiobjective optimization for recognition of isolated handwritten
indic scripts.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition Letters</em>, 128:318–325, 2019.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chakraborty et al. [2019]</span>
<span class="ltx_bibblock">
Sinjan Chakraborty, Sayantan Paul, Ram Sarkar, and Mita Nasipuri.

</span>
<span class="ltx_bibblock">Feature map reduction in cnn for handwritten digit recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Recent Developments in Machine Learning and Data Analytics</em>,
pages 143–148. Springer, 2019.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arora and Bhatia [2018]</span>
<span class="ltx_bibblock">
Shefali Arora and M. P. S Bhatia.

</span>
<span class="ltx_bibblock">Handwriting recognition using deep learning in keras.

</span>
<span class="ltx_bibblock">In <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">2018 International Conference on Advances in Computing,
Communication Control and Networking (ICACCCN)</em>, pages 142–145, 2018.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/ICACCCN.2018.8748540" title="" class="ltx_ref ltx_href">10.1109/ICACCCN.2018.8748540</a>.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Manjusha et al. [2018]</span>
<span class="ltx_bibblock">
K Manjusha, M Anand Kumar, and KP Soman.

</span>
<span class="ltx_bibblock">Integrating scattering feature maps with convolutional neural
networks for malayalam handwritten character recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">International Journal on Document Analysis and Recognition
(IJDAR)</em>, 21(3):187–198, 2018.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et al. [2018]</span>
<span class="ltx_bibblock">
Lei Kang, J Ignacio Toledo, Pau Riba, Mauricio Villegas, Alicia Fornés, and
Marçal Rusinol.

</span>
<span class="ltx_bibblock">Convolve, attend and spell: An attention-based sequence-to-sequence
model for handwritten word recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">German Conference on Pattern Recognition</em>, pages 459–472.
Springer, 2018.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarkhel et al. [2017]</span>
<span class="ltx_bibblock">
Ritesh Sarkhel, Nibaran Das, Aritra Das, Mahantapas Kundu, and Mita Nasipuri.

</span>
<span class="ltx_bibblock">A multi-scale deep quad tree based feature extraction method for the
recognition of isolated handwritten characters of popular indic scripts.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 71:78–93, 2017.

</span>
<span class="ltx_bibblock">ISSN 0031-3203.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.patcog.2017.05.022" title="" class="ltx_ref ltx_href">https://doi.org/10.1016/j.patcog.2017.05.022</a>.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0031320317302200" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S0031320317302200</a>.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poznanski and Wolf [2016]</span>
<span class="ltx_bibblock">
Arik Poznanski and Lior Wolf.

</span>
<span class="ltx_bibblock">Cnn-n-gram for handwriting word recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, June 2016.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim and Xie [2015]</span>
<span class="ltx_bibblock">
In-Jung Kim and Xiaohui Xie.

</span>
<span class="ltx_bibblock">Handwritten hangul recognition using deep convolutional neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">International Journal on Document Analysis and Recognition
(IJDAR)</em>, 18:1–13, 2015.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1007/s10032-014-0229-4" title="" class="ltx_ref ltx_href">10.1007/s10032-014-0229-4</a>.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. [2013]</span>
<span class="ltx_bibblock">
Li Wan, Matthew Zeiler, Sixin Zhang, Yann Le Cun, and Rob Fergus.

</span>
<span class="ltx_bibblock">Regularization of neural networks using dropconnect.

</span>
<span class="ltx_bibblock">In <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, pages
1058–1066. PMLR, 2013.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et al. [2012]</span>
<span class="ltx_bibblock">
Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and
Ruslan R Salakhutdinov.

</span>
<span class="ltx_bibblock">Improving neural networks by preventing co-adaptation of feature
detectors.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1207.0580</em>, 2012.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pham et al. [2014]</span>
<span class="ltx_bibblock">
Vu Pham, Théodore Bluche, Christopher Kermorvant, and Jérôme
Louradour.

</span>
<span class="ltx_bibblock">Dropout improves recurrent neural networks for handwriting
recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">2014 14th international conference on frontiers in
handwriting recognition</em>, pages 285–290. IEEE, 2014.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doetsch et al. [2014]</span>
<span class="ltx_bibblock">
Patrick Doetsch, Michal Kozielski, and Hermann Ney.

</span>
<span class="ltx_bibblock">Fast and robust training of recurrent neural networks for offline
handwriting recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">2014 14th International Conference on Frontiers in
Handwriting Recognition</em>, pages 279–284. IEEE, 2014.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chollet et al. [2015]</span>
<span class="ltx_bibblock">
Francois Chollet et al.

</span>
<span class="ltx_bibblock">Keras, 2015.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://github.com/fchollet/keras" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/fchollet/keras</a>.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chherawala et al. [2016]</span>
<span class="ltx_bibblock">
Youssouf Chherawala, Partha Pratim Roy, and Mohamed Cheriet.

</span>
<span class="ltx_bibblock">Feature set evaluation for offline handwriting recognition systems:
Application to the recurrent neural network model.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Cybernetics</em>, 46(12):2825–2836, Dec 2016.

</span>
<span class="ltx_bibblock">ISSN 2168-2275.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/TCYB.2015.2490165" title="" class="ltx_ref ltx_href">10.1109/TCYB.2015.2490165</a>.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shkarupa et al. [2016]</span>
<span class="ltx_bibblock">
Yaroslav Shkarupa, Roberts Mencis, and Matthia Sabatelli.

</span>
<span class="ltx_bibblock">Offline handwriting recognition using lstm recurrent neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">The 28th Benelux conference on artificial intelligence</em>,
2016.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wigington et al. [2017]</span>
<span class="ltx_bibblock">
Curtis Wigington, Seth Stewart, Brian Davis, Bill Barrett, Brian Price, and
Scott Cohen.

</span>
<span class="ltx_bibblock">Data augmentation for recognition of handwritten words and lines
using a cnn-lstm network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">2017 14th IAPR International Conference on Document Analysis
and Recognition (ICDAR)</em>, volume 01, pages 639–645, 2017.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/10.1109/ICDAR.2017.110" title="" class="ltx_ref ltx_href">10.1109/ICDAR.2017.110</a>.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dutta et al. [2018]</span>
<span class="ltx_bibblock">
Kartik Dutta, Praveen Krishnan, Minesh Mathew, and CV Jawahar.

</span>
<span class="ltx_bibblock">Improving cnn-rnn hybrid networks for handwriting recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">2018 16th international conference on frontiers in
handwriting recognition (ICFHR)</em>, pages 80–85. IEEE, 2018.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishnan et al. [2018]</span>
<span class="ltx_bibblock">
Praveen Krishnan, Kartik Dutta, and CV Jawahar.

</span>
<span class="ltx_bibblock">Word spotting and recognition using deep embedding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">2018 13th IAPR International Workshop on Document Analysis
Systems (DAS)</em>, pages 1–6. IEEE, 2018.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sueiras et al. [2018]</span>
<span class="ltx_bibblock">
Jorge Sueiras, Victoria Ruiz, Angel Sanchez, and Jose F. Velez.

</span>
<span class="ltx_bibblock">Offline continuous handwriting recognition using sequence to sequence
neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, 289:119–128, 2018.

</span>
<span class="ltx_bibblock">ISSN 0925-2312.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.neucom.2018.02.008" title="" class="ltx_ref ltx_href">https://doi.org/10.1016/j.neucom.2018.02.008</a>.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0925231218301371" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S0925231218301371</a>.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosh et al. [2019]</span>
<span class="ltx_bibblock">
Rajib Ghosh, Chirumavila Vamshi, and Prabhat Kumar.

</span>
<span class="ltx_bibblock">Rnn based online handwritten word recognition in devanagari and
bengali scripts using horizontal zoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, 92:203–218, 2019.

</span>
<span class="ltx_bibblock">ISSN 0031-3203.

</span>
<span class="ltx_bibblock">doi:<a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.patcog.2019.03.030" title="" class="ltx_ref ltx_href">https://doi.org/10.1016/j.patcog.2019.03.030</a>.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.sciencedirect.com/science/article/pii/S0031320319301384" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sciencedirect.com/science/article/pii/S0031320319301384</a>.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geetha et al. [2021]</span>
<span class="ltx_bibblock">
R Geetha, T Thilagam, and T Padmavathy.

</span>
<span class="ltx_bibblock">Effective offline handwritten text recognition model based on a
sequence-to-sequence approach with cnn–rnn networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">Neural Computing and Applications</em>, 33(17):10923–10934, 2021.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koutnik et al. [2014]</span>
<span class="ltx_bibblock">
Jan Koutnik, Klaus Greff, Faustino Gomez, and Juergen Schmidhuber.

</span>
<span class="ltx_bibblock">A clockwork rnn.

</span>
<span class="ltx_bibblock">In <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
1863–1871. PMLR, 2014.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szegedy et al. [2015b]</span>
<span class="ltx_bibblock">
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.

</span>
<span class="ltx_bibblock">Going deeper with convolutions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 1–9, 2015b.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. [2015]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Delving deep into rectifiers: Surpassing human-level performance on
imagenet classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 1026–1034, 2015.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Md Noor et al. [2017]</span>
<span class="ltx_bibblock">
Siti Salwa Md Noor, Jinchang Ren, Stephen Marshall, and Kaleena Michael.

</span>
<span class="ltx_bibblock">Hyperspectral image enhancement and mixture deep-learning
classification of corneal epithelium injuries.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, 17(11):2644, 2017.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sainath et al. [2015]</span>
<span class="ltx_bibblock">
Tara N Sainath, Brian Kingsbury, George Saon, Hagen Soltau, Abdel-rahman
Mohamed, George Dahl, and Bhuvana Ramabhadran.

</span>
<span class="ltx_bibblock">Deep convolutional neural networks for large-scale speech tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Neural networks</em>, 64:39–48, 2015.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. [2013]</span>
<span class="ltx_bibblock">
Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Speech recognition with deep recurrent neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">2013 IEEE international conference on acoustics, speech and
signal processing</em>, pages 6645–6649. Ieee, 2013.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Badrinarayanan et al. [2017]</span>
<span class="ltx_bibblock">
Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla.

</span>
<span class="ltx_bibblock">Segnet: A deep convolutional encoder-decoder architecture for image
segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 39(12):2481–2495, 2017.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. [2018]</span>
<span class="ltx_bibblock">
Ronghang Hu, Piotr Dollár, Kaiming He, Trevor Darrell, and Ross Girshick.

</span>
<span class="ltx_bibblock">Learning to segment every thing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em>, pages 4233–4241, 2018.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vinyals et al. [2014]</span>
<span class="ltx_bibblock">
Oriol Vinyals, Lukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and
Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Grammar as a foreign language.

</span>
<span class="ltx_bibblock"><em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.7449</em>, 2014.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Zhang [2018]</span>
<span class="ltx_bibblock">
Yang Liu and Jiajun Zhang.

</span>
<span class="ltx_bibblock">Deep learning in machine translation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">Deep Learning in Natural Language Processing</em>, pages
147–183. Springer, 2018.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpathy and Fei-Fei [2015]</span>
<span class="ltx_bibblock">
Andrej Karpathy and Li Fei-Fei.

</span>
<span class="ltx_bibblock">Deep visual-semantic alignments for generating image descriptions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 3128–3137, 2015.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pinheiro and Collobert [2014]</span>
<span class="ltx_bibblock">
Pedro Pinheiro and Ronan Collobert.

</span>
<span class="ltx_bibblock">Recurrent convolutional neural networks for scene labeling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, pages 82–90.
PMLR, 2014.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grover et al. [2015]</span>
<span class="ltx_bibblock">
Aditya Grover, Ashish Kapoor, and Eric Horvitz.

</span>
<span class="ltx_bibblock">A deep hybrid model for weather forecasting.

</span>
<span class="ltx_bibblock">In <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 21th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining</em>, pages 379–386, 2015.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hossain et al. [2015]</span>
<span class="ltx_bibblock">
Moinul Hossain, Banafsheh Rekabdar, Sushil J Louis, and Sergiu Dascalu.

</span>
<span class="ltx_bibblock">Forecasting the weather of nevada: A deep learning approach.

</span>
<span class="ltx_bibblock">In <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">2015 international joint conference on neural networks
(IJCNN)</em>, pages 1–6. IEEE, 2015.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Albarqouni et al. [2016]</span>
<span class="ltx_bibblock">
Shadi Albarqouni, Christoph Baur, Felix Achilles, Vasileios Belagiannis,
Stefanie Demirci, and Nassir Navab.

</span>
<span class="ltx_bibblock">Aggnet: deep learning from crowds for mitosis detection in breast
cancer histology images.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on medical imaging</em>, 35(5):1313–1321, 2016.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2016]</span>
<span class="ltx_bibblock">
Dayong Wang, Aditya Khosla, Rishab Gargeya, Humayun Irshad, and Andrew H Beck.

</span>
<span class="ltx_bibblock">Deep learning for identifying metastatic breast cancer.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.05718</em>, 2016.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cruz-Roa et al. [2013]</span>
<span class="ltx_bibblock">
Angel Alfonso Cruz-Roa, John Edison Arevalo Ovalle, Anant Madabhushi, and Fabio
Augusto González Osorio.

</span>
<span class="ltx_bibblock">A deep learning architecture for image representation, visual
interpretability and automated basal-cell carcinoma cancer detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">International Conference on Medical Image Computing and
Computer-Assisted Intervention</em>, pages 403–410. Springer, 2013.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Uçar et al. [2017]</span>
<span class="ltx_bibblock">
Ayşegül Uçar, Yakup Demir, and Cüneyt Güzeliş.

</span>
<span class="ltx_bibblock">Object recognition and detection with deep learning for autonomous
driving applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">Simulation</em>, 93(9):759–769, 2017.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2015]</span>
<span class="ltx_bibblock">
Chenyi Chen, Ari Seff, Alain Kornhauser, and Jianxiong Xiao.

</span>
<span class="ltx_bibblock">Deepdriving: Learning affordance for direct perception in autonomous
driving.

</span>
<span class="ltx_bibblock">In <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 2722–2730, 2015.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al. [2017]</span>
<span class="ltx_bibblock">
W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, and
G. Zweig.

</span>
<span class="ltx_bibblock">Achieving human parity in conversational speech recognition, 2017.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saon et al. [2017]</span>
<span class="ltx_bibblock">
George Saon, Gakuto Kurata, Tom Sercu, Kartik Audhkhasi, Samuel Thomas,
Dimitrios Dimitriadis, Xiaodong Cui, Bhuvana Ramabhadran, Michael Picheny,
Lynn-Li Lim, Bergul Roomi, and Phil Hall.

</span>
<span class="ltx_bibblock">English conversational telephone speech recognition by humans and
machines, 2017.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gulshan et al. [2016]</span>
<span class="ltx_bibblock">
Varun Gulshan, Lily Peng, Marc Coram, Martin C Stumpe, Derek Wu, Arunachalam
Narayanaswamy, Subhashini Venugopalan, Kasumi Widner, Tom Madams, Jorge
Cuadros, et al.

</span>
<span class="ltx_bibblock">Development and validation of a deep learning algorithm for detection
of diabetic retinopathy in retinal fundus photographs.

</span>
<span class="ltx_bibblock"><em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Jama</em>, 316(22):2402–2410, 2016.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esteva et al. [2017]</span>
<span class="ltx_bibblock">
Andre Esteva, Brett Kuprel, Roberto A Novoa, Justin Ko, Susan M Swetter,
Helen M Blau, and Sebastian Thrun.

</span>
<span class="ltx_bibblock">Dermatologist-level classification of skin cancer with deep neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">nature</em>, 542(7639):115–118, 2017.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lakhani and Sundaram [2017]</span>
<span class="ltx_bibblock">
Paras Lakhani and Baskaran Sundaram.

</span>
<span class="ltx_bibblock">Deep learning at chest radiography: automated classification of
pulmonary tuberculosis by using convolutional neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">Radiology</em>, 284(2):574–582, 2017.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szegedy et al. [2013]</span>
<span class="ltx_bibblock">
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus.

</span>
<span class="ltx_bibblock">Intriguing properties of neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6199</em>, 2013.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. [2014]</span>
<span class="ltx_bibblock">
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.

</span>
<span class="ltx_bibblock">Explaining and harnessing adversarial examples.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6572</em>, 2014.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Lin [2014]</span>
<span class="ltx_bibblock">
Xue-Wen Chen and Xiaotong Lin.

</span>
<span class="ltx_bibblock">Big data deep learning: challenges and perspectives.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">IEEE access</em>, 2:514–525, 2014.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Najafabadi et al. [2015]</span>
<span class="ltx_bibblock">
Maryam M Najafabadi, Flavio Villanustre, Taghi M Khoshgoftaar, Naeem Seliya,
Randall Wald, and Edin Muharemagic.

</span>
<span class="ltx_bibblock">Deep learning applications and challenges in big data analytics.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">Journal of big data</em>, 2(1):1–21, 2015.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bergstra et al. [2011]</span>
<span class="ltx_bibblock">
James Bergstra, Frédéric Bastien, Olivier Breuleux, Pascal Lamblin,
Razvan Pascanu, Olivier Delalleau, Guillaume Desjardins, David Warde-Farley,
Ian Goodfellow, Arnaud Bergeron, et al.

</span>
<span class="ltx_bibblock">Theano: Deep learning on gpus with python.

</span>
<span class="ltx_bibblock">In <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">NIPS 2011, BigLearning Workshop, Granada, Spain</em>, volume 3,
pages 1–48. Citeseer, 2011.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:creator" content="David S. Hippocampus, Elias D. Striatum"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="First keyword, Second keyword, More"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="q-bio.NC, q-bio.QM"></div>
<div class="ltx_rdf" about="" property="dcterms:title" content="A template for the arxiv style"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.08010" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.08011" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.08011">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.08011" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.08013" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 16:32:26 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
