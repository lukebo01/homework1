<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.12233] SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization</title><meta property="og:description" content="Visual Speech Recognition (VSR) stands at the intersection of computer vision and speech recognition, aiming to interpret spoken content from visual cues. A prominent challenge in VSR is the presence of homophenes—visu…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.12233">

<!--Generated on Sat Jul  6 00:58:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.6" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.7" class="ltx_ERROR undefined">\name</span>
<p id="p1.5" class="ltx_p">Young Jin Ahn<sup id="p1.5.1" class="ltx_sup"><span id="p1.5.1.1" class="ltx_text ltx_font_italic">1⋆</span></sup>, Jungwoo Park<sup id="p1.5.2" class="ltx_sup"><span id="p1.5.2.1" class="ltx_text ltx_font_italic">2⋆</span></sup>, Sangha Park<sup id="p1.5.3" class="ltx_sup">3</sup>, Jonghyun Choi<sup id="p1.5.4" class="ltx_sup">4</sup>, Kee-Eung Kim<sup id="p1.5.5" class="ltx_sup">1</sup></p>
</div>
<h1 class="ltx_title ltx_title_document">SyncVSR: Data-Efficient Visual Speech Recognition with 
<br class="ltx_break">End-to-End Crossmodal Audio Token Synchronization</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Visual Speech Recognition (VSR) stands at the intersection of computer vision and speech recognition, aiming to interpret spoken content from visual cues. A prominent challenge in VSR is the presence of homophenes—visually similar lip gestures that represent different phonemes. Prior approaches have sought to distinguish fine-grained visemes by aligning visual and auditory semantics, but often fell short of full synchronization. To address this, we present SyncVSR, an end-to-end learning framework that leverages quantized audio for frame-level crossmodal supervision. By integrating a projection layer that synchronizes visual representation with acoustic data, our encoder learns to generate discrete audio tokens from a video sequence in a non-autoregressive manner. SyncVSR shows versatility across tasks, languages, and modalities at the cost of a forward pass. Our empirical evaluations show that it not only achieves state-of-the-art results but also reduces data usage by up to ninefold.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>visual speech recognition, lip-reading, crossmodal learning, end-to-end training, data efficiency
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Visual Speech Recognition (VSR), also referred to as lip-reading, constitutes the process of decoding spoken language through the observation of the visual cues, specifically the movements of the lips and facial dynamics. This technology holds critical importance in a variety of contexts, including the interpretation of lip movements from individuals with speech disorders <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, benefiting individuals with hearing disorders <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, recognizing spoken content within environments where acoustic signals are compromised <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, providing voiceovers to silent historical films, and fortifying security systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><math id="footnote1.m1.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="footnote1.m1.1b"><mo id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml">⋆</mo><annotation-xml encoding="MathML-Content" id="footnote1.m1.1c"><ci id="footnote1.m1.1.1.cmml" xref="footnote1.m1.1.1">⋆</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m1.1d">\star</annotation></semantics></math> Equal contribution.</span></span></span></p>
</div>
<figure id="S1.F1" class="ltx_figure">
<p id="S1.F1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S1.F1.1.1" class="ltx_text"><img src="/html/2406.12233/assets/LRS3.png" id="S1.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="314" height="217" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;">Performance of SyncVSR on LRS3<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> benchmark. SyncVSR outperforms available methods given the similar amount of video data resources. Our method also advances a tier in model size, where our base-size model shows superior performance compared to other large-size models.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The primary challenge encountered in VSR stems from the inherent scarcity of information that can be extracted from visual cues alone <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Central to this issue is the presence of homophenes, wherein disparate sounds are visually manifested through identical or nearly identical lip movements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Such phenomena represent significant ambiguity in the analysis of visemes, the fundamental units of visual speech recognition. This ambiguity poses considerable difficulties, as it muddles the clarity of speech interpretation through visual means alone.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Previous research to overcome such limitations has predominantly revolved around aligning visual with auditory semantics, attempting to reduce the gap between audio models and visual models. Earlier techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> harnessed knowledge distillation from pretrained Automatic Speech Recognition (ASR) systems. Subsequent studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> trained auxiliary audio modules along with the visual encoder in order to transfer speech knowledge. However, the aforementioned methods create indirect links to the acoustic data, as visual models interact with the semantics of audio encoders rather than the acoustic data. Such audio modules might provide insufficient hidden knowledge to the visual modules due to the crossmodal gap in representations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> strived to connect the visual encoder with speech data, but they utilized handcrafted features (e.g., spectrograms or MFCCs) as their inputs or targets, which possibly encompass inductive biases that could affect the learned representations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Moreover, several works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> introduced learning methods based on crossmodal masked reconstruction, where portions of visual inputs are replaced with masked frames and models are trained to reconstruct corresponding audio representations. Nevertheless, an alternative method to masked segment reconstruction has been introduced in the Natural Language Processing (NLP) domain, which is token-level discrimination <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. A key advantage of such discriminatory supervision is that the model learns from all input tokens instead of just the small masked-out subset, advancing a tier of performance and being more sample-efficient <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. This method is even more promising in the VSR domain since there is a fine-grained correspondence between the visual and auditory modalities, which provides a natural source of self-supervision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In light of the above, we propose the SyncVSR framework, an innovative approach to VSR that directly aligns visual phonetic units with their acoustic counterparts through quantized audio tokens, facilitating robust end-to-end crossmodal synchronization. By exploiting the discrete nature of quantized audio for frame-level supervision, SyncVSR circumvents the limitations of previous methods that rely on indirect semantic alignment or utilize potentially biased handcrafted features. This allows our model to discern fine-grained phonetic differences inherent in homophenes, enhancing the model's interpretative fidelity and data efficiency. Our empirical results highlight the efficacy of SyncVSR, which establishes new benchmark results across a range of VSR tasks.</p>
</div>
<figure id="S1.F2" class="ltx_figure">
<p id="S1.F2.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S1.F2.1.1" class="ltx_text">   <img src="/html/2406.12233/assets/CMTS.png" id="S1.F2.1.1.g1" class="ltx_graphics ltx_img_square" width="275" height="283" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.7.3.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.5.2" class="ltx_text" style="font-size:90%;">Overview of the SyncVSR training framework. Given a sequence of video frames, the encoder generates a corresponding sequence of quantized audio tokens in a non-autoregressive manner. <math id="S1.F2.4.1.m1.1" class="ltx_Math" alttext="z_{t}" display="inline"><semantics id="S1.F2.4.1.m1.1b"><msub id="S1.F2.4.1.m1.1.1" xref="S1.F2.4.1.m1.1.1.cmml"><mi id="S1.F2.4.1.m1.1.1.2" xref="S1.F2.4.1.m1.1.1.2.cmml">z</mi><mi id="S1.F2.4.1.m1.1.1.3" xref="S1.F2.4.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S1.F2.4.1.m1.1c"><apply id="S1.F2.4.1.m1.1.1.cmml" xref="S1.F2.4.1.m1.1.1"><csymbol cd="ambiguous" id="S1.F2.4.1.m1.1.1.1.cmml" xref="S1.F2.4.1.m1.1.1">subscript</csymbol><ci id="S1.F2.4.1.m1.1.1.2.cmml" xref="S1.F2.4.1.m1.1.1.2">𝑧</ci><ci id="S1.F2.4.1.m1.1.1.3.cmml" xref="S1.F2.4.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.4.1.m1.1d">z_{t}</annotation></semantics></math> denotes audio tokens, and <math id="S1.F2.5.2.m2.1" class="ltx_Math" alttext="q(z_{t}|x)" display="inline"><semantics id="S1.F2.5.2.m2.1b"><mrow id="S1.F2.5.2.m2.1.1" xref="S1.F2.5.2.m2.1.1.cmml"><mi id="S1.F2.5.2.m2.1.1.3" xref="S1.F2.5.2.m2.1.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S1.F2.5.2.m2.1.1.2" xref="S1.F2.5.2.m2.1.1.2.cmml">​</mo><mrow id="S1.F2.5.2.m2.1.1.1.1" xref="S1.F2.5.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S1.F2.5.2.m2.1.1.1.1.2" xref="S1.F2.5.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S1.F2.5.2.m2.1.1.1.1.1" xref="S1.F2.5.2.m2.1.1.1.1.1.cmml"><msub id="S1.F2.5.2.m2.1.1.1.1.1.2" xref="S1.F2.5.2.m2.1.1.1.1.1.2.cmml"><mi id="S1.F2.5.2.m2.1.1.1.1.1.2.2" xref="S1.F2.5.2.m2.1.1.1.1.1.2.2.cmml">z</mi><mi id="S1.F2.5.2.m2.1.1.1.1.1.2.3" xref="S1.F2.5.2.m2.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S1.F2.5.2.m2.1.1.1.1.1.1" xref="S1.F2.5.2.m2.1.1.1.1.1.1.cmml">|</mo><mi id="S1.F2.5.2.m2.1.1.1.1.1.3" xref="S1.F2.5.2.m2.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S1.F2.5.2.m2.1.1.1.1.3" xref="S1.F2.5.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.F2.5.2.m2.1c"><apply id="S1.F2.5.2.m2.1.1.cmml" xref="S1.F2.5.2.m2.1.1"><times id="S1.F2.5.2.m2.1.1.2.cmml" xref="S1.F2.5.2.m2.1.1.2"></times><ci id="S1.F2.5.2.m2.1.1.3.cmml" xref="S1.F2.5.2.m2.1.1.3">𝑞</ci><apply id="S1.F2.5.2.m2.1.1.1.1.1.cmml" xref="S1.F2.5.2.m2.1.1.1.1"><csymbol cd="latexml" id="S1.F2.5.2.m2.1.1.1.1.1.1.cmml" xref="S1.F2.5.2.m2.1.1.1.1.1.1">conditional</csymbol><apply id="S1.F2.5.2.m2.1.1.1.1.1.2.cmml" xref="S1.F2.5.2.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S1.F2.5.2.m2.1.1.1.1.1.2.1.cmml" xref="S1.F2.5.2.m2.1.1.1.1.1.2">subscript</csymbol><ci id="S1.F2.5.2.m2.1.1.1.1.1.2.2.cmml" xref="S1.F2.5.2.m2.1.1.1.1.1.2.2">𝑧</ci><ci id="S1.F2.5.2.m2.1.1.1.1.1.2.3.cmml" xref="S1.F2.5.2.m2.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S1.F2.5.2.m2.1.1.1.1.1.3.cmml" xref="S1.F2.5.2.m2.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.5.2.m2.1d">q(z_{t}|x)</annotation></semantics></math> is the encoder's prediction through a linear projection layer.</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Crossmodal Audio Token Synchronization.</span> Our work integrates audio reconstruction loss with VSR training objectives. Conventionally, word-level VSR employs a word classification loss, whereas sentence-level VSR utilizes the joint CTC-Attention loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. The total loss is the weighted sum of the task-specific objective loss and our audio reconstruction loss.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.6" class="ltx_p">Let <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S2.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\mathcal{D}</annotation></semantics></math> be a training set that consists of a training sample <math id="S2.p2.2.m2.3" class="ltx_Math" alttext="(x,y,z)" display="inline"><semantics id="S2.p2.2.m2.3a"><mrow id="S2.p2.2.m2.3.4.2" xref="S2.p2.2.m2.3.4.1.cmml"><mo stretchy="false" id="S2.p2.2.m2.3.4.2.1" xref="S2.p2.2.m2.3.4.1.cmml">(</mo><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">x</mi><mo id="S2.p2.2.m2.3.4.2.2" xref="S2.p2.2.m2.3.4.1.cmml">,</mo><mi id="S2.p2.2.m2.2.2" xref="S2.p2.2.m2.2.2.cmml">y</mi><mo id="S2.p2.2.m2.3.4.2.3" xref="S2.p2.2.m2.3.4.1.cmml">,</mo><mi id="S2.p2.2.m2.3.3" xref="S2.p2.2.m2.3.3.cmml">z</mi><mo stretchy="false" id="S2.p2.2.m2.3.4.2.4" xref="S2.p2.2.m2.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.3b"><vector id="S2.p2.2.m2.3.4.1.cmml" xref="S2.p2.2.m2.3.4.2"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">𝑥</ci><ci id="S2.p2.2.m2.2.2.cmml" xref="S2.p2.2.m2.2.2">𝑦</ci><ci id="S2.p2.2.m2.3.3.cmml" xref="S2.p2.2.m2.3.3">𝑧</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.3c">(x,y,z)</annotation></semantics></math>. Let <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.p2.3.m3.1a"><mi id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><ci id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">x</annotation></semantics></math> and <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.p2.4.m4.1a"><mi id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">y</annotation></semantics></math> be the input video and ground truth label. Let <math id="S2.p2.5.m5.1" class="ltx_Math" alttext="z=\{z_{t}\}_{t\leq T}" display="inline"><semantics id="S2.p2.5.m5.1a"><mrow id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml"><mi id="S2.p2.5.m5.1.1.3" xref="S2.p2.5.m5.1.1.3.cmml">z</mi><mo id="S2.p2.5.m5.1.1.2" xref="S2.p2.5.m5.1.1.2.cmml">=</mo><msub id="S2.p2.5.m5.1.1.1" xref="S2.p2.5.m5.1.1.1.cmml"><mrow id="S2.p2.5.m5.1.1.1.1.1" xref="S2.p2.5.m5.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.p2.5.m5.1.1.1.1.1.2" xref="S2.p2.5.m5.1.1.1.1.2.cmml">{</mo><msub id="S2.p2.5.m5.1.1.1.1.1.1" xref="S2.p2.5.m5.1.1.1.1.1.1.cmml"><mi id="S2.p2.5.m5.1.1.1.1.1.1.2" xref="S2.p2.5.m5.1.1.1.1.1.1.2.cmml">z</mi><mi id="S2.p2.5.m5.1.1.1.1.1.1.3" xref="S2.p2.5.m5.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.p2.5.m5.1.1.1.1.1.3" xref="S2.p2.5.m5.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p2.5.m5.1.1.1.3" xref="S2.p2.5.m5.1.1.1.3.cmml"><mi id="S2.p2.5.m5.1.1.1.3.2" xref="S2.p2.5.m5.1.1.1.3.2.cmml">t</mi><mo id="S2.p2.5.m5.1.1.1.3.1" xref="S2.p2.5.m5.1.1.1.3.1.cmml">≤</mo><mi id="S2.p2.5.m5.1.1.1.3.3" xref="S2.p2.5.m5.1.1.1.3.3.cmml">T</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><apply id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1"><eq id="S2.p2.5.m5.1.1.2.cmml" xref="S2.p2.5.m5.1.1.2"></eq><ci id="S2.p2.5.m5.1.1.3.cmml" xref="S2.p2.5.m5.1.1.3">𝑧</ci><apply id="S2.p2.5.m5.1.1.1.cmml" xref="S2.p2.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.2.cmml" xref="S2.p2.5.m5.1.1.1">subscript</csymbol><set id="S2.p2.5.m5.1.1.1.1.2.cmml" xref="S2.p2.5.m5.1.1.1.1.1"><apply id="S2.p2.5.m5.1.1.1.1.1.1.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.1.1.1.1.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p2.5.m5.1.1.1.1.1.1.2.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.2">𝑧</ci><ci id="S2.p2.5.m5.1.1.1.1.1.1.3.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.3">𝑡</ci></apply></set><apply id="S2.p2.5.m5.1.1.1.3.cmml" xref="S2.p2.5.m5.1.1.1.3"><leq id="S2.p2.5.m5.1.1.1.3.1.cmml" xref="S2.p2.5.m5.1.1.1.3.1"></leq><ci id="S2.p2.5.m5.1.1.1.3.2.cmml" xref="S2.p2.5.m5.1.1.1.3.2">𝑡</ci><ci id="S2.p2.5.m5.1.1.1.3.3.cmml" xref="S2.p2.5.m5.1.1.1.3.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">z=\{z_{t}\}_{t\leq T}</annotation></semantics></math> be a discrete audio sequence corresponding to the input video <math id="S2.p2.6.m6.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.p2.6.m6.1a"><mi id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><ci id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">x</annotation></semantics></math>.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.2" class="ltx_p"><span id="S2.p3.2.1" class="ltx_text ltx_font_bold">Word Classification Loss.</span> For word-level VSR, cross-entropy loss measures the difference between predicted class probabilities and the ground truth labels. Given that <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.p3.1.m1.1a"><mi id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><ci id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">y</annotation></semantics></math> represents the ground truth category for the input video <math id="S2.p3.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.p3.2.m2.1a"><mi id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><ci id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">x</annotation></semantics></math>, the objective loss is formulated as follows:</p>
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.4" class="ltx_Math" alttext="\mathcal{L}_{\text{task}}=-\mathbb{E}_{(x,y,z)\in\mathcal{D}}\log p(y|x)" display="block"><semantics id="S2.Ex1.m1.4a"><mrow id="S2.Ex1.m1.4.4" xref="S2.Ex1.m1.4.4.cmml"><msub id="S2.Ex1.m1.4.4.3" xref="S2.Ex1.m1.4.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex1.m1.4.4.3.2" xref="S2.Ex1.m1.4.4.3.2.cmml">ℒ</mi><mtext id="S2.Ex1.m1.4.4.3.3" xref="S2.Ex1.m1.4.4.3.3a.cmml">task</mtext></msub><mo id="S2.Ex1.m1.4.4.2" xref="S2.Ex1.m1.4.4.2.cmml">=</mo><mrow id="S2.Ex1.m1.4.4.1" xref="S2.Ex1.m1.4.4.1.cmml"><mo id="S2.Ex1.m1.4.4.1a" xref="S2.Ex1.m1.4.4.1.cmml">−</mo><mrow id="S2.Ex1.m1.4.4.1.1" xref="S2.Ex1.m1.4.4.1.1.cmml"><msub id="S2.Ex1.m1.4.4.1.1.3" xref="S2.Ex1.m1.4.4.1.1.3.cmml"><mi id="S2.Ex1.m1.4.4.1.1.3.2" xref="S2.Ex1.m1.4.4.1.1.3.2.cmml">𝔼</mi><mrow id="S2.Ex1.m1.3.3.3" xref="S2.Ex1.m1.3.3.3.cmml"><mrow id="S2.Ex1.m1.3.3.3.5.2" xref="S2.Ex1.m1.3.3.3.5.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.3.3.3.5.2.1" xref="S2.Ex1.m1.3.3.3.5.1.cmml">(</mo><mi id="S2.Ex1.m1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.cmml">x</mi><mo id="S2.Ex1.m1.3.3.3.5.2.2" xref="S2.Ex1.m1.3.3.3.5.1.cmml">,</mo><mi id="S2.Ex1.m1.2.2.2.2" xref="S2.Ex1.m1.2.2.2.2.cmml">y</mi><mo id="S2.Ex1.m1.3.3.3.5.2.3" xref="S2.Ex1.m1.3.3.3.5.1.cmml">,</mo><mi id="S2.Ex1.m1.3.3.3.3" xref="S2.Ex1.m1.3.3.3.3.cmml">z</mi><mo stretchy="false" id="S2.Ex1.m1.3.3.3.5.2.4" xref="S2.Ex1.m1.3.3.3.5.1.cmml">)</mo></mrow><mo id="S2.Ex1.m1.3.3.3.4" xref="S2.Ex1.m1.3.3.3.4.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.Ex1.m1.3.3.3.6" xref="S2.Ex1.m1.3.3.3.6.cmml">𝒟</mi></mrow></msub><mo lspace="0.167em" rspace="0em" id="S2.Ex1.m1.4.4.1.1.2" xref="S2.Ex1.m1.4.4.1.1.2.cmml">​</mo><mrow id="S2.Ex1.m1.4.4.1.1.4" xref="S2.Ex1.m1.4.4.1.1.4.cmml"><mi id="S2.Ex1.m1.4.4.1.1.4.1" xref="S2.Ex1.m1.4.4.1.1.4.1.cmml">log</mi><mo lspace="0.167em" id="S2.Ex1.m1.4.4.1.1.4a" xref="S2.Ex1.m1.4.4.1.1.4.cmml">⁡</mo><mi id="S2.Ex1.m1.4.4.1.1.4.2" xref="S2.Ex1.m1.4.4.1.1.4.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.4.4.1.1.2a" xref="S2.Ex1.m1.4.4.1.1.2.cmml">​</mo><mrow id="S2.Ex1.m1.4.4.1.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.4.4.1.1.1.1.2" xref="S2.Ex1.m1.4.4.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.4.4.1.1.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.4.4.1.1.1.1.1.2" xref="S2.Ex1.m1.4.4.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.Ex1.m1.4.4.1.1.1.1.1.1" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml">|</mo><mi id="S2.Ex1.m1.4.4.1.1.1.1.1.3" xref="S2.Ex1.m1.4.4.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.Ex1.m1.4.4.1.1.1.1.3" xref="S2.Ex1.m1.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.4b"><apply id="S2.Ex1.m1.4.4.cmml" xref="S2.Ex1.m1.4.4"><eq id="S2.Ex1.m1.4.4.2.cmml" xref="S2.Ex1.m1.4.4.2"></eq><apply id="S2.Ex1.m1.4.4.3.cmml" xref="S2.Ex1.m1.4.4.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.4.4.3.1.cmml" xref="S2.Ex1.m1.4.4.3">subscript</csymbol><ci id="S2.Ex1.m1.4.4.3.2.cmml" xref="S2.Ex1.m1.4.4.3.2">ℒ</ci><ci id="S2.Ex1.m1.4.4.3.3a.cmml" xref="S2.Ex1.m1.4.4.3.3"><mtext mathsize="70%" id="S2.Ex1.m1.4.4.3.3.cmml" xref="S2.Ex1.m1.4.4.3.3">task</mtext></ci></apply><apply id="S2.Ex1.m1.4.4.1.cmml" xref="S2.Ex1.m1.4.4.1"><minus id="S2.Ex1.m1.4.4.1.2.cmml" xref="S2.Ex1.m1.4.4.1"></minus><apply id="S2.Ex1.m1.4.4.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1"><times id="S2.Ex1.m1.4.4.1.1.2.cmml" xref="S2.Ex1.m1.4.4.1.1.2"></times><apply id="S2.Ex1.m1.4.4.1.1.3.cmml" xref="S2.Ex1.m1.4.4.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.4.4.1.1.3.1.cmml" xref="S2.Ex1.m1.4.4.1.1.3">subscript</csymbol><ci id="S2.Ex1.m1.4.4.1.1.3.2.cmml" xref="S2.Ex1.m1.4.4.1.1.3.2">𝔼</ci><apply id="S2.Ex1.m1.3.3.3.cmml" xref="S2.Ex1.m1.3.3.3"><in id="S2.Ex1.m1.3.3.3.4.cmml" xref="S2.Ex1.m1.3.3.3.4"></in><vector id="S2.Ex1.m1.3.3.3.5.1.cmml" xref="S2.Ex1.m1.3.3.3.5.2"><ci id="S2.Ex1.m1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1">𝑥</ci><ci id="S2.Ex1.m1.2.2.2.2.cmml" xref="S2.Ex1.m1.2.2.2.2">𝑦</ci><ci id="S2.Ex1.m1.3.3.3.3.cmml" xref="S2.Ex1.m1.3.3.3.3">𝑧</ci></vector><ci id="S2.Ex1.m1.3.3.3.6.cmml" xref="S2.Ex1.m1.3.3.3.6">𝒟</ci></apply></apply><apply id="S2.Ex1.m1.4.4.1.1.4.cmml" xref="S2.Ex1.m1.4.4.1.1.4"><log id="S2.Ex1.m1.4.4.1.1.4.1.cmml" xref="S2.Ex1.m1.4.4.1.1.4.1"></log><ci id="S2.Ex1.m1.4.4.1.1.4.2.cmml" xref="S2.Ex1.m1.4.4.1.1.4.2">𝑝</ci></apply><apply id="S2.Ex1.m1.4.4.1.1.1.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1.1">conditional</csymbol><ci id="S2.Ex1.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1.2">𝑦</ci><ci id="S2.Ex1.m1.4.4.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.4.4.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.4c">\mathcal{L}_{\text{task}}=-\mathbb{E}_{(x,y,z)\in\mathcal{D}}\log p(y|x)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.p3.3" class="ltx_p">where <math id="S2.p3.3.m1.1" class="ltx_Math" alttext="p(y|x)" display="inline"><semantics id="S2.p3.3.m1.1a"><mrow id="S2.p3.3.m1.1.1" xref="S2.p3.3.m1.1.1.cmml"><mi id="S2.p3.3.m1.1.1.3" xref="S2.p3.3.m1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.p3.3.m1.1.1.2" xref="S2.p3.3.m1.1.1.2.cmml">​</mo><mrow id="S2.p3.3.m1.1.1.1.1" xref="S2.p3.3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p3.3.m1.1.1.1.1.2" xref="S2.p3.3.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.p3.3.m1.1.1.1.1.1" xref="S2.p3.3.m1.1.1.1.1.1.cmml"><mi id="S2.p3.3.m1.1.1.1.1.1.2" xref="S2.p3.3.m1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.p3.3.m1.1.1.1.1.1.1" xref="S2.p3.3.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.p3.3.m1.1.1.1.1.1.3" xref="S2.p3.3.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.p3.3.m1.1.1.1.1.3" xref="S2.p3.3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.3.m1.1b"><apply id="S2.p3.3.m1.1.1.cmml" xref="S2.p3.3.m1.1.1"><times id="S2.p3.3.m1.1.1.2.cmml" xref="S2.p3.3.m1.1.1.2"></times><ci id="S2.p3.3.m1.1.1.3.cmml" xref="S2.p3.3.m1.1.1.3">𝑝</ci><apply id="S2.p3.3.m1.1.1.1.1.1.cmml" xref="S2.p3.3.m1.1.1.1.1"><csymbol cd="latexml" id="S2.p3.3.m1.1.1.1.1.1.1.cmml" xref="S2.p3.3.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.p3.3.m1.1.1.1.1.1.2.cmml" xref="S2.p3.3.m1.1.1.1.1.1.2">𝑦</ci><ci id="S2.p3.3.m1.1.1.1.1.1.3.cmml" xref="S2.p3.3.m1.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.3.m1.1c">p(y|x)</annotation></semantics></math> denotes the output probability from the model.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Joint CTC-Attention Loss.</span> For sentence-level VSR, we employ a combination of Connectionist Temporal Classification (CTC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> loss from the encoder and Language Modeling (LM) loss from the decoder, known as joint CTC-Attention loss.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.4" class="ltx_p">Let <math id="S2.p5.1.m1.1" class="ltx_Math" alttext="\pi=\{\pi_{t}\}_{t\leq T}" display="inline"><semantics id="S2.p5.1.m1.1a"><mrow id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml"><mi id="S2.p5.1.m1.1.1.3" xref="S2.p5.1.m1.1.1.3.cmml">π</mi><mo id="S2.p5.1.m1.1.1.2" xref="S2.p5.1.m1.1.1.2.cmml">=</mo><msub id="S2.p5.1.m1.1.1.1" xref="S2.p5.1.m1.1.1.1.cmml"><mrow id="S2.p5.1.m1.1.1.1.1.1" xref="S2.p5.1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.p5.1.m1.1.1.1.1.1.2" xref="S2.p5.1.m1.1.1.1.1.2.cmml">{</mo><msub id="S2.p5.1.m1.1.1.1.1.1.1" xref="S2.p5.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.p5.1.m1.1.1.1.1.1.1.2" xref="S2.p5.1.m1.1.1.1.1.1.1.2.cmml">π</mi><mi id="S2.p5.1.m1.1.1.1.1.1.1.3" xref="S2.p5.1.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.p5.1.m1.1.1.1.1.1.3" xref="S2.p5.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p5.1.m1.1.1.1.3" xref="S2.p5.1.m1.1.1.1.3.cmml"><mi id="S2.p5.1.m1.1.1.1.3.2" xref="S2.p5.1.m1.1.1.1.3.2.cmml">t</mi><mo id="S2.p5.1.m1.1.1.1.3.1" xref="S2.p5.1.m1.1.1.1.3.1.cmml">≤</mo><mi id="S2.p5.1.m1.1.1.1.3.3" xref="S2.p5.1.m1.1.1.1.3.3.cmml">T</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><apply id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1"><eq id="S2.p5.1.m1.1.1.2.cmml" xref="S2.p5.1.m1.1.1.2"></eq><ci id="S2.p5.1.m1.1.1.3.cmml" xref="S2.p5.1.m1.1.1.3">𝜋</ci><apply id="S2.p5.1.m1.1.1.1.cmml" xref="S2.p5.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p5.1.m1.1.1.1.2.cmml" xref="S2.p5.1.m1.1.1.1">subscript</csymbol><set id="S2.p5.1.m1.1.1.1.1.2.cmml" xref="S2.p5.1.m1.1.1.1.1.1"><apply id="S2.p5.1.m1.1.1.1.1.1.1.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p5.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p5.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.2">𝜋</ci><ci id="S2.p5.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.p5.1.m1.1.1.1.1.1.1.3">𝑡</ci></apply></set><apply id="S2.p5.1.m1.1.1.1.3.cmml" xref="S2.p5.1.m1.1.1.1.3"><leq id="S2.p5.1.m1.1.1.1.3.1.cmml" xref="S2.p5.1.m1.1.1.1.3.1"></leq><ci id="S2.p5.1.m1.1.1.1.3.2.cmml" xref="S2.p5.1.m1.1.1.1.3.2">𝑡</ci><ci id="S2.p5.1.m1.1.1.1.3.3.cmml" xref="S2.p5.1.m1.1.1.1.3.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">\pi=\{\pi_{t}\}_{t\leq T}</annotation></semantics></math> be intermediate CTC labels, and <math id="S2.p5.2.m2.1" class="ltx_Math" alttext="\phi(y)" display="inline"><semantics id="S2.p5.2.m2.1a"><mrow id="S2.p5.2.m2.1.2" xref="S2.p5.2.m2.1.2.cmml"><mi id="S2.p5.2.m2.1.2.2" xref="S2.p5.2.m2.1.2.2.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S2.p5.2.m2.1.2.1" xref="S2.p5.2.m2.1.2.1.cmml">​</mo><mrow id="S2.p5.2.m2.1.2.3.2" xref="S2.p5.2.m2.1.2.cmml"><mo stretchy="false" id="S2.p5.2.m2.1.2.3.2.1" xref="S2.p5.2.m2.1.2.cmml">(</mo><mi id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml">y</mi><mo stretchy="false" id="S2.p5.2.m2.1.2.3.2.2" xref="S2.p5.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><apply id="S2.p5.2.m2.1.2.cmml" xref="S2.p5.2.m2.1.2"><times id="S2.p5.2.m2.1.2.1.cmml" xref="S2.p5.2.m2.1.2.1"></times><ci id="S2.p5.2.m2.1.2.2.cmml" xref="S2.p5.2.m2.1.2.2">italic-ϕ</ci><ci id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">\phi(y)</annotation></semantics></math> be a set of all possible intermediate labels for CTC loss. Using <math id="S2.p5.3.m3.1" class="ltx_Math" alttext="p_{\text{LM}}" display="inline"><semantics id="S2.p5.3.m3.1a"><msub id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml"><mi id="S2.p5.3.m3.1.1.2" xref="S2.p5.3.m3.1.1.2.cmml">p</mi><mtext id="S2.p5.3.m3.1.1.3" xref="S2.p5.3.m3.1.1.3a.cmml">LM</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><apply id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p5.3.m3.1.1.1.cmml" xref="S2.p5.3.m3.1.1">subscript</csymbol><ci id="S2.p5.3.m3.1.1.2.cmml" xref="S2.p5.3.m3.1.1.2">𝑝</ci><ci id="S2.p5.3.m3.1.1.3a.cmml" xref="S2.p5.3.m3.1.1.3"><mtext mathsize="70%" id="S2.p5.3.m3.1.1.3.cmml" xref="S2.p5.3.m3.1.1.3">LM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">p_{\text{LM}}</annotation></semantics></math> for language modeling and <math id="S2.p5.4.m4.1" class="ltx_Math" alttext="p_{\text{CTC}}" display="inline"><semantics id="S2.p5.4.m4.1a"><msub id="S2.p5.4.m4.1.1" xref="S2.p5.4.m4.1.1.cmml"><mi id="S2.p5.4.m4.1.1.2" xref="S2.p5.4.m4.1.1.2.cmml">p</mi><mtext id="S2.p5.4.m4.1.1.3" xref="S2.p5.4.m4.1.1.3a.cmml">CTC</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.p5.4.m4.1b"><apply id="S2.p5.4.m4.1.1.cmml" xref="S2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p5.4.m4.1.1.1.cmml" xref="S2.p5.4.m4.1.1">subscript</csymbol><ci id="S2.p5.4.m4.1.1.2.cmml" xref="S2.p5.4.m4.1.1.2">𝑝</ci><ci id="S2.p5.4.m4.1.1.3a.cmml" xref="S2.p5.4.m4.1.1.3"><mtext mathsize="70%" id="S2.p5.4.m4.1.1.3.cmml" xref="S2.p5.4.m4.1.1.3">CTC</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.4.m4.1c">p_{\text{CTC}}</annotation></semantics></math> for conditional independent prediction, we define the losses as follows:</p>
<table id="S2.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex2.m1.5" class="ltx_Math" alttext="\mathcal{L}_{\text{LM}}=-\mathbb{E}_{(x,y,z)\in\mathcal{D}}\sum_{t\leq T}\log p_{\text{LM}}(y_{t}|x,y_{&lt;t})," display="block"><semantics id="S2.Ex2.m1.5a"><mrow id="S2.Ex2.m1.5.5.1" xref="S2.Ex2.m1.5.5.1.1.cmml"><mrow id="S2.Ex2.m1.5.5.1.1" xref="S2.Ex2.m1.5.5.1.1.cmml"><msub id="S2.Ex2.m1.5.5.1.1.3" xref="S2.Ex2.m1.5.5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex2.m1.5.5.1.1.3.2" xref="S2.Ex2.m1.5.5.1.1.3.2.cmml">ℒ</mi><mtext id="S2.Ex2.m1.5.5.1.1.3.3" xref="S2.Ex2.m1.5.5.1.1.3.3a.cmml">LM</mtext></msub><mo id="S2.Ex2.m1.5.5.1.1.2" xref="S2.Ex2.m1.5.5.1.1.2.cmml">=</mo><mrow id="S2.Ex2.m1.5.5.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.cmml"><mo id="S2.Ex2.m1.5.5.1.1.1a" xref="S2.Ex2.m1.5.5.1.1.1.cmml">−</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.cmml"><msub id="S2.Ex2.m1.5.5.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.3.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.3.2" xref="S2.Ex2.m1.5.5.1.1.1.1.3.2.cmml">𝔼</mi><mrow id="S2.Ex2.m1.3.3.3" xref="S2.Ex2.m1.3.3.3.cmml"><mrow id="S2.Ex2.m1.3.3.3.5.2" xref="S2.Ex2.m1.3.3.3.5.1.cmml"><mo stretchy="false" id="S2.Ex2.m1.3.3.3.5.2.1" xref="S2.Ex2.m1.3.3.3.5.1.cmml">(</mo><mi id="S2.Ex2.m1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.cmml">x</mi><mo id="S2.Ex2.m1.3.3.3.5.2.2" xref="S2.Ex2.m1.3.3.3.5.1.cmml">,</mo><mi id="S2.Ex2.m1.2.2.2.2" xref="S2.Ex2.m1.2.2.2.2.cmml">y</mi><mo id="S2.Ex2.m1.3.3.3.5.2.3" xref="S2.Ex2.m1.3.3.3.5.1.cmml">,</mo><mi id="S2.Ex2.m1.3.3.3.3" xref="S2.Ex2.m1.3.3.3.3.cmml">z</mi><mo stretchy="false" id="S2.Ex2.m1.3.3.3.5.2.4" xref="S2.Ex2.m1.3.3.3.5.1.cmml">)</mo></mrow><mo id="S2.Ex2.m1.3.3.3.4" xref="S2.Ex2.m1.3.3.3.4.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.Ex2.m1.3.3.3.6" xref="S2.Ex2.m1.3.3.3.6.cmml">𝒟</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.5.5.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.cmml"><munder id="S2.Ex2.m1.5.5.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.Ex2.m1.5.5.1.1.1.1.1.2.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.2.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.1.cmml">≤</mo><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.3.cmml">T</mi></mrow></munder><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.cmml"><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3a" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.cmml">⁡</mo><msub id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.2.cmml">p</mi><mtext id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.3a.cmml">LM</mtext></msub></mrow><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo fence="false" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex2.m1.4.4" xref="S2.Ex2.m1.4.4.cmml">x</mi><mo id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">y</mi><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S2.Ex2.m1.5.5.1.2" xref="S2.Ex2.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.5b"><apply id="S2.Ex2.m1.5.5.1.1.cmml" xref="S2.Ex2.m1.5.5.1"><eq id="S2.Ex2.m1.5.5.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.2"></eq><apply id="S2.Ex2.m1.5.5.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.3.1.cmml" xref="S2.Ex2.m1.5.5.1.1.3">subscript</csymbol><ci id="S2.Ex2.m1.5.5.1.1.3.2.cmml" xref="S2.Ex2.m1.5.5.1.1.3.2">ℒ</ci><ci id="S2.Ex2.m1.5.5.1.1.3.3a.cmml" xref="S2.Ex2.m1.5.5.1.1.3.3"><mtext mathsize="70%" id="S2.Ex2.m1.5.5.1.1.3.3.cmml" xref="S2.Ex2.m1.5.5.1.1.3.3">LM</mtext></ci></apply><apply id="S2.Ex2.m1.5.5.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1"><minus id="S2.Ex2.m1.5.5.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1"></minus><apply id="S2.Ex2.m1.5.5.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1"><times id="S2.Ex2.m1.5.5.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.2"></times><apply id="S2.Ex2.m1.5.5.1.1.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.1.1.3.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex2.m1.5.5.1.1.1.1.3.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.3.2">𝔼</ci><apply id="S2.Ex2.m1.3.3.3.cmml" xref="S2.Ex2.m1.3.3.3"><in id="S2.Ex2.m1.3.3.3.4.cmml" xref="S2.Ex2.m1.3.3.3.4"></in><vector id="S2.Ex2.m1.3.3.3.5.1.cmml" xref="S2.Ex2.m1.3.3.3.5.2"><ci id="S2.Ex2.m1.1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1.1">𝑥</ci><ci id="S2.Ex2.m1.2.2.2.2.cmml" xref="S2.Ex2.m1.2.2.2.2">𝑦</ci><ci id="S2.Ex2.m1.3.3.3.3.cmml" xref="S2.Ex2.m1.3.3.3.3">𝑧</ci></vector><ci id="S2.Ex2.m1.3.3.3.6.cmml" xref="S2.Ex2.m1.3.3.3.6">𝒟</ci></apply></apply><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1"><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2">subscript</csymbol><sum id="S2.Ex2.m1.5.5.1.1.1.1.1.2.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.2"></sum><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.3"><leq id="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.1"></leq><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.2">𝑡</ci><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1"><times id="S2.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.2"></times><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3"><log id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.1"></log><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.2">𝑝</ci><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.3a.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.3"><mtext mathsize="70%" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.3.2.3">LM</mtext></ci></apply></apply><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.2">𝑦</ci><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><list id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1"><ci id="S2.Ex2.m1.4.4.cmml" xref="S2.Ex2.m1.4.4">𝑥</ci><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑦</ci><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3"><lt id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.5c">\mathcal{L}_{\text{LM}}=-\mathbb{E}_{(x,y,z)\in\mathcal{D}}\sum_{t\leq T}\log p_{\text{LM}}(y_{t}|x,y_{&lt;t}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S2.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex3.m1.5" class="ltx_Math" alttext="\mathcal{L}_{\text{CTC}}=-\mathbb{E}_{(x,y,z)\in\mathcal{D}}\sum_{\pi\in\phi(y)}\sum_{t\leq T}\log p_{\text{CTC}}(\pi_{t}|x)," display="block"><semantics id="S2.Ex3.m1.5a"><mrow id="S2.Ex3.m1.5.5.1" xref="S2.Ex3.m1.5.5.1.1.cmml"><mrow id="S2.Ex3.m1.5.5.1.1" xref="S2.Ex3.m1.5.5.1.1.cmml"><msub id="S2.Ex3.m1.5.5.1.1.3" xref="S2.Ex3.m1.5.5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex3.m1.5.5.1.1.3.2" xref="S2.Ex3.m1.5.5.1.1.3.2.cmml">ℒ</mi><mtext id="S2.Ex3.m1.5.5.1.1.3.3" xref="S2.Ex3.m1.5.5.1.1.3.3a.cmml">CTC</mtext></msub><mo id="S2.Ex3.m1.5.5.1.1.2" xref="S2.Ex3.m1.5.5.1.1.2.cmml">=</mo><mrow id="S2.Ex3.m1.5.5.1.1.1" xref="S2.Ex3.m1.5.5.1.1.1.cmml"><mo id="S2.Ex3.m1.5.5.1.1.1a" xref="S2.Ex3.m1.5.5.1.1.1.cmml">−</mo><mrow id="S2.Ex3.m1.5.5.1.1.1.1" xref="S2.Ex3.m1.5.5.1.1.1.1.cmml"><msub id="S2.Ex3.m1.5.5.1.1.1.1.3" xref="S2.Ex3.m1.5.5.1.1.1.1.3.cmml"><mi id="S2.Ex3.m1.5.5.1.1.1.1.3.2" xref="S2.Ex3.m1.5.5.1.1.1.1.3.2.cmml">𝔼</mi><mrow id="S2.Ex3.m1.3.3.3" xref="S2.Ex3.m1.3.3.3.cmml"><mrow id="S2.Ex3.m1.3.3.3.5.2" xref="S2.Ex3.m1.3.3.3.5.1.cmml"><mo stretchy="false" id="S2.Ex3.m1.3.3.3.5.2.1" xref="S2.Ex3.m1.3.3.3.5.1.cmml">(</mo><mi id="S2.Ex3.m1.1.1.1.1" xref="S2.Ex3.m1.1.1.1.1.cmml">x</mi><mo id="S2.Ex3.m1.3.3.3.5.2.2" xref="S2.Ex3.m1.3.3.3.5.1.cmml">,</mo><mi id="S2.Ex3.m1.2.2.2.2" xref="S2.Ex3.m1.2.2.2.2.cmml">y</mi><mo id="S2.Ex3.m1.3.3.3.5.2.3" xref="S2.Ex3.m1.3.3.3.5.1.cmml">,</mo><mi id="S2.Ex3.m1.3.3.3.3" xref="S2.Ex3.m1.3.3.3.3.cmml">z</mi><mo stretchy="false" id="S2.Ex3.m1.3.3.3.5.2.4" xref="S2.Ex3.m1.3.3.3.5.1.cmml">)</mo></mrow><mo id="S2.Ex3.m1.3.3.3.4" xref="S2.Ex3.m1.3.3.3.4.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.Ex3.m1.3.3.3.6" xref="S2.Ex3.m1.3.3.3.6.cmml">𝒟</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.5.5.1.1.1.1.2" xref="S2.Ex3.m1.5.5.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex3.m1.5.5.1.1.1.1.1" xref="S2.Ex3.m1.5.5.1.1.1.1.1.cmml"><munder id="S2.Ex3.m1.5.5.1.1.1.1.1.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S2.Ex3.m1.5.5.1.1.1.1.1.2.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.Ex3.m1.4.4.1" xref="S2.Ex3.m1.4.4.1.cmml"><mi id="S2.Ex3.m1.4.4.1.3" xref="S2.Ex3.m1.4.4.1.3.cmml">π</mi><mo id="S2.Ex3.m1.4.4.1.2" xref="S2.Ex3.m1.4.4.1.2.cmml">∈</mo><mrow id="S2.Ex3.m1.4.4.1.4" xref="S2.Ex3.m1.4.4.1.4.cmml"><mi id="S2.Ex3.m1.4.4.1.4.2" xref="S2.Ex3.m1.4.4.1.4.2.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.4.4.1.4.1" xref="S2.Ex3.m1.4.4.1.4.1.cmml">​</mo><mrow id="S2.Ex3.m1.4.4.1.4.3.2" xref="S2.Ex3.m1.4.4.1.4.cmml"><mo stretchy="false" id="S2.Ex3.m1.4.4.1.4.3.2.1" xref="S2.Ex3.m1.4.4.1.4.cmml">(</mo><mi id="S2.Ex3.m1.4.4.1.1" xref="S2.Ex3.m1.4.4.1.1.cmml">y</mi><mo stretchy="false" id="S2.Ex3.m1.4.4.1.4.3.2.2" xref="S2.Ex3.m1.4.4.1.4.cmml">)</mo></mrow></mrow></mrow></munder><mrow id="S2.Ex3.m1.5.5.1.1.1.1.1.1" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.cmml"><munder id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.cmml"><mi id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.1" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.1.cmml">≤</mo><mi id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.3" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.3.cmml">T</mi></mrow></munder><mrow id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.cmml"><mrow id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.1" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3a" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.cmml">⁡</mo><msub id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.cmml"><mi id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.2.cmml">p</mi><mtext id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.3" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.3a.cmml">CTC</mtext></msub></mrow><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.cmml">π</mi><mi id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S2.Ex3.m1.5.5.1.2" xref="S2.Ex3.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex3.m1.5b"><apply id="S2.Ex3.m1.5.5.1.1.cmml" xref="S2.Ex3.m1.5.5.1"><eq id="S2.Ex3.m1.5.5.1.1.2.cmml" xref="S2.Ex3.m1.5.5.1.1.2"></eq><apply id="S2.Ex3.m1.5.5.1.1.3.cmml" xref="S2.Ex3.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S2.Ex3.m1.5.5.1.1.3.1.cmml" xref="S2.Ex3.m1.5.5.1.1.3">subscript</csymbol><ci id="S2.Ex3.m1.5.5.1.1.3.2.cmml" xref="S2.Ex3.m1.5.5.1.1.3.2">ℒ</ci><ci id="S2.Ex3.m1.5.5.1.1.3.3a.cmml" xref="S2.Ex3.m1.5.5.1.1.3.3"><mtext mathsize="70%" id="S2.Ex3.m1.5.5.1.1.3.3.cmml" xref="S2.Ex3.m1.5.5.1.1.3.3">CTC</mtext></ci></apply><apply id="S2.Ex3.m1.5.5.1.1.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1"><minus id="S2.Ex3.m1.5.5.1.1.1.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1"></minus><apply id="S2.Ex3.m1.5.5.1.1.1.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1"><times id="S2.Ex3.m1.5.5.1.1.1.1.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.2"></times><apply id="S2.Ex3.m1.5.5.1.1.1.1.3.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex3.m1.5.5.1.1.1.1.3.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex3.m1.5.5.1.1.1.1.3.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.3.2">𝔼</ci><apply id="S2.Ex3.m1.3.3.3.cmml" xref="S2.Ex3.m1.3.3.3"><in id="S2.Ex3.m1.3.3.3.4.cmml" xref="S2.Ex3.m1.3.3.3.4"></in><vector id="S2.Ex3.m1.3.3.3.5.1.cmml" xref="S2.Ex3.m1.3.3.3.5.2"><ci id="S2.Ex3.m1.1.1.1.1.cmml" xref="S2.Ex3.m1.1.1.1.1">𝑥</ci><ci id="S2.Ex3.m1.2.2.2.2.cmml" xref="S2.Ex3.m1.2.2.2.2">𝑦</ci><ci id="S2.Ex3.m1.3.3.3.3.cmml" xref="S2.Ex3.m1.3.3.3.3">𝑧</ci></vector><ci id="S2.Ex3.m1.3.3.3.6.cmml" xref="S2.Ex3.m1.3.3.3.6">𝒟</ci></apply></apply><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1"><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex3.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.2">subscript</csymbol><sum id="S2.Ex3.m1.5.5.1.1.1.1.1.2.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.2.2"></sum><apply id="S2.Ex3.m1.4.4.1.cmml" xref="S2.Ex3.m1.4.4.1"><in id="S2.Ex3.m1.4.4.1.2.cmml" xref="S2.Ex3.m1.4.4.1.2"></in><ci id="S2.Ex3.m1.4.4.1.3.cmml" xref="S2.Ex3.m1.4.4.1.3">𝜋</ci><apply id="S2.Ex3.m1.4.4.1.4.cmml" xref="S2.Ex3.m1.4.4.1.4"><times id="S2.Ex3.m1.4.4.1.4.1.cmml" xref="S2.Ex3.m1.4.4.1.4.1"></times><ci id="S2.Ex3.m1.4.4.1.4.2.cmml" xref="S2.Ex3.m1.4.4.1.4.2">italic-ϕ</ci><ci id="S2.Ex3.m1.4.4.1.1.cmml" xref="S2.Ex3.m1.4.4.1.1">𝑦</ci></apply></apply></apply><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1"><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2">subscript</csymbol><sum id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.2"></sum><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3"><leq id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.1"></leq><ci id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.2">𝑡</ci><ci id="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.3.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1"><times id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.2"></times><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3"><log id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.1"></log><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.2">𝑝</ci><ci id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.3a.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.3"><mtext mathsize="70%" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.3.2.3">CTC</mtext></ci></apply></apply><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2">𝜋</ci><ci id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex3.m1.5.5.1.1.1.1.1.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex3.m1.5c">\mathcal{L}_{\text{CTC}}=-\mathbb{E}_{(x,y,z)\in\mathcal{D}}\sum_{\pi\in\phi(y)}\sum_{t\leq T}\log p_{\text{CTC}}(\pi_{t}|x),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.p5.6" class="ltx_p">and the final objective loss is defined as a combination of <math id="S2.p5.5.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{LM}}" display="inline"><semantics id="S2.p5.5.m1.1a"><msub id="S2.p5.5.m1.1.1" xref="S2.p5.5.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p5.5.m1.1.1.2" xref="S2.p5.5.m1.1.1.2.cmml">ℒ</mi><mtext id="S2.p5.5.m1.1.1.3" xref="S2.p5.5.m1.1.1.3a.cmml">LM</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.p5.5.m1.1b"><apply id="S2.p5.5.m1.1.1.cmml" xref="S2.p5.5.m1.1.1"><csymbol cd="ambiguous" id="S2.p5.5.m1.1.1.1.cmml" xref="S2.p5.5.m1.1.1">subscript</csymbol><ci id="S2.p5.5.m1.1.1.2.cmml" xref="S2.p5.5.m1.1.1.2">ℒ</ci><ci id="S2.p5.5.m1.1.1.3a.cmml" xref="S2.p5.5.m1.1.1.3"><mtext mathsize="70%" id="S2.p5.5.m1.1.1.3.cmml" xref="S2.p5.5.m1.1.1.3">LM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.5.m1.1c">\mathcal{L}_{\text{LM}}</annotation></semantics></math> and <math id="S2.p5.6.m2.1" class="ltx_Math" alttext="\mathcal{L}_{\text{CTC}}" display="inline"><semantics id="S2.p5.6.m2.1a"><msub id="S2.p5.6.m2.1.1" xref="S2.p5.6.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p5.6.m2.1.1.2" xref="S2.p5.6.m2.1.1.2.cmml">ℒ</mi><mtext id="S2.p5.6.m2.1.1.3" xref="S2.p5.6.m2.1.1.3a.cmml">CTC</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.p5.6.m2.1b"><apply id="S2.p5.6.m2.1.1.cmml" xref="S2.p5.6.m2.1.1"><csymbol cd="ambiguous" id="S2.p5.6.m2.1.1.1.cmml" xref="S2.p5.6.m2.1.1">subscript</csymbol><ci id="S2.p5.6.m2.1.1.2.cmml" xref="S2.p5.6.m2.1.1.2">ℒ</ci><ci id="S2.p5.6.m2.1.1.3a.cmml" xref="S2.p5.6.m2.1.1.3"><mtext mathsize="70%" id="S2.p5.6.m2.1.1.3.cmml" xref="S2.p5.6.m2.1.1.3">CTC</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.6.m2.1c">\mathcal{L}_{\text{CTC}}</annotation></semantics></math>, i.e.,</p>
<table id="S2.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex4.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{task}}=\alpha\mathcal{L}_{\text{CTC}}+(1-\alpha)\mathcal{L}_{\text{LM}}" display="block"><semantics id="S2.Ex4.m1.1a"><mrow id="S2.Ex4.m1.1.1" xref="S2.Ex4.m1.1.1.cmml"><msub id="S2.Ex4.m1.1.1.3" xref="S2.Ex4.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex4.m1.1.1.3.2" xref="S2.Ex4.m1.1.1.3.2.cmml">ℒ</mi><mtext id="S2.Ex4.m1.1.1.3.3" xref="S2.Ex4.m1.1.1.3.3a.cmml">task</mtext></msub><mo id="S2.Ex4.m1.1.1.2" xref="S2.Ex4.m1.1.1.2.cmml">=</mo><mrow id="S2.Ex4.m1.1.1.1" xref="S2.Ex4.m1.1.1.1.cmml"><mrow id="S2.Ex4.m1.1.1.1.3" xref="S2.Ex4.m1.1.1.1.3.cmml"><mi id="S2.Ex4.m1.1.1.1.3.2" xref="S2.Ex4.m1.1.1.1.3.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S2.Ex4.m1.1.1.1.3.1" xref="S2.Ex4.m1.1.1.1.3.1.cmml">​</mo><msub id="S2.Ex4.m1.1.1.1.3.3" xref="S2.Ex4.m1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex4.m1.1.1.1.3.3.2" xref="S2.Ex4.m1.1.1.1.3.3.2.cmml">ℒ</mi><mtext id="S2.Ex4.m1.1.1.1.3.3.3" xref="S2.Ex4.m1.1.1.1.3.3.3a.cmml">CTC</mtext></msub></mrow><mo id="S2.Ex4.m1.1.1.1.2" xref="S2.Ex4.m1.1.1.1.2.cmml">+</mo><mrow id="S2.Ex4.m1.1.1.1.1" xref="S2.Ex4.m1.1.1.1.1.cmml"><mrow id="S2.Ex4.m1.1.1.1.1.1.1" xref="S2.Ex4.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex4.m1.1.1.1.1.1.1.2" xref="S2.Ex4.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex4.m1.1.1.1.1.1.1.1" xref="S2.Ex4.m1.1.1.1.1.1.1.1.cmml"><mn id="S2.Ex4.m1.1.1.1.1.1.1.1.2" xref="S2.Ex4.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.Ex4.m1.1.1.1.1.1.1.1.1" xref="S2.Ex4.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S2.Ex4.m1.1.1.1.1.1.1.1.3" xref="S2.Ex4.m1.1.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo stretchy="false" id="S2.Ex4.m1.1.1.1.1.1.1.3" xref="S2.Ex4.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.Ex4.m1.1.1.1.1.2" xref="S2.Ex4.m1.1.1.1.1.2.cmml">​</mo><msub id="S2.Ex4.m1.1.1.1.1.3" xref="S2.Ex4.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex4.m1.1.1.1.1.3.2" xref="S2.Ex4.m1.1.1.1.1.3.2.cmml">ℒ</mi><mtext id="S2.Ex4.m1.1.1.1.1.3.3" xref="S2.Ex4.m1.1.1.1.1.3.3a.cmml">LM</mtext></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex4.m1.1b"><apply id="S2.Ex4.m1.1.1.cmml" xref="S2.Ex4.m1.1.1"><eq id="S2.Ex4.m1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.2"></eq><apply id="S2.Ex4.m1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex4.m1.1.1.3.1.cmml" xref="S2.Ex4.m1.1.1.3">subscript</csymbol><ci id="S2.Ex4.m1.1.1.3.2.cmml" xref="S2.Ex4.m1.1.1.3.2">ℒ</ci><ci id="S2.Ex4.m1.1.1.3.3a.cmml" xref="S2.Ex4.m1.1.1.3.3"><mtext mathsize="70%" id="S2.Ex4.m1.1.1.3.3.cmml" xref="S2.Ex4.m1.1.1.3.3">task</mtext></ci></apply><apply id="S2.Ex4.m1.1.1.1.cmml" xref="S2.Ex4.m1.1.1.1"><plus id="S2.Ex4.m1.1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.1.2"></plus><apply id="S2.Ex4.m1.1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.1.3"><times id="S2.Ex4.m1.1.1.1.3.1.cmml" xref="S2.Ex4.m1.1.1.1.3.1"></times><ci id="S2.Ex4.m1.1.1.1.3.2.cmml" xref="S2.Ex4.m1.1.1.1.3.2">𝛼</ci><apply id="S2.Ex4.m1.1.1.1.3.3.cmml" xref="S2.Ex4.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.Ex4.m1.1.1.1.3.3.1.cmml" xref="S2.Ex4.m1.1.1.1.3.3">subscript</csymbol><ci id="S2.Ex4.m1.1.1.1.3.3.2.cmml" xref="S2.Ex4.m1.1.1.1.3.3.2">ℒ</ci><ci id="S2.Ex4.m1.1.1.1.3.3.3a.cmml" xref="S2.Ex4.m1.1.1.1.3.3.3"><mtext mathsize="70%" id="S2.Ex4.m1.1.1.1.3.3.3.cmml" xref="S2.Ex4.m1.1.1.1.3.3.3">CTC</mtext></ci></apply></apply><apply id="S2.Ex4.m1.1.1.1.1.cmml" xref="S2.Ex4.m1.1.1.1.1"><times id="S2.Ex4.m1.1.1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.1.1.2"></times><apply id="S2.Ex4.m1.1.1.1.1.1.1.1.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1"><minus id="S2.Ex4.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S2.Ex4.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.1.2">1</cn><ci id="S2.Ex4.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.1.1.1.1.1.3">𝛼</ci></apply><apply id="S2.Ex4.m1.1.1.1.1.3.cmml" xref="S2.Ex4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex4.m1.1.1.1.1.3.1.cmml" xref="S2.Ex4.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex4.m1.1.1.1.1.3.2.cmml" xref="S2.Ex4.m1.1.1.1.1.3.2">ℒ</ci><ci id="S2.Ex4.m1.1.1.1.1.3.3a.cmml" xref="S2.Ex4.m1.1.1.1.1.3.3"><mtext mathsize="70%" id="S2.Ex4.m1.1.1.1.1.3.3.cmml" xref="S2.Ex4.m1.1.1.1.1.3.3">LM</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex4.m1.1c">\mathcal{L}_{\text{task}}=\alpha\mathcal{L}_{\text{CTC}}+(1-\alpha)\mathcal{L}_{\text{LM}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.p5.8" class="ltx_p">where <math id="S2.p5.7.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.p5.7.m1.1a"><mi id="S2.p5.7.m1.1.1" xref="S2.p5.7.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.p5.7.m1.1b"><ci id="S2.p5.7.m1.1.1.cmml" xref="S2.p5.7.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.7.m1.1c">\alpha</annotation></semantics></math> is a hyperparameter with the constraint <math id="S2.p5.8.m2.1" class="ltx_Math" alttext="0\leq\alpha\leq 1" display="inline"><semantics id="S2.p5.8.m2.1a"><mrow id="S2.p5.8.m2.1.1" xref="S2.p5.8.m2.1.1.cmml"><mn id="S2.p5.8.m2.1.1.2" xref="S2.p5.8.m2.1.1.2.cmml">0</mn><mo id="S2.p5.8.m2.1.1.3" xref="S2.p5.8.m2.1.1.3.cmml">≤</mo><mi id="S2.p5.8.m2.1.1.4" xref="S2.p5.8.m2.1.1.4.cmml">α</mi><mo id="S2.p5.8.m2.1.1.5" xref="S2.p5.8.m2.1.1.5.cmml">≤</mo><mn id="S2.p5.8.m2.1.1.6" xref="S2.p5.8.m2.1.1.6.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.8.m2.1b"><apply id="S2.p5.8.m2.1.1.cmml" xref="S2.p5.8.m2.1.1"><and id="S2.p5.8.m2.1.1a.cmml" xref="S2.p5.8.m2.1.1"></and><apply id="S2.p5.8.m2.1.1b.cmml" xref="S2.p5.8.m2.1.1"><leq id="S2.p5.8.m2.1.1.3.cmml" xref="S2.p5.8.m2.1.1.3"></leq><cn type="integer" id="S2.p5.8.m2.1.1.2.cmml" xref="S2.p5.8.m2.1.1.2">0</cn><ci id="S2.p5.8.m2.1.1.4.cmml" xref="S2.p5.8.m2.1.1.4">𝛼</ci></apply><apply id="S2.p5.8.m2.1.1c.cmml" xref="S2.p5.8.m2.1.1"><leq id="S2.p5.8.m2.1.1.5.cmml" xref="S2.p5.8.m2.1.1.5"></leq><share href="#S2.p5.8.m2.1.1.4.cmml" id="S2.p5.8.m2.1.1d.cmml" xref="S2.p5.8.m2.1.1"></share><cn type="integer" id="S2.p5.8.m2.1.1.6.cmml" xref="S2.p5.8.m2.1.1.6">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.8.m2.1c">0\leq\alpha\leq 1</annotation></semantics></math>.</p>
</div>
<figure id="S2.F3" class="ltx_figure">
<p id="S2.F3.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S2.F3.1.1" class="ltx_text"><img src="/html/2406.12233/assets/EditDistance.png" id="S2.F3.1.1.g1" class="ltx_graphics ltx_img_square" width="275" height="268" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.5.2.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S2.F3.3.1" class="ltx_text" style="font-size:90%;">The edit distance of word pairs and the model's discriminative ability. Homophene pairs resemble each other closely in graphemes, a scenario where SyncVSR shows better classification performance over the vanilla setting trained without audio information. Non-autoregressive generation with strong audio reconstruction loss weight (<math id="S2.F3.3.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S2.F3.3.1.m1.1b"><mi id="S2.F3.3.1.m1.1.1" xref="S2.F3.3.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S2.F3.3.1.m1.1c"><ci id="S2.F3.3.1.m1.1.1.cmml" xref="S2.F3.3.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.3.1.m1.1d">\lambda</annotation></semantics></math>) is optimal, whereas masked reconstruction could cause harm in certain instances.</span></figcaption>
</figure>
<div id="S2.p6" class="ltx_para ltx_noindent">
<p id="S2.p6.1" class="ltx_p"><span id="S2.p6.1.1" class="ltx_text ltx_font_bold">Audio Reconstruction Loss.</span>
The synchronization between audio and video in our framework is designed to align each video frame with a corresponding number of audio tokens. This alignment is based on audio (16kHz) and video (25fps) sampling rates, with a specific hop size ensuring a coherent match between video frame rate and audio units. We use a ratio of one video frame to four vector quantized audio tokens (100Hz).</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.4" class="ltx_p">To make the model generate discrete audio tokens, we use cross-entropy loss to predict the quantized audio <math id="S2.p7.1.m1.1" class="ltx_Math" alttext="z_{t}" display="inline"><semantics id="S2.p7.1.m1.1a"><msub id="S2.p7.1.m1.1.1" xref="S2.p7.1.m1.1.1.cmml"><mi id="S2.p7.1.m1.1.1.2" xref="S2.p7.1.m1.1.1.2.cmml">z</mi><mi id="S2.p7.1.m1.1.1.3" xref="S2.p7.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p7.1.m1.1b"><apply id="S2.p7.1.m1.1.1.cmml" xref="S2.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p7.1.m1.1.1.1.cmml" xref="S2.p7.1.m1.1.1">subscript</csymbol><ci id="S2.p7.1.m1.1.1.2.cmml" xref="S2.p7.1.m1.1.1.2">𝑧</ci><ci id="S2.p7.1.m1.1.1.3.cmml" xref="S2.p7.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.1.m1.1c">z_{t}</annotation></semantics></math> from the input video frames. Let <math id="S2.p7.2.m2.1" class="ltx_Math" alttext="q(z_{t}|x)" display="inline"><semantics id="S2.p7.2.m2.1a"><mrow id="S2.p7.2.m2.1.1" xref="S2.p7.2.m2.1.1.cmml"><mi id="S2.p7.2.m2.1.1.3" xref="S2.p7.2.m2.1.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S2.p7.2.m2.1.1.2" xref="S2.p7.2.m2.1.1.2.cmml">​</mo><mrow id="S2.p7.2.m2.1.1.1.1" xref="S2.p7.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p7.2.m2.1.1.1.1.2" xref="S2.p7.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.p7.2.m2.1.1.1.1.1" xref="S2.p7.2.m2.1.1.1.1.1.cmml"><msub id="S2.p7.2.m2.1.1.1.1.1.2" xref="S2.p7.2.m2.1.1.1.1.1.2.cmml"><mi id="S2.p7.2.m2.1.1.1.1.1.2.2" xref="S2.p7.2.m2.1.1.1.1.1.2.2.cmml">z</mi><mi id="S2.p7.2.m2.1.1.1.1.1.2.3" xref="S2.p7.2.m2.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.p7.2.m2.1.1.1.1.1.1" xref="S2.p7.2.m2.1.1.1.1.1.1.cmml">|</mo><mi id="S2.p7.2.m2.1.1.1.1.1.3" xref="S2.p7.2.m2.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.p7.2.m2.1.1.1.1.3" xref="S2.p7.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p7.2.m2.1b"><apply id="S2.p7.2.m2.1.1.cmml" xref="S2.p7.2.m2.1.1"><times id="S2.p7.2.m2.1.1.2.cmml" xref="S2.p7.2.m2.1.1.2"></times><ci id="S2.p7.2.m2.1.1.3.cmml" xref="S2.p7.2.m2.1.1.3">𝑞</ci><apply id="S2.p7.2.m2.1.1.1.1.1.cmml" xref="S2.p7.2.m2.1.1.1.1"><csymbol cd="latexml" id="S2.p7.2.m2.1.1.1.1.1.1.cmml" xref="S2.p7.2.m2.1.1.1.1.1.1">conditional</csymbol><apply id="S2.p7.2.m2.1.1.1.1.1.2.cmml" xref="S2.p7.2.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p7.2.m2.1.1.1.1.1.2.1.cmml" xref="S2.p7.2.m2.1.1.1.1.1.2">subscript</csymbol><ci id="S2.p7.2.m2.1.1.1.1.1.2.2.cmml" xref="S2.p7.2.m2.1.1.1.1.1.2.2">𝑧</ci><ci id="S2.p7.2.m2.1.1.1.1.1.2.3.cmml" xref="S2.p7.2.m2.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S2.p7.2.m2.1.1.1.1.1.3.cmml" xref="S2.p7.2.m2.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.2.m2.1c">q(z_{t}|x)</annotation></semantics></math> be an output of the model at time <math id="S2.p7.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.p7.3.m3.1a"><mi id="S2.p7.3.m3.1.1" xref="S2.p7.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.p7.3.m3.1b"><ci id="S2.p7.3.m3.1.1.cmml" xref="S2.p7.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.3.m3.1c">t</annotation></semantics></math> from the video <math id="S2.p7.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.p7.4.m4.1a"><mi id="S2.p7.4.m4.1.1" xref="S2.p7.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p7.4.m4.1b"><ci id="S2.p7.4.m4.1.1.cmml" xref="S2.p7.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.4.m4.1c">x</annotation></semantics></math>. The audio reconstruction loss is as follows:</p>
<table id="S2.Ex5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex5.m1.4" class="ltx_Math" alttext="\mathcal{L}_{\text{Sync}}=\mathbb{E}_{(x,y,z)\in\mathcal{D}}\left[-\frac{1}{T}\sum_{t\leq T}\log q(z_{t}|x)\right]" display="block"><semantics id="S2.Ex5.m1.4a"><mrow id="S2.Ex5.m1.4.4" xref="S2.Ex5.m1.4.4.cmml"><msub id="S2.Ex5.m1.4.4.3" xref="S2.Ex5.m1.4.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex5.m1.4.4.3.2" xref="S2.Ex5.m1.4.4.3.2.cmml">ℒ</mi><mtext id="S2.Ex5.m1.4.4.3.3" xref="S2.Ex5.m1.4.4.3.3a.cmml">Sync</mtext></msub><mo id="S2.Ex5.m1.4.4.2" xref="S2.Ex5.m1.4.4.2.cmml">=</mo><mrow id="S2.Ex5.m1.4.4.1" xref="S2.Ex5.m1.4.4.1.cmml"><msub id="S2.Ex5.m1.4.4.1.3" xref="S2.Ex5.m1.4.4.1.3.cmml"><mi id="S2.Ex5.m1.4.4.1.3.2" xref="S2.Ex5.m1.4.4.1.3.2.cmml">𝔼</mi><mrow id="S2.Ex5.m1.3.3.3" xref="S2.Ex5.m1.3.3.3.cmml"><mrow id="S2.Ex5.m1.3.3.3.5.2" xref="S2.Ex5.m1.3.3.3.5.1.cmml"><mo stretchy="false" id="S2.Ex5.m1.3.3.3.5.2.1" xref="S2.Ex5.m1.3.3.3.5.1.cmml">(</mo><mi id="S2.Ex5.m1.1.1.1.1" xref="S2.Ex5.m1.1.1.1.1.cmml">x</mi><mo id="S2.Ex5.m1.3.3.3.5.2.2" xref="S2.Ex5.m1.3.3.3.5.1.cmml">,</mo><mi id="S2.Ex5.m1.2.2.2.2" xref="S2.Ex5.m1.2.2.2.2.cmml">y</mi><mo id="S2.Ex5.m1.3.3.3.5.2.3" xref="S2.Ex5.m1.3.3.3.5.1.cmml">,</mo><mi id="S2.Ex5.m1.3.3.3.3" xref="S2.Ex5.m1.3.3.3.3.cmml">z</mi><mo stretchy="false" id="S2.Ex5.m1.3.3.3.5.2.4" xref="S2.Ex5.m1.3.3.3.5.1.cmml">)</mo></mrow><mo id="S2.Ex5.m1.3.3.3.4" xref="S2.Ex5.m1.3.3.3.4.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.Ex5.m1.3.3.3.6" xref="S2.Ex5.m1.3.3.3.6.cmml">𝒟</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.Ex5.m1.4.4.1.2" xref="S2.Ex5.m1.4.4.1.2.cmml">​</mo><mrow id="S2.Ex5.m1.4.4.1.1.1" xref="S2.Ex5.m1.4.4.1.1.2.cmml"><mo id="S2.Ex5.m1.4.4.1.1.1.2" xref="S2.Ex5.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S2.Ex5.m1.4.4.1.1.1.1" xref="S2.Ex5.m1.4.4.1.1.1.1.cmml"><mo id="S2.Ex5.m1.4.4.1.1.1.1a" xref="S2.Ex5.m1.4.4.1.1.1.1.cmml">−</mo><mrow id="S2.Ex5.m1.4.4.1.1.1.1.1" xref="S2.Ex5.m1.4.4.1.1.1.1.1.cmml"><mfrac id="S2.Ex5.m1.4.4.1.1.1.1.1.3" xref="S2.Ex5.m1.4.4.1.1.1.1.1.3.cmml"><mn id="S2.Ex5.m1.4.4.1.1.1.1.1.3.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.3.2.cmml">1</mn><mi id="S2.Ex5.m1.4.4.1.1.1.1.1.3.3" xref="S2.Ex5.m1.4.4.1.1.1.1.1.3.3.cmml">T</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.Ex5.m1.4.4.1.1.1.1.1.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex5.m1.4.4.1.1.1.1.1.1" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.cmml"><munder id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.cmml"><mi id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.1" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.1.cmml">≤</mo><mi id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.3" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.3.cmml">T</mi></mrow></munder><mrow id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.cmml"><mrow id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.1" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3a" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.cmml">⁡</mo><mi id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.2.cmml">q</mi></mrow><mo lspace="0em" rspace="0em" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.2.cmml">z</mi><mi id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S2.Ex5.m1.4.4.1.1.1.3" xref="S2.Ex5.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex5.m1.4b"><apply id="S2.Ex5.m1.4.4.cmml" xref="S2.Ex5.m1.4.4"><eq id="S2.Ex5.m1.4.4.2.cmml" xref="S2.Ex5.m1.4.4.2"></eq><apply id="S2.Ex5.m1.4.4.3.cmml" xref="S2.Ex5.m1.4.4.3"><csymbol cd="ambiguous" id="S2.Ex5.m1.4.4.3.1.cmml" xref="S2.Ex5.m1.4.4.3">subscript</csymbol><ci id="S2.Ex5.m1.4.4.3.2.cmml" xref="S2.Ex5.m1.4.4.3.2">ℒ</ci><ci id="S2.Ex5.m1.4.4.3.3a.cmml" xref="S2.Ex5.m1.4.4.3.3"><mtext mathsize="70%" id="S2.Ex5.m1.4.4.3.3.cmml" xref="S2.Ex5.m1.4.4.3.3">Sync</mtext></ci></apply><apply id="S2.Ex5.m1.4.4.1.cmml" xref="S2.Ex5.m1.4.4.1"><times id="S2.Ex5.m1.4.4.1.2.cmml" xref="S2.Ex5.m1.4.4.1.2"></times><apply id="S2.Ex5.m1.4.4.1.3.cmml" xref="S2.Ex5.m1.4.4.1.3"><csymbol cd="ambiguous" id="S2.Ex5.m1.4.4.1.3.1.cmml" xref="S2.Ex5.m1.4.4.1.3">subscript</csymbol><ci id="S2.Ex5.m1.4.4.1.3.2.cmml" xref="S2.Ex5.m1.4.4.1.3.2">𝔼</ci><apply id="S2.Ex5.m1.3.3.3.cmml" xref="S2.Ex5.m1.3.3.3"><in id="S2.Ex5.m1.3.3.3.4.cmml" xref="S2.Ex5.m1.3.3.3.4"></in><vector id="S2.Ex5.m1.3.3.3.5.1.cmml" xref="S2.Ex5.m1.3.3.3.5.2"><ci id="S2.Ex5.m1.1.1.1.1.cmml" xref="S2.Ex5.m1.1.1.1.1">𝑥</ci><ci id="S2.Ex5.m1.2.2.2.2.cmml" xref="S2.Ex5.m1.2.2.2.2">𝑦</ci><ci id="S2.Ex5.m1.3.3.3.3.cmml" xref="S2.Ex5.m1.3.3.3.3">𝑧</ci></vector><ci id="S2.Ex5.m1.3.3.3.6.cmml" xref="S2.Ex5.m1.3.3.3.6">𝒟</ci></apply></apply><apply id="S2.Ex5.m1.4.4.1.1.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.Ex5.m1.4.4.1.1.2.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S2.Ex5.m1.4.4.1.1.1.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1"><minus id="S2.Ex5.m1.4.4.1.1.1.1.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1"></minus><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1"><times id="S2.Ex5.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.2"></times><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.3.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.3"><divide id="S2.Ex5.m1.4.4.1.1.1.1.1.3.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.3"></divide><cn type="integer" id="S2.Ex5.m1.4.4.1.1.1.1.1.3.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.3.2">1</cn><ci id="S2.Ex5.m1.4.4.1.1.1.1.1.3.3.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.3.3">𝑇</ci></apply><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1"><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2">subscript</csymbol><sum id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.2"></sum><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3"><leq id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.1"></leq><ci id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.2">𝑡</ci><ci id="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.3.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1"><times id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.2"></times><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3"><log id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.1"></log><ci id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.3.2">𝑞</ci></apply><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.2">𝑧</ci><ci id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex5.m1.4.4.1.1.1.1.1.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex5.m1.4c">\mathcal{L}_{\text{Sync}}=\mathbb{E}_{(x,y,z)\in\mathcal{D}}\left[-\frac{1}{T}\sum_{t\leq T}\log q(z_{t}|x)\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.p7.5" class="ltx_p">where <math id="S2.p7.5.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.p7.5.m1.1a"><mi id="S2.p7.5.m1.1.1" xref="S2.p7.5.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.p7.5.m1.1b"><ci id="S2.p7.5.m1.1.1.cmml" xref="S2.p7.5.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p7.5.m1.1c">T</annotation></semantics></math> denotes the number of video frames.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p">Using these, we simply design the total loss as below, with the hyperparameter <math id="S2.p8.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S2.p8.1.m1.1a"><mi id="S2.p8.1.m1.1.1" xref="S2.p8.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S2.p8.1.m1.1b"><ci id="S2.p8.1.m1.1.1.cmml" xref="S2.p8.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.1.m1.1c">\lambda</annotation></semantics></math> as the weight for the audio reconstruction loss,</p>
<table id="S2.Ex6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex6.m1.1" class="ltx_Math" alttext="\mathcal{L}=\mathcal{L}_{\text{task}}+\lambda\mathcal{L}_{\text{Sync}}." display="block"><semantics id="S2.Ex6.m1.1a"><mrow id="S2.Ex6.m1.1.1.1" xref="S2.Ex6.m1.1.1.1.1.cmml"><mrow id="S2.Ex6.m1.1.1.1.1" xref="S2.Ex6.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex6.m1.1.1.1.1.2" xref="S2.Ex6.m1.1.1.1.1.2.cmml">ℒ</mi><mo id="S2.Ex6.m1.1.1.1.1.1" xref="S2.Ex6.m1.1.1.1.1.1.cmml">=</mo><mrow id="S2.Ex6.m1.1.1.1.1.3" xref="S2.Ex6.m1.1.1.1.1.3.cmml"><msub id="S2.Ex6.m1.1.1.1.1.3.2" xref="S2.Ex6.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex6.m1.1.1.1.1.3.2.2" xref="S2.Ex6.m1.1.1.1.1.3.2.2.cmml">ℒ</mi><mtext id="S2.Ex6.m1.1.1.1.1.3.2.3" xref="S2.Ex6.m1.1.1.1.1.3.2.3a.cmml">task</mtext></msub><mo id="S2.Ex6.m1.1.1.1.1.3.1" xref="S2.Ex6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S2.Ex6.m1.1.1.1.1.3.3" xref="S2.Ex6.m1.1.1.1.1.3.3.cmml"><mi id="S2.Ex6.m1.1.1.1.1.3.3.2" xref="S2.Ex6.m1.1.1.1.1.3.3.2.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S2.Ex6.m1.1.1.1.1.3.3.1" xref="S2.Ex6.m1.1.1.1.1.3.3.1.cmml">​</mo><msub id="S2.Ex6.m1.1.1.1.1.3.3.3" xref="S2.Ex6.m1.1.1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex6.m1.1.1.1.1.3.3.3.2" xref="S2.Ex6.m1.1.1.1.1.3.3.3.2.cmml">ℒ</mi><mtext id="S2.Ex6.m1.1.1.1.1.3.3.3.3" xref="S2.Ex6.m1.1.1.1.1.3.3.3.3a.cmml">Sync</mtext></msub></mrow></mrow></mrow><mo lspace="0em" id="S2.Ex6.m1.1.1.1.2" xref="S2.Ex6.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex6.m1.1b"><apply id="S2.Ex6.m1.1.1.1.1.cmml" xref="S2.Ex6.m1.1.1.1"><eq id="S2.Ex6.m1.1.1.1.1.1.cmml" xref="S2.Ex6.m1.1.1.1.1.1"></eq><ci id="S2.Ex6.m1.1.1.1.1.2.cmml" xref="S2.Ex6.m1.1.1.1.1.2">ℒ</ci><apply id="S2.Ex6.m1.1.1.1.1.3.cmml" xref="S2.Ex6.m1.1.1.1.1.3"><plus id="S2.Ex6.m1.1.1.1.1.3.1.cmml" xref="S2.Ex6.m1.1.1.1.1.3.1"></plus><apply id="S2.Ex6.m1.1.1.1.1.3.2.cmml" xref="S2.Ex6.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.Ex6.m1.1.1.1.1.3.2.1.cmml" xref="S2.Ex6.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.Ex6.m1.1.1.1.1.3.2.2.cmml" xref="S2.Ex6.m1.1.1.1.1.3.2.2">ℒ</ci><ci id="S2.Ex6.m1.1.1.1.1.3.2.3a.cmml" xref="S2.Ex6.m1.1.1.1.1.3.2.3"><mtext mathsize="70%" id="S2.Ex6.m1.1.1.1.1.3.2.3.cmml" xref="S2.Ex6.m1.1.1.1.1.3.2.3">task</mtext></ci></apply><apply id="S2.Ex6.m1.1.1.1.1.3.3.cmml" xref="S2.Ex6.m1.1.1.1.1.3.3"><times id="S2.Ex6.m1.1.1.1.1.3.3.1.cmml" xref="S2.Ex6.m1.1.1.1.1.3.3.1"></times><ci id="S2.Ex6.m1.1.1.1.1.3.3.2.cmml" xref="S2.Ex6.m1.1.1.1.1.3.3.2">𝜆</ci><apply id="S2.Ex6.m1.1.1.1.1.3.3.3.cmml" xref="S2.Ex6.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.Ex6.m1.1.1.1.1.3.3.3.1.cmml" xref="S2.Ex6.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.Ex6.m1.1.1.1.1.3.3.3.2.cmml" xref="S2.Ex6.m1.1.1.1.1.3.3.3.2">ℒ</ci><ci id="S2.Ex6.m1.1.1.1.1.3.3.3.3a.cmml" xref="S2.Ex6.m1.1.1.1.1.3.3.3.3"><mtext mathsize="70%" id="S2.Ex6.m1.1.1.1.1.3.3.3.3.cmml" xref="S2.Ex6.m1.1.1.1.1.3.3.3.3">Sync</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex6.m1.1c">\mathcal{L}=\mathcal{L}_{\text{task}}+\lambda\mathcal{L}_{\text{Sync}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.6.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.7.2" class="ltx_text" style="font-size:90%;">Video-based VSR performance on word-level tasks. Evaluations were done on Lip Reading in the Wild (LRW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> English benchmark and CAS-VSR-W1K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> Chinese benchmark. WB implies the usage of word boundary, which is an indicator for the target word's appearance. Our metrics are averaged across three experiments, with subscripts notating the standard deviation. Transcription Alignment is our experiment using the method of aligning character-level pseudo-labels from ASR models instead of auditory data.</span></figcaption>
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S2.T1.1.1.2.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S2.T1.1.1.3.1" class="ltx_text ltx_font_bold">Temporal Model</span></td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S2.T1.1.1.4.1" class="ltx_text ltx_font_bold">Video Hours</span></td>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S2.T1.1.1.1.1" class="ltx_text ltx_font_bold">Top-1 Acc. (%) <math id="S2.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S2.T1.1.1.1.1.m1.1a"><mo stretchy="false" id="S2.T1.1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.m1.1b"><ci id="S2.T1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
</tr>
<tr id="S2.T1.4.5" class="ltx_tr">
<td id="S2.T1.4.5.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.4.5.1.1" class="ltx_text ltx_font_bold">LRW</span></td>
<td id="S2.T1.4.5.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.4.5.2.1" class="ltx_text ltx_font_bold">LRW(WB)</span></td>
<td id="S2.T1.4.5.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.4.5.3.1" class="ltx_text ltx_font_bold">CAS-VSR-W1K</span></td>
</tr>
<tr id="S2.T1.4.6" class="ltx_tr">
<td id="S2.T1.4.6.1" class="ltx_td ltx_align_left ltx_border_t">Born-Again <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S2.T1.4.6.2" class="ltx_td ltx_align_center ltx_border_t">MS-TCN</td>
<td id="S2.T1.4.6.3" class="ltx_td ltx_align_center ltx_border_t">157</td>
<td id="S2.T1.4.6.4" class="ltx_td ltx_align_center ltx_border_t">87.9</td>
<td id="S2.T1.4.6.5" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S2.T1.4.6.6" class="ltx_td ltx_align_center ltx_border_t">46.6</td>
</tr>
<tr id="S2.T1.4.7" class="ltx_tr">
<td id="S2.T1.4.7.1" class="ltx_td ltx_align_left">LiRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>
</td>
<td id="S2.T1.4.7.2" class="ltx_td ltx_align_center">Conformer</td>
<td id="S2.T1.4.7.3" class="ltx_td ltx_align_center">590</td>
<td id="S2.T1.4.7.4" class="ltx_td ltx_align_center">88.1</td>
<td id="S2.T1.4.7.5" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.7.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T1.4.8" class="ltx_tr">
<td id="S2.T1.4.8.1" class="ltx_td ltx_align_left">WPCL + APFF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S2.T1.4.8.2" class="ltx_td ltx_align_center">MS-TCN</td>
<td id="S2.T1.4.8.3" class="ltx_td ltx_align_center">157</td>
<td id="S2.T1.4.8.4" class="ltx_td ltx_align_center">88.3</td>
<td id="S2.T1.4.8.5" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.8.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T1.4.9" class="ltx_tr">
<td id="S2.T1.4.9.1" class="ltx_td ltx_align_left">Ma <span id="S2.T1.4.9.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>
</td>
<td id="S2.T1.4.9.2" class="ltx_td ltx_align_center">DC-TCN</td>
<td id="S2.T1.4.9.3" class="ltx_td ltx_align_center">157</td>
<td id="S2.T1.4.9.4" class="ltx_td ltx_align_center">88.4</td>
<td id="S2.T1.4.9.5" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.9.6" class="ltx_td ltx_align_center">43.7</td>
</tr>
<tr id="S2.T1.4.10" class="ltx_tr">
<td id="S2.T1.4.10.1" class="ltx_td ltx_align_left">Feng <span id="S2.T1.4.10.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>
</td>
<td id="S2.T1.4.10.2" class="ltx_td ltx_align_center">BiGRU</td>
<td id="S2.T1.4.10.3" class="ltx_td ltx_align_center">157</td>
<td id="S2.T1.4.10.4" class="ltx_td ltx_align_center">86.2</td>
<td id="S2.T1.4.10.5" class="ltx_td ltx_align_center">88.4</td>
<td id="S2.T1.4.10.6" class="ltx_td ltx_align_center"><span id="S2.T1.4.10.6.1" class="ltx_text ltx_framed ltx_framed_underline">55.7</span></td>
</tr>
<tr id="S2.T1.4.11" class="ltx_tr">
<td id="S2.T1.4.11.1" class="ltx_td ltx_align_left">MVM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S2.T1.4.11.2" class="ltx_td ltx_align_center">MS-TCN</td>
<td id="S2.T1.4.11.3" class="ltx_td ltx_align_center">157</td>
<td id="S2.T1.4.11.4" class="ltx_td ltx_align_center">88.5</td>
<td id="S2.T1.4.11.5" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.11.6" class="ltx_td ltx_align_center">53.8</td>
</tr>
<tr id="S2.T1.4.12" class="ltx_tr">
<td id="S2.T1.4.12.1" class="ltx_td ltx_align_left">NetVLAD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>
</td>
<td id="S2.T1.4.12.2" class="ltx_td ltx_align_center">MS-TCN</td>
<td id="S2.T1.4.12.3" class="ltx_td ltx_align_center">157</td>
<td id="S2.T1.4.12.4" class="ltx_td ltx_align_center">89.4</td>
<td id="S2.T1.4.12.5" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.12.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T1.4.13" class="ltx_tr">
<td id="S2.T1.4.13.1" class="ltx_td ltx_align_left">Koumparoulis <span id="S2.T1.4.13.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</td>
<td id="S2.T1.4.13.2" class="ltx_td ltx_align_center">Transformer</td>
<td id="S2.T1.4.13.3" class="ltx_td ltx_align_center">157</td>
<td id="S2.T1.4.13.4" class="ltx_td ltx_align_center">89.5</td>
<td id="S2.T1.4.13.5" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.13.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T1.4.14" class="ltx_tr">
<td id="S2.T1.4.14.1" class="ltx_td ltx_align_left">Training Strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="S2.T1.4.14.2" class="ltx_td ltx_align_center">DC-TCN</td>
<td id="S2.T1.4.14.3" class="ltx_td ltx_align_center">157</td>
<td id="S2.T1.4.14.4" class="ltx_td ltx_align_center">90.4</td>
<td id="S2.T1.4.14.5" class="ltx_td ltx_align_center">92.1</td>
<td id="S2.T1.4.14.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T1.4.15" class="ltx_tr">
<td id="S2.T1.4.15.1" class="ltx_td ltx_align_left">MTLAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>
</td>
<td id="S2.T1.4.15.2" class="ltx_td ltx_align_center">DC-TCN</td>
<td id="S2.T1.4.15.3" class="ltx_td ltx_align_center">157</td>
<td id="S2.T1.4.15.4" class="ltx_td ltx_align_center"><span id="S2.T1.4.15.4.1" class="ltx_text ltx_framed ltx_framed_underline">91.7</span></td>
<td id="S2.T1.4.15.5" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.15.6" class="ltx_td ltx_align_center">54.3</td>
</tr>
<tr id="S2.T1.4.16" class="ltx_tr">
<td id="S2.T1.4.16.1" class="ltx_td ltx_align_left">Training Strategy + LiRA</td>
<td id="S2.T1.4.16.2" class="ltx_td ltx_align_center">DC-TCN</td>
<td id="S2.T1.4.16.3" class="ltx_td ltx_align_center">595</td>
<td id="S2.T1.4.16.4" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.16.5" class="ltx_td ltx_align_center">92.3</td>
<td id="S2.T1.4.16.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T1.4.17" class="ltx_tr">
<td id="S2.T1.4.17.1" class="ltx_td ltx_align_left">Training Strategy + CM-Aux <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S2.T1.4.17.2" class="ltx_td ltx_align_center">DC-TCN</td>
<td id="S2.T1.4.17.3" class="ltx_td ltx_align_center">1,459</td>
<td id="S2.T1.4.17.4" class="ltx_td ltx_align_center">-</td>
<td id="S2.T1.4.17.5" class="ltx_td ltx_align_center"><span id="S2.T1.4.17.5.1" class="ltx_text ltx_framed ltx_framed_underline">92.9</span></td>
<td id="S2.T1.4.17.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T1.4.18" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T1.4.18.1" class="ltx_td ltx_align_left"><span id="S2.T1.4.18.1.1" class="ltx_text" style="background-color:#EDF2FF;">Transcription Alignment</span></td>
<td id="S2.T1.4.18.2" class="ltx_td ltx_align_center"><span id="S2.T1.4.18.2.1" class="ltx_text" style="background-color:#EDF2FF;">Transformer</span></td>
<td id="S2.T1.4.18.3" class="ltx_td ltx_align_center"><span id="S2.T1.4.18.3.1" class="ltx_text" style="background-color:#EDF2FF;">157</span></td>
<td id="S2.T1.4.18.4" class="ltx_td ltx_align_center"><span id="S2.T1.4.18.4.1" class="ltx_text" style="background-color:#EDF2FF;">93.1</span></td>
<td id="S2.T1.4.18.5" class="ltx_td ltx_align_center"><span id="S2.T1.4.18.5.1" class="ltx_text" style="background-color:#EDF2FF;">94.8</span></td>
<td id="S2.T1.4.18.6" class="ltx_td ltx_align_center"><span id="S2.T1.4.18.6.1" class="ltx_text" style="background-color:#EDF2FF;">-</span></td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T1.4.4.4" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T1.4.4.4.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR</span></td>
<td id="S2.T1.4.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.4.4.5.1" class="ltx_text" style="background-color:#EDF2FF;">Transformer</span></td>
<td id="S2.T1.4.4.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.4.4.6.1" class="ltx_text" style="background-color:#EDF2FF;">157</span></td>
<td id="S2.T1.2.2.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.2.2.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">93.2<span id="S2.T1.2.2.1.1.1" class="ltx_text ltx_font_medium"> <math id="S2.T1.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.2.2.1.1.1.m1.1a"><mo mathbackground="#EDF2FF" mathsize="70%" id="S2.T1.2.2.1.1.1.m1.1.1" xref="S2.T1.2.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.2.2.1.1.1.m1.1.1.cmml" xref="S2.T1.2.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S2.T1.2.2.1.1.1.1" class="ltx_text" style="font-size:70%;"> 0.1</span></span></span></td>
<td id="S2.T1.3.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.3.3.2.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">95.0<span id="S2.T1.3.3.2.1.1" class="ltx_text ltx_font_medium"> <math id="S2.T1.3.3.2.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.3.3.2.1.1.m1.1a"><mo mathbackground="#EDF2FF" mathsize="70%" id="S2.T1.3.3.2.1.1.m1.1.1" xref="S2.T1.3.3.2.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.2.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.3.3.2.1.1.m1.1.1.cmml" xref="S2.T1.3.3.2.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.2.1.1.m1.1c">\pm</annotation></semantics></math><span id="S2.T1.3.3.2.1.1.1" class="ltx_text" style="font-size:70%;"> 0.0</span></span></span></td>
<td id="S2.T1.4.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.4.4.3.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">58.2<span id="S2.T1.4.4.3.1.1" class="ltx_text ltx_font_medium"> <math id="S2.T1.4.4.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.4.4.3.1.1.m1.1a"><mo mathbackground="#EDF2FF" mathsize="70%" id="S2.T1.4.4.3.1.1.m1.1.1" xref="S2.T1.4.4.3.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.3.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.4.4.3.1.1.m1.1.1.cmml" xref="S2.T1.4.4.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.3.1.1.m1.1c">\pm</annotation></semantics></math><span id="S2.T1.4.4.3.1.1.1" class="ltx_text" style="font-size:70%;"> 0.0</span></span></span></td>
</tr>
</table>
</figure>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.5.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S2.T2.6.2" class="ltx_text" style="font-size:90%;">Landmark-based VSR evaluated on a word-level task. The methods below were trained from scratch on the LRW.</span></figcaption>
<div id="S2.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:114.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(12.4pt,-3.3pt) scale(1.06078771412217,1.06078771412217) ;">
<table id="S2.T2.3.3" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.1.1.1" class="ltx_tr">
<td id="S2.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S2.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">Input Type</span></td>
<td id="S2.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">#Params</span></td>
<td id="S2.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Top-1 <math id="S2.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S2.T2.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S2.T2.1.1.1.1.1.m1.1.1" xref="S2.T2.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.1.1.m1.1b"><ci id="S2.T2.1.1.1.1.1.m1.1.1.cmml" xref="S2.T2.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
</tr>
<tr id="S2.T2.3.3.4" class="ltx_tr">
<td id="S2.T2.3.3.4.1" class="ltx_td ltx_align_left ltx_border_t">Lip Graph Assisted <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</td>
<td id="S2.T2.3.3.4.2" class="ltx_td ltx_align_center ltx_border_t">Graph</td>
<td id="S2.T2.3.3.4.3" class="ltx_td ltx_align_center ltx_border_t">30M</td>
<td id="S2.T2.3.3.4.4" class="ltx_td ltx_align_center ltx_border_t">49.3</td>
</tr>
<tr id="S2.T2.3.3.5" class="ltx_tr">
<td id="S2.T2.3.3.5.1" class="ltx_td ltx_align_left">Adaptive GCN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>
</td>
<td id="S2.T2.3.3.5.2" class="ltx_td ltx_align_center">Graph</td>
<td id="S2.T2.3.3.5.3" class="ltx_td ltx_align_center">45M</td>
<td id="S2.T2.3.3.5.4" class="ltx_td ltx_align_center">60.7</td>
</tr>
<tr id="S2.T2.3.3.6" class="ltx_tr">
<td id="S2.T2.3.3.6.1" class="ltx_td ltx_align_left">Another Point of View <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</td>
<td id="S2.T2.3.3.6.2" class="ltx_td ltx_align_center">Pointcloud</td>
<td id="S2.T2.3.3.6.3" class="ltx_td ltx_align_center">12M</td>
<td id="S2.T2.3.3.6.4" class="ltx_td ltx_align_center"><span id="S2.T2.3.3.6.4.1" class="ltx_text ltx_framed ltx_framed_underline">62.7</span></td>
</tr>
<tr id="S2.T2.2.2.2" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T2.2.2.2.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.2.2.2.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR</span></td>
<td id="S2.T2.2.2.2.3" class="ltx_td ltx_align_center"><span id="S2.T2.2.2.2.3.1" class="ltx_text" style="background-color:#EDF2FF;">Pointcloud</span></td>
<td id="S2.T2.2.2.2.4" class="ltx_td ltx_align_center"><span id="S2.T2.2.2.2.4.1" class="ltx_text" style="background-color:#EDF2FF;">11M</span></td>
<td id="S2.T2.2.2.2.1" class="ltx_td ltx_align_center"><span id="S2.T2.2.2.2.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">75.1<span id="S2.T2.2.2.2.1.1.1" class="ltx_text ltx_font_medium"> <math id="S2.T2.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T2.2.2.2.1.1.1.m1.1a"><mo mathbackground="#EDF2FF" mathsize="70%" id="S2.T2.2.2.2.1.1.1.m1.1.1" xref="S2.T2.2.2.2.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T2.2.2.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S2.T2.2.2.2.1.1.1.m1.1.1.cmml" xref="S2.T2.2.2.2.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.2.2.2.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S2.T2.2.2.2.1.1.1.1" class="ltx_text" style="font-size:70%;"> 0.1</span></span></span></td>
</tr>
<tr id="S2.T2.3.3.3" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T2.3.3.3.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T2.3.3.3.2.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR(WB)</span></td>
<td id="S2.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.3.3.3.3.1" class="ltx_text" style="background-color:#EDF2FF;">Pointcloud</span></td>
<td id="S2.T2.3.3.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.3.3.3.4.1" class="ltx_text" style="background-color:#EDF2FF;">11M</span></td>
<td id="S2.T2.3.3.3.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.3.3.3.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">80.3<span id="S2.T2.3.3.3.1.1.1" class="ltx_text ltx_font_medium"> <math id="S2.T2.3.3.3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T2.3.3.3.1.1.1.m1.1a"><mo mathbackground="#EDF2FF" mathsize="70%" id="S2.T2.3.3.3.1.1.1.m1.1.1" xref="S2.T2.3.3.3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T2.3.3.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S2.T2.3.3.3.1.1.1.m1.1.1.cmml" xref="S2.T2.3.3.3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.3.3.3.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S2.T2.3.3.3.1.1.1.1" class="ltx_text" style="font-size:70%;"> 0.0</span></span></span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S2.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T3.3.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S2.T3.4.2" class="ltx_text" style="font-size:90%;">Video-based VSR performance on sentence-level tasks grouped with video data resource usage. Evaluations were done on LRS2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> and LRS3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> benchmarks. LM indicates whether an external language model is used. The methods listed below use the base-size model unless specified as large-size. Reported scores have a standard deviation smaller than 0.5.</span></figcaption>
<div id="S2.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:790pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(24.2pt,-44.0pt) scale(1.12540050562337,1.12540050562337) ;">
<table id="S2.T3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T3.1.1.1" class="ltx_tr">
<td id="S2.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S2.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S2.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S2.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Video Hours</span></td>
<td id="S2.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S2.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">LM</span></td>
<td id="S2.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S2.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">WER <math id="S2.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S2.T3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S2.T3.1.1.1.1.1.m1.1.1" xref="S2.T3.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S2.T3.1.1.1.1.1.m1.1b"><ci id="S2.T3.1.1.1.1.1.m1.1.1.cmml" xref="S2.T3.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S2.T3.1.1.2" class="ltx_tr">
<td id="S2.T3.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T3.1.1.2.1.1" class="ltx_text ltx_font_bold">LRS2</span></td>
<td id="S2.T3.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T3.1.1.2.2.1" class="ltx_text ltx_font_bold">LRS3</span></td>
</tr>
<tr id="S2.T3.1.1.3" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S2.T3.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><span id="S2.T3.1.1.3.1.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">Less than 500h</span></td>
</tr>
<tr id="S2.T3.1.1.4" class="ltx_tr">
<td id="S2.T3.1.1.4.1" class="ltx_td ltx_align_left">TDNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</td>
<td id="S2.T3.1.1.4.2" class="ltx_td ltx_align_center">223</td>
<td id="S2.T3.1.1.4.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.4.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.4.4" class="ltx_td ltx_align_center">48.9</td>
<td id="S2.T3.1.1.4.5" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T3.1.1.5" class="ltx_tr">
<td id="S2.T3.1.1.5.1" class="ltx_td ltx_align_left">CM-Seq2Seq <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="S2.T3.1.1.5.2" class="ltx_td ltx_align_center">223/438</td>
<td id="S2.T3.1.1.5.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.5.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.5.4" class="ltx_td ltx_align_center">39.1</td>
<td id="S2.T3.1.1.5.5" class="ltx_td ltx_align_center">46.9</td>
</tr>
<tr id="S2.T3.1.1.6" class="ltx_tr">
<td id="S2.T3.1.1.6.1" class="ltx_td ltx_align_left">CM-Aux <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S2.T3.1.1.6.2" class="ltx_td ltx_align_center">223/438</td>
<td id="S2.T3.1.1.6.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.6.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.6.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.6.4.1" class="ltx_text ltx_framed ltx_framed_underline">32.9</span></td>
<td id="S2.T3.1.1.6.5" class="ltx_td ltx_align_center">37.9</td>
</tr>
<tr id="S2.T3.1.1.7" class="ltx_tr">
<td id="S2.T3.1.1.7.1" class="ltx_td ltx_align_left">RAVEn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</td>
<td id="S2.T3.1.1.7.2" class="ltx_td ltx_align_center">438</td>
<td id="S2.T3.1.1.7.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.7.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.7.4" class="ltx_td ltx_align_center">-</td>
<td id="S2.T3.1.1.7.5" class="ltx_td ltx_align_center">39.1</td>
</tr>
<tr id="S2.T3.1.1.8" class="ltx_tr">
<td id="S2.T3.1.1.8.1" class="ltx_td ltx_align_left">AutoAVSR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>
</td>
<td id="S2.T3.1.1.8.2" class="ltx_td ltx_align_center">438</td>
<td id="S2.T3.1.1.8.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.8.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.8.4" class="ltx_td ltx_align_center">-</td>
<td id="S2.T3.1.1.8.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.8.5.1" class="ltx_text ltx_framed ltx_framed_underline">36.3</span></td>
</tr>
<tr id="S2.T3.1.1.9" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T3.1.1.9.1" class="ltx_td ltx_align_left"><span id="S2.T3.1.1.9.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR (Ours)</span></td>
<td id="S2.T3.1.1.9.2" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.9.2.1" class="ltx_text" style="background-color:#EDF2FF;">223/438</span></td>
<td id="S2.T3.1.1.9.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.9.3.1" class="ltx_text" style="color:#FF0000;background-color:#EDF2FF;">✗</span></td>
<td id="S2.T3.1.1.9.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.9.4.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">30.7</span></td>
<td id="S2.T3.1.1.9.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.9.5.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">33.3</span></td>
</tr>
<tr id="S2.T3.1.1.10" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T3.1.1.10.1" class="ltx_td ltx_align_left"><span id="S2.T3.1.1.10.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR (Ours)</span></td>
<td id="S2.T3.1.1.10.2" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.10.2.1" class="ltx_text" style="background-color:#EDF2FF;">223/438</span></td>
<td id="S2.T3.1.1.10.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.10.3.1" class="ltx_text" style="color:#00FF00;background-color:#EDF2FF;">✓</span></td>
<td id="S2.T3.1.1.10.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.10.4.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">28.9</span></td>
<td id="S2.T3.1.1.10.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.10.5.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">31.2</span></td>
</tr>
<tr id="S2.T3.1.1.11" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S2.T3.1.1.11.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><span id="S2.T3.1.1.11.1.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">Less than 1000h</span></td>
</tr>
<tr id="S2.T3.1.1.12" class="ltx_tr">
<td id="S2.T3.1.1.12.1" class="ltx_td ltx_align_left">KD + CTC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="S2.T3.1.1.12.2" class="ltx_td ltx_align_center">995</td>
<td id="S2.T3.1.1.12.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.12.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.12.4" class="ltx_td ltx_align_center">51.3</td>
<td id="S2.T3.1.1.12.5" class="ltx_td ltx_align_center">59.8</td>
</tr>
<tr id="S2.T3.1.1.13" class="ltx_tr">
<td id="S2.T3.1.1.13.1" class="ltx_td ltx_align_left">KD-Seq2Seq <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S2.T3.1.1.13.2" class="ltx_td ltx_align_center">818</td>
<td id="S2.T3.1.1.13.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.13.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.13.4" class="ltx_td ltx_align_center">49.2</td>
<td id="S2.T3.1.1.13.5" class="ltx_td ltx_align_center">59.0</td>
</tr>
<tr id="S2.T3.1.1.14" class="ltx_tr">
<td id="S2.T3.1.1.14.1" class="ltx_td ltx_align_left">MVM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S2.T3.1.1.14.2" class="ltx_td ltx_align_center">818</td>
<td id="S2.T3.1.1.14.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.14.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.14.4" class="ltx_td ltx_align_center">44.5</td>
<td id="S2.T3.1.1.14.5" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T3.1.1.15" class="ltx_tr">
<td id="S2.T3.1.1.15.1" class="ltx_td ltx_align_left">LiRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>
</td>
<td id="S2.T3.1.1.15.2" class="ltx_td ltx_align_center">661</td>
<td id="S2.T3.1.1.15.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.15.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.15.4" class="ltx_td ltx_align_center">38.8</td>
<td id="S2.T3.1.1.15.5" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T3.1.1.16" class="ltx_tr">
<td id="S2.T3.1.1.16.1" class="ltx_td ltx_align_left">RAVEn</td>
<td id="S2.T3.1.1.16.2" class="ltx_td ltx_align_center">661</td>
<td id="S2.T3.1.1.16.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.16.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.16.4" class="ltx_td ltx_align_center">32.1</td>
<td id="S2.T3.1.1.16.5" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T3.1.1.17" class="ltx_tr">
<td id="S2.T3.1.1.17.1" class="ltx_td ltx_align_left">VTP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S2.T3.1.1.17.2" class="ltx_td ltx_align_center">698</td>
<td id="S2.T3.1.1.17.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.17.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.17.4" class="ltx_td ltx_align_center">28.9</td>
<td id="S2.T3.1.1.17.5" class="ltx_td ltx_align_center">40.6</td>
</tr>
<tr id="S2.T3.1.1.18" class="ltx_tr">
<td id="S2.T3.1.1.18.1" class="ltx_td ltx_align_left">AutoAVSR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>
</td>
<td id="S2.T3.1.1.18.2" class="ltx_td ltx_align_center">818</td>
<td id="S2.T3.1.1.18.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.18.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.18.4" class="ltx_td ltx_align_center">27.9</td>
<td id="S2.T3.1.1.18.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.18.5.1" class="ltx_text ltx_framed ltx_framed_underline">33.0</span></td>
</tr>
<tr id="S2.T3.1.1.19" class="ltx_tr">
<td id="S2.T3.1.1.19.1" class="ltx_td ltx_align_left">CM-Aux</td>
<td id="S2.T3.1.1.19.2" class="ltx_td ltx_align_center">818</td>
<td id="S2.T3.1.1.19.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.19.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.19.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.19.4.1" class="ltx_text ltx_framed ltx_framed_underline">27.3</span></td>
<td id="S2.T3.1.1.19.5" class="ltx_td ltx_align_center">34.7</td>
</tr>
<tr id="S2.T3.1.1.20" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T3.1.1.20.1" class="ltx_td ltx_align_left"><span id="S2.T3.1.1.20.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR (Ours)</span></td>
<td id="S2.T3.1.1.20.2" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.20.2.1" class="ltx_text" style="background-color:#EDF2FF;">661</span></td>
<td id="S2.T3.1.1.20.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.20.3.1" class="ltx_text" style="color:#FF0000;background-color:#EDF2FF;">✗</span></td>
<td id="S2.T3.1.1.20.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.20.4.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">22.0</span></td>
<td id="S2.T3.1.1.20.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.20.5.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">30.4</span></td>
</tr>
<tr id="S2.T3.1.1.21" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T3.1.1.21.1" class="ltx_td ltx_align_left"><span id="S2.T3.1.1.21.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR (Ours)</span></td>
<td id="S2.T3.1.1.21.2" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.21.2.1" class="ltx_text" style="background-color:#EDF2FF;">661</span></td>
<td id="S2.T3.1.1.21.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.21.3.1" class="ltx_text" style="color:#00FF00;background-color:#EDF2FF;">✓</span></td>
<td id="S2.T3.1.1.21.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.21.4.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">20.0</span></td>
<td id="S2.T3.1.1.21.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.21.5.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">28.1</span></td>
</tr>
<tr id="S2.T3.1.1.22" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S2.T3.1.1.22.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><span id="S2.T3.1.1.22.1.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">Less than 2000h</span></td>
</tr>
<tr id="S2.T3.1.1.23" class="ltx_tr">
<td id="S2.T3.1.1.23.1" class="ltx_td ltx_align_left">TM-Seq2Seq <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S2.T3.1.1.23.2" class="ltx_td ltx_align_center">1,391</td>
<td id="S2.T3.1.1.23.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.23.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.23.4" class="ltx_td ltx_align_center">48.3</td>
<td id="S2.T3.1.1.23.5" class="ltx_td ltx_align_center">58.9</td>
</tr>
<tr id="S2.T3.1.1.24" class="ltx_tr">
<td id="S2.T3.1.1.24.1" class="ltx_td ltx_align_left">CM-Aux</td>
<td id="S2.T3.1.1.24.2" class="ltx_td ltx_align_center">1,459</td>
<td id="S2.T3.1.1.24.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.24.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.24.4" class="ltx_td ltx_align_center">25.5</td>
<td id="S2.T3.1.1.24.5" class="ltx_td ltx_align_center">31.5</td>
</tr>
<tr id="S2.T3.1.1.25" class="ltx_tr">
<td id="S2.T3.1.1.25.1" class="ltx_td ltx_align_left">AV-HuBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S2.T3.1.1.25.2" class="ltx_td ltx_align_center">1,992/1,759</td>
<td id="S2.T3.1.1.25.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.25.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.25.4" class="ltx_td ltx_align_center">31.2</td>
<td id="S2.T3.1.1.25.5" class="ltx_td ltx_align_center">34.8</td>
</tr>
<tr id="S2.T3.1.1.26" class="ltx_tr">
<td id="S2.T3.1.1.26.1" class="ltx_td ltx_align_left">AV-HuBERT-Large</td>
<td id="S2.T3.1.1.26.2" class="ltx_td ltx_align_center">1,992/1,759</td>
<td id="S2.T3.1.1.26.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.26.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.26.4" class="ltx_td ltx_align_center">25.5</td>
<td id="S2.T3.1.1.26.5" class="ltx_td ltx_align_center">26.9</td>
</tr>
<tr id="S2.T3.1.1.27" class="ltx_tr">
<td id="S2.T3.1.1.27.1" class="ltx_td ltx_align_left">VATLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>
</td>
<td id="S2.T3.1.1.27.2" class="ltx_td ltx_align_center">1,992/1,759</td>
<td id="S2.T3.1.1.27.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.27.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.27.4" class="ltx_td ltx_align_center">30.6</td>
<td id="S2.T3.1.1.27.5" class="ltx_td ltx_align_center">34.2</td>
</tr>
<tr id="S2.T3.1.1.28" class="ltx_tr">
<td id="S2.T3.1.1.28.1" class="ltx_td ltx_align_left">VATLM-Large</td>
<td id="S2.T3.1.1.28.2" class="ltx_td ltx_align_center">1,992/1,759</td>
<td id="S2.T3.1.1.28.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.28.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.28.4" class="ltx_td ltx_align_center">24.3</td>
<td id="S2.T3.1.1.28.5" class="ltx_td ltx_align_center">26.2</td>
</tr>
<tr id="S2.T3.1.1.29" class="ltx_tr">
<td id="S2.T3.1.1.29.1" class="ltx_td ltx_align_left">LMDecoder<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</td>
<td id="S2.T3.1.1.29.2" class="ltx_td ltx_align_center">1,992</td>
<td id="S2.T3.1.1.29.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.29.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.29.4" class="ltx_td ltx_align_center">23.8</td>
<td id="S2.T3.1.1.29.5" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S2.T3.1.1.30" class="ltx_tr">
<td id="S2.T3.1.1.30.1" class="ltx_td ltx_align_left">RAVEn</td>
<td id="S2.T3.1.1.30.2" class="ltx_td ltx_align_center">1,992/1,759</td>
<td id="S2.T3.1.1.30.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.30.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.30.4" class="ltx_td ltx_align_center">-</td>
<td id="S2.T3.1.1.30.5" class="ltx_td ltx_align_center">33.1</td>
</tr>
<tr id="S2.T3.1.1.31" class="ltx_tr">
<td id="S2.T3.1.1.31.1" class="ltx_td ltx_align_left">RAVEn-Large</td>
<td id="S2.T3.1.1.31.2" class="ltx_td ltx_align_center">1,992/1,759</td>
<td id="S2.T3.1.1.31.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.31.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.31.4" class="ltx_td ltx_align_center">19.3</td>
<td id="S2.T3.1.1.31.5" class="ltx_td ltx_align_center">24.4</td>
</tr>
<tr id="S2.T3.1.1.32" class="ltx_tr">
<td id="S2.T3.1.1.32.1" class="ltx_td ltx_align_left">RAVEn-Large</td>
<td id="S2.T3.1.1.32.2" class="ltx_td ltx_align_center">1,992/1,759</td>
<td id="S2.T3.1.1.32.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.32.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.32.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.32.4.1" class="ltx_text ltx_framed ltx_framed_underline">17.9</span></td>
<td id="S2.T3.1.1.32.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.32.5.1" class="ltx_text ltx_framed ltx_framed_underline">23.1</span></td>
</tr>
<tr id="S2.T3.1.1.33" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T3.1.1.33.1" class="ltx_td ltx_align_left"><span id="S2.T3.1.1.33.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR (Ours)</span></td>
<td id="S2.T3.1.1.33.2" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.33.2.1" class="ltx_text" style="background-color:#EDF2FF;">1,992</span></td>
<td id="S2.T3.1.1.33.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.33.3.1" class="ltx_text" style="color:#FF0000;background-color:#EDF2FF;">✗</span></td>
<td id="S2.T3.1.1.33.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.33.4.1" class="ltx_text" style="background-color:#EDF2FF;">18.5</span></td>
<td id="S2.T3.1.1.33.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.33.5.1" class="ltx_text" style="background-color:#EDF2FF;">23.4</span></td>
</tr>
<tr id="S2.T3.1.1.34" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S2.T3.1.1.34.1" class="ltx_td ltx_align_left"><span id="S2.T3.1.1.34.1.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">SyncVSR (Ours)</span></td>
<td id="S2.T3.1.1.34.2" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.34.2.1" class="ltx_text" style="background-color:#EDF2FF;">1,992</span></td>
<td id="S2.T3.1.1.34.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.34.3.1" class="ltx_text" style="color:#00FF00;background-color:#EDF2FF;">✓</span></td>
<td id="S2.T3.1.1.34.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.34.4.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">16.5</span></td>
<td id="S2.T3.1.1.34.5" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.34.5.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">21.5</span></td>
</tr>
<tr id="S2.T3.1.1.35" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S2.T3.1.1.35.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><span id="S2.T3.1.1.35.1.1" class="ltx_text ltx_font_bold" style="background-color:#E6E6E6;">Greater than 2000h</span></td>
</tr>
<tr id="S2.T3.1.1.36" class="ltx_tr">
<td id="S2.T3.1.1.36.1" class="ltx_td ltx_align_left">VTP</td>
<td id="S2.T3.1.1.36.2" class="ltx_td ltx_align_center">2,676</td>
<td id="S2.T3.1.1.36.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.36.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.36.4" class="ltx_td ltx_align_center">22.6</td>
<td id="S2.T3.1.1.36.5" class="ltx_td ltx_align_center">30.7</td>
</tr>
<tr id="S2.T3.1.1.37" class="ltx_tr">
<td id="S2.T3.1.1.37.1" class="ltx_td ltx_align_left">AutoAVSR</td>
<td id="S2.T3.1.1.37.2" class="ltx_td ltx_align_center">3,448</td>
<td id="S2.T3.1.1.37.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.37.3.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S2.T3.1.1.37.4" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.37.4.1" class="ltx_text ltx_font_bold">14.6</span></td>
<td id="S2.T3.1.1.37.5" class="ltx_td ltx_align_center">19.1</td>
</tr>
<tr id="S2.T3.1.1.38" class="ltx_tr">
<td id="S2.T3.1.1.38.1" class="ltx_td ltx_align_left">ViT 3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>
</td>
<td id="S2.T3.1.1.38.2" class="ltx_td ltx_align_center">90,000</td>
<td id="S2.T3.1.1.38.3" class="ltx_td ltx_align_center"><span id="S2.T3.1.1.38.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.38.4" class="ltx_td ltx_align_center">-</td>
<td id="S2.T3.1.1.38.5" class="ltx_td ltx_align_center">17.0</td>
</tr>
<tr id="S2.T3.1.1.39" class="ltx_tr">
<td id="S2.T3.1.1.39.1" class="ltx_td ltx_align_left ltx_border_bb">LP Conformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>
</td>
<td id="S2.T3.1.1.39.2" class="ltx_td ltx_align_center ltx_border_bb">100,000</td>
<td id="S2.T3.1.1.39.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T3.1.1.39.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S2.T3.1.1.39.4" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S2.T3.1.1.39.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T3.1.1.39.5.1" class="ltx_text ltx_font_bold">12.8</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setup</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p"><span id="S3.p1.1.1" class="ltx_text ltx_font_bold">Training Dataset.</span> We employ the LRW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> dataset for English and the CAS-VSR-W1K <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> for Chinese to evaluate word-level VSR tasks. The LRW dataset comprises 500 words, each represented by up to 1,000 training videos. The LRW-1000 dataset consists of 718,018 videos spanning 1,000 words. Our sentence-level experimental framework was anchored on the LRS2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> and LRS3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> datasets, representing the most extensive publicly available resources for audio-visual speech recognition in English. The LRS2 dataset, sourced from BBC programs, comprises 144,482 video clips, totaling 225 hours of video content. The LRS3 dataset, harvested from TED talks, encompasses 151,819 video clips, amassing 439 hours of footage. Additional training data was sourced from the English-speaking segments of the VoxCeleb2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> dataset, comprised of a training corpus totaling 1,323 video hours, complemented by transcriptions following the scheme of AutoAVSR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Dataset Preprocessing.</span> We used MediaPipe <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> to identify the region of interest with a size of 128 x 128 for video-based VSR, and the extracted landmark data served as input for a pointcloud-based VSR system. We used a data augmentation scheme of a resized random crop with a size of (96, 96) and a random horizontal flip and applied a center crop for inference similar to that of previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
<div id="S3.p3" class="ltx_para ltx_noindent">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">Model Architecture.</span> For word-level VSR, an encoder is composed of a combination of 3D CNN, ResNet18, and Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> to extract video features following the previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. On the other hand, Conformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> is used as a temporal backbone for sentence-level VSR, where we follow the model size and configuration of previous works' settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para ltx_noindent">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">Training Recipe.</span> For word-level VSR tasks, we train the model for 200 epochs with the Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> optimizer. The learning rate increased from 0 to 0.0001 for the first 5 epochs and then decreased linearly. In the case of sentence-level VSR, the model is trained for 100 epochs with the Adam optimizer, where the learning rate linearly decays from the peak of 0.001 at the 3rd epoch. Batch size is 384 for word-level and 64 for sentence-level, distributed to 4<math id="S3.p4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S3.p4.1.m1.1a"><mo id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><times id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">\times</annotation></semantics></math>A100 GPUs. The rest of the training specifics follow the previous work's settings from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. Our metrics were obtained from the average of three random seeds.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text ltx_font_bold">Versatility Across Tasks, Languages, and Modalities.</span> Our framework is comprehensively evaluated according to tasks, languages, and input modalities. In word-level tasks, shown in Table <a href="#S2.T1" title="Table 1 ‣ 2 Methodology ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, SyncVSR marks state-of-the-art results in English and Chinese benchmarks. In sentence-level tasks, displayed in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Table <a href="#S2.T3" title="Table 3 ‣ 2 Methodology ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, SyncVSR outperforms available methodologies when given a similar amount of video dataset. Notably, our method also advances a tier in model size, where our base-size model shows superior performance over other large-size models. Our method also achieves state-of-the-art performance in landmark-based VSR tasks shown in Table <a href="#S2.T2" title="Table 2 ‣ 2 Methodology ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and Table <a href="#S4.T4" title="Table 4 ‣ 4 Results ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Distinguishing Homophenes.</span> Homophenes often closely resemble each other in their graphemes—the smallest functional units of a writing system. For example, homophene pairs, like (<span id="S4.p2.1.2" class="ltx_text ltx_font_italic">Million</span>, <span id="S4.p2.1.3" class="ltx_text ltx_font_italic">Billion</span>) or (<span id="S4.p2.1.4" class="ltx_text ltx_font_italic">Living</span>, <span id="S4.p2.1.5" class="ltx_text ltx_font_italic">Giving</span>), differ by just one grapheme. Although earlier research, notably by Kim <span id="S4.p2.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> has examined a subset of these pairs, a full-scale evaluation of every potential homophene pair has yet to be achieved. As a result, in Figure <a href="#S2.F3" title="Figure 3 ‣ 2 Methodology ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we assess the relative F1-score gain of existing training methods over a vanilla setting that does not utilize the audio data, focusing on the grapheme edit distances. This suggests that the inclusion of an audio reconstruction loss objective assists in differentiating visemes that are mapped into similar graphemes, which is where homophene pairs are typically found.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.4.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.5.2" class="ltx_text" style="font-size:90%;">Impact of CTC loss and audio reconstruction loss on the LRS2 benchmark. To the best of our knowledge, this is the first instance of reporting a successful implementation of landmark-based sentence-level visual speech recognition.</span></figcaption>
<div id="S4.T4.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:181pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(87.5pt,-36.5pt) scale(1.67636335642893,1.67636335642893) ;">
<table id="S4.T4.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.2.2.2" class="ltx_tr">
<td id="S4.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T4.2.2.2.3.1" class="ltx_text ltx_font_bold">Sync</span></td>
<td id="S4.T4.2.2.2.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T4.2.2.2.4.1" class="ltx_text ltx_font_bold">CTC</span></td>
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">WER <math id="S4.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T4.1.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T4.2.2.2.2.1" class="ltx_text ltx_font_bold">Perplexity <math id="S4.T4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T4.2.2.2.2.1.m1.1.1" xref="S4.T4.2.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.1.m1.1b"><ci id="S4.T4.2.2.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S4.T4.2.2.3" class="ltx_tr">
<td id="S4.T4.2.2.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.1.1" class="ltx_text ltx_font_bold">Video</span></td>
<td id="S4.T4.2.2.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.2.1" class="ltx_text ltx_font_bold">Pointcloud</span></td>
<td id="S4.T4.2.2.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.3.1" class="ltx_text ltx_font_bold">Video</span></td>
<td id="S4.T4.2.2.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.3.4.1" class="ltx_text ltx_font_bold">Pointcloud</span></td>
</tr>
<tr id="S4.T4.2.2.4" class="ltx_tr">
<td id="S4.T4.2.2.4.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.4.1.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S4.T4.2.2.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.4.2.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S4.T4.2.2.4.3" class="ltx_td ltx_align_center ltx_border_t">45.9</td>
<td id="S4.T4.2.2.4.4" class="ltx_td ltx_align_center ltx_border_t">99.9</td>
<td id="S4.T4.2.2.4.5" class="ltx_td ltx_align_center ltx_border_t">4.0</td>
<td id="S4.T4.2.2.4.6" class="ltx_td ltx_align_center ltx_border_t">40.7</td>
</tr>
<tr id="S4.T4.2.2.5" class="ltx_tr">
<td id="S4.T4.2.2.5.1" class="ltx_td ltx_align_center"><span id="S4.T4.2.2.5.1.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S4.T4.2.2.5.2" class="ltx_td ltx_align_center"><span id="S4.T4.2.2.5.2.1" class="ltx_text" style="color:#00FF00;">✓</span></td>
<td id="S4.T4.2.2.5.3" class="ltx_td ltx_align_center">43.2</td>
<td id="S4.T4.2.2.5.4" class="ltx_td ltx_align_center">99.8</td>
<td id="S4.T4.2.2.5.5" class="ltx_td ltx_align_center">4.1</td>
<td id="S4.T4.2.2.5.6" class="ltx_td ltx_align_center">40.4</td>
</tr>
<tr id="S4.T4.2.2.6" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S4.T4.2.2.6.1" class="ltx_td ltx_align_center"><span id="S4.T4.2.2.6.1.1" class="ltx_text" style="color:#00FF00;background-color:#EDF2FF;">✓</span></td>
<td id="S4.T4.2.2.6.2" class="ltx_td ltx_align_center"><span id="S4.T4.2.2.6.2.1" class="ltx_text" style="color:#FF0000;background-color:#EDF2FF;">✗</span></td>
<td id="S4.T4.2.2.6.3" class="ltx_td ltx_align_center"><span id="S4.T4.2.2.6.3.1" class="ltx_text" style="background-color:#EDF2FF;">38.1</span></td>
<td id="S4.T4.2.2.6.4" class="ltx_td ltx_align_center"><span id="S4.T4.2.2.6.4.1" class="ltx_text" style="background-color:#EDF2FF;">77.4</span></td>
<td id="S4.T4.2.2.6.5" class="ltx_td ltx_align_center"><span id="S4.T4.2.2.6.5.1" class="ltx_text" style="background-color:#EDF2FF;">2.8</span></td>
<td id="S4.T4.2.2.6.6" class="ltx_td ltx_align_center"><span id="S4.T4.2.2.6.6.1" class="ltx_text" style="background-color:#EDF2FF;">8.1</span></td>
</tr>
<tr id="S4.T4.2.2.7" class="ltx_tr" style="background-color:#EDF2FF;">
<td id="S4.T4.2.2.7.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.2.7.1.1" class="ltx_text" style="color:#00FF00;background-color:#EDF2FF;">✓</span></td>
<td id="S4.T4.2.2.7.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.2.7.2.1" class="ltx_text" style="color:#00FF00;background-color:#EDF2FF;">✓</span></td>
<td id="S4.T4.2.2.7.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.2.7.3.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">30.7</span></td>
<td id="S4.T4.2.2.7.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.2.7.4.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">74.6</span></td>
<td id="S4.T4.2.2.7.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.2.7.5.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">2.7</span></td>
<td id="S4.T4.2.2.7.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.2.2.7.6.1" class="ltx_text ltx_font_bold" style="background-color:#EDF2FF;">7.7</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F4.1" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:208.1pt;">
<p id="S4.F4.1.1" class="ltx_p ltx_align_center"><span id="S4.F4.1.1.1" class="ltx_text"><img src="/html/2406.12233/assets/lambda0.png" id="S4.F4.1.1.1.g1" class="ltx_graphics ltx_img_square" width="163" height="170" alt="Refer to caption"></span></p>
<p id="S4.F4.1.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S4.F4.1.2.1" class="ltx_text">(a) Trained w/o Sync</span></p>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F4.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:208.1pt;">
<p id="S4.F4.2.1" class="ltx_p ltx_align_center"><span id="S4.F4.2.1.1" class="ltx_text"><img src="/html/2406.12233/assets/lambda10.png" id="S4.F4.2.1.1.g1" class="ltx_graphics ltx_img_square" width="163" height="170" alt="Refer to caption"></span></p>
<p id="S4.F4.2.2" class="ltx_p ltx_align_center ltx_align_center"><span id="S4.F4.2.2.1" class="ltx_text">(b) Trained w/ Sync</span></p>
</div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.6.2.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.4.1" class="ltx_text" style="font-size:90%;">Influence of audio reconstruction loss weight (<math id="S4.F4.4.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.F4.4.1.m1.1b"><mi id="S4.F4.4.1.m1.1.1" xref="S4.F4.4.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.F4.4.1.m1.1c"><ci id="S4.F4.4.1.m1.1.1.cmml" xref="S4.F4.4.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.1.m1.1d">\lambda</annotation></semantics></math>) on the encoder's representation visualized with the mean attention distance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> distribution. Each point indicates the weighted distance of attention from the query frame to other frames.</span></figcaption>
</figure>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.1" class="ltx_p"><span id="S4.p3.1.1" class="ltx_text ltx_font_bold">Significance of Full Sequence Synchronization.</span> Furthermore, Figure <a href="#S2.F3" title="Figure 3 ‣ 2 Methodology ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> compares our reconstruction method with masked reconstruction. Not only does our full-length non-autoregressive generation excel when graphemes are similar, but it is also noteworthy that masked reconstruction could cause harm for classifying pairs with far edit distances. This implies previous works based on masked reconstruction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> might be imperfect for aligning visual and audio modalities. In contrast, our audio reconstruction objective can be amplified up to ten times above the original task objective, which assists in discerning fine-grained visemes without causing any obstruction. Types of crossmodal indicators, whether they be quantized acoustic tokens from vq-wav2vec <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> or character-level transcriptions from wav2vec2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, are trivial, as seen in Table <a href="#S2.T1" title="Table 1 ‣ 2 Methodology ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.1" class="ltx_p"><span id="S4.p4.1.1" class="ltx_text ltx_font_bold">Enhancing Speech Representation Learning.</span> For sentence-level VSR, joint CTC-Attention loss is widely used in previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Despite its benefit in the decoding stage, its utility in terms of representation learning remains uncertain. According to Table <a href="#S4.T4" title="Table 4 ‣ 4 Results ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, CTC loss marginally contributes to the perplexity of the model, whereas our audio reconstruction loss term strongly improves learning in both pointcloud and video modalities. The effect of frame-level crossmodal supervision is illustrated in Figure <a href="#S4.F4" title="Figure 4 ‣ 4 Results ‣ SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End Crossmodal Audio Token Synchronization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, where inner representation indicates that the temporal encoder model exhibits a change of bias towards local neighboring frames.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We addressed the problem of homophenes with an improved crossmodal synchronization method, effectively bridging the divide between visual cues and their corresponding audio segments. The use of quantized audio tokens for direct frame-level supervision enables SyncVSR to achieve state-of-the-art performance on various benchmarks with a remarkable level of data efficiency. We believe SyncVSR is a step toward future developments in the field of multimodal speech recognition.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This work was supported by Institute for Information &amp; communications Technology Promotion (IITP) grant funded by the Korea government (MSIT) (No.RS-2019-II190075 Artificial Intelligence Graduate School Program (KAIST), Cloud TPUs from Google's TPU Research Cloud (TRC), and an Electronics and Telecommunications Research Institute (ETRI) grant funded by the Korean Government (24ZB1100, Core Technology Research for Self-improving Integrated AI Systems).</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
H. Laux, A. Hallawa, J. C. S. Assis <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Two-stage visual speech recognition for intensive care patients,'' <em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic">Scientific Reports</em>, vol. 13, 2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
N. Tye‐Murray, M. Sommers, B. Spehar <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Audiovisual integration and lipreading abilities of older adults with normal and impaired hearing.'' <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">Ear and hearing</em>, vol. 28 5, pp. 656–68, 2006.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
B. Martínez, P. Ma, M. Pantic <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Lipreading using temporal convolutional networks,'' in <em id="bib.bib3.2.2" class="ltx_emph ltx_font_italic">ICASSP</em>, 2020, pp. 6319–6323.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
B. Xu, C. Lu, Y. Guo <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Discriminative multi-modality speech recognition,'' <em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">CVPR</em>, pp. 14 421–14 430, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. Haliassos, K. Vougioukas, S. Petridis <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Lips don't lie: A generalisable and robust approach to face forgery detection,'' <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">CVPR</em>, pp. 5037–5047, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T. Afouras, J. S. Chung, and A. Zisserman, ``Lrs3-ted: a large-scale dataset for visual speech recognition,'' 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
S. Ren, Y. Du, J. Lv, G. Han <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Learning from the master: Distilling cross-modal advanced knowledge for lip reading,'' in <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">CVPR</em>, 2021, pp. 13 325–13 333.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Kim, J. H. Yeo, and Y. M. Ro, ``Distinguishing homophenes using multi-head visual-audio memory for lip reading,'' in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, 2022, pp. 1174–1182.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Y. Zhao, R. Xu, X. Wang, P. Hou, H. Tang, and M. Song, ``Hearing lips: Improving lip reading by distilling speech recognizers,'' in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, vol. 34, no. 04, 2020, pp. 6917–6924.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
T. Afouras, J. S. Chung, A. Senior <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Deep audio-visual speech recognition,'' <em id="bib.bib10.2.2" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 44, pp. 8717–8727, 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
P. Ma, S. Petridis, and M. Pantic, ``Visual speech recognition for multiple languages in the wild,'' <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, pp. 1–10, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. H. Yeo, M. Kim, and Y. M. Ro, ``Multi-temporal lip-audio memory for visual speech recognition,'' in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2023, pp. 1–5.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
M. Kim, J. Hong, S. J. Park, and Y. M. Ro, ``Multi-modality associative bridging through memory: Speech sound recollected from face video,'' in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ICCV</em>, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
P. Ma, R. Mira, S. Petridis, B. W. Schuller, and M. Pantic, ``Lira: Learning visual speech representations from audio through self-supervision,'' in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2021, pp. 3011–3015.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
B. Shi, W.-N. Hsu, K. Lakhotia, and A. Mohamed, ``Learning audio-visual speech representation by masked multimodal cluster prediction,'' in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. Kim, J. H. Yeo, J. Choi, and Y. M. Ro, ``Lip reading for low-resource languages by learning and combining general speech knowledge and language-specific knowledge,'' in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ICCV</em>, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A. Haliassos, P. Ma, R. Mira <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Jointly learning visual and auditory speech representations from raw data,'' in <em id="bib.bib17.2.2" class="ltx_emph ltx_font_italic">ICLR</em>, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Q. Zhu, L. Zhou, Z. Zhang <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Vatlm: Visual-audio-text pre-training with unified masked prediction for speech representation learning,'' <em id="bib.bib18.2.2" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2211.11275, 2022.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
P. He, J. Gao, and W. Chen, ``Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing,'' <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2111.09543, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
K. Clark, M.-T. Luong, Q. V. Le <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Electra: Pre-training text encoders as discriminators rather than generators,'' <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">ICLR</em>, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
S. Kim, T. Hori, and S. Watanabe, ``Joint ctc-attention based end-to-end speech recognition using multi-task learning,'' in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2017, pp. 4835–4839.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A. Graves, S. Fernández, F. Gomez, and J. Schmidhuber, ``Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,'' in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2006.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
J. S. Chung, A. Senior, O. Vinyals, and A. Zisserman, ``Lip reading in the wild,'' in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ACCV</em>.   Springer, 2017, pp. 87–103.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
S. Yang, Y. Zhang, D. Feng <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Lrw-1000: A naturally-distributed large-scale benchmark for lip reading in the wild,'' <em id="bib.bib24.2.2" class="ltx_emph ltx_font_italic">FG</em>, pp. 1–8, 2018.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
P. Ma, B. Martinez, S. Petridis, and M. Pantic, ``Towards practical lipreading with distilled and efficient models,'' <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
W. Tian, H. Zhang, C. Peng, and Z.-Q. Zhao, ``Lipreading model based on whole-part collaborative learning,'' <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
P. Ma, Y. Wang, J. Shen, S. Petridis, and M. Pantic, ``Lip-reading with densely connected temporal convolutional networks,'' <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">WACV</em>, pp. 2856–2865, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
D. Feng, S. Yang, S. Shan, and X. Chen, ``Learn an effective lip reading model without pains,'' <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.07557</em>, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
H. Yang, T. Luo, Y. Zhang <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Improved word-level lipreading with temporal shrinkage network and netvlad,'' <em id="bib.bib29.2.2" class="ltx_emph ltx_font_italic">ICMI</em>, 2022.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
A. Koumparoulis and G. Potamianos, ``Accurate and resource-efficient lipreading with efficientnetv2 and transformers,'' in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2022, pp. 8467–8471.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
P. Ma, Y. Wang, S. Petridis <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Training strategies for improved lip-reading,'' in <em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic">ICASSP</em>, 2022, pp. 8472–8476.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
H. Liu, Z. Chen, and B. Yang, ``Lip graph assisted audio-visual speech recognition using bidirectional synchronous fusion,'' in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
X. Z. Changchong Sheng, H. Xu, M. Pietikäinen, and L. Liu, ``Adaptive semantic-spatio-temporal graph convolutional network for lip reading,'' <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em>, vol. 24, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
B. Pouthier, L. Pilati, and G. Valenti, ``Another point of view on visual speech recognition,'' <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
J. S. Chung, A. Senior, O. Vinyals, and A. Zisserman, ``Lip reading sentences in the wild,'' in <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2017, pp. 3444–3453.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
J. Yu, S.-X. Zhang, J. Wu <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Audio-visual recognition of overlapped speech for the lrs2 dataset,'' <em id="bib.bib36.2.2" class="ltx_emph ltx_font_italic">ICASSP</em>, pp. 6984–6988, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
P. Ma, S. Petridis, and M. Pantic, ``End-to-end audio-visual speech recognition with conformers,'' in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2021, pp. 7613–7617.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
P. Ma, A. Haliassos, A. Fernandez-Lopez <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Auto-avsr: Audio-visual speech recognition with automatic labels,'' in <em id="bib.bib38.2.2" class="ltx_emph ltx_font_italic">ICASSP</em>, 2023, pp. 1–5.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
T. Afouras, J. S. Chung, and A. Zisserman, ``Asr is all you need: Cross-modal distillation for lip reading,'' <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
K. R. Prajwal, T. Afouras, and A. Zisserman, ``Sub-word level lip reading with visual attention,'' in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2022, pp. 5162–5172.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
D. Serdyuk, O. Braga, and O. Siohan, ``Transformer-based video front-ends for audio-visual speech recognition,'' in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2022.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
O. Chang, H. Liao, D. Serdyuk, A. Shah, and O. Siohan, ``Conformers are all you need for visual speech recogntion,'' <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2024.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
J. S. Chung, A. Nagrani, and A. Zisserman, ``Voxceleb2: Deep speaker recognition,'' in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2018.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
C. Lugaresi, J. Tang, H. Nash <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Mediapipe: A framework for perceiving and processing reality,'' in <em id="bib.bib44.2.2" class="ltx_emph ltx_font_italic">CVPR</em>, vol. 2019.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Attention is all you need,'' <em id="bib.bib45.2.2" class="ltx_emph ltx_font_italic">NeurIPS</em>, vol. 30, 2017.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
A. Gulati, J. Qin, C.-C. Chiu <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Conformer: Convolution-augmented Transformer for Speech Recognition,'' in <em id="bib.bib46.2.2" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2020, pp. 5036–5040.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
D. P. Kingma and J. Ba, ``Adam: A method for stochastic optimization,'' <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, 2014.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
A. Dosovitskiy, L. Beyer, A. Kolesnikov <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' in <em id="bib.bib48.2.2" class="ltx_emph ltx_font_italic">ICLR</em>, 2021.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
A. Baevski, S. Schneider, and M. Auli, ``vq-wav2vec: Self-supervised learning of discrete speech representations,'' in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2020.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
A. Baevski, H. Zhou, A. Mohamed, and M. Auli, ``wav2vec 2.0: A framework for self-supervised learning of speech representations,'' <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, vol. 33, pp. 12 449–12 460, 2020.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.12232" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.12233" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.12233">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.12233" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.12234" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Jul  6 00:58:45 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
