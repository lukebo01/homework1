<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.10177] Augmenting Automatic Speech Recognition Models with Disfluency Detection</title><meta property="og:description" content="Speech disfluency commonly occurs in conversational and spontaneous speech. However, standard Automatic Speech Recognition (ASR) models struggle to accurately recognize these disfluencies because they are typically tra…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Augmenting Automatic Speech Recognition Models with Disfluency Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Augmenting Automatic Speech Recognition Models with Disfluency Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.10177">

<!--Generated on Sat Oct  5 23:22:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Augmenting Automatic Speech Recognition Models with Disfluency Detection</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Speech disfluency commonly occurs in conversational and spontaneous speech. However, standard Automatic Speech Recognition (ASR) models struggle to accurately recognize these disfluencies because they are typically trained on fluent transcripts. Current research mainly focuses on detecting disfluencies within transcripts, overlooking their exact location and duration in the speech. Additionally, previous work often requires model fine-tuning and addresses limited types of disfluencies.</p>
<p id="id2.id2" class="ltx_p">In this work, we present an inference-only approach to augment any ASR model with the ability to detect open-set disfluencies. We first demonstrate that ASR models have difficulty transcribing speech disfluencies. Next, this work proposes a modified Connectionist Temporal Classification(CTC)-based forced alignment algorithm from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> to predict word-level timestamps while effectively capturing disfluent speech. Additionally, we develop a model to classify alignment gaps between timestamps as either containing disfluent speech or silence. This model achieves an accuracy of 81.62% and an F1-score of 80.07%. We test the augmentation pipeline of alignment gap detection and classification on a disfluent dataset. Our results show that we captured 74.13% of the words that were initially missed by the transcription, demonstrating the potential of this pipeline for downstream tasks.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— </span></span>
Automatic speech recognition, speech disfluency, forced alignment</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Speech disfluency refers to interruptions in the flow of speech, such as repetitions, interjections, and revisions. It is a natural part of conversational and spontaneous speech but can be particularly pronounced and frequent in certain speech disorders, such as stuttering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Analyzing speech disfluency can aid in diagnosing speech disorders. It can also help in understanding language proficiency that can be applied, for example, in interviews and children’s education.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Manually annotating speech disfluency for analysis is costly, and Automatic Speech Recognition (ASR) can support the annotation process. The ASR systems transcribe the speech into readable text, which can then be passed to the evaluator or automatic evaluation pipelines for analysis. However, ASR models show performance degradation in disfluent speech, because the models are developed to generate fluent transcripts to enhance readability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.10177/assets/images/pipeline.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="334" height="327" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span>The pipeline to augment ASR models with disfluency detection with a follow-up re-transcription for example of application.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To detect speech disfluency with ASR models, one popular approach is post-processing the ASR predictions as a sequence labelling problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Alternatively, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> focus on jointly predicting transcriptions and disfluencies with end-to-end speech recognition. In addition, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> explores adapting the ASR foundation models, which are robust to recognize unfinished words, to detect disfluencies. However, those approaches only detect disfluency within the transcript while neglecting the location and duration of the speech disfluency, which plays an important role in the disfluency analysis, e.g. for the assessment of interlocutors’ alignment in collaborative activities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Recent work focuses on detecting speech disfluencies at the frame level to capture timing information. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> investigate fine-tuning ASR models with disfluent dataset. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> explores forced alignment that aligns the audio signal with its corresponding transcript by decoding with
Weighted Finite State Transducers (WFSTs) in alignment graph. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> hierarchically integrate transcription and detection modules. However, these works address predefined or restricted disfluency types and fail on the open-set disfluency detection for handling previously unseen types.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this work, we propose a straightforward yet effective pipeline to augment ASR models by detecting open-set speech disfluency <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/Robin-Amann/bachelor-thesis</span></span></span>. As illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the pipeline consists of three hierarchical steps: transcription and feature extraction with the ASR model and a frame-wise feature extractor, transcript and speech alignment with a modified Connectionist Temporal Classification(CTC)-based approach from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, and alignment gaps classification for detecting the potential disfluencies. The contributions of this work are as follows:</p>
</div>
<div id="S1.p6" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We examine one state-of-the-art ASR model Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> on speech disfluency detection. The experimental results show the model achieves 22.54 Word Error Rate (WER) points on a conversational dataset, but only 56% of speech disfluencies at the word level are correctly transcribed, and 73.77% of untranscribed words are disfluencies. The results indicate that the ASR model performs poorly on disfluent speech, which is reasonable since ASR models are designed to produce fluent transcriptions for better readability. The finding highlights the importance of augmenting ASR models with disfluency detection capabilities.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Aiming to detect the location and duration of speech disfluency, this work proposes a modified CTC-based forced alignment approach from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> to effectively locate and capture speech disfluency. We compare the proposed approach with the popular CTC-based alignment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and Whisper’s cross-attention alignment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, and show that the proposed algorithm clearly captures more untranscribed words than the others.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">With the proposed forced alignment approach, we build an inference-only pipeline to augment ASR models with disfluency detection capability. The pipeline is flexible and can be adapted to any ASR model. In addition, the pipeline detects the alignment gaps containing disfluent speech, allowing the detection of the open-set disfluency beyond predefined types. With an alignment gap classification model, the pipeline achieves 81.62% accuracy in identifying gaps containing speech, covering 74.13% of all untranscribed words in the initial transcript.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Disfluency Detection</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Augmentation pipeline</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">The inference-only pipeline to augment ASR models with open-set disfluency detection consists of three hierarchical steps (<a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>). In the first step, the ASR system generates an estimated transcript, and a feature extractor model produces the frame-wise probability from speech. The ASR model could be the same as the frame-wise feature extractor models, such as Wav2Vec2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. But it can be any ASR model as the augmentation pipeline only needs its transcript. After that, the pipeline applies a modified (CTC)-based forced alignment algorithm, that is based on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> with the above generations. The algorithm generates word-level timing information and the signal gaps between the word timesteps are recognized as potential instances of disfluent speech. In the end, a developed classification model is applied to identify alignment gaps containing disfluent speech or only silence. The classification results can be utilized for downstream tasks like second-step transcription and identifying disfluency types.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Forced alignment</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">As the key step to extract timing information, three forced alignment approaches are employed: the standard CTC forced alignment, a modified CTC forced alignment, and the cross-attention approach of Whisper, one of the SOTA ASR models, whose attention value exhibits a high degree of correlation with timestamps.</p>
</div>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Standard CTC Alignment</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.1" class="ltx_p">CTC-based forced alignment is a popular approach to extracting timing information used in many speech recognition packages, such as ESPnet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, SpeechBrain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and Flashlight <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. The alignment is calculated in three steps <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://pytorch.org/audio/stable/tutorials/forced_alignment_tutorial.html</span></span></span>:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">The audio is fed into a feature extraction model that is pre-trained with CTC to generate frame-wise label probability over the whole alphabet.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.4" class="ltx_p">From the probability, a trellis matrix is generated to represent the probability of labels occurring at each time frame. The trellis at point <math id="S2.I1.i2.p1.1.m1.2" class="ltx_Math" alttext="(t,j)" display="inline"><semantics id="S2.I1.i2.p1.1.m1.2a"><mrow id="S2.I1.i2.p1.1.m1.2.3.2" xref="S2.I1.i2.p1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S2.I1.i2.p1.1.m1.2.3.2.1" xref="S2.I1.i2.p1.1.m1.2.3.1.cmml">(</mo><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">t</mi><mo id="S2.I1.i2.p1.1.m1.2.3.2.2" xref="S2.I1.i2.p1.1.m1.2.3.1.cmml">,</mo><mi id="S2.I1.i2.p1.1.m1.2.2" xref="S2.I1.i2.p1.1.m1.2.2.cmml">j</mi><mo stretchy="false" id="S2.I1.i2.p1.1.m1.2.3.2.3" xref="S2.I1.i2.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.2b"><interval closure="open" id="S2.I1.i2.p1.1.m1.2.3.1.cmml" xref="S2.I1.i2.p1.1.m1.2.3.2"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">𝑡</ci><ci id="S2.I1.i2.p1.1.m1.2.2.cmml" xref="S2.I1.i2.p1.1.m1.2.2">𝑗</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.2c">(t,j)</annotation></semantics></math> (where <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="0\leq t\leq T-1\;and\;0\leq j\leq U-1" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><mrow id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml"><mn id="S2.I1.i2.p1.2.m2.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.2.cmml">0</mn><mo id="S2.I1.i2.p1.2.m2.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.3.cmml">≤</mo><mi id="S2.I1.i2.p1.2.m2.1.1.4" xref="S2.I1.i2.p1.2.m2.1.1.4.cmml">t</mi><mo id="S2.I1.i2.p1.2.m2.1.1.5" xref="S2.I1.i2.p1.2.m2.1.1.5.cmml">≤</mo><mrow id="S2.I1.i2.p1.2.m2.1.1.6" xref="S2.I1.i2.p1.2.m2.1.1.6.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.6.2" xref="S2.I1.i2.p1.2.m2.1.1.6.2.cmml">T</mi><mo id="S2.I1.i2.p1.2.m2.1.1.6.1" xref="S2.I1.i2.p1.2.m2.1.1.6.1.cmml">−</mo><mrow id="S2.I1.i2.p1.2.m2.1.1.6.3" xref="S2.I1.i2.p1.2.m2.1.1.6.3.cmml"><mn id="S2.I1.i2.p1.2.m2.1.1.6.3.2" xref="S2.I1.i2.p1.2.m2.1.1.6.3.2.cmml">1</mn><mo lspace="0.280em" rspace="0em" id="S2.I1.i2.p1.2.m2.1.1.6.3.1" xref="S2.I1.i2.p1.2.m2.1.1.6.3.1.cmml">​</mo><mi id="S2.I1.i2.p1.2.m2.1.1.6.3.3" xref="S2.I1.i2.p1.2.m2.1.1.6.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.2.m2.1.1.6.3.1a" xref="S2.I1.i2.p1.2.m2.1.1.6.3.1.cmml">​</mo><mi id="S2.I1.i2.p1.2.m2.1.1.6.3.4" xref="S2.I1.i2.p1.2.m2.1.1.6.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.2.m2.1.1.6.3.1b" xref="S2.I1.i2.p1.2.m2.1.1.6.3.1.cmml">​</mo><mi id="S2.I1.i2.p1.2.m2.1.1.6.3.5" xref="S2.I1.i2.p1.2.m2.1.1.6.3.5.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.2.m2.1.1.6.3.1c" xref="S2.I1.i2.p1.2.m2.1.1.6.3.1.cmml">​</mo><mn id="S2.I1.i2.p1.2.m2.1.1.6.3.6" xref="S2.I1.i2.p1.2.m2.1.1.6.3.6.cmml"> 0</mn></mrow></mrow><mo id="S2.I1.i2.p1.2.m2.1.1.7" xref="S2.I1.i2.p1.2.m2.1.1.7.cmml">≤</mo><mi id="S2.I1.i2.p1.2.m2.1.1.8" xref="S2.I1.i2.p1.2.m2.1.1.8.cmml">j</mi><mo id="S2.I1.i2.p1.2.m2.1.1.9" xref="S2.I1.i2.p1.2.m2.1.1.9.cmml">≤</mo><mrow id="S2.I1.i2.p1.2.m2.1.1.10" xref="S2.I1.i2.p1.2.m2.1.1.10.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.10.2" xref="S2.I1.i2.p1.2.m2.1.1.10.2.cmml">U</mi><mo id="S2.I1.i2.p1.2.m2.1.1.10.1" xref="S2.I1.i2.p1.2.m2.1.1.10.1.cmml">−</mo><mn id="S2.I1.i2.p1.2.m2.1.1.10.3" xref="S2.I1.i2.p1.2.m2.1.1.10.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><apply id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><and id="S2.I1.i2.p1.2.m2.1.1a.cmml" xref="S2.I1.i2.p1.2.m2.1.1"></and><apply id="S2.I1.i2.p1.2.m2.1.1b.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><leq id="S2.I1.i2.p1.2.m2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3"></leq><cn type="integer" id="S2.I1.i2.p1.2.m2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2">0</cn><ci id="S2.I1.i2.p1.2.m2.1.1.4.cmml" xref="S2.I1.i2.p1.2.m2.1.1.4">𝑡</ci></apply><apply id="S2.I1.i2.p1.2.m2.1.1c.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><leq id="S2.I1.i2.p1.2.m2.1.1.5.cmml" xref="S2.I1.i2.p1.2.m2.1.1.5"></leq><share href="#S2.I1.i2.p1.2.m2.1.1.4.cmml" id="S2.I1.i2.p1.2.m2.1.1d.cmml" xref="S2.I1.i2.p1.2.m2.1.1"></share><apply id="S2.I1.i2.p1.2.m2.1.1.6.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6"><minus id="S2.I1.i2.p1.2.m2.1.1.6.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.1"></minus><ci id="S2.I1.i2.p1.2.m2.1.1.6.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.2">𝑇</ci><apply id="S2.I1.i2.p1.2.m2.1.1.6.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.3"><times id="S2.I1.i2.p1.2.m2.1.1.6.3.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.3.1"></times><cn type="integer" id="S2.I1.i2.p1.2.m2.1.1.6.3.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.3.2">1</cn><ci id="S2.I1.i2.p1.2.m2.1.1.6.3.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.3.3">𝑎</ci><ci id="S2.I1.i2.p1.2.m2.1.1.6.3.4.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.3.4">𝑛</ci><ci id="S2.I1.i2.p1.2.m2.1.1.6.3.5.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.3.5">𝑑</ci><cn type="float" id="S2.I1.i2.p1.2.m2.1.1.6.3.6.cmml" xref="S2.I1.i2.p1.2.m2.1.1.6.3.6"> 0</cn></apply></apply></apply><apply id="S2.I1.i2.p1.2.m2.1.1e.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><leq id="S2.I1.i2.p1.2.m2.1.1.7.cmml" xref="S2.I1.i2.p1.2.m2.1.1.7"></leq><share href="#S2.I1.i2.p1.2.m2.1.1.6.cmml" id="S2.I1.i2.p1.2.m2.1.1f.cmml" xref="S2.I1.i2.p1.2.m2.1.1"></share><ci id="S2.I1.i2.p1.2.m2.1.1.8.cmml" xref="S2.I1.i2.p1.2.m2.1.1.8">𝑗</ci></apply><apply id="S2.I1.i2.p1.2.m2.1.1g.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><leq id="S2.I1.i2.p1.2.m2.1.1.9.cmml" xref="S2.I1.i2.p1.2.m2.1.1.9"></leq><share href="#S2.I1.i2.p1.2.m2.1.1.8.cmml" id="S2.I1.i2.p1.2.m2.1.1h.cmml" xref="S2.I1.i2.p1.2.m2.1.1"></share><apply id="S2.I1.i2.p1.2.m2.1.1.10.cmml" xref="S2.I1.i2.p1.2.m2.1.1.10"><minus id="S2.I1.i2.p1.2.m2.1.1.10.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.10.1"></minus><ci id="S2.I1.i2.p1.2.m2.1.1.10.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.10.2">𝑈</ci><cn type="integer" id="S2.I1.i2.p1.2.m2.1.1.10.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.10.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">0\leq t\leq T-1\;and\;0\leq j\leq U-1</annotation></semantics></math>) represents the maximal probability that the first <math id="S2.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="j-1" display="inline"><semantics id="S2.I1.i2.p1.3.m3.1a"><mrow id="S2.I1.i2.p1.3.m3.1.1" xref="S2.I1.i2.p1.3.m3.1.1.cmml"><mi id="S2.I1.i2.p1.3.m3.1.1.2" xref="S2.I1.i2.p1.3.m3.1.1.2.cmml">j</mi><mo id="S2.I1.i2.p1.3.m3.1.1.1" xref="S2.I1.i2.p1.3.m3.1.1.1.cmml">−</mo><mn id="S2.I1.i2.p1.3.m3.1.1.3" xref="S2.I1.i2.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.3.m3.1b"><apply id="S2.I1.i2.p1.3.m3.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1"><minus id="S2.I1.i2.p1.3.m3.1.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1.1"></minus><ci id="S2.I1.i2.p1.3.m3.1.1.2.cmml" xref="S2.I1.i2.p1.3.m3.1.1.2">𝑗</ci><cn type="integer" id="S2.I1.i2.p1.3.m3.1.1.3.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.3.m3.1c">j-1</annotation></semantics></math> labels of the transcripts are aligned to the first <math id="S2.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="t-1" display="inline"><semantics id="S2.I1.i2.p1.4.m4.1a"><mrow id="S2.I1.i2.p1.4.m4.1.1" xref="S2.I1.i2.p1.4.m4.1.1.cmml"><mi id="S2.I1.i2.p1.4.m4.1.1.2" xref="S2.I1.i2.p1.4.m4.1.1.2.cmml">t</mi><mo id="S2.I1.i2.p1.4.m4.1.1.1" xref="S2.I1.i2.p1.4.m4.1.1.1.cmml">−</mo><mn id="S2.I1.i2.p1.4.m4.1.1.3" xref="S2.I1.i2.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.4.m4.1b"><apply id="S2.I1.i2.p1.4.m4.1.1.cmml" xref="S2.I1.i2.p1.4.m4.1.1"><minus id="S2.I1.i2.p1.4.m4.1.1.1.cmml" xref="S2.I1.i2.p1.4.m4.1.1.1"></minus><ci id="S2.I1.i2.p1.4.m4.1.1.2.cmml" xref="S2.I1.i2.p1.4.m4.1.1.2">𝑡</ci><cn type="integer" id="S2.I1.i2.p1.4.m4.1.1.3.cmml" xref="S2.I1.i2.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.4.m4.1c">t-1</annotation></semantics></math> timeframes of the audio. The trellis is calculated in the log domain to avoid numerical instability.</p>
</div>
<div id="S2.I1.i2.p2" class="ltx_para">
<p id="S2.I1.i2.p2.8" class="ltx_p">The maximum probability that the first <math id="S2.I1.i2.p2.1.m1.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.I1.i2.p2.1.m1.1a"><mi id="S2.I1.i2.p2.1.m1.1.1" xref="S2.I1.i2.p2.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p2.1.m1.1b"><ci id="S2.I1.i2.p2.1.m1.1.1.cmml" xref="S2.I1.i2.p2.1.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p2.1.m1.1c">j</annotation></semantics></math> labels of the transcript are aligned at the timeframe <math id="S2.I1.i2.p2.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.I1.i2.p2.2.m2.1a"><mi id="S2.I1.i2.p2.2.m2.1.1" xref="S2.I1.i2.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p2.2.m2.1b"><ci id="S2.I1.i2.p2.2.m2.1.1.cmml" xref="S2.I1.i2.p2.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p2.2.m2.1c">t</annotation></semantics></math> is the maximum of 1) Stay on the label, which means the first <math id="S2.I1.i2.p2.3.m3.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.I1.i2.p2.3.m3.1a"><mi id="S2.I1.i2.p2.3.m3.1.1" xref="S2.I1.i2.p2.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p2.3.m3.1b"><ci id="S2.I1.i2.p2.3.m3.1.1.cmml" xref="S2.I1.i2.p2.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p2.3.m3.1c">j</annotation></semantics></math> labels of the transcript are already aligned at time <math id="S2.I1.i2.p2.4.m4.1" class="ltx_Math" alttext="t-1" display="inline"><semantics id="S2.I1.i2.p2.4.m4.1a"><mrow id="S2.I1.i2.p2.4.m4.1.1" xref="S2.I1.i2.p2.4.m4.1.1.cmml"><mi id="S2.I1.i2.p2.4.m4.1.1.2" xref="S2.I1.i2.p2.4.m4.1.1.2.cmml">t</mi><mo id="S2.I1.i2.p2.4.m4.1.1.1" xref="S2.I1.i2.p2.4.m4.1.1.1.cmml">−</mo><mn id="S2.I1.i2.p2.4.m4.1.1.3" xref="S2.I1.i2.p2.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p2.4.m4.1b"><apply id="S2.I1.i2.p2.4.m4.1.1.cmml" xref="S2.I1.i2.p2.4.m4.1.1"><minus id="S2.I1.i2.p2.4.m4.1.1.1.cmml" xref="S2.I1.i2.p2.4.m4.1.1.1"></minus><ci id="S2.I1.i2.p2.4.m4.1.1.2.cmml" xref="S2.I1.i2.p2.4.m4.1.1.2">𝑡</ci><cn type="integer" id="S2.I1.i2.p2.4.m4.1.1.3.cmml" xref="S2.I1.i2.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p2.4.m4.1c">t-1</annotation></semantics></math>, and the alignment remains with the same label; 2) Switch to next label, which means that the first <math id="S2.I1.i2.p2.5.m5.1" class="ltx_Math" alttext="j-1" display="inline"><semantics id="S2.I1.i2.p2.5.m5.1a"><mrow id="S2.I1.i2.p2.5.m5.1.1" xref="S2.I1.i2.p2.5.m5.1.1.cmml"><mi id="S2.I1.i2.p2.5.m5.1.1.2" xref="S2.I1.i2.p2.5.m5.1.1.2.cmml">j</mi><mo id="S2.I1.i2.p2.5.m5.1.1.1" xref="S2.I1.i2.p2.5.m5.1.1.1.cmml">−</mo><mn id="S2.I1.i2.p2.5.m5.1.1.3" xref="S2.I1.i2.p2.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p2.5.m5.1b"><apply id="S2.I1.i2.p2.5.m5.1.1.cmml" xref="S2.I1.i2.p2.5.m5.1.1"><minus id="S2.I1.i2.p2.5.m5.1.1.1.cmml" xref="S2.I1.i2.p2.5.m5.1.1.1"></minus><ci id="S2.I1.i2.p2.5.m5.1.1.2.cmml" xref="S2.I1.i2.p2.5.m5.1.1.2">𝑗</ci><cn type="integer" id="S2.I1.i2.p2.5.m5.1.1.3.cmml" xref="S2.I1.i2.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p2.5.m5.1c">j-1</annotation></semantics></math> labels of the transcript are aligned at time <math id="S2.I1.i2.p2.6.m6.1" class="ltx_Math" alttext="t-1" display="inline"><semantics id="S2.I1.i2.p2.6.m6.1a"><mrow id="S2.I1.i2.p2.6.m6.1.1" xref="S2.I1.i2.p2.6.m6.1.1.cmml"><mi id="S2.I1.i2.p2.6.m6.1.1.2" xref="S2.I1.i2.p2.6.m6.1.1.2.cmml">t</mi><mo id="S2.I1.i2.p2.6.m6.1.1.1" xref="S2.I1.i2.p2.6.m6.1.1.1.cmml">−</mo><mn id="S2.I1.i2.p2.6.m6.1.1.3" xref="S2.I1.i2.p2.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p2.6.m6.1b"><apply id="S2.I1.i2.p2.6.m6.1.1.cmml" xref="S2.I1.i2.p2.6.m6.1.1"><minus id="S2.I1.i2.p2.6.m6.1.1.1.cmml" xref="S2.I1.i2.p2.6.m6.1.1.1"></minus><ci id="S2.I1.i2.p2.6.m6.1.1.2.cmml" xref="S2.I1.i2.p2.6.m6.1.1.2">𝑡</ci><cn type="integer" id="S2.I1.i2.p2.6.m6.1.1.3.cmml" xref="S2.I1.i2.p2.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p2.6.m6.1c">t-1</annotation></semantics></math>, and the alignment switches to label <math id="S2.I1.i2.p2.7.m7.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.I1.i2.p2.7.m7.1a"><mi id="S2.I1.i2.p2.7.m7.1.1" xref="S2.I1.i2.p2.7.m7.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p2.7.m7.1b"><ci id="S2.I1.i2.p2.7.m7.1.1.cmml" xref="S2.I1.i2.p2.7.m7.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p2.7.m7.1c">j</annotation></semantics></math> at time <math id="S2.I1.i2.p2.8.m8.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.I1.i2.p2.8.m8.1a"><mi id="S2.I1.i2.p2.8.m8.1.1" xref="S2.I1.i2.p2.8.m8.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p2.8.m8.1b"><ci id="S2.I1.i2.p2.8.m8.1.1.cmml" xref="S2.I1.i2.p2.8.m8.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p2.8.m8.1c">t</annotation></semantics></math>. The calculation is as follows:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.71" class="ltx_Math" alttext="\begin{split}trellis[j,t]=max(trellis[j,t-1]\cdot prob[t,\epsilon],\\
trellis[j-1,t-1]\cdot prob[t,j])\end{split}" display="block"><semantics id="S2.E1.m1.71a"><mtable displaystyle="true" rowspacing="0pt" id="S2.E1.m1.69.69" xref="S2.E1.m1.71.71.2.cmml"><mtr id="S2.E1.m1.69.69a" xref="S2.E1.m1.71.71.2.cmml"><mtd class="ltx_align_right" columnalign="right" id="S2.E1.m1.69.69b" xref="S2.E1.m1.71.71.2.cmml"><mrow id="S2.E1.m1.42.42.42.42.42" xref="S2.E1.m1.71.71.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml">t</mi><mi id="S2.E1.m1.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.cmml">r</mi><mi id="S2.E1.m1.3.3.3.3.3.3" xref="S2.E1.m1.3.3.3.3.3.3.cmml">e</mi><mi id="S2.E1.m1.4.4.4.4.4.4" xref="S2.E1.m1.4.4.4.4.4.4.cmml">l</mi><mi id="S2.E1.m1.5.5.5.5.5.5" xref="S2.E1.m1.5.5.5.5.5.5.cmml">l</mi><mi id="S2.E1.m1.6.6.6.6.6.6" xref="S2.E1.m1.6.6.6.6.6.6.cmml">i</mi><mi id="S2.E1.m1.7.7.7.7.7.7" xref="S2.E1.m1.7.7.7.7.7.7.cmml">s</mi><mrow id="S2.E1.m1.42.42.42.42.42.43" xref="S2.E1.m1.71.71.2.cmml"><mo stretchy="false" id="S2.E1.m1.8.8.8.8.8.8" xref="S2.E1.m1.71.71.2.cmml">[</mo><mi id="S2.E1.m1.9.9.9.9.9.9" xref="S2.E1.m1.9.9.9.9.9.9.cmml">j</mi><mo id="S2.E1.m1.10.10.10.10.10.10" xref="S2.E1.m1.71.71.2.cmml">,</mo><mi id="S2.E1.m1.11.11.11.11.11.11" xref="S2.E1.m1.11.11.11.11.11.11.cmml">t</mi><mo stretchy="false" id="S2.E1.m1.12.12.12.12.12.12" xref="S2.E1.m1.71.71.2.cmml">]</mo></mrow><mo id="S2.E1.m1.13.13.13.13.13.13" xref="S2.E1.m1.13.13.13.13.13.13.cmml">=</mo><mi id="S2.E1.m1.14.14.14.14.14.14" xref="S2.E1.m1.14.14.14.14.14.14.cmml">m</mi><mi id="S2.E1.m1.15.15.15.15.15.15" xref="S2.E1.m1.15.15.15.15.15.15.cmml">a</mi><mi id="S2.E1.m1.16.16.16.16.16.16" xref="S2.E1.m1.16.16.16.16.16.16.cmml">x</mi><mrow id="S2.E1.m1.42.42.42.42.42.44" xref="S2.E1.m1.71.71.2.cmml"><mo stretchy="false" id="S2.E1.m1.17.17.17.17.17.17" xref="S2.E1.m1.71.71.2.cmml">(</mo><mi id="S2.E1.m1.18.18.18.18.18.18" xref="S2.E1.m1.18.18.18.18.18.18.cmml">t</mi><mi id="S2.E1.m1.19.19.19.19.19.19" xref="S2.E1.m1.19.19.19.19.19.19.cmml">r</mi><mi id="S2.E1.m1.20.20.20.20.20.20" xref="S2.E1.m1.20.20.20.20.20.20.cmml">e</mi><mi id="S2.E1.m1.21.21.21.21.21.21" xref="S2.E1.m1.21.21.21.21.21.21.cmml">l</mi><mi id="S2.E1.m1.22.22.22.22.22.22" xref="S2.E1.m1.22.22.22.22.22.22.cmml">l</mi><mi id="S2.E1.m1.23.23.23.23.23.23" xref="S2.E1.m1.23.23.23.23.23.23.cmml">i</mi><mi id="S2.E1.m1.24.24.24.24.24.24" xref="S2.E1.m1.24.24.24.24.24.24.cmml">s</mi><mrow id="S2.E1.m1.42.42.42.42.42.44.1" xref="S2.E1.m1.71.71.2.cmml"><mo stretchy="false" id="S2.E1.m1.25.25.25.25.25.25" xref="S2.E1.m1.71.71.2.cmml">[</mo><mi id="S2.E1.m1.26.26.26.26.26.26" xref="S2.E1.m1.26.26.26.26.26.26.cmml">j</mi><mo id="S2.E1.m1.27.27.27.27.27.27" xref="S2.E1.m1.71.71.2.cmml">,</mo><mi id="S2.E1.m1.28.28.28.28.28.28" xref="S2.E1.m1.28.28.28.28.28.28.cmml">t</mi><mo id="S2.E1.m1.29.29.29.29.29.29" xref="S2.E1.m1.29.29.29.29.29.29.cmml">−</mo><mn id="S2.E1.m1.30.30.30.30.30.30" xref="S2.E1.m1.30.30.30.30.30.30.cmml">1</mn><mo rspace="0.055em" stretchy="false" id="S2.E1.m1.31.31.31.31.31.31" xref="S2.E1.m1.71.71.2.cmml">]</mo></mrow><mo rspace="0.222em" id="S2.E1.m1.32.32.32.32.32.32" xref="S2.E1.m1.32.32.32.32.32.32.cmml">⋅</mo><mi id="S2.E1.m1.33.33.33.33.33.33" xref="S2.E1.m1.33.33.33.33.33.33.cmml">p</mi><mi id="S2.E1.m1.34.34.34.34.34.34" xref="S2.E1.m1.34.34.34.34.34.34.cmml">r</mi><mi id="S2.E1.m1.35.35.35.35.35.35" xref="S2.E1.m1.35.35.35.35.35.35.cmml">o</mi><mi id="S2.E1.m1.36.36.36.36.36.36" xref="S2.E1.m1.36.36.36.36.36.36.cmml">b</mi><mrow id="S2.E1.m1.42.42.42.42.42.44.2" xref="S2.E1.m1.71.71.2.cmml"><mo stretchy="false" id="S2.E1.m1.37.37.37.37.37.37" xref="S2.E1.m1.71.71.2.cmml">[</mo><mi id="S2.E1.m1.38.38.38.38.38.38" xref="S2.E1.m1.38.38.38.38.38.38.cmml">t</mi><mo id="S2.E1.m1.39.39.39.39.39.39" xref="S2.E1.m1.71.71.2.cmml">,</mo><mi id="S2.E1.m1.40.40.40.40.40.40" xref="S2.E1.m1.40.40.40.40.40.40.cmml">ϵ</mi><mo stretchy="false" id="S2.E1.m1.41.41.41.41.41.41" xref="S2.E1.m1.71.71.2.cmml">]</mo></mrow><mo id="S2.E1.m1.42.42.42.42.42.42" xref="S2.E1.m1.71.71.2.cmml">,</mo></mrow></mrow></mtd></mtr><mtr id="S2.E1.m1.69.69c" xref="S2.E1.m1.71.71.2.cmml"><mtd class="ltx_align_right" columnalign="right" id="S2.E1.m1.69.69d" xref="S2.E1.m1.71.71.2.cmml"><mrow id="S2.E1.m1.69.69.69.27.27" xref="S2.E1.m1.71.71.2.cmml"><mi id="S2.E1.m1.43.43.43.1.1.1" xref="S2.E1.m1.43.43.43.1.1.1.cmml">t</mi><mi id="S2.E1.m1.44.44.44.2.2.2" xref="S2.E1.m1.44.44.44.2.2.2.cmml">r</mi><mi id="S2.E1.m1.45.45.45.3.3.3" xref="S2.E1.m1.45.45.45.3.3.3.cmml">e</mi><mi id="S2.E1.m1.46.46.46.4.4.4" xref="S2.E1.m1.46.46.46.4.4.4.cmml">l</mi><mi id="S2.E1.m1.47.47.47.5.5.5" xref="S2.E1.m1.47.47.47.5.5.5.cmml">l</mi><mi id="S2.E1.m1.48.48.48.6.6.6" xref="S2.E1.m1.48.48.48.6.6.6.cmml">i</mi><mi id="S2.E1.m1.49.49.49.7.7.7" xref="S2.E1.m1.49.49.49.7.7.7.cmml">s</mi><mrow id="S2.E1.m1.69.69.69.27.27.28" xref="S2.E1.m1.71.71.2.cmml"><mo stretchy="false" id="S2.E1.m1.50.50.50.8.8.8" xref="S2.E1.m1.71.71.2.cmml">[</mo><mi id="S2.E1.m1.51.51.51.9.9.9" xref="S2.E1.m1.51.51.51.9.9.9.cmml">j</mi><mo id="S2.E1.m1.52.52.52.10.10.10" xref="S2.E1.m1.52.52.52.10.10.10.cmml">−</mo><mn id="S2.E1.m1.53.53.53.11.11.11" xref="S2.E1.m1.53.53.53.11.11.11.cmml">1</mn><mo id="S2.E1.m1.54.54.54.12.12.12" xref="S2.E1.m1.71.71.2.cmml">,</mo><mi id="S2.E1.m1.55.55.55.13.13.13" xref="S2.E1.m1.55.55.55.13.13.13.cmml">t</mi><mo id="S2.E1.m1.56.56.56.14.14.14" xref="S2.E1.m1.56.56.56.14.14.14.cmml">−</mo><mn id="S2.E1.m1.57.57.57.15.15.15" xref="S2.E1.m1.57.57.57.15.15.15.cmml">1</mn><mo rspace="0.055em" stretchy="false" id="S2.E1.m1.58.58.58.16.16.16" xref="S2.E1.m1.71.71.2.cmml">]</mo></mrow><mo rspace="0.222em" id="S2.E1.m1.59.59.59.17.17.17" xref="S2.E1.m1.59.59.59.17.17.17.cmml">⋅</mo><mi id="S2.E1.m1.60.60.60.18.18.18" xref="S2.E1.m1.60.60.60.18.18.18.cmml">p</mi><mi id="S2.E1.m1.61.61.61.19.19.19" xref="S2.E1.m1.61.61.61.19.19.19.cmml">r</mi><mi id="S2.E1.m1.62.62.62.20.20.20" xref="S2.E1.m1.62.62.62.20.20.20.cmml">o</mi><mi id="S2.E1.m1.63.63.63.21.21.21" xref="S2.E1.m1.63.63.63.21.21.21.cmml">b</mi><mrow id="S2.E1.m1.69.69.69.27.27.29" xref="S2.E1.m1.71.71.2.cmml"><mo stretchy="false" id="S2.E1.m1.64.64.64.22.22.22" xref="S2.E1.m1.71.71.2.cmml">[</mo><mi id="S2.E1.m1.65.65.65.23.23.23" xref="S2.E1.m1.65.65.65.23.23.23.cmml">t</mi><mo id="S2.E1.m1.66.66.66.24.24.24" xref="S2.E1.m1.71.71.2.cmml">,</mo><mi id="S2.E1.m1.67.67.67.25.25.25" xref="S2.E1.m1.67.67.67.25.25.25.cmml">j</mi><mo stretchy="false" id="S2.E1.m1.68.68.68.26.26.26" xref="S2.E1.m1.71.71.2.cmml">]</mo></mrow><mo stretchy="false" id="S2.E1.m1.69.69.69.27.27.27" xref="S2.E1.m1.71.71.2.cmml">)</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S2.E1.m1.71b"><apply id="S2.E1.m1.71.71.2.cmml" xref="S2.E1.m1.69.69"><eq id="S2.E1.m1.13.13.13.13.13.13.cmml" xref="S2.E1.m1.13.13.13.13.13.13"></eq><apply id="S2.E1.m1.71.71.2.4.cmml" xref="S2.E1.m1.69.69"><times id="S2.E1.m1.71.71.2.4.1.cmml" xref="S2.E1.m1.69.69"></times><ci id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1">𝑡</ci><ci id="S2.E1.m1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2">𝑟</ci><ci id="S2.E1.m1.3.3.3.3.3.3.cmml" xref="S2.E1.m1.3.3.3.3.3.3">𝑒</ci><ci id="S2.E1.m1.4.4.4.4.4.4.cmml" xref="S2.E1.m1.4.4.4.4.4.4">𝑙</ci><ci id="S2.E1.m1.5.5.5.5.5.5.cmml" xref="S2.E1.m1.5.5.5.5.5.5">𝑙</ci><ci id="S2.E1.m1.6.6.6.6.6.6.cmml" xref="S2.E1.m1.6.6.6.6.6.6">𝑖</ci><ci id="S2.E1.m1.7.7.7.7.7.7.cmml" xref="S2.E1.m1.7.7.7.7.7.7">𝑠</ci><interval closure="closed" id="S2.E1.m1.71.71.2.4.9.cmml" xref="S2.E1.m1.69.69"><ci id="S2.E1.m1.9.9.9.9.9.9.cmml" xref="S2.E1.m1.9.9.9.9.9.9">𝑗</ci><ci id="S2.E1.m1.11.11.11.11.11.11.cmml" xref="S2.E1.m1.11.11.11.11.11.11">𝑡</ci></interval></apply><apply id="S2.E1.m1.71.71.2.2.cmml" xref="S2.E1.m1.69.69"><times id="S2.E1.m1.71.71.2.2.3.cmml" xref="S2.E1.m1.69.69"></times><ci id="S2.E1.m1.14.14.14.14.14.14.cmml" xref="S2.E1.m1.14.14.14.14.14.14">𝑚</ci><ci id="S2.E1.m1.15.15.15.15.15.15.cmml" xref="S2.E1.m1.15.15.15.15.15.15">𝑎</ci><ci id="S2.E1.m1.16.16.16.16.16.16.cmml" xref="S2.E1.m1.16.16.16.16.16.16">𝑥</ci><interval closure="open" id="S2.E1.m1.71.71.2.2.2.3.cmml" xref="S2.E1.m1.69.69"><apply id="S2.E1.m1.70.70.1.1.1.1.1.cmml" xref="S2.E1.m1.69.69"><times id="S2.E1.m1.70.70.1.1.1.1.1.2.cmml" xref="S2.E1.m1.69.69"></times><apply id="S2.E1.m1.70.70.1.1.1.1.1.1.cmml" xref="S2.E1.m1.69.69"><ci id="S2.E1.m1.32.32.32.32.32.32.cmml" xref="S2.E1.m1.32.32.32.32.32.32">⋅</ci><apply id="S2.E1.m1.70.70.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.69.69"><times id="S2.E1.m1.70.70.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.69.69"></times><ci id="S2.E1.m1.18.18.18.18.18.18.cmml" xref="S2.E1.m1.18.18.18.18.18.18">𝑡</ci><ci id="S2.E1.m1.19.19.19.19.19.19.cmml" xref="S2.E1.m1.19.19.19.19.19.19">𝑟</ci><ci id="S2.E1.m1.20.20.20.20.20.20.cmml" xref="S2.E1.m1.20.20.20.20.20.20">𝑒</ci><ci id="S2.E1.m1.21.21.21.21.21.21.cmml" xref="S2.E1.m1.21.21.21.21.21.21">𝑙</ci><ci id="S2.E1.m1.22.22.22.22.22.22.cmml" xref="S2.E1.m1.22.22.22.22.22.22">𝑙</ci><ci id="S2.E1.m1.23.23.23.23.23.23.cmml" xref="S2.E1.m1.23.23.23.23.23.23">𝑖</ci><ci id="S2.E1.m1.24.24.24.24.24.24.cmml" xref="S2.E1.m1.24.24.24.24.24.24">𝑠</ci><interval closure="closed" id="S2.E1.m1.70.70.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.69.69"><ci id="S2.E1.m1.26.26.26.26.26.26.cmml" xref="S2.E1.m1.26.26.26.26.26.26">𝑗</ci><apply id="S2.E1.m1.70.70.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.69.69"><minus id="S2.E1.m1.29.29.29.29.29.29.cmml" xref="S2.E1.m1.29.29.29.29.29.29"></minus><ci id="S2.E1.m1.28.28.28.28.28.28.cmml" xref="S2.E1.m1.28.28.28.28.28.28">𝑡</ci><cn type="integer" id="S2.E1.m1.30.30.30.30.30.30.cmml" xref="S2.E1.m1.30.30.30.30.30.30">1</cn></apply></interval></apply><ci id="S2.E1.m1.33.33.33.33.33.33.cmml" xref="S2.E1.m1.33.33.33.33.33.33">𝑝</ci></apply><ci id="S2.E1.m1.34.34.34.34.34.34.cmml" xref="S2.E1.m1.34.34.34.34.34.34">𝑟</ci><ci id="S2.E1.m1.35.35.35.35.35.35.cmml" xref="S2.E1.m1.35.35.35.35.35.35">𝑜</ci><ci id="S2.E1.m1.36.36.36.36.36.36.cmml" xref="S2.E1.m1.36.36.36.36.36.36">𝑏</ci><interval closure="closed" id="S2.E1.m1.70.70.1.1.1.1.1.6.cmml" xref="S2.E1.m1.69.69"><ci id="S2.E1.m1.38.38.38.38.38.38.cmml" xref="S2.E1.m1.38.38.38.38.38.38">𝑡</ci><ci id="S2.E1.m1.40.40.40.40.40.40.cmml" xref="S2.E1.m1.40.40.40.40.40.40">italic-ϵ</ci></interval></apply><apply id="S2.E1.m1.71.71.2.2.2.2.2.cmml" xref="S2.E1.m1.69.69"><times id="S2.E1.m1.71.71.2.2.2.2.2.3.cmml" xref="S2.E1.m1.69.69"></times><apply id="S2.E1.m1.71.71.2.2.2.2.2.2.cmml" xref="S2.E1.m1.69.69"><ci id="S2.E1.m1.59.59.59.17.17.17.cmml" xref="S2.E1.m1.59.59.59.17.17.17">⋅</ci><apply id="S2.E1.m1.71.71.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.69.69"><times id="S2.E1.m1.71.71.2.2.2.2.2.2.2.3.cmml" xref="S2.E1.m1.69.69"></times><ci id="S2.E1.m1.43.43.43.1.1.1.cmml" xref="S2.E1.m1.43.43.43.1.1.1">𝑡</ci><ci id="S2.E1.m1.44.44.44.2.2.2.cmml" xref="S2.E1.m1.44.44.44.2.2.2">𝑟</ci><ci id="S2.E1.m1.45.45.45.3.3.3.cmml" xref="S2.E1.m1.45.45.45.3.3.3">𝑒</ci><ci id="S2.E1.m1.46.46.46.4.4.4.cmml" xref="S2.E1.m1.46.46.46.4.4.4">𝑙</ci><ci id="S2.E1.m1.47.47.47.5.5.5.cmml" xref="S2.E1.m1.47.47.47.5.5.5">𝑙</ci><ci id="S2.E1.m1.48.48.48.6.6.6.cmml" xref="S2.E1.m1.48.48.48.6.6.6">𝑖</ci><ci id="S2.E1.m1.49.49.49.7.7.7.cmml" xref="S2.E1.m1.49.49.49.7.7.7">𝑠</ci><interval closure="closed" id="S2.E1.m1.71.71.2.2.2.2.2.2.2.2.3.cmml" xref="S2.E1.m1.69.69"><apply id="S2.E1.m1.71.71.2.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.69.69"><minus id="S2.E1.m1.52.52.52.10.10.10.cmml" xref="S2.E1.m1.52.52.52.10.10.10"></minus><ci id="S2.E1.m1.51.51.51.9.9.9.cmml" xref="S2.E1.m1.51.51.51.9.9.9">𝑗</ci><cn type="integer" id="S2.E1.m1.53.53.53.11.11.11.cmml" xref="S2.E1.m1.53.53.53.11.11.11">1</cn></apply><apply id="S2.E1.m1.71.71.2.2.2.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.69.69"><minus id="S2.E1.m1.56.56.56.14.14.14.cmml" xref="S2.E1.m1.56.56.56.14.14.14"></minus><ci id="S2.E1.m1.55.55.55.13.13.13.cmml" xref="S2.E1.m1.55.55.55.13.13.13">𝑡</ci><cn type="integer" id="S2.E1.m1.57.57.57.15.15.15.cmml" xref="S2.E1.m1.57.57.57.15.15.15">1</cn></apply></interval></apply><ci id="S2.E1.m1.60.60.60.18.18.18.cmml" xref="S2.E1.m1.60.60.60.18.18.18">𝑝</ci></apply><ci id="S2.E1.m1.61.61.61.19.19.19.cmml" xref="S2.E1.m1.61.61.61.19.19.19">𝑟</ci><ci id="S2.E1.m1.62.62.62.20.20.20.cmml" xref="S2.E1.m1.62.62.62.20.20.20">𝑜</ci><ci id="S2.E1.m1.63.63.63.21.21.21.cmml" xref="S2.E1.m1.63.63.63.21.21.21">𝑏</ci><interval closure="closed" id="S2.E1.m1.71.71.2.2.2.2.2.7.cmml" xref="S2.E1.m1.69.69"><ci id="S2.E1.m1.65.65.65.23.23.23.cmml" xref="S2.E1.m1.65.65.65.23.23.23">𝑡</ci><ci id="S2.E1.m1.67.67.67.25.25.25.cmml" xref="S2.E1.m1.67.67.67.25.25.25">𝑗</ci></interval></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.71c">\begin{split}trellis[j,t]=max(trellis[j,t-1]\cdot prob[t,\epsilon],\\
trellis[j-1,t-1]\cdot prob[t,j])\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.I1.i2.p3" class="ltx_para">
<p id="S2.I1.i2.p3.4" class="ltx_p">where <math id="S2.I1.i2.p3.1.m1.2" class="ltx_Math" alttext="trellis[j,t]" display="inline"><semantics id="S2.I1.i2.p3.1.m1.2a"><mrow id="S2.I1.i2.p3.1.m1.2.3" xref="S2.I1.i2.p3.1.m1.2.3.cmml"><mi id="S2.I1.i2.p3.1.m1.2.3.2" xref="S2.I1.i2.p3.1.m1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.1.m1.2.3.1" xref="S2.I1.i2.p3.1.m1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.1.m1.2.3.3" xref="S2.I1.i2.p3.1.m1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.1.m1.2.3.1a" xref="S2.I1.i2.p3.1.m1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.1.m1.2.3.4" xref="S2.I1.i2.p3.1.m1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.1.m1.2.3.1b" xref="S2.I1.i2.p3.1.m1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.1.m1.2.3.5" xref="S2.I1.i2.p3.1.m1.2.3.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.1.m1.2.3.1c" xref="S2.I1.i2.p3.1.m1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.1.m1.2.3.6" xref="S2.I1.i2.p3.1.m1.2.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.1.m1.2.3.1d" xref="S2.I1.i2.p3.1.m1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.1.m1.2.3.7" xref="S2.I1.i2.p3.1.m1.2.3.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.1.m1.2.3.1e" xref="S2.I1.i2.p3.1.m1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.1.m1.2.3.8" xref="S2.I1.i2.p3.1.m1.2.3.8.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.1.m1.2.3.1f" xref="S2.I1.i2.p3.1.m1.2.3.1.cmml">​</mo><mrow id="S2.I1.i2.p3.1.m1.2.3.9.2" xref="S2.I1.i2.p3.1.m1.2.3.9.1.cmml"><mo stretchy="false" id="S2.I1.i2.p3.1.m1.2.3.9.2.1" xref="S2.I1.i2.p3.1.m1.2.3.9.1.cmml">[</mo><mi id="S2.I1.i2.p3.1.m1.1.1" xref="S2.I1.i2.p3.1.m1.1.1.cmml">j</mi><mo id="S2.I1.i2.p3.1.m1.2.3.9.2.2" xref="S2.I1.i2.p3.1.m1.2.3.9.1.cmml">,</mo><mi id="S2.I1.i2.p3.1.m1.2.2" xref="S2.I1.i2.p3.1.m1.2.2.cmml">t</mi><mo stretchy="false" id="S2.I1.i2.p3.1.m1.2.3.9.2.3" xref="S2.I1.i2.p3.1.m1.2.3.9.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p3.1.m1.2b"><apply id="S2.I1.i2.p3.1.m1.2.3.cmml" xref="S2.I1.i2.p3.1.m1.2.3"><times id="S2.I1.i2.p3.1.m1.2.3.1.cmml" xref="S2.I1.i2.p3.1.m1.2.3.1"></times><ci id="S2.I1.i2.p3.1.m1.2.3.2.cmml" xref="S2.I1.i2.p3.1.m1.2.3.2">𝑡</ci><ci id="S2.I1.i2.p3.1.m1.2.3.3.cmml" xref="S2.I1.i2.p3.1.m1.2.3.3">𝑟</ci><ci id="S2.I1.i2.p3.1.m1.2.3.4.cmml" xref="S2.I1.i2.p3.1.m1.2.3.4">𝑒</ci><ci id="S2.I1.i2.p3.1.m1.2.3.5.cmml" xref="S2.I1.i2.p3.1.m1.2.3.5">𝑙</ci><ci id="S2.I1.i2.p3.1.m1.2.3.6.cmml" xref="S2.I1.i2.p3.1.m1.2.3.6">𝑙</ci><ci id="S2.I1.i2.p3.1.m1.2.3.7.cmml" xref="S2.I1.i2.p3.1.m1.2.3.7">𝑖</ci><ci id="S2.I1.i2.p3.1.m1.2.3.8.cmml" xref="S2.I1.i2.p3.1.m1.2.3.8">𝑠</ci><interval closure="closed" id="S2.I1.i2.p3.1.m1.2.3.9.1.cmml" xref="S2.I1.i2.p3.1.m1.2.3.9.2"><ci id="S2.I1.i2.p3.1.m1.1.1.cmml" xref="S2.I1.i2.p3.1.m1.1.1">𝑗</ci><ci id="S2.I1.i2.p3.1.m1.2.2.cmml" xref="S2.I1.i2.p3.1.m1.2.2">𝑡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p3.1.m1.2c">trellis[j,t]</annotation></semantics></math> and <math id="S2.I1.i2.p3.2.m2.2" class="ltx_Math" alttext="prob[j,t]" display="inline"><semantics id="S2.I1.i2.p3.2.m2.2a"><mrow id="S2.I1.i2.p3.2.m2.2.3" xref="S2.I1.i2.p3.2.m2.2.3.cmml"><mi id="S2.I1.i2.p3.2.m2.2.3.2" xref="S2.I1.i2.p3.2.m2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.2.m2.2.3.1" xref="S2.I1.i2.p3.2.m2.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.2.m2.2.3.3" xref="S2.I1.i2.p3.2.m2.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.2.m2.2.3.1a" xref="S2.I1.i2.p3.2.m2.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.2.m2.2.3.4" xref="S2.I1.i2.p3.2.m2.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.2.m2.2.3.1b" xref="S2.I1.i2.p3.2.m2.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p3.2.m2.2.3.5" xref="S2.I1.i2.p3.2.m2.2.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p3.2.m2.2.3.1c" xref="S2.I1.i2.p3.2.m2.2.3.1.cmml">​</mo><mrow id="S2.I1.i2.p3.2.m2.2.3.6.2" xref="S2.I1.i2.p3.2.m2.2.3.6.1.cmml"><mo stretchy="false" id="S2.I1.i2.p3.2.m2.2.3.6.2.1" xref="S2.I1.i2.p3.2.m2.2.3.6.1.cmml">[</mo><mi id="S2.I1.i2.p3.2.m2.1.1" xref="S2.I1.i2.p3.2.m2.1.1.cmml">j</mi><mo id="S2.I1.i2.p3.2.m2.2.3.6.2.2" xref="S2.I1.i2.p3.2.m2.2.3.6.1.cmml">,</mo><mi id="S2.I1.i2.p3.2.m2.2.2" xref="S2.I1.i2.p3.2.m2.2.2.cmml">t</mi><mo stretchy="false" id="S2.I1.i2.p3.2.m2.2.3.6.2.3" xref="S2.I1.i2.p3.2.m2.2.3.6.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p3.2.m2.2b"><apply id="S2.I1.i2.p3.2.m2.2.3.cmml" xref="S2.I1.i2.p3.2.m2.2.3"><times id="S2.I1.i2.p3.2.m2.2.3.1.cmml" xref="S2.I1.i2.p3.2.m2.2.3.1"></times><ci id="S2.I1.i2.p3.2.m2.2.3.2.cmml" xref="S2.I1.i2.p3.2.m2.2.3.2">𝑝</ci><ci id="S2.I1.i2.p3.2.m2.2.3.3.cmml" xref="S2.I1.i2.p3.2.m2.2.3.3">𝑟</ci><ci id="S2.I1.i2.p3.2.m2.2.3.4.cmml" xref="S2.I1.i2.p3.2.m2.2.3.4">𝑜</ci><ci id="S2.I1.i2.p3.2.m2.2.3.5.cmml" xref="S2.I1.i2.p3.2.m2.2.3.5">𝑏</ci><interval closure="closed" id="S2.I1.i2.p3.2.m2.2.3.6.1.cmml" xref="S2.I1.i2.p3.2.m2.2.3.6.2"><ci id="S2.I1.i2.p3.2.m2.1.1.cmml" xref="S2.I1.i2.p3.2.m2.1.1">𝑗</ci><ci id="S2.I1.i2.p3.2.m2.2.2.cmml" xref="S2.I1.i2.p3.2.m2.2.2">𝑡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p3.2.m2.2c">prob[j,t]</annotation></semantics></math> indicate the trellis value and the frame-wise probability value at time <math id="S2.I1.i2.p3.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.I1.i2.p3.3.m3.1a"><mi id="S2.I1.i2.p3.3.m3.1.1" xref="S2.I1.i2.p3.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p3.3.m3.1b"><ci id="S2.I1.i2.p3.3.m3.1.1.cmml" xref="S2.I1.i2.p3.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p3.3.m3.1c">t</annotation></semantics></math> and label <math id="S2.I1.i2.p3.4.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.I1.i2.p3.4.m4.1a"><mi id="S2.I1.i2.p3.4.m4.1.1" xref="S2.I1.i2.p3.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p3.4.m4.1b"><ci id="S2.I1.i2.p3.4.m4.1.1.cmml" xref="S2.I1.i2.p3.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p3.4.m4.1c">j</annotation></semantics></math>, respectively.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p">In the third step, the path with the highest probability in the trellis is traced back. This path begins at position <math id="S2.I1.i3.p1.1.m1.4" class="ltx_Math" alttext="(0,0)andendsatposition(T,U)" display="inline"><semantics id="S2.I1.i3.p1.1.m1.4a"><mrow id="S2.I1.i3.p1.1.m1.4.5" xref="S2.I1.i3.p1.1.m1.4.5.cmml"><mrow id="S2.I1.i3.p1.1.m1.4.5.2.2" xref="S2.I1.i3.p1.1.m1.4.5.2.1.cmml"><mo stretchy="false" id="S2.I1.i3.p1.1.m1.4.5.2.2.1" xref="S2.I1.i3.p1.1.m1.4.5.2.1.cmml">(</mo><mn id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml">0</mn><mo id="S2.I1.i3.p1.1.m1.4.5.2.2.2" xref="S2.I1.i3.p1.1.m1.4.5.2.1.cmml">,</mo><mn id="S2.I1.i3.p1.1.m1.2.2" xref="S2.I1.i3.p1.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S2.I1.i3.p1.1.m1.4.5.2.2.3" xref="S2.I1.i3.p1.1.m1.4.5.2.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.3" xref="S2.I1.i3.p1.1.m1.4.5.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1a" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.4" xref="S2.I1.i3.p1.1.m1.4.5.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1b" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.5" xref="S2.I1.i3.p1.1.m1.4.5.5.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1c" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.6" xref="S2.I1.i3.p1.1.m1.4.5.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1d" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.7" xref="S2.I1.i3.p1.1.m1.4.5.7.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1e" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.8" xref="S2.I1.i3.p1.1.m1.4.5.8.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1f" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.9" xref="S2.I1.i3.p1.1.m1.4.5.9.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1g" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.10" xref="S2.I1.i3.p1.1.m1.4.5.10.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1h" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.11" xref="S2.I1.i3.p1.1.m1.4.5.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1i" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.12" xref="S2.I1.i3.p1.1.m1.4.5.12.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1j" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.13" xref="S2.I1.i3.p1.1.m1.4.5.13.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1k" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.14" xref="S2.I1.i3.p1.1.m1.4.5.14.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1l" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.15" xref="S2.I1.i3.p1.1.m1.4.5.15.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1m" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.16" xref="S2.I1.i3.p1.1.m1.4.5.16.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1n" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.17" xref="S2.I1.i3.p1.1.m1.4.5.17.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1o" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.18" xref="S2.I1.i3.p1.1.m1.4.5.18.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1p" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mi id="S2.I1.i3.p1.1.m1.4.5.19" xref="S2.I1.i3.p1.1.m1.4.5.19.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.1.m1.4.5.1q" xref="S2.I1.i3.p1.1.m1.4.5.1.cmml">​</mo><mrow id="S2.I1.i3.p1.1.m1.4.5.20.2" xref="S2.I1.i3.p1.1.m1.4.5.20.1.cmml"><mo stretchy="false" id="S2.I1.i3.p1.1.m1.4.5.20.2.1" xref="S2.I1.i3.p1.1.m1.4.5.20.1.cmml">(</mo><mi id="S2.I1.i3.p1.1.m1.3.3" xref="S2.I1.i3.p1.1.m1.3.3.cmml">T</mi><mo id="S2.I1.i3.p1.1.m1.4.5.20.2.2" xref="S2.I1.i3.p1.1.m1.4.5.20.1.cmml">,</mo><mi id="S2.I1.i3.p1.1.m1.4.4" xref="S2.I1.i3.p1.1.m1.4.4.cmml">U</mi><mo stretchy="false" id="S2.I1.i3.p1.1.m1.4.5.20.2.3" xref="S2.I1.i3.p1.1.m1.4.5.20.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.4b"><apply id="S2.I1.i3.p1.1.m1.4.5.cmml" xref="S2.I1.i3.p1.1.m1.4.5"><times id="S2.I1.i3.p1.1.m1.4.5.1.cmml" xref="S2.I1.i3.p1.1.m1.4.5.1"></times><interval closure="open" id="S2.I1.i3.p1.1.m1.4.5.2.1.cmml" xref="S2.I1.i3.p1.1.m1.4.5.2.2"><cn type="integer" id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">0</cn><cn type="integer" id="S2.I1.i3.p1.1.m1.2.2.cmml" xref="S2.I1.i3.p1.1.m1.2.2">0</cn></interval><ci id="S2.I1.i3.p1.1.m1.4.5.3.cmml" xref="S2.I1.i3.p1.1.m1.4.5.3">𝑎</ci><ci id="S2.I1.i3.p1.1.m1.4.5.4.cmml" xref="S2.I1.i3.p1.1.m1.4.5.4">𝑛</ci><ci id="S2.I1.i3.p1.1.m1.4.5.5.cmml" xref="S2.I1.i3.p1.1.m1.4.5.5">𝑑</ci><ci id="S2.I1.i3.p1.1.m1.4.5.6.cmml" xref="S2.I1.i3.p1.1.m1.4.5.6">𝑒</ci><ci id="S2.I1.i3.p1.1.m1.4.5.7.cmml" xref="S2.I1.i3.p1.1.m1.4.5.7">𝑛</ci><ci id="S2.I1.i3.p1.1.m1.4.5.8.cmml" xref="S2.I1.i3.p1.1.m1.4.5.8">𝑑</ci><ci id="S2.I1.i3.p1.1.m1.4.5.9.cmml" xref="S2.I1.i3.p1.1.m1.4.5.9">𝑠</ci><ci id="S2.I1.i3.p1.1.m1.4.5.10.cmml" xref="S2.I1.i3.p1.1.m1.4.5.10">𝑎</ci><ci id="S2.I1.i3.p1.1.m1.4.5.11.cmml" xref="S2.I1.i3.p1.1.m1.4.5.11">𝑡</ci><ci id="S2.I1.i3.p1.1.m1.4.5.12.cmml" xref="S2.I1.i3.p1.1.m1.4.5.12">𝑝</ci><ci id="S2.I1.i3.p1.1.m1.4.5.13.cmml" xref="S2.I1.i3.p1.1.m1.4.5.13">𝑜</ci><ci id="S2.I1.i3.p1.1.m1.4.5.14.cmml" xref="S2.I1.i3.p1.1.m1.4.5.14">𝑠</ci><ci id="S2.I1.i3.p1.1.m1.4.5.15.cmml" xref="S2.I1.i3.p1.1.m1.4.5.15">𝑖</ci><ci id="S2.I1.i3.p1.1.m1.4.5.16.cmml" xref="S2.I1.i3.p1.1.m1.4.5.16">𝑡</ci><ci id="S2.I1.i3.p1.1.m1.4.5.17.cmml" xref="S2.I1.i3.p1.1.m1.4.5.17">𝑖</ci><ci id="S2.I1.i3.p1.1.m1.4.5.18.cmml" xref="S2.I1.i3.p1.1.m1.4.5.18">𝑜</ci><ci id="S2.I1.i3.p1.1.m1.4.5.19.cmml" xref="S2.I1.i3.p1.1.m1.4.5.19">𝑛</ci><interval closure="open" id="S2.I1.i3.p1.1.m1.4.5.20.1.cmml" xref="S2.I1.i3.p1.1.m1.4.5.20.2"><ci id="S2.I1.i3.p1.1.m1.3.3.cmml" xref="S2.I1.i3.p1.1.m1.3.3">𝑇</ci><ci id="S2.I1.i3.p1.1.m1.4.4.cmml" xref="S2.I1.i3.p1.1.m1.4.4">𝑈</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.4c">(0,0)andendsatposition(T,U)</annotation></semantics></math> to encompass the entire audio and transcript.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>Modified CTC Alignment</h4>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2409.10177/assets/images/new_alignment.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="295" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.4.1.1" class="ltx_text ltx_font_bold">Fig. 2</span>: </span>Alignments of generated transcription to speech signal with standard (upper) and modified (lower) CTC forced alignments. The ASR prediction is: <span id="S2.F2.5.2" class="ltx_text ltx_font_italic">I had that curiosity at the moment</span>, while the manual transcript contains the disfluency: <span id="S2.F2.6.3" class="ltx_text ltx_font_italic">I had that curiosity <span id="S2.F2.6.3.1" class="ltx_text ltx_font_bold">beside me</span> at the moment</span>.</figcaption>
</figure>
<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">Our preliminary experiments show that the standard CTC alignment struggles to generate correct information when the automated transcription does not include the disfluency. As <a href="#S2.F2" title="Figure 2 ‣ 2.2.2 Modified CTC Alignment ‣ 2.2 Forced alignment ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a> shows, the manual transcript of this example contains the disfluency, which is removed by the ASR model for better readability. The standard CTC alignment extends the alignment around incomplete words, leading to inaccurate alignment and missing disfluency detection. This occurs because the standard CTC algorithm tends to align a word for a longer duration rather than to align silence where something is being said. In trellis generation (refer to <a href="#S2.E1" title="1 ‣ item 2 ‣ 2.2.1 Standard CTC Alignment ‣ 2.2 Forced alignment ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Equation 1</span></a>), the emissions for a blank token in this part of the audio are very low, as something was spoken there. As a consequence, gaps in the alignment of the transcript may not occur where they should, which is undesirable for this application.</p>
</div>
<div id="S2.SS2.SSS2.p2" class="ltx_para">
<p id="S2.SS2.SSS2.p2.2" class="ltx_p">To counteract this issue, we proposed the modified CTC alignment alignment to enable the model to detect the alignment gaps containing the speech of untranscribed disfluency. In trellis generation, the modified <a href="#S2.E2" title="2 ‣ 2.2.2 Modified CTC Alignment ‣ 2.2 Forced alignment ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Equation 2</span></a> is applied <span id="S2.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">if the current label <math id="S2.SS2.SSS2.p2.1.1.m1.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.SS2.SSS2.p2.1.1.m1.1a"><mi id="S2.SS2.SSS2.p2.1.1.m1.1.1" xref="S2.SS2.SSS2.p2.1.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p2.1.1.m1.1b"><ci id="S2.SS2.SSS2.p2.1.1.m1.1.1.cmml" xref="S2.SS2.SSS2.p2.1.1.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p2.1.1.m1.1c">j</annotation></semantics></math> is a space token</span>. The space token infers a special label used to represent gaps or spaces between characters or tokens in the output space. With modification, the modified probability of staying on this label is the maximum of the probability acquired through the emissions and a predefined probability <math id="S2.SS2.SSS2.p2.2.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S2.SS2.SSS2.p2.2.m1.1a"><mi id="S2.SS2.SSS2.p2.2.m1.1.1" xref="S2.SS2.SSS2.p2.2.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p2.2.m1.1b"><ci id="S2.SS2.SSS2.p2.2.m1.1.1.cmml" xref="S2.SS2.SSS2.p2.2.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p2.2.m1.1c">c</annotation></semantics></math>. This modification incentivises the algorithm to extend silence between words to some extent.</p>
</div>
<div id="S2.SS2.SSS2.p3" class="ltx_para">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.76" class="ltx_Math" alttext="\begin{split}trellis[j,t]=max(trellis[j,t-1]\cdot\\
\textbf{max}(prob[t,\epsilon],\textbf{c}),trellis[j-1,t-1]\cdot prob[t,j])\end{split}" display="block"><semantics id="S2.E2.m1.76a"><mtable displaystyle="true" rowspacing="0pt" id="S2.E2.m1.74.74" xref="S2.E2.m1.76.76.2.cmml"><mtr id="S2.E2.m1.74.74a" xref="S2.E2.m1.76.76.2.cmml"><mtd class="ltx_align_right" columnalign="right" id="S2.E2.m1.74.74b" xref="S2.E2.m1.76.76.2.cmml"><mrow id="S2.E2.m1.32.32.32.32.32" xref="S2.E2.m1.76.76.2.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml">t</mi><mi id="S2.E2.m1.2.2.2.2.2.2" xref="S2.E2.m1.2.2.2.2.2.2.cmml">r</mi><mi id="S2.E2.m1.3.3.3.3.3.3" xref="S2.E2.m1.3.3.3.3.3.3.cmml">e</mi><mi id="S2.E2.m1.4.4.4.4.4.4" xref="S2.E2.m1.4.4.4.4.4.4.cmml">l</mi><mi id="S2.E2.m1.5.5.5.5.5.5" xref="S2.E2.m1.5.5.5.5.5.5.cmml">l</mi><mi id="S2.E2.m1.6.6.6.6.6.6" xref="S2.E2.m1.6.6.6.6.6.6.cmml">i</mi><mi id="S2.E2.m1.7.7.7.7.7.7" xref="S2.E2.m1.7.7.7.7.7.7.cmml">s</mi><mrow id="S2.E2.m1.32.32.32.32.32.33" xref="S2.E2.m1.76.76.2.cmml"><mo stretchy="false" id="S2.E2.m1.8.8.8.8.8.8" xref="S2.E2.m1.76.76.2.cmml">[</mo><mi id="S2.E2.m1.9.9.9.9.9.9" xref="S2.E2.m1.9.9.9.9.9.9.cmml">j</mi><mo id="S2.E2.m1.10.10.10.10.10.10" xref="S2.E2.m1.76.76.2.cmml">,</mo><mi id="S2.E2.m1.11.11.11.11.11.11" xref="S2.E2.m1.11.11.11.11.11.11.cmml">t</mi><mo stretchy="false" id="S2.E2.m1.12.12.12.12.12.12" xref="S2.E2.m1.76.76.2.cmml">]</mo></mrow><mo id="S2.E2.m1.13.13.13.13.13.13" xref="S2.E2.m1.13.13.13.13.13.13.cmml">=</mo><mi id="S2.E2.m1.14.14.14.14.14.14" xref="S2.E2.m1.14.14.14.14.14.14.cmml">m</mi><mi id="S2.E2.m1.15.15.15.15.15.15" xref="S2.E2.m1.15.15.15.15.15.15.cmml">a</mi><mi id="S2.E2.m1.16.16.16.16.16.16" xref="S2.E2.m1.16.16.16.16.16.16.cmml">x</mi><mrow id="S2.E2.m1.32.32.32.32.32.34" xref="S2.E2.m1.76.76.2.cmml"><mo stretchy="false" id="S2.E2.m1.17.17.17.17.17.17" xref="S2.E2.m1.76.76.2.cmml">(</mo><mi id="S2.E2.m1.18.18.18.18.18.18" xref="S2.E2.m1.18.18.18.18.18.18.cmml">t</mi><mi id="S2.E2.m1.19.19.19.19.19.19" xref="S2.E2.m1.19.19.19.19.19.19.cmml">r</mi><mi id="S2.E2.m1.20.20.20.20.20.20" xref="S2.E2.m1.20.20.20.20.20.20.cmml">e</mi><mi id="S2.E2.m1.21.21.21.21.21.21" xref="S2.E2.m1.21.21.21.21.21.21.cmml">l</mi><mi id="S2.E2.m1.22.22.22.22.22.22" xref="S2.E2.m1.22.22.22.22.22.22.cmml">l</mi><mi id="S2.E2.m1.23.23.23.23.23.23" xref="S2.E2.m1.23.23.23.23.23.23.cmml">i</mi><mi id="S2.E2.m1.24.24.24.24.24.24" xref="S2.E2.m1.24.24.24.24.24.24.cmml">s</mi><mrow id="S2.E2.m1.32.32.32.32.32.34.1" xref="S2.E2.m1.76.76.2.cmml"><mo stretchy="false" id="S2.E2.m1.25.25.25.25.25.25" xref="S2.E2.m1.76.76.2.cmml">[</mo><mi id="S2.E2.m1.26.26.26.26.26.26" xref="S2.E2.m1.26.26.26.26.26.26.cmml">j</mi><mo id="S2.E2.m1.27.27.27.27.27.27" xref="S2.E2.m1.76.76.2.cmml">,</mo><mi id="S2.E2.m1.28.28.28.28.28.28" xref="S2.E2.m1.28.28.28.28.28.28.cmml">t</mi><mo id="S2.E2.m1.29.29.29.29.29.29" xref="S2.E2.m1.29.29.29.29.29.29.cmml">−</mo><mn id="S2.E2.m1.30.30.30.30.30.30" xref="S2.E2.m1.30.30.30.30.30.30.cmml">1</mn><mo rspace="0.055em" stretchy="false" id="S2.E2.m1.31.31.31.31.31.31" xref="S2.E2.m1.76.76.2.cmml">]</mo></mrow><mo id="S2.E2.m1.32.32.32.32.32.32" xref="S2.E2.m1.32.32.32.32.32.32.cmml">⋅</mo></mrow></mrow></mtd></mtr><mtr id="S2.E2.m1.74.74c" xref="S2.E2.m1.76.76.2.cmml"><mtd class="ltx_align_right" columnalign="right" id="S2.E2.m1.74.74d" xref="S2.E2.m1.76.76.2.cmml"><mrow id="S2.E2.m1.74.74.74.42.42" xref="S2.E2.m1.76.76.2.cmml"><mtext class="ltx_mathvariant_bold" id="S2.E2.m1.33.33.33.1.1.1" xref="S2.E2.m1.33.33.33.1.1.1a.cmml">max</mtext><mrow id="S2.E2.m1.74.74.74.42.42.43" xref="S2.E2.m1.76.76.2.cmml"><mo stretchy="false" id="S2.E2.m1.34.34.34.2.2.2" xref="S2.E2.m1.76.76.2.cmml">(</mo><mi id="S2.E2.m1.35.35.35.3.3.3" xref="S2.E2.m1.35.35.35.3.3.3.cmml">p</mi><mi id="S2.E2.m1.36.36.36.4.4.4" xref="S2.E2.m1.36.36.36.4.4.4.cmml">r</mi><mi id="S2.E2.m1.37.37.37.5.5.5" xref="S2.E2.m1.37.37.37.5.5.5.cmml">o</mi><mi id="S2.E2.m1.38.38.38.6.6.6" xref="S2.E2.m1.38.38.38.6.6.6.cmml">b</mi><mrow id="S2.E2.m1.74.74.74.42.42.43.1" xref="S2.E2.m1.76.76.2.cmml"><mo stretchy="false" id="S2.E2.m1.39.39.39.7.7.7" xref="S2.E2.m1.76.76.2.cmml">[</mo><mi id="S2.E2.m1.40.40.40.8.8.8" xref="S2.E2.m1.40.40.40.8.8.8.cmml">t</mi><mo id="S2.E2.m1.41.41.41.9.9.9" xref="S2.E2.m1.76.76.2.cmml">,</mo><mi id="S2.E2.m1.42.42.42.10.10.10" xref="S2.E2.m1.42.42.42.10.10.10.cmml">ϵ</mi><mo stretchy="false" id="S2.E2.m1.43.43.43.11.11.11" xref="S2.E2.m1.76.76.2.cmml">]</mo></mrow><mo id="S2.E2.m1.44.44.44.12.12.12" xref="S2.E2.m1.76.76.2.cmml">,</mo><mtext class="ltx_mathvariant_bold" id="S2.E2.m1.45.45.45.13.13.13" xref="S2.E2.m1.45.45.45.13.13.13a.cmml">c</mtext><mo stretchy="false" id="S2.E2.m1.46.46.46.14.14.14" xref="S2.E2.m1.76.76.2.cmml">)</mo></mrow><mo id="S2.E2.m1.47.47.47.15.15.15" xref="S2.E2.m1.76.76.2.cmml">,</mo><mi id="S2.E2.m1.48.48.48.16.16.16" xref="S2.E2.m1.48.48.48.16.16.16.cmml">t</mi><mi id="S2.E2.m1.49.49.49.17.17.17" xref="S2.E2.m1.49.49.49.17.17.17.cmml">r</mi><mi id="S2.E2.m1.50.50.50.18.18.18" xref="S2.E2.m1.50.50.50.18.18.18.cmml">e</mi><mi id="S2.E2.m1.51.51.51.19.19.19" xref="S2.E2.m1.51.51.51.19.19.19.cmml">l</mi><mi id="S2.E2.m1.52.52.52.20.20.20" xref="S2.E2.m1.52.52.52.20.20.20.cmml">l</mi><mi id="S2.E2.m1.53.53.53.21.21.21" xref="S2.E2.m1.53.53.53.21.21.21.cmml">i</mi><mi id="S2.E2.m1.54.54.54.22.22.22" xref="S2.E2.m1.54.54.54.22.22.22.cmml">s</mi><mrow id="S2.E2.m1.74.74.74.42.42.44" xref="S2.E2.m1.76.76.2.cmml"><mo stretchy="false" id="S2.E2.m1.55.55.55.23.23.23" xref="S2.E2.m1.76.76.2.cmml">[</mo><mi id="S2.E2.m1.56.56.56.24.24.24" xref="S2.E2.m1.56.56.56.24.24.24.cmml">j</mi><mo id="S2.E2.m1.57.57.57.25.25.25" xref="S2.E2.m1.57.57.57.25.25.25.cmml">−</mo><mn id="S2.E2.m1.58.58.58.26.26.26" xref="S2.E2.m1.58.58.58.26.26.26.cmml">1</mn><mo id="S2.E2.m1.59.59.59.27.27.27" xref="S2.E2.m1.76.76.2.cmml">,</mo><mi id="S2.E2.m1.60.60.60.28.28.28" xref="S2.E2.m1.60.60.60.28.28.28.cmml">t</mi><mo id="S2.E2.m1.61.61.61.29.29.29" xref="S2.E2.m1.61.61.61.29.29.29.cmml">−</mo><mn id="S2.E2.m1.62.62.62.30.30.30" xref="S2.E2.m1.62.62.62.30.30.30.cmml">1</mn><mo rspace="0.055em" stretchy="false" id="S2.E2.m1.63.63.63.31.31.31" xref="S2.E2.m1.76.76.2.cmml">]</mo></mrow><mo rspace="0.222em" id="S2.E2.m1.64.64.64.32.32.32" xref="S2.E2.m1.64.64.64.32.32.32.cmml">⋅</mo><mi id="S2.E2.m1.65.65.65.33.33.33" xref="S2.E2.m1.65.65.65.33.33.33.cmml">p</mi><mi id="S2.E2.m1.66.66.66.34.34.34" xref="S2.E2.m1.66.66.66.34.34.34.cmml">r</mi><mi id="S2.E2.m1.67.67.67.35.35.35" xref="S2.E2.m1.67.67.67.35.35.35.cmml">o</mi><mi id="S2.E2.m1.68.68.68.36.36.36" xref="S2.E2.m1.68.68.68.36.36.36.cmml">b</mi><mrow id="S2.E2.m1.74.74.74.42.42.45" xref="S2.E2.m1.76.76.2.cmml"><mo stretchy="false" id="S2.E2.m1.69.69.69.37.37.37" xref="S2.E2.m1.76.76.2.cmml">[</mo><mi id="S2.E2.m1.70.70.70.38.38.38" xref="S2.E2.m1.70.70.70.38.38.38.cmml">t</mi><mo id="S2.E2.m1.71.71.71.39.39.39" xref="S2.E2.m1.76.76.2.cmml">,</mo><mi id="S2.E2.m1.72.72.72.40.40.40" xref="S2.E2.m1.72.72.72.40.40.40.cmml">j</mi><mo stretchy="false" id="S2.E2.m1.73.73.73.41.41.41" xref="S2.E2.m1.76.76.2.cmml">]</mo></mrow><mo stretchy="false" id="S2.E2.m1.74.74.74.42.42.42" xref="S2.E2.m1.76.76.2.cmml">)</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S2.E2.m1.76b"><apply id="S2.E2.m1.76.76.2.cmml" xref="S2.E2.m1.74.74"><eq id="S2.E2.m1.13.13.13.13.13.13.cmml" xref="S2.E2.m1.13.13.13.13.13.13"></eq><apply id="S2.E2.m1.76.76.2.4.cmml" xref="S2.E2.m1.74.74"><times id="S2.E2.m1.76.76.2.4.1.cmml" xref="S2.E2.m1.74.74"></times><ci id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1">𝑡</ci><ci id="S2.E2.m1.2.2.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.2.2">𝑟</ci><ci id="S2.E2.m1.3.3.3.3.3.3.cmml" xref="S2.E2.m1.3.3.3.3.3.3">𝑒</ci><ci id="S2.E2.m1.4.4.4.4.4.4.cmml" xref="S2.E2.m1.4.4.4.4.4.4">𝑙</ci><ci id="S2.E2.m1.5.5.5.5.5.5.cmml" xref="S2.E2.m1.5.5.5.5.5.5">𝑙</ci><ci id="S2.E2.m1.6.6.6.6.6.6.cmml" xref="S2.E2.m1.6.6.6.6.6.6">𝑖</ci><ci id="S2.E2.m1.7.7.7.7.7.7.cmml" xref="S2.E2.m1.7.7.7.7.7.7">𝑠</ci><interval closure="closed" id="S2.E2.m1.76.76.2.4.9.cmml" xref="S2.E2.m1.74.74"><ci id="S2.E2.m1.9.9.9.9.9.9.cmml" xref="S2.E2.m1.9.9.9.9.9.9">𝑗</ci><ci id="S2.E2.m1.11.11.11.11.11.11.cmml" xref="S2.E2.m1.11.11.11.11.11.11">𝑡</ci></interval></apply><apply id="S2.E2.m1.76.76.2.2.cmml" xref="S2.E2.m1.74.74"><times id="S2.E2.m1.76.76.2.2.3.cmml" xref="S2.E2.m1.74.74"></times><ci id="S2.E2.m1.14.14.14.14.14.14.cmml" xref="S2.E2.m1.14.14.14.14.14.14">𝑚</ci><ci id="S2.E2.m1.15.15.15.15.15.15.cmml" xref="S2.E2.m1.15.15.15.15.15.15">𝑎</ci><ci id="S2.E2.m1.16.16.16.16.16.16.cmml" xref="S2.E2.m1.16.16.16.16.16.16">𝑥</ci><interval closure="open" id="S2.E2.m1.76.76.2.2.2.3.cmml" xref="S2.E2.m1.74.74"><apply id="S2.E2.m1.75.75.1.1.1.1.1.cmml" xref="S2.E2.m1.74.74"><times id="S2.E2.m1.75.75.1.1.1.1.1.3.cmml" xref="S2.E2.m1.74.74"></times><apply id="S2.E2.m1.75.75.1.1.1.1.1.1.cmml" xref="S2.E2.m1.74.74"><ci id="S2.E2.m1.32.32.32.32.32.32.cmml" xref="S2.E2.m1.32.32.32.32.32.32">⋅</ci><apply id="S2.E2.m1.75.75.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.74.74"><times id="S2.E2.m1.75.75.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.74.74"></times><ci id="S2.E2.m1.18.18.18.18.18.18.cmml" xref="S2.E2.m1.18.18.18.18.18.18">𝑡</ci><ci id="S2.E2.m1.19.19.19.19.19.19.cmml" xref="S2.E2.m1.19.19.19.19.19.19">𝑟</ci><ci id="S2.E2.m1.20.20.20.20.20.20.cmml" xref="S2.E2.m1.20.20.20.20.20.20">𝑒</ci><ci id="S2.E2.m1.21.21.21.21.21.21.cmml" xref="S2.E2.m1.21.21.21.21.21.21">𝑙</ci><ci id="S2.E2.m1.22.22.22.22.22.22.cmml" xref="S2.E2.m1.22.22.22.22.22.22">𝑙</ci><ci id="S2.E2.m1.23.23.23.23.23.23.cmml" xref="S2.E2.m1.23.23.23.23.23.23">𝑖</ci><ci id="S2.E2.m1.24.24.24.24.24.24.cmml" xref="S2.E2.m1.24.24.24.24.24.24">𝑠</ci><interval closure="closed" id="S2.E2.m1.75.75.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.74.74"><ci id="S2.E2.m1.26.26.26.26.26.26.cmml" xref="S2.E2.m1.26.26.26.26.26.26">𝑗</ci><apply id="S2.E2.m1.75.75.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.74.74"><minus id="S2.E2.m1.29.29.29.29.29.29.cmml" xref="S2.E2.m1.29.29.29.29.29.29"></minus><ci id="S2.E2.m1.28.28.28.28.28.28.cmml" xref="S2.E2.m1.28.28.28.28.28.28">𝑡</ci><cn type="integer" id="S2.E2.m1.30.30.30.30.30.30.cmml" xref="S2.E2.m1.30.30.30.30.30.30">1</cn></apply></interval></apply><ci id="S2.E2.m1.33.33.33.1.1.1a.cmml" xref="S2.E2.m1.33.33.33.1.1.1"><mtext class="ltx_mathvariant_bold" id="S2.E2.m1.33.33.33.1.1.1.cmml" xref="S2.E2.m1.33.33.33.1.1.1">max</mtext></ci></apply><interval closure="open" id="S2.E2.m1.75.75.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.74.74"><apply id="S2.E2.m1.75.75.1.1.1.1.1.2.1.1.cmml" xref="S2.E2.m1.74.74"><times id="S2.E2.m1.75.75.1.1.1.1.1.2.1.1.1.cmml" xref="S2.E2.m1.74.74"></times><ci id="S2.E2.m1.35.35.35.3.3.3.cmml" xref="S2.E2.m1.35.35.35.3.3.3">𝑝</ci><ci id="S2.E2.m1.36.36.36.4.4.4.cmml" xref="S2.E2.m1.36.36.36.4.4.4">𝑟</ci><ci id="S2.E2.m1.37.37.37.5.5.5.cmml" xref="S2.E2.m1.37.37.37.5.5.5">𝑜</ci><ci id="S2.E2.m1.38.38.38.6.6.6.cmml" xref="S2.E2.m1.38.38.38.6.6.6">𝑏</ci><interval closure="closed" id="S2.E2.m1.75.75.1.1.1.1.1.2.1.1.6.cmml" xref="S2.E2.m1.74.74"><ci id="S2.E2.m1.40.40.40.8.8.8.cmml" xref="S2.E2.m1.40.40.40.8.8.8">𝑡</ci><ci id="S2.E2.m1.42.42.42.10.10.10.cmml" xref="S2.E2.m1.42.42.42.10.10.10">italic-ϵ</ci></interval></apply><ci id="S2.E2.m1.45.45.45.13.13.13a.cmml" xref="S2.E2.m1.45.45.45.13.13.13"><mtext class="ltx_mathvariant_bold" id="S2.E2.m1.45.45.45.13.13.13.cmml" xref="S2.E2.m1.45.45.45.13.13.13">c</mtext></ci></interval></apply><apply id="S2.E2.m1.76.76.2.2.2.2.2.cmml" xref="S2.E2.m1.74.74"><times id="S2.E2.m1.76.76.2.2.2.2.2.3.cmml" xref="S2.E2.m1.74.74"></times><apply id="S2.E2.m1.76.76.2.2.2.2.2.2.cmml" xref="S2.E2.m1.74.74"><ci id="S2.E2.m1.64.64.64.32.32.32.cmml" xref="S2.E2.m1.64.64.64.32.32.32">⋅</ci><apply id="S2.E2.m1.76.76.2.2.2.2.2.2.2.cmml" xref="S2.E2.m1.74.74"><times id="S2.E2.m1.76.76.2.2.2.2.2.2.2.3.cmml" xref="S2.E2.m1.74.74"></times><ci id="S2.E2.m1.48.48.48.16.16.16.cmml" xref="S2.E2.m1.48.48.48.16.16.16">𝑡</ci><ci id="S2.E2.m1.49.49.49.17.17.17.cmml" xref="S2.E2.m1.49.49.49.17.17.17">𝑟</ci><ci id="S2.E2.m1.50.50.50.18.18.18.cmml" xref="S2.E2.m1.50.50.50.18.18.18">𝑒</ci><ci id="S2.E2.m1.51.51.51.19.19.19.cmml" xref="S2.E2.m1.51.51.51.19.19.19">𝑙</ci><ci id="S2.E2.m1.52.52.52.20.20.20.cmml" xref="S2.E2.m1.52.52.52.20.20.20">𝑙</ci><ci id="S2.E2.m1.53.53.53.21.21.21.cmml" xref="S2.E2.m1.53.53.53.21.21.21">𝑖</ci><ci id="S2.E2.m1.54.54.54.22.22.22.cmml" xref="S2.E2.m1.54.54.54.22.22.22">𝑠</ci><interval closure="closed" id="S2.E2.m1.76.76.2.2.2.2.2.2.2.2.3.cmml" xref="S2.E2.m1.74.74"><apply id="S2.E2.m1.76.76.2.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E2.m1.74.74"><minus id="S2.E2.m1.57.57.57.25.25.25.cmml" xref="S2.E2.m1.57.57.57.25.25.25"></minus><ci id="S2.E2.m1.56.56.56.24.24.24.cmml" xref="S2.E2.m1.56.56.56.24.24.24">𝑗</ci><cn type="integer" id="S2.E2.m1.58.58.58.26.26.26.cmml" xref="S2.E2.m1.58.58.58.26.26.26">1</cn></apply><apply id="S2.E2.m1.76.76.2.2.2.2.2.2.2.2.2.2.cmml" xref="S2.E2.m1.74.74"><minus id="S2.E2.m1.61.61.61.29.29.29.cmml" xref="S2.E2.m1.61.61.61.29.29.29"></minus><ci id="S2.E2.m1.60.60.60.28.28.28.cmml" xref="S2.E2.m1.60.60.60.28.28.28">𝑡</ci><cn type="integer" id="S2.E2.m1.62.62.62.30.30.30.cmml" xref="S2.E2.m1.62.62.62.30.30.30">1</cn></apply></interval></apply><ci id="S2.E2.m1.65.65.65.33.33.33.cmml" xref="S2.E2.m1.65.65.65.33.33.33">𝑝</ci></apply><ci id="S2.E2.m1.66.66.66.34.34.34.cmml" xref="S2.E2.m1.66.66.66.34.34.34">𝑟</ci><ci id="S2.E2.m1.67.67.67.35.35.35.cmml" xref="S2.E2.m1.67.67.67.35.35.35">𝑜</ci><ci id="S2.E2.m1.68.68.68.36.36.36.cmml" xref="S2.E2.m1.68.68.68.36.36.36">𝑏</ci><interval closure="closed" id="S2.E2.m1.76.76.2.2.2.2.2.7.cmml" xref="S2.E2.m1.74.74"><ci id="S2.E2.m1.70.70.70.38.38.38.cmml" xref="S2.E2.m1.70.70.70.38.38.38">𝑡</ci><ci id="S2.E2.m1.72.72.72.40.40.40.cmml" xref="S2.E2.m1.72.72.72.40.40.40">𝑗</ci></interval></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.76c">\begin{split}trellis[j,t]=max(trellis[j,t-1]\cdot\\
\textbf{max}(prob[t,\epsilon],\textbf{c}),trellis[j-1,t-1]\cdot prob[t,j])\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.SSS2.p4" class="ltx_para">
<p id="S2.SS2.SSS2.p4.1" class="ltx_p">As for the previous examples shown in <a href="#S2.F2" title="Figure 2 ‣ 2.2.2 Modified CTC Alignment ‣ 2.2 Forced alignment ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>, the modified CTC alignment correctly aligns the speech signals to the ASR prediction while capturing gaps that correspond to untranscribed disfluencies. However, it is also important to note that the modified alignment for, e.g., “that” has also become shorter. This is because this modification encourages the algorithm to keep words short since an alignment containing much silence gives a better score. Setting the probability <math id="S2.SS2.SSS2.p4.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S2.SS2.SSS2.p4.1.m1.1a"><mi id="S2.SS2.SSS2.p4.1.m1.1.1" xref="S2.SS2.SSS2.p4.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS2.p4.1.m1.1b"><ci id="S2.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S2.SS2.SSS2.p4.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS2.p4.1.m1.1c">c</annotation></semantics></math> too high may result in words being too short overall. Therefore, we experiment with different predefined probabilities to choose the value carefully.</p>
</div>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3 </span>Cross-attention Alignment</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p id="S2.SS2.SSS3.p1.1" class="ltx_p">Whisper is trained in such a way that there exists a correlation between the cross-attention weights and the audio input. Consequently, the cross-attention weights and the output transcript allow for the calculation of alignment to the input audio through Dynamic Time Warping (DTW) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. As implemented in the HuggingFace library <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://github.com/huggingface/transformers/blob/main/src/
<br class="ltx_break">transformers/models/whisper/generation_whisper.py</span></span></span>, token-level timesteps are calculated using the encoder-decoder cross-attentions and DTW to map each output token to a position in the input audio.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Alignment Comparison Metric</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.2" class="ltx_p">Comparing the alignment approaches requires an automatic metric, which is not available. This work proposes a metric that evaluates the alignment between the manual and automatic transcripts by considering the position and length of aligned words. The correctly transcribed words are extracted using Levenshtein Alignment, and we denote <math id="S2.SS3.p1.1.m1.2" class="ltx_Math" alttext="(s1,e1)" display="inline"><semantics id="S2.SS3.p1.1.m1.2a"><mrow id="S2.SS3.p1.1.m1.2.2.2" xref="S2.SS3.p1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S2.SS3.p1.1.m1.2.2.2.3" xref="S2.SS3.p1.1.m1.2.2.3.cmml">(</mo><mrow id="S2.SS3.p1.1.m1.1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.1.1.cmml"><mi id="S2.SS3.p1.1.m1.1.1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.1.m1.1.1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.1.1.1.cmml">​</mo><mn id="S2.SS3.p1.1.m1.1.1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S2.SS3.p1.1.m1.2.2.2.4" xref="S2.SS3.p1.1.m1.2.2.3.cmml">,</mo><mrow id="S2.SS3.p1.1.m1.2.2.2.2" xref="S2.SS3.p1.1.m1.2.2.2.2.cmml"><mi id="S2.SS3.p1.1.m1.2.2.2.2.2" xref="S2.SS3.p1.1.m1.2.2.2.2.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.1.m1.2.2.2.2.1" xref="S2.SS3.p1.1.m1.2.2.2.2.1.cmml">​</mo><mn id="S2.SS3.p1.1.m1.2.2.2.2.3" xref="S2.SS3.p1.1.m1.2.2.2.2.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.SS3.p1.1.m1.2.2.2.5" xref="S2.SS3.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.2b"><interval closure="open" id="S2.SS3.p1.1.m1.2.2.3.cmml" xref="S2.SS3.p1.1.m1.2.2.2"><apply id="S2.SS3.p1.1.m1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1"><times id="S2.SS3.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.1"></times><ci id="S2.SS3.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.2">𝑠</ci><cn type="integer" id="S2.SS3.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.3">1</cn></apply><apply id="S2.SS3.p1.1.m1.2.2.2.2.cmml" xref="S2.SS3.p1.1.m1.2.2.2.2"><times id="S2.SS3.p1.1.m1.2.2.2.2.1.cmml" xref="S2.SS3.p1.1.m1.2.2.2.2.1"></times><ci id="S2.SS3.p1.1.m1.2.2.2.2.2.cmml" xref="S2.SS3.p1.1.m1.2.2.2.2.2">𝑒</ci><cn type="integer" id="S2.SS3.p1.1.m1.2.2.2.2.3.cmml" xref="S2.SS3.p1.1.m1.2.2.2.2.3">1</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.2c">(s1,e1)</annotation></semantics></math> and <math id="S2.SS3.p1.2.m2.2" class="ltx_Math" alttext="(s2,e2)" display="inline"><semantics id="S2.SS3.p1.2.m2.2a"><mrow id="S2.SS3.p1.2.m2.2.2.2" xref="S2.SS3.p1.2.m2.2.2.3.cmml"><mo stretchy="false" id="S2.SS3.p1.2.m2.2.2.2.3" xref="S2.SS3.p1.2.m2.2.2.3.cmml">(</mo><mrow id="S2.SS3.p1.2.m2.1.1.1.1" xref="S2.SS3.p1.2.m2.1.1.1.1.cmml"><mi id="S2.SS3.p1.2.m2.1.1.1.1.2" xref="S2.SS3.p1.2.m2.1.1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.2.m2.1.1.1.1.1" xref="S2.SS3.p1.2.m2.1.1.1.1.1.cmml">​</mo><mn id="S2.SS3.p1.2.m2.1.1.1.1.3" xref="S2.SS3.p1.2.m2.1.1.1.1.3.cmml">2</mn></mrow><mo id="S2.SS3.p1.2.m2.2.2.2.4" xref="S2.SS3.p1.2.m2.2.2.3.cmml">,</mo><mrow id="S2.SS3.p1.2.m2.2.2.2.2" xref="S2.SS3.p1.2.m2.2.2.2.2.cmml"><mi id="S2.SS3.p1.2.m2.2.2.2.2.2" xref="S2.SS3.p1.2.m2.2.2.2.2.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.2.m2.2.2.2.2.1" xref="S2.SS3.p1.2.m2.2.2.2.2.1.cmml">​</mo><mn id="S2.SS3.p1.2.m2.2.2.2.2.3" xref="S2.SS3.p1.2.m2.2.2.2.2.3.cmml">2</mn></mrow><mo stretchy="false" id="S2.SS3.p1.2.m2.2.2.2.5" xref="S2.SS3.p1.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.2b"><interval closure="open" id="S2.SS3.p1.2.m2.2.2.3.cmml" xref="S2.SS3.p1.2.m2.2.2.2"><apply id="S2.SS3.p1.2.m2.1.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1.1.1"><times id="S2.SS3.p1.2.m2.1.1.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1.1.1.1"></times><ci id="S2.SS3.p1.2.m2.1.1.1.1.2.cmml" xref="S2.SS3.p1.2.m2.1.1.1.1.2">𝑠</ci><cn type="integer" id="S2.SS3.p1.2.m2.1.1.1.1.3.cmml" xref="S2.SS3.p1.2.m2.1.1.1.1.3">2</cn></apply><apply id="S2.SS3.p1.2.m2.2.2.2.2.cmml" xref="S2.SS3.p1.2.m2.2.2.2.2"><times id="S2.SS3.p1.2.m2.2.2.2.2.1.cmml" xref="S2.SS3.p1.2.m2.2.2.2.2.1"></times><ci id="S2.SS3.p1.2.m2.2.2.2.2.2.cmml" xref="S2.SS3.p1.2.m2.2.2.2.2.2">𝑒</ci><cn type="integer" id="S2.SS3.p1.2.m2.2.2.2.2.3.cmml" xref="S2.SS3.p1.2.m2.2.2.2.2.3">2</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.2c">(s2,e2)</annotation></semantics></math> as the manual timing annotation and automatically aligned timing information.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.3" class="ltx_p">After forced alignment, timing information of the same word from manual annotation <math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="A1" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><mrow id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><mi id="S2.SS3.p2.1.m1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.1.m1.1.1.1" xref="S2.SS3.p2.1.m1.1.1.1.cmml">​</mo><mn id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><times id="S2.SS3.p2.1.m1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1.1"></times><ci id="S2.SS3.p2.1.m1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2">𝐴</ci><cn type="integer" id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">A1</annotation></semantics></math> and automated transcription <math id="S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="A2" display="inline"><semantics id="S2.SS3.p2.2.m2.1a"><mrow id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml"><mi id="S2.SS3.p2.2.m2.1.1.2" xref="S2.SS3.p2.2.m2.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.2.m2.1.1.1" xref="S2.SS3.p2.2.m2.1.1.1.cmml">​</mo><mn id="S2.SS3.p2.2.m2.1.1.3" xref="S2.SS3.p2.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><apply id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1"><times id="S2.SS3.p2.2.m2.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1"></times><ci id="S2.SS3.p2.2.m2.1.1.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2">𝐴</ci><cn type="integer" id="S2.SS3.p2.2.m2.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">A2</annotation></semantics></math>. For each pair of words <math id="S2.SS3.p2.3.m3.2" class="ltx_Math" alttext="(w1,w2)" display="inline"><semantics id="S2.SS3.p2.3.m3.2a"><mrow id="S2.SS3.p2.3.m3.2.2.2" xref="S2.SS3.p2.3.m3.2.2.3.cmml"><mo stretchy="false" id="S2.SS3.p2.3.m3.2.2.2.3" xref="S2.SS3.p2.3.m3.2.2.3.cmml">(</mo><mrow id="S2.SS3.p2.3.m3.1.1.1.1" xref="S2.SS3.p2.3.m3.1.1.1.1.cmml"><mi id="S2.SS3.p2.3.m3.1.1.1.1.2" xref="S2.SS3.p2.3.m3.1.1.1.1.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.3.m3.1.1.1.1.1" xref="S2.SS3.p2.3.m3.1.1.1.1.1.cmml">​</mo><mn id="S2.SS3.p2.3.m3.1.1.1.1.3" xref="S2.SS3.p2.3.m3.1.1.1.1.3.cmml">1</mn></mrow><mo id="S2.SS3.p2.3.m3.2.2.2.4" xref="S2.SS3.p2.3.m3.2.2.3.cmml">,</mo><mrow id="S2.SS3.p2.3.m3.2.2.2.2" xref="S2.SS3.p2.3.m3.2.2.2.2.cmml"><mi id="S2.SS3.p2.3.m3.2.2.2.2.2" xref="S2.SS3.p2.3.m3.2.2.2.2.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p2.3.m3.2.2.2.2.1" xref="S2.SS3.p2.3.m3.2.2.2.2.1.cmml">​</mo><mn id="S2.SS3.p2.3.m3.2.2.2.2.3" xref="S2.SS3.p2.3.m3.2.2.2.2.3.cmml">2</mn></mrow><mo stretchy="false" id="S2.SS3.p2.3.m3.2.2.2.5" xref="S2.SS3.p2.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.2b"><interval closure="open" id="S2.SS3.p2.3.m3.2.2.3.cmml" xref="S2.SS3.p2.3.m3.2.2.2"><apply id="S2.SS3.p2.3.m3.1.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1"><times id="S2.SS3.p2.3.m3.1.1.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.1"></times><ci id="S2.SS3.p2.3.m3.1.1.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.2">𝑤</ci><cn type="integer" id="S2.SS3.p2.3.m3.1.1.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.1.1.3">1</cn></apply><apply id="S2.SS3.p2.3.m3.2.2.2.2.cmml" xref="S2.SS3.p2.3.m3.2.2.2.2"><times id="S2.SS3.p2.3.m3.2.2.2.2.1.cmml" xref="S2.SS3.p2.3.m3.2.2.2.2.1"></times><ci id="S2.SS3.p2.3.m3.2.2.2.2.2.cmml" xref="S2.SS3.p2.3.m3.2.2.2.2.2">𝑤</ci><cn type="integer" id="S2.SS3.p2.3.m3.2.2.2.2.3.cmml" xref="S2.SS3.p2.3.m3.2.2.2.2.3">2</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.2c">(w1,w2)</annotation></semantics></math>, the length, position and combined scores are calculated with Equations <a href="#S2.E3" title="In 2.3 Alignment Comparison Metric ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S2.E4" title="In 2.3 Alignment Comparison Metric ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#S2.E5" title="In 2.3 Alignment Comparison Metric ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, respectively:</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.3" class="ltx_Math" alttext="m_{p}(w_{1},w_{2})=\frac{1}{\mid\frac{p_{1}-p_{2}}{l_{1}}\mid+1}" display="block"><semantics id="S2.E3.m1.3a"><mrow id="S2.E3.m1.3.3" xref="S2.E3.m1.3.3.cmml"><mrow id="S2.E3.m1.3.3.2" xref="S2.E3.m1.3.3.2.cmml"><msub id="S2.E3.m1.3.3.2.4" xref="S2.E3.m1.3.3.2.4.cmml"><mi id="S2.E3.m1.3.3.2.4.2" xref="S2.E3.m1.3.3.2.4.2.cmml">m</mi><mi id="S2.E3.m1.3.3.2.4.3" xref="S2.E3.m1.3.3.2.4.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.3.3.2.3" xref="S2.E3.m1.3.3.2.3.cmml">​</mo><mrow id="S2.E3.m1.3.3.2.2.2" xref="S2.E3.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.2.2.2.3" xref="S2.E3.m1.3.3.2.2.3.cmml">(</mo><msub id="S2.E3.m1.2.2.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.2.cmml">w</mi><mn id="S2.E3.m1.2.2.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E3.m1.3.3.2.2.2.4" xref="S2.E3.m1.3.3.2.2.3.cmml">,</mo><msub id="S2.E3.m1.3.3.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.cmml"><mi id="S2.E3.m1.3.3.2.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.2.cmml">w</mi><mn id="S2.E3.m1.3.3.2.2.2.2.3" xref="S2.E3.m1.3.3.2.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S2.E3.m1.3.3.2.2.2.5" xref="S2.E3.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.3" xref="S2.E3.m1.3.3.3.cmml">=</mo><mfrac id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml"><mn id="S2.E3.m1.1.1.3" xref="S2.E3.m1.1.1.3.cmml">1</mn><mrow id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.3.1.cmml"><mo fence="true" rspace="0em" id="S2.E3.m1.1.1.1.3.2.1" xref="S2.E3.m1.1.1.1.3.1.1.cmml">∣</mo><mfrac id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.2.cmml"><msub id="S2.E3.m1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.2.2.cmml"><mi id="S2.E3.m1.1.1.1.1.2.2.2" xref="S2.E3.m1.1.1.1.1.2.2.2.cmml">p</mi><mn id="S2.E3.m1.1.1.1.1.2.2.3" xref="S2.E3.m1.1.1.1.1.2.2.3.cmml">1</mn></msub><mo id="S2.E3.m1.1.1.1.1.2.1" xref="S2.E3.m1.1.1.1.1.2.1.cmml">−</mo><msub id="S2.E3.m1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.2.3.cmml"><mi id="S2.E3.m1.1.1.1.1.2.3.2" xref="S2.E3.m1.1.1.1.1.2.3.2.cmml">p</mi><mn id="S2.E3.m1.1.1.1.1.2.3.3" xref="S2.E3.m1.1.1.1.1.2.3.3.cmml">2</mn></msub></mrow><msub id="S2.E3.m1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.3.2.cmml">l</mi><mn id="S2.E3.m1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.3.3.cmml">1</mn></msub></mfrac><mo fence="true" lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.3.2.2" xref="S2.E3.m1.1.1.1.3.1.1.cmml">∣</mo></mrow><mo id="S2.E3.m1.1.1.1.2" xref="S2.E3.m1.1.1.1.2.cmml">+</mo><mn id="S2.E3.m1.1.1.1.4" xref="S2.E3.m1.1.1.1.4.cmml">1</mn></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.3b"><apply id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3"><eq id="S2.E3.m1.3.3.3.cmml" xref="S2.E3.m1.3.3.3"></eq><apply id="S2.E3.m1.3.3.2.cmml" xref="S2.E3.m1.3.3.2"><times id="S2.E3.m1.3.3.2.3.cmml" xref="S2.E3.m1.3.3.2.3"></times><apply id="S2.E3.m1.3.3.2.4.cmml" xref="S2.E3.m1.3.3.2.4"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.2.4.1.cmml" xref="S2.E3.m1.3.3.2.4">subscript</csymbol><ci id="S2.E3.m1.3.3.2.4.2.cmml" xref="S2.E3.m1.3.3.2.4.2">𝑚</ci><ci id="S2.E3.m1.3.3.2.4.3.cmml" xref="S2.E3.m1.3.3.2.4.3">𝑝</ci></apply><interval closure="open" id="S2.E3.m1.3.3.2.2.3.cmml" xref="S2.E3.m1.3.3.2.2.2"><apply id="S2.E3.m1.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.2.2.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.2">𝑤</ci><cn type="integer" id="S2.E3.m1.2.2.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.3">1</cn></apply><apply id="S2.E3.m1.3.3.2.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.2.2.2.2.1.cmml" xref="S2.E3.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S2.E3.m1.3.3.2.2.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2.2">𝑤</ci><cn type="integer" id="S2.E3.m1.3.3.2.2.2.2.3.cmml" xref="S2.E3.m1.3.3.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1"><divide id="S2.E3.m1.1.1.2.cmml" xref="S2.E3.m1.1.1"></divide><cn type="integer" id="S2.E3.m1.1.1.3.cmml" xref="S2.E3.m1.1.1.3">1</cn><apply id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"><plus id="S2.E3.m1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.2"></plus><apply id="S2.E3.m1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.3.2"><csymbol cd="latexml" id="S2.E3.m1.1.1.1.3.1.1.cmml" xref="S2.E3.m1.1.1.1.3.2.1">delimited-∣∣</csymbol><apply id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1"><divide id="S2.E3.m1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1"></divide><apply id="S2.E3.m1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.2"><minus id="S2.E3.m1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2.1"></minus><apply id="S2.E3.m1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.2">𝑝</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.2.2.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.3">1</cn></apply><apply id="S2.E3.m1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.3.1.cmml" xref="S2.E3.m1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.2.3.2.cmml" xref="S2.E3.m1.1.1.1.1.2.3.2">𝑝</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.2.3.3.cmml" xref="S2.E3.m1.1.1.1.1.2.3.3">2</cn></apply></apply><apply id="S2.E3.m1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.3.2">𝑙</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.3.3">1</cn></apply></apply></apply><cn type="integer" id="S2.E3.m1.1.1.1.4.cmml" xref="S2.E3.m1.1.1.1.4">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.3c">m_{p}(w_{1},w_{2})=\frac{1}{\mid\frac{p_{1}-p_{2}}{l_{1}}\mid+1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.3" class="ltx_Math" alttext="m_{l}(w_{1},w_{2})=\frac{1}{\mid\frac{l_{1}-l_{2}}{l_{1}}\mid+1}" display="block"><semantics id="S2.E4.m1.3a"><mrow id="S2.E4.m1.3.3" xref="S2.E4.m1.3.3.cmml"><mrow id="S2.E4.m1.3.3.2" xref="S2.E4.m1.3.3.2.cmml"><msub id="S2.E4.m1.3.3.2.4" xref="S2.E4.m1.3.3.2.4.cmml"><mi id="S2.E4.m1.3.3.2.4.2" xref="S2.E4.m1.3.3.2.4.2.cmml">m</mi><mi id="S2.E4.m1.3.3.2.4.3" xref="S2.E4.m1.3.3.2.4.3.cmml">l</mi></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.3.3.2.3" xref="S2.E4.m1.3.3.2.3.cmml">​</mo><mrow id="S2.E4.m1.3.3.2.2.2" xref="S2.E4.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="S2.E4.m1.3.3.2.2.2.3" xref="S2.E4.m1.3.3.2.2.3.cmml">(</mo><msub id="S2.E4.m1.2.2.1.1.1.1" xref="S2.E4.m1.2.2.1.1.1.1.cmml"><mi id="S2.E4.m1.2.2.1.1.1.1.2" xref="S2.E4.m1.2.2.1.1.1.1.2.cmml">w</mi><mn id="S2.E4.m1.2.2.1.1.1.1.3" xref="S2.E4.m1.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E4.m1.3.3.2.2.2.4" xref="S2.E4.m1.3.3.2.2.3.cmml">,</mo><msub id="S2.E4.m1.3.3.2.2.2.2" xref="S2.E4.m1.3.3.2.2.2.2.cmml"><mi id="S2.E4.m1.3.3.2.2.2.2.2" xref="S2.E4.m1.3.3.2.2.2.2.2.cmml">w</mi><mn id="S2.E4.m1.3.3.2.2.2.2.3" xref="S2.E4.m1.3.3.2.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S2.E4.m1.3.3.2.2.2.5" xref="S2.E4.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.3.3.3" xref="S2.E4.m1.3.3.3.cmml">=</mo><mfrac id="S2.E4.m1.1.1" xref="S2.E4.m1.1.1.cmml"><mn id="S2.E4.m1.1.1.3" xref="S2.E4.m1.1.1.3.cmml">1</mn><mrow id="S2.E4.m1.1.1.1" xref="S2.E4.m1.1.1.1.cmml"><mrow id="S2.E4.m1.1.1.1.3.2" xref="S2.E4.m1.1.1.1.3.1.cmml"><mo fence="true" rspace="0em" id="S2.E4.m1.1.1.1.3.2.1" xref="S2.E4.m1.1.1.1.3.1.1.cmml">∣</mo><mfrac id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml"><mrow id="S2.E4.m1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.2.cmml"><msub id="S2.E4.m1.1.1.1.1.2.2" xref="S2.E4.m1.1.1.1.1.2.2.cmml"><mi id="S2.E4.m1.1.1.1.1.2.2.2" xref="S2.E4.m1.1.1.1.1.2.2.2.cmml">l</mi><mn id="S2.E4.m1.1.1.1.1.2.2.3" xref="S2.E4.m1.1.1.1.1.2.2.3.cmml">1</mn></msub><mo id="S2.E4.m1.1.1.1.1.2.1" xref="S2.E4.m1.1.1.1.1.2.1.cmml">−</mo><msub id="S2.E4.m1.1.1.1.1.2.3" xref="S2.E4.m1.1.1.1.1.2.3.cmml"><mi id="S2.E4.m1.1.1.1.1.2.3.2" xref="S2.E4.m1.1.1.1.1.2.3.2.cmml">l</mi><mn id="S2.E4.m1.1.1.1.1.2.3.3" xref="S2.E4.m1.1.1.1.1.2.3.3.cmml">2</mn></msub></mrow><msub id="S2.E4.m1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.1.1.1.1.3.2" xref="S2.E4.m1.1.1.1.1.3.2.cmml">l</mi><mn id="S2.E4.m1.1.1.1.1.3.3" xref="S2.E4.m1.1.1.1.1.3.3.cmml">1</mn></msub></mfrac><mo fence="true" lspace="0em" rspace="0em" id="S2.E4.m1.1.1.1.3.2.2" xref="S2.E4.m1.1.1.1.3.1.1.cmml">∣</mo></mrow><mo id="S2.E4.m1.1.1.1.2" xref="S2.E4.m1.1.1.1.2.cmml">+</mo><mn id="S2.E4.m1.1.1.1.4" xref="S2.E4.m1.1.1.1.4.cmml">1</mn></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.3b"><apply id="S2.E4.m1.3.3.cmml" xref="S2.E4.m1.3.3"><eq id="S2.E4.m1.3.3.3.cmml" xref="S2.E4.m1.3.3.3"></eq><apply id="S2.E4.m1.3.3.2.cmml" xref="S2.E4.m1.3.3.2"><times id="S2.E4.m1.3.3.2.3.cmml" xref="S2.E4.m1.3.3.2.3"></times><apply id="S2.E4.m1.3.3.2.4.cmml" xref="S2.E4.m1.3.3.2.4"><csymbol cd="ambiguous" id="S2.E4.m1.3.3.2.4.1.cmml" xref="S2.E4.m1.3.3.2.4">subscript</csymbol><ci id="S2.E4.m1.3.3.2.4.2.cmml" xref="S2.E4.m1.3.3.2.4.2">𝑚</ci><ci id="S2.E4.m1.3.3.2.4.3.cmml" xref="S2.E4.m1.3.3.2.4.3">𝑙</ci></apply><interval closure="open" id="S2.E4.m1.3.3.2.2.3.cmml" xref="S2.E4.m1.3.3.2.2.2"><apply id="S2.E4.m1.2.2.1.1.1.1.cmml" xref="S2.E4.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.1.1.1.1.1.cmml" xref="S2.E4.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S2.E4.m1.2.2.1.1.1.1.2.cmml" xref="S2.E4.m1.2.2.1.1.1.1.2">𝑤</ci><cn type="integer" id="S2.E4.m1.2.2.1.1.1.1.3.cmml" xref="S2.E4.m1.2.2.1.1.1.1.3">1</cn></apply><apply id="S2.E4.m1.3.3.2.2.2.2.cmml" xref="S2.E4.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.3.3.2.2.2.2.1.cmml" xref="S2.E4.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S2.E4.m1.3.3.2.2.2.2.2.cmml" xref="S2.E4.m1.3.3.2.2.2.2.2">𝑤</ci><cn type="integer" id="S2.E4.m1.3.3.2.2.2.2.3.cmml" xref="S2.E4.m1.3.3.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S2.E4.m1.1.1.cmml" xref="S2.E4.m1.1.1"><divide id="S2.E4.m1.1.1.2.cmml" xref="S2.E4.m1.1.1"></divide><cn type="integer" id="S2.E4.m1.1.1.3.cmml" xref="S2.E4.m1.1.1.3">1</cn><apply id="S2.E4.m1.1.1.1.cmml" xref="S2.E4.m1.1.1.1"><plus id="S2.E4.m1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.2"></plus><apply id="S2.E4.m1.1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.1.3.2"><csymbol cd="latexml" id="S2.E4.m1.1.1.1.3.1.1.cmml" xref="S2.E4.m1.1.1.1.3.2.1">delimited-∣∣</csymbol><apply id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1"><divide id="S2.E4.m1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1"></divide><apply id="S2.E4.m1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.2"><minus id="S2.E4.m1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.1.1.1.1.2.1"></minus><apply id="S2.E4.m1.1.1.1.1.2.2.cmml" xref="S2.E4.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.2.2.1.cmml" xref="S2.E4.m1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.2.2.2.cmml" xref="S2.E4.m1.1.1.1.1.2.2.2">𝑙</ci><cn type="integer" id="S2.E4.m1.1.1.1.1.2.2.3.cmml" xref="S2.E4.m1.1.1.1.1.2.2.3">1</cn></apply><apply id="S2.E4.m1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.2.3.1.cmml" xref="S2.E4.m1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.2.3.2.cmml" xref="S2.E4.m1.1.1.1.1.2.3.2">𝑙</ci><cn type="integer" id="S2.E4.m1.1.1.1.1.2.3.3.cmml" xref="S2.E4.m1.1.1.1.1.2.3.3">2</cn></apply></apply><apply id="S2.E4.m1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.1.1.1.1.3.2">𝑙</ci><cn type="integer" id="S2.E4.m1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.1.1.1.1.3.3">1</cn></apply></apply></apply><cn type="integer" id="S2.E4.m1.1.1.1.4.cmml" xref="S2.E4.m1.1.1.1.4">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.3c">m_{l}(w_{1},w_{2})=\frac{1}{\mid\frac{l_{1}-l_{2}}{l_{1}}\mid+1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<table id="S2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E5.m1.4" class="ltx_Math" alttext="m(w_{1},w_{2})=\frac{1}{\mid\frac{p_{1}-p_{2}}{l_{1}}\mid+1}\cdot\frac{1}{\mid\frac{l_{1}-l_{2}}{l_{1}}\mid+1}" display="block"><semantics id="S2.E5.m1.4a"><mrow id="S2.E5.m1.4.4" xref="S2.E5.m1.4.4.cmml"><mrow id="S2.E5.m1.4.4.2" xref="S2.E5.m1.4.4.2.cmml"><mi id="S2.E5.m1.4.4.2.4" xref="S2.E5.m1.4.4.2.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.4.4.2.3" xref="S2.E5.m1.4.4.2.3.cmml">​</mo><mrow id="S2.E5.m1.4.4.2.2.2" xref="S2.E5.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="S2.E5.m1.4.4.2.2.2.3" xref="S2.E5.m1.4.4.2.2.3.cmml">(</mo><msub id="S2.E5.m1.3.3.1.1.1.1" xref="S2.E5.m1.3.3.1.1.1.1.cmml"><mi id="S2.E5.m1.3.3.1.1.1.1.2" xref="S2.E5.m1.3.3.1.1.1.1.2.cmml">w</mi><mn id="S2.E5.m1.3.3.1.1.1.1.3" xref="S2.E5.m1.3.3.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.E5.m1.4.4.2.2.2.4" xref="S2.E5.m1.4.4.2.2.3.cmml">,</mo><msub id="S2.E5.m1.4.4.2.2.2.2" xref="S2.E5.m1.4.4.2.2.2.2.cmml"><mi id="S2.E5.m1.4.4.2.2.2.2.2" xref="S2.E5.m1.4.4.2.2.2.2.2.cmml">w</mi><mn id="S2.E5.m1.4.4.2.2.2.2.3" xref="S2.E5.m1.4.4.2.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S2.E5.m1.4.4.2.2.2.5" xref="S2.E5.m1.4.4.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E5.m1.4.4.3" xref="S2.E5.m1.4.4.3.cmml">=</mo><mrow id="S2.E5.m1.4.4.4" xref="S2.E5.m1.4.4.4.cmml"><mfrac id="S2.E5.m1.1.1" xref="S2.E5.m1.1.1.cmml"><mn id="S2.E5.m1.1.1.3" xref="S2.E5.m1.1.1.3.cmml">1</mn><mrow id="S2.E5.m1.1.1.1" xref="S2.E5.m1.1.1.1.cmml"><mrow id="S2.E5.m1.1.1.1.3.2" xref="S2.E5.m1.1.1.1.3.1.cmml"><mo fence="true" rspace="0em" id="S2.E5.m1.1.1.1.3.2.1" xref="S2.E5.m1.1.1.1.3.1.1.cmml">∣</mo><mfrac id="S2.E5.m1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.cmml"><mrow id="S2.E5.m1.1.1.1.1.2" xref="S2.E5.m1.1.1.1.1.2.cmml"><msub id="S2.E5.m1.1.1.1.1.2.2" xref="S2.E5.m1.1.1.1.1.2.2.cmml"><mi id="S2.E5.m1.1.1.1.1.2.2.2" xref="S2.E5.m1.1.1.1.1.2.2.2.cmml">p</mi><mn id="S2.E5.m1.1.1.1.1.2.2.3" xref="S2.E5.m1.1.1.1.1.2.2.3.cmml">1</mn></msub><mo id="S2.E5.m1.1.1.1.1.2.1" xref="S2.E5.m1.1.1.1.1.2.1.cmml">−</mo><msub id="S2.E5.m1.1.1.1.1.2.3" xref="S2.E5.m1.1.1.1.1.2.3.cmml"><mi id="S2.E5.m1.1.1.1.1.2.3.2" xref="S2.E5.m1.1.1.1.1.2.3.2.cmml">p</mi><mn id="S2.E5.m1.1.1.1.1.2.3.3" xref="S2.E5.m1.1.1.1.1.2.3.3.cmml">2</mn></msub></mrow><msub id="S2.E5.m1.1.1.1.1.3" xref="S2.E5.m1.1.1.1.1.3.cmml"><mi id="S2.E5.m1.1.1.1.1.3.2" xref="S2.E5.m1.1.1.1.1.3.2.cmml">l</mi><mn id="S2.E5.m1.1.1.1.1.3.3" xref="S2.E5.m1.1.1.1.1.3.3.cmml">1</mn></msub></mfrac><mo fence="true" lspace="0em" rspace="0em" id="S2.E5.m1.1.1.1.3.2.2" xref="S2.E5.m1.1.1.1.3.1.1.cmml">∣</mo></mrow><mo id="S2.E5.m1.1.1.1.2" xref="S2.E5.m1.1.1.1.2.cmml">+</mo><mn id="S2.E5.m1.1.1.1.4" xref="S2.E5.m1.1.1.1.4.cmml">1</mn></mrow></mfrac><mo lspace="0.222em" rspace="0.222em" id="S2.E5.m1.4.4.4.1" xref="S2.E5.m1.4.4.4.1.cmml">⋅</mo><mfrac id="S2.E5.m1.2.2" xref="S2.E5.m1.2.2.cmml"><mn id="S2.E5.m1.2.2.3" xref="S2.E5.m1.2.2.3.cmml">1</mn><mrow id="S2.E5.m1.2.2.1" xref="S2.E5.m1.2.2.1.cmml"><mrow id="S2.E5.m1.2.2.1.3.2" xref="S2.E5.m1.2.2.1.3.1.cmml"><mo fence="true" rspace="0em" id="S2.E5.m1.2.2.1.3.2.1" xref="S2.E5.m1.2.2.1.3.1.1.cmml">∣</mo><mfrac id="S2.E5.m1.2.2.1.1" xref="S2.E5.m1.2.2.1.1.cmml"><mrow id="S2.E5.m1.2.2.1.1.2" xref="S2.E5.m1.2.2.1.1.2.cmml"><msub id="S2.E5.m1.2.2.1.1.2.2" xref="S2.E5.m1.2.2.1.1.2.2.cmml"><mi id="S2.E5.m1.2.2.1.1.2.2.2" xref="S2.E5.m1.2.2.1.1.2.2.2.cmml">l</mi><mn id="S2.E5.m1.2.2.1.1.2.2.3" xref="S2.E5.m1.2.2.1.1.2.2.3.cmml">1</mn></msub><mo id="S2.E5.m1.2.2.1.1.2.1" xref="S2.E5.m1.2.2.1.1.2.1.cmml">−</mo><msub id="S2.E5.m1.2.2.1.1.2.3" xref="S2.E5.m1.2.2.1.1.2.3.cmml"><mi id="S2.E5.m1.2.2.1.1.2.3.2" xref="S2.E5.m1.2.2.1.1.2.3.2.cmml">l</mi><mn id="S2.E5.m1.2.2.1.1.2.3.3" xref="S2.E5.m1.2.2.1.1.2.3.3.cmml">2</mn></msub></mrow><msub id="S2.E5.m1.2.2.1.1.3" xref="S2.E5.m1.2.2.1.1.3.cmml"><mi id="S2.E5.m1.2.2.1.1.3.2" xref="S2.E5.m1.2.2.1.1.3.2.cmml">l</mi><mn id="S2.E5.m1.2.2.1.1.3.3" xref="S2.E5.m1.2.2.1.1.3.3.cmml">1</mn></msub></mfrac><mo fence="true" lspace="0em" rspace="0em" id="S2.E5.m1.2.2.1.3.2.2" xref="S2.E5.m1.2.2.1.3.1.1.cmml">∣</mo></mrow><mo id="S2.E5.m1.2.2.1.2" xref="S2.E5.m1.2.2.1.2.cmml">+</mo><mn id="S2.E5.m1.2.2.1.4" xref="S2.E5.m1.2.2.1.4.cmml">1</mn></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.4b"><apply id="S2.E5.m1.4.4.cmml" xref="S2.E5.m1.4.4"><eq id="S2.E5.m1.4.4.3.cmml" xref="S2.E5.m1.4.4.3"></eq><apply id="S2.E5.m1.4.4.2.cmml" xref="S2.E5.m1.4.4.2"><times id="S2.E5.m1.4.4.2.3.cmml" xref="S2.E5.m1.4.4.2.3"></times><ci id="S2.E5.m1.4.4.2.4.cmml" xref="S2.E5.m1.4.4.2.4">𝑚</ci><interval closure="open" id="S2.E5.m1.4.4.2.2.3.cmml" xref="S2.E5.m1.4.4.2.2.2"><apply id="S2.E5.m1.3.3.1.1.1.1.cmml" xref="S2.E5.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.3.3.1.1.1.1.1.cmml" xref="S2.E5.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S2.E5.m1.3.3.1.1.1.1.2.cmml" xref="S2.E5.m1.3.3.1.1.1.1.2">𝑤</ci><cn type="integer" id="S2.E5.m1.3.3.1.1.1.1.3.cmml" xref="S2.E5.m1.3.3.1.1.1.1.3">1</cn></apply><apply id="S2.E5.m1.4.4.2.2.2.2.cmml" xref="S2.E5.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.E5.m1.4.4.2.2.2.2.1.cmml" xref="S2.E5.m1.4.4.2.2.2.2">subscript</csymbol><ci id="S2.E5.m1.4.4.2.2.2.2.2.cmml" xref="S2.E5.m1.4.4.2.2.2.2.2">𝑤</ci><cn type="integer" id="S2.E5.m1.4.4.2.2.2.2.3.cmml" xref="S2.E5.m1.4.4.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S2.E5.m1.4.4.4.cmml" xref="S2.E5.m1.4.4.4"><ci id="S2.E5.m1.4.4.4.1.cmml" xref="S2.E5.m1.4.4.4.1">⋅</ci><apply id="S2.E5.m1.1.1.cmml" xref="S2.E5.m1.1.1"><divide id="S2.E5.m1.1.1.2.cmml" xref="S2.E5.m1.1.1"></divide><cn type="integer" id="S2.E5.m1.1.1.3.cmml" xref="S2.E5.m1.1.1.3">1</cn><apply id="S2.E5.m1.1.1.1.cmml" xref="S2.E5.m1.1.1.1"><plus id="S2.E5.m1.1.1.1.2.cmml" xref="S2.E5.m1.1.1.1.2"></plus><apply id="S2.E5.m1.1.1.1.3.1.cmml" xref="S2.E5.m1.1.1.1.3.2"><csymbol cd="latexml" id="S2.E5.m1.1.1.1.3.1.1.cmml" xref="S2.E5.m1.1.1.1.3.2.1">delimited-∣∣</csymbol><apply id="S2.E5.m1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1"><divide id="S2.E5.m1.1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1"></divide><apply id="S2.E5.m1.1.1.1.1.2.cmml" xref="S2.E5.m1.1.1.1.1.2"><minus id="S2.E5.m1.1.1.1.1.2.1.cmml" xref="S2.E5.m1.1.1.1.1.2.1"></minus><apply id="S2.E5.m1.1.1.1.1.2.2.cmml" xref="S2.E5.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.2.2.1.cmml" xref="S2.E5.m1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.E5.m1.1.1.1.1.2.2.2.cmml" xref="S2.E5.m1.1.1.1.1.2.2.2">𝑝</ci><cn type="integer" id="S2.E5.m1.1.1.1.1.2.2.3.cmml" xref="S2.E5.m1.1.1.1.1.2.2.3">1</cn></apply><apply id="S2.E5.m1.1.1.1.1.2.3.cmml" xref="S2.E5.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.2.3.1.cmml" xref="S2.E5.m1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E5.m1.1.1.1.1.2.3.2.cmml" xref="S2.E5.m1.1.1.1.1.2.3.2">𝑝</ci><cn type="integer" id="S2.E5.m1.1.1.1.1.2.3.3.cmml" xref="S2.E5.m1.1.1.1.1.2.3.3">2</cn></apply></apply><apply id="S2.E5.m1.1.1.1.1.3.cmml" xref="S2.E5.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.3.1.cmml" xref="S2.E5.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E5.m1.1.1.1.1.3.2.cmml" xref="S2.E5.m1.1.1.1.1.3.2">𝑙</ci><cn type="integer" id="S2.E5.m1.1.1.1.1.3.3.cmml" xref="S2.E5.m1.1.1.1.1.3.3">1</cn></apply></apply></apply><cn type="integer" id="S2.E5.m1.1.1.1.4.cmml" xref="S2.E5.m1.1.1.1.4">1</cn></apply></apply><apply id="S2.E5.m1.2.2.cmml" xref="S2.E5.m1.2.2"><divide id="S2.E5.m1.2.2.2.cmml" xref="S2.E5.m1.2.2"></divide><cn type="integer" id="S2.E5.m1.2.2.3.cmml" xref="S2.E5.m1.2.2.3">1</cn><apply id="S2.E5.m1.2.2.1.cmml" xref="S2.E5.m1.2.2.1"><plus id="S2.E5.m1.2.2.1.2.cmml" xref="S2.E5.m1.2.2.1.2"></plus><apply id="S2.E5.m1.2.2.1.3.1.cmml" xref="S2.E5.m1.2.2.1.3.2"><csymbol cd="latexml" id="S2.E5.m1.2.2.1.3.1.1.cmml" xref="S2.E5.m1.2.2.1.3.2.1">delimited-∣∣</csymbol><apply id="S2.E5.m1.2.2.1.1.cmml" xref="S2.E5.m1.2.2.1.1"><divide id="S2.E5.m1.2.2.1.1.1.cmml" xref="S2.E5.m1.2.2.1.1"></divide><apply id="S2.E5.m1.2.2.1.1.2.cmml" xref="S2.E5.m1.2.2.1.1.2"><minus id="S2.E5.m1.2.2.1.1.2.1.cmml" xref="S2.E5.m1.2.2.1.1.2.1"></minus><apply id="S2.E5.m1.2.2.1.1.2.2.cmml" xref="S2.E5.m1.2.2.1.1.2.2"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.2.2.1.cmml" xref="S2.E5.m1.2.2.1.1.2.2">subscript</csymbol><ci id="S2.E5.m1.2.2.1.1.2.2.2.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2">𝑙</ci><cn type="integer" id="S2.E5.m1.2.2.1.1.2.2.3.cmml" xref="S2.E5.m1.2.2.1.1.2.2.3">1</cn></apply><apply id="S2.E5.m1.2.2.1.1.2.3.cmml" xref="S2.E5.m1.2.2.1.1.2.3"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.2.3.1.cmml" xref="S2.E5.m1.2.2.1.1.2.3">subscript</csymbol><ci id="S2.E5.m1.2.2.1.1.2.3.2.cmml" xref="S2.E5.m1.2.2.1.1.2.3.2">𝑙</ci><cn type="integer" id="S2.E5.m1.2.2.1.1.2.3.3.cmml" xref="S2.E5.m1.2.2.1.1.2.3.3">2</cn></apply></apply><apply id="S2.E5.m1.2.2.1.1.3.cmml" xref="S2.E5.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.3.1.cmml" xref="S2.E5.m1.2.2.1.1.3">subscript</csymbol><ci id="S2.E5.m1.2.2.1.1.3.2.cmml" xref="S2.E5.m1.2.2.1.1.3.2">𝑙</ci><cn type="integer" id="S2.E5.m1.2.2.1.1.3.3.cmml" xref="S2.E5.m1.2.2.1.1.3.3">1</cn></apply></apply></apply><cn type="integer" id="S2.E5.m1.2.2.1.4.cmml" xref="S2.E5.m1.2.2.1.4">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.4c">m(w_{1},w_{2})=\frac{1}{\mid\frac{p_{1}-p_{2}}{l_{1}}\mid+1}\cdot\frac{1}{\mid\frac{l_{1}-l_{2}}{l_{1}}\mid+1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.7" class="ltx_p">Where <math id="S2.SS3.p5.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.SS3.p5.1.m1.1a"><mi id="S2.SS3.p5.1.m1.1.1" xref="S2.SS3.p5.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.1.m1.1b"><ci id="S2.SS3.p5.1.m1.1.1.cmml" xref="S2.SS3.p5.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.1.m1.1c">w</annotation></semantics></math> indicate a word with starting (<math id="S2.SS3.p5.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S2.SS3.p5.2.m2.1a"><mi id="S2.SS3.p5.2.m2.1.1" xref="S2.SS3.p5.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.2.m2.1b"><ci id="S2.SS3.p5.2.m2.1.1.cmml" xref="S2.SS3.p5.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.2.m2.1c">s</annotation></semantics></math>) and ending (<math id="S2.SS3.p5.3.m3.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S2.SS3.p5.3.m3.1a"><mi id="S2.SS3.p5.3.m3.1.1" xref="S2.SS3.p5.3.m3.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.3.m3.1b"><ci id="S2.SS3.p5.3.m3.1.1.cmml" xref="S2.SS3.p5.3.m3.1.1">𝑒</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.3.m3.1c">e</annotation></semantics></math>) time, and <math id="S2.SS3.p5.4.m4.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS3.p5.4.m4.1a"><mi id="S2.SS3.p5.4.m4.1.1" xref="S2.SS3.p5.4.m4.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.4.m4.1b"><ci id="S2.SS3.p5.4.m4.1.1.cmml" xref="S2.SS3.p5.4.m4.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.4.m4.1c">p</annotation></semantics></math> and <math id="S2.SS3.p5.5.m5.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S2.SS3.p5.5.m5.1a"><mi id="S2.SS3.p5.5.m5.1.1" xref="S2.SS3.p5.5.m5.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.5.m5.1b"><ci id="S2.SS3.p5.5.m5.1.1.cmml" xref="S2.SS3.p5.5.m5.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.5.m5.1c">q</annotation></semantics></math> indicate the position and length of the word calculated with <math id="S2.SS3.p5.6.m6.1" class="ltx_Math" alttext="p=\frac{s+e}{2}" display="inline"><semantics id="S2.SS3.p5.6.m6.1a"><mrow id="S2.SS3.p5.6.m6.1.1" xref="S2.SS3.p5.6.m6.1.1.cmml"><mi id="S2.SS3.p5.6.m6.1.1.2" xref="S2.SS3.p5.6.m6.1.1.2.cmml">p</mi><mo id="S2.SS3.p5.6.m6.1.1.1" xref="S2.SS3.p5.6.m6.1.1.1.cmml">=</mo><mfrac id="S2.SS3.p5.6.m6.1.1.3" xref="S2.SS3.p5.6.m6.1.1.3.cmml"><mrow id="S2.SS3.p5.6.m6.1.1.3.2" xref="S2.SS3.p5.6.m6.1.1.3.2.cmml"><mi id="S2.SS3.p5.6.m6.1.1.3.2.2" xref="S2.SS3.p5.6.m6.1.1.3.2.2.cmml">s</mi><mo id="S2.SS3.p5.6.m6.1.1.3.2.1" xref="S2.SS3.p5.6.m6.1.1.3.2.1.cmml">+</mo><mi id="S2.SS3.p5.6.m6.1.1.3.2.3" xref="S2.SS3.p5.6.m6.1.1.3.2.3.cmml">e</mi></mrow><mn id="S2.SS3.p5.6.m6.1.1.3.3" xref="S2.SS3.p5.6.m6.1.1.3.3.cmml">2</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.6.m6.1b"><apply id="S2.SS3.p5.6.m6.1.1.cmml" xref="S2.SS3.p5.6.m6.1.1"><eq id="S2.SS3.p5.6.m6.1.1.1.cmml" xref="S2.SS3.p5.6.m6.1.1.1"></eq><ci id="S2.SS3.p5.6.m6.1.1.2.cmml" xref="S2.SS3.p5.6.m6.1.1.2">𝑝</ci><apply id="S2.SS3.p5.6.m6.1.1.3.cmml" xref="S2.SS3.p5.6.m6.1.1.3"><divide id="S2.SS3.p5.6.m6.1.1.3.1.cmml" xref="S2.SS3.p5.6.m6.1.1.3"></divide><apply id="S2.SS3.p5.6.m6.1.1.3.2.cmml" xref="S2.SS3.p5.6.m6.1.1.3.2"><plus id="S2.SS3.p5.6.m6.1.1.3.2.1.cmml" xref="S2.SS3.p5.6.m6.1.1.3.2.1"></plus><ci id="S2.SS3.p5.6.m6.1.1.3.2.2.cmml" xref="S2.SS3.p5.6.m6.1.1.3.2.2">𝑠</ci><ci id="S2.SS3.p5.6.m6.1.1.3.2.3.cmml" xref="S2.SS3.p5.6.m6.1.1.3.2.3">𝑒</ci></apply><cn type="integer" id="S2.SS3.p5.6.m6.1.1.3.3.cmml" xref="S2.SS3.p5.6.m6.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.6.m6.1c">p=\frac{s+e}{2}</annotation></semantics></math> and <math id="S2.SS3.p5.7.m7.1" class="ltx_Math" alttext="l=\frac{e-s}{2}" display="inline"><semantics id="S2.SS3.p5.7.m7.1a"><mrow id="S2.SS3.p5.7.m7.1.1" xref="S2.SS3.p5.7.m7.1.1.cmml"><mi id="S2.SS3.p5.7.m7.1.1.2" xref="S2.SS3.p5.7.m7.1.1.2.cmml">l</mi><mo id="S2.SS3.p5.7.m7.1.1.1" xref="S2.SS3.p5.7.m7.1.1.1.cmml">=</mo><mfrac id="S2.SS3.p5.7.m7.1.1.3" xref="S2.SS3.p5.7.m7.1.1.3.cmml"><mrow id="S2.SS3.p5.7.m7.1.1.3.2" xref="S2.SS3.p5.7.m7.1.1.3.2.cmml"><mi id="S2.SS3.p5.7.m7.1.1.3.2.2" xref="S2.SS3.p5.7.m7.1.1.3.2.2.cmml">e</mi><mo id="S2.SS3.p5.7.m7.1.1.3.2.1" xref="S2.SS3.p5.7.m7.1.1.3.2.1.cmml">−</mo><mi id="S2.SS3.p5.7.m7.1.1.3.2.3" xref="S2.SS3.p5.7.m7.1.1.3.2.3.cmml">s</mi></mrow><mn id="S2.SS3.p5.7.m7.1.1.3.3" xref="S2.SS3.p5.7.m7.1.1.3.3.cmml">2</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.7.m7.1b"><apply id="S2.SS3.p5.7.m7.1.1.cmml" xref="S2.SS3.p5.7.m7.1.1"><eq id="S2.SS3.p5.7.m7.1.1.1.cmml" xref="S2.SS3.p5.7.m7.1.1.1"></eq><ci id="S2.SS3.p5.7.m7.1.1.2.cmml" xref="S2.SS3.p5.7.m7.1.1.2">𝑙</ci><apply id="S2.SS3.p5.7.m7.1.1.3.cmml" xref="S2.SS3.p5.7.m7.1.1.3"><divide id="S2.SS3.p5.7.m7.1.1.3.1.cmml" xref="S2.SS3.p5.7.m7.1.1.3"></divide><apply id="S2.SS3.p5.7.m7.1.1.3.2.cmml" xref="S2.SS3.p5.7.m7.1.1.3.2"><minus id="S2.SS3.p5.7.m7.1.1.3.2.1.cmml" xref="S2.SS3.p5.7.m7.1.1.3.2.1"></minus><ci id="S2.SS3.p5.7.m7.1.1.3.2.2.cmml" xref="S2.SS3.p5.7.m7.1.1.3.2.2">𝑒</ci><ci id="S2.SS3.p5.7.m7.1.1.3.2.3.cmml" xref="S2.SS3.p5.7.m7.1.1.3.2.3">𝑠</ci></apply><cn type="integer" id="S2.SS3.p5.7.m7.1.1.3.3.cmml" xref="S2.SS3.p5.7.m7.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.7.m7.1c">l=\frac{e-s}{2}</annotation></semantics></math>. The final scores for the entire alignments are then computed by averaging the scores of individual words. The three scores range from 0 to 1, and a higher value indicates a better alignment.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Gap classification</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">The forced alignment detects the alignment gaps, while the gaps can contain speech or only silence. Accordingly, we propose a classification step to identify alignment gaps where disfluent speech may occur.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">Since the timing information of the disfluent speech is not available in the dataset, we define an alignment gap containing disfluent speech as one that covers at least one word. We define the coverage as the duration of the word has more than 50% overlapping with the duration of the alignment gap. The 50% overlap criterion strikes a balance: Considering only words completely within the gap would result in many gaps being deemed empty, despite there being speech intuitively present. Conversely, if a gap is considered non-empty as soon as a word is even partially within it, the transcription model may find it challenging to transcribe this word in the subsequent step.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">Classification with all gaps is inefficient and might involve too small gaps due to alignment inaccuracy. Therefore, this work performs classification on gaps that exceed a minimum threshold length. The chosen minimum gap size should not be too small, as minimal inconsistencies in the alignment would become too noticeable. This would result in previously transcribed speech being transcribed again. On the other hand, the minimal gap should not be too large, as this could lead to overlooking too many gaps where untranscribed speech may be present. Based on preliminary experimental results, a gap size of 0.3 is selected as optimal.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset Preparation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">As this work aims to detect the location and duration of speech disfluencies, the dataset must be composed of spontaneous speech with word-level timing annotation. Besides, the dataset must be large enough to act as training data for the classification model. Therefore, we use the Switchboard-1 Release 2 <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://catalog.ldc.upenn.edu/LDC97S62</span></span></span> and Treebank 3 <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://catalog.ldc.upenn.edu/LDC99T42</span></span></span> datasets. The Switchboard dataset consists of approximately 260 hours of telephone conversations with word-level timing information, and the Treebank 3 dataset adds the corresponding word-level disfluency annotation to the transcripts of the Switchboard dataset.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Segmenting Audio</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">This dataset consists of recordings that are several minutes long. The long recordings hinder forced alignment performance, and the segmentation pre-processing is applied.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">First, the audio file is segmented at all points where there is more than 5 seconds of silence. These points provide good places to divide the transcript without interrupting the speaker’s flow of speech. However, there are still segments that remain several minutes long.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In the next step, as long as the segment is longer than 30 seconds, the largest gap between two words in the middle of the transcript is sought, ensuring that it is at least 10 seconds away from the beginning and end of the segment. This ensures that the resulting segments are between 10 and 30 seconds long. Of course, it is also possible that shorter segments are created when splitting by 5-second pauses.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental setups</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">This work experiments with the SOTA ASR model Whisper <span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://huggingface.co/openai/whisper-large-v3</span></span></span> to augment disfluency detection ability. As for frame-wise feature extractor, this work selects Wav2Vec2 <span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://huggingface.co/facebook/wav2vec2-base-960h</span></span></span> which is fine-tuned on English ASR. The ASR model can be the same as the feature extractor model in pipeline design, but we select Whisper as the ASR model because this pipeline supports augmenting any ASR model, and Whispers is a stronger ASR model in terms of accuracy and robustness for this dataset. We believe our approach is effective for ASR models providing more accurate predictions than Whisper. Besides, we acknowledge that our approach may suffer performance degradation with ASR models yielding less accurate predictions.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Are ASR models good at disfluency recognition?</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For the initial transcription of the audio, we employ the Whisper model on the dataset and achieve 22.54 WER points. To assess the percentage of fluent and not fluent speech transcribed, the manual and the automatic transcript are aligned using the operations obtained during the calculation of the WER. <a href="#S4.T1" title="Table 1 ‣ 4.2 Are ASR models good at disfluency recognition? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a> illustrates the number of words from the manual transcript that were correctly transcribed, incorrectly transcribed and not transcribed, each annotated as fluent or not fluent speech.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.2.1" class="ltx_tr">
<td id="S4.T1.2.1.1" class="ltx_td ltx_border_t"></td>
<td id="S4.T1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">Correctly</td>
<td id="S4.T1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">Incorrectly</td>
<td id="S4.T1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">Untranscribed</td>
</tr>
<tr id="S4.T1.2.2" class="ltx_tr">
<td id="S4.T1.2.2.1" class="ltx_td"></td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center">Transcribed</td>
<td id="S4.T1.2.2.3" class="ltx_td ltx_align_center">Transcribed</td>
<td id="S4.T1.2.2.4" class="ltx_td"></td>
</tr>
<tr id="S4.T1.2.3" class="ltx_tr">
<td id="S4.T1.2.3.1" class="ltx_td ltx_align_center ltx_border_t">Fluent</td>
<td id="S4.T1.2.3.2" class="ltx_td ltx_align_center ltx_border_t">895,474</td>
<td id="S4.T1.2.3.3" class="ltx_td ltx_align_center ltx_border_t">45,823</td>
<td id="S4.T1.2.3.4" class="ltx_td ltx_align_center ltx_border_t">31,931</td>
</tr>
<tr id="S4.T1.2.4" class="ltx_tr">
<td id="S4.T1.2.4.1" class="ltx_td ltx_align_center ltx_border_b">Disfluent</td>
<td id="S4.T1.2.4.2" class="ltx_td ltx_align_center ltx_border_b">136,718</td>
<td id="S4.T1.2.4.3" class="ltx_td ltx_align_center ltx_border_b">15,242</td>
<td id="S4.T1.2.4.4" class="ltx_td ltx_align_center ltx_border_b">89,799</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.3.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>Fluent and disfluent transcribed words.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">It can be observed that approximately 74% of all untranscribed words are labelled as speech disfluencies. Additionally, it is evident that 37% of all speech disfluencies are not transcribed, 6% are transcribed incorrectly and only 56% are transcribed correctly, confirming the initial assumption that Whisper does not fully transcribe speech disfluencies.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>What parameter to use for modified CTC algorithm?</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">This work proposes a modified CTC alignment algorithm to overcome the problems of the standard CTC alignment algorithm on disfluency recognition (Section <a href="#S2.SS2.SSS2" title="2.2.2 Modified CTC Alignment ‣ 2.2 Forced alignment ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2.2</span></a>). The modified algorithm involves a fixed probability <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">c</span> as to incentive gap recognition in alignment.
The probability <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_italic">c</span> experimented with probability values -5, -4, -3, -2, -1, -0.5, -0.1, -0.01 on a par with the log probability scale in frame-wise acoustic probability. Setting as -0.01 is essentially 0 and the value above 0 makes no sense as for comparison with log probability. A higher value of probability <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">c</annotation></semantics></math> indicates a higher chance to stay with the space token, corresponding to more and longer alignment gaps.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">This work counts the number of words that are covered by the alignment gaps to evaluate alignment performance. We evaluate the alignment approaches on all words in the manual transcription to show the general alignment performance, and we also evaluate them on only the words next to the untranscribed words to show the performance specifically on disfluent speech. Note that the untranscribed words are determined with Levenshtein Alignment, same as Section <a href="#S2.SS3" title="2.3 Alignment Comparison Metric ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>. As <a href="#S4.F3" title="Figure 3 ‣ 4.3 What parameter to use for modified CTC algorithm? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 3</span></a> shows, significantly more untranscribed words are reachable with a default probability of -0.01 than -5.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Besides, we evaluate using the proposed alignment scores. As shown in <a href="#S4.T2" title="Table 2 ‣ 4.3 What parameter to use for modified CTC algorithm? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>, the combined alignment scores for all words show no significant difference, but the score for words around the untranscribed words improves clearly with decreasing the probability value of <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mi id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><ci id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">c</annotation></semantics></math>, which is consistent to <a href="#S4.F3" title="Figure 3 ‣ 4.3 What parameter to use for modified CTC algorithm? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 3</span></a>. Therefore, the -0.001 is chosen for the modified CTC algorithm in later experiments.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2409.10177/assets/images/c_value_reachable_words.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="354" height="187" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.4.1.1" class="ltx_text ltx_font_bold">Fig. 3</span>: </span>The number of words that are covered by modified alignments with different probability <math id="S4.F3.2.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.F3.2.m1.1b"><mi id="S4.F3.2.m1.1.1" xref="S4.F3.2.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.F3.2.m1.1c"><ci id="S4.F3.2.m1.1.1.cmml" xref="S4.F3.2.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.2.m1.1d">c</annotation></semantics></math> value. The left is for all words and the right is for the words next to the untranscribed words in the manual transcript.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.2.1" class="ltx_tr">
<td id="S4.T2.2.1.1" class="ltx_td ltx_align_center ltx_border_t">Probability value</td>
<td id="S4.T2.2.1.2" class="ltx_td ltx_align_center ltx_border_t">All words</td>
<td id="S4.T2.2.1.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T2.2.1.3.1" class="ltx_text"></span> <span id="S4.T2.2.1.3.2" class="ltx_text">
<span id="S4.T2.2.1.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T2.2.1.3.2.1.1" class="ltx_tr">
<span id="S4.T2.2.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Words around</span></span>
<span id="S4.T2.2.1.3.2.1.2" class="ltx_tr">
<span id="S4.T2.2.1.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">untranscribed words</span></span>
</span></span><span id="S4.T2.2.1.3.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<td id="S4.T2.2.2.1" class="ltx_td ltx_align_center ltx_border_t">-0.01</td>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.5893</td>
<td id="S4.T2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">0.5628</td>
</tr>
<tr id="S4.T2.2.3" class="ltx_tr">
<td id="S4.T2.2.3.1" class="ltx_td ltx_align_center">-0.1</td>
<td id="S4.T2.2.3.2" class="ltx_td ltx_align_center">0.5896</td>
<td id="S4.T2.2.3.3" class="ltx_td ltx_align_center">0.5627</td>
</tr>
<tr id="S4.T2.2.4" class="ltx_tr">
<td id="S4.T2.2.4.1" class="ltx_td ltx_align_center">-0.5</td>
<td id="S4.T2.2.4.2" class="ltx_td ltx_align_center">0.5906</td>
<td id="S4.T2.2.4.3" class="ltx_td ltx_align_center">0.5627</td>
</tr>
<tr id="S4.T2.2.5" class="ltx_tr">
<td id="S4.T2.2.5.1" class="ltx_td ltx_align_center">-1</td>
<td id="S4.T2.2.5.2" class="ltx_td ltx_align_center">0.5917</td>
<td id="S4.T2.2.5.3" class="ltx_td ltx_align_center">0.5625</td>
</tr>
<tr id="S4.T2.2.6" class="ltx_tr">
<td id="S4.T2.2.6.1" class="ltx_td ltx_align_center">-2</td>
<td id="S4.T2.2.6.2" class="ltx_td ltx_align_center">0.5932</td>
<td id="S4.T2.2.6.3" class="ltx_td ltx_align_center">0.5600</td>
</tr>
<tr id="S4.T2.2.7" class="ltx_tr">
<td id="S4.T2.2.7.1" class="ltx_td ltx_align_center">-3</td>
<td id="S4.T2.2.7.2" class="ltx_td ltx_align_center">0.5937</td>
<td id="S4.T2.2.7.3" class="ltx_td ltx_align_center">0.5550</td>
</tr>
<tr id="S4.T2.2.8" class="ltx_tr">
<td id="S4.T2.2.8.1" class="ltx_td ltx_align_center">-4</td>
<td id="S4.T2.2.8.2" class="ltx_td ltx_align_center">0.5937</td>
<td id="S4.T2.2.8.3" class="ltx_td ltx_align_center">0.5484</td>
</tr>
<tr id="S4.T2.2.9" class="ltx_tr">
<td id="S4.T2.2.9.1" class="ltx_td ltx_align_center ltx_border_b">-5</td>
<td id="S4.T2.2.9.2" class="ltx_td ltx_align_center ltx_border_b">0.5932</td>
<td id="S4.T2.2.9.3" class="ltx_td ltx_align_center ltx_border_b">0.5407</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.3.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>Experimental results on modified CTC alignment with different predefined probability using the combined alignment score.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Which forced alignment algorithm works better?</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">The alignments calculated by the standard CTC alignment, the modified CTC algorithm and cross-attention are compared with the proposed evaluation metric. Same as Section <a href="#S4.SS3" title="4.3 What parameter to use for modified CTC algorithm? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>, we evaluate the performance for all words as well as only for the words around the untranscribed speech. But here we calculate the proposed alignment metrics of the position, length and the combined scores.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">As <a href="#S4.T3" title="Table 3 ‣ 4.4 Which forced alignment algorithm works better? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 3</span></a> shown, the modified CTC algorithm outperforms the others in all aspects, except the length for all words where the standard CTC is slightly better. For the alignment performance in the presence of untranscribed speech, the modified CTC algorithm shows a clear performance gain.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T3.2.1" class="ltx_tr">
<td id="S4.T3.2.1.1" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.2.1.2" class="ltx_td ltx_align_center ltx_border_t">Cross Attention</td>
<td id="S4.T3.2.1.3" class="ltx_td ltx_align_center ltx_border_t">CTC</td>
<td id="S4.T3.2.1.4" class="ltx_td ltx_align_center ltx_border_t">Modified CTC</td>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<td id="S4.T3.2.2.1" class="ltx_td ltx_align_left ltx_border_t" colspan="4">All words</td>
</tr>
<tr id="S4.T3.2.3" class="ltx_tr">
<td id="S4.T3.2.3.1" class="ltx_td ltx_align_center ltx_border_t">Position</td>
<td id="S4.T3.2.3.2" class="ltx_td ltx_align_center ltx_border_t">0.5941</td>
<td id="S4.T3.2.3.3" class="ltx_td ltx_align_center ltx_border_t">0.7465</td>
<td id="S4.T3.2.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.2.3.4.1" class="ltx_text ltx_font_bold">0.7702</span></td>
</tr>
<tr id="S4.T3.2.4" class="ltx_tr">
<td id="S4.T3.2.4.1" class="ltx_td ltx_align_center">Length</td>
<td id="S4.T3.2.4.2" class="ltx_td ltx_align_center">0.6855</td>
<td id="S4.T3.2.4.3" class="ltx_td ltx_align_center"><span id="S4.T3.2.4.3.1" class="ltx_text ltx_font_bold">0.7755</span></td>
<td id="S4.T3.2.4.4" class="ltx_td ltx_align_center">0.7612</td>
</tr>
<tr id="S4.T3.2.5" class="ltx_tr">
<td id="S4.T3.2.5.1" class="ltx_td ltx_align_center">Combined</td>
<td id="S4.T3.2.5.2" class="ltx_td ltx_align_center">0.4359</td>
<td id="S4.T3.2.5.3" class="ltx_td ltx_align_center">0.5880</td>
<td id="S4.T3.2.5.4" class="ltx_td ltx_align_center"><span id="S4.T3.2.5.4.1" class="ltx_text ltx_font_bold">0.5893</span></td>
</tr>
<tr id="S4.T3.2.6" class="ltx_tr">
<td id="S4.T3.2.6.1" class="ltx_td ltx_align_left ltx_border_t" colspan="4">Words around untranscribed words</td>
</tr>
<tr id="S4.T3.2.7" class="ltx_tr">
<td id="S4.T3.2.7.1" class="ltx_td ltx_align_center ltx_border_t">Position</td>
<td id="S4.T3.2.7.2" class="ltx_td ltx_align_center ltx_border_t">0.5138</td>
<td id="S4.T3.2.7.3" class="ltx_td ltx_align_center ltx_border_t">0.7177</td>
<td id="S4.T3.2.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.2.7.4.1" class="ltx_text ltx_font_bold">0.7619</span></td>
</tr>
<tr id="S4.T3.2.8" class="ltx_tr">
<td id="S4.T3.2.8.1" class="ltx_td ltx_align_center">Length</td>
<td id="S4.T3.2.8.2" class="ltx_td ltx_align_center">0.6051</td>
<td id="S4.T3.2.8.3" class="ltx_td ltx_align_center">0.7376</td>
<td id="S4.T3.2.8.4" class="ltx_td ltx_align_center"><span id="S4.T3.2.8.4.1" class="ltx_text ltx_font_bold">0.7555</span></td>
</tr>
<tr id="S4.T3.2.9" class="ltx_tr">
<td id="S4.T3.2.9.1" class="ltx_td ltx_align_center ltx_border_b">Combined</td>
<td id="S4.T3.2.9.2" class="ltx_td ltx_align_center ltx_border_b">0.3508</td>
<td id="S4.T3.2.9.3" class="ltx_td ltx_align_center ltx_border_b">0.5493</td>
<td id="S4.T3.2.9.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.2.9.4.1" class="ltx_text ltx_font_bold">0.5802</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.6.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>Comparison of forced alignment algorithms with evaluation of alignment metric. <span id="S4.T3.7.2" class="ltx_text ltx_font_italic">Position</span> and <span id="S4.T3.8.3" class="ltx_text ltx_font_italic">Length</span> indicate the individual score, and <span id="S4.T3.9.4" class="ltx_text ltx_font_italic">Combined</span> indicates the score considering position and length (Section <a href="#S2.SS3" title="2.3 Alignment Comparison Metric ‣ 2 Disfluency Detection ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>).</figcaption>
</figure>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">Besides evaluating the metric scores, this work also counts how many untranscribed words are covered. <a href="#S4.F4" title="Figure 4 ‣ 4.4 Which forced alignment algorithm works better? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 4</span></a> shows for each presented alignment method the number of untranscribed words and already transcribed words within a gap for various minimum gap sizes. As can be seen, the modified CTC algorithm recognized many more untranscribed words than other algorithms. Specifically, with a total amount of 121,738, modified CTC, standard CTC and cross-attention cover 81.69%, 46.10% and 12.02% untranscribed words, respectively. Therefore, the modified CTC alignment is chosen for further analysis.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2409.10177/assets/images/alignment_method_comparison.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="236" height="193" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text ltx_font_bold">Fig. 4</span>: </span>Untranscribed and transcribed words covered by three forced alignment approaches.</figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>How to build disfluency classification model?</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">The forced alignment brings gaps between the words of transcription, and the next question comes as to how to classify the gaps as containing speech or empty. This work proposes to build a classification model and train it with a dataset tailored for the pipeline with the gaps.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">With the combined dataset, we build the datasets consisting of extracted gaps. The gap is labelled as “gap contains speech” if at least one word from the manual transcript falls into this gap. Otherwise, they were labelled as “gap is empty”. We use the modified CTC algorithm for alignment. After shuffling, we select 80% of the gaps for training data, and the rest for test data (<a href="#S4.T4" title="Table 4 ‣ 4.5 How to build disfluency classification model? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 4</span></a>).</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.2.1" class="ltx_tr">
<td id="S4.T4.2.1.1" class="ltx_td ltx_border_t"></td>
<td id="S4.T4.2.1.2" class="ltx_td ltx_align_center ltx_border_t">Total</td>
<td id="S4.T4.2.1.3" class="ltx_td ltx_align_center ltx_border_t">Containing Speech</td>
<td id="S4.T4.2.1.4" class="ltx_td ltx_align_center ltx_border_t">Empty</td>
</tr>
<tr id="S4.T4.2.2" class="ltx_tr">
<td id="S4.T4.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Training</td>
<td id="S4.T4.2.2.2" class="ltx_td ltx_align_center ltx_border_t">220,344</td>
<td id="S4.T4.2.2.3" class="ltx_td ltx_align_center ltx_border_t">101,207</td>
<td id="S4.T4.2.2.4" class="ltx_td ltx_align_center ltx_border_t">119,137</td>
</tr>
<tr id="S4.T4.2.3" class="ltx_tr">
<td id="S4.T4.2.3.1" class="ltx_td ltx_align_center ltx_border_b">Test</td>
<td id="S4.T4.2.3.2" class="ltx_td ltx_align_center ltx_border_b">40,980</td>
<td id="S4.T4.2.3.3" class="ltx_td ltx_align_center ltx_border_b">19,651</td>
<td id="S4.T4.2.3.4" class="ltx_td ltx_align_center ltx_border_b">21,329</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.3.1.1" class="ltx_text ltx_font_bold">Table 4</span>: </span>Statistics of the gaps classification dataset</figcaption>
</figure>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p">With the above dataset, this work builds a classification model by fine-tuning a wav2wec2 model in conjunction with a classification head. The classification head consists of a linear layer projecting the output of Wav2Vec2 onto the predefined classes: an empty gap and a gap with speech. With the evaluation of the test split, the classification model achieved an accuracy of 81.62%, a precision of 86.14%, a recall of 74.80%, and an F1-score of 80.07%.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>How effective is the disfluency detection pipeline?</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">Knowing the proportion of all gaps successfully classified does not provide information about the proportion of untranscribed words successfully classified. Therefore, we count the number of transcribed and untranscribed words that are classified and covered in the gaps, classified but not covered in gaps and not classified by the gap classification model.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p">As <a href="#S4.T5" title="Table 5 ‣ 4.6 How effective is the disfluency detection pipeline? ‣ 4 Experiments and Results ‣ Augmenting Automatic Speech Recognition Models with Disfluency Detection" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 5</span></a> shows, 15,478 out of a total of 20,880 untranscribed words are covered by the detected alignment gaps, leading to a detection rate of 74.13%. However, 13,202 out of 168,256 already transcribed words are also labelled as predicted in the gaps, counting to a false detection rate of 8.6%. The false detection rate indicates the risk of double transcription if a follow-up re-transcription was carried on.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T5.2.1" class="ltx_tr">
<td id="S4.T5.2.1.1" class="ltx_td ltx_border_t"></td>
<td id="S4.T5.2.1.2" class="ltx_td ltx_align_center ltx_border_t">Transcribed</td>
<td id="S4.T5.2.1.3" class="ltx_td ltx_align_center ltx_border_t">Untranscribed</td>
</tr>
<tr id="S4.T5.2.2" class="ltx_tr">
<td id="S4.T5.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Classified and covered</td>
<td id="S4.T5.2.2.2" class="ltx_td ltx_align_center ltx_border_t">13,202</td>
<td id="S4.T5.2.2.3" class="ltx_td ltx_align_center ltx_border_t">15,478</td>
</tr>
<tr id="S4.T5.2.3" class="ltx_tr">
<td id="S4.T5.2.3.1" class="ltx_td ltx_align_center">Classified but uncovered</td>
<td id="S4.T5.2.3.2" class="ltx_td ltx_align_center">153,975</td>
<td id="S4.T5.2.3.3" class="ltx_td ltx_align_center">3,952</td>
</tr>
<tr id="S4.T5.2.4" class="ltx_tr">
<td id="S4.T5.2.4.1" class="ltx_td ltx_align_center ltx_border_b">Not classified</td>
<td id="S4.T5.2.4.2" class="ltx_td ltx_align_center ltx_border_b">1,079</td>
<td id="S4.T5.2.4.3" class="ltx_td ltx_align_center ltx_border_b">1,450</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.3.1.1" class="ltx_text ltx_font_bold">Table 5</span>: </span>Pipeline performance evaluation on the type of words covered by the gaps.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we propose an inference-only pipeline to augment any ASR model with open-set disfluency detection. We reveal the current ASR models struggle to transcribe speech disfluency. To tackle this issue, we propose a modified CTC forced alignment algorithm to recognize the location and duration of speech disfluencies. We show the effectiveness of this approach by comparing it with popular forced alignment approaches in disfluency recognition. Additionally, we build a pipeline for disfluency detection and show that the approach captures 74.13% of the words that are not transcribed by the initial transcription.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">However, the disfluency detection performance is dependent on the ASR model performance. This is because that transcribed disfluencies will not be identified as disfluencies, as they are already aligned with the transcribed words.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>ACKNOWLEDGMENTS</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This work was funded by the Baden-Württemberg Ministry of Science, Research and Art (MWK), via the state digitalisation strategy digital@bw.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Ludwig Kürzinger, Dominik Winkelbauer, Lujun Li, Tobias Watzel, and Gerhard Rigoll,

</span>
<span class="ltx_bibblock">“CTC-segmentation of large corpora for german end-to-end speech recognition,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">International Conference on Speech and Computer</span>. Springer, 2020, pp. 267–278.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Shaomei Wu,

</span>
<span class="ltx_bibblock">“The world is designed for fluent people: Benefits and challenges of videoconferencing technologies for people who stutter,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, 2023, pp. 1–17.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Ai Leen Choo, Daphne Greenberg, Hongli Li, and Amani Talwar,

</span>
<span class="ltx_bibblock">“Rate of stuttering and factors associated with speech fluency characteristics in adult struggling readers,”

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Journal of Learning Disabilities</span>, vol. 56, no. 1, pp. 7–24, 2023.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Theodoros Kouzelis, Georgios Paraskevopoulos, Athanasios Katsamanis, and Vassilis Katsouros,

</span>
<span class="ltx_bibblock">“Weakly-supervised forced alignment of disfluent speech using phoneme-level modeling,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Proc. INTERSPEECH 2023</span>, 2023, pp. 1563–1567.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Colin Lea, Zifang Huang, Jaya Narain, Lauren Tooley, Dianna Yee, Dung Tien Tran, Panayiotis Georgiou, Jeffrey P Bigham, and Leah Findlater,

</span>
<span class="ltx_bibblock">“From user perceptions to technical improvement: Enabling people who stutter to better use speech recognition,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</span>, New York, NY, USA, 2023, CHI ’23, Association for Computing Machinery.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Angelica Chen, Vicky Zayats, Daniel Walker, and Dirk Padfield,

</span>
<span class="ltx_bibblock">“Teaching BERT to wait: Balancing accuracy and latency for streaming disfluency detection,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</span>, Seattle, United States, July 2022, pp. 827–838, Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Johann C. Rocholl, Vicky Zayats, Daniel D. Walker, Noah B. Murad, Aaron Schneider, and Daniel J. Liebling,

</span>
<span class="ltx_bibblock">“Disfluency Detection with Unlabeled Data and Small BERT Models,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Proc. Interspeech 2021</span>, 2021, pp. 766–770.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Morteza Rohanian and Julian Hough,

</span>
<span class="ltx_bibblock">“Best of both worlds: Making high accuracy non-incremental transformer-based disfluency detection incremental,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Annual Meeting of the Association for Computational Linguistics</span>, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Motoi Omachi, Yuya Fujita, Shinji Watanabe, and Tianzi Wang,

</span>
<span class="ltx_bibblock">“Non-autoregressive end-to-end automatic speech recognition incorporating downstream natural language processing,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, 2022, pp. 6772–6776.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Peter Mihajlik, Yan Meng, Mate S Kadar, Julian Linke, Barbara Schuppler, and Katalin Mády,

</span>
<span class="ltx_bibblock">“On disfluency and non-lexical sound labeling for end-to-end automatic speech recognition,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Interspeech 2024</span>, 2024, pp. 1270–1274.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Tedd Kourkounakis, Amirhossein Hajavi, and Ali Etemad,

</span>
<span class="ltx_bibblock">“FLUENTNet: End-to-end detection of stuttered speech disfluencies with deep learning,”

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, vol. 29, pp. 2986–2999, 2021.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Hayato Futami, Emiru Tsunoo, Kentaro Shibata, Yosuke Kashiwagi, Takao Okuda, Siddhant Arora, and Shinji Watanabe,

</span>
<span class="ltx_bibblock">“Streaming joint speech recognition and disfluency detection,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, 2023, pp. 1–5.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Koharu Horii, Meiko Fukuda, Kengo Ohta, Ryota Nishimura, Atsunori Ogawa, and Norihide Kitaoka,

</span>
<span class="ltx_bibblock">“End-to-end spontaneous speech recognition using disfluency labeling.,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, 2022, pp. 4108–4112.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Jiachen Lian, Carly Feng, Naasir Farooqi, Steve Li, Anshul Kashyap, Cheol Jun Cho, Peter Wu, Robbie Netzorg, Tingle Li, and Gopala Krishna Anumanchipalli,

</span>
<span class="ltx_bibblock">“Unconstrained dysfluency modeling for dysfluent speech transcription and detection,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</span>, 2023, pp. 1–8.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Lavanya Venkatasubramaniam, Vishal Sunder, and Eric Fosler-Lussier,

</span>
<span class="ltx_bibblock">“End-to-end word-level disfluency detection and classification in children’s reading assessment,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, 2023, pp. 1–5.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Dena Mujtaba, Nihar R. Mahapatra, Megan Arney, J. Scott Yaruss, Caryn Herring, and Jia Bin,

</span>
<span class="ltx_bibblock">“Inclusive asr for disfluent speech: Cascaded large-scale self-supervised learning with targeted fine-tuning and data augmentation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Interspeech 2024</span>, 2024, pp. 1275–1279.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Rao Ma, Mengjie Qian, Mark Gales, and Katherine M Knill,

</span>
<span class="ltx_bibblock">“Adapting an ASR foundation model for spoken language assessment,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">9th Workshop on Speech and Language Technology in Education (SLaTE)</span>. Aug. 2023, slate_2023, ISCA.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Utku Norman, Tanvi Dinkar, Barbara Bruno, and Chloé Clavel,

</span>
<span class="ltx_bibblock">“Studying alignment in a collaborative learning activity via automatic methods: The link between what we say and do,”

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Dialogue &amp; Discourse</span>, vol. 13, no. 2, pp. 1–48, 2022.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
John Harvill, Mark Hasegawa-Johnson, and Chang D. Yoo,

</span>
<span class="ltx_bibblock">“Frame-Level Stutter Detection,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proc. Interspeech 2022</span>, 2022, pp. 2843–2847.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Olabanji Shonibare, Xiaosu Tong, and Venkatesh Ravichandran,

</span>
<span class="ltx_bibblock">“Enhancing ASR for stuttered speech with limited data using detect and pass,” 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Jiachen Lian and Gopala Anumanchipalli,

</span>
<span class="ltx_bibblock">“Towards hierarchical spoken language disfluency modeling,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, Yvette Graham and Matthew Purver, Eds., St. Julian’s, Malta, Mar. 2024, pp. 539–551, Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever,

</span>
<span class="ltx_bibblock">“Robust speech recognition via large-scale weak supervision,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>. PMLR, 2023, pp. 28492–28518.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli,

</span>
<span class="ltx_bibblock">“wav2vec 2.0: A framework for self-supervised learning of speech representations,”

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, vol. 33, pp. 12449–12460, 2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Shinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro Nishitoba, Yuya Unno, Nelson Enrique Yalta Soplin, Jahn Heymann, Matthew Wiesner, Nanxin Chen, Adithya Renduchintala, and Tsubasa Ochiai,

</span>
<span class="ltx_bibblock">“ESPnet: End-to-end speech processing toolkit,” 2018.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Mirco Ravanelli, Titouan Parcollet, Peter Plantinga, Aku Rouhe, Samuele Cornell, Loren Lugosch, Cem Subakan, Nauman Dawalatabad, Abdelwahab Heba, Jianyuan Zhong, Ju-Chieh Chou, Sung-Lin Yeh, Szu-Wei Fu, Chien-Feng Liao, Elena Rastorgueva, François Grondin, William Aris, Hwidong Na, Yan Gao, Renato De Mori, and Yoshua Bengio,

</span>
<span class="ltx_bibblock">“SpeechBrain: A general-purpose speech toolkit,” 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Jacob Kahn, Vineel Pratap, Tatiana Likhomanenko, Qiantong Xu, Awni Hannun, Jeff Cai, Paden Tomasello, Ann Lee, Edouard Grave, Gilad Avidov, Benoit Steiner, Vitaliy Liptchinsky, Gabriel Synnaeve, and Ronan Collobert,

</span>
<span class="ltx_bibblock">“Flashlight: Enabling innovation in tools for machine learning,” 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Toni Giorgino,

</span>
<span class="ltx_bibblock">“Computing and visualizing dynamic time warping alignments in r: The dtw package,”

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Journal of Statistical Software</span>, vol. 31, no. 7, pp. 1–24, 2009.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.10176" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.10177" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.10177">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.10177" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.10178" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 23:22:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
