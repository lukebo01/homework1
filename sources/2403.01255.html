<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.01255] Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey</title><meta property="og:description" content="Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial compu…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.01255">

<!--Generated on Fri Apr  5 15:24:13 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_fleqn">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">[orcid=0000-0002-9532-2453]
<span id="p1.1.1" class="ltx_ERROR undefined">\cormark</span>[1]
<span id="p1.1.2" class="ltx_ERROR undefined">\credit</span>Conceptualization; Methodology; Data Curation; Resources; Investigation; Visualization; Writing original draft; Writing, review, and editing</p>
</div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p">[orcid=0000-0002-6353-0215]
<span id="p2.1.1" class="ltx_ERROR undefined">\credit</span>Conceptualization; Methodology; Resources; Investigation; Writing original draft; Writing, review, and editing</p>
</div>
<div id="p3" class="ltx_para">
<p id="p3.1" class="ltx_p">[orcid=0000-0001-8904-5587]
<span id="p3.1.1" class="ltx_ERROR undefined">\credit</span>Conceptualization; Methodology; Resources; Investigation; Writing original draft; Writing, review, and editing</p>
</div>
<h1 class="ltx_title ltx_title_document">Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hamza Kheddar
</span><span class="ltx_author_notes">kheddar.hamza@univ-medea.dz</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mustapha Hemis
</span><span class="ltx_author_notes">hemismustapha@yahoo.fr </span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yassine Himeur
</span><span class="ltx_author_notes">yhimeur@ud.ac.ae
<span class="ltx_contact ltx_role_address">LSEA Laboratory, Department of Electrical Engineering, University of Medea, 26000, Algeria
</span>
<span class="ltx_contact ltx_role_address">LCPTS Laboratory, University of Sciences and Technology Houari Boumediene (USTHB), P.O. Box 32, El-Alia, Bab-Ezzouar, Algiers 16111, Algeria.
</span>
<span class="ltx_contact ltx_role_address">College of Engineering and Information Technology, University of Dubai, Dubai, UAE
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources. Enabling adaptive systems improves ASR performance in dynamic environments. DL techniques assume training and testing data originate from the same domain, which is not always true. Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and reinforcement learning (RL) address these issues. DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and RL optimizes decision-making in dynamic environments, reducing computation costs.</p>
<p id="id2.id2" class="ltx_p">This survey offers a comprehensive review of DTL, FL, and RL-based ASR frameworks, aiming to provide insights into the latest developments and aid researchers and professionals in understanding the current challenges. Additionally, transformers, which are advanced DL techniques heavily used in proposed ASR frameworks, are considered in this survey for their ability to capture extensive dependencies in the input ASR sequence. The paper starts by presenting the background of DTL, FL, RL, and Transformers and then adopts a well-designed taxonomy to outline the  <a href="#Sx1.44.44.44"><span href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">state-of-the-art</span></span></span></a> (<a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a>) approaches. Subsequently, a critical analysis is conducted to identify the strengths and weaknesses of each framework. Additionally, a comparative study is presented to highlight the existing challenges, paving the way for future research opportunities.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Automatic speech recognition <span id="id3.id1" class="ltx_ERROR undefined">\sep</span>Deep transfer learning <span id="id4.id2" class="ltx_ERROR undefined">\sep</span>Transformers <span id="id5.id3" class="ltx_ERROR undefined">\sep</span>Federated learning <span id="id6.id4" class="ltx_ERROR undefined">\sep</span>Reinforcement learning

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Preliminary</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Advancements in  <a href="#Sx1.1.1.1"><span href="#Sx1.1.1.1" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">artificial intelligence</span></span></span></a> (<a href="#Sx1.1.1.1"><abbr href="#Sx1.1.1.1" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AI</span></span></abbr></a>) have significantly improved  <a href="#Sx1.22.22.22"><span href="#Sx1.22.22.22" title="human-machine interaction" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">human-machine interaction</span></span></span></a> (<a href="#Sx1.22.22.22"><abbr href="#Sx1.22.22.22" title="human-machine interaction" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">HMI</span></span></abbr></a>), especially with technologies that convert speech into executable actions.  <a href="#Sx1.4.4.4"><span href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">automatic speech recognition</span></span></span></a> (<a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>) emerges as a leading communication technology in <a href="#Sx1.22.22.22"><abbr href="#Sx1.22.22.22" title="human-machine interaction" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">HMI</span></span></abbr></a>, extensively utilized by corporations and service providers for facilitating interactions through AI platforms like chatbots and digital assistants. Spoken language forms the core of these interactions, emphasizing the necessity for sophisticated speech processing in <a href="#Sx1.1.1.1"><abbr href="#Sx1.1.1.1" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AI</span></span></abbr></a> systems tailored for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>.
<a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> technology encompasses the analysis of (i) acoustic, lexical, and syntactic aspects; and (ii) semantic understanding. The  <a href="#Sx1.2.2.2"><span href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">acoustic model</span></span></span></a> (<a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a>) processing includes speech coding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">1</span></a>]</cite>, enhancement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">2</span></a>]</cite>, and source separation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">3</span></a>]</cite>, alongside securing speech via steganography <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">4</span></a>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">5</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">6</span></a>]</cite> and watermarking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">7</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">8</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">9</span></a>]</cite>. These components are integral to audio analysis.
On the other hand, the  <a href="#Sx1.42.42.42"><span href="#Sx1.42.42.42" title="semantic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">semantic model</span></span></span></a> (<a href="#Sx1.42.42.42"><abbr href="#Sx1.42.42.42" title="semantic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SM</span></span></abbr></a>), often identified as  <a href="#Sx1.24.24.24"><span href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">language model</span></span></span></a> (<a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a>) processing in literature, involves all  <a href="#Sx1.31.31.31"><span href="#Sx1.31.31.31" title="natural language processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">natural language processing</span></span></span></a> (<a href="#Sx1.31.31.31"><abbr href="#Sx1.31.31.31" title="natural language processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">NLP</span></span></abbr></a>) techniques. This AI branch aims at teaching computers to understand and interpret human language, serving as the basis for applications like music information retrieval <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">10</span></a>]</cite>, sound file organization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">11</span></a>]</cite>, audio tagging, and  <a href="#Sx1.17.17.17"><span href="#Sx1.17.17.17" title="event detection" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">event detection</span></span></span></a> (<a href="#Sx1.17.17.17"><abbr href="#Sx1.17.17.17" title="event detection" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ED</span></span></abbr></a>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">12</span></a>]</cite>, as well as converting speech to text and vice versa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">13</span></a>]</cite>, detecting hate speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">14</span></a>]</cite>, and cyberbullying <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">15</span></a>]</cite>. Employing <a href="#Sx1.31.31.31"><abbr href="#Sx1.31.31.31" title="natural language processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">NLP</span></span></abbr></a> across various domains enables AI models to effectively comprehend and respond to human inputs, unveiling extensive research prospects in diverse sectors.</p>
</div>
<figure id="S1.SS1.tab1" class="ltx_table">
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">Abbreviations</h2>

<div class="ltx_pagination ltx_role_start_3_columns"></div>
<section id="Sx1.62" class="ltx_glossary ltx_acronym ltx_list_acronym">
<dl id="Sx1.62.62" class="ltx_glossarylist">
<dt id="Sx1.1.1.1" class="ltx_glossaryentry"><span id="Sx1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">AI</span></dt>
<dd><span id="Sx1.1.1.1.4.1" class="ltx_text" style="font-size:80%;">artificial intelligence</span></dd>
<dt id="Sx1.2.2.2" class="ltx_glossaryentry"><span id="Sx1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">AM</span></dt>
<dd><span id="Sx1.2.2.2.4.1" class="ltx_text" style="font-size:80%;">acoustic model</span></dd>
<dt id="Sx1.3.3.3" class="ltx_glossaryentry"><span id="Sx1.3.3.3.1.1" class="ltx_text" style="font-size:80%;">APT</span></dt>
<dd><span id="Sx1.3.3.3.4.1" class="ltx_text" style="font-size:80%;">audio pyramid transformer</span></dd>
<dt id="Sx1.4.4.4" class="ltx_glossaryentry"><span id="Sx1.4.4.4.1.1" class="ltx_text" style="font-size:80%;">ASR</span></dt>
<dd><span id="Sx1.4.4.4.4.1" class="ltx_text" style="font-size:80%;">automatic speech recognition</span></dd>
<dt id="Sx1.5.5.5" class="ltx_glossaryentry"><span id="Sx1.5.5.5.1.1" class="ltx_text" style="font-size:80%;">AST</span></dt>
<dd><span id="Sx1.5.5.5.4.1" class="ltx_text" style="font-size:80%;">audio spectrogram transformer</span></dd>
<dt id="Sx1.6.6.6" class="ltx_glossaryentry"><span id="Sx1.6.6.6.1.1" class="ltx_text" style="font-size:80%;">AT</span></dt>
<dd><span id="Sx1.6.6.6.4.1" class="ltx_text" style="font-size:80%;">audio tagging</span></dd>
<dt id="Sx1.7.7.7" class="ltx_glossaryentry"><span id="Sx1.7.7.7.1.1" class="ltx_text" style="font-size:80%;">CAFT</span></dt>
<dd><span id="Sx1.7.7.7.4.1" class="ltx_text" style="font-size:80%;">client adaptive federated training</span></dd>
<dt id="Sx1.8.8.8" class="ltx_glossaryentry"><span id="Sx1.8.8.8.1.1" class="ltx_text" style="font-size:80%;">CER</span></dt>
<dd><span id="Sx1.8.8.8.4.1" class="ltx_text" style="font-size:80%;">character error rate</span></dd>
<dt id="Sx1.9.9.9" class="ltx_glossaryentry"><span id="Sx1.9.9.9.1.1" class="ltx_text" style="font-size:80%;">CNN</span></dt>
<dd><span id="Sx1.9.9.9.4.1" class="ltx_text" style="font-size:80%;">convolutional neural network</span></dd>
<dt id="Sx1.10.10.10" class="ltx_glossaryentry"><span id="Sx1.10.10.10.1.1" class="ltx_text" style="font-size:80%;">CS</span></dt>
<dd><span id="Sx1.10.10.10.4.1" class="ltx_text" style="font-size:80%;">code-switching</span></dd>
<dt id="Sx1.11.11.11" class="ltx_glossaryentry"><span id="Sx1.11.11.11.1.1" class="ltx_text" style="font-size:80%;">CTC</span></dt>
<dd><span id="Sx1.11.11.11.4.1" class="ltx_text" style="font-size:80%;">connectionist temporal classification</span></dd>
<dt id="Sx1.12.12.12" class="ltx_glossaryentry"><span id="Sx1.12.12.12.1.1" class="ltx_text" style="font-size:80%;">CV</span></dt>
<dd><span id="Sx1.12.12.12.4.1" class="ltx_text" style="font-size:80%;">computer vision</span></dd>
<dt id="Sx1.13.13.13" class="ltx_glossaryentry"><span id="Sx1.13.13.13.1.1" class="ltx_text" style="font-size:80%;">DA</span></dt>
<dd><span id="Sx1.13.13.13.4.1" class="ltx_text" style="font-size:80%;">domain adaptation</span></dd>
<dt id="Sx1.14.14.14" class="ltx_glossaryentry"><span id="Sx1.14.14.14.1.1" class="ltx_text" style="font-size:80%;">DL</span></dt>
<dd><span id="Sx1.14.14.14.4.1" class="ltx_text" style="font-size:80%;">deep learning</span></dd>
<dt id="Sx1.15.15.15" class="ltx_glossaryentry"><span id="Sx1.15.15.15.1.1" class="ltx_text" style="font-size:80%;">DRL</span></dt>
<dd><span id="Sx1.15.15.15.4.1" class="ltx_text" style="font-size:80%;">deep reinforcement learning</span></dd>
<dt id="Sx1.16.16.16" class="ltx_glossaryentry"><span id="Sx1.16.16.16.1.1" class="ltx_text" style="font-size:80%;">DTL</span></dt>
<dd><span id="Sx1.16.16.16.4.1" class="ltx_text" style="font-size:80%;">deep transfer learning</span></dd>
<dt id="Sx1.17.17.17" class="ltx_glossaryentry"><span id="Sx1.17.17.17.1.1" class="ltx_text" style="font-size:80%;">ED</span></dt>
<dd><span id="Sx1.17.17.17.4.1" class="ltx_text" style="font-size:80%;">event detection</span></dd>
<dt id="Sx1.18.18.18" class="ltx_glossaryentry"><span id="Sx1.18.18.18.1.1" class="ltx_text" style="font-size:80%;">FCF</span></dt>
<dd><span id="Sx1.18.18.18.4.1" class="ltx_text" style="font-size:80%;">feature correlation-based fusion</span></dd>
<dt id="Sx1.19.19.19" class="ltx_glossaryentry"><span id="Sx1.19.19.19.1.1" class="ltx_text" style="font-size:80%;">FedNST</span></dt>
<dd><span id="Sx1.19.19.19.4.1" class="ltx_text" style="font-size:80%;">federated noisy student training</span></dd>
<dt id="Sx1.20.20.20" class="ltx_glossaryentry"><span id="Sx1.20.20.20.1.1" class="ltx_text" style="font-size:80%;">FL</span></dt>
<dd><span id="Sx1.20.20.20.4.1" class="ltx_text" style="font-size:80%;">federated learning</span></dd>
<dt id="Sx1.21.21.21" class="ltx_glossaryentry"><span id="Sx1.21.21.21.1.1" class="ltx_text" style="font-size:80%;">FR</span></dt>
<dd><span id="Sx1.21.21.21.4.1" class="ltx_text" style="font-size:80%;">form recognition</span></dd>
<dt id="Sx1.22.22.22" class="ltx_glossaryentry"><span id="Sx1.22.22.22.1.1" class="ltx_text" style="font-size:80%;">HMI</span></dt>
<dd><span id="Sx1.22.22.22.4.1" class="ltx_text" style="font-size:80%;">human-machine interaction</span></dd>
<dt id="Sx1.23.23.23" class="ltx_glossaryentry"><span id="Sx1.23.23.23.1.1" class="ltx_text" style="font-size:80%;">HMM</span></dt>
<dd><span id="Sx1.23.23.23.4.1" class="ltx_text" style="font-size:80%;">hidden Markov models</span></dd>
<dt id="Sx1.24.24.24" class="ltx_glossaryentry"><span id="Sx1.24.24.24.1.1" class="ltx_text" style="font-size:80%;">LM</span></dt>
<dd><span id="Sx1.24.24.24.4.1" class="ltx_text" style="font-size:80%;">language model</span></dd>
<dt id="Sx1.25.25.25" class="ltx_glossaryentry"><span id="Sx1.25.25.25.1.1" class="ltx_text" style="font-size:80%;">LPC</span></dt>
<dd><span id="Sx1.25.25.25.4.1" class="ltx_text" style="font-size:80%;">linear predictive coding</span></dd>
<dt id="Sx1.26.26.26" class="ltx_glossaryentry"><span id="Sx1.26.26.26.1.1" class="ltx_text" style="font-size:80%;">LSTM</span></dt>
<dd><span id="Sx1.26.26.26.4.1" class="ltx_text" style="font-size:80%;">long short term memory</span></dd>
<dt id="Sx1.27.27.27" class="ltx_glossaryentry"><span id="Sx1.27.27.27.1.1" class="ltx_text" style="font-size:80%;">mAP</span></dt>
<dd><span id="Sx1.27.27.27.4.1" class="ltx_text" style="font-size:80%;">mean average precision</span></dd>
<dt id="Sx1.28.28.28" class="ltx_glossaryentry"><span id="Sx1.28.28.28.1.1" class="ltx_text" style="font-size:80%;">MFCC</span></dt>
<dd><span id="Sx1.28.28.28.4.1" class="ltx_text" style="font-size:80%;">Mel-frequency cepstral coefficient</span></dd>
<dt id="Sx1.29.29.29" class="ltx_glossaryentry"><span id="Sx1.29.29.29.1.1" class="ltx_text" style="font-size:80%;">MHSA</span></dt>
<dd><span id="Sx1.29.29.29.4.1" class="ltx_text" style="font-size:80%;">multi-head self-attention</span></dd>
<dt id="Sx1.30.30.30" class="ltx_glossaryentry"><span id="Sx1.30.30.30.1.1" class="ltx_text" style="font-size:80%;">ML</span></dt>
<dd><span id="Sx1.30.30.30.4.1" class="ltx_text" style="font-size:80%;">machine learning</span></dd>
<dt id="Sx1.31.31.31" class="ltx_glossaryentry"><span id="Sx1.31.31.31.1.1" class="ltx_text" style="font-size:80%;">NLP</span></dt>
<dd><span id="Sx1.31.31.31.4.1" class="ltx_text" style="font-size:80%;">natural language processing</span></dd>
<dt id="Sx1.32.32.32" class="ltx_glossaryentry"><span id="Sx1.32.32.32.1.1" class="ltx_text" style="font-size:80%;">NT</span></dt>
<dd><span id="Sx1.32.32.32.4.1" class="ltx_text" style="font-size:80%;">negative transfer</span></dd>
<dt id="Sx1.33.33.33" class="ltx_glossaryentry"><span id="Sx1.33.33.33.1.1" class="ltx_text" style="font-size:80%;">PESQ</span></dt>
<dd><span id="Sx1.33.33.33.4.1" class="ltx_text" style="font-size:80%;">perceptual evaluation of speech quality</span></dd>
<dt id="Sx1.34.34.34" class="ltx_glossaryentry"><span id="Sx1.34.34.34.1.1" class="ltx_text" style="font-size:80%;">RER</span></dt>
<dd><span id="Sx1.34.34.34.4.1" class="ltx_text" style="font-size:80%;">relative error rate</span></dd>
<dt id="Sx1.35.35.35" class="ltx_glossaryentry"><span id="Sx1.35.35.35.1.1" class="ltx_text" style="font-size:80%;">RL</span></dt>
<dd><span id="Sx1.35.35.35.4.1" class="ltx_text" style="font-size:80%;">reinforcement learning</span></dd>
<dt id="Sx1.36.36.36" class="ltx_glossaryentry"><span id="Sx1.36.36.36.1.1" class="ltx_text" style="font-size:80%;">RNN</span></dt>
<dd><span id="Sx1.36.36.36.4.1" class="ltx_text" style="font-size:80%;">recurrent neural network</span></dd>
<dt id="Sx1.37.37.37" class="ltx_glossaryentry"><span id="Sx1.37.37.37.1.1" class="ltx_text" style="font-size:80%;">RTF</span></dt>
<dd><span id="Sx1.37.37.37.4.1" class="ltx_text" style="font-size:80%;">real-time factor</span></dd>
<dt id="Sx1.38.38.38" class="ltx_glossaryentry"><span id="Sx1.38.38.38.1.1" class="ltx_text" style="font-size:80%;">S2S</span></dt>
<dd><span id="Sx1.38.38.38.4.1" class="ltx_text" style="font-size:80%;">sequence-to-sequence</span></dd>
<dt id="Sx1.39.39.39" class="ltx_glossaryentry"><span id="Sx1.39.39.39.1.1" class="ltx_text" style="font-size:80%;">S2S</span></dt>
<dd><span id="Sx1.39.39.39.4.1" class="ltx_text" style="font-size:80%;">sequence-to-sequence</span></dd>
<dt id="Sx1.40.40.40" class="ltx_glossaryentry"><span id="Sx1.40.40.40.1.1" class="ltx_text" style="font-size:80%;">SD</span></dt>
<dd><span id="Sx1.40.40.40.4.1" class="ltx_text" style="font-size:80%;">source domain</span></dd>
<dt id="Sx1.41.41.41" class="ltx_glossaryentry"><span id="Sx1.41.41.41.1.1" class="ltx_text" style="font-size:80%;">SER</span></dt>
<dd><span id="Sx1.41.41.41.4.1" class="ltx_text" style="font-size:80%;">speech emotion recognition</span></dd>
<dt id="Sx1.42.42.42" class="ltx_glossaryentry"><span id="Sx1.42.42.42.1.1" class="ltx_text" style="font-size:80%;">SM</span></dt>
<dd><span id="Sx1.42.42.42.4.1" class="ltx_text" style="font-size:80%;">semantic model</span></dd>
<dt id="Sx1.43.43.43" class="ltx_glossaryentry"><span id="Sx1.43.43.43.1.1" class="ltx_text" style="font-size:80%;">SNR</span></dt>
<dd><span id="Sx1.43.43.43.4.1" class="ltx_text" style="font-size:80%;">signal-to-noise ratio</span></dd>
<dt id="Sx1.44.44.44" class="ltx_glossaryentry"><span id="Sx1.44.44.44.1.1" class="ltx_text" style="font-size:80%;">SOTA</span></dt>
<dd><span id="Sx1.44.44.44.4.1" class="ltx_text" style="font-size:80%;">state-of-the-art</span></dd>
<dt id="Sx1.45.45.45" class="ltx_glossaryentry"><span id="Sx1.45.45.45.1.1" class="ltx_text" style="font-size:80%;">SS</span></dt>
<dd><span id="Sx1.45.45.45.4.1" class="ltx_text" style="font-size:80%;">speech security</span></dd>
<dt id="Sx1.46.46.46" class="ltx_glossaryentry"><span id="Sx1.46.46.46.1.1" class="ltx_text" style="font-size:80%;">SSAST</span></dt>
<dd><span id="Sx1.46.46.46.4.1" class="ltx_text" style="font-size:80%;">self-supervised audio spectrogram transformer</span></dd>
<dt id="Sx1.47.47.47" class="ltx_glossaryentry"><span id="Sx1.47.47.47.1.1" class="ltx_text" style="font-size:80%;">SWBD</span></dt>
<dd><span id="Sx1.47.47.47.4.1" class="ltx_text" style="font-size:80%;">switchboard</span></dd>
<dt id="Sx1.48.48.48" class="ltx_glossaryentry"><span id="Sx1.48.48.48.1.1" class="ltx_text" style="font-size:80%;">TD</span></dt>
<dd><span id="Sx1.48.48.48.4.1" class="ltx_text" style="font-size:80%;">target domain</span></dd>
<dt id="Sx1.49.49.49" class="ltx_glossaryentry"><span id="Sx1.49.49.49.1.1" class="ltx_text" style="font-size:80%;">TNR</span></dt>
<dd><span id="Sx1.49.49.49.4.1" class="ltx_text" style="font-size:80%;">true negative rate</span></dd>
<dt id="Sx1.50.50.50" class="ltx_glossaryentry"><span id="Sx1.50.50.50.1.1" class="ltx_text" style="font-size:80%;">TPR</span></dt>
<dd><span id="Sx1.50.50.50.4.1" class="ltx_text" style="font-size:80%;">true positive rate</span></dd>
<dt id="Sx1.51.51.51" class="ltx_glossaryentry"><span id="Sx1.51.51.51.1.1" class="ltx_text" style="font-size:80%;">TRUNet</span></dt>
<dd><span id="Sx1.51.51.51.4.1" class="ltx_text" style="font-size:80%;">transformer-recurrent-U network</span></dd>
<dt id="Sx1.52.52.52" class="ltx_glossaryentry"><span id="Sx1.52.52.52.1.1" class="ltx_text" style="font-size:80%;">WER</span></dt>
<dd><span id="Sx1.52.52.52.4.1" class="ltx_text" style="font-size:80%;">word error rate</span></dd>
<dt id="Sx1.53.53.53" class="ltx_glossaryentry"><span id="Sx1.53.53.53.1.1" class="ltx_text" style="font-size:80%;">WSJ</span></dt>
<dd><span id="Sx1.53.53.53.4.1" class="ltx_text" style="font-size:80%;">wall street journal</span></dd>
<dt id="Sx1.54.54.54" class="ltx_glossaryentry"><span id="Sx1.54.54.54.1.1" class="ltx_text" style="font-size:80%;">GAN</span></dt>
<dd><span id="Sx1.54.54.54.4.1" class="ltx_text" style="font-size:80%;">generative adversarial network</span></dd>
<dt id="Sx1.55.55.55" class="ltx_glossaryentry"><span id="Sx1.55.55.55.1.1" class="ltx_text" style="font-size:80%;">MTL</span></dt>
<dd><span id="Sx1.55.55.55.4.1" class="ltx_text" style="font-size:80%;">multitask learning</span></dd>
<dt id="Sx1.56.56.56" class="ltx_glossaryentry"><span id="Sx1.56.56.56.1.1" class="ltx_text" style="font-size:80%;">FMTL</span></dt>
<dd><span id="Sx1.56.56.56.4.1" class="ltx_text" style="font-size:80%;">federated multi-task learning</span></dd>
<dt id="Sx1.57.57.57" class="ltx_glossaryentry"><span id="Sx1.57.57.57.1.1" class="ltx_text" style="font-size:80%;">DSLM</span></dt>
<dd><span id="Sx1.57.57.57.4.1" class="ltx_text" style="font-size:80%;">domain-specific language modeling</span></dd>
<dt id="Sx1.58.58.58" class="ltx_glossaryentry"><span id="Sx1.58.58.58.1.1" class="ltx_text" style="font-size:80%;">LLM</span></dt>
<dd><span id="Sx1.58.58.58.4.1" class="ltx_text" style="font-size:80%;">large language model</span></dd>
<dt id="Sx1.59.59.59" class="ltx_glossaryentry"><span id="Sx1.59.59.59.1.1" class="ltx_text" style="font-size:80%;">DDQN</span></dt>
<dd><span id="Sx1.59.59.59.4.1" class="ltx_text" style="font-size:80%;">double deep Q-network</span></dd>
<dt id="Sx1.60.60.60" class="ltx_glossaryentry"><span id="Sx1.60.60.60.1.1" class="ltx_text" style="font-size:80%;">AC</span></dt>
<dd><span id="Sx1.60.60.60.4.1" class="ltx_text" style="font-size:80%;">actor-critic</span></dd>
<dt id="Sx1.61.61.61" class="ltx_glossaryentry"><span id="Sx1.61.61.61.1.1" class="ltx_text" style="font-size:80%;">SARSA</span></dt>
<dd><span id="Sx1.61.61.61.4.1" class="ltx_text" style="font-size:80%;">State–action–reward–state–action</span></dd>
<dt id="Sx1.62.62.62" class="ltx_glossaryentry"><span id="Sx1.62.62.62.1.1" class="ltx_text" style="font-size:80%;">DDPG</span></dt>
<dd><span id="Sx1.62.62.62.4.1" class="ltx_text" style="font-size:80%;">deep deterministic policy gradien</span></dd>
</dl>
</section>
<div class="ltx_pagination ltx_role_end_3_columns"></div>
</section>
</figure>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Recent advancements in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> have been significantly propelled by the evolution of  <a href="#Sx1.14.14.14"><span href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">deep learning</span></span></span></a> (<a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a>) methodologies. An extensive range of <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> models has been developed, demonstrating remarkable improvements and surpassing former <a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a> achievements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">16</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">17</span></a>]</cite>. Transformers, a notable innovation within these <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> approaches, have become a cornerstone in advancing various <a href="#Sx1.31.31.31"><abbr href="#Sx1.31.31.31" title="natural language processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">NLP</span></span></abbr></a> tasks, including <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. Initially conceptualized for  <a href="#Sx1.39.39.39"><span href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">sequence-to-sequence</span></span></span></a> (<a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a>) applications in <a href="#Sx1.31.31.31"><abbr href="#Sx1.31.31.31" title="natural language processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">NLP</span></span></abbr></a>, their success is largely attributed to their adeptness at discerning long-range dependencies and complex patterns within sequential data. A hallmark of transformer models is their utilization of an attention mechanism, which precisely focuses on specific portions of the input sequence during prediction tasks. This mechanism is particularly effective in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, facilitating the detailed modeling of contextual nuances and the interconnections among acoustic signals, essential for accurate transcription. Models such as the Transformer Transducer, Conformer, and ESPnet, leveraging self-attention and parallel processing, have achieved leading performance in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> tasks. Their robustness across diverse languages further underscores their capability to adapt to a wide range of linguistic features and acoustic variations, making transformers an exceptionally promising option for enhancing <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems, surpassing the constraints of conventional models.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">The integration of <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> with its variants in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> introduces substantial challenges, especially concerning its application in natural <a href="#Sx1.22.22.22"><abbr href="#Sx1.22.22.22" title="human-machine interaction" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">HMI</span></span></abbr></a>. Despite <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a>’s numerous advantages, it encounters various obstacles. The inherent complexity of <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> models, which stems from their need for extensive training data to attain high performance, demands significant computational and storage resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">18</span></a>]</cite>. Moreover, the issue of data scarcity in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> reflects the inadequate quantities of training data available for exploiting complex <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> algorithms effectively <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">19</span></a>]</cite>.
The paucity of annotated data further complicates the development of supervised <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a>-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> models. Additionally, the presumption that training and testing datasets originate from the same domain, possessing identical feature spaces and distribution characteristics, is often misguided. This mismatch challenges the practical deployment of <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> models in real-world settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">20</span></a>]</cite>.
Thus, the performance of <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> models may be compromised when faced with limited training datasets or discrepancies in data distribution between training and testing environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">21</span></a>]</cite>. These challenges highlight the critical need for adaptive methodologies and improved data management approaches to fully harness the capabilities of <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems.</p>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p id="S1.SS1.p4.1" class="ltx_p">In an effort to address existing challenges and increase the robustness and flexibility of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems, novel <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> methodologies have been introduced. These include  <a href="#Sx1.16.16.16"><span href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">deep transfer learning</span></span></span></a> (<a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a>),  <a href="#Sx1.15.15.15"><span href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">deep reinforcement learning</span></span></span></a> (<a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a>), and  <a href="#Sx1.20.20.20"><span href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">federated learning</span></span></span></a> (<a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a>), which collectively aim at overcoming difficulties related to the transfer of knowledge, enhancing the generalization capabilities of models, and optimizing training processes. These innovative approaches significantly broaden the operational scope of conventional <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> frameworks within the <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> field.</p>
</div>
<div id="S1.SS1.p5" class="ltx_para">
<p id="S1.SS1.p5.1" class="ltx_p">Figure <a href="#Sx1.F1" title="Figure 1 ‣ 1.1 Preliminary ‣ 1 Introduction ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> highlights critical areas in speech processing where <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a>, <a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a>, and <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a> can be applied.
Consequently, domains such as <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, speech enhancement (SE), hate speech detection (HSD), and  <a href="#Sx1.45.45.45"><span href="#Sx1.45.45.45" title="speech security" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">speech security</span></span></span></a> (<a href="#Sx1.45.45.45"><abbr href="#Sx1.45.45.45" title="speech security" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SS</span></span></abbr></a>) are closely interconnected.
<a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> provides acoustic parameters to <a href="#Sx1.31.31.31"><abbr href="#Sx1.31.31.31" title="natural language processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">NLP</span></span></abbr></a> for HSD task, which in turn provides semantic details to <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. Additionally, <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> can be employed in the SS domain as a steganalytic process to verify the integrity of speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">4</span></a>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">22</span></a>]</cite>. Furthermore, <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> and SE can mutually offer performance feedback.</p>
</div>
<figure id="Sx1.F1" class="ltx_figure"><img src="/html/2403.01255/assets/x1.png" id="Sx1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="297" height="166" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="Sx1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="Sx1.F1.3.2" class="ltx_text" style="font-size:90%;"> Summary of critical areas in speech processing where <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a>, DRL, FL, and transformers can be applied. </span></figcaption>
</figure>
</section>
<section id="Sx1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Contribution of the paper</h3>

<div id="Sx1.SS2.p1" class="ltx_para">
<p id="Sx1.SS2.p1.1" class="ltx_p">This article offers an extensive examination of contemporary frameworks within advanced deep learning approaches, spanning the period from 2016 to 2023. These approaches include <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a>, <a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a>, <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a>, and Transformers, all within the context of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. To the best of the authors’ knowledge, there has been no prior research paper that has intricately explored and critically evaluated contributions in the aforementioned advanced DL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> until now.</p>
</div>
<div id="Sx1.SS2.p2" class="ltx_para">
<p id="Sx1.SS2.p2.1" class="ltx_p">In recent years, numerous survey papers have been published to assess various aspects of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> models. Some of these surveys concentrate on specific languages, such as Portuguese <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">23</span></a>]</cite>, Indian <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">24</span></a>]</cite>, Turkish <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">25</span></a>]</cite>, Arabic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">26</span></a>]</cite> and tonal languages (including Asian, Indo-European and African) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">27</span></a>]</cite>. Additionally, Abushariah et al.’s review emphasizes bilingual ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">28</span></a>]</cite>. On the non-specific language review front, specific areas within ASR have been targeted, including ASR using limited vocabulary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">29</span></a>]</cite>, ASR for children <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">30</span></a>]</cite>, error detection and correction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">31</span></a>]</cite>, and unsupervised ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">32</span></a>]</cite>. Systematic reviews with a focus on neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">33</span></a>]</cite> and deep neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">34</span></a>]</cite> have also been proposed. In another comprehensive review, Malik et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">35</span></a>]</cite> discussed diverse feature extraction methods, <a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a> classification models, and some deep learning approaches. Recently, the authors presented an ASR review focused on DTL for ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">36</span></a>]</cite>. Table <a href="#Sx1.T1" title="Table 1 ‣ 1.2 Contribution of the paper ‣ 1 Introduction ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents a summary of the main contributions of the proposed ASR review compared to other existing ASR reviews/surveys.</p>
</div>
<div id="Sx1.SS2.p3" class="ltx_para">
<p id="Sx1.SS2.p3.1" class="ltx_p">This survey article offers several significant enhancements and additions compared to previous ASR surveys. Firstly, it consolidates works that utilize both ASR and advanced DL approaches, providing a comprehensive overview of their intersection. Secondly, it provides performance evaluation results of all considered approaches. Thirdly, it includes metrics and dataset reviews used in ASR models. Furthermore, it tackles ongoing challenges and consequently proposes future directions. The main contributions of this article can be summarized as follows:</p>
</div>
<div id="Sx1.SS2.p4" class="ltx_para">
<ul id="Sx1.I1" class="ltx_itemize">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.p1.1" class="ltx_p">Presenting the background of advanced DL techniques including DTL, DRL, FL and transformers.
Describing the evaluation metrics and datasets employed for validating <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> approaches.</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.p1.1" class="ltx_p">Introducing a well-defined taxonomy categorizing <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> methodologies based on the domains of <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> and <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a>.</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.p1.1" class="ltx_p">Identifying challenges and gaps in advanced DL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>.</p>
</div>
</li>
<li id="Sx1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i4.p1" class="ltx_para">
<p id="Sx1.I1.i4.p1.1" class="ltx_p">Proposing future directions to enhance the performance of advanced DL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> solutions and predicting the potential advancements in the field.</p>
</div>
</li>
</ul>
</div>
<figure id="Sx1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="Sx1.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="Sx1.T1.4.2" class="ltx_text" style="font-size:90%;">Contribution comparison of the proposed contribution against other hand ASR review. The tick mark (✓) indicates that the specific field has been
addressed, whereas the cross mark (<span id="Sx1.T1.4.2.1" class="ltx_text">✗</span>) means addressing the specific fields has been missed.</span></figcaption>
<table id="Sx1.T1.5" class="ltx_tabular ltx_align_middle">
<tr id="Sx1.T1.5.1" class="ltx_tr">
<td id="Sx1.T1.5.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="Sx1.T1.5.1.1.1" class="ltx_text" style="font-size:70%;">Refs</span></td>
<td id="Sx1.T1.5.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="Sx1.T1.5.1.2.1" class="ltx_text" style="font-size:70%;">Year</span></td>
<td id="Sx1.T1.5.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="Sx1.T1.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.1.3.1.1" class="ltx_p"><span id="Sx1.T1.5.1.3.1.1.1" class="ltx_text" style="font-size:70%;">Description of the survey/review</span></span>
</span>
</td>
<td id="Sx1.T1.5.1.4" class="ltx_td ltx_align_center ltx_align_middle ltx_border_t" colspan="4"><span id="Sx1.T1.5.1.4.1" class="ltx_text" style="font-size:70%;">Advanced DL methods</span></td>
<td id="Sx1.T1.5.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="Sx1.T1.5.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.1.5.1.1" class="ltx_p"><span id="Sx1.T1.5.1.5.1.1.1" class="ltx_text" style="font-size:70%;">Performances</span></span>
</span>
</td>
<td id="Sx1.T1.5.1.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:28.5pt;">
<span id="Sx1.T1.5.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.1.6.1.1" class="ltx_p"><span id="Sx1.T1.5.1.6.1.1.1" class="ltx_text" style="font-size:70%;">Metrics</span></span>
</span>
</td>
<td id="Sx1.T1.5.1.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:28.5pt;">
<span id="Sx1.T1.5.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.1.7.1.1" class="ltx_p"><span id="Sx1.T1.5.1.7.1.1.1" class="ltx_text" style="font-size:70%;">Dataset</span></span>
</span>
</td>
<td id="Sx1.T1.5.1.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="Sx1.T1.5.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.1.8.1.1" class="ltx_p"><span id="Sx1.T1.5.1.8.1.1.1" class="ltx_text" style="font-size:70%;">Current</span></span>
</span>
</td>
<td id="Sx1.T1.5.1.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:37.0pt;">
<span id="Sx1.T1.5.1.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.1.9.1.1" class="ltx_p"><span id="Sx1.T1.5.1.9.1.1.1" class="ltx_text" style="font-size:70%;">Future</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.2" class="ltx_tr">
<td id="Sx1.T1.5.2.1" class="ltx_td"></td>
<td id="Sx1.T1.5.2.2" class="ltx_td"></td>
<td id="Sx1.T1.5.2.3" class="ltx_td ltx_align_middle" style="width:113.8pt;"></td>
<td id="Sx1.T1.5.2.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="Sx1.T1.5.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.2.4.1.1" class="ltx_p"><span id="Sx1.T1.5.2.4.1.1.1" class="ltx_text" style="font-size:70%;">DRL</span></span>
</span>
</td>
<td id="Sx1.T1.5.2.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="Sx1.T1.5.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.2.5.1.1" class="ltx_p"><span id="Sx1.T1.5.2.5.1.1.1" class="ltx_text" style="font-size:70%;">FL</span></span>
</span>
</td>
<td id="Sx1.T1.5.2.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="Sx1.T1.5.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.2.6.1.1" class="ltx_p"><span id="Sx1.T1.5.2.6.1.1.1" class="ltx_text" style="font-size:70%;">TL</span></span>
</span>
</td>
<td id="Sx1.T1.5.2.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="Sx1.T1.5.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.2.7.1.1" class="ltx_p"><span id="Sx1.T1.5.2.7.1.1.1" class="ltx_text" style="font-size:70%;">Transf.</span></span>
</span>
</td>
<td id="Sx1.T1.5.2.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.2.8.1.1" class="ltx_p"><span id="Sx1.T1.5.2.8.1.1.1" class="ltx_text" style="font-size:70%;">evaluation</span></span>
</span>
</td>
<td id="Sx1.T1.5.2.9" class="ltx_td ltx_align_middle" style="width:28.5pt;"></td>
<td id="Sx1.T1.5.2.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.2.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.2.10.1.1" class="ltx_p"><span id="Sx1.T1.5.2.10.1.1.1" class="ltx_text" style="font-size:70%;">review</span></span>
</span>
</td>
<td id="Sx1.T1.5.2.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.2.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.2.11.1.1" class="ltx_p"><span id="Sx1.T1.5.2.11.1.1.1" class="ltx_text" style="font-size:70%;">challe/Gaps</span></span>
</span>
</td>
<td id="Sx1.T1.5.2.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.2.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.2.12.1.1" class="ltx_p"><span id="Sx1.T1.5.2.12.1.1.1" class="ltx_text" style="font-size:70%;">directions</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.3" class="ltx_tr">
<td id="Sx1.T1.5.3.1" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.3.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">31</span></a><span id="Sx1.T1.5.3.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="Sx1.T1.5.3.2.1" class="ltx_text" style="font-size:70%;">2018</span></td>
<td id="Sx1.T1.5.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="Sx1.T1.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.3.1.1" class="ltx_p"><span id="Sx1.T1.5.3.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR review for error errors detection and correction</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="Sx1.T1.5.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.4.1.1" class="ltx_p"><span id="Sx1.T1.5.3.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="Sx1.T1.5.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.5.1.1" class="ltx_p"><span id="Sx1.T1.5.3.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="Sx1.T1.5.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.6.1.1" class="ltx_p"><span id="Sx1.T1.5.3.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:14.2pt;">
<span id="Sx1.T1.5.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.7.1.1" class="ltx_p"><span id="Sx1.T1.5.3.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="Sx1.T1.5.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.8.1.1" class="ltx_p"><span id="Sx1.T1.5.3.8.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:28.5pt;">
<span id="Sx1.T1.5.3.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.9.1.1" class="ltx_p"><span id="Sx1.T1.5.3.9.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:28.5pt;">
<span id="Sx1.T1.5.3.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.10.1.1" class="ltx_p"><span id="Sx1.T1.5.3.10.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="Sx1.T1.5.3.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.11.1.1" class="ltx_p"><span id="Sx1.T1.5.3.11.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.3.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:37.0pt;">
<span id="Sx1.T1.5.3.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.3.12.1.1" class="ltx_p"><span id="Sx1.T1.5.3.12.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.4" class="ltx_tr">
<td id="Sx1.T1.5.4.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.4.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">34</span></a><span id="Sx1.T1.5.4.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.4.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.4.2.1" class="ltx_text" style="font-size:70%;">2019</span></td>
<td id="Sx1.T1.5.4.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.3.1.1" class="ltx_p"><span id="Sx1.T1.5.4.3.1.1.1" class="ltx_text" style="font-size:70%;">Systematic review on DL-based speech recognition</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.4.1.1" class="ltx_p"><span id="Sx1.T1.5.4.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.5.1.1" class="ltx_p"><span id="Sx1.T1.5.4.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.6.1.1" class="ltx_p"><span id="Sx1.T1.5.4.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.7.1.1" class="ltx_p"><span id="Sx1.T1.5.4.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.8.1.1" class="ltx_p"><span id="Sx1.T1.5.4.8.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.4.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.9.1.1" class="ltx_p"><span id="Sx1.T1.5.4.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.4.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.10.1.1" class="ltx_p"><span id="Sx1.T1.5.4.10.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.4.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.11.1.1" class="ltx_p"><span id="Sx1.T1.5.4.11.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.4.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.4.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.4.12.1.1" class="ltx_p"><span id="Sx1.T1.5.4.12.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.5" class="ltx_tr">
<td id="Sx1.T1.5.5.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.5.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">24</span></a><span id="Sx1.T1.5.5.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.5.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.5.2.1" class="ltx_text" style="font-size:70%;">2020</span></td>
<td id="Sx1.T1.5.5.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.3.1.1" class="ltx_p"><span id="Sx1.T1.5.5.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR survey for Indian languages</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.4.1.1" class="ltx_p"><span id="Sx1.T1.5.5.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.5.1.1" class="ltx_p"><span id="Sx1.T1.5.5.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.6.1.1" class="ltx_p"><span id="Sx1.T1.5.5.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.7.1.1" class="ltx_p"><span id="Sx1.T1.5.5.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.8.1.1" class="ltx_p"><span id="Sx1.T1.5.5.8.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.5.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.9.1.1" class="ltx_p"><span id="Sx1.T1.5.5.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.5.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.10.1.1" class="ltx_p"><span id="Sx1.T1.5.5.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.5.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.11.1.1" class="ltx_p"><span id="Sx1.T1.5.5.11.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.5.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.5.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.5.12.1.1" class="ltx_p"><span id="Sx1.T1.5.5.12.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.6" class="ltx_tr">
<td id="Sx1.T1.5.6.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.6.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">23</span></a><span id="Sx1.T1.5.6.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.6.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.6.2.1" class="ltx_text" style="font-size:70%;">2020</span></td>
<td id="Sx1.T1.5.6.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.3.1.1" class="ltx_p"><span id="Sx1.T1.5.6.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR survey for Portuguese language</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.4.1.1" class="ltx_p"><span id="Sx1.T1.5.6.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.5.1.1" class="ltx_p"><span id="Sx1.T1.5.6.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.6.1.1" class="ltx_p"><span id="Sx1.T1.5.6.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.7.1.1" class="ltx_p"><span id="Sx1.T1.5.6.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.8.1.1" class="ltx_p"><span id="Sx1.T1.5.6.8.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.6.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.9.1.1" class="ltx_p"><span id="Sx1.T1.5.6.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.6.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.10.1.1" class="ltx_p"><span id="Sx1.T1.5.6.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.6.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.11.1.1" class="ltx_p"><span id="Sx1.T1.5.6.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.6.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.6.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.6.12.1.1" class="ltx_p"><span id="Sx1.T1.5.6.12.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.7" class="ltx_tr">
<td id="Sx1.T1.5.7.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.7.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">25</span></a><span id="Sx1.T1.5.7.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.7.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.7.2.1" class="ltx_text" style="font-size:70%;">2020</span></td>
<td id="Sx1.T1.5.7.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.3.1.1" class="ltx_p"><span id="Sx1.T1.5.7.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR survey for Turkich language</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.4.1.1" class="ltx_p"><span id="Sx1.T1.5.7.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.5.1.1" class="ltx_p"><span id="Sx1.T1.5.7.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.6.1.1" class="ltx_p"><span id="Sx1.T1.5.7.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.7.1.1" class="ltx_p"><span id="Sx1.T1.5.7.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.8.1.1" class="ltx_p"><span id="Sx1.T1.5.7.8.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.7.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.9.1.1" class="ltx_p"><span id="Sx1.T1.5.7.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.7.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.10.1.1" class="ltx_p"><span id="Sx1.T1.5.7.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.7.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.11.1.1" class="ltx_p"><span id="Sx1.T1.5.7.11.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.7.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.7.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.7.12.1.1" class="ltx_p"><span id="Sx1.T1.5.7.12.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.8" class="ltx_tr">
<td id="Sx1.T1.5.8.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.8.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">35</span></a><span id="Sx1.T1.5.8.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.8.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.8.2.1" class="ltx_text" style="font-size:70%;">2021</span></td>
<td id="Sx1.T1.5.8.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.3.1.1" class="ltx_p"><span id="Sx1.T1.5.8.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR survey</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.4.1.1" class="ltx_p"><span id="Sx1.T1.5.8.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.5.1.1" class="ltx_p"><span id="Sx1.T1.5.8.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.6.1.1" class="ltx_p"><span id="Sx1.T1.5.8.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.7.1.1" class="ltx_p"><span id="Sx1.T1.5.8.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.8.1.1" class="ltx_p"><span id="Sx1.T1.5.8.8.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.8.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.9.1.1" class="ltx_p"><span id="Sx1.T1.5.8.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.8.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.10.1.1" class="ltx_p"><span id="Sx1.T1.5.8.10.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.8.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.11.1.1" class="ltx_p"><span id="Sx1.T1.5.8.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.8.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.8.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.8.12.1.1" class="ltx_p"><span id="Sx1.T1.5.8.12.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.9" class="ltx_tr">
<td id="Sx1.T1.5.9.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.9.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">27</span></a><span id="Sx1.T1.5.9.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.9.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.9.2.1" class="ltx_text" style="font-size:70%;">2021</span></td>
<td id="Sx1.T1.5.9.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.3.1.1" class="ltx_p"><span id="Sx1.T1.5.9.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR survey for tonal languages</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.4.1.1" class="ltx_p"><span id="Sx1.T1.5.9.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.5.1.1" class="ltx_p"><span id="Sx1.T1.5.9.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.6.1.1" class="ltx_p"><span id="Sx1.T1.5.9.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.7.1.1" class="ltx_p"><span id="Sx1.T1.5.9.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.8.1.1" class="ltx_p"><span id="Sx1.T1.5.9.8.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.9.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.9.1.1" class="ltx_p"><span id="Sx1.T1.5.9.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.9.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.10.1.1" class="ltx_p"><span id="Sx1.T1.5.9.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.9.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.11.1.1" class="ltx_p"><span id="Sx1.T1.5.9.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.9.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.9.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.9.12.1.1" class="ltx_p"><span id="Sx1.T1.5.9.12.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.10" class="ltx_tr">
<td id="Sx1.T1.5.10.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.10.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">32</span></a><span id="Sx1.T1.5.10.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.10.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.10.2.1" class="ltx_text" style="font-size:70%;">2022</span></td>
<td id="Sx1.T1.5.10.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.3.1.1" class="ltx_p"><span id="Sx1.T1.5.10.3.1.1.1" class="ltx_text" style="font-size:70%;">Unsupervised ASR review</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.4.1.1" class="ltx_p"><span id="Sx1.T1.5.10.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.5.1.1" class="ltx_p"><span id="Sx1.T1.5.10.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.6.1.1" class="ltx_p"><span id="Sx1.T1.5.10.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.7.1.1" class="ltx_p"><span id="Sx1.T1.5.10.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.8.1.1" class="ltx_p"><span id="Sx1.T1.5.10.8.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.10.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.9.1.1" class="ltx_p"><span id="Sx1.T1.5.10.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.10.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.10.1.1" class="ltx_p"><span id="Sx1.T1.5.10.10.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.10.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.11.1.1" class="ltx_p"><span id="Sx1.T1.5.10.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.10.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.10.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.10.12.1.1" class="ltx_p"><span id="Sx1.T1.5.10.12.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.11" class="ltx_tr">
<td id="Sx1.T1.5.11.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.11.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">30</span></a><span id="Sx1.T1.5.11.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.11.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.11.2.1" class="ltx_text" style="font-size:70%;">2022</span></td>
<td id="Sx1.T1.5.11.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.3.1.1" class="ltx_p"><span id="Sx1.T1.5.11.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR Systematic review for children</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.4.1.1" class="ltx_p"><span id="Sx1.T1.5.11.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.5.1.1" class="ltx_p"><span id="Sx1.T1.5.11.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.6.1.1" class="ltx_p"><span id="Sx1.T1.5.11.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.7.1.1" class="ltx_p"><span id="Sx1.T1.5.11.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.11.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.8.1.1" class="ltx_p"><span id="Sx1.T1.5.11.8.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.11.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.9.1.1" class="ltx_p"><span id="Sx1.T1.5.11.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.11.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.10.1.1" class="ltx_p"><span id="Sx1.T1.5.11.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.11.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.11.1.1" class="ltx_p"><span id="Sx1.T1.5.11.11.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.11.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.11.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.11.12.1.1" class="ltx_p"><span id="Sx1.T1.5.11.12.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.12" class="ltx_tr">
<td id="Sx1.T1.5.12.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.12.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">29</span></a><span id="Sx1.T1.5.12.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.12.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.12.2.1" class="ltx_text" style="font-size:70%;">2022</span></td>
<td id="Sx1.T1.5.12.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.3.1.1" class="ltx_p"><span id="Sx1.T1.5.12.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR survey for limited vocabulary</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.4.1.1" class="ltx_p"><span id="Sx1.T1.5.12.4.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.5.1.1" class="ltx_p"><span id="Sx1.T1.5.12.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.6.1.1" class="ltx_p"><span id="Sx1.T1.5.12.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.7.1.1" class="ltx_p"><span id="Sx1.T1.5.12.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.12.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.8.1.1" class="ltx_p"><span id="Sx1.T1.5.12.8.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.12.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.9.1.1" class="ltx_p"><span id="Sx1.T1.5.12.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.12.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.10.1.1" class="ltx_p"><span id="Sx1.T1.5.12.10.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.12.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.11.1.1" class="ltx_p"><span id="Sx1.T1.5.12.11.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.12.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.12.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.12.12.1.1" class="ltx_p"><span id="Sx1.T1.5.12.12.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.13" class="ltx_tr">
<td id="Sx1.T1.5.13.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.13.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">26</span></a><span id="Sx1.T1.5.13.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.13.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.13.2.1" class="ltx_text" style="font-size:70%;">2022</span></td>
<td id="Sx1.T1.5.13.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.3.1.1" class="ltx_p"><span id="Sx1.T1.5.13.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR Systematic review for Arabic language</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.4.1.1" class="ltx_p"><span id="Sx1.T1.5.13.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.5.1.1" class="ltx_p"><span id="Sx1.T1.5.13.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.6.1.1" class="ltx_p"><span id="Sx1.T1.5.13.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.7.1.1" class="ltx_p"><span id="Sx1.T1.5.13.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.8.1.1" class="ltx_p"><span id="Sx1.T1.5.13.8.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.13.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.9.1.1" class="ltx_p"><span id="Sx1.T1.5.13.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.13.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.10.1.1" class="ltx_p"><span id="Sx1.T1.5.13.10.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.13.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.11.1.1" class="ltx_p"><span id="Sx1.T1.5.13.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.13.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.13.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.13.12.1.1" class="ltx_p"><span id="Sx1.T1.5.13.12.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.14" class="ltx_tr">
<td id="Sx1.T1.5.14.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.14.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">28</span></a><span id="Sx1.T1.5.14.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.14.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.14.2.1" class="ltx_text" style="font-size:70%;">2022</span></td>
<td id="Sx1.T1.5.14.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.3.1.1" class="ltx_p"><span id="Sx1.T1.5.14.3.1.1.1" class="ltx_text" style="font-size:70%;">Bilingual ASR review</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.4.1.1" class="ltx_p"><span id="Sx1.T1.5.14.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.5.1.1" class="ltx_p"><span id="Sx1.T1.5.14.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.6.1.1" class="ltx_p"><span id="Sx1.T1.5.14.6.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.7.1.1" class="ltx_p"><span id="Sx1.T1.5.14.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.14.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.8.1.1" class="ltx_p"><span id="Sx1.T1.5.14.8.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.14.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.9.1.1" class="ltx_p"><span id="Sx1.T1.5.14.9.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.14.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.10.1.1" class="ltx_p"><span id="Sx1.T1.5.14.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.14.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.11.1.1" class="ltx_p"><span id="Sx1.T1.5.14.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.14.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.14.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.14.12.1.1" class="ltx_p"><span id="Sx1.T1.5.14.12.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.15" class="ltx_tr">
<td id="Sx1.T1.5.15.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.15.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">33</span></a><span id="Sx1.T1.5.15.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.15.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.15.2.1" class="ltx_text" style="font-size:70%;">2023</span></td>
<td id="Sx1.T1.5.15.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.3.1.1" class="ltx_p"><span id="Sx1.T1.5.15.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR survey on neural network techniques</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.4.1.1" class="ltx_p"><span id="Sx1.T1.5.15.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.5.1.1" class="ltx_p"><span id="Sx1.T1.5.15.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.6.1.1" class="ltx_p"><span id="Sx1.T1.5.15.6.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.15.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.7.1.1" class="ltx_p"><span id="Sx1.T1.5.15.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.15.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.8.1.1" class="ltx_p"><span id="Sx1.T1.5.15.8.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.15.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.9.1.1" class="ltx_p"><span id="Sx1.T1.5.15.9.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.15.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.10.1.1" class="ltx_p"><span id="Sx1.T1.5.15.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.15.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.11.1.1" class="ltx_p"><span id="Sx1.T1.5.15.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.15.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.15.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.15.12.1.1" class="ltx_p"><span id="Sx1.T1.5.15.12.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.16" class="ltx_tr">
<td id="Sx1.T1.5.16.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="Sx1.T1.5.16.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">36</span></a><span id="Sx1.T1.5.16.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="Sx1.T1.5.16.2" class="ltx_td ltx_align_left"><span id="Sx1.T1.5.16.2.1" class="ltx_text" style="font-size:70%;">2023</span></td>
<td id="Sx1.T1.5.16.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="Sx1.T1.5.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.3.1.1" class="ltx_p"><span id="Sx1.T1.5.16.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR based on </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="Sx1.T1.5.16.3.1.1.2" class="ltx_text" style="font-size:70%;"> review</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.4.1.1" class="ltx_p"><span id="Sx1.T1.5.16.4.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.5.1.1" class="ltx_p"><span id="Sx1.T1.5.16.5.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.6.1.1" class="ltx_p"><span id="Sx1.T1.5.16.6.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:14.2pt;">
<span id="Sx1.T1.5.16.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.7.1.1" class="ltx_p"><span id="Sx1.T1.5.16.7.1.1.1" class="ltx_text" style="font-size:70%;">✗</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.16.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.8.1.1" class="ltx_p"><span id="Sx1.T1.5.16.8.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.16.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.9.1.1" class="ltx_p"><span id="Sx1.T1.5.16.9.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.10" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="Sx1.T1.5.16.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.10.1.1" class="ltx_p"><span id="Sx1.T1.5.16.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.11" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="Sx1.T1.5.16.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.11.1.1" class="ltx_p"><span id="Sx1.T1.5.16.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.16.12" class="ltx_td ltx_align_justify ltx_align_middle" style="width:37.0pt;">
<span id="Sx1.T1.5.16.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.16.12.1.1" class="ltx_p"><span id="Sx1.T1.5.16.12.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
</tr>
<tr id="Sx1.T1.5.17" class="ltx_tr">
<td id="Sx1.T1.5.17.1" class="ltx_td ltx_align_left ltx_border_b"><span id="Sx1.T1.5.17.1.1" class="ltx_text" style="font-size:70%;">Our</span></td>
<td id="Sx1.T1.5.17.2" class="ltx_td ltx_align_left ltx_border_b"><span id="Sx1.T1.5.17.2.1" class="ltx_text" style="font-size:70%;">2024</span></td>
<td id="Sx1.T1.5.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:113.8pt;">
<span id="Sx1.T1.5.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.3.1.1" class="ltx_p"><span id="Sx1.T1.5.17.3.1.1.1" class="ltx_text" style="font-size:70%;">ASR review on advanced DL techniques</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:14.2pt;">
<span id="Sx1.T1.5.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.4.1.1" class="ltx_p"><span id="Sx1.T1.5.17.4.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:14.2pt;">
<span id="Sx1.T1.5.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.5.1.1" class="ltx_p"><span id="Sx1.T1.5.17.5.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:14.2pt;">
<span id="Sx1.T1.5.17.6.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.6.1.1" class="ltx_p"><span id="Sx1.T1.5.17.6.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.7" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:14.2pt;">
<span id="Sx1.T1.5.17.7.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.7.1.1" class="ltx_p"><span id="Sx1.T1.5.17.7.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.8" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:42.7pt;">
<span id="Sx1.T1.5.17.8.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.8.1.1" class="ltx_p"><span id="Sx1.T1.5.17.8.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:28.5pt;">
<span id="Sx1.T1.5.17.9.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.9.1.1" class="ltx_p"><span id="Sx1.T1.5.17.9.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:28.5pt;">
<span id="Sx1.T1.5.17.10.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.10.1.1" class="ltx_p"><span id="Sx1.T1.5.17.10.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.11" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:42.7pt;">
<span id="Sx1.T1.5.17.11.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.11.1.1" class="ltx_p"><span id="Sx1.T1.5.17.11.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
<td id="Sx1.T1.5.17.12" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:37.0pt;">
<span id="Sx1.T1.5.17.12.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.T1.5.17.12.1.1" class="ltx_p"><span id="Sx1.T1.5.17.12.1.1.1" class="ltx_text" style="font-size:70%;">✓</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="Sx1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Review methodology</h3>

<div id="Sx1.SS3.p1" class="ltx_para">
<p id="Sx1.SS3.p1.1" class="ltx_p">The methodology for the review is delineated in this segment, encompassing the search strategy and study selection. Inclusion criteria, comprising keyword alignment, creativity and impact, and uniqueness, are explicated, collectively influencing the formulation of the paper’s quality assessment protocol. To locate and compile extant advanced DL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> studies, a thorough search was executed on renowned publication databases recognized for hosting top-tier scientific research articles. The exploration encompassed Scopus and Web of Science. Keywords were extracted and organized from the initial set of references through manual analysis. Employing "theme clustering," these publications were sorted based on keywords found in the "Abstract," "Title," and "Authors keywords." The outcome of this process yielded the formulation of the following query:</p>
</div>
<div id="Sx1.SS3.p2" class="ltx_para">
<p id="Sx1.SS3.p2.1" class="ltx_p ltx_align_center">References=FROM "Abstract" || "Title"|| "Authors keywords" SELECT<span id="Sx1.SS3.p2.1.1" class="ltx_text" style="font-size:120%;">(</span> Papers WHERE keywords= (<a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> || <a href="#Sx1.31.31.31"><abbr href="#Sx1.31.31.31" title="natural language processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">NLP</span></span></abbr></a>) &amp; ( <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a> || <a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a> || <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a> || Transformers)<span id="Sx1.SS3.p2.1.2" class="ltx_text" style="font-size:120%;">)</span>.</p>
</div>
<div id="Sx1.SS3.p3" class="ltx_para ltx_noindent">
<p id="Sx1.SS3.p3.1" class="ltx_p">The symbols || and &amp; denote OR and AND logical operations, respectively. The evaluation of publications considered the innovation level in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, the study’s quality, and the contributions and findings presented. This review exclusively encompassed research contributions that were published within the timeframe of 2016 to 2023.</p>
</div>
</section>
<section id="Sx1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.4 </span>Structure of the paper</h3>

<div id="Sx1.SS4.p1" class="ltx_para">
<p id="Sx1.SS4.p1.1" class="ltx_p">This paper is structured into six sections. The current section provides an introduction to the paper. Section <a href="#Sx1.SS3" title="1.3 Review methodology ‣ 1 Introduction ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1.3</span></a> providing background on <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> and <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a>, and reviewing evaluation metrics and datasets utilized in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. Moving forward, Section <a href="#S4" title="4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> delves into a comprehensive review of recent advancements in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> utilizing advanced <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> approaches, including Transformers, <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a>, <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a> and <a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a>. Sections <a href="#S5" title="5 Open Issues and of Key challenges ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S6" title="6 Future directions ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> respectively address the existing challenges and future directions concerning advanced DL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. Finally, Section <a href="#S7" title="7 Conclusion ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> presents concluding remarks summarizing the key findings of the paper.</p>
</div>
<figure id="Sx1.F2" class="ltx_figure"><img src="/html/2403.01255/assets/x2.png" id="Sx1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="350" height="155" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="Sx1.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="Sx1.F2.3.2" class="ltx_text" style="font-size:90%;">Survey roadmap: A guide for navigating paper sections and subsections.</span></figcaption>
</figure>
<div id="Sx1.SS4.p2" class="ltx_para">
<p id="Sx1.SS4.p2.1" class="ltx_p">table[t!]
<span id="Sx1.SS4.p2.1.1" class="ltx_text ltx_caption">Literature acquisition databases. <span id="Sx1.SS4.p2.1.1.1" class="ltx_text" style="color:#FF0000;">to be modified</span></span>


<span id="Sx1.SS4.p2.1.2" class="ltx_tabular ltx_align_middle">
<span id="Sx1.SS4.p2.1.2.1" class="ltx_tr">
<span id="Sx1.SS4.p2.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="Sx1.SS4.p2.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="Sx1.SS4.p2.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Database</span></span>
</span></span>
<span id="Sx1.SS4.p2.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="Sx1.SS4.p2.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.1.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="Sx1.SS4.p2.1.2.1.2.1.1.1" class="ltx_text ltx_font_bold">Research Articles</span></span>
</span></span>
<span id="Sx1.SS4.p2.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="Sx1.SS4.p2.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.1.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="Sx1.SS4.p2.1.2.1.3.1.1.1" class="ltx_text ltx_font_bold">Conference Papers</span></span>
</span></span>
<span id="Sx1.SS4.p2.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="Sx1.SS4.p2.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.1.4.1.1" class="ltx_p" style="width:85.4pt;"><span id="Sx1.SS4.p2.1.2.1.4.1.1.1" class="ltx_text ltx_font_bold">Book Chapter</span></span>
</span></span>
<span id="Sx1.SS4.p2.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="Sx1.SS4.p2.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.1.5.1.1" class="ltx_p" style="width:85.4pt;"><span id="Sx1.SS4.p2.1.2.1.5.1.1.1" class="ltx_text ltx_font_bold">Total</span></span>
</span></span></span>
<span id="Sx1.SS4.p2.1.2.2" class="ltx_tr">
<span id="Sx1.SS4.p2.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx1.SS4.p2.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.2.1.1.1" class="ltx_p" style="width:85.4pt;">ACM</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx1.SS4.p2.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.2.2.1.1" class="ltx_p" style="width:85.4pt;">5</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx1.SS4.p2.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.2.3.1.1" class="ltx_p" style="width:85.4pt;">1</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx1.SS4.p2.1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.2.4.1.1" class="ltx_p" style="width:85.4pt;">–</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx1.SS4.p2.1.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.2.5.1.1" class="ltx_p" style="width:85.4pt;">6</span>
</span></span></span>
<span id="Sx1.SS4.p2.1.2.3" class="ltx_tr">
<span id="Sx1.SS4.p2.1.2.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.1.1.1" class="ltx_p" style="width:85.4pt;">Elsevier</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.3.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.2.1.1" class="ltx_p" style="width:85.4pt;">26</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.3.1.1" class="ltx_p" style="width:85.4pt;">–</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.4.1.1" class="ltx_p" style="width:85.4pt;">–</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.3.5.1.1" class="ltx_p" style="width:85.4pt;">26</span>
</span></span></span>
<span id="Sx1.SS4.p2.1.2.4" class="ltx_tr">
<span id="Sx1.SS4.p2.1.2.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.1.1.1" class="ltx_p" style="width:85.4pt;">Springer</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.2.1.1" class="ltx_p" style="width:85.4pt;">23</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.3.1.1" class="ltx_p" style="width:85.4pt;">–</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.4.1.1" class="ltx_p" style="width:85.4pt;">10</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.4.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.4.5.1.1" class="ltx_p" style="width:85.4pt;">33</span>
</span></span></span>
<span id="Sx1.SS4.p2.1.2.5" class="ltx_tr">
<span id="Sx1.SS4.p2.1.2.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.1.1.1" class="ltx_p" style="width:85.4pt;">IEEE</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.2.1.1" class="ltx_p" style="width:85.4pt;">39</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.3.1.1" class="ltx_p" style="width:85.4pt;">28</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.4.1.1" class="ltx_p" style="width:85.4pt;">–</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.5.5.1.1" class="ltx_p" style="width:85.4pt;">67</span>
</span></span></span>
<span id="Sx1.SS4.p2.1.2.6" class="ltx_tr">
<span id="Sx1.SS4.p2.1.2.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="Sx1.SS4.p2.1.2.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.6.1.1.1" class="ltx_p" style="width:85.4pt;">Others</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="Sx1.SS4.p2.1.2.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.6.2.1.1" class="ltx_p" style="width:85.4pt;">44</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="Sx1.SS4.p2.1.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.6.3.1.1" class="ltx_p" style="width:85.4pt;">29</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="Sx1.SS4.p2.1.2.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.6.4.1.1" class="ltx_p" style="width:85.4pt;">–</span>
</span></span>
<span id="Sx1.SS4.p2.1.2.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="Sx1.SS4.p2.1.2.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="Sx1.SS4.p2.1.2.6.5.1.1" class="ltx_p" style="width:85.4pt;">70</span>
</span></span></span>
</span></p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Overview of DTL techniques for speech recognition</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Taxonomy of existing DTL techniques</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">To date, there is no standardized and comprehensive technique for classifying DTL into categories. However, DTL algorithms could be classified into several types depending on <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">what</span>, <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">when</span>, and <span id="S2.SS1.p1.1.3" class="ltx_text ltx_font_italic">how</span> knowledge is transferred:</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">(a) What knowledge is transferred?</span> Enquires about which characteristics of knowledge are transferable across domains or tasks. Some information is particular to certain domains or tasks, while other knowledge is shared across domains and can aid increase performance in the target task or domain. Based on this definition, DTL could be feature-based, instance-based, relation-based, or model-based.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">(b) How is knowledge transferred?</span> Enquires about which learning algorithms must be implemented to transfer the knowledge.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">(c) When is knowledge transferred?</span> Inquires as to when and under what circumstances knowledge should or should not be transferred. 
<br class="ltx_break"></p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">Furthermore, researchers have proposed taxonomies to categorize DTL-based ASR techniques. For instance, Niu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">21</span></a>]</cite> present a taxonomy with two levels. The first level consists of four sub-groups based on the availability of labeled data and the data modality in the source and target domains. These sub-groups include inductive DTL, transductive DTL, cross-modality DTL, and unsupervised DTL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">80</span></a>]</cite>. Table <a href="#S2.T2" title="Table 2 ‣ 2.1 Taxonomy of existing DTL techniques ‣ 2 Overview of DTL techniques for speech recognition ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> provides a summary of these possibilities. Moreover, each sub-group at the first level can be further divided into four distinct learning types: learning on instances, learning on features, learning on parameters, and learning on relations.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.41.4.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S2.T2.6.3" class="ltx_text" style="font-size:90%;">DTL possibilities. whereas the mark (<math id="S2.T2.4.1.m1.1" class="ltx_Math" alttext="\varsubsetneq" display="inline"><semantics id="S2.T2.4.1.m1.1b"><mo id="S2.T2.4.1.m1.1.1" xref="S2.T2.4.1.m1.1.1.cmml">⊊</mo><annotation-xml encoding="MathML-Content" id="S2.T2.4.1.m1.1c"><prsubset id="S2.T2.4.1.m1.1.1.cmml" xref="S2.T2.4.1.m1.1.1"></prsubset></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.4.1.m1.1d">\varsubsetneq</annotation></semantics></math>) indicates that the domains/tasks are different but related, (<math id="S2.T2.5.2.m2.1" class="ltx_Math" alttext="\exists!" display="inline"><semantics id="S2.T2.5.2.m2.1b"><mrow id="S2.T2.5.2.m2.1.1" xref="S2.T2.5.2.m2.1.1.cmml"><mo rspace="0.167em" id="S2.T2.5.2.m2.1.1.2" xref="S2.T2.5.2.m2.1.1.2.cmml">∃</mo><mo id="S2.T2.5.2.m2.1.1.1" xref="S2.T2.5.2.m2.1.1.1.cmml">!</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.5.2.m2.1c"><apply id="S2.T2.5.2.m2.1.1.cmml" xref="S2.T2.5.2.m2.1.1"><factorial id="S2.T2.5.2.m2.1.1.1.cmml" xref="S2.T2.5.2.m2.1.1.1"></factorial><exists id="S2.T2.5.2.m2.1.1.2.cmml" xref="S2.T2.5.2.m2.1.1.2"></exists></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.5.2.m2.1d">\exists!</annotation></semantics></math>) indicates that there exists one and only one domain/task, and (<math id="S2.T2.6.3.m3.1" class="ltx_Math" alttext="\cong" display="inline"><semantics id="S2.T2.6.3.m3.1b"><mo id="S2.T2.6.3.m3.1.1" xref="S2.T2.6.3.m3.1.1.cmml">≅</mo><annotation-xml encoding="MathML-Content" id="S2.T2.6.3.m3.1c"><approx id="S2.T2.6.3.m3.1.1.cmml" xref="S2.T2.6.3.m3.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.6.3.m3.1d">\cong</annotation></semantics></math>) indicates that domains, tasks, or spaces are not always equals.</span></figcaption>
<table id="S2.T2.39" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.39.34" class="ltx_tr">
<td id="S2.T2.39.34.1" class="ltx_td ltx_border_t"></td>
<td id="S2.T2.39.34.2" class="ltx_td ltx_align_left ltx_border_t">Domains</td>
<td id="S2.T2.39.34.3" class="ltx_td ltx_align_left ltx_border_t">Tasks</td>
<td id="S2.T2.39.34.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:71.1pt;">
<span id="S2.T2.39.34.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.39.34.4.1.1" class="ltx_p">Math. propriety</span>
</span>
</td>
<td id="S2.T2.39.34.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:170.7pt;">
<span id="S2.T2.39.34.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.39.34.5.1.1" class="ltx_p">Sub-categories / Usage</span>
</span>
</td>
</tr>
<tr id="S2.T2.12.6" class="ltx_tr">
<td id="S2.T2.12.6.7" class="ltx_td ltx_align_left ltx_border_t">Traditional ML/DL</td>
<td id="S2.T2.7.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S2.T2.7.1.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{S}=\mathbb{D}_{T}" display="inline"><semantics id="S2.T2.7.1.1.m1.1a"><mrow id="S2.T2.7.1.1.m1.1.1" xref="S2.T2.7.1.1.m1.1.1.cmml"><msub id="S2.T2.7.1.1.m1.1.1.2" xref="S2.T2.7.1.1.m1.1.1.2.cmml"><mi id="S2.T2.7.1.1.m1.1.1.2.2" xref="S2.T2.7.1.1.m1.1.1.2.2.cmml">𝔻</mi><mi id="S2.T2.7.1.1.m1.1.1.2.3" xref="S2.T2.7.1.1.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.7.1.1.m1.1.1.1" xref="S2.T2.7.1.1.m1.1.1.1.cmml">=</mo><msub id="S2.T2.7.1.1.m1.1.1.3" xref="S2.T2.7.1.1.m1.1.1.3.cmml"><mi id="S2.T2.7.1.1.m1.1.1.3.2" xref="S2.T2.7.1.1.m1.1.1.3.2.cmml">𝔻</mi><mi id="S2.T2.7.1.1.m1.1.1.3.3" xref="S2.T2.7.1.1.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.7.1.1.m1.1b"><apply id="S2.T2.7.1.1.m1.1.1.cmml" xref="S2.T2.7.1.1.m1.1.1"><eq id="S2.T2.7.1.1.m1.1.1.1.cmml" xref="S2.T2.7.1.1.m1.1.1.1"></eq><apply id="S2.T2.7.1.1.m1.1.1.2.cmml" xref="S2.T2.7.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.7.1.1.m1.1.1.2.1.cmml" xref="S2.T2.7.1.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.7.1.1.m1.1.1.2.2.cmml" xref="S2.T2.7.1.1.m1.1.1.2.2">𝔻</ci><ci id="S2.T2.7.1.1.m1.1.1.2.3.cmml" xref="S2.T2.7.1.1.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.7.1.1.m1.1.1.3.cmml" xref="S2.T2.7.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.7.1.1.m1.1.1.3.1.cmml" xref="S2.T2.7.1.1.m1.1.1.3">subscript</csymbol><ci id="S2.T2.7.1.1.m1.1.1.3.2.cmml" xref="S2.T2.7.1.1.m1.1.1.3.2">𝔻</ci><ci id="S2.T2.7.1.1.m1.1.1.3.3.cmml" xref="S2.T2.7.1.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.7.1.1.m1.1c">\mathbb{D}_{S}=\mathbb{D}_{T}</annotation></semantics></math></td>
<td id="S2.T2.8.2.2" class="ltx_td ltx_align_left ltx_border_t"><math id="S2.T2.8.2.2.m1.1" class="ltx_Math" alttext="\mathbb{T}_{S}=\mathbb{T}_{T}" display="inline"><semantics id="S2.T2.8.2.2.m1.1a"><mrow id="S2.T2.8.2.2.m1.1.1" xref="S2.T2.8.2.2.m1.1.1.cmml"><msub id="S2.T2.8.2.2.m1.1.1.2" xref="S2.T2.8.2.2.m1.1.1.2.cmml"><mi id="S2.T2.8.2.2.m1.1.1.2.2" xref="S2.T2.8.2.2.m1.1.1.2.2.cmml">𝕋</mi><mi id="S2.T2.8.2.2.m1.1.1.2.3" xref="S2.T2.8.2.2.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.8.2.2.m1.1.1.1" xref="S2.T2.8.2.2.m1.1.1.1.cmml">=</mo><msub id="S2.T2.8.2.2.m1.1.1.3" xref="S2.T2.8.2.2.m1.1.1.3.cmml"><mi id="S2.T2.8.2.2.m1.1.1.3.2" xref="S2.T2.8.2.2.m1.1.1.3.2.cmml">𝕋</mi><mi id="S2.T2.8.2.2.m1.1.1.3.3" xref="S2.T2.8.2.2.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.8.2.2.m1.1b"><apply id="S2.T2.8.2.2.m1.1.1.cmml" xref="S2.T2.8.2.2.m1.1.1"><eq id="S2.T2.8.2.2.m1.1.1.1.cmml" xref="S2.T2.8.2.2.m1.1.1.1"></eq><apply id="S2.T2.8.2.2.m1.1.1.2.cmml" xref="S2.T2.8.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.8.2.2.m1.1.1.2.1.cmml" xref="S2.T2.8.2.2.m1.1.1.2">subscript</csymbol><ci id="S2.T2.8.2.2.m1.1.1.2.2.cmml" xref="S2.T2.8.2.2.m1.1.1.2.2">𝕋</ci><ci id="S2.T2.8.2.2.m1.1.1.2.3.cmml" xref="S2.T2.8.2.2.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.8.2.2.m1.1.1.3.cmml" xref="S2.T2.8.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.8.2.2.m1.1.1.3.1.cmml" xref="S2.T2.8.2.2.m1.1.1.3">subscript</csymbol><ci id="S2.T2.8.2.2.m1.1.1.3.2.cmml" xref="S2.T2.8.2.2.m1.1.1.3.2">𝕋</ci><ci id="S2.T2.8.2.2.m1.1.1.3.3.cmml" xref="S2.T2.8.2.2.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.8.2.2.m1.1c">\mathbb{T}_{S}=\mathbb{T}_{T}</annotation></semantics></math></td>
<td id="S2.T2.10.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:71.1pt;">
<span id="S2.T2.10.4.4.2" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.10.4.4.2.2" class="ltx_p"><math id="S2.T2.9.3.3.1.1.m1.1" class="ltx_Math" alttext="X_{S}\neq X_{T}" display="inline"><semantics id="S2.T2.9.3.3.1.1.m1.1a"><mrow id="S2.T2.9.3.3.1.1.m1.1.1" xref="S2.T2.9.3.3.1.1.m1.1.1.cmml"><msub id="S2.T2.9.3.3.1.1.m1.1.1.2" xref="S2.T2.9.3.3.1.1.m1.1.1.2.cmml"><mi id="S2.T2.9.3.3.1.1.m1.1.1.2.2" xref="S2.T2.9.3.3.1.1.m1.1.1.2.2.cmml">X</mi><mi id="S2.T2.9.3.3.1.1.m1.1.1.2.3" xref="S2.T2.9.3.3.1.1.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.9.3.3.1.1.m1.1.1.1" xref="S2.T2.9.3.3.1.1.m1.1.1.1.cmml">≠</mo><msub id="S2.T2.9.3.3.1.1.m1.1.1.3" xref="S2.T2.9.3.3.1.1.m1.1.1.3.cmml"><mi id="S2.T2.9.3.3.1.1.m1.1.1.3.2" xref="S2.T2.9.3.3.1.1.m1.1.1.3.2.cmml">X</mi><mi id="S2.T2.9.3.3.1.1.m1.1.1.3.3" xref="S2.T2.9.3.3.1.1.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.9.3.3.1.1.m1.1b"><apply id="S2.T2.9.3.3.1.1.m1.1.1.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1"><neq id="S2.T2.9.3.3.1.1.m1.1.1.1.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.1"></neq><apply id="S2.T2.9.3.3.1.1.m1.1.1.2.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.9.3.3.1.1.m1.1.1.2.1.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.9.3.3.1.1.m1.1.1.2.2.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.2.2">𝑋</ci><ci id="S2.T2.9.3.3.1.1.m1.1.1.2.3.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.9.3.3.1.1.m1.1.1.3.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.9.3.3.1.1.m1.1.1.3.1.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.3">subscript</csymbol><ci id="S2.T2.9.3.3.1.1.m1.1.1.3.2.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.3.2">𝑋</ci><ci id="S2.T2.9.3.3.1.1.m1.1.1.3.3.cmml" xref="S2.T2.9.3.3.1.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.9.3.3.1.1.m1.1c">X_{S}\neq X_{T}</annotation></semantics></math>, 
<br class="ltx_break"><math id="S2.T2.10.4.4.2.2.m2.1" class="ltx_Math" alttext="Y_{S}=Y_{T}" display="inline"><semantics id="S2.T2.10.4.4.2.2.m2.1a"><mrow id="S2.T2.10.4.4.2.2.m2.1.1" xref="S2.T2.10.4.4.2.2.m2.1.1.cmml"><msub id="S2.T2.10.4.4.2.2.m2.1.1.2" xref="S2.T2.10.4.4.2.2.m2.1.1.2.cmml"><mi id="S2.T2.10.4.4.2.2.m2.1.1.2.2" xref="S2.T2.10.4.4.2.2.m2.1.1.2.2.cmml">Y</mi><mi id="S2.T2.10.4.4.2.2.m2.1.1.2.3" xref="S2.T2.10.4.4.2.2.m2.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.10.4.4.2.2.m2.1.1.1" xref="S2.T2.10.4.4.2.2.m2.1.1.1.cmml">=</mo><msub id="S2.T2.10.4.4.2.2.m2.1.1.3" xref="S2.T2.10.4.4.2.2.m2.1.1.3.cmml"><mi id="S2.T2.10.4.4.2.2.m2.1.1.3.2" xref="S2.T2.10.4.4.2.2.m2.1.1.3.2.cmml">Y</mi><mi id="S2.T2.10.4.4.2.2.m2.1.1.3.3" xref="S2.T2.10.4.4.2.2.m2.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.10.4.4.2.2.m2.1b"><apply id="S2.T2.10.4.4.2.2.m2.1.1.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1"><eq id="S2.T2.10.4.4.2.2.m2.1.1.1.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.1"></eq><apply id="S2.T2.10.4.4.2.2.m2.1.1.2.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.T2.10.4.4.2.2.m2.1.1.2.1.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.2">subscript</csymbol><ci id="S2.T2.10.4.4.2.2.m2.1.1.2.2.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.2.2">𝑌</ci><ci id="S2.T2.10.4.4.2.2.m2.1.1.2.3.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.10.4.4.2.2.m2.1.1.3.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.T2.10.4.4.2.2.m2.1.1.3.1.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.3">subscript</csymbol><ci id="S2.T2.10.4.4.2.2.m2.1.1.3.2.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.3.2">𝑌</ci><ci id="S2.T2.10.4.4.2.2.m2.1.1.3.3.cmml" xref="S2.T2.10.4.4.2.2.m2.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.10.4.4.2.2.m2.1c">Y_{S}=Y_{T}</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T2.12.6.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:170.7pt;">
<span id="S2.T2.12.6.6.2" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.12.6.6.2.2" class="ltx_p">ASR model trained with <math id="S2.T2.11.5.5.1.1.m1.1" class="ltx_Math" alttext="X_{S}" display="inline"><semantics id="S2.T2.11.5.5.1.1.m1.1a"><msub id="S2.T2.11.5.5.1.1.m1.1.1" xref="S2.T2.11.5.5.1.1.m1.1.1.cmml"><mi id="S2.T2.11.5.5.1.1.m1.1.1.2" xref="S2.T2.11.5.5.1.1.m1.1.1.2.cmml">X</mi><mi id="S2.T2.11.5.5.1.1.m1.1.1.3" xref="S2.T2.11.5.5.1.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T2.11.5.5.1.1.m1.1b"><apply id="S2.T2.11.5.5.1.1.m1.1.1.cmml" xref="S2.T2.11.5.5.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T2.11.5.5.1.1.m1.1.1.1.cmml" xref="S2.T2.11.5.5.1.1.m1.1.1">subscript</csymbol><ci id="S2.T2.11.5.5.1.1.m1.1.1.2.cmml" xref="S2.T2.11.5.5.1.1.m1.1.1.2">𝑋</ci><ci id="S2.T2.11.5.5.1.1.m1.1.1.3.cmml" xref="S2.T2.11.5.5.1.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.11.5.5.1.1.m1.1c">X_{S}</annotation></semantics></math> database and used to recognise <math id="S2.T2.12.6.6.2.2.m2.1" class="ltx_Math" alttext="X_{T}" display="inline"><semantics id="S2.T2.12.6.6.2.2.m2.1a"><msub id="S2.T2.12.6.6.2.2.m2.1.1" xref="S2.T2.12.6.6.2.2.m2.1.1.cmml"><mi id="S2.T2.12.6.6.2.2.m2.1.1.2" xref="S2.T2.12.6.6.2.2.m2.1.1.2.cmml">X</mi><mi id="S2.T2.12.6.6.2.2.m2.1.1.3" xref="S2.T2.12.6.6.2.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T2.12.6.6.2.2.m2.1b"><apply id="S2.T2.12.6.6.2.2.m2.1.1.cmml" xref="S2.T2.12.6.6.2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T2.12.6.6.2.2.m2.1.1.1.cmml" xref="S2.T2.12.6.6.2.2.m2.1.1">subscript</csymbol><ci id="S2.T2.12.6.6.2.2.m2.1.1.2.cmml" xref="S2.T2.12.6.6.2.2.m2.1.1.2">𝑋</ci><ci id="S2.T2.12.6.6.2.2.m2.1.1.3.cmml" xref="S2.T2.12.6.6.2.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.12.6.6.2.2.m2.1c">X_{T}</annotation></semantics></math> database.</span>
</span>
</td>
</tr>
<tr id="S2.T2.19.13" class="ltx_tr">
<td id="S2.T2.19.13.8" class="ltx_td ltx_align_left">Inductive DTL</td>
<td id="S2.T2.13.7.1" class="ltx_td ltx_align_left"><math id="S2.T2.13.7.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{S}\cong\mathbb{D}_{T}" display="inline"><semantics id="S2.T2.13.7.1.m1.1a"><mrow id="S2.T2.13.7.1.m1.1.1" xref="S2.T2.13.7.1.m1.1.1.cmml"><msub id="S2.T2.13.7.1.m1.1.1.2" xref="S2.T2.13.7.1.m1.1.1.2.cmml"><mi id="S2.T2.13.7.1.m1.1.1.2.2" xref="S2.T2.13.7.1.m1.1.1.2.2.cmml">𝔻</mi><mi id="S2.T2.13.7.1.m1.1.1.2.3" xref="S2.T2.13.7.1.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.13.7.1.m1.1.1.1" xref="S2.T2.13.7.1.m1.1.1.1.cmml">≅</mo><msub id="S2.T2.13.7.1.m1.1.1.3" xref="S2.T2.13.7.1.m1.1.1.3.cmml"><mi id="S2.T2.13.7.1.m1.1.1.3.2" xref="S2.T2.13.7.1.m1.1.1.3.2.cmml">𝔻</mi><mi id="S2.T2.13.7.1.m1.1.1.3.3" xref="S2.T2.13.7.1.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.13.7.1.m1.1b"><apply id="S2.T2.13.7.1.m1.1.1.cmml" xref="S2.T2.13.7.1.m1.1.1"><approx id="S2.T2.13.7.1.m1.1.1.1.cmml" xref="S2.T2.13.7.1.m1.1.1.1"></approx><apply id="S2.T2.13.7.1.m1.1.1.2.cmml" xref="S2.T2.13.7.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.13.7.1.m1.1.1.2.1.cmml" xref="S2.T2.13.7.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.13.7.1.m1.1.1.2.2.cmml" xref="S2.T2.13.7.1.m1.1.1.2.2">𝔻</ci><ci id="S2.T2.13.7.1.m1.1.1.2.3.cmml" xref="S2.T2.13.7.1.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.13.7.1.m1.1.1.3.cmml" xref="S2.T2.13.7.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.13.7.1.m1.1.1.3.1.cmml" xref="S2.T2.13.7.1.m1.1.1.3">subscript</csymbol><ci id="S2.T2.13.7.1.m1.1.1.3.2.cmml" xref="S2.T2.13.7.1.m1.1.1.3.2">𝔻</ci><ci id="S2.T2.13.7.1.m1.1.1.3.3.cmml" xref="S2.T2.13.7.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.13.7.1.m1.1c">\mathbb{D}_{S}\cong\mathbb{D}_{T}</annotation></semantics></math></td>
<td id="S2.T2.14.8.2" class="ltx_td ltx_align_left"><math id="S2.T2.14.8.2.m1.1" class="ltx_Math" alttext="\mathbb{T}_{S}\neq\mathbb{T}_{T}" display="inline"><semantics id="S2.T2.14.8.2.m1.1a"><mrow id="S2.T2.14.8.2.m1.1.1" xref="S2.T2.14.8.2.m1.1.1.cmml"><msub id="S2.T2.14.8.2.m1.1.1.2" xref="S2.T2.14.8.2.m1.1.1.2.cmml"><mi id="S2.T2.14.8.2.m1.1.1.2.2" xref="S2.T2.14.8.2.m1.1.1.2.2.cmml">𝕋</mi><mi id="S2.T2.14.8.2.m1.1.1.2.3" xref="S2.T2.14.8.2.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.14.8.2.m1.1.1.1" xref="S2.T2.14.8.2.m1.1.1.1.cmml">≠</mo><msub id="S2.T2.14.8.2.m1.1.1.3" xref="S2.T2.14.8.2.m1.1.1.3.cmml"><mi id="S2.T2.14.8.2.m1.1.1.3.2" xref="S2.T2.14.8.2.m1.1.1.3.2.cmml">𝕋</mi><mi id="S2.T2.14.8.2.m1.1.1.3.3" xref="S2.T2.14.8.2.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.14.8.2.m1.1b"><apply id="S2.T2.14.8.2.m1.1.1.cmml" xref="S2.T2.14.8.2.m1.1.1"><neq id="S2.T2.14.8.2.m1.1.1.1.cmml" xref="S2.T2.14.8.2.m1.1.1.1"></neq><apply id="S2.T2.14.8.2.m1.1.1.2.cmml" xref="S2.T2.14.8.2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.14.8.2.m1.1.1.2.1.cmml" xref="S2.T2.14.8.2.m1.1.1.2">subscript</csymbol><ci id="S2.T2.14.8.2.m1.1.1.2.2.cmml" xref="S2.T2.14.8.2.m1.1.1.2.2">𝕋</ci><ci id="S2.T2.14.8.2.m1.1.1.2.3.cmml" xref="S2.T2.14.8.2.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.14.8.2.m1.1.1.3.cmml" xref="S2.T2.14.8.2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.14.8.2.m1.1.1.3.1.cmml" xref="S2.T2.14.8.2.m1.1.1.3">subscript</csymbol><ci id="S2.T2.14.8.2.m1.1.1.3.2.cmml" xref="S2.T2.14.8.2.m1.1.1.3.2">𝕋</ci><ci id="S2.T2.14.8.2.m1.1.1.3.3.cmml" xref="S2.T2.14.8.2.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.14.8.2.m1.1c">\mathbb{T}_{S}\neq\mathbb{T}_{T}</annotation></semantics></math></td>
<td id="S2.T2.16.10.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S2.T2.16.10.4.2" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.16.10.4.2.2" class="ltx_p"><math id="S2.T2.15.9.3.1.1.m1.1" class="ltx_Math" alttext="X_{S}\neq X_{T}" display="inline"><semantics id="S2.T2.15.9.3.1.1.m1.1a"><mrow id="S2.T2.15.9.3.1.1.m1.1.1" xref="S2.T2.15.9.3.1.1.m1.1.1.cmml"><msub id="S2.T2.15.9.3.1.1.m1.1.1.2" xref="S2.T2.15.9.3.1.1.m1.1.1.2.cmml"><mi id="S2.T2.15.9.3.1.1.m1.1.1.2.2" xref="S2.T2.15.9.3.1.1.m1.1.1.2.2.cmml">X</mi><mi id="S2.T2.15.9.3.1.1.m1.1.1.2.3" xref="S2.T2.15.9.3.1.1.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.15.9.3.1.1.m1.1.1.1" xref="S2.T2.15.9.3.1.1.m1.1.1.1.cmml">≠</mo><msub id="S2.T2.15.9.3.1.1.m1.1.1.3" xref="S2.T2.15.9.3.1.1.m1.1.1.3.cmml"><mi id="S2.T2.15.9.3.1.1.m1.1.1.3.2" xref="S2.T2.15.9.3.1.1.m1.1.1.3.2.cmml">X</mi><mi id="S2.T2.15.9.3.1.1.m1.1.1.3.3" xref="S2.T2.15.9.3.1.1.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.15.9.3.1.1.m1.1b"><apply id="S2.T2.15.9.3.1.1.m1.1.1.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1"><neq id="S2.T2.15.9.3.1.1.m1.1.1.1.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.1"></neq><apply id="S2.T2.15.9.3.1.1.m1.1.1.2.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.15.9.3.1.1.m1.1.1.2.1.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.15.9.3.1.1.m1.1.1.2.2.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.2.2">𝑋</ci><ci id="S2.T2.15.9.3.1.1.m1.1.1.2.3.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.15.9.3.1.1.m1.1.1.3.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.15.9.3.1.1.m1.1.1.3.1.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.3">subscript</csymbol><ci id="S2.T2.15.9.3.1.1.m1.1.1.3.2.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.3.2">𝑋</ci><ci id="S2.T2.15.9.3.1.1.m1.1.1.3.3.cmml" xref="S2.T2.15.9.3.1.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.15.9.3.1.1.m1.1c">X_{S}\neq X_{T}</annotation></semantics></math>, 
<br class="ltx_break"><math id="S2.T2.16.10.4.2.2.m2.2" class="ltx_Math" alttext="Y_{S}\exists,Y_{T}\exists" display="inline"><semantics id="S2.T2.16.10.4.2.2.m2.2a"><mrow id="S2.T2.16.10.4.2.2.m2.2.2.2" xref="S2.T2.16.10.4.2.2.m2.2.2.3.cmml"><mrow id="S2.T2.16.10.4.2.2.m2.1.1.1.1" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.cmml"><msub id="S2.T2.16.10.4.2.2.m2.1.1.1.1.2" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.cmml"><mi id="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.2" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.2.cmml">Y</mi><mi id="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.3" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.3.cmml">S</mi></msub><mo lspace="0.167em" rspace="0em" id="S2.T2.16.10.4.2.2.m2.1.1.1.1.1" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.1.cmml">​</mo><mo id="S2.T2.16.10.4.2.2.m2.1.1.1.1.3" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.3.cmml">∃</mo></mrow><mo id="S2.T2.16.10.4.2.2.m2.2.2.2.3" xref="S2.T2.16.10.4.2.2.m2.2.2.3.cmml">,</mo><mrow id="S2.T2.16.10.4.2.2.m2.2.2.2.2" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.cmml"><msub id="S2.T2.16.10.4.2.2.m2.2.2.2.2.2" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.cmml"><mi id="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.2" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.2.cmml">Y</mi><mi id="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.3" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.3.cmml">T</mi></msub><mo lspace="0.167em" rspace="0em" id="S2.T2.16.10.4.2.2.m2.2.2.2.2.1" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.1.cmml">​</mo><mo id="S2.T2.16.10.4.2.2.m2.2.2.2.2.3" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.3.cmml">∃</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.16.10.4.2.2.m2.2b"><list id="S2.T2.16.10.4.2.2.m2.2.2.3.cmml" xref="S2.T2.16.10.4.2.2.m2.2.2.2"><apply id="S2.T2.16.10.4.2.2.m2.1.1.1.1.cmml" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1"><times id="S2.T2.16.10.4.2.2.m2.1.1.1.1.1.cmml" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.1"></times><apply id="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.cmml" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.1.cmml" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.2">subscript</csymbol><ci id="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.2.cmml" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.2">𝑌</ci><ci id="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.3.cmml" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.2.3">𝑆</ci></apply><exists id="S2.T2.16.10.4.2.2.m2.1.1.1.1.3.cmml" xref="S2.T2.16.10.4.2.2.m2.1.1.1.1.3"></exists></apply><apply id="S2.T2.16.10.4.2.2.m2.2.2.2.2.cmml" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2"><times id="S2.T2.16.10.4.2.2.m2.2.2.2.2.1.cmml" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.1"></times><apply id="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.cmml" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.1.cmml" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.2.cmml" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.2">𝑌</ci><ci id="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.3.cmml" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.2.3">𝑇</ci></apply><exists id="S2.T2.16.10.4.2.2.m2.2.2.2.2.3.cmml" xref="S2.T2.16.10.4.2.2.m2.2.2.2.2.3"></exists></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.16.10.4.2.2.m2.2c">Y_{S}\exists,Y_{T}\exists</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T2.19.13.7" class="ltx_td ltx_align_justify ltx_align_middle" style="width:170.7pt;">
<span id="S2.T2.19.13.7.3" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.19.13.7.3.3" class="ltx_p">If <math id="S2.T2.17.11.5.1.1.m1.1" class="ltx_Math" alttext="Y_{S}\exists" display="inline"><semantics id="S2.T2.17.11.5.1.1.m1.1a"><mrow id="S2.T2.17.11.5.1.1.m1.1.1" xref="S2.T2.17.11.5.1.1.m1.1.1.cmml"><msub id="S2.T2.17.11.5.1.1.m1.1.1.2" xref="S2.T2.17.11.5.1.1.m1.1.1.2.cmml"><mi id="S2.T2.17.11.5.1.1.m1.1.1.2.2" xref="S2.T2.17.11.5.1.1.m1.1.1.2.2.cmml">Y</mi><mi id="S2.T2.17.11.5.1.1.m1.1.1.2.3" xref="S2.T2.17.11.5.1.1.m1.1.1.2.3.cmml">S</mi></msub><mo lspace="0.167em" rspace="0em" id="S2.T2.17.11.5.1.1.m1.1.1.1" xref="S2.T2.17.11.5.1.1.m1.1.1.1.cmml">​</mo><mo id="S2.T2.17.11.5.1.1.m1.1.1.3" xref="S2.T2.17.11.5.1.1.m1.1.1.3.cmml">∃</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.17.11.5.1.1.m1.1b"><apply id="S2.T2.17.11.5.1.1.m1.1.1.cmml" xref="S2.T2.17.11.5.1.1.m1.1.1"><times id="S2.T2.17.11.5.1.1.m1.1.1.1.cmml" xref="S2.T2.17.11.5.1.1.m1.1.1.1"></times><apply id="S2.T2.17.11.5.1.1.m1.1.1.2.cmml" xref="S2.T2.17.11.5.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.17.11.5.1.1.m1.1.1.2.1.cmml" xref="S2.T2.17.11.5.1.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.17.11.5.1.1.m1.1.1.2.2.cmml" xref="S2.T2.17.11.5.1.1.m1.1.1.2.2">𝑌</ci><ci id="S2.T2.17.11.5.1.1.m1.1.1.2.3.cmml" xref="S2.T2.17.11.5.1.1.m1.1.1.2.3">𝑆</ci></apply><exists id="S2.T2.17.11.5.1.1.m1.1.1.3.cmml" xref="S2.T2.17.11.5.1.1.m1.1.1.3"></exists></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.17.11.5.1.1.m1.1c">Y_{S}\exists</annotation></semantics></math>, DTL is multitask learning. If <math id="S2.T2.18.12.6.2.2.m2.1" class="ltx_Math" alttext="Y_{S}\nexists" display="inline"><semantics id="S2.T2.18.12.6.2.2.m2.1a"><mrow id="S2.T2.18.12.6.2.2.m2.1.1" xref="S2.T2.18.12.6.2.2.m2.1.1.cmml"><msub id="S2.T2.18.12.6.2.2.m2.1.1.2" xref="S2.T2.18.12.6.2.2.m2.1.1.2.cmml"><mi id="S2.T2.18.12.6.2.2.m2.1.1.2.2" xref="S2.T2.18.12.6.2.2.m2.1.1.2.2.cmml">Y</mi><mi id="S2.T2.18.12.6.2.2.m2.1.1.2.3" xref="S2.T2.18.12.6.2.2.m2.1.1.2.3.cmml">S</mi></msub><mo lspace="0em" rspace="0em" id="S2.T2.18.12.6.2.2.m2.1.1.1" xref="S2.T2.18.12.6.2.2.m2.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S2.T2.18.12.6.2.2.m2.1.1.3" xref="S2.T2.18.12.6.2.2.m2.1.1.3.cmml">∄</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.18.12.6.2.2.m2.1b"><apply id="S2.T2.18.12.6.2.2.m2.1.1.cmml" xref="S2.T2.18.12.6.2.2.m2.1.1"><times id="S2.T2.18.12.6.2.2.m2.1.1.1.cmml" xref="S2.T2.18.12.6.2.2.m2.1.1.1"></times><apply id="S2.T2.18.12.6.2.2.m2.1.1.2.cmml" xref="S2.T2.18.12.6.2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.T2.18.12.6.2.2.m2.1.1.2.1.cmml" xref="S2.T2.18.12.6.2.2.m2.1.1.2">subscript</csymbol><ci id="S2.T2.18.12.6.2.2.m2.1.1.2.2.cmml" xref="S2.T2.18.12.6.2.2.m2.1.1.2.2">𝑌</ci><ci id="S2.T2.18.12.6.2.2.m2.1.1.2.3.cmml" xref="S2.T2.18.12.6.2.2.m2.1.1.2.3">𝑆</ci></apply><csymbol cd="latexml" id="S2.T2.18.12.6.2.2.m2.1.1.3.cmml" xref="S2.T2.18.12.6.2.2.m2.1.1.3">not-exists</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.18.12.6.2.2.m2.1c">Y_{S}\nexists</annotation></semantics></math>, DTL is self-taught
learning, thus <math id="S2.T2.19.13.7.3.3.m3.1" class="ltx_Math" alttext="\chi_{S}\cong\chi_{T}" display="inline"><semantics id="S2.T2.19.13.7.3.3.m3.1a"><mrow id="S2.T2.19.13.7.3.3.m3.1.1" xref="S2.T2.19.13.7.3.3.m3.1.1.cmml"><msub id="S2.T2.19.13.7.3.3.m3.1.1.2" xref="S2.T2.19.13.7.3.3.m3.1.1.2.cmml"><mi id="S2.T2.19.13.7.3.3.m3.1.1.2.2" xref="S2.T2.19.13.7.3.3.m3.1.1.2.2.cmml">χ</mi><mi id="S2.T2.19.13.7.3.3.m3.1.1.2.3" xref="S2.T2.19.13.7.3.3.m3.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.19.13.7.3.3.m3.1.1.1" xref="S2.T2.19.13.7.3.3.m3.1.1.1.cmml">≅</mo><msub id="S2.T2.19.13.7.3.3.m3.1.1.3" xref="S2.T2.19.13.7.3.3.m3.1.1.3.cmml"><mi id="S2.T2.19.13.7.3.3.m3.1.1.3.2" xref="S2.T2.19.13.7.3.3.m3.1.1.3.2.cmml">χ</mi><mi id="S2.T2.19.13.7.3.3.m3.1.1.3.3" xref="S2.T2.19.13.7.3.3.m3.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.19.13.7.3.3.m3.1b"><apply id="S2.T2.19.13.7.3.3.m3.1.1.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1"><approx id="S2.T2.19.13.7.3.3.m3.1.1.1.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.1"></approx><apply id="S2.T2.19.13.7.3.3.m3.1.1.2.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.T2.19.13.7.3.3.m3.1.1.2.1.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.2">subscript</csymbol><ci id="S2.T2.19.13.7.3.3.m3.1.1.2.2.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.2.2">𝜒</ci><ci id="S2.T2.19.13.7.3.3.m3.1.1.2.3.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.19.13.7.3.3.m3.1.1.3.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.T2.19.13.7.3.3.m3.1.1.3.1.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.3">subscript</csymbol><ci id="S2.T2.19.13.7.3.3.m3.1.1.3.2.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.3.2">𝜒</ci><ci id="S2.T2.19.13.7.3.3.m3.1.1.3.3.cmml" xref="S2.T2.19.13.7.3.3.m3.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.19.13.7.3.3.m3.1c">\chi_{S}\cong\chi_{T}</annotation></semantics></math>.</span>
</span>
</td>
</tr>
<tr id="S2.T2.27.21" class="ltx_tr">
<td id="S2.T2.27.21.9" class="ltx_td ltx_align_left">Transductive DTL</td>
<td id="S2.T2.20.14.1" class="ltx_td ltx_align_left"><math id="S2.T2.20.14.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{S}\neq\mathbb{D}_{T}" display="inline"><semantics id="S2.T2.20.14.1.m1.1a"><mrow id="S2.T2.20.14.1.m1.1.1" xref="S2.T2.20.14.1.m1.1.1.cmml"><msub id="S2.T2.20.14.1.m1.1.1.2" xref="S2.T2.20.14.1.m1.1.1.2.cmml"><mi id="S2.T2.20.14.1.m1.1.1.2.2" xref="S2.T2.20.14.1.m1.1.1.2.2.cmml">𝔻</mi><mi id="S2.T2.20.14.1.m1.1.1.2.3" xref="S2.T2.20.14.1.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.20.14.1.m1.1.1.1" xref="S2.T2.20.14.1.m1.1.1.1.cmml">≠</mo><msub id="S2.T2.20.14.1.m1.1.1.3" xref="S2.T2.20.14.1.m1.1.1.3.cmml"><mi id="S2.T2.20.14.1.m1.1.1.3.2" xref="S2.T2.20.14.1.m1.1.1.3.2.cmml">𝔻</mi><mi id="S2.T2.20.14.1.m1.1.1.3.3" xref="S2.T2.20.14.1.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.20.14.1.m1.1b"><apply id="S2.T2.20.14.1.m1.1.1.cmml" xref="S2.T2.20.14.1.m1.1.1"><neq id="S2.T2.20.14.1.m1.1.1.1.cmml" xref="S2.T2.20.14.1.m1.1.1.1"></neq><apply id="S2.T2.20.14.1.m1.1.1.2.cmml" xref="S2.T2.20.14.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.20.14.1.m1.1.1.2.1.cmml" xref="S2.T2.20.14.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.20.14.1.m1.1.1.2.2.cmml" xref="S2.T2.20.14.1.m1.1.1.2.2">𝔻</ci><ci id="S2.T2.20.14.1.m1.1.1.2.3.cmml" xref="S2.T2.20.14.1.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.20.14.1.m1.1.1.3.cmml" xref="S2.T2.20.14.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.20.14.1.m1.1.1.3.1.cmml" xref="S2.T2.20.14.1.m1.1.1.3">subscript</csymbol><ci id="S2.T2.20.14.1.m1.1.1.3.2.cmml" xref="S2.T2.20.14.1.m1.1.1.3.2">𝔻</ci><ci id="S2.T2.20.14.1.m1.1.1.3.3.cmml" xref="S2.T2.20.14.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.20.14.1.m1.1c">\mathbb{D}_{S}\neq\mathbb{D}_{T}</annotation></semantics></math></td>
<td id="S2.T2.21.15.2" class="ltx_td ltx_align_left"><math id="S2.T2.21.15.2.m1.1" class="ltx_Math" alttext="\mathbb{T}_{S}=\mathbb{T}_{T}" display="inline"><semantics id="S2.T2.21.15.2.m1.1a"><mrow id="S2.T2.21.15.2.m1.1.1" xref="S2.T2.21.15.2.m1.1.1.cmml"><msub id="S2.T2.21.15.2.m1.1.1.2" xref="S2.T2.21.15.2.m1.1.1.2.cmml"><mi id="S2.T2.21.15.2.m1.1.1.2.2" xref="S2.T2.21.15.2.m1.1.1.2.2.cmml">𝕋</mi><mi id="S2.T2.21.15.2.m1.1.1.2.3" xref="S2.T2.21.15.2.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.21.15.2.m1.1.1.1" xref="S2.T2.21.15.2.m1.1.1.1.cmml">=</mo><msub id="S2.T2.21.15.2.m1.1.1.3" xref="S2.T2.21.15.2.m1.1.1.3.cmml"><mi id="S2.T2.21.15.2.m1.1.1.3.2" xref="S2.T2.21.15.2.m1.1.1.3.2.cmml">𝕋</mi><mi id="S2.T2.21.15.2.m1.1.1.3.3" xref="S2.T2.21.15.2.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.21.15.2.m1.1b"><apply id="S2.T2.21.15.2.m1.1.1.cmml" xref="S2.T2.21.15.2.m1.1.1"><eq id="S2.T2.21.15.2.m1.1.1.1.cmml" xref="S2.T2.21.15.2.m1.1.1.1"></eq><apply id="S2.T2.21.15.2.m1.1.1.2.cmml" xref="S2.T2.21.15.2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.21.15.2.m1.1.1.2.1.cmml" xref="S2.T2.21.15.2.m1.1.1.2">subscript</csymbol><ci id="S2.T2.21.15.2.m1.1.1.2.2.cmml" xref="S2.T2.21.15.2.m1.1.1.2.2">𝕋</ci><ci id="S2.T2.21.15.2.m1.1.1.2.3.cmml" xref="S2.T2.21.15.2.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.21.15.2.m1.1.1.3.cmml" xref="S2.T2.21.15.2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.21.15.2.m1.1.1.3.1.cmml" xref="S2.T2.21.15.2.m1.1.1.3">subscript</csymbol><ci id="S2.T2.21.15.2.m1.1.1.3.2.cmml" xref="S2.T2.21.15.2.m1.1.1.3.2">𝕋</ci><ci id="S2.T2.21.15.2.m1.1.1.3.3.cmml" xref="S2.T2.21.15.2.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.21.15.2.m1.1c">\mathbb{T}_{S}=\mathbb{T}_{T}</annotation></semantics></math></td>
<td id="S2.T2.24.18.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S2.T2.24.18.5.3" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.24.18.5.3.3" class="ltx_p"><math id="S2.T2.22.16.3.1.1.m1.2" class="ltx_Math" alttext="P(X_{S})\neq P(X_{T})" display="inline"><semantics id="S2.T2.22.16.3.1.1.m1.2a"><mrow id="S2.T2.22.16.3.1.1.m1.2.2" xref="S2.T2.22.16.3.1.1.m1.2.2.cmml"><mrow id="S2.T2.22.16.3.1.1.m1.1.1.1" xref="S2.T2.22.16.3.1.1.m1.1.1.1.cmml"><mi id="S2.T2.22.16.3.1.1.m1.1.1.1.3" xref="S2.T2.22.16.3.1.1.m1.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.T2.22.16.3.1.1.m1.1.1.1.2" xref="S2.T2.22.16.3.1.1.m1.1.1.1.2.cmml">​</mo><mrow id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.2" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.2" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.2.cmml">X</mi><mi id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.3" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.3.cmml">S</mi></msub><mo stretchy="false" id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.3" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.T2.22.16.3.1.1.m1.2.2.3" xref="S2.T2.22.16.3.1.1.m1.2.2.3.cmml">≠</mo><mrow id="S2.T2.22.16.3.1.1.m1.2.2.2" xref="S2.T2.22.16.3.1.1.m1.2.2.2.cmml"><mi id="S2.T2.22.16.3.1.1.m1.2.2.2.3" xref="S2.T2.22.16.3.1.1.m1.2.2.2.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.T2.22.16.3.1.1.m1.2.2.2.2" xref="S2.T2.22.16.3.1.1.m1.2.2.2.2.cmml">​</mo><mrow id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.2" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.cmml">(</mo><msub id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.cmml"><mi id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.2" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.2.cmml">X</mi><mi id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.3" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.3.cmml">T</mi></msub><mo stretchy="false" id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.3" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.22.16.3.1.1.m1.2b"><apply id="S2.T2.22.16.3.1.1.m1.2.2.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2"><neq id="S2.T2.22.16.3.1.1.m1.2.2.3.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2.3"></neq><apply id="S2.T2.22.16.3.1.1.m1.1.1.1.cmml" xref="S2.T2.22.16.3.1.1.m1.1.1.1"><times id="S2.T2.22.16.3.1.1.m1.1.1.1.2.cmml" xref="S2.T2.22.16.3.1.1.m1.1.1.1.2"></times><ci id="S2.T2.22.16.3.1.1.m1.1.1.1.3.cmml" xref="S2.T2.22.16.3.1.1.m1.1.1.1.3">𝑃</ci><apply id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.2">𝑋</ci><ci id="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.T2.22.16.3.1.1.m1.1.1.1.1.1.1.3">𝑆</ci></apply></apply><apply id="S2.T2.22.16.3.1.1.m1.2.2.2.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2.2"><times id="S2.T2.22.16.3.1.1.m1.2.2.2.2.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2.2.2"></times><ci id="S2.T2.22.16.3.1.1.m1.2.2.2.3.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2.2.3">𝑃</ci><apply id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.1.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1">subscript</csymbol><ci id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.2.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.2">𝑋</ci><ci id="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.3.cmml" xref="S2.T2.22.16.3.1.1.m1.2.2.2.1.1.1.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.22.16.3.1.1.m1.2c">P(X_{S})\neq P(X_{T})</annotation></semantics></math>, 
<br class="ltx_break"><math id="S2.T2.23.17.4.2.2.m2.2" class="ltx_Math" alttext="Y_{S}\exists,Y_{T}\nexists" display="inline"><semantics id="S2.T2.23.17.4.2.2.m2.2a"><mrow id="S2.T2.23.17.4.2.2.m2.2.2.2" xref="S2.T2.23.17.4.2.2.m2.2.2.3.cmml"><mrow id="S2.T2.23.17.4.2.2.m2.1.1.1.1" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.cmml"><msub id="S2.T2.23.17.4.2.2.m2.1.1.1.1.2" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.cmml"><mi id="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.2" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.2.cmml">Y</mi><mi id="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.3" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.3.cmml">S</mi></msub><mo lspace="0.167em" rspace="0em" id="S2.T2.23.17.4.2.2.m2.1.1.1.1.1" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.1.cmml">​</mo><mo id="S2.T2.23.17.4.2.2.m2.1.1.1.1.3" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.3.cmml">∃</mo></mrow><mo id="S2.T2.23.17.4.2.2.m2.2.2.2.3" xref="S2.T2.23.17.4.2.2.m2.2.2.3.cmml">,</mo><mrow id="S2.T2.23.17.4.2.2.m2.2.2.2.2" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.cmml"><msub id="S2.T2.23.17.4.2.2.m2.2.2.2.2.2" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.cmml"><mi id="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.2" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.2.cmml">Y</mi><mi id="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.3" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S2.T2.23.17.4.2.2.m2.2.2.2.2.1" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S2.T2.23.17.4.2.2.m2.2.2.2.2.3" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.3.cmml">∄</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.23.17.4.2.2.m2.2b"><list id="S2.T2.23.17.4.2.2.m2.2.2.3.cmml" xref="S2.T2.23.17.4.2.2.m2.2.2.2"><apply id="S2.T2.23.17.4.2.2.m2.1.1.1.1.cmml" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1"><times id="S2.T2.23.17.4.2.2.m2.1.1.1.1.1.cmml" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.1"></times><apply id="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.cmml" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.1.cmml" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.2">subscript</csymbol><ci id="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.2.cmml" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.2">𝑌</ci><ci id="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.3.cmml" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.2.3">𝑆</ci></apply><exists id="S2.T2.23.17.4.2.2.m2.1.1.1.1.3.cmml" xref="S2.T2.23.17.4.2.2.m2.1.1.1.1.3"></exists></apply><apply id="S2.T2.23.17.4.2.2.m2.2.2.2.2.cmml" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2"><times id="S2.T2.23.17.4.2.2.m2.2.2.2.2.1.cmml" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.1"></times><apply id="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.cmml" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.1.cmml" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.2.cmml" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.2">𝑌</ci><ci id="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.3.cmml" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.2.3">𝑇</ci></apply><csymbol cd="latexml" id="S2.T2.23.17.4.2.2.m2.2.2.2.2.3.cmml" xref="S2.T2.23.17.4.2.2.m2.2.2.2.2.3">not-exists</csymbol></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.23.17.4.2.2.m2.2c">Y_{S}\exists,Y_{T}\nexists</annotation></semantics></math> , 
<br class="ltx_break"><math id="S2.T2.24.18.5.3.3.m3.1" class="ltx_Math" alttext="\chi_{S}=\chi_{T}" display="inline"><semantics id="S2.T2.24.18.5.3.3.m3.1a"><mrow id="S2.T2.24.18.5.3.3.m3.1.1" xref="S2.T2.24.18.5.3.3.m3.1.1.cmml"><msub id="S2.T2.24.18.5.3.3.m3.1.1.2" xref="S2.T2.24.18.5.3.3.m3.1.1.2.cmml"><mi id="S2.T2.24.18.5.3.3.m3.1.1.2.2" xref="S2.T2.24.18.5.3.3.m3.1.1.2.2.cmml">χ</mi><mi id="S2.T2.24.18.5.3.3.m3.1.1.2.3" xref="S2.T2.24.18.5.3.3.m3.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.24.18.5.3.3.m3.1.1.1" xref="S2.T2.24.18.5.3.3.m3.1.1.1.cmml">=</mo><msub id="S2.T2.24.18.5.3.3.m3.1.1.3" xref="S2.T2.24.18.5.3.3.m3.1.1.3.cmml"><mi id="S2.T2.24.18.5.3.3.m3.1.1.3.2" xref="S2.T2.24.18.5.3.3.m3.1.1.3.2.cmml">χ</mi><mi id="S2.T2.24.18.5.3.3.m3.1.1.3.3" xref="S2.T2.24.18.5.3.3.m3.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.24.18.5.3.3.m3.1b"><apply id="S2.T2.24.18.5.3.3.m3.1.1.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1"><eq id="S2.T2.24.18.5.3.3.m3.1.1.1.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.1"></eq><apply id="S2.T2.24.18.5.3.3.m3.1.1.2.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.T2.24.18.5.3.3.m3.1.1.2.1.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.2">subscript</csymbol><ci id="S2.T2.24.18.5.3.3.m3.1.1.2.2.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.2.2">𝜒</ci><ci id="S2.T2.24.18.5.3.3.m3.1.1.2.3.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.24.18.5.3.3.m3.1.1.3.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.T2.24.18.5.3.3.m3.1.1.3.1.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.3">subscript</csymbol><ci id="S2.T2.24.18.5.3.3.m3.1.1.3.2.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.3.2">𝜒</ci><ci id="S2.T2.24.18.5.3.3.m3.1.1.3.3.cmml" xref="S2.T2.24.18.5.3.3.m3.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.24.18.5.3.3.m3.1c">\chi_{S}=\chi_{T}</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T2.27.21.8" class="ltx_td ltx_align_justify ltx_align_middle" style="width:170.7pt;">
<span id="S2.T2.27.21.8.3" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.27.21.8.3.3" class="ltx_p">When <math id="S2.T2.25.19.6.1.1.m1.1" class="ltx_Math" alttext="\chi_{S}=\chi_{T}" display="inline"><semantics id="S2.T2.25.19.6.1.1.m1.1a"><mrow id="S2.T2.25.19.6.1.1.m1.1.1" xref="S2.T2.25.19.6.1.1.m1.1.1.cmml"><msub id="S2.T2.25.19.6.1.1.m1.1.1.2" xref="S2.T2.25.19.6.1.1.m1.1.1.2.cmml"><mi id="S2.T2.25.19.6.1.1.m1.1.1.2.2" xref="S2.T2.25.19.6.1.1.m1.1.1.2.2.cmml">χ</mi><mi id="S2.T2.25.19.6.1.1.m1.1.1.2.3" xref="S2.T2.25.19.6.1.1.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.25.19.6.1.1.m1.1.1.1" xref="S2.T2.25.19.6.1.1.m1.1.1.1.cmml">=</mo><msub id="S2.T2.25.19.6.1.1.m1.1.1.3" xref="S2.T2.25.19.6.1.1.m1.1.1.3.cmml"><mi id="S2.T2.25.19.6.1.1.m1.1.1.3.2" xref="S2.T2.25.19.6.1.1.m1.1.1.3.2.cmml">χ</mi><mi id="S2.T2.25.19.6.1.1.m1.1.1.3.3" xref="S2.T2.25.19.6.1.1.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.25.19.6.1.1.m1.1b"><apply id="S2.T2.25.19.6.1.1.m1.1.1.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1"><eq id="S2.T2.25.19.6.1.1.m1.1.1.1.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.1"></eq><apply id="S2.T2.25.19.6.1.1.m1.1.1.2.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.25.19.6.1.1.m1.1.1.2.1.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.25.19.6.1.1.m1.1.1.2.2.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.2.2">𝜒</ci><ci id="S2.T2.25.19.6.1.1.m1.1.1.2.3.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.25.19.6.1.1.m1.1.1.3.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.25.19.6.1.1.m1.1.1.3.1.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.3">subscript</csymbol><ci id="S2.T2.25.19.6.1.1.m1.1.1.3.2.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.3.2">𝜒</ci><ci id="S2.T2.25.19.6.1.1.m1.1.1.3.3.cmml" xref="S2.T2.25.19.6.1.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.25.19.6.1.1.m1.1c">\chi_{S}=\chi_{T}</annotation></semantics></math>, DTL is is related to DA. If <math id="S2.T2.26.20.7.2.2.m2.1" class="ltx_Math" alttext="\mathbb{D}_{T}\exists!" display="inline"><semantics id="S2.T2.26.20.7.2.2.m2.1a"><mrow id="S2.T2.26.20.7.2.2.m2.1.1" xref="S2.T2.26.20.7.2.2.m2.1.1.cmml"><msub id="S2.T2.26.20.7.2.2.m2.1.1.2" xref="S2.T2.26.20.7.2.2.m2.1.1.2.cmml"><mi id="S2.T2.26.20.7.2.2.m2.1.1.2.2" xref="S2.T2.26.20.7.2.2.m2.1.1.2.2.cmml">𝔻</mi><mi id="S2.T2.26.20.7.2.2.m2.1.1.2.3" xref="S2.T2.26.20.7.2.2.m2.1.1.2.3.cmml">T</mi></msub><mo lspace="0.167em" rspace="0em" id="S2.T2.26.20.7.2.2.m2.1.1.1" xref="S2.T2.26.20.7.2.2.m2.1.1.1.cmml">​</mo><mrow id="S2.T2.26.20.7.2.2.m2.1.1.3" xref="S2.T2.26.20.7.2.2.m2.1.1.3.cmml"><mo rspace="0.167em" id="S2.T2.26.20.7.2.2.m2.1.1.3.2" xref="S2.T2.26.20.7.2.2.m2.1.1.3.2.cmml">∃</mo><mo id="S2.T2.26.20.7.2.2.m2.1.1.3.1" xref="S2.T2.26.20.7.2.2.m2.1.1.3.1.cmml">!</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.26.20.7.2.2.m2.1b"><apply id="S2.T2.26.20.7.2.2.m2.1.1.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1"><times id="S2.T2.26.20.7.2.2.m2.1.1.1.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1.1"></times><apply id="S2.T2.26.20.7.2.2.m2.1.1.2.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.T2.26.20.7.2.2.m2.1.1.2.1.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1.2">subscript</csymbol><ci id="S2.T2.26.20.7.2.2.m2.1.1.2.2.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1.2.2">𝔻</ci><ci id="S2.T2.26.20.7.2.2.m2.1.1.2.3.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1.2.3">𝑇</ci></apply><apply id="S2.T2.26.20.7.2.2.m2.1.1.3.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1.3"><factorial id="S2.T2.26.20.7.2.2.m2.1.1.3.1.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1.3.1"></factorial><exists id="S2.T2.26.20.7.2.2.m2.1.1.3.2.cmml" xref="S2.T2.26.20.7.2.2.m2.1.1.3.2"></exists></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.26.20.7.2.2.m2.1c">\mathbb{D}_{T}\exists!</annotation></semantics></math> and <math id="S2.T2.27.21.8.3.3.m3.1" class="ltx_Math" alttext="\mathbb{T}_{T}\exists!" display="inline"><semantics id="S2.T2.27.21.8.3.3.m3.1a"><mrow id="S2.T2.27.21.8.3.3.m3.1.1" xref="S2.T2.27.21.8.3.3.m3.1.1.cmml"><msub id="S2.T2.27.21.8.3.3.m3.1.1.2" xref="S2.T2.27.21.8.3.3.m3.1.1.2.cmml"><mi id="S2.T2.27.21.8.3.3.m3.1.1.2.2" xref="S2.T2.27.21.8.3.3.m3.1.1.2.2.cmml">𝕋</mi><mi id="S2.T2.27.21.8.3.3.m3.1.1.2.3" xref="S2.T2.27.21.8.3.3.m3.1.1.2.3.cmml">T</mi></msub><mo lspace="0.167em" rspace="0em" id="S2.T2.27.21.8.3.3.m3.1.1.1" xref="S2.T2.27.21.8.3.3.m3.1.1.1.cmml">​</mo><mrow id="S2.T2.27.21.8.3.3.m3.1.1.3" xref="S2.T2.27.21.8.3.3.m3.1.1.3.cmml"><mo rspace="0.167em" id="S2.T2.27.21.8.3.3.m3.1.1.3.2" xref="S2.T2.27.21.8.3.3.m3.1.1.3.2.cmml">∃</mo><mo id="S2.T2.27.21.8.3.3.m3.1.1.3.1" xref="S2.T2.27.21.8.3.3.m3.1.1.3.1.cmml">!</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.27.21.8.3.3.m3.1b"><apply id="S2.T2.27.21.8.3.3.m3.1.1.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1"><times id="S2.T2.27.21.8.3.3.m3.1.1.1.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1.1"></times><apply id="S2.T2.27.21.8.3.3.m3.1.1.2.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.T2.27.21.8.3.3.m3.1.1.2.1.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1.2">subscript</csymbol><ci id="S2.T2.27.21.8.3.3.m3.1.1.2.2.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1.2.2">𝕋</ci><ci id="S2.T2.27.21.8.3.3.m3.1.1.2.3.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1.2.3">𝑇</ci></apply><apply id="S2.T2.27.21.8.3.3.m3.1.1.3.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1.3"><factorial id="S2.T2.27.21.8.3.3.m3.1.1.3.1.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1.3.1"></factorial><exists id="S2.T2.27.21.8.3.3.m3.1.1.3.2.cmml" xref="S2.T2.27.21.8.3.3.m3.1.1.3.2"></exists></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.27.21.8.3.3.m3.1c">\mathbb{T}_{T}\exists!</annotation></semantics></math>, DTL is used for sample selection bias or covariate shift.</span>
</span>
</td>
</tr>
<tr id="S2.T2.36.30" class="ltx_tr">
<td id="S2.T2.36.30.10" class="ltx_td ltx_align_left">Cross-modality DTL</td>
<td id="S2.T2.28.22.1" class="ltx_td ltx_align_left"><math id="S2.T2.28.22.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{S}\neq\mathbb{D}_{T}" display="inline"><semantics id="S2.T2.28.22.1.m1.1a"><mrow id="S2.T2.28.22.1.m1.1.1" xref="S2.T2.28.22.1.m1.1.1.cmml"><msub id="S2.T2.28.22.1.m1.1.1.2" xref="S2.T2.28.22.1.m1.1.1.2.cmml"><mi id="S2.T2.28.22.1.m1.1.1.2.2" xref="S2.T2.28.22.1.m1.1.1.2.2.cmml">𝔻</mi><mi id="S2.T2.28.22.1.m1.1.1.2.3" xref="S2.T2.28.22.1.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.28.22.1.m1.1.1.1" xref="S2.T2.28.22.1.m1.1.1.1.cmml">≠</mo><msub id="S2.T2.28.22.1.m1.1.1.3" xref="S2.T2.28.22.1.m1.1.1.3.cmml"><mi id="S2.T2.28.22.1.m1.1.1.3.2" xref="S2.T2.28.22.1.m1.1.1.3.2.cmml">𝔻</mi><mi id="S2.T2.28.22.1.m1.1.1.3.3" xref="S2.T2.28.22.1.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.28.22.1.m1.1b"><apply id="S2.T2.28.22.1.m1.1.1.cmml" xref="S2.T2.28.22.1.m1.1.1"><neq id="S2.T2.28.22.1.m1.1.1.1.cmml" xref="S2.T2.28.22.1.m1.1.1.1"></neq><apply id="S2.T2.28.22.1.m1.1.1.2.cmml" xref="S2.T2.28.22.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.28.22.1.m1.1.1.2.1.cmml" xref="S2.T2.28.22.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.28.22.1.m1.1.1.2.2.cmml" xref="S2.T2.28.22.1.m1.1.1.2.2">𝔻</ci><ci id="S2.T2.28.22.1.m1.1.1.2.3.cmml" xref="S2.T2.28.22.1.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.28.22.1.m1.1.1.3.cmml" xref="S2.T2.28.22.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.28.22.1.m1.1.1.3.1.cmml" xref="S2.T2.28.22.1.m1.1.1.3">subscript</csymbol><ci id="S2.T2.28.22.1.m1.1.1.3.2.cmml" xref="S2.T2.28.22.1.m1.1.1.3.2">𝔻</ci><ci id="S2.T2.28.22.1.m1.1.1.3.3.cmml" xref="S2.T2.28.22.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.28.22.1.m1.1c">\mathbb{D}_{S}\neq\mathbb{D}_{T}</annotation></semantics></math></td>
<td id="S2.T2.29.23.2" class="ltx_td ltx_align_left"><math id="S2.T2.29.23.2.m1.1" class="ltx_Math" alttext="\mathbb{T}_{S}\neq\mathbb{T}_{T}" display="inline"><semantics id="S2.T2.29.23.2.m1.1a"><mrow id="S2.T2.29.23.2.m1.1.1" xref="S2.T2.29.23.2.m1.1.1.cmml"><msub id="S2.T2.29.23.2.m1.1.1.2" xref="S2.T2.29.23.2.m1.1.1.2.cmml"><mi id="S2.T2.29.23.2.m1.1.1.2.2" xref="S2.T2.29.23.2.m1.1.1.2.2.cmml">𝕋</mi><mi id="S2.T2.29.23.2.m1.1.1.2.3" xref="S2.T2.29.23.2.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.29.23.2.m1.1.1.1" xref="S2.T2.29.23.2.m1.1.1.1.cmml">≠</mo><msub id="S2.T2.29.23.2.m1.1.1.3" xref="S2.T2.29.23.2.m1.1.1.3.cmml"><mi id="S2.T2.29.23.2.m1.1.1.3.2" xref="S2.T2.29.23.2.m1.1.1.3.2.cmml">𝕋</mi><mi id="S2.T2.29.23.2.m1.1.1.3.3" xref="S2.T2.29.23.2.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.29.23.2.m1.1b"><apply id="S2.T2.29.23.2.m1.1.1.cmml" xref="S2.T2.29.23.2.m1.1.1"><neq id="S2.T2.29.23.2.m1.1.1.1.cmml" xref="S2.T2.29.23.2.m1.1.1.1"></neq><apply id="S2.T2.29.23.2.m1.1.1.2.cmml" xref="S2.T2.29.23.2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.29.23.2.m1.1.1.2.1.cmml" xref="S2.T2.29.23.2.m1.1.1.2">subscript</csymbol><ci id="S2.T2.29.23.2.m1.1.1.2.2.cmml" xref="S2.T2.29.23.2.m1.1.1.2.2">𝕋</ci><ci id="S2.T2.29.23.2.m1.1.1.2.3.cmml" xref="S2.T2.29.23.2.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.29.23.2.m1.1.1.3.cmml" xref="S2.T2.29.23.2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.29.23.2.m1.1.1.3.1.cmml" xref="S2.T2.29.23.2.m1.1.1.3">subscript</csymbol><ci id="S2.T2.29.23.2.m1.1.1.3.2.cmml" xref="S2.T2.29.23.2.m1.1.1.3.2">𝕋</ci><ci id="S2.T2.29.23.2.m1.1.1.3.3.cmml" xref="S2.T2.29.23.2.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.29.23.2.m1.1c">\mathbb{T}_{S}\neq\mathbb{T}_{T}</annotation></semantics></math></td>
<td id="S2.T2.32.26.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S2.T2.32.26.5.3" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.32.26.5.3.3" class="ltx_p"><math id="S2.T2.30.24.3.1.1.m1.2" class="ltx_Math" alttext="P(Y_{S}/X_{S})\neq P(Y_{T}/X_{T})" display="inline"><semantics id="S2.T2.30.24.3.1.1.m1.2a"><mrow id="S2.T2.30.24.3.1.1.m1.2.2" xref="S2.T2.30.24.3.1.1.m1.2.2.cmml"><mrow id="S2.T2.30.24.3.1.1.m1.1.1.1" xref="S2.T2.30.24.3.1.1.m1.1.1.1.cmml"><mi id="S2.T2.30.24.3.1.1.m1.1.1.1.3" xref="S2.T2.30.24.3.1.1.m1.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.T2.30.24.3.1.1.m1.1.1.1.2" xref="S2.T2.30.24.3.1.1.m1.1.1.1.2.cmml">​</mo><mrow id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.2" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.cmml"><msub id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.cmml"><mi id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.2" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.2.cmml">Y</mi><mi id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.3" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.1" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.1.cmml">/</mo><msub id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.2" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.2.cmml">X</mi><mi id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.3" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.3.cmml">S</mi></msub></mrow><mo stretchy="false" id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.3" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.T2.30.24.3.1.1.m1.2.2.3" xref="S2.T2.30.24.3.1.1.m1.2.2.3.cmml">≠</mo><mrow id="S2.T2.30.24.3.1.1.m1.2.2.2" xref="S2.T2.30.24.3.1.1.m1.2.2.2.cmml"><mi id="S2.T2.30.24.3.1.1.m1.2.2.2.3" xref="S2.T2.30.24.3.1.1.m1.2.2.2.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.T2.30.24.3.1.1.m1.2.2.2.2" xref="S2.T2.30.24.3.1.1.m1.2.2.2.2.cmml">​</mo><mrow id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.2" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.cmml"><msub id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.cmml"><mi id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.2" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.2.cmml">Y</mi><mi id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.3" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.3.cmml">T</mi></msub><mo id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.1" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.1.cmml">/</mo><msub id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.cmml"><mi id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.2" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.2.cmml">X</mi><mi id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.3" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.3.cmml">T</mi></msub></mrow><mo stretchy="false" id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.3" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.30.24.3.1.1.m1.2b"><apply id="S2.T2.30.24.3.1.1.m1.2.2.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2"><neq id="S2.T2.30.24.3.1.1.m1.2.2.3.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.3"></neq><apply id="S2.T2.30.24.3.1.1.m1.1.1.1.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1"><times id="S2.T2.30.24.3.1.1.m1.1.1.1.2.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.2"></times><ci id="S2.T2.30.24.3.1.1.m1.1.1.1.3.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.3">𝑃</ci><apply id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1"><divide id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.1"></divide><apply id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.2">𝑌</ci><ci id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.2">𝑋</ci><ci id="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.T2.30.24.3.1.1.m1.1.1.1.1.1.1.3.3">𝑆</ci></apply></apply></apply><apply id="S2.T2.30.24.3.1.1.m1.2.2.2.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2"><times id="S2.T2.30.24.3.1.1.m1.2.2.2.2.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.2"></times><ci id="S2.T2.30.24.3.1.1.m1.2.2.2.3.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.3">𝑃</ci><apply id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1"><divide id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.1.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.1"></divide><apply id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.1.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2">subscript</csymbol><ci id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.2.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.2">𝑌</ci><ci id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.3.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.2.3">𝑇</ci></apply><apply id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.1.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3">subscript</csymbol><ci id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.2.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.2">𝑋</ci><ci id="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.3.cmml" xref="S2.T2.30.24.3.1.1.m1.2.2.2.1.1.1.3.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.30.24.3.1.1.m1.2c">P(Y_{S}/X_{S})\neq P(Y_{T}/X_{T})</annotation></semantics></math>,
<br class="ltx_break"><math id="S2.T2.31.25.4.2.2.m2.1" class="ltx_Math" alttext="Y_{S}\neq Y_{T}" display="inline"><semantics id="S2.T2.31.25.4.2.2.m2.1a"><mrow id="S2.T2.31.25.4.2.2.m2.1.1" xref="S2.T2.31.25.4.2.2.m2.1.1.cmml"><msub id="S2.T2.31.25.4.2.2.m2.1.1.2" xref="S2.T2.31.25.4.2.2.m2.1.1.2.cmml"><mi id="S2.T2.31.25.4.2.2.m2.1.1.2.2" xref="S2.T2.31.25.4.2.2.m2.1.1.2.2.cmml">Y</mi><mi id="S2.T2.31.25.4.2.2.m2.1.1.2.3" xref="S2.T2.31.25.4.2.2.m2.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.31.25.4.2.2.m2.1.1.1" xref="S2.T2.31.25.4.2.2.m2.1.1.1.cmml">≠</mo><msub id="S2.T2.31.25.4.2.2.m2.1.1.3" xref="S2.T2.31.25.4.2.2.m2.1.1.3.cmml"><mi id="S2.T2.31.25.4.2.2.m2.1.1.3.2" xref="S2.T2.31.25.4.2.2.m2.1.1.3.2.cmml">Y</mi><mi id="S2.T2.31.25.4.2.2.m2.1.1.3.3" xref="S2.T2.31.25.4.2.2.m2.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.31.25.4.2.2.m2.1b"><apply id="S2.T2.31.25.4.2.2.m2.1.1.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1"><neq id="S2.T2.31.25.4.2.2.m2.1.1.1.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.1"></neq><apply id="S2.T2.31.25.4.2.2.m2.1.1.2.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.T2.31.25.4.2.2.m2.1.1.2.1.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.2">subscript</csymbol><ci id="S2.T2.31.25.4.2.2.m2.1.1.2.2.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.2.2">𝑌</ci><ci id="S2.T2.31.25.4.2.2.m2.1.1.2.3.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.31.25.4.2.2.m2.1.1.3.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.T2.31.25.4.2.2.m2.1.1.3.1.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.3">subscript</csymbol><ci id="S2.T2.31.25.4.2.2.m2.1.1.3.2.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.3.2">𝑌</ci><ci id="S2.T2.31.25.4.2.2.m2.1.1.3.3.cmml" xref="S2.T2.31.25.4.2.2.m2.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.31.25.4.2.2.m2.1c">Y_{S}\neq Y_{T}</annotation></semantics></math>, <math id="S2.T2.32.26.5.3.3.m3.1" class="ltx_Math" alttext="\chi_{S}\neq\chi_{T}" display="inline"><semantics id="S2.T2.32.26.5.3.3.m3.1a"><mrow id="S2.T2.32.26.5.3.3.m3.1.1" xref="S2.T2.32.26.5.3.3.m3.1.1.cmml"><msub id="S2.T2.32.26.5.3.3.m3.1.1.2" xref="S2.T2.32.26.5.3.3.m3.1.1.2.cmml"><mi id="S2.T2.32.26.5.3.3.m3.1.1.2.2" xref="S2.T2.32.26.5.3.3.m3.1.1.2.2.cmml">χ</mi><mi id="S2.T2.32.26.5.3.3.m3.1.1.2.3" xref="S2.T2.32.26.5.3.3.m3.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.32.26.5.3.3.m3.1.1.1" xref="S2.T2.32.26.5.3.3.m3.1.1.1.cmml">≠</mo><msub id="S2.T2.32.26.5.3.3.m3.1.1.3" xref="S2.T2.32.26.5.3.3.m3.1.1.3.cmml"><mi id="S2.T2.32.26.5.3.3.m3.1.1.3.2" xref="S2.T2.32.26.5.3.3.m3.1.1.3.2.cmml">χ</mi><mi id="S2.T2.32.26.5.3.3.m3.1.1.3.3" xref="S2.T2.32.26.5.3.3.m3.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.32.26.5.3.3.m3.1b"><apply id="S2.T2.32.26.5.3.3.m3.1.1.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1"><neq id="S2.T2.32.26.5.3.3.m3.1.1.1.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.1"></neq><apply id="S2.T2.32.26.5.3.3.m3.1.1.2.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.T2.32.26.5.3.3.m3.1.1.2.1.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.2">subscript</csymbol><ci id="S2.T2.32.26.5.3.3.m3.1.1.2.2.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.2.2">𝜒</ci><ci id="S2.T2.32.26.5.3.3.m3.1.1.2.3.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.32.26.5.3.3.m3.1.1.3.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.T2.32.26.5.3.3.m3.1.1.3.1.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.3">subscript</csymbol><ci id="S2.T2.32.26.5.3.3.m3.1.1.3.2.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.3.2">𝜒</ci><ci id="S2.T2.32.26.5.3.3.m3.1.1.3.3.cmml" xref="S2.T2.32.26.5.3.3.m3.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.32.26.5.3.3.m3.1c">\chi_{S}\neq\chi_{T}</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T2.36.30.9" class="ltx_td ltx_align_justify ltx_align_middle" style="width:170.7pt;">
<span id="S2.T2.36.30.9.4" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.36.30.9.4.4" class="ltx_p">i,e. the dataset <math id="S2.T2.33.27.6.1.1.m1.1" class="ltx_Math" alttext="X_{S}" display="inline"><semantics id="S2.T2.33.27.6.1.1.m1.1a"><msub id="S2.T2.33.27.6.1.1.m1.1.1" xref="S2.T2.33.27.6.1.1.m1.1.1.cmml"><mi id="S2.T2.33.27.6.1.1.m1.1.1.2" xref="S2.T2.33.27.6.1.1.m1.1.1.2.cmml">X</mi><mi id="S2.T2.33.27.6.1.1.m1.1.1.3" xref="S2.T2.33.27.6.1.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T2.33.27.6.1.1.m1.1b"><apply id="S2.T2.33.27.6.1.1.m1.1.1.cmml" xref="S2.T2.33.27.6.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T2.33.27.6.1.1.m1.1.1.1.cmml" xref="S2.T2.33.27.6.1.1.m1.1.1">subscript</csymbol><ci id="S2.T2.33.27.6.1.1.m1.1.1.2.cmml" xref="S2.T2.33.27.6.1.1.m1.1.1.2">𝑋</ci><ci id="S2.T2.33.27.6.1.1.m1.1.1.3.cmml" xref="S2.T2.33.27.6.1.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.33.27.6.1.1.m1.1c">X_{S}</annotation></semantics></math> of <math id="S2.T2.34.28.7.2.2.m2.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.T2.34.28.7.2.2.m2.1a"><msub id="S2.T2.34.28.7.2.2.m2.1.1" xref="S2.T2.34.28.7.2.2.m2.1.1.cmml"><mi id="S2.T2.34.28.7.2.2.m2.1.1.2" xref="S2.T2.34.28.7.2.2.m2.1.1.2.cmml">𝔻</mi><mi id="S2.T2.34.28.7.2.2.m2.1.1.3" xref="S2.T2.34.28.7.2.2.m2.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T2.34.28.7.2.2.m2.1b"><apply id="S2.T2.34.28.7.2.2.m2.1.1.cmml" xref="S2.T2.34.28.7.2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.T2.34.28.7.2.2.m2.1.1.1.cmml" xref="S2.T2.34.28.7.2.2.m2.1.1">subscript</csymbol><ci id="S2.T2.34.28.7.2.2.m2.1.1.2.cmml" xref="S2.T2.34.28.7.2.2.m2.1.1.2">𝔻</ci><ci id="S2.T2.34.28.7.2.2.m2.1.1.3.cmml" xref="S2.T2.34.28.7.2.2.m2.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.34.28.7.2.2.m2.1c">\mathbb{D}_{S}</annotation></semantics></math> is speech data, and the dataset <math id="S2.T2.35.29.8.3.3.m3.1" class="ltx_Math" alttext="X_{T}" display="inline"><semantics id="S2.T2.35.29.8.3.3.m3.1a"><msub id="S2.T2.35.29.8.3.3.m3.1.1" xref="S2.T2.35.29.8.3.3.m3.1.1.cmml"><mi id="S2.T2.35.29.8.3.3.m3.1.1.2" xref="S2.T2.35.29.8.3.3.m3.1.1.2.cmml">X</mi><mi id="S2.T2.35.29.8.3.3.m3.1.1.3" xref="S2.T2.35.29.8.3.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T2.35.29.8.3.3.m3.1b"><apply id="S2.T2.35.29.8.3.3.m3.1.1.cmml" xref="S2.T2.35.29.8.3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.T2.35.29.8.3.3.m3.1.1.1.cmml" xref="S2.T2.35.29.8.3.3.m3.1.1">subscript</csymbol><ci id="S2.T2.35.29.8.3.3.m3.1.1.2.cmml" xref="S2.T2.35.29.8.3.3.m3.1.1.2">𝑋</ci><ci id="S2.T2.35.29.8.3.3.m3.1.1.3.cmml" xref="S2.T2.35.29.8.3.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.35.29.8.3.3.m3.1c">X_{T}</annotation></semantics></math> of <math id="S2.T2.36.30.9.4.4.m4.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.T2.36.30.9.4.4.m4.1a"><msub id="S2.T2.36.30.9.4.4.m4.1.1" xref="S2.T2.36.30.9.4.4.m4.1.1.cmml"><mi id="S2.T2.36.30.9.4.4.m4.1.1.2" xref="S2.T2.36.30.9.4.4.m4.1.1.2.cmml">𝔻</mi><mi id="S2.T2.36.30.9.4.4.m4.1.1.3" xref="S2.T2.36.30.9.4.4.m4.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.T2.36.30.9.4.4.m4.1b"><apply id="S2.T2.36.30.9.4.4.m4.1.1.cmml" xref="S2.T2.36.30.9.4.4.m4.1.1"><csymbol cd="ambiguous" id="S2.T2.36.30.9.4.4.m4.1.1.1.cmml" xref="S2.T2.36.30.9.4.4.m4.1.1">subscript</csymbol><ci id="S2.T2.36.30.9.4.4.m4.1.1.2.cmml" xref="S2.T2.36.30.9.4.4.m4.1.1.2">𝔻</ci><ci id="S2.T2.36.30.9.4.4.m4.1.1.3.cmml" xref="S2.T2.36.30.9.4.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.36.30.9.4.4.m4.1c">\mathbb{D}_{T}</annotation></semantics></math> is text data.</span>
</span>
</td>
</tr>
<tr id="S2.T2.39.33" class="ltx_tr">
<td id="S2.T2.39.33.4" class="ltx_td ltx_align_left ltx_border_b">Unsupervised DTL</td>
<td id="S2.T2.37.31.1" class="ltx_td ltx_align_left ltx_border_b"><math id="S2.T2.37.31.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{S}\varsubsetneq\mathbb{D}_{T}" display="inline"><semantics id="S2.T2.37.31.1.m1.1a"><mrow id="S2.T2.37.31.1.m1.1.1" xref="S2.T2.37.31.1.m1.1.1.cmml"><msub id="S2.T2.37.31.1.m1.1.1.2" xref="S2.T2.37.31.1.m1.1.1.2.cmml"><mi id="S2.T2.37.31.1.m1.1.1.2.2" xref="S2.T2.37.31.1.m1.1.1.2.2.cmml">𝔻</mi><mi id="S2.T2.37.31.1.m1.1.1.2.3" xref="S2.T2.37.31.1.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.37.31.1.m1.1.1.1" xref="S2.T2.37.31.1.m1.1.1.1.cmml">⊊</mo><msub id="S2.T2.37.31.1.m1.1.1.3" xref="S2.T2.37.31.1.m1.1.1.3.cmml"><mi id="S2.T2.37.31.1.m1.1.1.3.2" xref="S2.T2.37.31.1.m1.1.1.3.2.cmml">𝔻</mi><mi id="S2.T2.37.31.1.m1.1.1.3.3" xref="S2.T2.37.31.1.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.37.31.1.m1.1b"><apply id="S2.T2.37.31.1.m1.1.1.cmml" xref="S2.T2.37.31.1.m1.1.1"><prsubset id="S2.T2.37.31.1.m1.1.1.1.cmml" xref="S2.T2.37.31.1.m1.1.1.1"></prsubset><apply id="S2.T2.37.31.1.m1.1.1.2.cmml" xref="S2.T2.37.31.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.37.31.1.m1.1.1.2.1.cmml" xref="S2.T2.37.31.1.m1.1.1.2">subscript</csymbol><ci id="S2.T2.37.31.1.m1.1.1.2.2.cmml" xref="S2.T2.37.31.1.m1.1.1.2.2">𝔻</ci><ci id="S2.T2.37.31.1.m1.1.1.2.3.cmml" xref="S2.T2.37.31.1.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.37.31.1.m1.1.1.3.cmml" xref="S2.T2.37.31.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.37.31.1.m1.1.1.3.1.cmml" xref="S2.T2.37.31.1.m1.1.1.3">subscript</csymbol><ci id="S2.T2.37.31.1.m1.1.1.3.2.cmml" xref="S2.T2.37.31.1.m1.1.1.3.2">𝔻</ci><ci id="S2.T2.37.31.1.m1.1.1.3.3.cmml" xref="S2.T2.37.31.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.37.31.1.m1.1c">\mathbb{D}_{S}\varsubsetneq\mathbb{D}_{T}</annotation></semantics></math></td>
<td id="S2.T2.38.32.2" class="ltx_td ltx_align_left ltx_border_b"><math id="S2.T2.38.32.2.m1.1" class="ltx_Math" alttext="\mathbb{T}_{S}\varsubsetneq\mathbb{T}_{T}" display="inline"><semantics id="S2.T2.38.32.2.m1.1a"><mrow id="S2.T2.38.32.2.m1.1.1" xref="S2.T2.38.32.2.m1.1.1.cmml"><msub id="S2.T2.38.32.2.m1.1.1.2" xref="S2.T2.38.32.2.m1.1.1.2.cmml"><mi id="S2.T2.38.32.2.m1.1.1.2.2" xref="S2.T2.38.32.2.m1.1.1.2.2.cmml">𝕋</mi><mi id="S2.T2.38.32.2.m1.1.1.2.3" xref="S2.T2.38.32.2.m1.1.1.2.3.cmml">S</mi></msub><mo id="S2.T2.38.32.2.m1.1.1.1" xref="S2.T2.38.32.2.m1.1.1.1.cmml">⊊</mo><msub id="S2.T2.38.32.2.m1.1.1.3" xref="S2.T2.38.32.2.m1.1.1.3.cmml"><mi id="S2.T2.38.32.2.m1.1.1.3.2" xref="S2.T2.38.32.2.m1.1.1.3.2.cmml">𝕋</mi><mi id="S2.T2.38.32.2.m1.1.1.3.3" xref="S2.T2.38.32.2.m1.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.38.32.2.m1.1b"><apply id="S2.T2.38.32.2.m1.1.1.cmml" xref="S2.T2.38.32.2.m1.1.1"><prsubset id="S2.T2.38.32.2.m1.1.1.1.cmml" xref="S2.T2.38.32.2.m1.1.1.1"></prsubset><apply id="S2.T2.38.32.2.m1.1.1.2.cmml" xref="S2.T2.38.32.2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.38.32.2.m1.1.1.2.1.cmml" xref="S2.T2.38.32.2.m1.1.1.2">subscript</csymbol><ci id="S2.T2.38.32.2.m1.1.1.2.2.cmml" xref="S2.T2.38.32.2.m1.1.1.2.2">𝕋</ci><ci id="S2.T2.38.32.2.m1.1.1.2.3.cmml" xref="S2.T2.38.32.2.m1.1.1.2.3">𝑆</ci></apply><apply id="S2.T2.38.32.2.m1.1.1.3.cmml" xref="S2.T2.38.32.2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.T2.38.32.2.m1.1.1.3.1.cmml" xref="S2.T2.38.32.2.m1.1.1.3">subscript</csymbol><ci id="S2.T2.38.32.2.m1.1.1.3.2.cmml" xref="S2.T2.38.32.2.m1.1.1.3.2">𝕋</ci><ci id="S2.T2.38.32.2.m1.1.1.3.3.cmml" xref="S2.T2.38.32.2.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.38.32.2.m1.1c">\mathbb{T}_{S}\varsubsetneq\mathbb{T}_{T}</annotation></semantics></math></td>
<td id="S2.T2.39.33.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:71.1pt;">
<span id="S2.T2.39.33.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.39.33.3.1.1" class="ltx_p"><math id="S2.T2.39.33.3.1.1.m1.2" class="ltx_Math" alttext="Y_{S}\nexists,Y_{T}\nexists" display="inline"><semantics id="S2.T2.39.33.3.1.1.m1.2a"><mrow id="S2.T2.39.33.3.1.1.m1.2.2.2" xref="S2.T2.39.33.3.1.1.m1.2.2.3.cmml"><mrow id="S2.T2.39.33.3.1.1.m1.1.1.1.1" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.cmml"><msub id="S2.T2.39.33.3.1.1.m1.1.1.1.1.2" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.cmml"><mi id="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.2" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.2.cmml">Y</mi><mi id="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.3" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.3.cmml">S</mi></msub><mo lspace="0em" rspace="0em" id="S2.T2.39.33.3.1.1.m1.1.1.1.1.1" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S2.T2.39.33.3.1.1.m1.1.1.1.1.3" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.3.cmml">∄</mi></mrow><mo id="S2.T2.39.33.3.1.1.m1.2.2.2.3" xref="S2.T2.39.33.3.1.1.m1.2.2.3.cmml">,</mo><mrow id="S2.T2.39.33.3.1.1.m1.2.2.2.2" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.cmml"><msub id="S2.T2.39.33.3.1.1.m1.2.2.2.2.2" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.cmml"><mi id="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.2" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.2.cmml">Y</mi><mi id="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.3" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S2.T2.39.33.3.1.1.m1.2.2.2.2.1" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S2.T2.39.33.3.1.1.m1.2.2.2.2.3" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.3.cmml">∄</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.39.33.3.1.1.m1.2b"><list id="S2.T2.39.33.3.1.1.m1.2.2.3.cmml" xref="S2.T2.39.33.3.1.1.m1.2.2.2"><apply id="S2.T2.39.33.3.1.1.m1.1.1.1.1.cmml" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1"><times id="S2.T2.39.33.3.1.1.m1.1.1.1.1.1.cmml" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.1"></times><apply id="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.cmml" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.1.cmml" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.2.cmml" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.2">𝑌</ci><ci id="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.3.cmml" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.2.3">𝑆</ci></apply><csymbol cd="latexml" id="S2.T2.39.33.3.1.1.m1.1.1.1.1.3.cmml" xref="S2.T2.39.33.3.1.1.m1.1.1.1.1.3">not-exists</csymbol></apply><apply id="S2.T2.39.33.3.1.1.m1.2.2.2.2.cmml" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2"><times id="S2.T2.39.33.3.1.1.m1.2.2.2.2.1.cmml" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.1"></times><apply id="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.cmml" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.1.cmml" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.2.cmml" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.2">𝑌</ci><ci id="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.3.cmml" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.2.3">𝑇</ci></apply><csymbol cd="latexml" id="S2.T2.39.33.3.1.1.m1.2.2.2.2.3.cmml" xref="S2.T2.39.33.3.1.1.m1.2.2.2.2.3">not-exists</csymbol></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.39.33.3.1.1.m1.2c">Y_{S}\nexists,Y_{T}\nexists</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T2.39.33.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:170.7pt;">
<span id="S2.T2.39.33.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T2.39.33.5.1.1" class="ltx_p">DTL used for clustering, dimensionality reduction,
and density estimation, etc.</span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S2.SS1.p6" class="ltx_para">
<p id="S2.SS1.p6.8" class="ltx_p">Inductive DTL
In comparison to classical ML, which may be used as a reference for DTL comparison, and given that the target tasks <math id="S2.SS1.p6.1.m1.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S2.SS1.p6.1.m1.1a"><msub id="S2.SS1.p6.1.m1.1.1" xref="S2.SS1.p6.1.m1.1.1.cmml"><mi id="S2.SS1.p6.1.m1.1.1.2" xref="S2.SS1.p6.1.m1.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.p6.1.m1.1.1.3" xref="S2.SS1.p6.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.1.m1.1b"><apply id="S2.SS1.p6.1.m1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p6.1.m1.1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p6.1.m1.1.1.2.cmml" xref="S2.SS1.p6.1.m1.1.1.2">𝕋</ci><ci id="S2.SS1.p6.1.m1.1.1.3.cmml" xref="S2.SS1.p6.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.1.m1.1c">\mathbb{T}_{T}</annotation></semantics></math> are distinct from the source tasks <math id="S2.SS1.p6.2.m2.1" class="ltx_Math" alttext="\mathbb{T}_{S}" display="inline"><semantics id="S2.SS1.p6.2.m2.1a"><msub id="S2.SS1.p6.2.m2.1.1" xref="S2.SS1.p6.2.m2.1.1.cmml"><mi id="S2.SS1.p6.2.m2.1.1.2" xref="S2.SS1.p6.2.m2.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.p6.2.m2.1.1.3" xref="S2.SS1.p6.2.m2.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.2.m2.1b"><apply id="S2.SS1.p6.2.m2.1.1.cmml" xref="S2.SS1.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p6.2.m2.1.1.1.cmml" xref="S2.SS1.p6.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p6.2.m2.1.1.2.cmml" xref="S2.SS1.p6.2.m2.1.1.2">𝕋</ci><ci id="S2.SS1.p6.2.m2.1.1.3.cmml" xref="S2.SS1.p6.2.m2.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.2.m2.1c">\mathbb{T}_{S}</annotation></semantics></math>, the goal of inductive DTL is to enhance the target prediction function <math id="S2.SS1.p6.3.m3.1" class="ltx_Math" alttext="\mathbb{F}_{T}" display="inline"><semantics id="S2.SS1.p6.3.m3.1a"><msub id="S2.SS1.p6.3.m3.1.1" xref="S2.SS1.p6.3.m3.1.1.cmml"><mi id="S2.SS1.p6.3.m3.1.1.2" xref="S2.SS1.p6.3.m3.1.1.2.cmml">𝔽</mi><mi id="S2.SS1.p6.3.m3.1.1.3" xref="S2.SS1.p6.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.3.m3.1b"><apply id="S2.SS1.p6.3.m3.1.1.cmml" xref="S2.SS1.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p6.3.m3.1.1.1.cmml" xref="S2.SS1.p6.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p6.3.m3.1.1.2.cmml" xref="S2.SS1.p6.3.m3.1.1.2">𝔽</ci><ci id="S2.SS1.p6.3.m3.1.1.3.cmml" xref="S2.SS1.p6.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.3.m3.1c">\mathbb{F}_{T}</annotation></semantics></math> in the TD, mentioned above in subsection <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:sub12</span>. However, the SD <math id="S2.SS1.p6.4.m4.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.SS1.p6.4.m4.1a"><msub id="S2.SS1.p6.4.m4.1.1" xref="S2.SS1.p6.4.m4.1.1.cmml"><mi id="S2.SS1.p6.4.m4.1.1.2" xref="S2.SS1.p6.4.m4.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.p6.4.m4.1.1.3" xref="S2.SS1.p6.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.4.m4.1b"><apply id="S2.SS1.p6.4.m4.1.1.cmml" xref="S2.SS1.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p6.4.m4.1.1.1.cmml" xref="S2.SS1.p6.4.m4.1.1">subscript</csymbol><ci id="S2.SS1.p6.4.m4.1.1.2.cmml" xref="S2.SS1.p6.4.m4.1.1.2">𝔻</ci><ci id="S2.SS1.p6.4.m4.1.1.3.cmml" xref="S2.SS1.p6.4.m4.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.4.m4.1c">\mathbb{D}_{S}</annotation></semantics></math> and TD <math id="S2.SS1.p6.5.m5.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.SS1.p6.5.m5.1a"><msub id="S2.SS1.p6.5.m5.1.1" xref="S2.SS1.p6.5.m5.1.1.cmml"><mi id="S2.SS1.p6.5.m5.1.1.2" xref="S2.SS1.p6.5.m5.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.p6.5.m5.1.1.3" xref="S2.SS1.p6.5.m5.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.5.m5.1b"><apply id="S2.SS1.p6.5.m5.1.1.cmml" xref="S2.SS1.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p6.5.m5.1.1.1.cmml" xref="S2.SS1.p6.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p6.5.m5.1.1.2.cmml" xref="S2.SS1.p6.5.m5.1.1.2">𝔻</ci><ci id="S2.SS1.p6.5.m5.1.1.3.cmml" xref="S2.SS1.p6.5.m5.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.5.m5.1c">\mathbb{D}_{T}</annotation></semantics></math> may not always be the same (Table <a href="#S2.T2" title="Table 2 ‣ 2.1 Taxonomy of existing DTL techniques ‣ 2 Overview of DTL techniques for speech recognition ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). The inductive DTL can be stated similarly to the following two cases, depending on whether labeled or unlabeled data is available: 
<br class="ltx_break"><span id="S2.SS1.p6.8.1" class="ltx_text ltx_font_bold">(a) Multi-task DTL:</span> The SD has a huge labeled database (<math id="S2.SS1.p6.6.m6.1" class="ltx_Math" alttext="X_{S}" display="inline"><semantics id="S2.SS1.p6.6.m6.1a"><msub id="S2.SS1.p6.6.m6.1.1" xref="S2.SS1.p6.6.m6.1.1.cmml"><mi id="S2.SS1.p6.6.m6.1.1.2" xref="S2.SS1.p6.6.m6.1.1.2.cmml">X</mi><mi id="S2.SS1.p6.6.m6.1.1.3" xref="S2.SS1.p6.6.m6.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.6.m6.1b"><apply id="S2.SS1.p6.6.m6.1.1.cmml" xref="S2.SS1.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.p6.6.m6.1.1.1.cmml" xref="S2.SS1.p6.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.p6.6.m6.1.1.2.cmml" xref="S2.SS1.p6.6.m6.1.1.2">𝑋</ci><ci id="S2.SS1.p6.6.m6.1.1.3.cmml" xref="S2.SS1.p6.6.m6.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.6.m6.1c">X_{S}</annotation></semantics></math> labeled with <math id="S2.SS1.p6.7.m7.1" class="ltx_Math" alttext="Y_{S}" display="inline"><semantics id="S2.SS1.p6.7.m7.1a"><msub id="S2.SS1.p6.7.m7.1.1" xref="S2.SS1.p6.7.m7.1.1.cmml"><mi id="S2.SS1.p6.7.m7.1.1.2" xref="S2.SS1.p6.7.m7.1.1.2.cmml">Y</mi><mi id="S2.SS1.p6.7.m7.1.1.3" xref="S2.SS1.p6.7.m7.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.7.m7.1b"><apply id="S2.SS1.p6.7.m7.1.1.cmml" xref="S2.SS1.p6.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p6.7.m7.1.1.1.cmml" xref="S2.SS1.p6.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p6.7.m7.1.1.2.cmml" xref="S2.SS1.p6.7.m7.1.1.2">𝑌</ci><ci id="S2.SS1.p6.7.m7.1.1.3.cmml" xref="S2.SS1.p6.7.m7.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.7.m7.1c">Y_{S}</annotation></semantics></math>), which is a distinctive form of multi-task learning. However, with multi-task approaches, many tasks <math id="S2.SS1.p6.8.m8.4" class="ltx_Math" alttext="(T_{1},T_{2},\dots,T_{n})" display="inline"><semantics id="S2.SS1.p6.8.m8.4a"><mrow id="S2.SS1.p6.8.m8.4.4.3" xref="S2.SS1.p6.8.m8.4.4.4.cmml"><mo stretchy="false" id="S2.SS1.p6.8.m8.4.4.3.4" xref="S2.SS1.p6.8.m8.4.4.4.cmml">(</mo><msub id="S2.SS1.p6.8.m8.2.2.1.1" xref="S2.SS1.p6.8.m8.2.2.1.1.cmml"><mi id="S2.SS1.p6.8.m8.2.2.1.1.2" xref="S2.SS1.p6.8.m8.2.2.1.1.2.cmml">T</mi><mn id="S2.SS1.p6.8.m8.2.2.1.1.3" xref="S2.SS1.p6.8.m8.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p6.8.m8.4.4.3.5" xref="S2.SS1.p6.8.m8.4.4.4.cmml">,</mo><msub id="S2.SS1.p6.8.m8.3.3.2.2" xref="S2.SS1.p6.8.m8.3.3.2.2.cmml"><mi id="S2.SS1.p6.8.m8.3.3.2.2.2" xref="S2.SS1.p6.8.m8.3.3.2.2.2.cmml">T</mi><mn id="S2.SS1.p6.8.m8.3.3.2.2.3" xref="S2.SS1.p6.8.m8.3.3.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p6.8.m8.4.4.3.6" xref="S2.SS1.p6.8.m8.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p6.8.m8.1.1" xref="S2.SS1.p6.8.m8.1.1.cmml">…</mi><mo id="S2.SS1.p6.8.m8.4.4.3.7" xref="S2.SS1.p6.8.m8.4.4.4.cmml">,</mo><msub id="S2.SS1.p6.8.m8.4.4.3.3" xref="S2.SS1.p6.8.m8.4.4.3.3.cmml"><mi id="S2.SS1.p6.8.m8.4.4.3.3.2" xref="S2.SS1.p6.8.m8.4.4.3.3.2.cmml">T</mi><mi id="S2.SS1.p6.8.m8.4.4.3.3.3" xref="S2.SS1.p6.8.m8.4.4.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S2.SS1.p6.8.m8.4.4.3.8" xref="S2.SS1.p6.8.m8.4.4.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.8.m8.4b"><vector id="S2.SS1.p6.8.m8.4.4.4.cmml" xref="S2.SS1.p6.8.m8.4.4.3"><apply id="S2.SS1.p6.8.m8.2.2.1.1.cmml" xref="S2.SS1.p6.8.m8.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p6.8.m8.2.2.1.1.1.cmml" xref="S2.SS1.p6.8.m8.2.2.1.1">subscript</csymbol><ci id="S2.SS1.p6.8.m8.2.2.1.1.2.cmml" xref="S2.SS1.p6.8.m8.2.2.1.1.2">𝑇</ci><cn type="integer" id="S2.SS1.p6.8.m8.2.2.1.1.3.cmml" xref="S2.SS1.p6.8.m8.2.2.1.1.3">1</cn></apply><apply id="S2.SS1.p6.8.m8.3.3.2.2.cmml" xref="S2.SS1.p6.8.m8.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p6.8.m8.3.3.2.2.1.cmml" xref="S2.SS1.p6.8.m8.3.3.2.2">subscript</csymbol><ci id="S2.SS1.p6.8.m8.3.3.2.2.2.cmml" xref="S2.SS1.p6.8.m8.3.3.2.2.2">𝑇</ci><cn type="integer" id="S2.SS1.p6.8.m8.3.3.2.2.3.cmml" xref="S2.SS1.p6.8.m8.3.3.2.2.3">2</cn></apply><ci id="S2.SS1.p6.8.m8.1.1.cmml" xref="S2.SS1.p6.8.m8.1.1">…</ci><apply id="S2.SS1.p6.8.m8.4.4.3.3.cmml" xref="S2.SS1.p6.8.m8.4.4.3.3"><csymbol cd="ambiguous" id="S2.SS1.p6.8.m8.4.4.3.3.1.cmml" xref="S2.SS1.p6.8.m8.4.4.3.3">subscript</csymbol><ci id="S2.SS1.p6.8.m8.4.4.3.3.2.cmml" xref="S2.SS1.p6.8.m8.4.4.3.3.2">𝑇</ci><ci id="S2.SS1.p6.8.m8.4.4.3.3.3.cmml" xref="S2.SS1.p6.8.m8.4.4.3.3.3">𝑛</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.8.m8.4c">(T_{1},T_{2},\dots,T_{n})</annotation></semantics></math> are learned at the same time (in parallel), including both source and target activities (tasks).</p>
</div>
<div id="S2.SS1.p7" class="ltx_para ltx_noindent">
<p id="S2.SS1.p7.8" class="ltx_p"><span id="S2.SS1.p7.8.1" class="ltx_text ltx_font_bold">(b) Sequential DTL:</span> ( Commonly known as <span id="S2.SS1.p7.8.2" class="ltx_text ltx_font_italic">self-taught learning</span>) Dataset is not labeled in the SD (<math id="S2.SS1.p7.1.m1.1" class="ltx_Math" alttext="X_{S}" display="inline"><semantics id="S2.SS1.p7.1.m1.1a"><msub id="S2.SS1.p7.1.m1.1.1" xref="S2.SS1.p7.1.m1.1.1.cmml"><mi id="S2.SS1.p7.1.m1.1.1.2" xref="S2.SS1.p7.1.m1.1.1.2.cmml">X</mi><mi id="S2.SS1.p7.1.m1.1.1.3" xref="S2.SS1.p7.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.1.m1.1b"><apply id="S2.SS1.p7.1.m1.1.1.cmml" xref="S2.SS1.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p7.1.m1.1.1.1.cmml" xref="S2.SS1.p7.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p7.1.m1.1.1.2.cmml" xref="S2.SS1.p7.1.m1.1.1.2">𝑋</ci><ci id="S2.SS1.p7.1.m1.1.1.3.cmml" xref="S2.SS1.p7.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.1.m1.1c">X_{S}</annotation></semantics></math> is not labeled with <math id="S2.SS1.p7.2.m2.1" class="ltx_Math" alttext="Y_{S}" display="inline"><semantics id="S2.SS1.p7.2.m2.1a"><msub id="S2.SS1.p7.2.m2.1.1" xref="S2.SS1.p7.2.m2.1.1.cmml"><mi id="S2.SS1.p7.2.m2.1.1.2" xref="S2.SS1.p7.2.m2.1.1.2.cmml">Y</mi><mi id="S2.SS1.p7.2.m2.1.1.3" xref="S2.SS1.p7.2.m2.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.2.m2.1b"><apply id="S2.SS1.p7.2.m2.1.1.cmml" xref="S2.SS1.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p7.2.m2.1.1.1.cmml" xref="S2.SS1.p7.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p7.2.m2.1.1.2.cmml" xref="S2.SS1.p7.2.m2.1.1.2">𝑌</ci><ci id="S2.SS1.p7.2.m2.1.1.3.cmml" xref="S2.SS1.p7.2.m2.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.2.m2.1c">Y_{S}</annotation></semantics></math>) but the labels are available in the destination domain (<math id="S2.SS1.p7.3.m3.1" class="ltx_Math" alttext="X_{T}" display="inline"><semantics id="S2.SS1.p7.3.m3.1a"><msub id="S2.SS1.p7.3.m3.1.1" xref="S2.SS1.p7.3.m3.1.1.cmml"><mi id="S2.SS1.p7.3.m3.1.1.2" xref="S2.SS1.p7.3.m3.1.1.2.cmml">X</mi><mi id="S2.SS1.p7.3.m3.1.1.3" xref="S2.SS1.p7.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.3.m3.1b"><apply id="S2.SS1.p7.3.m3.1.1.cmml" xref="S2.SS1.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p7.3.m3.1.1.1.cmml" xref="S2.SS1.p7.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p7.3.m3.1.1.2.cmml" xref="S2.SS1.p7.3.m3.1.1.2">𝑋</ci><ci id="S2.SS1.p7.3.m3.1.1.3.cmml" xref="S2.SS1.p7.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.3.m3.1c">X_{T}</annotation></semantics></math> is labeled with <math id="S2.SS1.p7.4.m4.1" class="ltx_Math" alttext="Y_{T}" display="inline"><semantics id="S2.SS1.p7.4.m4.1a"><msub id="S2.SS1.p7.4.m4.1.1" xref="S2.SS1.p7.4.m4.1.1.cmml"><mi id="S2.SS1.p7.4.m4.1.1.2" xref="S2.SS1.p7.4.m4.1.1.2.cmml">Y</mi><mi id="S2.SS1.p7.4.m4.1.1.3" xref="S2.SS1.p7.4.m4.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.4.m4.1b"><apply id="S2.SS1.p7.4.m4.1.1.cmml" xref="S2.SS1.p7.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p7.4.m4.1.1.1.cmml" xref="S2.SS1.p7.4.m4.1.1">subscript</csymbol><ci id="S2.SS1.p7.4.m4.1.1.2.cmml" xref="S2.SS1.p7.4.m4.1.1.2">𝑌</ci><ci id="S2.SS1.p7.4.m4.1.1.3.cmml" xref="S2.SS1.p7.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.4.m4.1c">Y_{T}</annotation></semantics></math>). Sequential learning is a DL system that can be realized in two steps for classification purposes. The first step is the feature representation transfer, which is learned from a large collection of the unlabeled datasets, and the second stage is when this learned representation is applied to labeled data to accomplish classification tasks. Hence, sequential DTL is a method of sequentially learning a number of activities (Tasks). The spaces between the source and destination domains may differ. For example, let suppose we have a pre-trained model <math id="S2.SS1.p7.5.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS1.p7.5.m5.1a"><mi id="S2.SS1.p7.5.m5.1.1" xref="S2.SS1.p7.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.5.m5.1b"><ci id="S2.SS1.p7.5.m5.1.1.cmml" xref="S2.SS1.p7.5.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.5.m5.1c">M</annotation></semantics></math> and consider applying DTL to a number of tasks <math id="S2.SS1.p7.6.m6.4" class="ltx_Math" alttext="(T_{1},T_{2},\dots,T_{n})" display="inline"><semantics id="S2.SS1.p7.6.m6.4a"><mrow id="S2.SS1.p7.6.m6.4.4.3" xref="S2.SS1.p7.6.m6.4.4.4.cmml"><mo stretchy="false" id="S2.SS1.p7.6.m6.4.4.3.4" xref="S2.SS1.p7.6.m6.4.4.4.cmml">(</mo><msub id="S2.SS1.p7.6.m6.2.2.1.1" xref="S2.SS1.p7.6.m6.2.2.1.1.cmml"><mi id="S2.SS1.p7.6.m6.2.2.1.1.2" xref="S2.SS1.p7.6.m6.2.2.1.1.2.cmml">T</mi><mn id="S2.SS1.p7.6.m6.2.2.1.1.3" xref="S2.SS1.p7.6.m6.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p7.6.m6.4.4.3.5" xref="S2.SS1.p7.6.m6.4.4.4.cmml">,</mo><msub id="S2.SS1.p7.6.m6.3.3.2.2" xref="S2.SS1.p7.6.m6.3.3.2.2.cmml"><mi id="S2.SS1.p7.6.m6.3.3.2.2.2" xref="S2.SS1.p7.6.m6.3.3.2.2.2.cmml">T</mi><mn id="S2.SS1.p7.6.m6.3.3.2.2.3" xref="S2.SS1.p7.6.m6.3.3.2.2.3.cmml">2</mn></msub><mo id="S2.SS1.p7.6.m6.4.4.3.6" xref="S2.SS1.p7.6.m6.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p7.6.m6.1.1" xref="S2.SS1.p7.6.m6.1.1.cmml">…</mi><mo id="S2.SS1.p7.6.m6.4.4.3.7" xref="S2.SS1.p7.6.m6.4.4.4.cmml">,</mo><msub id="S2.SS1.p7.6.m6.4.4.3.3" xref="S2.SS1.p7.6.m6.4.4.3.3.cmml"><mi id="S2.SS1.p7.6.m6.4.4.3.3.2" xref="S2.SS1.p7.6.m6.4.4.3.3.2.cmml">T</mi><mi id="S2.SS1.p7.6.m6.4.4.3.3.3" xref="S2.SS1.p7.6.m6.4.4.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S2.SS1.p7.6.m6.4.4.3.8" xref="S2.SS1.p7.6.m6.4.4.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.6.m6.4b"><vector id="S2.SS1.p7.6.m6.4.4.4.cmml" xref="S2.SS1.p7.6.m6.4.4.3"><apply id="S2.SS1.p7.6.m6.2.2.1.1.cmml" xref="S2.SS1.p7.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p7.6.m6.2.2.1.1.1.cmml" xref="S2.SS1.p7.6.m6.2.2.1.1">subscript</csymbol><ci id="S2.SS1.p7.6.m6.2.2.1.1.2.cmml" xref="S2.SS1.p7.6.m6.2.2.1.1.2">𝑇</ci><cn type="integer" id="S2.SS1.p7.6.m6.2.2.1.1.3.cmml" xref="S2.SS1.p7.6.m6.2.2.1.1.3">1</cn></apply><apply id="S2.SS1.p7.6.m6.3.3.2.2.cmml" xref="S2.SS1.p7.6.m6.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p7.6.m6.3.3.2.2.1.cmml" xref="S2.SS1.p7.6.m6.3.3.2.2">subscript</csymbol><ci id="S2.SS1.p7.6.m6.3.3.2.2.2.cmml" xref="S2.SS1.p7.6.m6.3.3.2.2.2">𝑇</ci><cn type="integer" id="S2.SS1.p7.6.m6.3.3.2.2.3.cmml" xref="S2.SS1.p7.6.m6.3.3.2.2.3">2</cn></apply><ci id="S2.SS1.p7.6.m6.1.1.cmml" xref="S2.SS1.p7.6.m6.1.1">…</ci><apply id="S2.SS1.p7.6.m6.4.4.3.3.cmml" xref="S2.SS1.p7.6.m6.4.4.3.3"><csymbol cd="ambiguous" id="S2.SS1.p7.6.m6.4.4.3.3.1.cmml" xref="S2.SS1.p7.6.m6.4.4.3.3">subscript</csymbol><ci id="S2.SS1.p7.6.m6.4.4.3.3.2.cmml" xref="S2.SS1.p7.6.m6.4.4.3.3.2">𝑇</ci><ci id="S2.SS1.p7.6.m6.4.4.3.3.3.cmml" xref="S2.SS1.p7.6.m6.4.4.3.3.3">𝑛</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.6.m6.4c">(T_{1},T_{2},\dots,T_{n})</annotation></semantics></math>. We learn a specific task <math id="S2.SS1.p7.7.m7.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S2.SS1.p7.7.m7.1a"><msub id="S2.SS1.p7.7.m7.1.1" xref="S2.SS1.p7.7.m7.1.1.cmml"><mi id="S2.SS1.p7.7.m7.1.1.2" xref="S2.SS1.p7.7.m7.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.p7.7.m7.1.1.3" xref="S2.SS1.p7.7.m7.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.7.m7.1b"><apply id="S2.SS1.p7.7.m7.1.1.cmml" xref="S2.SS1.p7.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p7.7.m7.1.1.1.cmml" xref="S2.SS1.p7.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p7.7.m7.1.1.2.cmml" xref="S2.SS1.p7.7.m7.1.1.2">𝕋</ci><ci id="S2.SS1.p7.7.m7.1.1.3.cmml" xref="S2.SS1.p7.7.m7.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.7.m7.1c">\mathbb{T}_{T}</annotation></semantics></math> at each time step <math id="S2.SS1.p7.8.m8.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p7.8.m8.1a"><mi id="S2.SS1.p7.8.m8.1.1" xref="S2.SS1.p7.8.m8.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.8.m8.1b"><ci id="S2.SS1.p7.8.m8.1.1.cmml" xref="S2.SS1.p7.8.m8.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.8.m8.1c">t</annotation></semantics></math>, which is slower than multi-task learning. However, when not all the tasks are present during training time, it might be beneficial. Sequential DTL is additionally classified into several types <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">alyafeai2020survey</span>]</cite>:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1-</span> 
<div id="S2.I1.ix1.p1" class="ltx_para">
<p id="S2.I1.ix1.p1.9" class="ltx_p"><span id="S2.I1.ix1.p1.9.1" class="ltx_text ltx_font_bold">Fine-tuning:</span> The principle is to learn a new function <math id="S2.I1.ix1.p1.1.m1.1" class="ltx_Math" alttext="\mathbb{F}_{T}" display="inline"><semantics id="S2.I1.ix1.p1.1.m1.1a"><msub id="S2.I1.ix1.p1.1.m1.1.1" xref="S2.I1.ix1.p1.1.m1.1.1.cmml"><mi id="S2.I1.ix1.p1.1.m1.1.1.2" xref="S2.I1.ix1.p1.1.m1.1.1.2.cmml">𝔽</mi><mi id="S2.I1.ix1.p1.1.m1.1.1.3" xref="S2.I1.ix1.p1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.1.m1.1b"><apply id="S2.I1.ix1.p1.1.m1.1.1.cmml" xref="S2.I1.ix1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.1.m1.1.1.1.cmml" xref="S2.I1.ix1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.ix1.p1.1.m1.1.1.2.cmml" xref="S2.I1.ix1.p1.1.m1.1.1.2">𝔽</ci><ci id="S2.I1.ix1.p1.1.m1.1.1.3.cmml" xref="S2.I1.ix1.p1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.1.m1.1c">\mathbb{F}_{T}</annotation></semantics></math> that translates the parameters <math id="S2.I1.ix1.p1.2.m2.1" class="ltx_Math" alttext="\mathbb{F}_{T}(W_{S})=W_{T}" display="inline"><semantics id="S2.I1.ix1.p1.2.m2.1a"><mrow id="S2.I1.ix1.p1.2.m2.1.1" xref="S2.I1.ix1.p1.2.m2.1.1.cmml"><mrow id="S2.I1.ix1.p1.2.m2.1.1.1" xref="S2.I1.ix1.p1.2.m2.1.1.1.cmml"><msub id="S2.I1.ix1.p1.2.m2.1.1.1.3" xref="S2.I1.ix1.p1.2.m2.1.1.1.3.cmml"><mi id="S2.I1.ix1.p1.2.m2.1.1.1.3.2" xref="S2.I1.ix1.p1.2.m2.1.1.1.3.2.cmml">𝔽</mi><mi id="S2.I1.ix1.p1.2.m2.1.1.1.3.3" xref="S2.I1.ix1.p1.2.m2.1.1.1.3.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S2.I1.ix1.p1.2.m2.1.1.1.2" xref="S2.I1.ix1.p1.2.m2.1.1.1.2.cmml">​</mo><mrow id="S2.I1.ix1.p1.2.m2.1.1.1.1.1" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.2" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.cmml">(</mo><msub id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.cmml"><mi id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.2" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.2.cmml">W</mi><mi id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.3" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.3.cmml">S</mi></msub><mo stretchy="false" id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.3" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.I1.ix1.p1.2.m2.1.1.2" xref="S2.I1.ix1.p1.2.m2.1.1.2.cmml">=</mo><msub id="S2.I1.ix1.p1.2.m2.1.1.3" xref="S2.I1.ix1.p1.2.m2.1.1.3.cmml"><mi id="S2.I1.ix1.p1.2.m2.1.1.3.2" xref="S2.I1.ix1.p1.2.m2.1.1.3.2.cmml">W</mi><mi id="S2.I1.ix1.p1.2.m2.1.1.3.3" xref="S2.I1.ix1.p1.2.m2.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.2.m2.1b"><apply id="S2.I1.ix1.p1.2.m2.1.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.1"><eq id="S2.I1.ix1.p1.2.m2.1.1.2.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.2"></eq><apply id="S2.I1.ix1.p1.2.m2.1.1.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1"><times id="S2.I1.ix1.p1.2.m2.1.1.1.2.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.2"></times><apply id="S2.I1.ix1.p1.2.m2.1.1.1.3.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.2.m2.1.1.1.3.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.3">subscript</csymbol><ci id="S2.I1.ix1.p1.2.m2.1.1.1.3.2.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.3.2">𝔽</ci><ci id="S2.I1.ix1.p1.2.m2.1.1.1.3.3.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.3.3">𝑇</ci></apply><apply id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.2.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.2">𝑊</ci><ci id="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.3.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.1.1.1.1.3">𝑆</ci></apply></apply><apply id="S2.I1.ix1.p1.2.m2.1.1.3.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.2.m2.1.1.3.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.3">subscript</csymbol><ci id="S2.I1.ix1.p1.2.m2.1.1.3.2.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.3.2">𝑊</ci><ci id="S2.I1.ix1.p1.2.m2.1.1.3.3.cmml" xref="S2.I1.ix1.p1.2.m2.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.2.m2.1c">\mathbb{F}_{T}(W_{S})=W_{T}</annotation></semantics></math> by using <math id="S2.I1.ix1.p1.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.I1.ix1.p1.3.m3.1a"><mi id="S2.I1.ix1.p1.3.m3.1.1" xref="S2.I1.ix1.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.3.m3.1b"><ci id="S2.I1.ix1.p1.3.m3.1.1.cmml" xref="S2.I1.ix1.p1.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.3.m3.1c">M</annotation></semantics></math>, given a pre-trained model <math id="S2.I1.ix1.p1.4.m4.1" class="ltx_Math" alttext="M_{S}" display="inline"><semantics id="S2.I1.ix1.p1.4.m4.1a"><msub id="S2.I1.ix1.p1.4.m4.1.1" xref="S2.I1.ix1.p1.4.m4.1.1.cmml"><mi id="S2.I1.ix1.p1.4.m4.1.1.2" xref="S2.I1.ix1.p1.4.m4.1.1.2.cmml">M</mi><mi id="S2.I1.ix1.p1.4.m4.1.1.3" xref="S2.I1.ix1.p1.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.4.m4.1b"><apply id="S2.I1.ix1.p1.4.m4.1.1.cmml" xref="S2.I1.ix1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.4.m4.1.1.1.cmml" xref="S2.I1.ix1.p1.4.m4.1.1">subscript</csymbol><ci id="S2.I1.ix1.p1.4.m4.1.1.2.cmml" xref="S2.I1.ix1.p1.4.m4.1.1.2">𝑀</ci><ci id="S2.I1.ix1.p1.4.m4.1.1.3.cmml" xref="S2.I1.ix1.p1.4.m4.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.4.m4.1c">M_{S}</annotation></semantics></math> having <math id="S2.I1.ix1.p1.5.m5.1" class="ltx_Math" alttext="W_{S}" display="inline"><semantics id="S2.I1.ix1.p1.5.m5.1a"><msub id="S2.I1.ix1.p1.5.m5.1.1" xref="S2.I1.ix1.p1.5.m5.1.1.cmml"><mi id="S2.I1.ix1.p1.5.m5.1.1.2" xref="S2.I1.ix1.p1.5.m5.1.1.2.cmml">W</mi><mi id="S2.I1.ix1.p1.5.m5.1.1.3" xref="S2.I1.ix1.p1.5.m5.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.5.m5.1b"><apply id="S2.I1.ix1.p1.5.m5.1.1.cmml" xref="S2.I1.ix1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.5.m5.1.1.1.cmml" xref="S2.I1.ix1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.I1.ix1.p1.5.m5.1.1.2.cmml" xref="S2.I1.ix1.p1.5.m5.1.1.2">𝑊</ci><ci id="S2.I1.ix1.p1.5.m5.1.1.3.cmml" xref="S2.I1.ix1.p1.5.m5.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.5.m5.1c">W_{S}</annotation></semantics></math> as weights and target task <math id="S2.I1.ix1.p1.6.m6.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S2.I1.ix1.p1.6.m6.1a"><msub id="S2.I1.ix1.p1.6.m6.1.1" xref="S2.I1.ix1.p1.6.m6.1.1.cmml"><mi id="S2.I1.ix1.p1.6.m6.1.1.2" xref="S2.I1.ix1.p1.6.m6.1.1.2.cmml">𝕋</mi><mi id="S2.I1.ix1.p1.6.m6.1.1.3" xref="S2.I1.ix1.p1.6.m6.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.6.m6.1b"><apply id="S2.I1.ix1.p1.6.m6.1.1.cmml" xref="S2.I1.ix1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.6.m6.1.1.1.cmml" xref="S2.I1.ix1.p1.6.m6.1.1">subscript</csymbol><ci id="S2.I1.ix1.p1.6.m6.1.1.2.cmml" xref="S2.I1.ix1.p1.6.m6.1.1.2">𝕋</ci><ci id="S2.I1.ix1.p1.6.m6.1.1.3.cmml" xref="S2.I1.ix1.p1.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.6.m6.1c">\mathbb{T}_{T}</annotation></semantics></math> having <math id="S2.I1.ix1.p1.7.m7.1" class="ltx_Math" alttext="W_{T}" display="inline"><semantics id="S2.I1.ix1.p1.7.m7.1a"><msub id="S2.I1.ix1.p1.7.m7.1.1" xref="S2.I1.ix1.p1.7.m7.1.1.cmml"><mi id="S2.I1.ix1.p1.7.m7.1.1.2" xref="S2.I1.ix1.p1.7.m7.1.1.2.cmml">W</mi><mi id="S2.I1.ix1.p1.7.m7.1.1.3" xref="S2.I1.ix1.p1.7.m7.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.7.m7.1b"><apply id="S2.I1.ix1.p1.7.m7.1.1.cmml" xref="S2.I1.ix1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.7.m7.1.1.1.cmml" xref="S2.I1.ix1.p1.7.m7.1.1">subscript</csymbol><ci id="S2.I1.ix1.p1.7.m7.1.1.2.cmml" xref="S2.I1.ix1.p1.7.m7.1.1.2">𝑊</ci><ci id="S2.I1.ix1.p1.7.m7.1.1.3.cmml" xref="S2.I1.ix1.p1.7.m7.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.7.m7.1c">W_{T}</annotation></semantics></math> as weights. The settings can be adjusted across all layers or just some of (Fig. <a href="#S2.F3" title="Figure 3 ‣ 2.1 Taxonomy of existing DTL techniques ‣ 2 Overview of DTL techniques for speech recognition ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (a)). The learning rate for each layer could be distinct (discriminative fine tuning). A new set of parameters <math id="S2.I1.ix1.p1.8.m8.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.I1.ix1.p1.8.m8.1a"><mi id="S2.I1.ix1.p1.8.m8.1.1" xref="S2.I1.ix1.p1.8.m8.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.8.m8.1b"><ci id="S2.I1.ix1.p1.8.m8.1.1.cmml" xref="S2.I1.ix1.p1.8.m8.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.8.m8.1c">K</annotation></semantics></math> could be added to most of the tasks so that <math id="S2.I1.ix1.p1.9.m9.2" class="ltx_Math" alttext="\mathbb{F}_{T}(W_{T},K)=W_{S}\circ K" display="inline"><semantics id="S2.I1.ix1.p1.9.m9.2a"><mrow id="S2.I1.ix1.p1.9.m9.2.2" xref="S2.I1.ix1.p1.9.m9.2.2.cmml"><mrow id="S2.I1.ix1.p1.9.m9.2.2.1" xref="S2.I1.ix1.p1.9.m9.2.2.1.cmml"><msub id="S2.I1.ix1.p1.9.m9.2.2.1.3" xref="S2.I1.ix1.p1.9.m9.2.2.1.3.cmml"><mi id="S2.I1.ix1.p1.9.m9.2.2.1.3.2" xref="S2.I1.ix1.p1.9.m9.2.2.1.3.2.cmml">𝔽</mi><mi id="S2.I1.ix1.p1.9.m9.2.2.1.3.3" xref="S2.I1.ix1.p1.9.m9.2.2.1.3.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S2.I1.ix1.p1.9.m9.2.2.1.2" xref="S2.I1.ix1.p1.9.m9.2.2.1.2.cmml">​</mo><mrow id="S2.I1.ix1.p1.9.m9.2.2.1.1.1" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.2" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.2.cmml">(</mo><msub id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.cmml"><mi id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.2" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.2.cmml">W</mi><mi id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.3" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.3.cmml">T</mi></msub><mo id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.3" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.2.cmml">,</mo><mi id="S2.I1.ix1.p1.9.m9.1.1" xref="S2.I1.ix1.p1.9.m9.1.1.cmml">K</mi><mo stretchy="false" id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.4" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.I1.ix1.p1.9.m9.2.2.2" xref="S2.I1.ix1.p1.9.m9.2.2.2.cmml">=</mo><mrow id="S2.I1.ix1.p1.9.m9.2.2.3" xref="S2.I1.ix1.p1.9.m9.2.2.3.cmml"><msub id="S2.I1.ix1.p1.9.m9.2.2.3.2" xref="S2.I1.ix1.p1.9.m9.2.2.3.2.cmml"><mi id="S2.I1.ix1.p1.9.m9.2.2.3.2.2" xref="S2.I1.ix1.p1.9.m9.2.2.3.2.2.cmml">W</mi><mi id="S2.I1.ix1.p1.9.m9.2.2.3.2.3" xref="S2.I1.ix1.p1.9.m9.2.2.3.2.3.cmml">S</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S2.I1.ix1.p1.9.m9.2.2.3.1" xref="S2.I1.ix1.p1.9.m9.2.2.3.1.cmml">∘</mo><mi id="S2.I1.ix1.p1.9.m9.2.2.3.3" xref="S2.I1.ix1.p1.9.m9.2.2.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.9.m9.2b"><apply id="S2.I1.ix1.p1.9.m9.2.2.cmml" xref="S2.I1.ix1.p1.9.m9.2.2"><eq id="S2.I1.ix1.p1.9.m9.2.2.2.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.2"></eq><apply id="S2.I1.ix1.p1.9.m9.2.2.1.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1"><times id="S2.I1.ix1.p1.9.m9.2.2.1.2.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.2"></times><apply id="S2.I1.ix1.p1.9.m9.2.2.1.3.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.3"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.9.m9.2.2.1.3.1.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.3">subscript</csymbol><ci id="S2.I1.ix1.p1.9.m9.2.2.1.3.2.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.3.2">𝔽</ci><ci id="S2.I1.ix1.p1.9.m9.2.2.1.3.3.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.3.3">𝑇</ci></apply><interval closure="open" id="S2.I1.ix1.p1.9.m9.2.2.1.1.2.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.1"><apply id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.1.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1">subscript</csymbol><ci id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.2.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.2">𝑊</ci><ci id="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.3.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.1.1.1.1.3">𝑇</ci></apply><ci id="S2.I1.ix1.p1.9.m9.1.1.cmml" xref="S2.I1.ix1.p1.9.m9.1.1">𝐾</ci></interval></apply><apply id="S2.I1.ix1.p1.9.m9.2.2.3.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.3"><compose id="S2.I1.ix1.p1.9.m9.2.2.3.1.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.3.1"></compose><apply id="S2.I1.ix1.p1.9.m9.2.2.3.2.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.3.2"><csymbol cd="ambiguous" id="S2.I1.ix1.p1.9.m9.2.2.3.2.1.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.3.2">subscript</csymbol><ci id="S2.I1.ix1.p1.9.m9.2.2.3.2.2.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.3.2.2">𝑊</ci><ci id="S2.I1.ix1.p1.9.m9.2.2.3.2.3.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.3.2.3">𝑆</ci></apply><ci id="S2.I1.ix1.p1.9.m9.2.2.3.3.cmml" xref="S2.I1.ix1.p1.9.m9.2.2.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.9.m9.2c">\mathbb{F}_{T}(W_{T},K)=W_{S}\circ K</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2-</span> 
<div id="S2.I1.ix2.p1" class="ltx_para">
<p id="S2.I1.ix2.p1.11" class="ltx_p"><span id="S2.I1.ix2.p1.11.1" class="ltx_text ltx_font_bold">Adapter modules:</span> Given an <math id="S2.I1.ix2.p1.1.m1.1" class="ltx_Math" alttext="M_{S}" display="inline"><semantics id="S2.I1.ix2.p1.1.m1.1a"><msub id="S2.I1.ix2.p1.1.m1.1.1" xref="S2.I1.ix2.p1.1.m1.1.1.cmml"><mi id="S2.I1.ix2.p1.1.m1.1.1.2" xref="S2.I1.ix2.p1.1.m1.1.1.2.cmml">M</mi><mi id="S2.I1.ix2.p1.1.m1.1.1.3" xref="S2.I1.ix2.p1.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.1.m1.1b"><apply id="S2.I1.ix2.p1.1.m1.1.1.cmml" xref="S2.I1.ix2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.1.m1.1.1.1.cmml" xref="S2.I1.ix2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.ix2.p1.1.m1.1.1.2.cmml" xref="S2.I1.ix2.p1.1.m1.1.1.2">𝑀</ci><ci id="S2.I1.ix2.p1.1.m1.1.1.3.cmml" xref="S2.I1.ix2.p1.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.1.m1.1c">M_{S}</annotation></semantics></math> model that has been pre-trained and output <math id="S2.I1.ix2.p1.2.m2.1" class="ltx_Math" alttext="W_{S}" display="inline"><semantics id="S2.I1.ix2.p1.2.m2.1a"><msub id="S2.I1.ix2.p1.2.m2.1.1" xref="S2.I1.ix2.p1.2.m2.1.1.cmml"><mi id="S2.I1.ix2.p1.2.m2.1.1.2" xref="S2.I1.ix2.p1.2.m2.1.1.2.cmml">W</mi><mi id="S2.I1.ix2.p1.2.m2.1.1.3" xref="S2.I1.ix2.p1.2.m2.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.2.m2.1b"><apply id="S2.I1.ix2.p1.2.m2.1.1.cmml" xref="S2.I1.ix2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.2.m2.1.1.1.cmml" xref="S2.I1.ix2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.ix2.p1.2.m2.1.1.2.cmml" xref="S2.I1.ix2.p1.2.m2.1.1.2">𝑊</ci><ci id="S2.I1.ix2.p1.2.m2.1.1.3.cmml" xref="S2.I1.ix2.p1.2.m2.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.2.m2.1c">W_{S}</annotation></semantics></math>, for a target task <math id="S2.I1.ix2.p1.3.m3.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S2.I1.ix2.p1.3.m3.1a"><msub id="S2.I1.ix2.p1.3.m3.1.1" xref="S2.I1.ix2.p1.3.m3.1.1.cmml"><mi id="S2.I1.ix2.p1.3.m3.1.1.2" xref="S2.I1.ix2.p1.3.m3.1.1.2.cmml">𝕋</mi><mi id="S2.I1.ix2.p1.3.m3.1.1.3" xref="S2.I1.ix2.p1.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.3.m3.1b"><apply id="S2.I1.ix2.p1.3.m3.1.1.cmml" xref="S2.I1.ix2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.3.m3.1.1.1.cmml" xref="S2.I1.ix2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.ix2.p1.3.m3.1.1.2.cmml" xref="S2.I1.ix2.p1.3.m3.1.1.2">𝕋</ci><ci id="S2.I1.ix2.p1.3.m3.1.1.3.cmml" xref="S2.I1.ix2.p1.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.3.m3.1c">\mathbb{T}_{T}</annotation></semantics></math>. The adapter module aims to lunch a different set of parameters <math id="S2.I1.ix2.p1.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.I1.ix2.p1.4.m4.1a"><mi id="S2.I1.ix2.p1.4.m4.1.1" xref="S2.I1.ix2.p1.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.4.m4.1b"><ci id="S2.I1.ix2.p1.4.m4.1.1.cmml" xref="S2.I1.ix2.p1.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.4.m4.1c">K</annotation></semantics></math> that is too much less than <math id="S2.I1.ix2.p1.5.m5.1" class="ltx_Math" alttext="W_{S}" display="inline"><semantics id="S2.I1.ix2.p1.5.m5.1a"><msub id="S2.I1.ix2.p1.5.m5.1.1" xref="S2.I1.ix2.p1.5.m5.1.1.cmml"><mi id="S2.I1.ix2.p1.5.m5.1.1.2" xref="S2.I1.ix2.p1.5.m5.1.1.2.cmml">W</mi><mi id="S2.I1.ix2.p1.5.m5.1.1.3" xref="S2.I1.ix2.p1.5.m5.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.5.m5.1b"><apply id="S2.I1.ix2.p1.5.m5.1.1.cmml" xref="S2.I1.ix2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.5.m5.1.1.1.cmml" xref="S2.I1.ix2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.I1.ix2.p1.5.m5.1.1.2.cmml" xref="S2.I1.ix2.p1.5.m5.1.1.2">𝑊</ci><ci id="S2.I1.ix2.p1.5.m5.1.1.3.cmml" xref="S2.I1.ix2.p1.5.m5.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.5.m5.1c">W_{S}</annotation></semantics></math>, i.e, <math id="S2.I1.ix2.p1.6.m6.1" class="ltx_Math" alttext="K\ll W_{S}" display="inline"><semantics id="S2.I1.ix2.p1.6.m6.1a"><mrow id="S2.I1.ix2.p1.6.m6.1.1" xref="S2.I1.ix2.p1.6.m6.1.1.cmml"><mi id="S2.I1.ix2.p1.6.m6.1.1.2" xref="S2.I1.ix2.p1.6.m6.1.1.2.cmml">K</mi><mo id="S2.I1.ix2.p1.6.m6.1.1.1" xref="S2.I1.ix2.p1.6.m6.1.1.1.cmml">≪</mo><msub id="S2.I1.ix2.p1.6.m6.1.1.3" xref="S2.I1.ix2.p1.6.m6.1.1.3.cmml"><mi id="S2.I1.ix2.p1.6.m6.1.1.3.2" xref="S2.I1.ix2.p1.6.m6.1.1.3.2.cmml">W</mi><mi id="S2.I1.ix2.p1.6.m6.1.1.3.3" xref="S2.I1.ix2.p1.6.m6.1.1.3.3.cmml">S</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.6.m6.1b"><apply id="S2.I1.ix2.p1.6.m6.1.1.cmml" xref="S2.I1.ix2.p1.6.m6.1.1"><csymbol cd="latexml" id="S2.I1.ix2.p1.6.m6.1.1.1.cmml" xref="S2.I1.ix2.p1.6.m6.1.1.1">much-less-than</csymbol><ci id="S2.I1.ix2.p1.6.m6.1.1.2.cmml" xref="S2.I1.ix2.p1.6.m6.1.1.2">𝐾</ci><apply id="S2.I1.ix2.p1.6.m6.1.1.3.cmml" xref="S2.I1.ix2.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.6.m6.1.1.3.1.cmml" xref="S2.I1.ix2.p1.6.m6.1.1.3">subscript</csymbol><ci id="S2.I1.ix2.p1.6.m6.1.1.3.2.cmml" xref="S2.I1.ix2.p1.6.m6.1.1.3.2">𝑊</ci><ci id="S2.I1.ix2.p1.6.m6.1.1.3.3.cmml" xref="S2.I1.ix2.p1.6.m6.1.1.3.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.6.m6.1c">K\ll W_{S}</annotation></semantics></math>. <math id="S2.I1.ix2.p1.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.I1.ix2.p1.7.m7.1a"><mi id="S2.I1.ix2.p1.7.m7.1.1" xref="S2.I1.ix2.p1.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.7.m7.1b"><ci id="S2.I1.ix2.p1.7.m7.1.1.cmml" xref="S2.I1.ix2.p1.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.7.m7.1c">K</annotation></semantics></math> and <math id="S2.I1.ix2.p1.8.m8.1" class="ltx_Math" alttext="W_{S}" display="inline"><semantics id="S2.I1.ix2.p1.8.m8.1a"><msub id="S2.I1.ix2.p1.8.m8.1.1" xref="S2.I1.ix2.p1.8.m8.1.1.cmml"><mi id="S2.I1.ix2.p1.8.m8.1.1.2" xref="S2.I1.ix2.p1.8.m8.1.1.2.cmml">W</mi><mi id="S2.I1.ix2.p1.8.m8.1.1.3" xref="S2.I1.ix2.p1.8.m8.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.8.m8.1b"><apply id="S2.I1.ix2.p1.8.m8.1.1.cmml" xref="S2.I1.ix2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.8.m8.1.1.1.cmml" xref="S2.I1.ix2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.I1.ix2.p1.8.m8.1.1.2.cmml" xref="S2.I1.ix2.p1.8.m8.1.1.2">𝑊</ci><ci id="S2.I1.ix2.p1.8.m8.1.1.3.cmml" xref="S2.I1.ix2.p1.8.m8.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.8.m8.1c">W_{S}</annotation></semantics></math> must have the ability to be decomposed into more compact modules such that, <math id="S2.I1.ix2.p1.9.m9.1" class="ltx_Math" alttext="W_{S}=\{w\}_{n}" display="inline"><semantics id="S2.I1.ix2.p1.9.m9.1a"><mrow id="S2.I1.ix2.p1.9.m9.1.2" xref="S2.I1.ix2.p1.9.m9.1.2.cmml"><msub id="S2.I1.ix2.p1.9.m9.1.2.2" xref="S2.I1.ix2.p1.9.m9.1.2.2.cmml"><mi id="S2.I1.ix2.p1.9.m9.1.2.2.2" xref="S2.I1.ix2.p1.9.m9.1.2.2.2.cmml">W</mi><mi id="S2.I1.ix2.p1.9.m9.1.2.2.3" xref="S2.I1.ix2.p1.9.m9.1.2.2.3.cmml">S</mi></msub><mo id="S2.I1.ix2.p1.9.m9.1.2.1" xref="S2.I1.ix2.p1.9.m9.1.2.1.cmml">=</mo><msub id="S2.I1.ix2.p1.9.m9.1.2.3" xref="S2.I1.ix2.p1.9.m9.1.2.3.cmml"><mrow id="S2.I1.ix2.p1.9.m9.1.2.3.2.2" xref="S2.I1.ix2.p1.9.m9.1.2.3.2.1.cmml"><mo stretchy="false" id="S2.I1.ix2.p1.9.m9.1.2.3.2.2.1" xref="S2.I1.ix2.p1.9.m9.1.2.3.2.1.cmml">{</mo><mi id="S2.I1.ix2.p1.9.m9.1.1" xref="S2.I1.ix2.p1.9.m9.1.1.cmml">w</mi><mo stretchy="false" id="S2.I1.ix2.p1.9.m9.1.2.3.2.2.2" xref="S2.I1.ix2.p1.9.m9.1.2.3.2.1.cmml">}</mo></mrow><mi id="S2.I1.ix2.p1.9.m9.1.2.3.3" xref="S2.I1.ix2.p1.9.m9.1.2.3.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.9.m9.1b"><apply id="S2.I1.ix2.p1.9.m9.1.2.cmml" xref="S2.I1.ix2.p1.9.m9.1.2"><eq id="S2.I1.ix2.p1.9.m9.1.2.1.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.1"></eq><apply id="S2.I1.ix2.p1.9.m9.1.2.2.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.2"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.9.m9.1.2.2.1.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.2">subscript</csymbol><ci id="S2.I1.ix2.p1.9.m9.1.2.2.2.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.2.2">𝑊</ci><ci id="S2.I1.ix2.p1.9.m9.1.2.2.3.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.2.3">𝑆</ci></apply><apply id="S2.I1.ix2.p1.9.m9.1.2.3.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.3"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.9.m9.1.2.3.1.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.3">subscript</csymbol><set id="S2.I1.ix2.p1.9.m9.1.2.3.2.1.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.3.2.2"><ci id="S2.I1.ix2.p1.9.m9.1.1.cmml" xref="S2.I1.ix2.p1.9.m9.1.1">𝑤</ci></set><ci id="S2.I1.ix2.p1.9.m9.1.2.3.3.cmml" xref="S2.I1.ix2.p1.9.m9.1.2.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.9.m9.1c">W_{S}=\{w\}_{n}</annotation></semantics></math> and <math id="S2.I1.ix2.p1.10.m10.1" class="ltx_Math" alttext="K=\{k\}_{n}" display="inline"><semantics id="S2.I1.ix2.p1.10.m10.1a"><mrow id="S2.I1.ix2.p1.10.m10.1.2" xref="S2.I1.ix2.p1.10.m10.1.2.cmml"><mi id="S2.I1.ix2.p1.10.m10.1.2.2" xref="S2.I1.ix2.p1.10.m10.1.2.2.cmml">K</mi><mo id="S2.I1.ix2.p1.10.m10.1.2.1" xref="S2.I1.ix2.p1.10.m10.1.2.1.cmml">=</mo><msub id="S2.I1.ix2.p1.10.m10.1.2.3" xref="S2.I1.ix2.p1.10.m10.1.2.3.cmml"><mrow id="S2.I1.ix2.p1.10.m10.1.2.3.2.2" xref="S2.I1.ix2.p1.10.m10.1.2.3.2.1.cmml"><mo stretchy="false" id="S2.I1.ix2.p1.10.m10.1.2.3.2.2.1" xref="S2.I1.ix2.p1.10.m10.1.2.3.2.1.cmml">{</mo><mi id="S2.I1.ix2.p1.10.m10.1.1" xref="S2.I1.ix2.p1.10.m10.1.1.cmml">k</mi><mo stretchy="false" id="S2.I1.ix2.p1.10.m10.1.2.3.2.2.2" xref="S2.I1.ix2.p1.10.m10.1.2.3.2.1.cmml">}</mo></mrow><mi id="S2.I1.ix2.p1.10.m10.1.2.3.3" xref="S2.I1.ix2.p1.10.m10.1.2.3.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.10.m10.1b"><apply id="S2.I1.ix2.p1.10.m10.1.2.cmml" xref="S2.I1.ix2.p1.10.m10.1.2"><eq id="S2.I1.ix2.p1.10.m10.1.2.1.cmml" xref="S2.I1.ix2.p1.10.m10.1.2.1"></eq><ci id="S2.I1.ix2.p1.10.m10.1.2.2.cmml" xref="S2.I1.ix2.p1.10.m10.1.2.2">𝐾</ci><apply id="S2.I1.ix2.p1.10.m10.1.2.3.cmml" xref="S2.I1.ix2.p1.10.m10.1.2.3"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.10.m10.1.2.3.1.cmml" xref="S2.I1.ix2.p1.10.m10.1.2.3">subscript</csymbol><set id="S2.I1.ix2.p1.10.m10.1.2.3.2.1.cmml" xref="S2.I1.ix2.p1.10.m10.1.2.3.2.2"><ci id="S2.I1.ix2.p1.10.m10.1.1.cmml" xref="S2.I1.ix2.p1.10.m10.1.1">𝑘</ci></set><ci id="S2.I1.ix2.p1.10.m10.1.2.3.3.cmml" xref="S2.I1.ix2.p1.10.m10.1.2.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.10.m10.1c">K=\{k\}_{n}</annotation></semantics></math>. The adapter module permit learning the following new function <math id="S2.I1.ix2.p1.11.m11.1" class="ltx_Math" alttext="\mathbb{F}_{T}" display="inline"><semantics id="S2.I1.ix2.p1.11.m11.1a"><msub id="S2.I1.ix2.p1.11.m11.1.1" xref="S2.I1.ix2.p1.11.m11.1.1.cmml"><mi id="S2.I1.ix2.p1.11.m11.1.1.2" xref="S2.I1.ix2.p1.11.m11.1.1.2.cmml">𝔽</mi><mi id="S2.I1.ix2.p1.11.m11.1.1.3" xref="S2.I1.ix2.p1.11.m11.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.11.m11.1b"><apply id="S2.I1.ix2.p1.11.m11.1.1.cmml" xref="S2.I1.ix2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p1.11.m11.1.1.1.cmml" xref="S2.I1.ix2.p1.11.m11.1.1">subscript</csymbol><ci id="S2.I1.ix2.p1.11.m11.1.1.2.cmml" xref="S2.I1.ix2.p1.11.m11.1.1.2">𝔽</ci><ci id="S2.I1.ix2.p1.11.m11.1.1.3.cmml" xref="S2.I1.ix2.p1.11.m11.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.11.m11.1c">\mathbb{F}_{T}</annotation></semantics></math>:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\mathbb{F}_{T}(K,W_{S})=k_{1}^{\prime}\circ w_{1}\circ\dots k_{n}^{\prime}\circ w_{n}." display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.1.cmml"><msub id="S2.E1.m1.2.2.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.3.2" xref="S2.E1.m1.2.2.1.1.1.3.2.cmml">𝔽</mi><mi id="S2.E1.m1.2.2.1.1.1.3.3" xref="S2.E1.m1.2.2.1.1.1.3.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">K</mi><mo id="S2.E1.m1.2.2.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">,</mo><msub id="S2.E1.m1.2.2.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml">W</mi><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.cmml">S</mi></msub><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.4" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.2.2.1.1.2" xref="S2.E1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.2.2.1.1.3" xref="S2.E1.m1.2.2.1.1.3.cmml"><mrow id="S2.E1.m1.2.2.1.1.3.2" xref="S2.E1.m1.2.2.1.1.3.2.cmml"><mrow id="S2.E1.m1.2.2.1.1.3.2.2" xref="S2.E1.m1.2.2.1.1.3.2.2.cmml"><msubsup id="S2.E1.m1.2.2.1.1.3.2.2.2" xref="S2.E1.m1.2.2.1.1.3.2.2.2.cmml"><mi id="S2.E1.m1.2.2.1.1.3.2.2.2.2.2" xref="S2.E1.m1.2.2.1.1.3.2.2.2.2.2.cmml">k</mi><mn id="S2.E1.m1.2.2.1.1.3.2.2.2.2.3" xref="S2.E1.m1.2.2.1.1.3.2.2.2.2.3.cmml">1</mn><mo id="S2.E1.m1.2.2.1.1.3.2.2.2.3" xref="S2.E1.m1.2.2.1.1.3.2.2.2.3.cmml">′</mo></msubsup><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.2.2.1.1.3.2.2.1" xref="S2.E1.m1.2.2.1.1.3.2.2.1.cmml">∘</mo><msub id="S2.E1.m1.2.2.1.1.3.2.2.3" xref="S2.E1.m1.2.2.1.1.3.2.2.3.cmml"><mi id="S2.E1.m1.2.2.1.1.3.2.2.3.2" xref="S2.E1.m1.2.2.1.1.3.2.2.3.2.cmml">w</mi><mn id="S2.E1.m1.2.2.1.1.3.2.2.3.3" xref="S2.E1.m1.2.2.1.1.3.2.2.3.3.cmml">1</mn></msub><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.2.2.1.1.3.2.2.1a" xref="S2.E1.m1.2.2.1.1.3.2.2.1.cmml">∘</mo><mi mathvariant="normal" id="S2.E1.m1.2.2.1.1.3.2.2.4" xref="S2.E1.m1.2.2.1.1.3.2.2.4.cmml">…</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.3.2.1" xref="S2.E1.m1.2.2.1.1.3.2.1.cmml">​</mo><msubsup id="S2.E1.m1.2.2.1.1.3.2.3" xref="S2.E1.m1.2.2.1.1.3.2.3.cmml"><mi id="S2.E1.m1.2.2.1.1.3.2.3.2.2" xref="S2.E1.m1.2.2.1.1.3.2.3.2.2.cmml">k</mi><mi id="S2.E1.m1.2.2.1.1.3.2.3.2.3" xref="S2.E1.m1.2.2.1.1.3.2.3.2.3.cmml">n</mi><mo id="S2.E1.m1.2.2.1.1.3.2.3.3" xref="S2.E1.m1.2.2.1.1.3.2.3.3.cmml">′</mo></msubsup></mrow><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.2.2.1.1.3.1" xref="S2.E1.m1.2.2.1.1.3.1.cmml">∘</mo><msub id="S2.E1.m1.2.2.1.1.3.3" xref="S2.E1.m1.2.2.1.1.3.3.cmml"><mi id="S2.E1.m1.2.2.1.1.3.3.2" xref="S2.E1.m1.2.2.1.1.3.3.2.cmml">w</mi><mi id="S2.E1.m1.2.2.1.1.3.3.3" xref="S2.E1.m1.2.2.1.1.3.3.3.cmml">n</mi></msub></mrow></mrow><mo lspace="0em" id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1"><eq id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2"></eq><apply id="S2.E1.m1.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1"><times id="S2.E1.m1.2.2.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.2"></times><apply id="S2.E1.m1.2.2.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.3.2">𝔽</ci><ci id="S2.E1.m1.2.2.1.1.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.3.3">𝑇</ci></apply><interval closure="open" id="S2.E1.m1.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝐾</ci><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2">𝑊</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3">𝑆</ci></apply></interval></apply><apply id="S2.E1.m1.2.2.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.3"><compose id="S2.E1.m1.2.2.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.1"></compose><apply id="S2.E1.m1.2.2.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2"><times id="S2.E1.m1.2.2.1.1.3.2.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.1"></times><apply id="S2.E1.m1.2.2.1.1.3.2.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2"><compose id="S2.E1.m1.2.2.1.1.3.2.2.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.1"></compose><apply id="S2.E1.m1.2.2.1.1.3.2.2.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.2.2.2.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.2">superscript</csymbol><apply id="S2.E1.m1.2.2.1.1.3.2.2.2.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.3.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.2.2.2">𝑘</ci><cn type="integer" id="S2.E1.m1.2.2.1.1.3.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.2.2.3">1</cn></apply><ci id="S2.E1.m1.2.2.1.1.3.2.2.2.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.2.3">′</ci></apply><apply id="S2.E1.m1.2.2.1.1.3.2.2.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.2.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.3.2.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.3.2">𝑤</ci><cn type="integer" id="S2.E1.m1.2.2.1.1.3.2.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.3.3">1</cn></apply><ci id="S2.E1.m1.2.2.1.1.3.2.2.4.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2.4">…</ci></apply><apply id="S2.E1.m1.2.2.1.1.3.2.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3">superscript</csymbol><apply id="S2.E1.m1.2.2.1.1.3.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.2.3.2.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.3.2.3.2.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3.2.2">𝑘</ci><ci id="S2.E1.m1.2.2.1.1.3.2.3.2.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3.2.3">𝑛</ci></apply><ci id="S2.E1.m1.2.2.1.1.3.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3.3">′</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.3.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.3.2">𝑤</ci><ci id="S2.E1.m1.2.2.1.1.3.3.3.cmml" xref="S2.E1.m1.2.2.1.1.3.3.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\mathbb{F}_{T}(K,W_{S})=k_{1}^{\prime}\circ w_{1}\circ\dots k_{n}^{\prime}\circ w_{n}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.I1.ix2.p2" class="ltx_para">
<p id="S2.I1.ix2.p2.2" class="ltx_p">According to equation <a href="#S2.E1" title="In item 2- ‣ 2.1 Taxonomy of existing DTL techniques ‣ 2 Overview of DTL techniques for speech recognition ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, during the adaptation procedure, the set of original weights <math id="S2.I1.ix2.p2.1.m1.1" class="ltx_Math" alttext="W_{S}=\{w\}_{n}" display="inline"><semantics id="S2.I1.ix2.p2.1.m1.1a"><mrow id="S2.I1.ix2.p2.1.m1.1.2" xref="S2.I1.ix2.p2.1.m1.1.2.cmml"><msub id="S2.I1.ix2.p2.1.m1.1.2.2" xref="S2.I1.ix2.p2.1.m1.1.2.2.cmml"><mi id="S2.I1.ix2.p2.1.m1.1.2.2.2" xref="S2.I1.ix2.p2.1.m1.1.2.2.2.cmml">W</mi><mi id="S2.I1.ix2.p2.1.m1.1.2.2.3" xref="S2.I1.ix2.p2.1.m1.1.2.2.3.cmml">S</mi></msub><mo id="S2.I1.ix2.p2.1.m1.1.2.1" xref="S2.I1.ix2.p2.1.m1.1.2.1.cmml">=</mo><msub id="S2.I1.ix2.p2.1.m1.1.2.3" xref="S2.I1.ix2.p2.1.m1.1.2.3.cmml"><mrow id="S2.I1.ix2.p2.1.m1.1.2.3.2.2" xref="S2.I1.ix2.p2.1.m1.1.2.3.2.1.cmml"><mo stretchy="false" id="S2.I1.ix2.p2.1.m1.1.2.3.2.2.1" xref="S2.I1.ix2.p2.1.m1.1.2.3.2.1.cmml">{</mo><mi id="S2.I1.ix2.p2.1.m1.1.1" xref="S2.I1.ix2.p2.1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S2.I1.ix2.p2.1.m1.1.2.3.2.2.2" xref="S2.I1.ix2.p2.1.m1.1.2.3.2.1.cmml">}</mo></mrow><mi id="S2.I1.ix2.p2.1.m1.1.2.3.3" xref="S2.I1.ix2.p2.1.m1.1.2.3.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p2.1.m1.1b"><apply id="S2.I1.ix2.p2.1.m1.1.2.cmml" xref="S2.I1.ix2.p2.1.m1.1.2"><eq id="S2.I1.ix2.p2.1.m1.1.2.1.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.1"></eq><apply id="S2.I1.ix2.p2.1.m1.1.2.2.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.2"><csymbol cd="ambiguous" id="S2.I1.ix2.p2.1.m1.1.2.2.1.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.2">subscript</csymbol><ci id="S2.I1.ix2.p2.1.m1.1.2.2.2.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.2.2">𝑊</ci><ci id="S2.I1.ix2.p2.1.m1.1.2.2.3.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.2.3">𝑆</ci></apply><apply id="S2.I1.ix2.p2.1.m1.1.2.3.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.3"><csymbol cd="ambiguous" id="S2.I1.ix2.p2.1.m1.1.2.3.1.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.3">subscript</csymbol><set id="S2.I1.ix2.p2.1.m1.1.2.3.2.1.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.3.2.2"><ci id="S2.I1.ix2.p2.1.m1.1.1.cmml" xref="S2.I1.ix2.p2.1.m1.1.1">𝑤</ci></set><ci id="S2.I1.ix2.p2.1.m1.1.2.3.3.cmml" xref="S2.I1.ix2.p2.1.m1.1.2.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p2.1.m1.1c">W_{S}=\{w\}_{n}</annotation></semantics></math> is left unaltered, but the set of weights K is changed to <math id="S2.I1.ix2.p2.2.m2.1" class="ltx_Math" alttext="K^{\prime}=\{k^{\prime}\}_{n}" display="inline"><semantics id="S2.I1.ix2.p2.2.m2.1a"><mrow id="S2.I1.ix2.p2.2.m2.1.1" xref="S2.I1.ix2.p2.2.m2.1.1.cmml"><msup id="S2.I1.ix2.p2.2.m2.1.1.3" xref="S2.I1.ix2.p2.2.m2.1.1.3.cmml"><mi id="S2.I1.ix2.p2.2.m2.1.1.3.2" xref="S2.I1.ix2.p2.2.m2.1.1.3.2.cmml">K</mi><mo id="S2.I1.ix2.p2.2.m2.1.1.3.3" xref="S2.I1.ix2.p2.2.m2.1.1.3.3.cmml">′</mo></msup><mo id="S2.I1.ix2.p2.2.m2.1.1.2" xref="S2.I1.ix2.p2.2.m2.1.1.2.cmml">=</mo><msub id="S2.I1.ix2.p2.2.m2.1.1.1" xref="S2.I1.ix2.p2.2.m2.1.1.1.cmml"><mrow id="S2.I1.ix2.p2.2.m2.1.1.1.1.1" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.2" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.2.cmml">{</mo><msup id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.cmml"><mi id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.2" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.2.cmml">k</mi><mo id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.3" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.3" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.2.cmml">}</mo></mrow><mi id="S2.I1.ix2.p2.2.m2.1.1.1.3" xref="S2.I1.ix2.p2.2.m2.1.1.1.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p2.2.m2.1b"><apply id="S2.I1.ix2.p2.2.m2.1.1.cmml" xref="S2.I1.ix2.p2.2.m2.1.1"><eq id="S2.I1.ix2.p2.2.m2.1.1.2.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.2"></eq><apply id="S2.I1.ix2.p2.2.m2.1.1.3.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.I1.ix2.p2.2.m2.1.1.3.1.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.3">superscript</csymbol><ci id="S2.I1.ix2.p2.2.m2.1.1.3.2.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.3.2">𝐾</ci><ci id="S2.I1.ix2.p2.2.m2.1.1.3.3.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.3.3">′</ci></apply><apply id="S2.I1.ix2.p2.2.m2.1.1.1.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p2.2.m2.1.1.1.2.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.1">subscript</csymbol><set id="S2.I1.ix2.p2.2.m2.1.1.1.1.2.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.1"><apply id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.1.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1">superscript</csymbol><ci id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.2.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.2">𝑘</ci><ci id="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.3.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.1.1.1.1.3">′</ci></apply></set><ci id="S2.I1.ix2.p2.2.m2.1.1.1.3.cmml" xref="S2.I1.ix2.p2.2.m2.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p2.2.m2.1c">K^{\prime}=\{k^{\prime}\}_{n}</annotation></semantics></math>. The principle of the adaptation domain is illustrated in Fig. <a href="#S2.F3" title="Figure 3 ‣ 2.1 Taxonomy of existing DTL techniques ‣ 2 Overview of DTL techniques for speech recognition ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (b).</p>
</div>
</li>
<li id="S2.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3-</span> 
<div id="S2.I1.ix3.p1" class="ltx_para">
<p id="S2.I1.ix3.p1.5" class="ltx_p"><span id="S2.I1.ix3.p1.5.1" class="ltx_text ltx_font_bold">Feature based:</span> Interested only in learning concepts and representations, at various levels, such as, word, character, phrase, or paragraph embedding <math id="S2.I1.ix3.p1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.I1.ix3.p1.1.m1.1a"><mi id="S2.I1.ix3.p1.1.m1.1.1" xref="S2.I1.ix3.p1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.1.m1.1b"><ci id="S2.I1.ix3.p1.1.m1.1.1.cmml" xref="S2.I1.ix3.p1.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.1.m1.1c">E</annotation></semantics></math>. The collection of <math id="S2.I1.ix3.p1.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.I1.ix3.p1.2.m2.1a"><mi id="S2.I1.ix3.p1.2.m2.1.1" xref="S2.I1.ix3.p1.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.2.m2.1b"><ci id="S2.I1.ix3.p1.2.m2.1.1.cmml" xref="S2.I1.ix3.p1.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.2.m2.1c">E</annotation></semantics></math> based on a model <math id="S2.I1.ix3.p1.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.I1.ix3.p1.3.m3.1a"><mi id="S2.I1.ix3.p1.3.m3.1.1" xref="S2.I1.ix3.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.3.m3.1b"><ci id="S2.I1.ix3.p1.3.m3.1.1.cmml" xref="S2.I1.ix3.p1.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.3.m3.1c">M</annotation></semantics></math> remains unaltered, i.e., <math id="S2.I1.ix3.p1.4.m4.2" class="ltx_Math" alttext="\mathbb{F}_{T}(W_{S},E)=E\circ W^{\prime}" display="inline"><semantics id="S2.I1.ix3.p1.4.m4.2a"><mrow id="S2.I1.ix3.p1.4.m4.2.2" xref="S2.I1.ix3.p1.4.m4.2.2.cmml"><mrow id="S2.I1.ix3.p1.4.m4.2.2.1" xref="S2.I1.ix3.p1.4.m4.2.2.1.cmml"><msub id="S2.I1.ix3.p1.4.m4.2.2.1.3" xref="S2.I1.ix3.p1.4.m4.2.2.1.3.cmml"><mi id="S2.I1.ix3.p1.4.m4.2.2.1.3.2" xref="S2.I1.ix3.p1.4.m4.2.2.1.3.2.cmml">𝔽</mi><mi id="S2.I1.ix3.p1.4.m4.2.2.1.3.3" xref="S2.I1.ix3.p1.4.m4.2.2.1.3.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S2.I1.ix3.p1.4.m4.2.2.1.2" xref="S2.I1.ix3.p1.4.m4.2.2.1.2.cmml">​</mo><mrow id="S2.I1.ix3.p1.4.m4.2.2.1.1.1" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.2" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.2.cmml">(</mo><msub id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.cmml"><mi id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.2" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.2.cmml">W</mi><mi id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.3" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.3.cmml">S</mi></msub><mo id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.3" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.2.cmml">,</mo><mi id="S2.I1.ix3.p1.4.m4.1.1" xref="S2.I1.ix3.p1.4.m4.1.1.cmml">E</mi><mo stretchy="false" id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.4" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.I1.ix3.p1.4.m4.2.2.2" xref="S2.I1.ix3.p1.4.m4.2.2.2.cmml">=</mo><mrow id="S2.I1.ix3.p1.4.m4.2.2.3" xref="S2.I1.ix3.p1.4.m4.2.2.3.cmml"><mi id="S2.I1.ix3.p1.4.m4.2.2.3.2" xref="S2.I1.ix3.p1.4.m4.2.2.3.2.cmml">E</mi><mo lspace="0.222em" rspace="0.222em" id="S2.I1.ix3.p1.4.m4.2.2.3.1" xref="S2.I1.ix3.p1.4.m4.2.2.3.1.cmml">∘</mo><msup id="S2.I1.ix3.p1.4.m4.2.2.3.3" xref="S2.I1.ix3.p1.4.m4.2.2.3.3.cmml"><mi id="S2.I1.ix3.p1.4.m4.2.2.3.3.2" xref="S2.I1.ix3.p1.4.m4.2.2.3.3.2.cmml">W</mi><mo id="S2.I1.ix3.p1.4.m4.2.2.3.3.3" xref="S2.I1.ix3.p1.4.m4.2.2.3.3.3.cmml">′</mo></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.4.m4.2b"><apply id="S2.I1.ix3.p1.4.m4.2.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.2"><eq id="S2.I1.ix3.p1.4.m4.2.2.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.2"></eq><apply id="S2.I1.ix3.p1.4.m4.2.2.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1"><times id="S2.I1.ix3.p1.4.m4.2.2.1.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.2"></times><apply id="S2.I1.ix3.p1.4.m4.2.2.1.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.3"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.4.m4.2.2.1.3.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.3">subscript</csymbol><ci id="S2.I1.ix3.p1.4.m4.2.2.1.3.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.3.2">𝔽</ci><ci id="S2.I1.ix3.p1.4.m4.2.2.1.3.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.3.3">𝑇</ci></apply><interval closure="open" id="S2.I1.ix3.p1.4.m4.2.2.1.1.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.1"><apply id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1">subscript</csymbol><ci id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.2">𝑊</ci><ci id="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.1.1.1.1.3">𝑆</ci></apply><ci id="S2.I1.ix3.p1.4.m4.1.1.cmml" xref="S2.I1.ix3.p1.4.m4.1.1">𝐸</ci></interval></apply><apply id="S2.I1.ix3.p1.4.m4.2.2.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.3"><compose id="S2.I1.ix3.p1.4.m4.2.2.3.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.3.1"></compose><ci id="S2.I1.ix3.p1.4.m4.2.2.3.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.3.2">𝐸</ci><apply id="S2.I1.ix3.p1.4.m4.2.2.3.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.3.3"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.4.m4.2.2.3.3.1.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.3.3">superscript</csymbol><ci id="S2.I1.ix3.p1.4.m4.2.2.3.3.2.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.3.3.2">𝑊</ci><ci id="S2.I1.ix3.p1.4.m4.2.2.3.3.3.cmml" xref="S2.I1.ix3.p1.4.m4.2.2.3.3.3">′</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.4.m4.2c">\mathbb{F}_{T}(W_{S},E)=E\circ W^{\prime}</annotation></semantics></math>, in the way that <math id="S2.I1.ix3.p1.5.m5.1" class="ltx_Math" alttext="W^{\prime}" display="inline"><semantics id="S2.I1.ix3.p1.5.m5.1a"><msup id="S2.I1.ix3.p1.5.m5.1.1" xref="S2.I1.ix3.p1.5.m5.1.1.cmml"><mi id="S2.I1.ix3.p1.5.m5.1.1.2" xref="S2.I1.ix3.p1.5.m5.1.1.2.cmml">W</mi><mo id="S2.I1.ix3.p1.5.m5.1.1.3" xref="S2.I1.ix3.p1.5.m5.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.I1.ix3.p1.5.m5.1b"><apply id="S2.I1.ix3.p1.5.m5.1.1.cmml" xref="S2.I1.ix3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.I1.ix3.p1.5.m5.1.1.1.cmml" xref="S2.I1.ix3.p1.5.m5.1.1">superscript</csymbol><ci id="S2.I1.ix3.p1.5.m5.1.1.2.cmml" xref="S2.I1.ix3.p1.5.m5.1.1.2">𝑊</ci><ci id="S2.I1.ix3.p1.5.m5.1.1.3.cmml" xref="S2.I1.ix3.p1.5.m5.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix3.p1.5.m5.1c">W^{\prime}</annotation></semantics></math> is fine-tuned. For example, researchers have applied the generative adversarial network (GAN) principle to DTL where, the generators send features from the SD and the TD to a discriminator, which determines the source of the features and feeds the result back to the generators until they can no longer be distinguished. In this procedure, GAN obtains the common properties of two domains, as shown in Fig. <a href="#S2.F3" title="Figure 3 ‣ 2.1 Taxonomy of existing DTL techniques ‣ 2 Overview of DTL techniques for speech recognition ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (c).</p>
</div>
</li>
<li id="S2.I1.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4-</span> 
<div id="S2.I1.ix4.p1" class="ltx_para">
<p id="S2.I1.ix4.p1.4" class="ltx_p"><span id="S2.I1.ix4.p1.4.1" class="ltx_text ltx_font_bold">Zero-shot:</span> Is the easiest method among all of the others. Making the assumption that the parameters <math id="S2.I1.ix4.p1.1.m1.1" class="ltx_Math" alttext="W_{S}" display="inline"><semantics id="S2.I1.ix4.p1.1.m1.1a"><msub id="S2.I1.ix4.p1.1.m1.1.1" xref="S2.I1.ix4.p1.1.m1.1.1.cmml"><mi id="S2.I1.ix4.p1.1.m1.1.1.2" xref="S2.I1.ix4.p1.1.m1.1.1.2.cmml">W</mi><mi id="S2.I1.ix4.p1.1.m1.1.1.3" xref="S2.I1.ix4.p1.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix4.p1.1.m1.1b"><apply id="S2.I1.ix4.p1.1.m1.1.1.cmml" xref="S2.I1.ix4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.ix4.p1.1.m1.1.1.1.cmml" xref="S2.I1.ix4.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.ix4.p1.1.m1.1.1.2.cmml" xref="S2.I1.ix4.p1.1.m1.1.1.2">𝑊</ci><ci id="S2.I1.ix4.p1.1.m1.1.1.3.cmml" xref="S2.I1.ix4.p1.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix4.p1.1.m1.1c">W_{S}</annotation></semantics></math> can’t be modified or add <math id="S2.I1.ix4.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.I1.ix4.p1.2.m2.1a"><mi id="S2.I1.ix4.p1.2.m2.1.1" xref="S2.I1.ix4.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.I1.ix4.p1.2.m2.1b"><ci id="S2.I1.ix4.p1.2.m2.1.1.cmml" xref="S2.I1.ix4.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix4.p1.2.m2.1c">K</annotation></semantics></math> as a new parameters to a pre-trained model <math id="S2.I1.ix4.p1.3.m3.1" class="ltx_Math" alttext="M_{S}" display="inline"><semantics id="S2.I1.ix4.p1.3.m3.1a"><msub id="S2.I1.ix4.p1.3.m3.1.1" xref="S2.I1.ix4.p1.3.m3.1.1.cmml"><mi id="S2.I1.ix4.p1.3.m3.1.1.2" xref="S2.I1.ix4.p1.3.m3.1.1.2.cmml">M</mi><mi id="S2.I1.ix4.p1.3.m3.1.1.3" xref="S2.I1.ix4.p1.3.m3.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix4.p1.3.m3.1b"><apply id="S2.I1.ix4.p1.3.m3.1.1.cmml" xref="S2.I1.ix4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.ix4.p1.3.m3.1.1.1.cmml" xref="S2.I1.ix4.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.ix4.p1.3.m3.1.1.2.cmml" xref="S2.I1.ix4.p1.3.m3.1.1.2">𝑀</ci><ci id="S2.I1.ix4.p1.3.m3.1.1.3.cmml" xref="S2.I1.ix4.p1.3.m3.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix4.p1.3.m3.1c">M_{S}</annotation></semantics></math> using <math id="S2.I1.ix4.p1.4.m4.1" class="ltx_Math" alttext="W_{S}" display="inline"><semantics id="S2.I1.ix4.p1.4.m4.1a"><msub id="S2.I1.ix4.p1.4.m4.1.1" xref="S2.I1.ix4.p1.4.m4.1.1.cmml"><mi id="S2.I1.ix4.p1.4.m4.1.1.2" xref="S2.I1.ix4.p1.4.m4.1.1.2.cmml">W</mi><mi id="S2.I1.ix4.p1.4.m4.1.1.3" xref="S2.I1.ix4.p1.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.ix4.p1.4.m4.1b"><apply id="S2.I1.ix4.p1.4.m4.1.1.cmml" xref="S2.I1.ix4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.I1.ix4.p1.4.m4.1.1.1.cmml" xref="S2.I1.ix4.p1.4.m4.1.1">subscript</csymbol><ci id="S2.I1.ix4.p1.4.m4.1.1.2.cmml" xref="S2.I1.ix4.p1.4.m4.1.1.2">𝑊</ci><ci id="S2.I1.ix4.p1.4.m4.1.1.3.cmml" xref="S2.I1.ix4.p1.4.m4.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix4.p1.4.m4.1c">W_{S}</annotation></semantics></math>. To put this into context, in zero-shot there is no training technique to optimize or learn new parameters.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2403.01255/assets/x3.png" id="S2.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="402" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S2.F3.4.2" class="ltx_text" style="font-size:90%;">Structures of: (a) Fine-tuning, (b) DA, and (c) DTL-based GAN.</span></figcaption>
</figure>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Transductive DTL</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.14" class="ltx_p">Compared to the traditional ML, which can be considered as a reference for DTL comparison, and given that the TDs <math id="S2.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p1.1.m1.1a"><msub id="S2.SS1.SSS1.p1.1.m1.1.1" xref="S2.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S2.SS1.SSS1.p1.1.m1.1.1.2" xref="S2.SS1.SSS1.p1.1.m1.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p1.1.m1.1.1.3" xref="S2.SS1.SSS1.p1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.1.m1.1b"><apply id="S2.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.SSS1.p1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.1.m1.1c">\mathbb{D}_{T}</annotation></semantics></math> are distinct from the SDs <math id="S2.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p1.2.m2.1a"><msub id="S2.SS1.SSS1.p1.2.m2.1.1" xref="S2.SS1.SSS1.p1.2.m2.1.1.cmml"><mi id="S2.SS1.SSS1.p1.2.m2.1.1.2" xref="S2.SS1.SSS1.p1.2.m2.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p1.2.m2.1.1.3" xref="S2.SS1.SSS1.p1.2.m2.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.2.m2.1b"><apply id="S2.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.SSS1.p1.2.m2.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.SSS1.p1.2.m2.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.2.m2.1c">\mathbb{D}_{S}</annotation></semantics></math>. The SD has a labeled dataset (<math id="S2.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="X_{S}" display="inline"><semantics id="S2.SS1.SSS1.p1.3.m3.1a"><msub id="S2.SS1.SSS1.p1.3.m3.1.1" xref="S2.SS1.SSS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.SSS1.p1.3.m3.1.1.2" xref="S2.SS1.SSS1.p1.3.m3.1.1.2.cmml">X</mi><mi id="S2.SS1.SSS1.p1.3.m3.1.1.3" xref="S2.SS1.SSS1.p1.3.m3.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.3.m3.1b"><apply id="S2.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS1.p1.3.m3.1.1.2">𝑋</ci><ci id="S2.SS1.SSS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.SSS1.p1.3.m3.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.3.m3.1c">X_{S}</annotation></semantics></math> labeled with <math id="S2.SS1.SSS1.p1.4.m4.1" class="ltx_Math" alttext="Y_{S}" display="inline"><semantics id="S2.SS1.SSS1.p1.4.m4.1a"><msub id="S2.SS1.SSS1.p1.4.m4.1.1" xref="S2.SS1.SSS1.p1.4.m4.1.1.cmml"><mi id="S2.SS1.SSS1.p1.4.m4.1.1.2" xref="S2.SS1.SSS1.p1.4.m4.1.1.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p1.4.m4.1.1.3" xref="S2.SS1.SSS1.p1.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.4.m4.1b"><apply id="S2.SS1.SSS1.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.SSS1.p1.4.m4.1.1.2">𝑌</ci><ci id="S2.SS1.SSS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.SSS1.p1.4.m4.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.4.m4.1c">Y_{S}</annotation></semantics></math>), whereas the TD has no labeled dataset, the source and target tasks are equal ( Table <a href="#S2.T2" title="Table 2 ‣ 2.1 Taxonomy of existing DTL techniques ‣ 2 Overview of DTL techniques for speech recognition ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). The goal of transductive DTL is to build the target prediction function <math id="S2.SS1.SSS1.p1.5.m5.1" class="ltx_Math" alttext="\mathbb{F}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p1.5.m5.1a"><msub id="S2.SS1.SSS1.p1.5.m5.1.1" xref="S2.SS1.SSS1.p1.5.m5.1.1.cmml"><mi id="S2.SS1.SSS1.p1.5.m5.1.1.2" xref="S2.SS1.SSS1.p1.5.m5.1.1.2.cmml">𝔽</mi><mi id="S2.SS1.SSS1.p1.5.m5.1.1.3" xref="S2.SS1.SSS1.p1.5.m5.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.5.m5.1b"><apply id="S2.SS1.SSS1.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.SSS1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.SSS1.p1.5.m5.1.1.2">𝔽</ci><ci id="S2.SS1.SSS1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.SSS1.p1.5.m5.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.5.m5.1c">\mathbb{F}_{T}</annotation></semantics></math> in the <math id="S2.SS1.SSS1.p1.6.m6.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p1.6.m6.1a"><msub id="S2.SS1.SSS1.p1.6.m6.1.1" xref="S2.SS1.SSS1.p1.6.m6.1.1.cmml"><mi id="S2.SS1.SSS1.p1.6.m6.1.1.2" xref="S2.SS1.SSS1.p1.6.m6.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p1.6.m6.1.1.3" xref="S2.SS1.SSS1.p1.6.m6.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.6.m6.1b"><apply id="S2.SS1.SSS1.p1.6.m6.1.1.cmml" xref="S2.SS1.SSS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.6.m6.1.1.1.cmml" xref="S2.SS1.SSS1.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.6.m6.1.1.2.cmml" xref="S2.SS1.SSS1.p1.6.m6.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p1.6.m6.1.1.3.cmml" xref="S2.SS1.SSS1.p1.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.6.m6.1c">\mathbb{D}_{T}</annotation></semantics></math> by knowledge of the <math id="S2.SS1.SSS1.p1.7.m7.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p1.7.m7.1a"><msub id="S2.SS1.SSS1.p1.7.m7.1.1" xref="S2.SS1.SSS1.p1.7.m7.1.1.cmml"><mi id="S2.SS1.SSS1.p1.7.m7.1.1.2" xref="S2.SS1.SSS1.p1.7.m7.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p1.7.m7.1.1.3" xref="S2.SS1.SSS1.p1.7.m7.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.7.m7.1b"><apply id="S2.SS1.SSS1.p1.7.m7.1.1.cmml" xref="S2.SS1.SSS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.7.m7.1.1.1.cmml" xref="S2.SS1.SSS1.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.7.m7.1.1.2.cmml" xref="S2.SS1.SSS1.p1.7.m7.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p1.7.m7.1.1.3.cmml" xref="S2.SS1.SSS1.p1.7.m7.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.7.m7.1c">\mathbb{D}_{S}</annotation></semantics></math> and <math id="S2.SS1.SSS1.p1.8.m8.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p1.8.m8.1a"><msub id="S2.SS1.SSS1.p1.8.m8.1.1" xref="S2.SS1.SSS1.p1.8.m8.1.1.cmml"><mi id="S2.SS1.SSS1.p1.8.m8.1.1.2" xref="S2.SS1.SSS1.p1.8.m8.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.SSS1.p1.8.m8.1.1.3" xref="S2.SS1.SSS1.p1.8.m8.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.8.m8.1b"><apply id="S2.SS1.SSS1.p1.8.m8.1.1.cmml" xref="S2.SS1.SSS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.8.m8.1.1.1.cmml" xref="S2.SS1.SSS1.p1.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.8.m8.1.1.2.cmml" xref="S2.SS1.SSS1.p1.8.m8.1.1.2">𝕋</ci><ci id="S2.SS1.SSS1.p1.8.m8.1.1.3.cmml" xref="S2.SS1.SSS1.p1.8.m8.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.8.m8.1c">\mathbb{T}_{T}</annotation></semantics></math>. Furthermore, the transductive DTL environment may be further classified into two categories depending on different conditions between the source and destination domains:
<br class="ltx_break"><span id="S2.SS1.SSS1.p1.14.1" class="ltx_text ltx_font_bold">(a) Domain adaptation (DA):</span> The feature spaces across domains, <math id="S2.SS1.SSS1.p1.9.m9.1" class="ltx_Math" alttext="\chi_{S}" display="inline"><semantics id="S2.SS1.SSS1.p1.9.m9.1a"><msub id="S2.SS1.SSS1.p1.9.m9.1.1" xref="S2.SS1.SSS1.p1.9.m9.1.1.cmml"><mi id="S2.SS1.SSS1.p1.9.m9.1.1.2" xref="S2.SS1.SSS1.p1.9.m9.1.1.2.cmml">χ</mi><mi id="S2.SS1.SSS1.p1.9.m9.1.1.3" xref="S2.SS1.SSS1.p1.9.m9.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.9.m9.1b"><apply id="S2.SS1.SSS1.p1.9.m9.1.1.cmml" xref="S2.SS1.SSS1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.9.m9.1.1.1.cmml" xref="S2.SS1.SSS1.p1.9.m9.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.9.m9.1.1.2.cmml" xref="S2.SS1.SSS1.p1.9.m9.1.1.2">𝜒</ci><ci id="S2.SS1.SSS1.p1.9.m9.1.1.3.cmml" xref="S2.SS1.SSS1.p1.9.m9.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.9.m9.1c">\chi_{S}</annotation></semantics></math> and <math id="S2.SS1.SSS1.p1.10.m10.1" class="ltx_Math" alttext="\chi_{T}" display="inline"><semantics id="S2.SS1.SSS1.p1.10.m10.1a"><msub id="S2.SS1.SSS1.p1.10.m10.1.1" xref="S2.SS1.SSS1.p1.10.m10.1.1.cmml"><mi id="S2.SS1.SSS1.p1.10.m10.1.1.2" xref="S2.SS1.SSS1.p1.10.m10.1.1.2.cmml">χ</mi><mi id="S2.SS1.SSS1.p1.10.m10.1.1.3" xref="S2.SS1.SSS1.p1.10.m10.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.10.m10.1b"><apply id="S2.SS1.SSS1.p1.10.m10.1.1.cmml" xref="S2.SS1.SSS1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.10.m10.1.1.1.cmml" xref="S2.SS1.SSS1.p1.10.m10.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.10.m10.1.1.2.cmml" xref="S2.SS1.SSS1.p1.10.m10.1.1.2">𝜒</ci><ci id="S2.SS1.SSS1.p1.10.m10.1.1.3.cmml" xref="S2.SS1.SSS1.p1.10.m10.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.10.m10.1c">\chi_{T}</annotation></semantics></math>, are the identical, but the marginal probability distributions of the input dataset are not, <math id="S2.SS1.SSS1.p1.11.m11.2" class="ltx_Math" alttext="P(Y_{S}/X_{S})\neq P(Y_{T}/X_{T})" display="inline"><semantics id="S2.SS1.SSS1.p1.11.m11.2a"><mrow id="S2.SS1.SSS1.p1.11.m11.2.2" xref="S2.SS1.SSS1.p1.11.m11.2.2.cmml"><mrow id="S2.SS1.SSS1.p1.11.m11.1.1.1" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.cmml"><mi id="S2.SS1.SSS1.p1.11.m11.1.1.1.3" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS1.p1.11.m11.1.1.1.2" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.2.cmml">​</mo><mrow id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.2" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.cmml"><msub id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.cmml"><mi id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.2" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.3" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.3.cmml">S</mi></msub><mo id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.1" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.1.cmml">/</mo><msub id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.cmml"><mi id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.2" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.2.cmml">X</mi><mi id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.3" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.3.cmml">S</mi></msub></mrow><mo stretchy="false" id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.3" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.SSS1.p1.11.m11.2.2.3" xref="S2.SS1.SSS1.p1.11.m11.2.2.3.cmml">≠</mo><mrow id="S2.SS1.SSS1.p1.11.m11.2.2.2" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.cmml"><mi id="S2.SS1.SSS1.p1.11.m11.2.2.2.3" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS1.p1.11.m11.2.2.2.2" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.2.cmml">​</mo><mrow id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.2" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.cmml"><msub id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.cmml"><mi id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.2" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.3" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.3.cmml">T</mi></msub><mo id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.1" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.1.cmml">/</mo><msub id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.cmml"><mi id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.2" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.2.cmml">X</mi><mi id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.3" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.3.cmml">T</mi></msub></mrow><mo stretchy="false" id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.3" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.11.m11.2b"><apply id="S2.SS1.SSS1.p1.11.m11.2.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2"><neq id="S2.SS1.SSS1.p1.11.m11.2.2.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.3"></neq><apply id="S2.SS1.SSS1.p1.11.m11.1.1.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1"><times id="S2.SS1.SSS1.p1.11.m11.1.1.1.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.2"></times><ci id="S2.SS1.SSS1.p1.11.m11.1.1.1.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.3">𝑃</ci><apply id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1"><divide id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.1"></divide><apply id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.2">𝑌</ci><ci id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.2.3">𝑆</ci></apply><apply id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.2">𝑋</ci><ci id="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.1.1.1.1.1.1.3.3">𝑆</ci></apply></apply></apply><apply id="S2.SS1.SSS1.p1.11.m11.2.2.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2"><times id="S2.SS1.SSS1.p1.11.m11.2.2.2.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.2"></times><ci id="S2.SS1.SSS1.p1.11.m11.2.2.2.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.3">𝑃</ci><apply id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1"><divide id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.1"></divide><apply id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2">subscript</csymbol><ci id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.2">𝑌</ci><ci id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.2.3">𝑇</ci></apply><apply id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.1.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.2.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.2">𝑋</ci><ci id="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.3.cmml" xref="S2.SS1.SSS1.p1.11.m11.2.2.2.1.1.1.3.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.11.m11.2c">P(Y_{S}/X_{S})\neq P(Y_{T}/X_{T})</annotation></semantics></math>. For example, an assessment may be done on the topic of the resort in the <math id="S2.SS1.SSS1.p1.12.m12.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p1.12.m12.1a"><msub id="S2.SS1.SSS1.p1.12.m12.1.1" xref="S2.SS1.SSS1.p1.12.m12.1.1.cmml"><mi id="S2.SS1.SSS1.p1.12.m12.1.1.2" xref="S2.SS1.SSS1.p1.12.m12.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p1.12.m12.1.1.3" xref="S2.SS1.SSS1.p1.12.m12.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.12.m12.1b"><apply id="S2.SS1.SSS1.p1.12.m12.1.1.cmml" xref="S2.SS1.SSS1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.12.m12.1.1.1.cmml" xref="S2.SS1.SSS1.p1.12.m12.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.12.m12.1.1.2.cmml" xref="S2.SS1.SSS1.p1.12.m12.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p1.12.m12.1.1.3.cmml" xref="S2.SS1.SSS1.p1.12.m12.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.12.m12.1c">\mathbb{D}_{S}</annotation></semantics></math> and it will be used to train a model for restaurants in the <math id="S2.SS1.SSS1.p1.13.m13.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p1.13.m13.1a"><msub id="S2.SS1.SSS1.p1.13.m13.1.1" xref="S2.SS1.SSS1.p1.13.m13.1.1.cmml"><mi id="S2.SS1.SSS1.p1.13.m13.1.1.2" xref="S2.SS1.SSS1.p1.13.m13.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p1.13.m13.1.1.3" xref="S2.SS1.SSS1.p1.13.m13.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.13.m13.1b"><apply id="S2.SS1.SSS1.p1.13.m13.1.1.cmml" xref="S2.SS1.SSS1.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.13.m13.1.1.1.cmml" xref="S2.SS1.SSS1.p1.13.m13.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.13.m13.1.1.2.cmml" xref="S2.SS1.SSS1.p1.13.m13.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p1.13.m13.1.1.3.cmml" xref="S2.SS1.SSS1.p1.13.m13.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.13.m13.1c">\mathbb{D}_{T}</annotation></semantics></math>. DA is mostly effective when the <math id="S2.SS1.SSS1.p1.14.m14.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p1.14.m14.1a"><msub id="S2.SS1.SSS1.p1.14.m14.1.1" xref="S2.SS1.SSS1.p1.14.m14.1.1.cmml"><mi id="S2.SS1.SSS1.p1.14.m14.1.1.2" xref="S2.SS1.SSS1.p1.14.m14.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.SSS1.p1.14.m14.1.1.3" xref="S2.SS1.SSS1.p1.14.m14.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p1.14.m14.1b"><apply id="S2.SS1.SSS1.p1.14.m14.1.1.cmml" xref="S2.SS1.SSS1.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p1.14.m14.1.1.1.cmml" xref="S2.SS1.SSS1.p1.14.m14.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p1.14.m14.1.1.2.cmml" xref="S2.SS1.SSS1.p1.14.m14.1.1.2">𝕋</ci><ci id="S2.SS1.SSS1.p1.14.m14.1.1.3.cmml" xref="S2.SS1.SSS1.p1.14.m14.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p1.14.m14.1c">\mathbb{T}_{T}</annotation></semantics></math> has a distinct distribution or there is a scarcity of labeled data.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS1.p2.6" class="ltx_p"><span id="S2.SS1.SSS1.p2.6.1" class="ltx_text ltx_font_bold">(b) Cross-modality DTL:</span> Also known as cross-lingual DTL in the spoken language field, most DTL methods, more or less, a connection in feature spaces or label spaces is required between <math id="S2.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p2.1.m1.1a"><msub id="S2.SS1.SSS1.p2.1.m1.1.1" xref="S2.SS1.SSS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.SSS1.p2.1.m1.1.1.2" xref="S2.SS1.SSS1.p2.1.m1.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p2.1.m1.1.1.3" xref="S2.SS1.SSS1.p2.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.1.m1.1b"><apply id="S2.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS1.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.SSS1.p2.1.m1.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.SSS1.p2.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.1.m1.1c">\mathbb{D}_{S}</annotation></semantics></math> and <math id="S2.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p2.2.m2.1a"><msub id="S2.SS1.SSS1.p2.2.m2.1.1" xref="S2.SS1.SSS1.p2.2.m2.1.1.cmml"><mi id="S2.SS1.SSS1.p2.2.m2.1.1.2" xref="S2.SS1.SSS1.p2.2.m2.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p2.2.m2.1.1.3" xref="S2.SS1.SSS1.p2.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.2.m2.1b"><apply id="S2.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS1.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p2.2.m2.1.1.1.cmml" xref="S2.SS1.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p2.2.m2.1.1.2.cmml" xref="S2.SS1.SSS1.p2.2.m2.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p2.2.m2.1.1.3.cmml" xref="S2.SS1.SSS1.p2.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.2.m2.1c">\mathbb{D}_{T}</annotation></semantics></math>. In other words, DTL can only occur when the source and destination data are both in the same modality, like video, speech, or text. cross-lingual DTL, in contrast to all other DTL approaches, is one of the most complicated issues in DTL. It is assumed that the feature spaces of the source and destination domains are completely distinct (<math id="S2.SS1.SSS1.p2.3.m3.1" class="ltx_Math" alttext="\chi_{S}\neq\chi_{T}" display="inline"><semantics id="S2.SS1.SSS1.p2.3.m3.1a"><mrow id="S2.SS1.SSS1.p2.3.m3.1.1" xref="S2.SS1.SSS1.p2.3.m3.1.1.cmml"><msub id="S2.SS1.SSS1.p2.3.m3.1.1.2" xref="S2.SS1.SSS1.p2.3.m3.1.1.2.cmml"><mi id="S2.SS1.SSS1.p2.3.m3.1.1.2.2" xref="S2.SS1.SSS1.p2.3.m3.1.1.2.2.cmml">χ</mi><mi id="S2.SS1.SSS1.p2.3.m3.1.1.2.3" xref="S2.SS1.SSS1.p2.3.m3.1.1.2.3.cmml">S</mi></msub><mo id="S2.SS1.SSS1.p2.3.m3.1.1.1" xref="S2.SS1.SSS1.p2.3.m3.1.1.1.cmml">≠</mo><msub id="S2.SS1.SSS1.p2.3.m3.1.1.3" xref="S2.SS1.SSS1.p2.3.m3.1.1.3.cmml"><mi id="S2.SS1.SSS1.p2.3.m3.1.1.3.2" xref="S2.SS1.SSS1.p2.3.m3.1.1.3.2.cmml">χ</mi><mi id="S2.SS1.SSS1.p2.3.m3.1.1.3.3" xref="S2.SS1.SSS1.p2.3.m3.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.3.m3.1b"><apply id="S2.SS1.SSS1.p2.3.m3.1.1.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1"><neq id="S2.SS1.SSS1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.1"></neq><apply id="S2.SS1.SSS1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p2.3.m3.1.1.2.1.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.2">subscript</csymbol><ci id="S2.SS1.SSS1.p2.3.m3.1.1.2.2.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.2.2">𝜒</ci><ci id="S2.SS1.SSS1.p2.3.m3.1.1.2.3.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.2.3">𝑆</ci></apply><apply id="S2.SS1.SSS1.p2.3.m3.1.1.3.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p2.3.m3.1.1.3.1.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS1.p2.3.m3.1.1.3.2.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.3.2">𝜒</ci><ci id="S2.SS1.SSS1.p2.3.m3.1.1.3.3.cmml" xref="S2.SS1.SSS1.p2.3.m3.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.3.m3.1c">\chi_{S}\neq\chi_{T}</annotation></semantics></math>), as in speech-to-image, image-to-text, and text-to-speech. Furthermore, the label spaces of source <math id="S2.SS1.SSS1.p2.4.m4.1" class="ltx_Math" alttext="Y_{S}" display="inline"><semantics id="S2.SS1.SSS1.p2.4.m4.1a"><msub id="S2.SS1.SSS1.p2.4.m4.1.1" xref="S2.SS1.SSS1.p2.4.m4.1.1.cmml"><mi id="S2.SS1.SSS1.p2.4.m4.1.1.2" xref="S2.SS1.SSS1.p2.4.m4.1.1.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p2.4.m4.1.1.3" xref="S2.SS1.SSS1.p2.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.4.m4.1b"><apply id="S2.SS1.SSS1.p2.4.m4.1.1.cmml" xref="S2.SS1.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p2.4.m4.1.1.1.cmml" xref="S2.SS1.SSS1.p2.4.m4.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p2.4.m4.1.1.2.cmml" xref="S2.SS1.SSS1.p2.4.m4.1.1.2">𝑌</ci><ci id="S2.SS1.SSS1.p2.4.m4.1.1.3.cmml" xref="S2.SS1.SSS1.p2.4.m4.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.4.m4.1c">Y_{S}</annotation></semantics></math> and destination <math id="S2.SS1.SSS1.p2.5.m5.1" class="ltx_Math" alttext="Y_{S}" display="inline"><semantics id="S2.SS1.SSS1.p2.5.m5.1a"><msub id="S2.SS1.SSS1.p2.5.m5.1.1" xref="S2.SS1.SSS1.p2.5.m5.1.1.cmml"><mi id="S2.SS1.SSS1.p2.5.m5.1.1.2" xref="S2.SS1.SSS1.p2.5.m5.1.1.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p2.5.m5.1.1.3" xref="S2.SS1.SSS1.p2.5.m5.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.5.m5.1b"><apply id="S2.SS1.SSS1.p2.5.m5.1.1.cmml" xref="S2.SS1.SSS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.SSS1.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.SSS1.p2.5.m5.1.1.2">𝑌</ci><ci id="S2.SS1.SSS1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.SSS1.p2.5.m5.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.5.m5.1c">Y_{S}</annotation></semantics></math> domains might differ (<math id="S2.SS1.SSS1.p2.6.m6.1" class="ltx_Math" alttext="Y_{S}\neq Y_{T}" display="inline"><semantics id="S2.SS1.SSS1.p2.6.m6.1a"><mrow id="S2.SS1.SSS1.p2.6.m6.1.1" xref="S2.SS1.SSS1.p2.6.m6.1.1.cmml"><msub id="S2.SS1.SSS1.p2.6.m6.1.1.2" xref="S2.SS1.SSS1.p2.6.m6.1.1.2.cmml"><mi id="S2.SS1.SSS1.p2.6.m6.1.1.2.2" xref="S2.SS1.SSS1.p2.6.m6.1.1.2.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p2.6.m6.1.1.2.3" xref="S2.SS1.SSS1.p2.6.m6.1.1.2.3.cmml">S</mi></msub><mo id="S2.SS1.SSS1.p2.6.m6.1.1.1" xref="S2.SS1.SSS1.p2.6.m6.1.1.1.cmml">≠</mo><msub id="S2.SS1.SSS1.p2.6.m6.1.1.3" xref="S2.SS1.SSS1.p2.6.m6.1.1.3.cmml"><mi id="S2.SS1.SSS1.p2.6.m6.1.1.3.2" xref="S2.SS1.SSS1.p2.6.m6.1.1.3.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p2.6.m6.1.1.3.3" xref="S2.SS1.SSS1.p2.6.m6.1.1.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p2.6.m6.1b"><apply id="S2.SS1.SSS1.p2.6.m6.1.1.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1"><neq id="S2.SS1.SSS1.p2.6.m6.1.1.1.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.1"></neq><apply id="S2.SS1.SSS1.p2.6.m6.1.1.2.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p2.6.m6.1.1.2.1.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.2">subscript</csymbol><ci id="S2.SS1.SSS1.p2.6.m6.1.1.2.2.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.2.2">𝑌</ci><ci id="S2.SS1.SSS1.p2.6.m6.1.1.2.3.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.2.3">𝑆</ci></apply><apply id="S2.SS1.SSS1.p2.6.m6.1.1.3.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p2.6.m6.1.1.3.1.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.3">subscript</csymbol><ci id="S2.SS1.SSS1.p2.6.m6.1.1.3.2.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.3.2">𝑌</ci><ci id="S2.SS1.SSS1.p2.6.m6.1.1.3.3.cmml" xref="S2.SS1.SSS1.p2.6.m6.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p2.6.m6.1c">Y_{S}\neq Y_{T}</annotation></semantics></math>).</p>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS1.p3.14" class="ltx_p"><span id="S2.SS1.SSS1.p3.14.1" class="ltx_text ltx_font_bold">(c) Unsupervised DTL:</span> Intends to enhance the learning of the target predictive function <math id="S2.SS1.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\mathbb{F}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p3.1.m1.1a"><msub id="S2.SS1.SSS1.p3.1.m1.1.1" xref="S2.SS1.SSS1.p3.1.m1.1.1.cmml"><mi id="S2.SS1.SSS1.p3.1.m1.1.1.2" xref="S2.SS1.SSS1.p3.1.m1.1.1.2.cmml">𝔽</mi><mi id="S2.SS1.SSS1.p3.1.m1.1.1.3" xref="S2.SS1.SSS1.p3.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.1.m1.1b"><apply id="S2.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S2.SS1.SSS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.SSS1.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.SSS1.p3.1.m1.1.1.2">𝔽</ci><ci id="S2.SS1.SSS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.SSS1.p3.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.1.m1.1c">\mathbb{F}_{T}</annotation></semantics></math> in <math id="S2.SS1.SSS1.p3.2.m2.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p3.2.m2.1a"><msub id="S2.SS1.SSS1.p3.2.m2.1.1" xref="S2.SS1.SSS1.p3.2.m2.1.1.cmml"><mi id="S2.SS1.SSS1.p3.2.m2.1.1.2" xref="S2.SS1.SSS1.p3.2.m2.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p3.2.m2.1.1.3" xref="S2.SS1.SSS1.p3.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.2.m2.1b"><apply id="S2.SS1.SSS1.p3.2.m2.1.1.cmml" xref="S2.SS1.SSS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.2.m2.1.1.1.cmml" xref="S2.SS1.SSS1.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.2.m2.1.1.2.cmml" xref="S2.SS1.SSS1.p3.2.m2.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p3.2.m2.1.1.3.cmml" xref="S2.SS1.SSS1.p3.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.2.m2.1c">\mathbb{D}_{T}</annotation></semantics></math> using the knowledge in <math id="S2.SS1.SSS1.p3.3.m3.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p3.3.m3.1a"><msub id="S2.SS1.SSS1.p3.3.m3.1.1" xref="S2.SS1.SSS1.p3.3.m3.1.1.cmml"><mi id="S2.SS1.SSS1.p3.3.m3.1.1.2" xref="S2.SS1.SSS1.p3.3.m3.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p3.3.m3.1.1.3" xref="S2.SS1.SSS1.p3.3.m3.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.3.m3.1b"><apply id="S2.SS1.SSS1.p3.3.m3.1.1.cmml" xref="S2.SS1.SSS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.3.m3.1.1.1.cmml" xref="S2.SS1.SSS1.p3.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.3.m3.1.1.2.cmml" xref="S2.SS1.SSS1.p3.3.m3.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p3.3.m3.1.1.3.cmml" xref="S2.SS1.SSS1.p3.3.m3.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.3.m3.1c">\mathbb{D}_{S}</annotation></semantics></math> and <math id="S2.SS1.SSS1.p3.4.m4.1" class="ltx_Math" alttext="\mathbb{T}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p3.4.m4.1a"><msub id="S2.SS1.SSS1.p3.4.m4.1.1" xref="S2.SS1.SSS1.p3.4.m4.1.1.cmml"><mi id="S2.SS1.SSS1.p3.4.m4.1.1.2" xref="S2.SS1.SSS1.p3.4.m4.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.SSS1.p3.4.m4.1.1.3" xref="S2.SS1.SSS1.p3.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.4.m4.1b"><apply id="S2.SS1.SSS1.p3.4.m4.1.1.cmml" xref="S2.SS1.SSS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.4.m4.1.1.1.cmml" xref="S2.SS1.SSS1.p3.4.m4.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.4.m4.1.1.2.cmml" xref="S2.SS1.SSS1.p3.4.m4.1.1.2">𝕋</ci><ci id="S2.SS1.SSS1.p3.4.m4.1.1.3.cmml" xref="S2.SS1.SSS1.p3.4.m4.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.4.m4.1c">\mathbb{T}_{S}</annotation></semantics></math>, where <math id="S2.SS1.SSS1.p3.5.m5.1" class="ltx_Math" alttext="\mathbb{T}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p3.5.m5.1a"><msub id="S2.SS1.SSS1.p3.5.m5.1.1" xref="S2.SS1.SSS1.p3.5.m5.1.1.cmml"><mi id="S2.SS1.SSS1.p3.5.m5.1.1.2" xref="S2.SS1.SSS1.p3.5.m5.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.SSS1.p3.5.m5.1.1.3" xref="S2.SS1.SSS1.p3.5.m5.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.5.m5.1b"><apply id="S2.SS1.SSS1.p3.5.m5.1.1.cmml" xref="S2.SS1.SSS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.5.m5.1.1.1.cmml" xref="S2.SS1.SSS1.p3.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.5.m5.1.1.2.cmml" xref="S2.SS1.SSS1.p3.5.m5.1.1.2">𝕋</ci><ci id="S2.SS1.SSS1.p3.5.m5.1.1.3.cmml" xref="S2.SS1.SSS1.p3.5.m5.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.5.m5.1c">\mathbb{T}_{S}</annotation></semantics></math> different from <math id="S2.SS1.SSS1.p3.6.m6.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p3.6.m6.1a"><msub id="S2.SS1.SSS1.p3.6.m6.1.1" xref="S2.SS1.SSS1.p3.6.m6.1.1.cmml"><mi id="S2.SS1.SSS1.p3.6.m6.1.1.2" xref="S2.SS1.SSS1.p3.6.m6.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.SSS1.p3.6.m6.1.1.3" xref="S2.SS1.SSS1.p3.6.m6.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.6.m6.1b"><apply id="S2.SS1.SSS1.p3.6.m6.1.1.cmml" xref="S2.SS1.SSS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.6.m6.1.1.1.cmml" xref="S2.SS1.SSS1.p3.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.6.m6.1.1.2.cmml" xref="S2.SS1.SSS1.p3.6.m6.1.1.2">𝕋</ci><ci id="S2.SS1.SSS1.p3.6.m6.1.1.3.cmml" xref="S2.SS1.SSS1.p3.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.6.m6.1c">\mathbb{T}_{T}</annotation></semantics></math> but related, and <math id="S2.SS1.SSS1.p3.7.m7.1" class="ltx_Math" alttext="Y_{S}" display="inline"><semantics id="S2.SS1.SSS1.p3.7.m7.1a"><msub id="S2.SS1.SSS1.p3.7.m7.1.1" xref="S2.SS1.SSS1.p3.7.m7.1.1.cmml"><mi id="S2.SS1.SSS1.p3.7.m7.1.1.2" xref="S2.SS1.SSS1.p3.7.m7.1.1.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p3.7.m7.1.1.3" xref="S2.SS1.SSS1.p3.7.m7.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.7.m7.1b"><apply id="S2.SS1.SSS1.p3.7.m7.1.1.cmml" xref="S2.SS1.SSS1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.7.m7.1.1.1.cmml" xref="S2.SS1.SSS1.p3.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.7.m7.1.1.2.cmml" xref="S2.SS1.SSS1.p3.7.m7.1.1.2">𝑌</ci><ci id="S2.SS1.SSS1.p3.7.m7.1.1.3.cmml" xref="S2.SS1.SSS1.p3.7.m7.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.7.m7.1c">Y_{S}</annotation></semantics></math> and <math id="S2.SS1.SSS1.p3.8.m8.1" class="ltx_Math" alttext="Y_{T}" display="inline"><semantics id="S2.SS1.SSS1.p3.8.m8.1a"><msub id="S2.SS1.SSS1.p3.8.m8.1.1" xref="S2.SS1.SSS1.p3.8.m8.1.1.cmml"><mi id="S2.SS1.SSS1.p3.8.m8.1.1.2" xref="S2.SS1.SSS1.p3.8.m8.1.1.2.cmml">Y</mi><mi id="S2.SS1.SSS1.p3.8.m8.1.1.3" xref="S2.SS1.SSS1.p3.8.m8.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.8.m8.1b"><apply id="S2.SS1.SSS1.p3.8.m8.1.1.cmml" xref="S2.SS1.SSS1.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.8.m8.1.1.1.cmml" xref="S2.SS1.SSS1.p3.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.8.m8.1.1.2.cmml" xref="S2.SS1.SSS1.p3.8.m8.1.1.2">𝑌</ci><ci id="S2.SS1.SSS1.p3.8.m8.1.1.3.cmml" xref="S2.SS1.SSS1.p3.8.m8.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.8.m8.1c">Y_{T}</annotation></semantics></math> are not visible, given a SD <math id="S2.SS1.SSS1.p3.9.m9.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p3.9.m9.1a"><msub id="S2.SS1.SSS1.p3.9.m9.1.1" xref="S2.SS1.SSS1.p3.9.m9.1.1.cmml"><mi id="S2.SS1.SSS1.p3.9.m9.1.1.2" xref="S2.SS1.SSS1.p3.9.m9.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p3.9.m9.1.1.3" xref="S2.SS1.SSS1.p3.9.m9.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.9.m9.1b"><apply id="S2.SS1.SSS1.p3.9.m9.1.1.cmml" xref="S2.SS1.SSS1.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.9.m9.1.1.1.cmml" xref="S2.SS1.SSS1.p3.9.m9.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.9.m9.1.1.2.cmml" xref="S2.SS1.SSS1.p3.9.m9.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p3.9.m9.1.1.3.cmml" xref="S2.SS1.SSS1.p3.9.m9.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.9.m9.1c">\mathbb{D}_{S}</annotation></semantics></math> with a learning task <math id="S2.SS1.SSS1.p3.10.m10.1" class="ltx_Math" alttext="\mathbb{T}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p3.10.m10.1a"><msub id="S2.SS1.SSS1.p3.10.m10.1.1" xref="S2.SS1.SSS1.p3.10.m10.1.1.cmml"><mi id="S2.SS1.SSS1.p3.10.m10.1.1.2" xref="S2.SS1.SSS1.p3.10.m10.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.SSS1.p3.10.m10.1.1.3" xref="S2.SS1.SSS1.p3.10.m10.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.10.m10.1b"><apply id="S2.SS1.SSS1.p3.10.m10.1.1.cmml" xref="S2.SS1.SSS1.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.10.m10.1.1.1.cmml" xref="S2.SS1.SSS1.p3.10.m10.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.10.m10.1.1.2.cmml" xref="S2.SS1.SSS1.p3.10.m10.1.1.2">𝕋</ci><ci id="S2.SS1.SSS1.p3.10.m10.1.1.3.cmml" xref="S2.SS1.SSS1.p3.10.m10.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.10.m10.1c">\mathbb{T}_{S}</annotation></semantics></math>, a TD <math id="S2.SS1.SSS1.p3.11.m11.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p3.11.m11.1a"><msub id="S2.SS1.SSS1.p3.11.m11.1.1" xref="S2.SS1.SSS1.p3.11.m11.1.1.cmml"><mi id="S2.SS1.SSS1.p3.11.m11.1.1.2" xref="S2.SS1.SSS1.p3.11.m11.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p3.11.m11.1.1.3" xref="S2.SS1.SSS1.p3.11.m11.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.11.m11.1b"><apply id="S2.SS1.SSS1.p3.11.m11.1.1.cmml" xref="S2.SS1.SSS1.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.11.m11.1.1.1.cmml" xref="S2.SS1.SSS1.p3.11.m11.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.11.m11.1.1.2.cmml" xref="S2.SS1.SSS1.p3.11.m11.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p3.11.m11.1.1.3.cmml" xref="S2.SS1.SSS1.p3.11.m11.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.11.m11.1c">\mathbb{D}_{T}</annotation></semantics></math> and a matching learning task <math id="S2.SS1.SSS1.p3.12.m12.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p3.12.m12.1a"><msub id="S2.SS1.SSS1.p3.12.m12.1.1" xref="S2.SS1.SSS1.p3.12.m12.1.1.cmml"><mi id="S2.SS1.SSS1.p3.12.m12.1.1.2" xref="S2.SS1.SSS1.p3.12.m12.1.1.2.cmml">𝕋</mi><mi id="S2.SS1.SSS1.p3.12.m12.1.1.3" xref="S2.SS1.SSS1.p3.12.m12.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.12.m12.1b"><apply id="S2.SS1.SSS1.p3.12.m12.1.1.cmml" xref="S2.SS1.SSS1.p3.12.m12.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.12.m12.1.1.1.cmml" xref="S2.SS1.SSS1.p3.12.m12.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.12.m12.1.1.2.cmml" xref="S2.SS1.SSS1.p3.12.m12.1.1.2">𝕋</ci><ci id="S2.SS1.SSS1.p3.12.m12.1.1.3.cmml" xref="S2.SS1.SSS1.p3.12.m12.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.12.m12.1c">\mathbb{T}_{T}</annotation></semantics></math> (<math id="S2.SS1.SSS1.p3.13.m13.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S2.SS1.SSS1.p3.13.m13.1a"><msub id="S2.SS1.SSS1.p3.13.m13.1.1" xref="S2.SS1.SSS1.p3.13.m13.1.1.cmml"><mi id="S2.SS1.SSS1.p3.13.m13.1.1.2" xref="S2.SS1.SSS1.p3.13.m13.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p3.13.m13.1.1.3" xref="S2.SS1.SSS1.p3.13.m13.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.13.m13.1b"><apply id="S2.SS1.SSS1.p3.13.m13.1.1.cmml" xref="S2.SS1.SSS1.p3.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.13.m13.1.1.1.cmml" xref="S2.SS1.SSS1.p3.13.m13.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.13.m13.1.1.2.cmml" xref="S2.SS1.SSS1.p3.13.m13.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p3.13.m13.1.1.3.cmml" xref="S2.SS1.SSS1.p3.13.m13.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.13.m13.1c">\mathbb{D}_{S}</annotation></semantics></math> different from <math id="S2.SS1.SSS1.p3.14.m14.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S2.SS1.SSS1.p3.14.m14.1a"><msub id="S2.SS1.SSS1.p3.14.m14.1.1" xref="S2.SS1.SSS1.p3.14.m14.1.1.cmml"><mi id="S2.SS1.SSS1.p3.14.m14.1.1.2" xref="S2.SS1.SSS1.p3.14.m14.1.1.2.cmml">𝔻</mi><mi id="S2.SS1.SSS1.p3.14.m14.1.1.3" xref="S2.SS1.SSS1.p3.14.m14.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS1.p3.14.m14.1b"><apply id="S2.SS1.SSS1.p3.14.m14.1.1.cmml" xref="S2.SS1.SSS1.p3.14.m14.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS1.p3.14.m14.1.1.1.cmml" xref="S2.SS1.SSS1.p3.14.m14.1.1">subscript</csymbol><ci id="S2.SS1.SSS1.p3.14.m14.1.1.2.cmml" xref="S2.SS1.SSS1.p3.14.m14.1.1.2">𝔻</ci><ci id="S2.SS1.SSS1.p3.14.m14.1.1.3.cmml" xref="S2.SS1.SSS1.p3.14.m14.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS1.p3.14.m14.1c">\mathbb{D}_{T}</annotation></semantics></math>, but related).</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Adversarial DTL</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.1" class="ltx_p">In contrast to the methods described above for DTL, adversarial learning <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020transfer</span>]</cite> aids in the learning of more transferable and discriminative representations. The work in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ganin2016domain</span>]</cite>, was the first that introduced the domain-adversarial neural network (DANN). Instead of using a predefined distance function like maximum mean discrepancy (MMD), the core idea is to use a domain-adversarial loss in the network. This has greatly aided the network’s ability to learn more discriminative data. Many studies have used domain-adversarial training as a result of DANN’s idea <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bousmalis2016domain</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019joint</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">long2017deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018collaborative</span>]</cite>. All of the previous work ignores the different effects of marginal and conditional distributions in adversarial TL, whereas in <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020transfer</span>]</cite>, the proposed scheme, named dynamic distribution alignment (DDA), can dynamically evaluate the importance of each distribution.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Background</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Acoustic and language models</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> is in charge of capturing the sound characteristics of different phonetic units. This involves generating statistical measures for characteristic vector sequences from the audio waveform. Various techniques, such as  <a href="#Sx1.25.25.25"><span href="#Sx1.25.25.25" title="linear predictive coding" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">linear predictive coding</span></span></span></a> (<a href="#Sx1.25.25.25"><abbr href="#Sx1.25.25.25" title="linear predictive coding" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LPC</span></span></abbr></a>), Cepstral analysis, filter-bank analysis, <a href="#Sx1.28.28.28"><span href="#Sx1.28.28.28" title="Mel-frequency cepstral coefficient" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long-plural"><span class="ltx_text" style="font-size:80%;">Mel-frequency cepstral coefficient</span>s</span></span></a>, wavelet analysis, and others, can be used to extract these features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">37</span></a>]</cite>. In the processing stage, a decoder (search algorithm) uses the acoustic lexicon and <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a> to create the hypothesized word or phoneme. You can see the overall process illustrated in Figure <a href="#S3.F4" title="Figure 4 ‣ 3.1 Acoustic and language models ‣ 3 Background ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<span id="S3.SS1.p2.2" class="ltx_ERROR undefined">\Acp</span>
<p id="S3.SS1.p2.1" class="ltx_p">LM provide probabilities of sequences of words, crucial for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems to predict the likelihood of subsequent words in a sentence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">38</span></a>]</cite>. A domain-specific LM is trained on text data from the target domain to capture its unique vocabulary and grammatical structures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">39</span></a>]</cite>. For n-gram models, this involves calculating the conditional probability of a word given the previous <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="n-1" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">n</mi><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">−</mo><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><minus id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></minus><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝑛</ci><cn type="integer" id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">n-1</annotation></semantics></math> words <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">40</span></a>]</cite>:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E2.m1.11" class="ltx_Math" alttext="P(w_{n}|w_{n-1},w_{n-2},\ldots,w_{n-(n-1)})=\frac{C(w_{n-(n-1)},\ldots,w_{n})}{C(w_{n-(n-1)},\ldots,w_{n-1})}" display="block"><semantics id="S3.E2.m1.11a"><mrow id="S3.E2.m1.11.11" xref="S3.E2.m1.11.11.cmml"><mrow id="S3.E2.m1.11.11.1" xref="S3.E2.m1.11.11.1.cmml"><mi id="S3.E2.m1.11.11.1.3" xref="S3.E2.m1.11.11.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.11.11.1.2" xref="S3.E2.m1.11.11.1.2.cmml">​</mo><mrow id="S3.E2.m1.11.11.1.1.1" xref="S3.E2.m1.11.11.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.11.11.1.1.1.2" xref="S3.E2.m1.11.11.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.11.11.1.1.1.1" xref="S3.E2.m1.11.11.1.1.1.1.cmml"><msub id="S3.E2.m1.11.11.1.1.1.1.5" xref="S3.E2.m1.11.11.1.1.1.1.5.cmml"><mi id="S3.E2.m1.11.11.1.1.1.1.5.2" xref="S3.E2.m1.11.11.1.1.1.1.5.2.cmml">w</mi><mi id="S3.E2.m1.11.11.1.1.1.1.5.3" xref="S3.E2.m1.11.11.1.1.1.1.5.3.cmml">n</mi></msub><mo fence="false" id="S3.E2.m1.11.11.1.1.1.1.4" xref="S3.E2.m1.11.11.1.1.1.1.4.cmml">|</mo><mrow id="S3.E2.m1.11.11.1.1.1.1.3.3" xref="S3.E2.m1.11.11.1.1.1.1.3.4.cmml"><msub id="S3.E2.m1.11.11.1.1.1.1.1.1.1" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.11.11.1.1.1.1.1.1.1.2" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.2.cmml">w</mi><mrow id="S3.E2.m1.11.11.1.1.1.1.1.1.1.3" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.2.cmml">n</mi><mo id="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.1" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.E2.m1.11.11.1.1.1.1.3.3.4" xref="S3.E2.m1.11.11.1.1.1.1.3.4.cmml">,</mo><msub id="S3.E2.m1.11.11.1.1.1.1.2.2.2" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.cmml"><mi id="S3.E2.m1.11.11.1.1.1.1.2.2.2.2" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.2.cmml">w</mi><mrow id="S3.E2.m1.11.11.1.1.1.1.2.2.2.3" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.cmml"><mi id="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.2" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.2.cmml">n</mi><mo id="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.1" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.1.cmml">−</mo><mn id="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.3" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.3.cmml">2</mn></mrow></msub><mo id="S3.E2.m1.11.11.1.1.1.1.3.3.5" xref="S3.E2.m1.11.11.1.1.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E2.m1.10.10" xref="S3.E2.m1.10.10.cmml">…</mi><mo id="S3.E2.m1.11.11.1.1.1.1.3.3.6" xref="S3.E2.m1.11.11.1.1.1.1.3.4.cmml">,</mo><msub id="S3.E2.m1.11.11.1.1.1.1.3.3.3" xref="S3.E2.m1.11.11.1.1.1.1.3.3.3.cmml"><mi id="S3.E2.m1.11.11.1.1.1.1.3.3.3.2" xref="S3.E2.m1.11.11.1.1.1.1.3.3.3.2.cmml">w</mi><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">n</mi><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">−</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">n</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub></mrow></mrow><mo stretchy="false" id="S3.E2.m1.11.11.1.1.1.3" xref="S3.E2.m1.11.11.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.11.11.2" xref="S3.E2.m1.11.11.2.cmml">=</mo><mfrac id="S3.E2.m1.9.9" xref="S3.E2.m1.9.9.cmml"><mrow id="S3.E2.m1.5.5.4" xref="S3.E2.m1.5.5.4.cmml"><mi id="S3.E2.m1.5.5.4.6" xref="S3.E2.m1.5.5.4.6.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.4.5" xref="S3.E2.m1.5.5.4.5.cmml">​</mo><mrow id="S3.E2.m1.5.5.4.4.2" xref="S3.E2.m1.5.5.4.4.3.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.4.4.2.3" xref="S3.E2.m1.5.5.4.4.3.cmml">(</mo><msub id="S3.E2.m1.4.4.3.3.1.1" xref="S3.E2.m1.4.4.3.3.1.1.cmml"><mi id="S3.E2.m1.4.4.3.3.1.1.2" xref="S3.E2.m1.4.4.3.3.1.1.2.cmml">w</mi><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.3.cmml">n</mi><mo id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml">−</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2.cmml">n</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml">−</mo><mn id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub><mo id="S3.E2.m1.5.5.4.4.2.4" xref="S3.E2.m1.5.5.4.4.3.cmml">,</mo><mi mathvariant="normal" id="S3.E2.m1.3.3.2.2" xref="S3.E2.m1.3.3.2.2.cmml">…</mi><mo id="S3.E2.m1.5.5.4.4.2.5" xref="S3.E2.m1.5.5.4.4.3.cmml">,</mo><msub id="S3.E2.m1.5.5.4.4.2.2" xref="S3.E2.m1.5.5.4.4.2.2.cmml"><mi id="S3.E2.m1.5.5.4.4.2.2.2" xref="S3.E2.m1.5.5.4.4.2.2.2.cmml">w</mi><mi id="S3.E2.m1.5.5.4.4.2.2.3" xref="S3.E2.m1.5.5.4.4.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S3.E2.m1.5.5.4.4.2.6" xref="S3.E2.m1.5.5.4.4.3.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.9.9.8" xref="S3.E2.m1.9.9.8.cmml"><mi id="S3.E2.m1.9.9.8.6" xref="S3.E2.m1.9.9.8.6.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.9.9.8.5" xref="S3.E2.m1.9.9.8.5.cmml">​</mo><mrow id="S3.E2.m1.9.9.8.4.2" xref="S3.E2.m1.9.9.8.4.3.cmml"><mo stretchy="false" id="S3.E2.m1.9.9.8.4.2.3" xref="S3.E2.m1.9.9.8.4.3.cmml">(</mo><msub id="S3.E2.m1.8.8.7.3.1.1" xref="S3.E2.m1.8.8.7.3.1.1.cmml"><mi id="S3.E2.m1.8.8.7.3.1.1.2" xref="S3.E2.m1.8.8.7.3.1.1.2.cmml">w</mi><mrow id="S3.E2.m1.6.6.5.1.1" xref="S3.E2.m1.6.6.5.1.1.cmml"><mi id="S3.E2.m1.6.6.5.1.1.3" xref="S3.E2.m1.6.6.5.1.1.3.cmml">n</mi><mo id="S3.E2.m1.6.6.5.1.1.2" xref="S3.E2.m1.6.6.5.1.1.2.cmml">−</mo><mrow id="S3.E2.m1.6.6.5.1.1.1.1" xref="S3.E2.m1.6.6.5.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.5.1.1.1.1.2" xref="S3.E2.m1.6.6.5.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.6.6.5.1.1.1.1.1" xref="S3.E2.m1.6.6.5.1.1.1.1.1.cmml"><mi id="S3.E2.m1.6.6.5.1.1.1.1.1.2" xref="S3.E2.m1.6.6.5.1.1.1.1.1.2.cmml">n</mi><mo id="S3.E2.m1.6.6.5.1.1.1.1.1.1" xref="S3.E2.m1.6.6.5.1.1.1.1.1.1.cmml">−</mo><mn id="S3.E2.m1.6.6.5.1.1.1.1.1.3" xref="S3.E2.m1.6.6.5.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.E2.m1.6.6.5.1.1.1.1.3" xref="S3.E2.m1.6.6.5.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub><mo id="S3.E2.m1.9.9.8.4.2.4" xref="S3.E2.m1.9.9.8.4.3.cmml">,</mo><mi mathvariant="normal" id="S3.E2.m1.7.7.6.2" xref="S3.E2.m1.7.7.6.2.cmml">…</mi><mo id="S3.E2.m1.9.9.8.4.2.5" xref="S3.E2.m1.9.9.8.4.3.cmml">,</mo><msub id="S3.E2.m1.9.9.8.4.2.2" xref="S3.E2.m1.9.9.8.4.2.2.cmml"><mi id="S3.E2.m1.9.9.8.4.2.2.2" xref="S3.E2.m1.9.9.8.4.2.2.2.cmml">w</mi><mrow id="S3.E2.m1.9.9.8.4.2.2.3" xref="S3.E2.m1.9.9.8.4.2.2.3.cmml"><mi id="S3.E2.m1.9.9.8.4.2.2.3.2" xref="S3.E2.m1.9.9.8.4.2.2.3.2.cmml">n</mi><mo id="S3.E2.m1.9.9.8.4.2.2.3.1" xref="S3.E2.m1.9.9.8.4.2.2.3.1.cmml">−</mo><mn id="S3.E2.m1.9.9.8.4.2.2.3.3" xref="S3.E2.m1.9.9.8.4.2.2.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="S3.E2.m1.9.9.8.4.2.6" xref="S3.E2.m1.9.9.8.4.3.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.11b"><apply id="S3.E2.m1.11.11.cmml" xref="S3.E2.m1.11.11"><eq id="S3.E2.m1.11.11.2.cmml" xref="S3.E2.m1.11.11.2"></eq><apply id="S3.E2.m1.11.11.1.cmml" xref="S3.E2.m1.11.11.1"><times id="S3.E2.m1.11.11.1.2.cmml" xref="S3.E2.m1.11.11.1.2"></times><ci id="S3.E2.m1.11.11.1.3.cmml" xref="S3.E2.m1.11.11.1.3">𝑃</ci><apply id="S3.E2.m1.11.11.1.1.1.1.cmml" xref="S3.E2.m1.11.11.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.11.11.1.1.1.1.4.cmml" xref="S3.E2.m1.11.11.1.1.1.1.4">conditional</csymbol><apply id="S3.E2.m1.11.11.1.1.1.1.5.cmml" xref="S3.E2.m1.11.11.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E2.m1.11.11.1.1.1.1.5.1.cmml" xref="S3.E2.m1.11.11.1.1.1.1.5">subscript</csymbol><ci id="S3.E2.m1.11.11.1.1.1.1.5.2.cmml" xref="S3.E2.m1.11.11.1.1.1.1.5.2">𝑤</ci><ci id="S3.E2.m1.11.11.1.1.1.1.5.3.cmml" xref="S3.E2.m1.11.11.1.1.1.1.5.3">𝑛</ci></apply><list id="S3.E2.m1.11.11.1.1.1.1.3.4.cmml" xref="S3.E2.m1.11.11.1.1.1.1.3.3"><apply id="S3.E2.m1.11.11.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.11.11.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.11.11.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.2">𝑤</ci><apply id="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.3"><minus id="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.1"></minus><ci id="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.2">𝑛</ci><cn type="integer" id="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.11.11.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.E2.m1.11.11.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.11.11.1.1.1.1.2.2.2.1.cmml" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.11.11.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.2">𝑤</ci><apply id="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.3"><minus id="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.1"></minus><ci id="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.2">𝑛</ci><cn type="integer" id="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E2.m1.11.11.1.1.1.1.2.2.2.3.3">2</cn></apply></apply><ci id="S3.E2.m1.10.10.cmml" xref="S3.E2.m1.10.10">…</ci><apply id="S3.E2.m1.11.11.1.1.1.1.3.3.3.cmml" xref="S3.E2.m1.11.11.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.11.11.1.1.1.1.3.3.3.1.cmml" xref="S3.E2.m1.11.11.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E2.m1.11.11.1.1.1.1.3.3.3.2.cmml" xref="S3.E2.m1.11.11.1.1.1.1.3.3.3.2">𝑤</ci><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><minus id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></minus><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">𝑛</ci><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><minus id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"></minus><ci id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">1</cn></apply></apply></apply></list></apply></apply><apply id="S3.E2.m1.9.9.cmml" xref="S3.E2.m1.9.9"><divide id="S3.E2.m1.9.9.9.cmml" xref="S3.E2.m1.9.9"></divide><apply id="S3.E2.m1.5.5.4.cmml" xref="S3.E2.m1.5.5.4"><times id="S3.E2.m1.5.5.4.5.cmml" xref="S3.E2.m1.5.5.4.5"></times><ci id="S3.E2.m1.5.5.4.6.cmml" xref="S3.E2.m1.5.5.4.6">𝐶</ci><vector id="S3.E2.m1.5.5.4.4.3.cmml" xref="S3.E2.m1.5.5.4.4.2"><apply id="S3.E2.m1.4.4.3.3.1.1.cmml" xref="S3.E2.m1.4.4.3.3.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.3.1.1.1.cmml" xref="S3.E2.m1.4.4.3.3.1.1">subscript</csymbol><ci id="S3.E2.m1.4.4.3.3.1.1.2.cmml" xref="S3.E2.m1.4.4.3.3.1.1.2">𝑤</ci><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><minus id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2"></minus><ci id="S3.E2.m1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.3">𝑛</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"><minus id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1"></minus><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S3.E2.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.3">1</cn></apply></apply></apply><ci id="S3.E2.m1.3.3.2.2.cmml" xref="S3.E2.m1.3.3.2.2">…</ci><apply id="S3.E2.m1.5.5.4.4.2.2.cmml" xref="S3.E2.m1.5.5.4.4.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.4.4.2.2.1.cmml" xref="S3.E2.m1.5.5.4.4.2.2">subscript</csymbol><ci id="S3.E2.m1.5.5.4.4.2.2.2.cmml" xref="S3.E2.m1.5.5.4.4.2.2.2">𝑤</ci><ci id="S3.E2.m1.5.5.4.4.2.2.3.cmml" xref="S3.E2.m1.5.5.4.4.2.2.3">𝑛</ci></apply></vector></apply><apply id="S3.E2.m1.9.9.8.cmml" xref="S3.E2.m1.9.9.8"><times id="S3.E2.m1.9.9.8.5.cmml" xref="S3.E2.m1.9.9.8.5"></times><ci id="S3.E2.m1.9.9.8.6.cmml" xref="S3.E2.m1.9.9.8.6">𝐶</ci><vector id="S3.E2.m1.9.9.8.4.3.cmml" xref="S3.E2.m1.9.9.8.4.2"><apply id="S3.E2.m1.8.8.7.3.1.1.cmml" xref="S3.E2.m1.8.8.7.3.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.7.3.1.1.1.cmml" xref="S3.E2.m1.8.8.7.3.1.1">subscript</csymbol><ci id="S3.E2.m1.8.8.7.3.1.1.2.cmml" xref="S3.E2.m1.8.8.7.3.1.1.2">𝑤</ci><apply id="S3.E2.m1.6.6.5.1.1.cmml" xref="S3.E2.m1.6.6.5.1.1"><minus id="S3.E2.m1.6.6.5.1.1.2.cmml" xref="S3.E2.m1.6.6.5.1.1.2"></minus><ci id="S3.E2.m1.6.6.5.1.1.3.cmml" xref="S3.E2.m1.6.6.5.1.1.3">𝑛</ci><apply id="S3.E2.m1.6.6.5.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.5.1.1.1.1"><minus id="S3.E2.m1.6.6.5.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.5.1.1.1.1.1.1"></minus><ci id="S3.E2.m1.6.6.5.1.1.1.1.1.2.cmml" xref="S3.E2.m1.6.6.5.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S3.E2.m1.6.6.5.1.1.1.1.1.3.cmml" xref="S3.E2.m1.6.6.5.1.1.1.1.1.3">1</cn></apply></apply></apply><ci id="S3.E2.m1.7.7.6.2.cmml" xref="S3.E2.m1.7.7.6.2">…</ci><apply id="S3.E2.m1.9.9.8.4.2.2.cmml" xref="S3.E2.m1.9.9.8.4.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.9.9.8.4.2.2.1.cmml" xref="S3.E2.m1.9.9.8.4.2.2">subscript</csymbol><ci id="S3.E2.m1.9.9.8.4.2.2.2.cmml" xref="S3.E2.m1.9.9.8.4.2.2.2">𝑤</ci><apply id="S3.E2.m1.9.9.8.4.2.2.3.cmml" xref="S3.E2.m1.9.9.8.4.2.2.3"><minus id="S3.E2.m1.9.9.8.4.2.2.3.1.cmml" xref="S3.E2.m1.9.9.8.4.2.2.3.1"></minus><ci id="S3.E2.m1.9.9.8.4.2.2.3.2.cmml" xref="S3.E2.m1.9.9.8.4.2.2.3.2">𝑛</ci><cn type="integer" id="S3.E2.m1.9.9.8.4.2.2.3.3.cmml" xref="S3.E2.m1.9.9.8.4.2.2.3.3">1</cn></apply></apply></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.11c">P(w_{n}|w_{n-1},w_{n-2},\ldots,w_{n-(n-1)})=\frac{C(w_{n-(n-1)},\ldots,w_{n})}{C(w_{n-(n-1)},\ldots,w_{n-1})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In the context of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, the <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a> complements the <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> by providing linguistic context. The combined probability from the <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> and the <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a> helps in determining the most likely transcription for a given audio input during the decoding process. The frequently utilized <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a> in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems is the backoff n-gram model.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2403.01255/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="212" height="116" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">Diagram illustrating the end-to-end framework for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation criteria in ASR</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To assess the effectiveness and suitability of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> techniques, researchers have employed diverse methods. Some of these encompass well-established <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> metrics, including accuracy, F1-score, recall (sensitivity or  <a href="#Sx1.50.50.50"><span href="#Sx1.50.50.50" title="true positive rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">true positive rate</span></span></span></a> (<a href="#Sx1.50.50.50"><abbr href="#Sx1.50.50.50" title="true positive rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">TPR</span></span></abbr></a>)), precision (also known as positive predictive value), and specificity (commonly referred to as  <a href="#Sx1.49.49.49"><span href="#Sx1.49.49.49" title="true negative rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">true negative rate</span></span></span></a> (<a href="#Sx1.49.49.49"><abbr href="#Sx1.49.49.49" title="true negative rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">TNR</span></span></abbr></a>)) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">41</span></a>]</cite>. These metrics serve as crucial evaluation criteria for experimental outcomes, as evidenced in studies such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">42</span></a>, <a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">43</span></a>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">44</span></a>]</cite>. Additionally, there are <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>-specific metrics, which are detailed in Table <a href="#S3.T3" title="Table 3 ‣ 3.2 Evaluation criteria in ASR ‣ 3 Background ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.17" class="ltx_tabular ltx_align_middle">
<tr id="S3.T3.17.18" class="ltx_tr">
<td id="S3.T3.17.18.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<div id="S3.T3.17.18.1.1" class="ltx_block ltx_align_top">
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_block"><span id="S3.T3.17.18.1.1.4.1.1" class="ltx_text" style="font-size:129%;">Table 3</span>: </span><span id="S3.T3.17.18.1.1.5.2" class="ltx_text" style="font-size:129%;">An overview of the metrics employed for evaluating <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> methods.</span></figcaption>
</div>
</td>
<td id="S3.T3.17.18.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;"></td>
<td id="S3.T3.17.18.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:284.5pt;"></td>
</tr>
<tr id="S3.T3.17.19" class="ltx_tr">
<td id="S3.T3.17.19.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T3.17.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.17.19.1.1.1" class="ltx_p"><span id="S3.T3.17.19.1.1.1.1" class="ltx_text" style="font-size:70%;">Metric</span></span>
</span>
</td>
<td id="S3.T3.17.19.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:142.3pt;">
<span id="S3.T3.17.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.17.19.2.1.1" class="ltx_p"><span id="S3.T3.17.19.2.1.1.1" class="ltx_text" style="font-size:70%;">Formula</span></span>
</span>
</td>
<td id="S3.T3.17.19.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:284.5pt;">
<span id="S3.T3.17.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.17.19.3.1.1" class="ltx_p"><span id="S3.T3.17.19.3.1.1.1" class="ltx_text" style="font-size:70%;">Description</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.3.3" class="ltx_tr">
<td id="S3.T3.3.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;padding-bottom:22.76228pt;">
<span id="S3.T3.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.3.3.4.1.1" class="ltx_p"><a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">WER</span></span></abbr></a></span>
</span>
</td>
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:142.3pt;padding-bottom:22.76228pt;">
<span id="S3.T3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.1.1" class="ltx_p"><math id="S3.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\mathrm{\frac{S+D+I}{N}=\frac{S+D+I}{H+S+D}}." display="inline"><semantics id="S3.T3.1.1.1.1.1.m1.1a"><mrow id="S3.T3.1.1.1.1.1.m1.1.1.1" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.cmml"><mrow id="S3.T3.1.1.1.1.1.m1.1.1.1.1" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.cmml"><mfrac id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2a" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.cmml"><mrow id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.cmml"><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.2" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.2.cmml">S</mi><mo mathsize="70%" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.1" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.1.cmml">+</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.3" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.3.cmml">D</mi><mo mathsize="70%" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.1a" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.1.cmml">+</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.4" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.4.cmml">I</mi></mrow><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.3" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.3.cmml">N</mi></mfrac></mstyle><mo mathsize="70%" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.1" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mfrac id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3a" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mrow id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.cmml"><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.2" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.2.cmml">S</mi><mo mathsize="70%" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.1" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.1.cmml">+</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.3" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.3.cmml">D</mi><mo mathsize="70%" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.1a" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.1.cmml">+</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.4" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.4.cmml">I</mi></mrow><mrow id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.cmml"><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.2" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.2.cmml">H</mi><mo mathsize="70%" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.1" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.1.cmml">+</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.3" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.3.cmml">S</mi><mo mathsize="70%" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.1a" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.1.cmml">+</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.4" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.4.cmml">D</mi></mrow></mfrac></mstyle></mrow><mo lspace="0em" mathsize="70%" id="S3.T3.1.1.1.1.1.m1.1.1.1.2" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.1.m1.1b"><apply id="S3.T3.1.1.1.1.1.m1.1.1.1.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1"><eq id="S3.T3.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.1"></eq><apply id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2"><divide id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2"></divide><apply id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2"><plus id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.1"></plus><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.2.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.2">S</ci><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.3.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.3">D</ci><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.4.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.2.4">I</ci></apply><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.3.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.2.3">N</ci></apply><apply id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3"><divide id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3"></divide><apply id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2"><plus id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.1"></plus><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.2.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.2">S</ci><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.3.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.3">D</ci><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.4.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.2.4">I</ci></apply><apply id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3"><plus id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.1"></plus><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.2.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.2">H</ci><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.3.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.3">S</ci><ci id="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.4.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1.1.3.3.4">D</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.1.m1.1c">\displaystyle\mathrm{\frac{S+D+I}{N}=\frac{S+D+I}{H+S+D}}.</annotation></semantics></math></span>
</span>
</td>
<td id="S3.T3.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:284.5pt;padding-bottom:22.76228pt;">
<span id="S3.T3.3.3.3.2" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.3.3.3.2.2" class="ltx_p"><span id="S3.T3.3.3.3.2.2.1" class="ltx_text" style="font-size:70%;">The  </span><a href="#Sx1.52.52.52"><span href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">word error rate</span></span></span></a><span id="S3.T3.3.3.3.2.2.2" class="ltx_text" style="font-size:70%;"> (</span><a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">WER</span></span></abbr></a><span id="S3.T3.3.3.3.2.2.3" class="ltx_text" style="font-size:70%;">) serves as a frequently utilized metric to assess the performance of Automatic Speech Recognition (</span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S3.T3.3.3.3.2.2.4" class="ltx_text" style="font-size:70%;">). It is computed by determining the ratio of incorrectly recognized words to the overall number of processed words </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.3.3.3.2.2.5.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">45</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">17</span></a>, <a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">46</span></a><span id="S3.T3.3.3.3.2.2.6.2" class="ltx_text" style="font-size:70%;">]</span></cite><span id="S3.T3.3.3.3.2.2.7" class="ltx_text" style="font-size:70%;">. In the given context, </span><math id="S3.T3.2.2.2.1.1.m1.4" class="ltx_Math" alttext="\mathrm{I,D,S,H}" display="inline"><semantics id="S3.T3.2.2.2.1.1.m1.4a"><mrow id="S3.T3.2.2.2.1.1.m1.4.5.2" xref="S3.T3.2.2.2.1.1.m1.4.5.1.cmml"><mi mathsize="70%" mathvariant="normal" id="S3.T3.2.2.2.1.1.m1.1.1" xref="S3.T3.2.2.2.1.1.m1.1.1.cmml">I</mi><mo mathsize="70%" id="S3.T3.2.2.2.1.1.m1.4.5.2.1" xref="S3.T3.2.2.2.1.1.m1.4.5.1.cmml">,</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.2.2.2.1.1.m1.2.2" xref="S3.T3.2.2.2.1.1.m1.2.2.cmml">D</mi><mo mathsize="70%" id="S3.T3.2.2.2.1.1.m1.4.5.2.2" xref="S3.T3.2.2.2.1.1.m1.4.5.1.cmml">,</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.2.2.2.1.1.m1.3.3" xref="S3.T3.2.2.2.1.1.m1.3.3.cmml">S</mi><mo mathsize="70%" id="S3.T3.2.2.2.1.1.m1.4.5.2.3" xref="S3.T3.2.2.2.1.1.m1.4.5.1.cmml">,</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.2.2.2.1.1.m1.4.4" xref="S3.T3.2.2.2.1.1.m1.4.4.cmml">H</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.1.1.m1.4b"><list id="S3.T3.2.2.2.1.1.m1.4.5.1.cmml" xref="S3.T3.2.2.2.1.1.m1.4.5.2"><ci id="S3.T3.2.2.2.1.1.m1.1.1.cmml" xref="S3.T3.2.2.2.1.1.m1.1.1">I</ci><ci id="S3.T3.2.2.2.1.1.m1.2.2.cmml" xref="S3.T3.2.2.2.1.1.m1.2.2">D</ci><ci id="S3.T3.2.2.2.1.1.m1.3.3.cmml" xref="S3.T3.2.2.2.1.1.m1.3.3">S</ci><ci id="S3.T3.2.2.2.1.1.m1.4.4.cmml" xref="S3.T3.2.2.2.1.1.m1.4.4">H</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.1.1.m1.4c">\mathrm{I,D,S,H}</annotation></semantics></math><span id="S3.T3.3.3.3.2.2.8" class="ltx_text" style="font-size:70%;">, and </span><math id="S3.T3.3.3.3.2.2.m2.1" class="ltx_Math" alttext="\mathrm{N}" display="inline"><semantics id="S3.T3.3.3.3.2.2.m2.1a"><mi mathsize="70%" mathvariant="normal" id="S3.T3.3.3.3.2.2.m2.1.1" xref="S3.T3.3.3.3.2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.2.2.m2.1b"><ci id="S3.T3.3.3.3.2.2.m2.1.1.cmml" xref="S3.T3.3.3.3.2.2.m2.1.1">N</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.2.2.m2.1c">\mathrm{N}</annotation></semantics></math><span id="S3.T3.3.3.3.2.2.9" class="ltx_text" style="font-size:70%;"> denote the quantities of insertions, deletions, substitutions, hits, and input words, respectively. Instead of </span><a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">WER</span></span></abbr></a><span id="S3.T3.3.3.3.2.2.10" class="ltx_text" style="font-size:70%;">, the  </span><a href="#Sx1.8.8.8"><span href="#Sx1.8.8.8" title="character error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">character error rate</span></span></span></a><span id="S3.T3.3.3.3.2.2.11" class="ltx_text" style="font-size:70%;"> (</span><a href="#Sx1.8.8.8"><abbr href="#Sx1.8.8.8" title="character error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CER</span></span></abbr></a><span id="S3.T3.3.3.3.2.2.12" class="ltx_text" style="font-size:70%;">) has been employed, while adhering to the same evaluation principle.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.4.4" class="ltx_tr">
<td id="S3.T3.4.4.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:22.76228pt;">
<span id="S3.T3.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.4.4.2.1.1" class="ltx_p"><span id="S3.T3.4.4.2.1.1.1" class="ltx_text" style="font-size:70%;">PESQ and MOS-LQO</span></span>
</span>
</td>
<td id="S3.T3.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;padding-bottom:22.76228pt;">
<span id="S3.T3.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.4.4.1.1.1" class="ltx_p"><math id="S3.T3.4.4.1.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\mathrm{MOS-LQO}=0.999+\frac{4.999-0.999}{1+e^{-1.4945.PESQ+4.6607}}" display="inline"><semantics id="S3.T3.4.4.1.1.1.m1.2a"><mrow id="S3.T3.4.4.1.1.1.m1.2.3" xref="S3.T3.4.4.1.1.1.m1.2.3.cmml"><mrow id="S3.T3.4.4.1.1.1.m1.2.3.2" xref="S3.T3.4.4.1.1.1.m1.2.3.2.cmml"><mi mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.3.2.2" xref="S3.T3.4.4.1.1.1.m1.2.3.2.2.cmml">MOS</mi><mo mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.3.2.1" xref="S3.T3.4.4.1.1.1.m1.2.3.2.1.cmml">−</mo><mi mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.3.2.3" xref="S3.T3.4.4.1.1.1.m1.2.3.2.3.cmml">LQO</mi></mrow><mo mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.3.1" xref="S3.T3.4.4.1.1.1.m1.2.3.1.cmml">=</mo><mrow id="S3.T3.4.4.1.1.1.m1.2.3.3" xref="S3.T3.4.4.1.1.1.m1.2.3.3.cmml"><mn mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.3.3.2" xref="S3.T3.4.4.1.1.1.m1.2.3.3.2.cmml">0.999</mn><mo mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.3.3.1" xref="S3.T3.4.4.1.1.1.m1.2.3.3.1.cmml">+</mo><mstyle displaystyle="true" id="S3.T3.4.4.1.1.1.m1.2.2" xref="S3.T3.4.4.1.1.1.m1.2.2.cmml"><mfrac id="S3.T3.4.4.1.1.1.m1.2.2a" xref="S3.T3.4.4.1.1.1.m1.2.2.cmml"><mrow id="S3.T3.4.4.1.1.1.m1.2.2.4" xref="S3.T3.4.4.1.1.1.m1.2.2.4.cmml"><mn mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.4.2" xref="S3.T3.4.4.1.1.1.m1.2.2.4.2.cmml">4.999</mn><mo mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.4.1" xref="S3.T3.4.4.1.1.1.m1.2.2.4.1.cmml">−</mo><mn mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.4.3" xref="S3.T3.4.4.1.1.1.m1.2.2.4.3.cmml">0.999</mn></mrow><mrow id="S3.T3.4.4.1.1.1.m1.2.2.2" xref="S3.T3.4.4.1.1.1.m1.2.2.2.cmml"><mn mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.4" xref="S3.T3.4.4.1.1.1.m1.2.2.2.4.cmml">1</mn><mo mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.3" xref="S3.T3.4.4.1.1.1.m1.2.2.2.3.cmml">+</mo><msup id="S3.T3.4.4.1.1.1.m1.2.2.2.5" xref="S3.T3.4.4.1.1.1.m1.2.2.2.5.cmml"><mi mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.5.2" xref="S3.T3.4.4.1.1.1.m1.2.2.2.5.2.cmml">e</mi><mrow id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.3.cmml"><mrow id="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1" xref="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.cmml"><mo mathsize="70%" id="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1a" xref="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.cmml">−</mo><mn mathsize="70%" id="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.2" xref="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.2.cmml">1.4945</mn></mrow><mo lspace="0em" mathsize="70%" rspace="0.167em" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.3" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.3a.cmml">.</mo><mrow id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.cmml"><mrow id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.cmml"><mi mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.2" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.1" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.1.cmml">​</mo><mi mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.3" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.1a" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.1.cmml">​</mo><mi mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.4" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.4.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.1b" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.1.cmml">​</mo><mi mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.5" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.5.cmml">Q</mi></mrow><mo mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.1" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.1.cmml">+</mo><mn mathsize="70%" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.3" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.3.cmml">4.6607</mn></mrow></mrow></msup></mrow></mfrac></mstyle></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.1.1.1.m1.2b"><apply id="S3.T3.4.4.1.1.1.m1.2.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3"><eq id="S3.T3.4.4.1.1.1.m1.2.3.1.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3.1"></eq><apply id="S3.T3.4.4.1.1.1.m1.2.3.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3.2"><minus id="S3.T3.4.4.1.1.1.m1.2.3.2.1.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3.2.1"></minus><ci id="S3.T3.4.4.1.1.1.m1.2.3.2.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3.2.2">MOS</ci><ci id="S3.T3.4.4.1.1.1.m1.2.3.2.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3.2.3">LQO</ci></apply><apply id="S3.T3.4.4.1.1.1.m1.2.3.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3.3"><plus id="S3.T3.4.4.1.1.1.m1.2.3.3.1.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3.3.1"></plus><cn type="float" id="S3.T3.4.4.1.1.1.m1.2.3.3.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.3.3.2">0.999</cn><apply id="S3.T3.4.4.1.1.1.m1.2.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2"><divide id="S3.T3.4.4.1.1.1.m1.2.2.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2"></divide><apply id="S3.T3.4.4.1.1.1.m1.2.2.4.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.4"><minus id="S3.T3.4.4.1.1.1.m1.2.2.4.1.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.4.1"></minus><cn type="float" id="S3.T3.4.4.1.1.1.m1.2.2.4.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.4.2">4.999</cn><cn type="float" id="S3.T3.4.4.1.1.1.m1.2.2.4.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.4.3">0.999</cn></apply><apply id="S3.T3.4.4.1.1.1.m1.2.2.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2"><plus id="S3.T3.4.4.1.1.1.m1.2.2.2.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.3"></plus><cn type="integer" id="S3.T3.4.4.1.1.1.m1.2.2.2.4.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.4">1</cn><apply id="S3.T3.4.4.1.1.1.m1.2.2.2.5.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.5"><csymbol cd="ambiguous" id="S3.T3.4.4.1.1.1.m1.2.2.2.5.1.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.5">superscript</csymbol><ci id="S3.T3.4.4.1.1.1.m1.2.2.2.5.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.5.2">𝑒</ci><apply id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.3a.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1"><minus id="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1"></minus><cn type="float" id="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.T3.4.4.1.1.1.m1.1.1.1.1.1.1.1.2">1.4945</cn></apply><apply id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2"><plus id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.1"></plus><apply id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2"><times id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.1"></times><ci id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.2">𝑃</ci><ci id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.3">𝐸</ci><ci id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.4.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.4">𝑆</ci><ci id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.5.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.2.5">𝑄</ci></apply><cn type="float" id="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.T3.4.4.1.1.1.m1.2.2.2.2.2.2.2.3">4.6607</cn></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.1.1.1.m1.2c">\displaystyle\mathrm{MOS-LQO}=0.999+\frac{4.999-0.999}{1+e^{-1.4945.PESQ+4.6607}}</annotation></semantics></math></span>
</span>
</td>
<td id="S3.T3.4.4.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:284.5pt;padding-bottom:22.76228pt;">
<span id="S3.T3.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.4.4.3.1.1" class="ltx_p"><a href="#Sx1.33.33.33"><abbr href="#Sx1.33.33.33" title="perceptual evaluation of speech quality" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">PESQ</span></span></abbr></a><span id="S3.T3.4.4.3.1.1.1" class="ltx_text" style="font-size:70%;"> serves as an objective technique for evaluating the perceived quality of speech </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.4.4.3.1.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">47</span></a><span id="S3.T3.4.4.3.1.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite><span id="S3.T3.4.4.3.1.1.4" class="ltx_text" style="font-size:70%;">. The assessment involves assigning numerical scores within the range of -0.5 to 4.5. Additionally, a correlation can be established between MOS and PESQ scores, giving rise to a novel evaluation metric termed the mean opinion score-listening quality objective (MOS-LQO), also identified as PESQ Rec.862.1. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.4.4.3.1.1.5.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">22</span></a><span id="S3.T3.4.4.3.1.1.6.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span>
</td>
</tr>
<tr id="S3.T3.5.5" class="ltx_tr">
<td id="S3.T3.5.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:17.07182pt;">
<span id="S3.T3.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.2.1.1" class="ltx_p"><a href="#Sx1.37.37.37"><abbr href="#Sx1.37.37.37" title="real-time factor" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RTF</span></span></abbr></a></span>
</span>
</td>
<td id="S3.T3.5.5.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;padding-bottom:17.07182pt;">
<span id="S3.T3.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.1.1.1" class="ltx_p"><math id="S3.T3.5.5.1.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\mathrm{RTF=\frac{\text{Total Processing Time}}{\text{Total Duration}}}" display="inline"><semantics id="S3.T3.5.5.1.1.1.m1.1a"><mrow id="S3.T3.5.5.1.1.1.m1.1.1" xref="S3.T3.5.5.1.1.1.m1.1.1.cmml"><mi mathsize="70%" id="S3.T3.5.5.1.1.1.m1.1.1.2" xref="S3.T3.5.5.1.1.1.m1.1.1.2.cmml">RTF</mi><mo mathsize="70%" id="S3.T3.5.5.1.1.1.m1.1.1.1" xref="S3.T3.5.5.1.1.1.m1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S3.T3.5.5.1.1.1.m1.1.1.3" xref="S3.T3.5.5.1.1.1.m1.1.1.3.cmml"><mfrac id="S3.T3.5.5.1.1.1.m1.1.1.3a" xref="S3.T3.5.5.1.1.1.m1.1.1.3.cmml"><mtext mathsize="70%" id="S3.T3.5.5.1.1.1.m1.1.1.3.2" xref="S3.T3.5.5.1.1.1.m1.1.1.3.2a.cmml">Total Processing Time</mtext><mtext mathsize="70%" id="S3.T3.5.5.1.1.1.m1.1.1.3.3" xref="S3.T3.5.5.1.1.1.m1.1.1.3.3a.cmml">Total Duration</mtext></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.1.1.1.m1.1b"><apply id="S3.T3.5.5.1.1.1.m1.1.1.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1"><eq id="S3.T3.5.5.1.1.1.m1.1.1.1.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1.1"></eq><ci id="S3.T3.5.5.1.1.1.m1.1.1.2.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1.2">RTF</ci><apply id="S3.T3.5.5.1.1.1.m1.1.1.3.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1.3"><divide id="S3.T3.5.5.1.1.1.m1.1.1.3.1.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1.3"></divide><ci id="S3.T3.5.5.1.1.1.m1.1.1.3.2a.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1.3.2"><mtext mathsize="70%" id="S3.T3.5.5.1.1.1.m1.1.1.3.2.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1.3.2">Total Processing Time</mtext></ci><ci id="S3.T3.5.5.1.1.1.m1.1.1.3.3a.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1.3.3"><mtext mathsize="70%" id="S3.T3.5.5.1.1.1.m1.1.1.3.3.cmml" xref="S3.T3.5.5.1.1.1.m1.1.1.3.3">Total Duration</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.1.1.1.m1.1c">\displaystyle\mathrm{RTF=\frac{\text{Total Processing Time}}{\text{Total Duration}}}</annotation></semantics></math></span>
</span>
</td>
<td id="S3.T3.5.5.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:284.5pt;padding-bottom:17.07182pt;">
<span id="S3.T3.5.5.3.1" class="ltx_inline-block ltx_align_top"><span id="S3.T3.5.5.3.1.1" class="ltx_ERROR undefined">\Ac</span>
<span id="S3.T3.5.5.3.1.2" class="ltx_p"><span id="S3.T3.5.5.3.1.2.1" class="ltx_text" style="font-size:70%;">RTF serves as a standard metric to assess the processing time cost of an </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S3.T3.5.5.3.1.2.2" class="ltx_text" style="font-size:70%;"> system. It represents the average processing time required for one second of speech</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.8.8" class="ltx_tr">
<td id="S3.T3.8.8.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:17.07182pt;">
<span id="S3.T3.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.8.8.4.1.1" class="ltx_p"><a href="#Sx1.34.34.34"><abbr href="#Sx1.34.34.34" title="relative error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RER</span></span></abbr></a></span>
</span>
</td>
<td id="S3.T3.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;padding-bottom:17.07182pt;">
<span id="S3.T3.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.6.6.1.1.1" class="ltx_p"><math id="S3.T3.6.6.1.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\frac{(E_{\text{baseline}}-E_{\text{proposed}})}{E_{\text{baseline}}}\times 100\%" display="inline"><semantics id="S3.T3.6.6.1.1.1.m1.1a"><mrow id="S3.T3.6.6.1.1.1.m1.1.2" xref="S3.T3.6.6.1.1.1.m1.1.2.cmml"><mstyle displaystyle="true" id="S3.T3.6.6.1.1.1.m1.1.1" xref="S3.T3.6.6.1.1.1.m1.1.1.cmml"><mfrac id="S3.T3.6.6.1.1.1.m1.1.1a" xref="S3.T3.6.6.1.1.1.m1.1.1.cmml"><mrow id="S3.T3.6.6.1.1.1.m1.1.1.1.1" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.cmml"><mo maxsize="70%" minsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.2" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.cmml"><msub id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.cmml"><mi mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.2" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.2.cmml">E</mi><mtext mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.3" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.3a.cmml">baseline</mtext></msub><mo mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.1" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.cmml"><mi mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.2" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.2.cmml">E</mi><mtext mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.3" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.3a.cmml">proposed</mtext></msub></mrow><mo maxsize="70%" minsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.3" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow><msub id="S3.T3.6.6.1.1.1.m1.1.1.3" xref="S3.T3.6.6.1.1.1.m1.1.1.3.cmml"><mi mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.3.2" xref="S3.T3.6.6.1.1.1.m1.1.1.3.2.cmml">E</mi><mtext mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.1.3.3" xref="S3.T3.6.6.1.1.1.m1.1.1.3.3a.cmml">baseline</mtext></msub></mfrac></mstyle><mo lspace="0.222em" mathsize="70%" rspace="0.222em" id="S3.T3.6.6.1.1.1.m1.1.2.1" xref="S3.T3.6.6.1.1.1.m1.1.2.1.cmml">×</mo><mrow id="S3.T3.6.6.1.1.1.m1.1.2.2" xref="S3.T3.6.6.1.1.1.m1.1.2.2.cmml"><mn mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.2.2.2" xref="S3.T3.6.6.1.1.1.m1.1.2.2.2.cmml">100</mn><mo mathsize="70%" id="S3.T3.6.6.1.1.1.m1.1.2.2.1" xref="S3.T3.6.6.1.1.1.m1.1.2.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.1.1.1.m1.1b"><apply id="S3.T3.6.6.1.1.1.m1.1.2.cmml" xref="S3.T3.6.6.1.1.1.m1.1.2"><times id="S3.T3.6.6.1.1.1.m1.1.2.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.2.1"></times><apply id="S3.T3.6.6.1.1.1.m1.1.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1"><divide id="S3.T3.6.6.1.1.1.m1.1.1.2.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1"></divide><apply id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1"><minus id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.1"></minus><apply id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.2">𝐸</ci><ci id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.3a.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.3"><mtext mathsize="49%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.2.3">baseline</mtext></ci></apply><apply id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.2">𝐸</ci><ci id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.3a.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.3"><mtext mathsize="49%" id="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.1.1.1.3.3">proposed</mtext></ci></apply></apply><apply id="S3.T3.6.6.1.1.1.m1.1.1.3.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.T3.6.6.1.1.1.m1.1.1.3.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.3">subscript</csymbol><ci id="S3.T3.6.6.1.1.1.m1.1.1.3.2.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.3.2">𝐸</ci><ci id="S3.T3.6.6.1.1.1.m1.1.1.3.3a.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.3.3"><mtext mathsize="49%" id="S3.T3.6.6.1.1.1.m1.1.1.3.3.cmml" xref="S3.T3.6.6.1.1.1.m1.1.1.3.3">baseline</mtext></ci></apply></apply><apply id="S3.T3.6.6.1.1.1.m1.1.2.2.cmml" xref="S3.T3.6.6.1.1.1.m1.1.2.2"><csymbol cd="latexml" id="S3.T3.6.6.1.1.1.m1.1.2.2.1.cmml" xref="S3.T3.6.6.1.1.1.m1.1.2.2.1">percent</csymbol><cn type="integer" id="S3.T3.6.6.1.1.1.m1.1.2.2.2.cmml" xref="S3.T3.6.6.1.1.1.m1.1.2.2.2">100</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.1.1.1.m1.1c">\displaystyle\frac{(E_{\text{baseline}}-E_{\text{proposed}})}{E_{\text{baseline}}}\times 100\%</annotation></semantics></math></span>
</span>
</td>
<td id="S3.T3.8.8.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:284.5pt;padding-bottom:17.07182pt;">
<span id="S3.T3.8.8.3.2" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.8.8.3.2.2" class="ltx_p"><span id="S3.T3.8.8.3.2.2.1" class="ltx_text" style="font-size:70%;">The  </span><a href="#Sx1.34.34.34"><span href="#Sx1.34.34.34" title="relative error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">relative error rate</span></span></span></a><span id="S3.T3.8.8.3.2.2.2" class="ltx_text" style="font-size:70%;"> (</span><a href="#Sx1.34.34.34"><abbr href="#Sx1.34.34.34" title="relative error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RER</span></span></abbr></a><span id="S3.T3.8.8.3.2.2.3" class="ltx_text" style="font-size:70%;">) expresses the percentage error rate achieved by the proposed DL model compared to the baseline. </span><math id="S3.T3.7.7.2.1.1.m1.1" class="ltx_Math" alttext="E_{\text{baseline}}" display="inline"><semantics id="S3.T3.7.7.2.1.1.m1.1a"><msub id="S3.T3.7.7.2.1.1.m1.1.1" xref="S3.T3.7.7.2.1.1.m1.1.1.cmml"><mi mathsize="70%" id="S3.T3.7.7.2.1.1.m1.1.1.2" xref="S3.T3.7.7.2.1.1.m1.1.1.2.cmml">E</mi><mtext mathsize="70%" id="S3.T3.7.7.2.1.1.m1.1.1.3" xref="S3.T3.7.7.2.1.1.m1.1.1.3a.cmml">baseline</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.2.1.1.m1.1b"><apply id="S3.T3.7.7.2.1.1.m1.1.1.cmml" xref="S3.T3.7.7.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T3.7.7.2.1.1.m1.1.1.1.cmml" xref="S3.T3.7.7.2.1.1.m1.1.1">subscript</csymbol><ci id="S3.T3.7.7.2.1.1.m1.1.1.2.cmml" xref="S3.T3.7.7.2.1.1.m1.1.1.2">𝐸</ci><ci id="S3.T3.7.7.2.1.1.m1.1.1.3a.cmml" xref="S3.T3.7.7.2.1.1.m1.1.1.3"><mtext mathsize="49%" id="S3.T3.7.7.2.1.1.m1.1.1.3.cmml" xref="S3.T3.7.7.2.1.1.m1.1.1.3">baseline</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.2.1.1.m1.1c">E_{\text{baseline}}</annotation></semantics></math><span id="S3.T3.8.8.3.2.2.4" class="ltx_text" style="font-size:70%;"> is the error rate of the baseline model. </span><math id="S3.T3.8.8.3.2.2.m2.1" class="ltx_Math" alttext="E_{\text{proposed}}" display="inline"><semantics id="S3.T3.8.8.3.2.2.m2.1a"><msub id="S3.T3.8.8.3.2.2.m2.1.1" xref="S3.T3.8.8.3.2.2.m2.1.1.cmml"><mi mathsize="70%" id="S3.T3.8.8.3.2.2.m2.1.1.2" xref="S3.T3.8.8.3.2.2.m2.1.1.2.cmml">E</mi><mtext mathsize="70%" id="S3.T3.8.8.3.2.2.m2.1.1.3" xref="S3.T3.8.8.3.2.2.m2.1.1.3a.cmml">proposed</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.3.2.2.m2.1b"><apply id="S3.T3.8.8.3.2.2.m2.1.1.cmml" xref="S3.T3.8.8.3.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T3.8.8.3.2.2.m2.1.1.1.cmml" xref="S3.T3.8.8.3.2.2.m2.1.1">subscript</csymbol><ci id="S3.T3.8.8.3.2.2.m2.1.1.2.cmml" xref="S3.T3.8.8.3.2.2.m2.1.1.2">𝐸</ci><ci id="S3.T3.8.8.3.2.2.m2.1.1.3a.cmml" xref="S3.T3.8.8.3.2.2.m2.1.1.3"><mtext mathsize="49%" id="S3.T3.8.8.3.2.2.m2.1.1.3.cmml" xref="S3.T3.8.8.3.2.2.m2.1.1.3">proposed</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.3.2.2.m2.1c">E_{\text{proposed}}</annotation></semantics></math><span id="S3.T3.8.8.3.2.2.5" class="ltx_text" style="font-size:70%;"> is the error rate of the proposed model or method.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.17.17" class="ltx_tr">
<td id="S3.T3.17.17.10" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:42.7pt;">
<span id="S3.T3.17.17.10.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.17.17.10.1.1" class="ltx_p"><span id="S3.T3.17.17.10.1.1.1" class="ltx_text" style="font-size:70%;">D</span></span>
</span>
</td>
<td id="S3.T3.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:142.3pt;">
<span id="S3.T3.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.1.1.1" class="ltx_p"><math id="S3.T3.9.9.1.1.1.m1.7" class="ltx_Math" alttext="\displaystyle\frac{\sum_{i=1}^{n}\Big{(}1-\frac{\sum_{j=1}^{n}a_{ij}\cdot|i-j|}{\max(|i-1|,|i-2|,\ldots,|i-n|)}\Big{)}}{n}\hskip 28.45274pt" display="inline"><semantics id="S3.T3.9.9.1.1.1.m1.7a"><mrow id="S3.T3.9.9.1.1.1.m1.7.8.2" xref="S3.T3.9.9.1.1.1.m1.7.7.cmml"><mstyle displaystyle="true" id="S3.T3.9.9.1.1.1.m1.7.7" xref="S3.T3.9.9.1.1.1.m1.7.7.cmml"><mfrac id="S3.T3.9.9.1.1.1.m1.7.7a" xref="S3.T3.9.9.1.1.1.m1.7.7.cmml"><mrow id="S3.T3.9.9.1.1.1.m1.7.7.7" xref="S3.T3.9.9.1.1.1.m1.7.7.7.cmml"><msubsup id="S3.T3.9.9.1.1.1.m1.7.7.7.8" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.cmml"><mo maxsize="70%" minsize="70%" stretchy="true" id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.2" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.2.cmml">∑</mo><mrow id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.2" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.2.cmml">i</mi><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.1" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.1.cmml">=</mo><mn mathsize="70%" id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.3" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.3.cmml">1</mn></mrow><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.7.7.7.8.3" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.3.cmml">n</mi></msubsup><mrow id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.cmml"><mo lspace="0em" maxsize="160%" minsize="160%" id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.2" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.cmml">(</mo><mrow id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.cmml"><mn mathsize="70%" id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.2" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.2.cmml">1</mn><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.1" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.1.cmml">−</mo><mfrac id="S3.T3.9.9.1.1.1.m1.6.6.6.6" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.cmml"><mrow id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.cmml"><mstyle displaystyle="false" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.cmml"><msubsup id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2a" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.cmml"><mo maxsize="49%" minsize="49%" stretchy="true" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.2" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.2" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.2.cmml">j</mi><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.1" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.3" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.3" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.3.cmml">n</mi></msubsup></mstyle><mrow id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.cmml"><msub id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.2" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.2.cmml">a</mi><mrow id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.2" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.1" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.3" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.3.cmml">j</mi></mrow></msub><mo lspace="0.222em" mathsize="70%" rspace="0.222em" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.2" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.2.cmml">⋅</mo><mrow id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.2.cmml"><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">i</mi><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi></mrow><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow><mrow id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.2.2.2.2.2.1" xref="S3.T3.9.9.1.1.1.m1.2.2.2.2.2.1.cmml">max</mi><mo id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5a" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml">⁡</mo><mrow id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml"><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.4" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml">(</mo><mrow id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.2.cmml"><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.2" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.2.1.cmml">|</mo><mrow id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.2" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.2.cmml">i</mi><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.1" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.1.cmml">−</mo><mn mathsize="70%" id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.3" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.3.cmml">1</mn></mrow><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.3" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.2.1.cmml">|</mo></mrow><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.5" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml">,</mo><mrow id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.2.cmml"><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.2" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.2.1.cmml">|</mo><mrow id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.2" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.2.cmml">i</mi><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.1" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.1.cmml">−</mo><mn mathsize="70%" id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.3" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.3.cmml">2</mn></mrow><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.3" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.2.1.cmml">|</mo></mrow><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.6" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml">,</mo><mi mathsize="70%" mathvariant="normal" id="S3.T3.9.9.1.1.1.m1.3.3.3.3.3.2" xref="S3.T3.9.9.1.1.1.m1.3.3.3.3.3.2.cmml">…</mi><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.7" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml">,</mo><mrow id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.2.cmml"><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.2" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.2.1.cmml">|</mo><mrow id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.cmml"><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.2" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.2.cmml">i</mi><mo mathsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.1" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.1.cmml">−</mo><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.3" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.3.cmml">n</mi></mrow><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.3" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.2.1.cmml">|</mo></mrow><mo maxsize="70%" minsize="70%" id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.8" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml">)</mo></mrow></mrow></mfrac></mrow><mo maxsize="160%" minsize="160%" id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.3" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.cmml">)</mo></mrow></mrow><mi mathsize="70%" id="S3.T3.9.9.1.1.1.m1.7.7.9" xref="S3.T3.9.9.1.1.1.m1.7.7.9.cmml">n</mi></mfrac></mstyle><mspace width="2.85em" id="S3.T3.9.9.1.1.1.m1.7.8.2.1" xref="S3.T3.9.9.1.1.1.m1.7.7.cmml"></mspace></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.9.9.1.1.1.m1.7b"><apply id="S3.T3.9.9.1.1.1.m1.7.7.cmml" xref="S3.T3.9.9.1.1.1.m1.7.8.2"><divide id="S3.T3.9.9.1.1.1.m1.7.7.8.cmml" xref="S3.T3.9.9.1.1.1.m1.7.8.2"></divide><apply id="S3.T3.9.9.1.1.1.m1.7.7.7.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7"><apply id="S3.T3.9.9.1.1.1.m1.7.7.7.8.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8"><csymbol cd="ambiguous" id="S3.T3.9.9.1.1.1.m1.7.7.7.8.1.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8">superscript</csymbol><apply id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8"><csymbol cd="ambiguous" id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.1.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8">subscript</csymbol><sum id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.2.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.2"></sum><apply id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3"><eq id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.1.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.1"></eq><ci id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.2.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.2">𝑖</ci><cn type="integer" id="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.3.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.2.3.3">1</cn></apply></apply><ci id="S3.T3.9.9.1.1.1.m1.7.7.7.8.3.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.8.3">𝑛</ci></apply><apply id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1"><minus id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.1"></minus><cn type="integer" id="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.7.7.1.1.2">1</cn><apply id="S3.T3.9.9.1.1.1.m1.6.6.6.6.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6"><divide id="S3.T3.9.9.1.1.1.m1.6.6.6.6.7.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6"></divide><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1"><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.2"></sum><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3"><eq id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.2">𝑗</ci><cn type="integer" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.2.3">𝑛</ci></apply><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1"><ci id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.2">⋅</ci><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.2">𝑎</ci><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3"><times id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.2">𝑖</ci><ci id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.3.3.3">𝑗</ci></apply></apply><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1"><abs id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.2"></abs><apply id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.1"></minus><ci id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.2">𝑖</ci><ci id="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.T3.9.9.1.1.1.m1.1.1.1.1.1.1.1.1.1.3">𝑗</ci></apply></apply></apply></apply><apply id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.6.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5"><max id="S3.T3.9.9.1.1.1.m1.2.2.2.2.2.1.cmml" xref="S3.T3.9.9.1.1.1.m1.2.2.2.2.2.1"></max><apply id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1"><abs id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.2.1.cmml" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.2"></abs><apply id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1"><minus id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.1"></minus><ci id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.2">𝑖</ci><cn type="integer" id="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.3.cmml" xref="S3.T3.9.9.1.1.1.m1.4.4.4.4.4.3.1.1.1.1.3">1</cn></apply></apply><apply id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.2.cmml" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1"><abs id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.2.1.cmml" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.2"></abs><apply id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1"><minus id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.1"></minus><ci id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.2">𝑖</ci><cn type="integer" id="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.3.cmml" xref="S3.T3.9.9.1.1.1.m1.5.5.5.5.5.4.2.2.1.1.3">2</cn></apply></apply><ci id="S3.T3.9.9.1.1.1.m1.3.3.3.3.3.2.cmml" xref="S3.T3.9.9.1.1.1.m1.3.3.3.3.3.2">…</ci><apply id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.2.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1"><abs id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.2.1.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.2"></abs><apply id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1"><minus id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.1.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.1"></minus><ci id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.2.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.2">𝑖</ci><ci id="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.3.cmml" xref="S3.T3.9.9.1.1.1.m1.6.6.6.6.6.5.3.3.1.1.3">𝑛</ci></apply></apply></apply></apply></apply></apply><ci id="S3.T3.9.9.1.1.1.m1.7.7.9.cmml" xref="S3.T3.9.9.1.1.1.m1.7.7.9">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.9.1.1.1.m1.7c">\displaystyle\frac{\sum_{i=1}^{n}\Big{(}1-\frac{\sum_{j=1}^{n}a_{ij}\cdot|i-j|}{\max(|i-1|,|i-2|,\ldots,|i-n|)}\Big{)}}{n}\hskip 28.45274pt</annotation></semantics></math></span>
</span>
</td>
<td id="S3.T3.17.17.9" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:284.5pt;">
<span id="S3.T3.17.17.9.8" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.17.17.9.8.8" class="ltx_p"><span id="S3.T3.17.17.9.8.8.1" class="ltx_text" style="font-size:70%;">Diagonal centrality of an attention matrix (D) is defined as the mean value across the centrality of all its rows. where </span><math id="S3.T3.10.10.2.1.1.m1.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.T3.10.10.2.1.1.m1.1a"><mi mathsize="70%" id="S3.T3.10.10.2.1.1.m1.1.1" xref="S3.T3.10.10.2.1.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.T3.10.10.2.1.1.m1.1b"><ci id="S3.T3.10.10.2.1.1.m1.1.1.cmml" xref="S3.T3.10.10.2.1.1.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.10.2.1.1.m1.1c">j</annotation></semantics></math><span id="S3.T3.17.17.9.8.8.2" class="ltx_text" style="font-size:70%;"> represents the index of each column, </span><math id="S3.T3.11.11.3.2.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.T3.11.11.3.2.2.m2.1a"><mi mathsize="70%" id="S3.T3.11.11.3.2.2.m2.1.1" xref="S3.T3.11.11.3.2.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.T3.11.11.3.2.2.m2.1b"><ci id="S3.T3.11.11.3.2.2.m2.1.1.cmml" xref="S3.T3.11.11.3.2.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.11.3.2.2.m2.1c">n</annotation></semantics></math><span id="S3.T3.17.17.9.8.8.3" class="ltx_text" style="font-size:70%;"> signifies the length of the input sequence, </span><math id="S3.T3.12.12.4.3.3.m3.1" class="ltx_Math" alttext="a_{ij}" display="inline"><semantics id="S3.T3.12.12.4.3.3.m3.1a"><msub id="S3.T3.12.12.4.3.3.m3.1.1" xref="S3.T3.12.12.4.3.3.m3.1.1.cmml"><mi mathsize="70%" id="S3.T3.12.12.4.3.3.m3.1.1.2" xref="S3.T3.12.12.4.3.3.m3.1.1.2.cmml">a</mi><mrow id="S3.T3.12.12.4.3.3.m3.1.1.3" xref="S3.T3.12.12.4.3.3.m3.1.1.3.cmml"><mi mathsize="70%" id="S3.T3.12.12.4.3.3.m3.1.1.3.2" xref="S3.T3.12.12.4.3.3.m3.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.T3.12.12.4.3.3.m3.1.1.3.1" xref="S3.T3.12.12.4.3.3.m3.1.1.3.1.cmml">​</mo><mi mathsize="70%" id="S3.T3.12.12.4.3.3.m3.1.1.3.3" xref="S3.T3.12.12.4.3.3.m3.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T3.12.12.4.3.3.m3.1b"><apply id="S3.T3.12.12.4.3.3.m3.1.1.cmml" xref="S3.T3.12.12.4.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.T3.12.12.4.3.3.m3.1.1.1.cmml" xref="S3.T3.12.12.4.3.3.m3.1.1">subscript</csymbol><ci id="S3.T3.12.12.4.3.3.m3.1.1.2.cmml" xref="S3.T3.12.12.4.3.3.m3.1.1.2">𝑎</ci><apply id="S3.T3.12.12.4.3.3.m3.1.1.3.cmml" xref="S3.T3.12.12.4.3.3.m3.1.1.3"><times id="S3.T3.12.12.4.3.3.m3.1.1.3.1.cmml" xref="S3.T3.12.12.4.3.3.m3.1.1.3.1"></times><ci id="S3.T3.12.12.4.3.3.m3.1.1.3.2.cmml" xref="S3.T3.12.12.4.3.3.m3.1.1.3.2">𝑖</ci><ci id="S3.T3.12.12.4.3.3.m3.1.1.3.3.cmml" xref="S3.T3.12.12.4.3.3.m3.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.12.12.4.3.3.m3.1c">a_{ij}</annotation></semantics></math><span id="S3.T3.17.17.9.8.8.4" class="ltx_text" style="font-size:70%;"> denotes the attention weight between the </span><math id="S3.T3.13.13.5.4.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.T3.13.13.5.4.4.m4.1a"><mi mathsize="70%" id="S3.T3.13.13.5.4.4.m4.1.1" xref="S3.T3.13.13.5.4.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.T3.13.13.5.4.4.m4.1b"><ci id="S3.T3.13.13.5.4.4.m4.1.1.cmml" xref="S3.T3.13.13.5.4.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.13.13.5.4.4.m4.1c">i</annotation></semantics></math><span id="S3.T3.17.17.9.8.8.5" class="ltx_text" style="font-size:70%;">-th and </span><math id="S3.T3.14.14.6.5.5.m5.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.T3.14.14.6.5.5.m5.1a"><mi mathsize="70%" id="S3.T3.14.14.6.5.5.m5.1.1" xref="S3.T3.14.14.6.5.5.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.T3.14.14.6.5.5.m5.1b"><ci id="S3.T3.14.14.6.5.5.m5.1.1.cmml" xref="S3.T3.14.14.6.5.5.m5.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.14.14.6.5.5.m5.1c">j</annotation></semantics></math><span id="S3.T3.17.17.9.8.8.6" class="ltx_text" style="font-size:70%;">-th elements of the input sequence, and </span><math id="S3.T3.15.15.7.6.6.m6.1" class="ltx_Math" alttext="|i-j|" display="inline"><semantics id="S3.T3.15.15.7.6.6.m6.1a"><mrow id="S3.T3.15.15.7.6.6.m6.1.1.1" xref="S3.T3.15.15.7.6.6.m6.1.1.2.cmml"><mo maxsize="70%" minsize="70%" id="S3.T3.15.15.7.6.6.m6.1.1.1.2" xref="S3.T3.15.15.7.6.6.m6.1.1.2.1.cmml">|</mo><mrow id="S3.T3.15.15.7.6.6.m6.1.1.1.1" xref="S3.T3.15.15.7.6.6.m6.1.1.1.1.cmml"><mi mathsize="70%" id="S3.T3.15.15.7.6.6.m6.1.1.1.1.2" xref="S3.T3.15.15.7.6.6.m6.1.1.1.1.2.cmml">i</mi><mo mathsize="70%" id="S3.T3.15.15.7.6.6.m6.1.1.1.1.1" xref="S3.T3.15.15.7.6.6.m6.1.1.1.1.1.cmml">−</mo><mi mathsize="70%" id="S3.T3.15.15.7.6.6.m6.1.1.1.1.3" xref="S3.T3.15.15.7.6.6.m6.1.1.1.1.3.cmml">j</mi></mrow><mo maxsize="70%" minsize="70%" id="S3.T3.15.15.7.6.6.m6.1.1.1.3" xref="S3.T3.15.15.7.6.6.m6.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.15.15.7.6.6.m6.1b"><apply id="S3.T3.15.15.7.6.6.m6.1.1.2.cmml" xref="S3.T3.15.15.7.6.6.m6.1.1.1"><abs id="S3.T3.15.15.7.6.6.m6.1.1.2.1.cmml" xref="S3.T3.15.15.7.6.6.m6.1.1.1.2"></abs><apply id="S3.T3.15.15.7.6.6.m6.1.1.1.1.cmml" xref="S3.T3.15.15.7.6.6.m6.1.1.1.1"><minus id="S3.T3.15.15.7.6.6.m6.1.1.1.1.1.cmml" xref="S3.T3.15.15.7.6.6.m6.1.1.1.1.1"></minus><ci id="S3.T3.15.15.7.6.6.m6.1.1.1.1.2.cmml" xref="S3.T3.15.15.7.6.6.m6.1.1.1.1.2">𝑖</ci><ci id="S3.T3.15.15.7.6.6.m6.1.1.1.1.3.cmml" xref="S3.T3.15.15.7.6.6.m6.1.1.1.1.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.15.15.7.6.6.m6.1c">|i-j|</annotation></semantics></math><span id="S3.T3.17.17.9.8.8.7" class="ltx_text" style="font-size:70%;"> signifies the distance between the </span><math id="S3.T3.16.16.8.7.7.m7.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.T3.16.16.8.7.7.m7.1a"><mi mathsize="70%" id="S3.T3.16.16.8.7.7.m7.1.1" xref="S3.T3.16.16.8.7.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.T3.16.16.8.7.7.m7.1b"><ci id="S3.T3.16.16.8.7.7.m7.1.1.cmml" xref="S3.T3.16.16.8.7.7.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.16.16.8.7.7.m7.1c">i</annotation></semantics></math><span id="S3.T3.17.17.9.8.8.8" class="ltx_text" style="font-size:70%;">-th and </span><math id="S3.T3.17.17.9.8.8.m8.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.T3.17.17.9.8.8.m8.1a"><mi mathsize="70%" id="S3.T3.17.17.9.8.8.m8.1.1" xref="S3.T3.17.17.9.8.8.m8.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.T3.17.17.9.8.8.m8.1b"><ci id="S3.T3.17.17.9.8.8.m8.1.1.cmml" xref="S3.T3.17.17.9.8.8.m8.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.17.17.9.8.8.m8.1c">j</annotation></semantics></math><span id="S3.T3.17.17.9.8.8.9" class="ltx_text" style="font-size:70%;">-th elements of the input sequence </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.17.17.9.8.8.10.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">48</span></a><span id="S3.T3.17.17.9.8.8.11.2" class="ltx_text" style="font-size:70%;">]</span></cite><span id="S3.T3.17.17.9.8.8.12" class="ltx_text" style="font-size:70%;">.</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>ASR datasets</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Various datasets have been employed in the literature for diverse <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> tasks. Table <a href="#S3.T4" title="Table 4 ‣ 3.3 ASR datasets ‣ 3 Background ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents a selection of datasets utilized for DTL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> applications, along with their respective characteristics. It is important to note that the table primarily includes publicly accessible repositories. Furthermore, it is worth mentioning that certain datasets have undergone multiple updates and improvements over time, leading to their enhanced development.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S3.T4.3.2" class="ltx_text" style="font-size:90%;">List of publicly available datasets used for advanced DL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> applications</span></figcaption>
<p id="S3.T4.4" class="ltx_p">.


<span id="S3.T4.4.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.4.1.1" class="ltx_tr">
<span id="S3.T4.4.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T4.4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.1.1.1.1" class="ltx_p"><span id="S3.T4.4.1.1.1.1.1.1" class="ltx_text" style="font-size:70%;">Dataset</span></span>
</span></span>
<span id="S3.T4.4.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S3.T4.4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.1.2.1.1" class="ltx_p"><span id="S3.T4.4.1.1.2.1.1.1" class="ltx_text" style="font-size:70%;">Used by</span></span>
</span></span>
<span id="S3.T4.4.1.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S3.T4.4.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.1.3.1.1" class="ltx_p"><span id="S3.T4.4.1.1.3.1.1.1" class="ltx_text" style="font-size:70%;">Default ASR task</span></span>
</span></span>
<span id="S3.T4.4.1.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:256.1pt;">
<span id="S3.T4.4.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.1.4.1.1" class="ltx_p"><span id="S3.T4.4.1.1.4.1.1.1" class="ltx_text" style="font-size:70%;">Characteristics</span></span>
</span></span></span>
<span id="S3.T4.4.1.2" class="ltx_tr">
<span id="S3.T4.4.1.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.2.1.1.1" class="ltx_p"><span id="S3.T4.4.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">LibriSpeech</span></span>
</span></span>
<span id="S3.T4.4.1.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.2.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.2.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">49</span></a>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">50</span></a>, <a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">51</span></a><span id="S3.T4.4.1.2.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.2.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.2.3.1.1" class="ltx_p"><span id="S3.T4.4.1.2.3.1.1.1" class="ltx_text" style="font-size:70%;">Train and assess systems for recognizing speech.</span></span>
</span></span>
<span id="S3.T4.4.1.2.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.2.4.1.1" class="ltx_p"><span id="S3.T4.4.1.2.4.1.1.1" class="ltx_text" style="font-size:70%;">The collection consists of 1000 hours of speech recorded at a 16 kHz sampling rate, sourced from audiobooks included in the LibriVox project.</span></span>
</span></span></span>
<span id="S3.T4.4.1.3" class="ltx_tr">
<span id="S3.T4.4.1.3.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.3.1.1.1" class="ltx_p"><span id="S3.T4.4.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">DCASE</span></span>
</span></span>
<span id="S3.T4.4.1.3.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.3.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.3.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">52</span></a>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">53</span></a><span id="S3.T4.4.1.3.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.3.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.3.3.1.1" class="ltx_p"><span id="S3.T4.4.1.3.3.1.1.1" class="ltx_text" style="font-size:70%;">Identifying acoustic environments and detecting sound occurrences.</span></span>
</span></span>
<span id="S3.T4.4.1.3.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.3.4.1.1" class="ltx_p"><span id="S3.T4.4.1.3.4.1.1.1" class="ltx_text" style="font-size:70%;">Comprise 8 coarse-level and 23 fine-level urban sound categories, collected in New York City in 2020 using 50 acoustic sensors.</span></span>
</span></span></span>
<span id="S3.T4.4.1.4" class="ltx_tr">
<span id="S3.T4.4.1.4.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.4.1.1.1" class="ltx_p"><span id="S3.T4.4.1.4.1.1.1.1" class="ltx_text" style="font-size:70%;">WSJ</span></span>
</span></span>
<span id="S3.T4.4.1.4.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.4.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.4.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">48</span></a><span id="S3.T4.4.1.4.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.4.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.4.3.1.1" class="ltx_p"><span id="S3.T4.4.1.4.3.1.1.1" class="ltx_text" style="font-size:70%;">Acoustic scene and sound event corpus</span></span>
</span></span>
<span id="S3.T4.4.1.4.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.4.4.1.1" class="ltx_p"><span id="S3.T4.4.1.4.4.1.1.1" class="ltx_text" style="font-size:70%;">Comprises an extensive 81 hours of meticulously curated read speech training data.</span></span>
</span></span></span>
<span id="S3.T4.4.1.5" class="ltx_tr">
<span id="S3.T4.4.1.5.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.5.1.1.1" class="ltx_p"><span id="S3.T4.4.1.5.1.1.1.1" class="ltx_text" style="font-size:70%;">SWBD</span></span>
</span></span>
<span id="S3.T4.4.1.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.5.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.5.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">48</span></a><span id="S3.T4.4.1.5.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.5.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.5.3.1.1" class="ltx_p"><span id="S3.T4.4.1.5.3.1.1.1" class="ltx_text" style="font-size:70%;">Conversational telephone speech corpus</span></span>
</span></span>
<span id="S3.T4.4.1.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.5.4.1.1" class="ltx_p"><span id="S3.T4.4.1.5.4.1.1.1" class="ltx_text" style="font-size:70%;">Is a comprehensive collection, boasting a substantial 260 hours of conversational telephone speech training data.</span></span>
</span></span></span>
<span id="S3.T4.4.1.6" class="ltx_tr">
<span id="S3.T4.4.1.6.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.6.1.1.1" class="ltx_p"><span id="S3.T4.4.1.6.1.1.1.1" class="ltx_text" style="font-size:70%;">AISHELL</span></span>
</span></span>
<span id="S3.T4.4.1.6.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.6.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.6.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">54</span></a>, <a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">55</span></a>, <a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">56</span></a><span id="S3.T4.4.1.6.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.6.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.6.3.1.1" class="ltx_p"><span id="S3.T4.4.1.6.3.1.1.1" class="ltx_text" style="font-size:70%;">Chinese Mandarin speech corpus</span></span>
</span></span>
<span id="S3.T4.4.1.6.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.6.4.1.1" class="ltx_p"><span id="S3.T4.4.1.6.4.1.1.1" class="ltx_text" style="font-size:70%;">400 participants from diverse Chinese accent regions recorded in a quiet indoor space using high-fidelity microphones, later downsampled to 16kHz.</span></span>
</span></span></span>
<span id="S3.T4.4.1.7" class="ltx_tr">
<span id="S3.T4.4.1.7.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.7.1.1.1" class="ltx_p"><span id="S3.T4.4.1.7.1.1.1.1" class="ltx_text" style="font-size:70%;">CHIME3</span></span>
</span></span>
<span id="S3.T4.4.1.7.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.7.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.7.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">57</span></a><span id="S3.T4.4.1.7.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.7.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.7.3.1.1" class="ltx_p"><span id="S3.T4.4.1.7.3.1.1.1" class="ltx_text" style="font-size:70%;">SR for distant microphone in real-world settings.</span></span>
</span></span>
<span id="S3.T4.4.1.7.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.7.4.1.1" class="ltx_p"><span id="S3.T4.4.1.7.4.1.1.1" class="ltx_text" style="font-size:70%;">Includes around 342 hours of English speech with noisy transcripts and 50 hours of noisy environment recordings.</span></span>
</span></span></span>
<span id="S3.T4.4.1.8" class="ltx_tr">
<span id="S3.T4.4.1.8.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:22.76228pt;">
<span id="S3.T4.4.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.8.1.1.1" class="ltx_p"><span id="S3.T4.4.1.8.1.1.1.1" class="ltx_text" style="font-size:70%;">Google-SC</span></span>
</span></span>
<span id="S3.T4.4.1.8.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:22.76228pt;">
<span id="S3.T4.4.1.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.8.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.8.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">57</span></a><span id="S3.T4.4.1.8.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.8.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:22.76228pt;">
<span id="S3.T4.4.1.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.8.3.1.1" class="ltx_p"><span id="S3.T4.4.1.8.3.1.1.1" class="ltx_text" style="font-size:70%;">Speech commands with a restricted range of words.</span></span>
</span></span>
<span id="S3.T4.4.1.8.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:22.76228pt;">
<span id="S3.T4.4.1.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.8.4.1.1" class="ltx_p"><span id="S3.T4.4.1.8.4.1.1.1" class="ltx_text" style="font-size:70%;">The dataset contains 105,829 one-second utterances of 35 words categorized by frequency. Each utterance is stored as a one-second WAVE format file with 16-bit single-channel at 16KHz rate. It involves 2,618 speakers</span></span>
</span></span></span>
<span id="S3.T4.4.1.9" class="ltx_tr">
<span id="S3.T4.4.1.9.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.9.1.1.1" class="ltx_p"><span id="S3.T4.4.1.9.1.1.1.1" class="ltx_text" style="font-size:70%;">AURORA4</span></span>
</span></span>
<span id="S3.T4.4.1.9.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.9.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.9.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">57</span></a><span id="S3.T4.4.1.9.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.9.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.9.3.1.1" class="ltx_p"><span id="S3.T4.4.1.9.3.1.1.1" class="ltx_text" style="font-size:70%;">Compare front-ends for large vocabulary recognition performance.</span></span>
</span></span>
<span id="S3.T4.4.1.9.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.9.4.1.1" class="ltx_p"><span id="S3.T4.4.1.9.4.1.1.1" class="ltx_text" style="font-size:70%;">Aurora-4 is a speech recognition dataset derived from the WSJ corpus, offering four conditions (Clean, channel, noisy, channel+noisy) with two microphone types and six noise types, totaling 4,620 utterances per set.</span></span>
</span></span></span>
<span id="S3.T4.4.1.10" class="ltx_tr">
<span id="S3.T4.4.1.10.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.10.1.1.1" class="ltx_p"><span id="S3.T4.4.1.10.1.1.1.1" class="ltx_text" style="font-size:70%;">Car-env</span></span>
</span></span>
<span id="S3.T4.4.1.10.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.10.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.10.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">57</span></a><span id="S3.T4.4.1.10.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.10.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.10.3.1.1" class="ltx_p"><span id="S3.T4.4.1.10.3.1.1.1" class="ltx_text" style="font-size:70%;">Vehicle environment sound</span></span>
</span></span>
<span id="S3.T4.4.1.10.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.10.4.1.1" class="ltx_p"><span id="S3.T4.4.1.10.4.1.1.1" class="ltx_text" style="font-size:70%;">Is a dataset from Korea that spans 100 hours of recordings in a vehicle. It comprises brief commands, with an average of 1.6 words per command.</span></span>
</span></span></span>
<span id="S3.T4.4.1.11" class="ltx_tr">
<span id="S3.T4.4.1.11.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.11.1.1.1" class="ltx_p"><span id="S3.T4.4.1.11.1.1.1.1" class="ltx_text" style="font-size:70%;">HKUST</span></span>
</span></span>
<span id="S3.T4.4.1.11.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.11.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.11.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">50</span></a>, <a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">56</span></a><span id="S3.T4.4.1.11.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.11.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.11.3.1.1" class="ltx_p"><span id="S3.T4.4.1.11.3.1.1.1" class="ltx_text" style="font-size:70%;">Classify Mandarin speech into standard and accented types.</span></span>
</span></span>
<span id="S3.T4.4.1.11.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.11.4.1.1" class="ltx_p"><span id="S3.T4.4.1.11.4.1.1.1" class="ltx_text" style="font-size:70%;">Comprises roughly 149 hours of telephone conversations in Mandarin.</span></span>
</span></span></span>
<span id="S3.T4.4.1.12" class="ltx_tr">
<span id="S3.T4.4.1.12.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.12.1.1.1" class="ltx_p"><span id="S3.T4.4.1.12.1.1.1.1" class="ltx_text" style="font-size:70%;">AudioSet</span></span>
</span></span>
<span id="S3.T4.4.1.12.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.12.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.12.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">51</span></a><span id="S3.T4.4.1.12.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.12.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.12.3.1.1" class="ltx_p"><span id="S3.T4.4.1.12.3.1.1.1" class="ltx_text" style="font-size:70%;">Audio event recognition</span></span>
</span></span>
<span id="S3.T4.4.1.12.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:14.22636pt;">
<span id="S3.T4.4.1.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.12.4.1.1" class="ltx_p"><span id="S3.T4.4.1.12.4.1.1.1" class="ltx_text" style="font-size:70%;">Includes 1,789,621 segments of 10 seconds each (equivalent to 4,971 hours). It consists of at least 100 instances clustered into 632 audio classes, with only 485 audio event categories clearly identified.</span></span>
</span></span></span>
<span id="S3.T4.4.1.13" class="ltx_tr">
<span id="S3.T4.4.1.13.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:8.5359pt;">
<span id="S3.T4.4.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.13.1.1.1" class="ltx_p"><span id="S3.T4.4.1.13.1.1.1.1" class="ltx_text" style="font-size:70%;">AWIC-19</span></span>
</span></span>
<span id="S3.T4.4.1.13.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;padding-bottom:8.5359pt;">
<span id="S3.T4.4.1.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.13.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.13.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">58</span></a><span id="S3.T4.4.1.13.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.13.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;padding-bottom:8.5359pt;">
<span id="S3.T4.4.1.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.13.3.1.1" class="ltx_p"><span id="S3.T4.4.1.13.3.1.1.1" class="ltx_text" style="font-size:70%;">Arabic words recognition</span></span>
</span></span>
<span id="S3.T4.4.1.13.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:256.1pt;padding-bottom:8.5359pt;">
<span id="S3.T4.4.1.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.13.4.1.1" class="ltx_p"><span id="S3.T4.4.1.13.4.1.1.1" class="ltx_text" style="font-size:70%;">It comprises 770 recordings featuring isolated Arabic words.</span></span>
</span></span></span>
<span id="S3.T4.4.1.14" class="ltx_tr">
<span id="S3.T4.4.1.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:42.7pt;">
<span id="S3.T4.4.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.14.1.1.1" class="ltx_p"><span id="S3.T4.4.1.14.1.1.1.1" class="ltx_text" style="font-size:70%;">TED2</span></span>
</span></span>
<span id="S3.T4.4.1.14.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:42.7pt;">
<span id="S3.T4.4.1.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.14.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.4.1.14.2.1.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">59</span></a><span id="S3.T4.4.1.14.2.1.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></span>
</span></span>
<span id="S3.T4.4.1.14.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:113.8pt;">
<span id="S3.T4.4.1.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.14.3.1.1" class="ltx_p"><span id="S3.T4.4.1.14.3.1.1.1" class="ltx_text" style="font-size:70%;">English corpus for ASR</span></span>
</span></span>
<span id="S3.T4.4.1.14.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:256.1pt;">
<span id="S3.T4.4.1.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.4.1.14.4.1.1" class="ltx_p"><span id="S3.T4.4.1.14.4.1.1.1" class="ltx_text" style="font-size:70%;">The dataset was first made available in May 2012, for training, it comprising 118 hours, 4 minutes, and 48 seconds of training data from 666 speakers, containing approximately 1.7 million words.</span></span>
</span></span></span>
</span><span id="S3.T4.4.2" class="ltx_text" style="font-size:70%;"></span></p>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Advanced ASR methods and applications</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Traditional statistical <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural"><span class="ltx_text" style="font-size:80%;">LM</span>s</span></abbr></a>, such as backoff n-gram <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural"><span class="ltx_text" style="font-size:80%;">LM</span>s</span></abbr></a>, have been widely used due to their simplicity and reliability. However, bidirectional encoder representations from transformers (BERT), which utilize attention models, have shown better contextual understanding compared to single-direction LMs, as demonstrated in the work of Devlin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">60</span></a>]</cite>.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">In terms of <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a>, deep learning-based models like the deep neural network-hidden Markov model (DNN-HMM) and the  <a href="#Sx1.11.11.11"><span href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">connectionist temporal classification</span></span></span></a> (<a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a>) have made significant advancements. DNN-HMM models have been extensively studied in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> research, while <a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a> is an end-to-end training method that does not require pre-alignment and only needs input and output sequences. The <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> model has also been successful in solving <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> tasks without using an <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a> or pronunciation dictionary, as described in Chiu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">61</span></a>]</cite>.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p"><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems often face performance degradation in certain situations due to the "one-model-fits-all" approach. Additionally, the lack of diverse and sufficient training data affects <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> performance. To overcome these constraints and improve the resilience and flexibility of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems, advanced DL methodologies such as <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a> and it sub-field  <a href="#Sx1.13.13.13"><span href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">domain adaptation</span></span></span></a> (<a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a>), <a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a>, and <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a> have surfaced. These innovative methodologies collectively address issues concerning knowledge transfer, model generalization, and training effectiveness, offering remedies that expand upon the capabilities of traditional DL models within the <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> sphere. Thus, many research studies have focused on enhancing existing <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems by applying the aforementioned algorithms. Figure <a href="#S4.F5" title="Figure 5 ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> provides an overview of the current <a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a> advanced DL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> and its most useful related schemes in both <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> and <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a>.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2403.01255/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="230" height="200" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Overview of advanced DL-driven <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> algorithms and their commonly utilized models.</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Transformer-based ASR</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.3" class="ltx_p">The Transformer stands as a prominent deep learning model extensively employed across diverse domains, including <a href="#Sx1.31.31.31"><abbr href="#Sx1.31.31.31" title="natural language processing" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">NLP</span></span></abbr></a>,  <a href="#Sx1.12.12.12"><span href="#Sx1.12.12.12" title="computer vision" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">computer vision</span></span></span></a> (<a href="#Sx1.12.12.12"><abbr href="#Sx1.12.12.12" title="computer vision" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CV</span></span></abbr></a>), and speech processing. Originally conceived for machine translation as a <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> model, it has evolved to find applications in various fields. The Transformer heavily relies on the self-attention mechanism, enabling it to capture extensive dependencies in input sequences. The standard Transformer model incorporates the query–key–value (QKV) attention mechanism. In this setup, given matrix representations of queries <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{Q}\in\mathbb{R}^{N\times D_{k}}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">𝐐</mi><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.3.2" xref="S4.SS1.p1.1.m1.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.1.m1.1.1.3.3.1" xref="S4.SS1.p1.1.m1.1.1.3.3.1.cmml">×</mo><msub id="S4.SS1.p1.1.m1.1.1.3.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.3.3.2" xref="S4.SS1.p1.1.m1.1.1.3.3.3.2.cmml">D</mi><mi id="S4.SS1.p1.1.m1.1.1.3.3.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.3.3.cmml">k</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><in id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></in><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝐐</ci><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3"><times id="S4.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.1"></times><ci id="S4.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.2">𝑁</ci><apply id="S4.SS1.p1.1.m1.1.1.3.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.3.3.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.3.3.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.3.2">𝐷</ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\mathbf{Q}\in\mathbb{R}^{N\times D_{k}}</annotation></semantics></math>, keys <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{K}\in\mathbb{R}^{M\times D_{k}}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">𝐊</mi><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml"><mi id="S4.SS1.p1.2.m2.1.1.3.2" xref="S4.SS1.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p1.2.m2.1.1.3.3" xref="S4.SS1.p1.2.m2.1.1.3.3.cmml"><mi id="S4.SS1.p1.2.m2.1.1.3.3.2" xref="S4.SS1.p1.2.m2.1.1.3.3.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.2.m2.1.1.3.3.1" xref="S4.SS1.p1.2.m2.1.1.3.3.1.cmml">×</mo><msub id="S4.SS1.p1.2.m2.1.1.3.3.3" xref="S4.SS1.p1.2.m2.1.1.3.3.3.cmml"><mi id="S4.SS1.p1.2.m2.1.1.3.3.3.2" xref="S4.SS1.p1.2.m2.1.1.3.3.3.2.cmml">D</mi><mi id="S4.SS1.p1.2.m2.1.1.3.3.3.3" xref="S4.SS1.p1.2.m2.1.1.3.3.3.3.cmml">k</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><in id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></in><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝐊</ci><apply id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.3.1.cmml" xref="S4.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.3.2.cmml" xref="S4.SS1.p1.2.m2.1.1.3.2">ℝ</ci><apply id="S4.SS1.p1.2.m2.1.1.3.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3"><times id="S4.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.1"></times><ci id="S4.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.2">𝑀</ci><apply id="S4.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.3.3.3.1.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.3.3.3.2.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.3.2">𝐷</ci><ci id="S4.SS1.p1.2.m2.1.1.3.3.3.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\mathbf{K}\in\mathbb{R}^{M\times D_{k}}</annotation></semantics></math>, and values <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{V}\in\mathbb{R}^{M\times D_{v}}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">𝐕</mi><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml"><mi id="S4.SS1.p1.3.m3.1.1.3.2" xref="S4.SS1.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p1.3.m3.1.1.3.3" xref="S4.SS1.p1.3.m3.1.1.3.3.cmml"><mi id="S4.SS1.p1.3.m3.1.1.3.3.2" xref="S4.SS1.p1.3.m3.1.1.3.3.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.3.m3.1.1.3.3.1" xref="S4.SS1.p1.3.m3.1.1.3.3.1.cmml">×</mo><msub id="S4.SS1.p1.3.m3.1.1.3.3.3" xref="S4.SS1.p1.3.m3.1.1.3.3.3.cmml"><mi id="S4.SS1.p1.3.m3.1.1.3.3.3.2" xref="S4.SS1.p1.3.m3.1.1.3.3.3.2.cmml">D</mi><mi id="S4.SS1.p1.3.m3.1.1.3.3.3.3" xref="S4.SS1.p1.3.m3.1.1.3.3.3.3.cmml">v</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><in id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></in><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝐕</ci><apply id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.3.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.2">ℝ</ci><apply id="S4.SS1.p1.3.m3.1.1.3.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3"><times id="S4.SS1.p1.3.m3.1.1.3.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.1"></times><ci id="S4.SS1.p1.3.m3.1.1.3.3.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.2">𝑀</ci><apply id="S4.SS1.p1.3.m3.1.1.3.3.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.3.3.3.1.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.3.3.3.2.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.3.2">𝐷</ci><ci id="S4.SS1.p1.3.m3.1.1.3.3.3.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3.3.3.3">𝑣</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\mathbf{V}\in\mathbb{R}^{M\times D_{v}}</annotation></semantics></math>, the scaled dot-product attention is defined as:</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.Ex1.m1.4" class="ltx_Math" alttext="\text{Attention}(\mathbf{Q},\mathbf{K},\mathbf{V})=\text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^{T}}{\sqrt{D_{k}}}\right)\mathbf{V}" display="block"><semantics id="S4.Ex1.m1.4a"><mrow id="S4.Ex1.m1.4.5" xref="S4.Ex1.m1.4.5.cmml"><mrow id="S4.Ex1.m1.4.5.2" xref="S4.Ex1.m1.4.5.2.cmml"><mtext id="S4.Ex1.m1.4.5.2.2" xref="S4.Ex1.m1.4.5.2.2a.cmml">Attention</mtext><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.4.5.2.1" xref="S4.Ex1.m1.4.5.2.1.cmml">​</mo><mrow id="S4.Ex1.m1.4.5.2.3.2" xref="S4.Ex1.m1.4.5.2.3.1.cmml"><mo stretchy="false" id="S4.Ex1.m1.4.5.2.3.2.1" xref="S4.Ex1.m1.4.5.2.3.1.cmml">(</mo><mi id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml">𝐐</mi><mo id="S4.Ex1.m1.4.5.2.3.2.2" xref="S4.Ex1.m1.4.5.2.3.1.cmml">,</mo><mi id="S4.Ex1.m1.2.2" xref="S4.Ex1.m1.2.2.cmml">𝐊</mi><mo id="S4.Ex1.m1.4.5.2.3.2.3" xref="S4.Ex1.m1.4.5.2.3.1.cmml">,</mo><mi id="S4.Ex1.m1.3.3" xref="S4.Ex1.m1.3.3.cmml">𝐕</mi><mo stretchy="false" id="S4.Ex1.m1.4.5.2.3.2.4" xref="S4.Ex1.m1.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.4.5.1" xref="S4.Ex1.m1.4.5.1.cmml">=</mo><mrow id="S4.Ex1.m1.4.5.3" xref="S4.Ex1.m1.4.5.3.cmml"><mtext id="S4.Ex1.m1.4.5.3.2" xref="S4.Ex1.m1.4.5.3.2a.cmml">softmax</mtext><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.4.5.3.1" xref="S4.Ex1.m1.4.5.3.1.cmml">​</mo><mrow id="S4.Ex1.m1.4.5.3.3.2" xref="S4.Ex1.m1.4.4.cmml"><mo id="S4.Ex1.m1.4.5.3.3.2.1" xref="S4.Ex1.m1.4.4.cmml">(</mo><mfrac id="S4.Ex1.m1.4.4" xref="S4.Ex1.m1.4.4.cmml"><msup id="S4.Ex1.m1.4.4.2" xref="S4.Ex1.m1.4.4.2.cmml"><mi id="S4.Ex1.m1.4.4.2.2" xref="S4.Ex1.m1.4.4.2.2.cmml">𝐐𝐊</mi><mi id="S4.Ex1.m1.4.4.2.3" xref="S4.Ex1.m1.4.4.2.3.cmml">T</mi></msup><msqrt id="S4.Ex1.m1.4.4.3" xref="S4.Ex1.m1.4.4.3.cmml"><msub id="S4.Ex1.m1.4.4.3.2" xref="S4.Ex1.m1.4.4.3.2.cmml"><mi id="S4.Ex1.m1.4.4.3.2.2" xref="S4.Ex1.m1.4.4.3.2.2.cmml">D</mi><mi id="S4.Ex1.m1.4.4.3.2.3" xref="S4.Ex1.m1.4.4.3.2.3.cmml">k</mi></msub></msqrt></mfrac><mo id="S4.Ex1.m1.4.5.3.3.2.2" xref="S4.Ex1.m1.4.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.4.5.3.1a" xref="S4.Ex1.m1.4.5.3.1.cmml">​</mo><mi id="S4.Ex1.m1.4.5.3.4" xref="S4.Ex1.m1.4.5.3.4.cmml">𝐕</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.4b"><apply id="S4.Ex1.m1.4.5.cmml" xref="S4.Ex1.m1.4.5"><eq id="S4.Ex1.m1.4.5.1.cmml" xref="S4.Ex1.m1.4.5.1"></eq><apply id="S4.Ex1.m1.4.5.2.cmml" xref="S4.Ex1.m1.4.5.2"><times id="S4.Ex1.m1.4.5.2.1.cmml" xref="S4.Ex1.m1.4.5.2.1"></times><ci id="S4.Ex1.m1.4.5.2.2a.cmml" xref="S4.Ex1.m1.4.5.2.2"><mtext id="S4.Ex1.m1.4.5.2.2.cmml" xref="S4.Ex1.m1.4.5.2.2">Attention</mtext></ci><vector id="S4.Ex1.m1.4.5.2.3.1.cmml" xref="S4.Ex1.m1.4.5.2.3.2"><ci id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1">𝐐</ci><ci id="S4.Ex1.m1.2.2.cmml" xref="S4.Ex1.m1.2.2">𝐊</ci><ci id="S4.Ex1.m1.3.3.cmml" xref="S4.Ex1.m1.3.3">𝐕</ci></vector></apply><apply id="S4.Ex1.m1.4.5.3.cmml" xref="S4.Ex1.m1.4.5.3"><times id="S4.Ex1.m1.4.5.3.1.cmml" xref="S4.Ex1.m1.4.5.3.1"></times><ci id="S4.Ex1.m1.4.5.3.2a.cmml" xref="S4.Ex1.m1.4.5.3.2"><mtext id="S4.Ex1.m1.4.5.3.2.cmml" xref="S4.Ex1.m1.4.5.3.2">softmax</mtext></ci><apply id="S4.Ex1.m1.4.4.cmml" xref="S4.Ex1.m1.4.5.3.3.2"><divide id="S4.Ex1.m1.4.4.1.cmml" xref="S4.Ex1.m1.4.5.3.3.2"></divide><apply id="S4.Ex1.m1.4.4.2.cmml" xref="S4.Ex1.m1.4.4.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.4.4.2.1.cmml" xref="S4.Ex1.m1.4.4.2">superscript</csymbol><ci id="S4.Ex1.m1.4.4.2.2.cmml" xref="S4.Ex1.m1.4.4.2.2">𝐐𝐊</ci><ci id="S4.Ex1.m1.4.4.2.3.cmml" xref="S4.Ex1.m1.4.4.2.3">𝑇</ci></apply><apply id="S4.Ex1.m1.4.4.3.cmml" xref="S4.Ex1.m1.4.4.3"><root id="S4.Ex1.m1.4.4.3a.cmml" xref="S4.Ex1.m1.4.4.3"></root><apply id="S4.Ex1.m1.4.4.3.2.cmml" xref="S4.Ex1.m1.4.4.3.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.4.4.3.2.1.cmml" xref="S4.Ex1.m1.4.4.3.2">subscript</csymbol><ci id="S4.Ex1.m1.4.4.3.2.2.cmml" xref="S4.Ex1.m1.4.4.3.2.2">𝐷</ci><ci id="S4.Ex1.m1.4.4.3.2.3.cmml" xref="S4.Ex1.m1.4.4.3.2.3">𝑘</ci></apply></apply></apply><ci id="S4.Ex1.m1.4.5.3.4.cmml" xref="S4.Ex1.m1.4.5.3.4">𝐕</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.4c">\text{Attention}(\mathbf{Q},\mathbf{K},\mathbf{V})=\text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^{T}}{\sqrt{D_{k}}}\right)\mathbf{V}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.5" class="ltx_p">Here, <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">N</annotation></semantics></math> and <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mi id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">M</annotation></semantics></math> represent the lengths of queries and keys (or values), and <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><msub id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">D</mi><mi id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">𝐷</ci><ci id="S4.SS1.p3.3.m3.1.1.3.cmml" xref="S4.SS1.p3.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">D_{k}</annotation></semantics></math> and <math id="S4.SS1.p3.4.m4.1" class="ltx_Math" alttext="D_{v}" display="inline"><semantics id="S4.SS1.p3.4.m4.1a"><msub id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><mi id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml">D</mi><mi id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2">𝐷</ci><ci id="S4.SS1.p3.4.m4.1.1.3.cmml" xref="S4.SS1.p3.4.m4.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">D_{v}</annotation></semantics></math> denote the dimensions of keys (or queries) and values. The softmax operation is applied row-wise to the matrix <math id="S4.SS1.p3.5.m5.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S4.SS1.p3.5.m5.1a"><mi id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml">𝐀</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><ci id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1">𝐀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">\mathbf{A}</annotation></semantics></math>. Within the Transformer architecture, three attention mechanisms exist based on the source of queries and key–value pairs:</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.4" class="ltx_p"><span id="S4.I1.i1.p1.4.1" class="ltx_text ltx_font_bold">Self-attention:</span> In the Transformer encoder, queries <math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{Q}" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><mi id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><ci id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">\mathbf{Q}</annotation></semantics></math>, keys <math id="S4.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{K}" display="inline"><semantics id="S4.I1.i1.p1.2.m2.1a"><mi id="S4.I1.i1.p1.2.m2.1.1" xref="S4.I1.i1.p1.2.m2.1.1.cmml">𝐊</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.2.m2.1b"><ci id="S4.I1.i1.p1.2.m2.1.1.cmml" xref="S4.I1.i1.p1.2.m2.1.1">𝐊</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.2.m2.1c">\mathbf{K}</annotation></semantics></math>, and values <math id="S4.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{V}" display="inline"><semantics id="S4.I1.i1.p1.3.m3.1a"><mi id="S4.I1.i1.p1.3.m3.1.1" xref="S4.I1.i1.p1.3.m3.1.1.cmml">𝐕</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.3.m3.1b"><ci id="S4.I1.i1.p1.3.m3.1.1.cmml" xref="S4.I1.i1.p1.3.m3.1.1">𝐕</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.3.m3.1c">\mathbf{V}</annotation></semantics></math> all equal the outputs of the previous layer, denoted as <math id="S4.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S4.I1.i1.p1.4.m4.1a"><mi id="S4.I1.i1.p1.4.m4.1.1" xref="S4.I1.i1.p1.4.m4.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.4.m4.1b"><ci id="S4.I1.i1.p1.4.m4.1.1.cmml" xref="S4.I1.i1.p1.4.m4.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.4.m4.1c">\mathbf{X}</annotation></semantics></math> in Eq. (2).</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.3" class="ltx_p"><span id="S4.I1.i2.p1.3.1" class="ltx_text ltx_font_bold">Masked Self-attention: </span>In the Transformer decoder, self-attention is constrained, allowing queries at each position to attend only to key–value pairs up to and including that position. This is accomplished by implementing a mask function, before normalization, on the attention matrix <math id="S4.I1.i2.p1.1.m1.2" class="ltx_Math" alttext="\hat{\mathbf{A}}=\exp\left(\frac{\mathbf{Q}\mathbf{K}^{T}}{\sqrt{D_{k}}}\right)" display="inline"><semantics id="S4.I1.i2.p1.1.m1.2a"><mrow id="S4.I1.i2.p1.1.m1.2.3" xref="S4.I1.i2.p1.1.m1.2.3.cmml"><mover accent="true" id="S4.I1.i2.p1.1.m1.2.3.2" xref="S4.I1.i2.p1.1.m1.2.3.2.cmml"><mi id="S4.I1.i2.p1.1.m1.2.3.2.2" xref="S4.I1.i2.p1.1.m1.2.3.2.2.cmml">𝐀</mi><mo id="S4.I1.i2.p1.1.m1.2.3.2.1" xref="S4.I1.i2.p1.1.m1.2.3.2.1.cmml">^</mo></mover><mo id="S4.I1.i2.p1.1.m1.2.3.1" xref="S4.I1.i2.p1.1.m1.2.3.1.cmml">=</mo><mrow id="S4.I1.i2.p1.1.m1.2.3.3.2" xref="S4.I1.i2.p1.1.m1.2.3.3.1.cmml"><mi id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">exp</mi><mo id="S4.I1.i2.p1.1.m1.2.3.3.2a" xref="S4.I1.i2.p1.1.m1.2.3.3.1.cmml">⁡</mo><mrow id="S4.I1.i2.p1.1.m1.2.3.3.2.1" xref="S4.I1.i2.p1.1.m1.2.3.3.1.cmml"><mo id="S4.I1.i2.p1.1.m1.2.3.3.2.1.1" xref="S4.I1.i2.p1.1.m1.2.3.3.1.cmml">(</mo><mfrac id="S4.I1.i2.p1.1.m1.2.2" xref="S4.I1.i2.p1.1.m1.2.2.cmml"><msup id="S4.I1.i2.p1.1.m1.2.2.2" xref="S4.I1.i2.p1.1.m1.2.2.2.cmml"><mi id="S4.I1.i2.p1.1.m1.2.2.2.2" xref="S4.I1.i2.p1.1.m1.2.2.2.2.cmml">𝐐𝐊</mi><mi id="S4.I1.i2.p1.1.m1.2.2.2.3" xref="S4.I1.i2.p1.1.m1.2.2.2.3.cmml">T</mi></msup><msqrt id="S4.I1.i2.p1.1.m1.2.2.3" xref="S4.I1.i2.p1.1.m1.2.2.3.cmml"><msub id="S4.I1.i2.p1.1.m1.2.2.3.2" xref="S4.I1.i2.p1.1.m1.2.2.3.2.cmml"><mi id="S4.I1.i2.p1.1.m1.2.2.3.2.2" xref="S4.I1.i2.p1.1.m1.2.2.3.2.2.cmml">D</mi><mi id="S4.I1.i2.p1.1.m1.2.2.3.2.3" xref="S4.I1.i2.p1.1.m1.2.2.3.2.3.cmml">k</mi></msub></msqrt></mfrac><mo id="S4.I1.i2.p1.1.m1.2.3.3.2.1.2" xref="S4.I1.i2.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.2b"><apply id="S4.I1.i2.p1.1.m1.2.3.cmml" xref="S4.I1.i2.p1.1.m1.2.3"><eq id="S4.I1.i2.p1.1.m1.2.3.1.cmml" xref="S4.I1.i2.p1.1.m1.2.3.1"></eq><apply id="S4.I1.i2.p1.1.m1.2.3.2.cmml" xref="S4.I1.i2.p1.1.m1.2.3.2"><ci id="S4.I1.i2.p1.1.m1.2.3.2.1.cmml" xref="S4.I1.i2.p1.1.m1.2.3.2.1">^</ci><ci id="S4.I1.i2.p1.1.m1.2.3.2.2.cmml" xref="S4.I1.i2.p1.1.m1.2.3.2.2">𝐀</ci></apply><apply id="S4.I1.i2.p1.1.m1.2.3.3.1.cmml" xref="S4.I1.i2.p1.1.m1.2.3.3.2"><exp id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1"></exp><apply id="S4.I1.i2.p1.1.m1.2.2.cmml" xref="S4.I1.i2.p1.1.m1.2.2"><divide id="S4.I1.i2.p1.1.m1.2.2.1.cmml" xref="S4.I1.i2.p1.1.m1.2.2"></divide><apply id="S4.I1.i2.p1.1.m1.2.2.2.cmml" xref="S4.I1.i2.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.I1.i2.p1.1.m1.2.2.2.1.cmml" xref="S4.I1.i2.p1.1.m1.2.2.2">superscript</csymbol><ci id="S4.I1.i2.p1.1.m1.2.2.2.2.cmml" xref="S4.I1.i2.p1.1.m1.2.2.2.2">𝐐𝐊</ci><ci id="S4.I1.i2.p1.1.m1.2.2.2.3.cmml" xref="S4.I1.i2.p1.1.m1.2.2.2.3">𝑇</ci></apply><apply id="S4.I1.i2.p1.1.m1.2.2.3.cmml" xref="S4.I1.i2.p1.1.m1.2.2.3"><root id="S4.I1.i2.p1.1.m1.2.2.3a.cmml" xref="S4.I1.i2.p1.1.m1.2.2.3"></root><apply id="S4.I1.i2.p1.1.m1.2.2.3.2.cmml" xref="S4.I1.i2.p1.1.m1.2.2.3.2"><csymbol cd="ambiguous" id="S4.I1.i2.p1.1.m1.2.2.3.2.1.cmml" xref="S4.I1.i2.p1.1.m1.2.2.3.2">subscript</csymbol><ci id="S4.I1.i2.p1.1.m1.2.2.3.2.2.cmml" xref="S4.I1.i2.p1.1.m1.2.2.3.2.2">𝐷</ci><ci id="S4.I1.i2.p1.1.m1.2.2.3.2.3.cmml" xref="S4.I1.i2.p1.1.m1.2.2.3.2.3">𝑘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.2c">\hat{\mathbf{A}}=\exp\left(\frac{\mathbf{Q}\mathbf{K}^{T}}{\sqrt{D_{k}}}\right)</annotation></semantics></math>, where illegal positions are masked out by setting <math id="S4.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="\hat{A}_{ij}=-\infty" display="inline"><semantics id="S4.I1.i2.p1.2.m2.1a"><mrow id="S4.I1.i2.p1.2.m2.1.1" xref="S4.I1.i2.p1.2.m2.1.1.cmml"><msub id="S4.I1.i2.p1.2.m2.1.1.2" xref="S4.I1.i2.p1.2.m2.1.1.2.cmml"><mover accent="true" id="S4.I1.i2.p1.2.m2.1.1.2.2" xref="S4.I1.i2.p1.2.m2.1.1.2.2.cmml"><mi id="S4.I1.i2.p1.2.m2.1.1.2.2.2" xref="S4.I1.i2.p1.2.m2.1.1.2.2.2.cmml">A</mi><mo id="S4.I1.i2.p1.2.m2.1.1.2.2.1" xref="S4.I1.i2.p1.2.m2.1.1.2.2.1.cmml">^</mo></mover><mrow id="S4.I1.i2.p1.2.m2.1.1.2.3" xref="S4.I1.i2.p1.2.m2.1.1.2.3.cmml"><mi id="S4.I1.i2.p1.2.m2.1.1.2.3.2" xref="S4.I1.i2.p1.2.m2.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.I1.i2.p1.2.m2.1.1.2.3.1" xref="S4.I1.i2.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S4.I1.i2.p1.2.m2.1.1.2.3.3" xref="S4.I1.i2.p1.2.m2.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S4.I1.i2.p1.2.m2.1.1.1" xref="S4.I1.i2.p1.2.m2.1.1.1.cmml">=</mo><mrow id="S4.I1.i2.p1.2.m2.1.1.3" xref="S4.I1.i2.p1.2.m2.1.1.3.cmml"><mo id="S4.I1.i2.p1.2.m2.1.1.3a" xref="S4.I1.i2.p1.2.m2.1.1.3.cmml">−</mo><mi mathvariant="normal" id="S4.I1.i2.p1.2.m2.1.1.3.2" xref="S4.I1.i2.p1.2.m2.1.1.3.2.cmml">∞</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.2.m2.1b"><apply id="S4.I1.i2.p1.2.m2.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1"><eq id="S4.I1.i2.p1.2.m2.1.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1.1"></eq><apply id="S4.I1.i2.p1.2.m2.1.1.2.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.I1.i2.p1.2.m2.1.1.2.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2">subscript</csymbol><apply id="S4.I1.i2.p1.2.m2.1.1.2.2.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2.2"><ci id="S4.I1.i2.p1.2.m2.1.1.2.2.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2.2.1">^</ci><ci id="S4.I1.i2.p1.2.m2.1.1.2.2.2.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2.2.2">𝐴</ci></apply><apply id="S4.I1.i2.p1.2.m2.1.1.2.3.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2.3"><times id="S4.I1.i2.p1.2.m2.1.1.2.3.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2.3.1"></times><ci id="S4.I1.i2.p1.2.m2.1.1.2.3.2.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2.3.2">𝑖</ci><ci id="S4.I1.i2.p1.2.m2.1.1.2.3.3.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S4.I1.i2.p1.2.m2.1.1.3.cmml" xref="S4.I1.i2.p1.2.m2.1.1.3"><minus id="S4.I1.i2.p1.2.m2.1.1.3.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1.3"></minus><infinity id="S4.I1.i2.p1.2.m2.1.1.3.2.cmml" xref="S4.I1.i2.p1.2.m2.1.1.3.2"></infinity></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.2.m2.1c">\hat{A}_{ij}=-\infty</annotation></semantics></math> if <math id="S4.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="i&lt;j" display="inline"><semantics id="S4.I1.i2.p1.3.m3.1a"><mrow id="S4.I1.i2.p1.3.m3.1.1" xref="S4.I1.i2.p1.3.m3.1.1.cmml"><mi id="S4.I1.i2.p1.3.m3.1.1.2" xref="S4.I1.i2.p1.3.m3.1.1.2.cmml">i</mi><mo id="S4.I1.i2.p1.3.m3.1.1.1" xref="S4.I1.i2.p1.3.m3.1.1.1.cmml">&lt;</mo><mi id="S4.I1.i2.p1.3.m3.1.1.3" xref="S4.I1.i2.p1.3.m3.1.1.3.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.3.m3.1b"><apply id="S4.I1.i2.p1.3.m3.1.1.cmml" xref="S4.I1.i2.p1.3.m3.1.1"><lt id="S4.I1.i2.p1.3.m3.1.1.1.cmml" xref="S4.I1.i2.p1.3.m3.1.1.1"></lt><ci id="S4.I1.i2.p1.3.m3.1.1.2.cmml" xref="S4.I1.i2.p1.3.m3.1.1.2">𝑖</ci><ci id="S4.I1.i2.p1.3.m3.1.1.3.cmml" xref="S4.I1.i2.p1.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.3.m3.1c">i&lt;j</annotation></semantics></math>. This type of self-attention is often referred to as autoregressive or causal attention.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Cross-attention:</span> In cross-attention, queries originate from the results of the preceding (decoder) layer, while keys and values stem from the outputs of the encoder.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">Numerous studies in the <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> field have introduced transformer-based approaches, encompassing both the acoustic and language domains. In the subsequent subsections, we delve into a comprehensive review and detailed analysis of several cutting-edge techniques within each of these categories.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.17.3.1" class="ltx_text" style="font-size:129%;">Table 5</span>: </span><span id="S4.T5.4.2" class="ltx_text" style="font-size:129%;">Summary of some proposed work in transformer-based ASR. The symbol (<math id="S4.T5.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.3.1.m1.1b"><mo stretchy="false" id="S4.T5.3.1.m1.1.1" xref="S4.T5.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.1.m1.1c"><ci id="S4.T5.3.1.m1.1.1.cmml" xref="S4.T5.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.1.m1.1d">\uparrow</annotation></semantics></math>) denotes result increase, whereas (<math id="S4.T5.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.4.2.m2.1b"><mo stretchy="false" id="S4.T5.4.2.m2.1.1" xref="S4.T5.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.2.m2.1c"><ci id="S4.T5.4.2.m2.1.1.cmml" xref="S4.T5.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.2.m2.1d">\downarrow</annotation></semantics></math>) signifies result decrease. In cases where multiple scenarios are examined, only the top-performing outcome is mentioned.</span></figcaption>
<table id="S4.T5.11" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.11.8" class="ltx_tr">
<td id="S4.T5.11.8.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T5.11.8.1.1" class="ltx_text" style="font-size:70%;">Ref.</span></td>
<td id="S4.T5.11.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:71.1pt;">
<span id="S4.T5.11.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.8.2.1.1" class="ltx_p"><span id="S4.T5.11.8.2.1.1.1" class="ltx_text" style="font-size:70%;">Based on</span></span>
</span>
</td>
<td id="S4.T5.11.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:142.3pt;">
<span id="S4.T5.11.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.8.3.1.1" class="ltx_p"><span id="S4.T5.11.8.3.1.1.1" class="ltx_text" style="font-size:70%;">Speech recognition task</span></span>
</span>
</td>
<td id="S4.T5.11.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:85.4pt;">
<span id="S4.T5.11.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.8.4.1.1" class="ltx_p"><span id="S4.T5.11.8.4.1.1.1" class="ltx_text" style="font-size:70%;">Transformer</span></span>
</span>
</td>
<td id="S4.T5.11.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:28.5pt;">
<span id="S4.T5.11.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.8.5.1.1" class="ltx_p"><span id="S4.T5.11.8.5.1.1.1" class="ltx_text" style="font-size:70%;">AM/LM</span></span>
</span>
</td>
<td id="S4.T5.11.8.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:71.1pt;">
<span id="S4.T5.11.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.8.6.1.1" class="ltx_p"><span id="S4.T5.11.8.6.1.1.1" class="ltx_text" style="font-size:70%;">Result with metric</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.11.9" class="ltx_tr">
<td id="S4.T5.11.9.1" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.11.9.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">55</span></a><span id="S4.T5.11.9.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.11.9.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:71.1pt;">
<span id="S4.T5.11.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.9.2.1.1" class="ltx_p"><span id="S4.T5.11.9.2.1.1.1" class="ltx_text" style="font-size:70%;">CNN</span></span>
</span>
</td>
<td id="S4.T5.11.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:142.3pt;">
<span id="S4.T5.11.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.9.3.1.1" class="ltx_p"><span id="S4.T5.11.9.3.1.1.1" class="ltx_text" style="font-size:70%;">Solve the problem of code-switching</span></span>
</span>
</td>
<td id="S4.T5.11.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:85.4pt;">
<span id="S4.T5.11.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.9.4.1.1" class="ltx_p"><span id="S4.T5.11.9.4.1.1.1" class="ltx_text" style="font-size:70%;">Multi-head attention</span></span>
</span>
</td>
<td id="S4.T5.11.9.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:28.5pt;">
<span id="S4.T5.11.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.9.5.1.1" class="ltx_p"><span id="S4.T5.11.9.5.1.1.1" class="ltx_text" style="font-size:70%;">LM</span></span>
</span>
</td>
<td id="S4.T5.11.9.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:71.1pt;">
<span id="S4.T5.11.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.9.6.1.1" class="ltx_p"><span id="S4.T5.11.9.6.1.1.1" class="ltx_text" style="font-size:70%;">RER= 10.2%</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.11.10" class="ltx_tr">
<td id="S4.T5.11.10.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.11.10.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">56</span></a><span id="S4.T5.11.10.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.11.10.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.10.2.1.1" class="ltx_p"><span id="S4.T5.11.10.2.1.1.1" class="ltx_text" style="font-size:70%;">VGGnet</span></span>
</span>
</td>
<td id="S4.T5.11.10.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.10.3.1.1" class="ltx_p"><span id="S4.T5.11.10.3.1.1.1" class="ltx_text" style="font-size:70%;">Compress ASR parameters and speeds up the inference time</span></span>
</span>
</td>
<td id="S4.T5.11.10.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.10.4.1.1" class="ltx_p"><span id="S4.T5.11.10.4.1.1.1" class="ltx_text" style="font-size:70%;">Low-rank multi-head attention</span></span>
</span>
</td>
<td id="S4.T5.11.10.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.10.5.1.1" class="ltx_p"><span id="S4.T5.11.10.5.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.11.10.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.10.6.1.1" class="ltx_p"><span id="S4.T5.11.10.6.1.1.1" class="ltx_text" style="font-size:70%;">CER= 13.09%</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.5.1" class="ltx_tr">
<td id="S4.T5.5.1.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.5.1.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">57</span></a><span id="S4.T5.5.1.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.5.1.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.5.1.3.1.1" class="ltx_p"><span id="S4.T5.5.1.3.1.1.1" class="ltx_text" style="font-size:70%;">DNN-HMM</span></span>
</span>
</td>
<td id="S4.T5.5.1.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.5.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.5.1.4.1.1" class="ltx_p"><span id="S4.T5.5.1.4.1.1.1" class="ltx_text" style="font-size:70%;">Improve ASR</span></span>
</span>
</td>
<td id="S4.T5.5.1.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.5.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.5.1.5.1.1" class="ltx_p"><span id="S4.T5.5.1.5.1.1.1" class="ltx_text" style="font-size:70%;">Attention</span></span>
</span>
</td>
<td id="S4.T5.5.1.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.5.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.5.1.6.1.1" class="ltx_p"><span id="S4.T5.5.1.6.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.5.1.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.5.1.1.1.1" class="ltx_p"><span id="S4.T5.5.1.1.1.1.1" class="ltx_text" style="font-size:70%;">RER= 4.7%</span><math id="S4.T5.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.5.1.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T5.5.1.1.1.1.m1.1.1" xref="S4.T5.5.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.1.1.1.1.m1.1b"><ci id="S4.T5.5.1.1.1.1.m1.1.1.cmml" xref="S4.T5.5.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T5.11.11" class="ltx_tr">
<td id="S4.T5.11.11.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.11.11.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">62</span></a><span id="S4.T5.11.11.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.11.11.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.11.2.1.1" class="ltx_p"><span id="S4.T5.11.11.2.1.1.1" class="ltx_text" style="font-size:70%;">Emformer</span></span>
</span>
</td>
<td id="S4.T5.11.11.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.11.3.1.1" class="ltx_p"><span id="S4.T5.11.11.3.1.1.1" class="ltx_text" style="font-size:70%;">Large scale </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T5.11.11.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.11.4.1.1" class="ltx_p"><span id="S4.T5.11.11.4.1.1.1" class="ltx_text" style="font-size:70%;">Attention</span></span>
</span>
</td>
<td id="S4.T5.11.11.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.11.5.1.1" class="ltx_p"><span id="S4.T5.11.11.5.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.11.11.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.11.6.1.1" class="ltx_p"><span id="S4.T5.11.11.6.1.1.1" class="ltx_text" style="font-size:70%;">RERR= 26%</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.6.2" class="ltx_tr">
<td id="S4.T5.6.2.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.6.2.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">63</span></a><span id="S4.T5.6.2.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.6.2.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.6.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.6.2.3.1.1" class="ltx_p"><span id="S4.T5.6.2.3.1.1.1" class="ltx_text" style="font-size:70%;">TRUNet</span></span>
</span>
</td>
<td id="S4.T5.6.2.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.6.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.6.2.4.1.1" class="ltx_p"><span id="S4.T5.6.2.4.1.1.1" class="ltx_text" style="font-size:70%;">Sound source separation</span></span>
</span>
</td>
<td id="S4.T5.6.2.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.6.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.6.2.5.1.1" class="ltx_p"><span id="S4.T5.6.2.5.1.1.1" class="ltx_text" style="font-size:70%;">TNet</span></span>
</span>
</td>
<td id="S4.T5.6.2.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.6.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.6.2.6.1.1" class="ltx_p"><span id="S4.T5.6.2.6.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.6.2.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.6.2.1.1.1" class="ltx_p"><span id="S4.T5.6.2.1.1.1.1" class="ltx_text" style="font-size:70%;">PESQ= 0.22</span><math id="S4.T5.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.6.2.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T5.6.2.1.1.1.m1.1.1" xref="S4.T5.6.2.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.2.1.1.1.m1.1b"><ci id="S4.T5.6.2.1.1.1.m1.1.1.cmml" xref="S4.T5.6.2.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.2.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T5.8.4" class="ltx_tr">
<td id="S4.T5.8.4.3" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.8.4.3.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">64</span></a><span id="S4.T5.8.4.3.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.8.4.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.8.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.8.4.4.1.1" class="ltx_p"><a href="#Sx1.29.29.29"><abbr href="#Sx1.29.29.29" title="multi-head self-attention" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">MHSA</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T5.8.4.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.8.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.8.4.5.1.1" class="ltx_p"><span id="S4.T5.8.4.5.1.1.1" class="ltx_text" style="font-size:70%;">Improve speech/ASR</span></span>
</span>
</td>
<td id="S4.T5.7.3.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.7.3.1.1.1" class="ltx_p"><span id="S4.T5.7.3.1.1.1.1" class="ltx_text" style="font-size:70%;">D</span><sup id="S4.T5.7.3.1.1.1.2" class="ltx_sup"><span id="S4.T5.7.3.1.1.1.2.1" class="ltx_text" style="font-size:70%;">2</span></sup><span id="S4.T5.7.3.1.1.1.3" class="ltx_text" style="font-size:70%;">Net</span></span>
</span>
</td>
<td id="S4.T5.8.4.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.8.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.8.4.6.1.1" class="ltx_p"><span id="S4.T5.8.4.6.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.8.4.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.8.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.8.4.2.1.1" class="ltx_p"><span id="S4.T5.8.4.2.1.1.1" class="ltx_text" style="font-size:70%;">PESQ= 0.96</span><math id="S4.T5.8.4.2.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.8.4.2.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T5.8.4.2.1.1.m1.1.1" xref="S4.T5.8.4.2.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.8.4.2.1.1.m1.1b"><ci id="S4.T5.8.4.2.1.1.m1.1.1.cmml" xref="S4.T5.8.4.2.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.4.2.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T5.11.12" class="ltx_tr">
<td id="S4.T5.11.12.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.11.12.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">58</span></a><span id="S4.T5.11.12.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.11.12.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.12.2.1.1" class="ltx_p"><span id="S4.T5.11.12.2.1.1.1" class="ltx_text" style="font-size:70%;">HMM</span></span>
</span>
</td>
<td id="S4.T5.11.12.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.11.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.12.3.1.1" class="ltx_p"><span id="S4.T5.11.12.3.1.1.1" class="ltx_text" style="font-size:70%;">Improve ASR</span></span>
</span>
</td>
<td id="S4.T5.11.12.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.11.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.12.4.1.1" class="ltx_p"><span id="S4.T5.11.12.4.1.1.1" class="ltx_text" style="font-size:70%;">Acoustic Encoder</span></span>
</span>
</td>
<td id="S4.T5.11.12.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.11.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.12.5.1.1" class="ltx_p"><span id="S4.T5.11.12.5.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.11.12.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.12.6.1.1" class="ltx_p"><span id="S4.T5.11.12.6.1.1.1" class="ltx_text" style="font-size:70%;">Acc= 96%</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.9.5" class="ltx_tr">
<td id="S4.T5.9.5.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.9.5.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">65</span></a><span id="S4.T5.9.5.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.9.5.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.9.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.9.5.3.1.1" class="ltx_p"><span id="S4.T5.9.5.3.1.1.1" class="ltx_text" style="font-size:70%;">RNN-T</span></span>
</span>
</td>
<td id="S4.T5.9.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.9.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.9.5.4.1.1" class="ltx_p"><span id="S4.T5.9.5.4.1.1.1" class="ltx_text" style="font-size:70%;">Acoustic re-scoring scenario</span></span>
</span>
</td>
<td id="S4.T5.9.5.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.9.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.9.5.5.1.1" class="ltx_p"><span id="S4.T5.9.5.5.1.1.1" class="ltx_text" style="font-size:70%;">Transformer- Transducer</span></span>
</span>
</td>
<td id="S4.T5.9.5.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.9.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.9.5.6.1.1" class="ltx_p"><span id="S4.T5.9.5.6.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.9.5.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.9.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.9.5.1.1.1" class="ltx_p"><span id="S4.T5.9.5.1.1.1.1" class="ltx_text" style="font-size:70%;">Acc= 8%</span><math id="S4.T5.9.5.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.9.5.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T5.9.5.1.1.1.m1.1.1" xref="S4.T5.9.5.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.9.5.1.1.1.m1.1b"><ci id="S4.T5.9.5.1.1.1.m1.1.1.cmml" xref="S4.T5.9.5.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.5.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T5.10.6" class="ltx_tr">
<td id="S4.T5.10.6.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.10.6.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">66</span></a><span id="S4.T5.10.6.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.10.6.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.10.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.10.6.3.1.1" class="ltx_p"><span id="S4.T5.10.6.3.1.1.1" class="ltx_text" style="font-size:70%;">CTC</span></span>
</span>
</td>
<td id="S4.T5.10.6.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.10.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.10.6.4.1.1" class="ltx_p"><span id="S4.T5.10.6.4.1.1.1" class="ltx_text" style="font-size:70%;">ASR, ST, Acoustic </span><a href="#Sx1.17.17.17"><abbr href="#Sx1.17.17.17" title="event detection" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ED</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T5.10.6.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.10.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.10.6.5.1.1" class="ltx_p"><span id="S4.T5.10.6.5.1.1.1" class="ltx_text" style="font-size:70%;">All-in-one</span></span>
</span>
</td>
<td id="S4.T5.10.6.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.10.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.10.6.6.1.1" class="ltx_p"><span id="S4.T5.10.6.6.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.10.6.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.10.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.10.6.1.1.1" class="ltx_p"><span id="S4.T5.10.6.1.1.1.1" class="ltx_text" style="font-size:70%;">WER=0.3%</span><math id="S4.T5.10.6.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.10.6.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T5.10.6.1.1.1.m1.1.1" xref="S4.T5.10.6.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.10.6.1.1.1.m1.1b"><ci id="S4.T5.10.6.1.1.1.m1.1.1.cmml" xref="S4.T5.10.6.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.6.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T5.11.13" class="ltx_tr">
<td id="S4.T5.11.13.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.11.13.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">67</span></a><span id="S4.T5.11.13.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.11.13.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.13.2.1.1" class="ltx_p"><span id="S4.T5.11.13.2.1.1.1" class="ltx_text" style="font-size:70%;">CNN</span></span>
</span>
</td>
<td id="S4.T5.11.13.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.11.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.13.3.1.1" class="ltx_p"><span id="S4.T5.11.13.3.1.1.1" class="ltx_text" style="font-size:70%;">Speech recognition with low latency, reduced frame rate, and streamability.</span></span>
</span>
</td>
<td id="S4.T5.11.13.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.11.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.13.4.1.1" class="ltx_p"><span id="S4.T5.11.13.4.1.1.1" class="ltx_text" style="font-size:70%;">Transformer-Transducer</span></span>
</span>
</td>
<td id="S4.T5.11.13.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.11.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.13.5.1.1" class="ltx_p"><span id="S4.T5.11.13.5.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.11.13.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.13.6.1.1" class="ltx_p"><span id="S4.T5.11.13.6.1.1.1" class="ltx_text" style="font-size:70%;">WER= 3.6%</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.11.7" class="ltx_tr">
<td id="S4.T5.11.7.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.11.7.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">68</span></a><span id="S4.T5.11.7.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.11.7.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.7.3.1.1" class="ltx_p"><span id="S4.T5.11.7.3.1.1.1" class="ltx_text" style="font-size:70%;">CTC alignment</span></span>
</span>
</td>
<td id="S4.T5.11.7.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.11.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.7.4.1.1" class="ltx_p"><span id="S4.T5.11.7.4.1.1.1" class="ltx_text" style="font-size:70%;">Retrieve the acoustic embedding at the token level for better ASR</span></span>
</span>
</td>
<td id="S4.T5.11.7.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.11.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.7.5.1.1" class="ltx_p"><span id="S4.T5.11.7.5.1.1.1" class="ltx_text" style="font-size:70%;">Attention</span></span>
</span>
</td>
<td id="S4.T5.11.7.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.11.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.7.6.1.1" class="ltx_p"><span id="S4.T5.11.7.6.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.11.7.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.7.1.1.1" class="ltx_p"><span id="S4.T5.11.7.1.1.1.1" class="ltx_text" style="font-size:70%;">51.2x RTF</span><math id="S4.T5.11.7.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.11.7.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T5.11.7.1.1.1.m1.1.1" xref="S4.T5.11.7.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.11.7.1.1.1.m1.1b"><ci id="S4.T5.11.7.1.1.1.m1.1.1.cmml" xref="S4.T5.11.7.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.11.7.1.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S4.T5.11.7.1.1.1.2" class="ltx_text" style="font-size:70%;"> </span>
<br class="ltx_break"><span id="S4.T5.11.7.1.1.1.3" class="ltx_text" style="font-size:70%;">WER= 2.3%</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.11.14" class="ltx_tr">
<td id="S4.T5.11.14.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.11.14.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">69</span></a><span id="S4.T5.11.14.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.11.14.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.14.2.1.1" class="ltx_p"><span id="S4.T5.11.14.2.1.1.1" class="ltx_text" style="font-size:70%;">RNN-LSTM</span></span>
</span>
</td>
<td id="S4.T5.11.14.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:142.3pt;">
<span id="S4.T5.11.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.14.3.1.1" class="ltx_p"><span id="S4.T5.11.14.3.1.1.1" class="ltx_text" style="font-size:70%;">Improve the efficiency of end-to-end ASR</span></span>
</span>
</td>
<td id="S4.T5.11.14.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T5.11.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.14.4.1.1" class="ltx_p"><span id="S4.T5.11.14.4.1.1.1" class="ltx_text" style="font-size:70%;">Attention</span></span>
</span>
</td>
<td id="S4.T5.11.14.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:28.5pt;">
<span id="S4.T5.11.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.14.5.1.1" class="ltx_p"><span id="S4.T5.11.14.5.1.1.1" class="ltx_text" style="font-size:70%;">LM</span></span>
</span>
</td>
<td id="S4.T5.11.14.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T5.11.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.14.6.1.1" class="ltx_p"><span id="S4.T5.11.14.6.1.1.1" class="ltx_text" style="font-size:70%;">CER=1.98%</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.11.15" class="ltx_tr">
<td id="S4.T5.11.15.1" class="ltx_td ltx_align_left ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.11.15.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">59</span></a><span id="S4.T5.11.15.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T5.11.15.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:71.1pt;">
<span id="S4.T5.11.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.15.2.1.1" class="ltx_p"><span id="S4.T5.11.15.2.1.1.1" class="ltx_text" style="font-size:70%;">CTC Alignment</span></span>
</span>
</td>
<td id="S4.T5.11.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:142.3pt;">
<span id="S4.T5.11.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.15.3.1.1" class="ltx_p"><span id="S4.T5.11.15.3.1.1.1" class="ltx_text" style="font-size:70%;">Enhance the performance of end-to-end </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T5.11.15.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:85.4pt;">
<span id="S4.T5.11.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.15.4.1.1" class="ltx_p"><span id="S4.T5.11.15.4.1.1.1" class="ltx_text" style="font-size:70%;">Autoregressive Transformer</span></span>
</span>
</td>
<td id="S4.T5.11.15.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:28.5pt;">
<span id="S4.T5.11.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.15.5.1.1" class="ltx_p"><span id="S4.T5.11.15.5.1.1.1" class="ltx_text" style="font-size:70%;">AM</span></span>
</span>
</td>
<td id="S4.T5.11.15.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:71.1pt;">
<span id="S4.T5.11.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.11.15.6.1.1" class="ltx_p"><span id="S4.T5.11.15.6.1.1.1" class="ltx_text" style="font-size:70%;">RTF= 0.0134 </span>
<br class="ltx_break"><span id="S4.T5.11.15.6.1.1.2" class="ltx_text" style="font-size:70%;">WER= 2.7%</span></span>
</span>
</td>
</tr>
</table>
</figure>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Acoustic domain</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">The study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">57</span></a>]</cite> reveals the Transformer model’s increased susceptibility to input sparsity compared to the  <a href="#Sx1.9.9.9"><span href="#Sx1.9.9.9" title="convolutional neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">convolutional neural network</span></span></span></a> (<a href="#Sx1.9.9.9"><abbr href="#Sx1.9.9.9" title="convolutional neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CNN</span></span></abbr></a>). The authors analyze the performance decline, attributing it to the Transformer’s structural characteristics. Additionally, they introduce a novel regularization method to enhance the Transformer’s resilience to input sparsity. This method directly regulates attention weights through silence label information in forced-alignment, offering the advantage of not requiring extra module training and excessive computation.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.1" class="ltx_p">The paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">50</span></a>]</cite> addresses a limitation in Transformer-based end-to-end modeling for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> tasks, where intermediate features from multiple input streams may lack diversity. The proposed solution introduces a multi-level acoustic feature extraction framework, incorporating shallow and deep streams to capture both traditional features for classification and speaker-invariant deep features for diversity. A  <a href="#Sx1.18.18.18"><span href="#Sx1.18.18.18" title="feature correlation-based fusion" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">feature correlation-based fusion</span></span></span></a> (<a href="#Sx1.18.18.18"><abbr href="#Sx1.18.18.18" title="feature correlation-based fusion" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FCF</span></span></abbr></a>) strategy, employed to combine intermediate features across both the frequency and time domains, correlates and combines these features before feeding them into the Transformer encoder-decoder module.</p>
</div>
<div id="S4.SS1.SSS1.p3" class="ltx_para">
<p id="S4.SS1.SSS1.p3.2" class="ltx_p">The proposed masked autoencoding audio spectrogram Transformer (MAE-AST) operates solely on unmasked tokens <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">51</span></a>]</cite>, utilizing a large encoder. It concatenates mask tokens with encoder output embeddings, feeding them into a shallow decoder. Fine-tuning for downstream tasks involves using only the encoder, eliminating the decoder’s reconstruction layers. MAE-AST represents a significant improvement over the  <a href="#Sx1.46.46.46"><span href="#Sx1.46.46.46" title="self-supervised audio spectrogram transformer" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">self-supervised audio spectrogram transformer</span></span></span></a> (<a href="#Sx1.46.46.46"><abbr href="#Sx1.46.46.46" title="self-supervised audio spectrogram transformer" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SSAST</span></span></abbr></a>) model for speech and audio classification. Addressing the high masking ratio issue, the method achieves a 3<math id="S4.SS1.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.SSS1.p3.1.m1.1a"><mo id="S4.SS1.SSS1.p3.1.m1.1.1" xref="S4.SS1.SSS1.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p3.1.m1.1b"><times id="S4.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p3.1.m1.1c">\times</annotation></semantics></math> speedup and 2<math id="S4.SS1.SSS1.p3.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.SSS1.p3.2.m2.1a"><mo id="S4.SS1.SSS1.p3.2.m2.1.1" xref="S4.SS1.SSS1.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p3.2.m2.1b"><times id="S4.SS1.SSS1.p3.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p3.2.m2.1c">\times</annotation></semantics></math> memory usage reduction. During downstream tasks, the approach consistently outperforms <a href="#Sx1.46.46.46"><abbr href="#Sx1.46.46.46" title="self-supervised audio spectrogram transformer" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SSAST</span></span></abbr></a>. To identify varities of sounds types, Bai et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">52</span></a>]</cite> introduce SE-Trans, a cross-task model for environmental sound recognition, encompassing acoustic scene classification, urban sound tagging, and anomalous sound detection. Utilizing attention mechanisms and Transformer encoder modules, SE-Trans learns channel-wise relationships and temporal dependencies in acoustic features. The model incorporates FMix data augmentation, involving the creation of a binary mask from a randomly sampled complex matrix with a low-pass filter. SE-Trans achieves outstanding performance in ESR tasks, proven through evaluations on DCASE challenge databases, underscoring its robustness and versatility in environmental sound recognition.</p>
</div>
<div id="S4.SS1.SSS1.p4" class="ltx_para">
<p id="S4.SS1.SSS1.p4.1" class="ltx_p">Automated audio captioning (AAC) involves generating textual descriptions for audio recordings, covering sound events, acoustic scenes, and event relationships. Current AAC systems typically employ an encoder-decoder architecture, with the decoder crafting captions based on extracted audio features. Chen et al. in their paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">53</span></a>]</cite> introduces a novel approach that enhances caption generation by leveraging multi-level information extracted from the audio clip. The proposed method consists of a CNN encoder with multi-level feature extraction (channel attention, spatial attention), A module specialized in predicting keywords to generate guidance information at the word level and Transformer decoder. Figure <a href="#S4.F6" title="Figure 6 ‣ 4.1.1 Acoustic domain ‣ 4.1 Transformer-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> depicts the overall architecture incorporating the three mentioned modules. Results demonstrate significant improvements in various metrics, achieving <a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a> performance during the cross-entropy training stage.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2403.01255/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="332" height="113" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">An example of CNN-based transformer for automated audio captioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">53</span></a>]</cite>.</span></figcaption>
</figure>
<div id="S4.SS1.SSS1.p5" class="ltx_para">
<p id="S4.SS1.SSS1.p5.1" class="ltx_p">Adversarial audio involves manipulating sound to deceive or compromise  <a href="#Sx1.30.30.30"><span href="#Sx1.30.30.30" title="machine learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">machine learning</span></span></span></a> (<a href="#Sx1.30.30.30"><abbr href="#Sx1.30.30.30" title="machine learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ML</span></span></abbr></a>) systems, exploiting vulnerabilities in audio recognition models. Both <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">70</span></a>, <a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">71</span></a>]</cite> work are built to combat adversarial noise using transformers. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">70</span></a>]</cite> employed a vision transformer customized for audio signals to identify speech regions amidst challenging acoustic conditions. To enhance adaptability, they incorporated an augmentation module as an additional head in the transformer, integrating low-pass and band-pass filters. Experimental results reveal that the augmented vision architecture achieves an F1-score of up to 85.2% when using a low-pass filter, surpassing the baseline vision transformer, which attains an F1-score of up to 81.2%, in speech detection. However, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">71</span></a>]</cite> the authors present an adversarial detection framework using an attention-based transformer mechanism to identify adversarial audio. Spectrogram features are segmented and integrated with positional information before input into the transformer encoder, achieving 96.5% accuracy under diverse conditions such as noisy environments, black-box attacks, and white-box attacks.</p>
</div>
<div id="S4.SS1.SSS1.p6" class="ltx_para">
<p id="S4.SS1.SSS1.p6.1" class="ltx_p">The paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">72</span></a>]</cite> introduces a parallel-path transformer model to address computation cost challenges for speech separation tasks. Using improved feed-forward networks and transformer modules, it employs a parallel processing strategy with intra-chunk and inter-chunk transformers. This enables parallel local and global modeling of speech signals, enhancing overall system performance by capturing short and long-term dependencies.</p>
</div>
<div id="S4.SS1.SSS1.p7" class="ltx_para">
<p id="S4.SS1.SSS1.p7.1" class="ltx_p">A Hybrid <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> approach outlines the conceptualization and execution of a technique that integrates neural network methodologies into advanced continuous speech recognition systems. This integration is built upon <a href="#Sx1.23.23.23"><span href="#Sx1.23.23.23" title="hidden Markov models" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long-plural"><span class="ltx_text" style="font-size:80%;">hidden Markov models</span>s</span></span></a> with the aim of enhancing their overall performance. Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">73</span></a>]</cite> introduce and assess transformer-based <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural"><span class="ltx_text" style="font-size:80%;">AM</span>s</span></abbr></a> for hybrid speech recognition. The approach incorporates various positional embedding methods and an iterated loss for training deep transformers. Demonstrating superior performance on the Librispeech benchmark, the suggested transformer-based <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> outperforms the best hybrid result by 19% to 26% relative with a standard n-gram <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a>.</p>
</div>
<div id="S4.SS1.SSS1.p8" class="ltx_para">
<span id="S4.SS1.SSS1.p8.1" class="ltx_ERROR undefined">\Ac</span>
<p id="S4.SS1.SSS1.p8.2" class="ltx_p">TRUNet proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">63</span></a>]</cite> represents an innovative approach to end-to-end multi-channel reverberant sound source separation. The model incorporates a recurrent-U network that directly estimates multi-channel filters from input spectra, enabling the exploitation of spatial and spectro-temporal diversity in sound source separation. In Figure <a href="#S4.F7" title="Figure 7 ‣ 4.1.1 Acoustic domain ‣ 4.1 Transformer-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, the block diagram illustrates the architecture of TRUNet’s transformer. The transformer network (TNet) encompasses three variations: (i) TNet–Cat, which concatenates multi-channel spectra, treating them as a single input. This approach allows for the direct utilization of spatial information between channels. (ii) TNet–RealImag, utilizing two separate transformer stacks for real and imaginary parts, respectively. Queries and keys are computed from the multi-channel spectra. Despite this, the method may not fully exploit spatial information, such as phase differences, directly. (iii) TNet–MagPhase, analogous to TNet–RealImag, but employing spectral magnitude and spectral phase instead of real and imaginary parts. This variation proves superior in extracting spatial information from complex-valued spectra, resulting in maximum enhanced performance in sound source separation when employing TRUNet-MagPhase architecture.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2403.01255/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="356" height="108" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">An example of source separation scheme based on Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">63</span></a>]</cite>. </span></figcaption>
</figure>
<div id="S4.SS1.SSS1.p9" class="ltx_para">
<p id="S4.SS1.SSS1.p9.2" class="ltx_p">In recent times, dual-path networks have demonstrated effective results in many speech processing tasks such as speech separation and speech enhancement. In light of this, Wang Ke and colleagues incorporated the transformer into the structure of dual-path networks, presenting a time-domain speech enhancement model called the Two-stage Transformer-based Neural Network (TSTNN). This model significantly enhances the performance of speech enhancement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">74</span></a>]</cite>. Some research findings suggest that the dot-product self-attention may not be essential for transformer models. Similarly, The paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">64</span></a>]</cite> introduces D<sup id="S4.SS1.SSS1.p9.2.1" class="ltx_sup">2</sup>Net, a denoising and dereverberation network for challenging single-channel mixture speech in complex acoustic environments. D<sup id="S4.SS1.SSS1.p9.2.2" class="ltx_sup">2</sup>Net incorporates a two-branch encoder (TBE) for feature extraction and fusion, along with a global-local dual-path transformer (GLDPT) featuring local dense synthesizer attention (LDSA) to enhance local information perception.</p>
</div>
<div id="S4.SS1.SSS1.p10" class="ltx_para">
<p id="S4.SS1.SSS1.p10.1" class="ltx_p">The study proposed by gong et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">75</span></a>]</cite> explores self-attention-based neural networks like the  <a href="#Sx1.5.5.5"><span href="#Sx1.5.5.5" title="audio spectrogram transformer" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">audio spectrogram transformer</span></span></span></a> (<a href="#Sx1.5.5.5"><abbr href="#Sx1.5.5.5" title="audio spectrogram transformer" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AST</span></span></abbr></a>) for audio tasks. It introduces a self-supervised framework, improving <a href="#Sx1.5.5.5"><abbr href="#Sx1.5.5.5" title="audio spectrogram transformer" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AST</span></span></abbr></a> performance by 60.9% on various speech classification tasks such as <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, speaker recognition, and more, reducing reliance on labeled data. The approach marks a pioneering effort in audio self-supervised learning. Likewise, a novel augmented memory self-attention addresses limitations of transformer-based acoustic modeling in streaming applications has been proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">76</span></a>]</cite>, outperforming existing streamable methods by over 15% in relative error reduction on benchmark datasets.</p>
</div>
<div id="S4.SS1.SSS1.p11" class="ltx_para">
<p id="S4.SS1.SSS1.p11.1" class="ltx_p">Shareef et al. in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">58</span></a>]</cite> propose a collaborative training method for acoustic encoders in Arabic ASR systems for speech-impaired children, achieving a 10% relative accuracy improvement on phoneme alignment in the output sequence. Pioneering in recognizing impaired children’s Arabic speech. Similarly in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">77</span></a>]</cite>, collaboratively training acoustic encoders of various sizes for on-device <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> improves efficiency and reduces redundancy. Using co-distillation with an auxiliary task, collaborative training achieves up to 11% relative <a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">WER</span></span></abbr></a> improvement on LibriSpeech corpus.</p>
</div>
<div id="S4.SS1.SSS1.p12" class="ltx_para">
<p id="S4.SS1.SSS1.p12.1" class="ltx_p">Transducer models, in the context of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, map input sequences (acoustic features) to output sequences (transcriptions). Unlike traditional <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> models, transducers can handle variable-length input and output sequences more efficiently. The study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">65</span></a>]</cite> explores attention masking in transformer-transducer-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, comparing fixed masking with chunked masking in terms of accuracy and latency. The authors claim that variable masking is the viable choice in acoustic rescoring scenarios. Similarly, to adapt the Transformer for streaming ASR, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">67</span></a>]</cite> employ the Transducer framework for streamable alignments. Using a unidirectional Transformer with interleaved convolution layers for audio encoding, they model future context and gradually downsample input to reduce computation cost, while limiting history context length.</p>
</div>
<div id="S4.SS1.SSS1.p13" class="ltx_para">
<p id="S4.SS1.SSS1.p13.1" class="ltx_p">Moving on, The work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">66</span></a>]</cite> introduces an all-in-one <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> based on the Transformer architecture, combined with the <a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a> to ensure a sequential arrangement and utilize timing details. It addresses <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>,  <a href="#Sx1.6.6.6"><span href="#Sx1.6.6.6" title="audio tagging" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">audio tagging</span></span></span></a> (<a href="#Sx1.6.6.6"><abbr href="#Sx1.6.6.6" title="audio tagging" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AT</span></span></abbr></a>), and acoustic <a href="#Sx1.17.17.17"><abbr href="#Sx1.17.17.17" title="event detection" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ED</span></span></abbr></a> simultaneously. The model demonstrates superior performance, showcasing its suitability for comprehensive acoustic scene transcription.</p>
</div>
<div id="S4.SS1.SSS1.p14" class="ltx_para">
<p id="S4.SS1.SSS1.p14.1" class="ltx_p">Winata et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">56</span></a>]</cite> propose a memory-efficient Transformer architecture for end-to-end speech recognition. It significantly reduces parameters, boosting training speed by over 50% and inference time by 1.35<math id="S4.SS1.SSS1.p14.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.SSS1.p14.1.m1.1a"><mo id="S4.SS1.SSS1.p14.1.m1.1.1" xref="S4.SS1.SSS1.p14.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p14.1.m1.1b"><times id="S4.SS1.SSS1.p14.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p14.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p14.1.m1.1c">\times</annotation></semantics></math> compared to baseline. Experiments show better generalization, lower error rates, and outperformance existing schemes without external language or acoustic models. Growing demand for on-device <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems prompts interest in model compression.compression.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Language domain</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Self-attention models, such as Transformers, excel in speech recognition and reveal an important pattern. As upper self-attention layers are replaced with feed-forward layers, resembling CLDNN architecture in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">48</span></a>]</cite>, experiments on  <a href="#Sx1.53.53.53"><span href="#Sx1.53.53.53" title="wall street journal" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">wall street journal</span></span></span></a> (<a href="#Sx1.53.53.53"><abbr href="#Sx1.53.53.53" title="wall street journal" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">WSJ</span></span></abbr></a>) and  <a href="#Sx1.47.47.47"><span href="#Sx1.47.47.47" title="switchboard" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">switchboard</span></span></span></a> (<a href="#Sx1.47.47.47"><abbr href="#Sx1.47.47.47" title="switchboard" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SWBD</span></span></abbr></a>) datasets show no performance drop and minor gains. The novel proposed metric of attention matrix diagonality indicates increased diagonality in lower to upper encoder self-attention layers. The authors conclude that a global view appears unnecessary for training upper encoder layers in speech recognition Transformers when lower layers capture sufficient contextual information. The study conducted by Hrinchuk et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">49</span></a>]</cite> presents a proficient postprocessing model for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> with a Transformer-based encoder-decoder architecture, initialized with the weights of pre-trained BERT model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">36</span></a>]</cite>. The model effectively refines <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> output, demonstrating substantial performance gains through strategies like extensive data augmentation and pretrained weight initialization. On the LibriSpeech benchmark dataset, significant reductions in <a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural"><span class="ltx_text" style="font-size:80%;">WER</span>s</span></abbr></a> are observed, particularly on noisier evaluation dataset portions, outperforming baseline models and approaching the performance of Transformer-XL neural language model re-scoring with 6-gram.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2403.01255/assets/x8.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="316" height="135" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.3.2" class="ltx_text" style="font-size:90%;">Some end-to-end models: Basic CTC , RNN-Transducer, and attention architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">78</span></a>]</cite>. </span></figcaption>
</figure>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<span id="S4.SS1.SSS2.p2.1" class="ltx_ERROR undefined">\Ac</span>
<p id="S4.SS1.SSS2.p2.2" class="ltx_p">CTC is an architecture and principle commonly used in <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> tasks (Figure <a href="#S4.F8" title="Figure 8 ‣ 4.1.2 Language domain ‣ 4.1 Transformer-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>), such as <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. It enables alignment-free training by introducing a blank symbol and allowing variable-length alignments between input and output sequences. During training, the model learns to align the input sequence with the target sequence, and the blank symbol accounts for multiple possible alignments. <a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a> is particularly effective in tasks with variable-length outputs, making it well-suited for applications like speech recognition where the duration of spoken words may vary. Figure Figure <a href="#S4.F8" title="Figure 8 ‣ 4.1.2 Language domain ‣ 4.1 Transformer-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> (a) illustrates the operational principles and components of <a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a>. This latter has been used in many <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> schemes, for example, Deng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">54</span></a>]</cite> presents the innovative pretrained Transformer <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> architecture, which integrates self-supervised pretraining techniques for comprehensive end-to-end <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. Employing a hybrid <a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a>/attention model, it maximizes the potential of pretrained <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> and <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a>. The inclusion of a <a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a> branch aids in the encoder’s convergence during training and considers all potential time boundaries in beam searching. The encoder is initiated with wav2vec2.0, and the introduction of a one-cross decoder (OCD) mitigates reliance on acoustic representations, enabling initialization with pretrained DistilGPT2 and overcoming the constraint of conditioning on acoustic features.</p>
</div>
<div id="S4.SS1.SSS2.p3" class="ltx_para">
<span id="S4.SS1.SSS2.p3.1" class="ltx_ERROR undefined">\Ac</span>
<p id="S4.SS1.SSS2.p3.2" class="ltx_p">CS takes place when a speaker switches between words of two or more languages within a single sentence or across sentences. Zhou et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">55</span></a>]</cite> introduces a multi-encoder-decoder Transformer, for  <a href="#Sx1.10.10.10"><span href="#Sx1.10.10.10" title="code-switching" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">code-switching</span></span></span></a> (<a href="#Sx1.10.10.10"><abbr href="#Sx1.10.10.10" title="code-switching" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CS</span></span></abbr></a>) problem. It employs language-specific encoders and attention mechanisms to enhance acoustic representations, pre-trained on monolingual data to address limited <a href="#Sx1.10.10.10"><abbr href="#Sx1.10.10.10" title="code-switching" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CS</span></span></abbr></a> training data.
Hadwan et al. research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">69</span></a>]</cite> employ an attention-based encoder-decoder transformer, to enhance end-to-end <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> for the Arabic language, focusing on Qur’an recitation. The proposed model incorporates a multi-head attention mechanism and Mel filter bank for feature extraction. For constructing a <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a>,  <a href="#Sx1.36.36.36"><span href="#Sx1.36.36.36" title="recurrent neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">recurrent neural network</span></span></span></a> (<a href="#Sx1.36.36.36"><abbr href="#Sx1.36.36.36" title="recurrent neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RNN</span></span></abbr></a>) and  <a href="#Sx1.26.26.26"><span href="#Sx1.26.26.26" title="long short term memory" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">long short term memory</span></span></span></a> (<a href="#Sx1.26.26.26"><abbr href="#Sx1.26.26.26" title="long short term memory" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LSTM</span></span></abbr></a>) techniques were employed to train an n-gram word-based <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a>. The study introduces a new dataset, yielding <a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a> results with a low character error rate.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>TL-based ASR</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Overall, DTL consists of training a DL model on a specific domain (or task) and then transferring the acquired knowledge to a new, similar domain (or task). In what follows, we present some of the definitions that are essential to understand the principle of DTL for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> applications.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<span id="S4.SS2.p2.2" class="ltx_ERROR undefined">\Ac</span>
<p id="S4.SS2.p2.1" class="ltx_p">DTL refers to a <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> paradigm where knowledge gained from pre-training a model (Source model) on one domain or task is leveraged to enhance performance of target model, on a different but related domain or task. In this context, a "domain" refers to a specific data distribution, while a "task" represents a learning objective. <span id="S4.SS2.p2.1.1" class="ltx_ERROR undefined">\Ac</span><span id="S4.SS2.p2.1.2" class="ltx_text ltx_font_italic">DA</span> in <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a> involves adapting a model trained on a <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="D_{S}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">D</mi><mi id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">𝐷</ci><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">D_{S}</annotation></semantics></math> to perform well on a target domain. This is crucial when there are differences in data distributions between the two domains. <span id="S4.SS2.p2.1.3" class="ltx_text ltx_font_italic">Fine-tuning</span> is a technique where a pre-trained model is further trained on task-specific data to improve its performance on a related task. <span id="S4.SS2.p2.1.4" class="ltx_text ltx_font_italic">Cross-domain learning</span> extends transfer learning to scenarios where the source and target domains are distinct. <span id="S4.SS2.p2.1.5" class="ltx_text ltx_font_italic">Zero-shot learning</span> involves training a model to recognize classes not present in the training data. <span id="S4.SS2.p2.1.6" class="ltx_text ltx_font_italic">Transductive</span> <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a> focuses on adapting a model based on a specific set of target instances. <span id="S4.SS2.p2.1.7" class="ltx_text ltx_font_italic">Inductive</span> <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a> aims to generalize knowledge across domains by training a model to handle diverse tasks and domains simultaneously <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">36</span></a>, <a href="#bib.bib79" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">79</span></a>, <a href="#bib.bib80" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">80</span></a>]</cite>. These techniques contribute to the versatility and adaptability of <a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a> models in various applications. Fig. <a href="#S4.F9" title="Figure 9 ‣ 4.2 TL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> depicted the principle of <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a> techniques. Table <a href="#S4.T6" title="Table 6 ‣ 4.2.2 Language domain ‣ 4.2 TL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> summarises the most recent DTL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> techniques used in <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> and <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a> domains.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2403.01255/assets/x9.png" id="S4.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="207" height="146" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.3.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S4.F9.4.2" class="ltx_text" style="font-size:90%;">Deep transfer learning principle.</span></figcaption>
</figure>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Acoustic domain</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Schneider et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">81</span></a>]</cite> explored unsupervised pre-training for speech recognition using wav2vec model on large unlabeled audio data. The learned representations enhanced <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> training with a simple <a href="#Sx1.9.9.9"><abbr href="#Sx1.9.9.9" title="convolutional neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CNN</span></span></abbr></a> optimized through noise contrastive binary classification.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">82</span></a>]</cite>, a source filter warping data augmentation strategy is proposed to enhance the robustness of children’s speech <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. The authors constructed an end-to-end acoustic model using the XLS-R wav2vec 2.0 model, pre-trained in a self-supervised manner on extensive cross-lingual corpora of adult speech. The work proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">83</span></a>]</cite> introduces a multi-dialect acoustic model employing soft-parameter-sharing multi-task learning, a transductive DTL subcategory, within the Transformer architecture. Auxiliary cross-attentions aid dialect ID recognition, providing dialect information. Adaptive cross-entropy loss automatically balances multi-task learning. Experimental results demonstrate a significant reduction in error rates compared to various single- and multi-task models on multi-dialect speech recognition and dialect ID recognition tasks. Similarly, in the realm of computer vision, <a href="#Sx1.9.9.9"><abbr href="#Sx1.9.9.9" title="convolutional neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural"><span class="ltx_text" style="font-size:80%;">CNN</span>s</span></abbr></a> models like ConvNeXt have outperformed cutting-edge transformers, partly due to the integration of depthwise separable convolutions (DSC). DSC, which approximates regular convolutions, enhances the efficiency of <a href="#Sx1.9.9.9"><abbr href="#Sx1.9.9.9" title="convolutional neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural"><span class="ltx_text" style="font-size:80%;">CNN</span>s</span></abbr></a> in terms of time and memory usage without compromising accuracy—in some cases, even enhancing it. The study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">84</span></a>]</cite> introduces DSC into the pre-trained audio model family for audio classification on AudioSet (target task), demonstrating its advantages in balancing accuracy and model size. Xin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">85</span></a>]</cite> introduce an audio pyramid Transformer with an attention tree structure, with four branches, to reduce computational complexity in fine-grained audio spectrogram processing. It proposes a <a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a> transfer learning approach for weakly supervised sound event detection, a sub-field of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, enhancing localization performance by aligning feature distributions between frame and clip domains with a <a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a> detection loss.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Language domain</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.2" class="ltx_p">The methodology is founded on the utilization of the BERT model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">86</span></a>]</cite>, which involves pretraining language models and demonstrates improved performance across various downstream tasks.
DTL approaches for language models, specifically employed in the domain of voice recognition, are referred to as <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a> adaptation. These approaches aim to bridge the gap between the source distribution <math id="S4.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S4.SS2.SSS2.p1.1.m1.1a"><msub id="S4.SS2.SSS2.p1.1.m1.1.1" xref="S4.SS2.SSS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS2.p1.1.m1.1.1.2" xref="S4.SS2.SSS2.p1.1.m1.1.1.2.cmml">𝔻</mi><mi id="S4.SS2.SSS2.p1.1.m1.1.1.3" xref="S4.SS2.SSS2.p1.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.1.m1.1b"><apply id="S4.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.2">𝔻</ci><ci id="S4.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.1.m1.1c">\mathbb{D}_{S}</annotation></semantics></math> and the target distribution <math id="S4.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S4.SS2.SSS2.p1.2.m2.1a"><msub id="S4.SS2.SSS2.p1.2.m2.1.1" xref="S4.SS2.SSS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS2.p1.2.m2.1.1.2" xref="S4.SS2.SSS2.p1.2.m2.1.1.2.cmml">𝔻</mi><mi id="S4.SS2.SSS2.p1.2.m2.1.1.3" xref="S4.SS2.SSS2.p1.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.2.m2.1b"><apply id="S4.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1.2">𝔻</ci><ci id="S4.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS2.p1.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.2.m2.1c">\mathbb{D}_{T}</annotation></semantics></math>.
Song et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">87</span></a>]</cite> present a novel learning-to-rescore (L2RS) approach, which relies on two main components: (i) utilizing diverse textual data from <a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a> NLP models, such as BERT, and (ii) automatically determining their weights to rescore the N-best lists for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">Recent advancements in <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> models have shown promising results for training monolingual <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> systems. The <a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a> and encoder-decoder models are two popular architectures for end-to-end <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. Additionally, joint training of these architectures in a multi-task hybrid approach has been explored, demonstrating improved overall performance. For instance, the architecture illustrated in Fig. <a href="#S4.F8" title="Figure 8 ‣ 4.1.2 Language domain ‣ 4.1 Transformer-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> (a) comprises <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> layers. The encoder network of <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> consists of a series of <a href="#Sx1.36.36.36"><abbr href="#Sx1.36.36.36" title="recurrent neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural"><span class="ltx_text" style="font-size:80%;">RNN</span>s</span></abbr></a> that generate embedding vectors, while the <a href="#Sx1.36.36.36"><abbr href="#Sx1.36.36.36" title="recurrent neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RNN</span></span></abbr></a> decoder utilizes these vectors to produce final results. The <a href="#Sx1.36.36.36"><abbr href="#Sx1.36.36.36" title="recurrent neural network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RNN</span></span></abbr></a> also benefits from prior predictions (<math id="S4.SS2.SSS2.p2.1.m1.5" class="ltx_Math" alttext="P_{i},i=0,\dots,n" display="inline"><semantics id="S4.SS2.SSS2.p2.1.m1.5a"><mrow id="S4.SS2.SSS2.p2.1.m1.5.5.2" xref="S4.SS2.SSS2.p2.1.m1.5.5.3.cmml"><mrow id="S4.SS2.SSS2.p2.1.m1.4.4.1.1" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.cmml"><mrow id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.2.cmml"><msub id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.2" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.2.cmml">P</mi><mi id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.3" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.2" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.2.cmml">,</mo><mi id="S4.SS2.SSS2.p2.1.m1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.cmml">i</mi></mrow><mo id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.2" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.2.cmml">=</mo><mn id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.3" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.3.cmml">0</mn></mrow><mo id="S4.SS2.SSS2.p2.1.m1.5.5.2.3" xref="S4.SS2.SSS2.p2.1.m1.5.5.3a.cmml">,</mo><mrow id="S4.SS2.SSS2.p2.1.m1.5.5.2.2.2" xref="S4.SS2.SSS2.p2.1.m1.5.5.2.2.1.cmml"><mi mathvariant="normal" id="S4.SS2.SSS2.p2.1.m1.2.2" xref="S4.SS2.SSS2.p2.1.m1.2.2.cmml">…</mi><mo id="S4.SS2.SSS2.p2.1.m1.5.5.2.2.2.1" xref="S4.SS2.SSS2.p2.1.m1.5.5.2.2.1.cmml">,</mo><mi id="S4.SS2.SSS2.p2.1.m1.3.3" xref="S4.SS2.SSS2.p2.1.m1.3.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.1.m1.5b"><apply id="S4.SS2.SSS2.p2.1.m1.5.5.3.cmml" xref="S4.SS2.SSS2.p2.1.m1.5.5.2"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p2.1.m1.5.5.3a.cmml" xref="S4.SS2.SSS2.p2.1.m1.5.5.2.3">formulae-sequence</csymbol><apply id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1"><eq id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.2"></eq><list id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1"><apply id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.2">𝑃</ci><ci id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.1.1.1.3">𝑖</ci></apply><ci id="S4.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1">𝑖</ci></list><cn type="integer" id="S4.SS2.SSS2.p2.1.m1.4.4.1.1.3.cmml" xref="S4.SS2.SSS2.p2.1.m1.4.4.1.1.3">0</cn></apply><list id="S4.SS2.SSS2.p2.1.m1.5.5.2.2.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.5.5.2.2.2"><ci id="S4.SS2.SSS2.p2.1.m1.2.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.2.2">…</ci><ci id="S4.SS2.SSS2.p2.1.m1.3.3.cmml" xref="S4.SS2.SSS2.p2.1.m1.3.3">𝑛</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.1.m1.5c">P_{i},i=0,\dots,n</annotation></semantics></math>), enhancing the accuracy of subsequent predictions. Moving on, a novel TL-based approach that enhances end-to-end speech recognition has been proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">88</span></a>]</cite>.
The novelty lies in applying <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a> through multilingual training and multi-task learning at two levels. The initial stage utilizes nonnegative matrix factorization (NMF), instead of a bottleneck layer, and multilingual training for high-level feature extraction. The subsequent stage employs joint CTC-attention models on these features, where the CTC was transferred to the target attention-based model. The scheme demonstrated superior performance on TIMIT but requires testing on high-resource data. Further optimization is needed for standard end-to-end training. In addition, Integrating both <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a> and <a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a> methodologies has the potential to enhance or construct an effective DTL-based ASR model, as demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">46</span></a>, <a href="#bib.bib89" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">89</span></a>, <a href="#bib.bib90" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">90</span></a>, <a href="#bib.bib91" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">91</span></a>, <a href="#bib.bib92" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">92</span></a>, <a href="#bib.bib93" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">93</span></a>]</cite>.</p>
</div>
<figure id="S4.T6" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.11.3.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.4.2" class="ltx_text" style="font-size:90%;">In contemporary cutting-edge frameworks, diverse pre-trained models are utilized for distinct tasks within the field. These frameworks employ different DTL approaches and assess their efficacy using specific metrics. The symbol (<math id="S4.T6.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T6.3.1.m1.1b"><mo stretchy="false" id="S4.T6.3.1.m1.1.1" xref="S4.T6.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.3.1.m1.1c"><ci id="S4.T6.3.1.m1.1.1.cmml" xref="S4.T6.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.1.m1.1d">\uparrow</annotation></semantics></math>) result increase, whereas (<math id="S4.T6.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.4.2.m2.1b"><mo stretchy="false" id="S4.T6.4.2.m2.1.1" xref="S4.T6.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.4.2.m2.1c"><ci id="S4.T6.4.2.m2.1.1.cmml" xref="S4.T6.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.2.m2.1d">\downarrow</annotation></semantics></math>) signifies result decrease. In cases where multiple scenarios are examined, only the top-performing outcome is mentioned.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S4.T6.9" class="ltx_tabular ltx_figure_panel ltx_align_middle">
<tr id="S4.T6.5.1" class="ltx_tr">
<td id="S4.T6.5.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.5.1.2.1" class="ltx_text" style="font-size:70%;">Scheme</span></td>
<td id="S4.T6.5.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.5.1.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.5.1.3.1.1.1" class="ltx_text" style="font-size:70%;">Based on</span></span>
</span>
</td>
<td id="S4.T6.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.5.1.1.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.5.1.1.1.1.1" class="ltx_text" style="font-size:70%;">Speech recognition task (</span><math id="S4.T6.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S4.T6.5.1.1.1.1.m1.1a"><msub id="S4.T6.5.1.1.1.1.m1.1.1" xref="S4.T6.5.1.1.1.1.m1.1.1.cmml"><mi mathsize="70%" id="S4.T6.5.1.1.1.1.m1.1.1.2" xref="S4.T6.5.1.1.1.1.m1.1.1.2.cmml">𝕋</mi><mi mathsize="70%" id="S4.T6.5.1.1.1.1.m1.1.1.3" xref="S4.T6.5.1.1.1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T6.5.1.1.1.1.m1.1b"><apply id="S4.T6.5.1.1.1.1.m1.1.1.cmml" xref="S4.T6.5.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.5.1.1.1.1.m1.1.1.1.cmml" xref="S4.T6.5.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T6.5.1.1.1.1.m1.1.1.2.cmml" xref="S4.T6.5.1.1.1.1.m1.1.1.2">𝕋</ci><ci id="S4.T6.5.1.1.1.1.m1.1.1.3.cmml" xref="S4.T6.5.1.1.1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.5.1.1.1.1.m1.1c">\mathbb{T}_{T}</annotation></semantics></math><span id="S4.T6.5.1.1.1.1.2" class="ltx_text" style="font-size:70%;">)</span></span>
</span>
</td>
<td id="S4.T6.5.1.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.5.1.4.1" class="ltx_text" style="font-size:70%;">AM/LM</span></td>
<td id="S4.T6.5.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.5.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.5.1.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.5.1.5.1.1.1" class="ltx_text" style="font-size:70%;">Adaptation</span></span>
</span>
</td>
<td id="S4.T6.5.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.5.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.5.1.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.5.1.6.1.1.1" class="ltx_text" style="font-size:70%;">Result with metric</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.6" class="ltx_tr">
<td id="S4.T6.9.6.1" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.6.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib84" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">84</span></a><span id="S4.T6.9.6.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.9.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.6.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.6.2.1.1.1" class="ltx_text" style="font-size:70%;">ConvNeXt-Tiny</span></span>
</span>
</td>
<td id="S4.T6.9.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.9.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.6.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.6.3.1.1.1" class="ltx_text" style="font-size:70%;">Audio classification</span></span>
</span>
</td>
<td id="S4.T6.9.6.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.9.6.4.1" class="ltx_text" style="font-size:70%;">AM</span></td>
<td id="S4.T6.9.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.9.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.6.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.6.5.1.1.1" class="ltx_text" style="font-size:70%;">DA</span></span>
</span>
</td>
<td id="S4.T6.9.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T6.9.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.6.6.1.1" class="ltx_p" style="width:79.7pt;"><a href="#Sx1.27.27.27"><abbr href="#Sx1.27.27.27" title="mean average precision" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">mAP</span></span></abbr></a><span id="S4.T6.9.6.6.1.1.1" class="ltx_text" style="font-size:70%;">= 0.471</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.7" class="ltx_tr">
<td id="S4.T6.9.7.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.7.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib85" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">85</span></a><span id="S4.T6.9.7.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.7.2.1.1" class="ltx_p" style="width:71.1pt;"><a href="#Sx1.3.3.3"><abbr href="#Sx1.3.3.3" title="audio pyramid transformer" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">APT</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T6.9.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.7.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.7.3.1.1.1" class="ltx_text" style="font-size:70%;">Sound event detection</span></span>
</span>
</td>
<td id="S4.T6.9.7.4" class="ltx_td ltx_align_left"><span id="S4.T6.9.7.4.1" class="ltx_text" style="font-size:70%;">AM</span></td>
<td id="S4.T6.9.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.7.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.7.5.1.1.1" class="ltx_text" style="font-size:70%;">DA</span></span>
</span>
</td>
<td id="S4.T6.9.7.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.7.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.9.7.6.1.1.1" class="ltx_text" style="font-size:70%;">F1= 79.6%</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.8" class="ltx_tr">
<td id="S4.T6.9.8.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.8.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">49</span></a><span id="S4.T6.9.8.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.8.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.8.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.8.2.1.1.1" class="ltx_text" style="font-size:70%;">BERT (Jasper)</span></span>
</span>
</td>
<td id="S4.T6.9.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.8.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.8.3.1.1.1" class="ltx_text" style="font-size:70%;">Speech-to-text</span></span>
</span>
</td>
<td id="S4.T6.9.8.4" class="ltx_td ltx_align_left"><span id="S4.T6.9.8.4.1" class="ltx_text" style="font-size:70%;">LM</span></td>
<td id="S4.T6.9.8.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.8.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.8.5.1.1.1" class="ltx_text" style="font-size:70%;">TL</span></span>
</span>
</td>
<td id="S4.T6.9.8.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.8.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.9.8.6.1.1.1" class="ltx_text" style="font-size:70%;">WER= 14%</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.9" class="ltx_tr">
<td id="S4.T6.9.9.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.9.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">54</span></a><span id="S4.T6.9.9.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.9.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.9.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.9.2.1.1.1" class="ltx_text" style="font-size:70%;">DistilGPT2</span></span>
</span>
</td>
<td id="S4.T6.9.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.9.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.9.3.1.1.1" class="ltx_text" style="font-size:70%;">Improve ASR</span></span>
</span>
</td>
<td id="S4.T6.9.9.4" class="ltx_td ltx_align_left"><span id="S4.T6.9.9.4.1" class="ltx_text" style="font-size:70%;">Both</span></td>
<td id="S4.T6.9.9.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.9.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.9.5.1.1.1" class="ltx_text" style="font-size:70%;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T6.9.9.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.9.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.9.9.6.1.1.1" class="ltx_text" style="font-size:70%;">CER= 4.6%</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.6.2" class="ltx_tr">
<td id="S4.T6.6.2.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.6.2.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib93" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">93</span></a><span id="S4.T6.6.2.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.6.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.6.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.6.2.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.6.2.3.1.1.1" class="ltx_text" style="font-size:70%;">XLRS Wave2vec</span></span>
</span>
</td>
<td id="S4.T6.6.2.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.6.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.6.2.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.6.2.4.1.1.1" class="ltx_text" style="font-size:70%;">Improve ASR in low resource language</span></span>
</span>
</td>
<td id="S4.T6.6.2.5" class="ltx_td ltx_align_left"><span id="S4.T6.6.2.5.1" class="ltx_text" style="font-size:70%;">Both</span></td>
<td id="S4.T6.6.2.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.6.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.6.2.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.6.2.6.1.1.1" class="ltx_text" style="font-size:70%;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T6.6.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.6.2.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.6.2.1.1.1.1" class="ltx_text" style="font-size:70%;">5.6% WER </span><math id="S4.T6.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.6.2.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T6.6.2.1.1.1.m1.1.1" xref="S4.T6.6.2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.6.2.1.1.1.m1.1b"><ci id="S4.T6.6.2.1.1.1.m1.1.1.cmml" xref="S4.T6.6.2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.6.2.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.10" class="ltx_tr">
<td id="S4.T6.9.10.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.10.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib82" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">82</span></a><span id="S4.T6.9.10.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.10.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.10.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.10.2.1.1.1" class="ltx_text" style="font-size:70%;">XLRS Wave2vec</span></span>
</span>
</td>
<td id="S4.T6.9.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.10.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.10.3.1.1.1" class="ltx_text" style="font-size:70%;">Improve ASR for children’s speech</span></span>
</span>
</td>
<td id="S4.T6.9.10.4" class="ltx_td ltx_align_left"><span id="S4.T6.9.10.4.1" class="ltx_text" style="font-size:70%;">AM</span></td>
<td id="S4.T6.9.10.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.10.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.10.5.1.1.1" class="ltx_text" style="font-size:70%;">TL</span></span>
</span>
</td>
<td id="S4.T6.9.10.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.10.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.9.10.6.1.1.1" class="ltx_text" style="font-size:70%;">WER = 4.86%</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.7.3" class="ltx_tr">
<td id="S4.T6.7.3.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.7.3.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib90" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">90</span></a><span id="S4.T6.7.3.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.7.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.7.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.7.3.3.1.1" class="ltx_p" style="width:71.1pt;"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T6.7.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.7.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.7.3.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.7.3.4.1.1.1" class="ltx_text" style="font-size:70%;">Speaker adaptation</span></span>
</span>
</td>
<td id="S4.T6.7.3.5" class="ltx_td ltx_align_left"><span id="S4.T6.7.3.5.1" class="ltx_text" style="font-size:70%;">Both</span></td>
<td id="S4.T6.7.3.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.7.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.7.3.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.7.3.6.1.1.1" class="ltx_text" style="font-size:70%;">Features norm.</span></span>
</span>
</td>
<td id="S4.T6.7.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.7.3.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.7.3.1.1.1.1" class="ltx_text" style="font-size:70%;">25.0% WER</span><math id="S4.T6.7.3.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.7.3.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T6.7.3.1.1.1.m1.1.1" xref="S4.T6.7.3.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.7.3.1.1.1.m1.1b"><ci id="S4.T6.7.3.1.1.1.m1.1.1.cmml" xref="S4.T6.7.3.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.7.3.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.11" class="ltx_tr">
<td id="S4.T6.9.11.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.11.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib83" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">83</span></a><span id="S4.T6.9.11.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.11.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.11.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.11.2.1.1.1" class="ltx_text" style="font-size:70%;">Transformer</span></span>
</span>
</td>
<td id="S4.T6.9.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.11.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.11.3.1.1.1" class="ltx_text" style="font-size:70%;">Multi-dialect model aids recognizing diverse speech dialects effectively</span></span>
</span>
</td>
<td id="S4.T6.9.11.4" class="ltx_td ltx_align_left"><span id="S4.T6.9.11.4.1" class="ltx_text" style="font-size:70%;">AM</span></td>
<td id="S4.T6.9.11.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.11.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.11.5.1.1.1" class="ltx_text" style="font-size:70%;">Multi-task learning</span></span>
</span>
</td>
<td id="S4.T6.9.11.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.11.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.9.11.6.1.1.1" class="ltx_text" style="font-size:70%;">Acc= 100%</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.8.4" class="ltx_tr">
<td id="S4.T6.8.4.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.8.4.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib94" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">94</span></a><span id="S4.T6.8.4.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.8.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.8.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.8.4.3.1.1" class="ltx_p" style="width:71.1pt;"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T6.8.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.8.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.8.4.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.8.4.4.1.1.1" class="ltx_text" style="font-size:70%;">Enhancing the existing multilingual </span><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a><span id="S4.T6.8.4.4.1.1.2" class="ltx_text" style="font-size:70%;"> model.</span></span>
</span>
</td>
<td id="S4.T6.8.4.5" class="ltx_td ltx_align_left"><span id="S4.T6.8.4.5.1" class="ltx_text" style="font-size:70%;">LM</span></td>
<td id="S4.T6.8.4.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.8.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.8.4.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.8.4.6.1.1.1" class="ltx_text" style="font-size:70%;">DTL</span></span>
</span>
</td>
<td id="S4.T6.8.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.8.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.8.4.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.8.4.1.1.1.1" class="ltx_text" style="font-size:70%;">4%CER </span><math id="S4.T6.8.4.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.8.4.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T6.8.4.1.1.1.m1.1.1" xref="S4.T6.8.4.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.8.4.1.1.1.m1.1b"><ci id="S4.T6.8.4.1.1.1.m1.1.1.cmml" xref="S4.T6.8.4.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.8.4.1.1.1.m1.1c">\downarrow</annotation></semantics></math><span id="S4.T6.8.4.1.1.1.2" class="ltx_text" style="font-size:70%;"> 6% WER</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.12" class="ltx_tr">
<td id="S4.T6.9.12.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.12.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib95" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">95</span></a><span id="S4.T6.9.12.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.12.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.12.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.12.2.1.1.1" class="ltx_text" style="font-size:70%;">PaSST</span></span>
</span>
</td>
<td id="S4.T6.9.12.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.12.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.12.3.1.1.1" class="ltx_text" style="font-size:70%;">Audio tagging and event detection</span></span>
</span>
</td>
<td id="S4.T6.9.12.4" class="ltx_td ltx_align_left"><span id="S4.T6.9.12.4.1" class="ltx_text" style="font-size:70%;">AM</span></td>
<td id="S4.T6.9.12.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.12.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.12.5.1.1.1" class="ltx_text" style="font-size:70%;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T6.9.12.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.12.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.9.12.6.1.1.1" class="ltx_text" style="font-size:70%;">F1= 64.85%</span></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.5" class="ltx_tr">
<td id="S4.T6.9.5.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.5.2.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib81" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">81</span></a><span id="S4.T6.9.5.2.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.5.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.5.3.1.1.1" class="ltx_text" style="font-size:70%;">Wav2vec</span></span>
</span>
</td>
<td id="S4.T6.9.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.5.4.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.5.4.1.1.1" class="ltx_text" style="font-size:70%;">WSJ data speech</span></span>
</span>
</td>
<td id="S4.T6.9.5.5" class="ltx_td ltx_align_left"><span id="S4.T6.9.5.5.1" class="ltx_text" style="font-size:70%;">AM</span></td>
<td id="S4.T6.9.5.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.5.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.5.6.1.1.1" class="ltx_text" style="font-size:70%;">affine transform.</span></span>
</span>
</td>
<td id="S4.T6.9.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T6.9.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.5.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.9.5.1.1.1.1" class="ltx_text" style="font-size:70%;">36% WER</span><math id="S4.T6.9.5.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.9.5.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S4.T6.9.5.1.1.1.m1.1.1" xref="S4.T6.9.5.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.9.5.1.1.1.m1.1b"><ci id="S4.T6.9.5.1.1.1.m1.1.1.cmml" xref="S4.T6.9.5.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.9.5.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T6.9.13" class="ltx_tr">
<td id="S4.T6.9.13.1" class="ltx_td ltx_align_left ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T6.9.13.1.1.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib96" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">96</span></a><span id="S4.T6.9.13.1.2.2" class="ltx_text" style="font-size:70%;">]</span></cite></td>
<td id="S4.T6.9.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T6.9.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.13.2.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.13.2.1.1.1" class="ltx_text" style="font-size:70%;">ARoBERT</span></span>
</span>
</td>
<td id="S4.T6.9.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T6.9.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.13.3.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T6.9.13.3.1.1.1" class="ltx_text" style="font-size:70%;">Spoken language understanding</span></span>
</span>
</td>
<td id="S4.T6.9.13.4" class="ltx_td ltx_align_left ltx_border_b"><span id="S4.T6.9.13.4.1" class="ltx_text" style="font-size:70%;">LM</span></td>
<td id="S4.T6.9.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T6.9.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.13.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T6.9.13.5.1.1.1" class="ltx_text" style="font-size:70%;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T6.9.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T6.9.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T6.9.13.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T6.9.13.6.1.1.1" class="ltx_text" style="font-size:70%;">F1-score=92.56%</span></span>
</span>
</td>
</tr>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.T6.12" class="ltx_p ltx_figure_panel ltx_align_left"><span id="S4.T6.12.1" class="ltx_text" style="font-size:70%;">Abbreviations: Transformer (T)</span></p>
</div>
</div>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>FL-based ASR</h3>

<div id="S4.SS3.p1" class="ltx_para">
<span id="S4.SS3.p1.1" class="ltx_ERROR undefined">\Ac</span>
<p id="S4.SS3.p1.2" class="ltx_p">FL revolutionizes AI model training by enabling collaboration without the need to share sensitive training data. Traditional centralized approaches are evolving towards decentralized models, where <a href="#Sx1.30.30.30"><abbr href="#Sx1.30.30.30" title="machine learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ML</span></span></abbr></a> algorithms are trained collaboratively on edge devices like mobile phones, laptops, or private servers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">97</span></a>]</cite>. The mathematical formulation of FL focuses on training a single global model across multiple devices or nodes (clients) while keeping the data localized. The objective is to minimize a global loss function that is typically the weighted sum of the local loss functions on all clients. The standard <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a> problem can be formulated as:</p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E3.m1.2" class="ltx_Math" alttext="\min_{\theta}F(\theta)=\min_{\theta}\sum_{k=1}^{K}\frac{n_{k}}{N}F_{k}(\theta)" display="block"><semantics id="S4.E3.m1.2a"><mrow id="S4.E3.m1.2.3" xref="S4.E3.m1.2.3.cmml"><mrow id="S4.E3.m1.2.3.2" xref="S4.E3.m1.2.3.2.cmml"><mrow id="S4.E3.m1.2.3.2.2" xref="S4.E3.m1.2.3.2.2.cmml"><munder id="S4.E3.m1.2.3.2.2.1" xref="S4.E3.m1.2.3.2.2.1.cmml"><mi id="S4.E3.m1.2.3.2.2.1.2" xref="S4.E3.m1.2.3.2.2.1.2.cmml">min</mi><mi id="S4.E3.m1.2.3.2.2.1.3" xref="S4.E3.m1.2.3.2.2.1.3.cmml">θ</mi></munder><mo lspace="0.167em" id="S4.E3.m1.2.3.2.2a" xref="S4.E3.m1.2.3.2.2.cmml">⁡</mo><mi id="S4.E3.m1.2.3.2.2.2" xref="S4.E3.m1.2.3.2.2.2.cmml">F</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.3.2.1" xref="S4.E3.m1.2.3.2.1.cmml">​</mo><mrow id="S4.E3.m1.2.3.2.3.2" xref="S4.E3.m1.2.3.2.cmml"><mo stretchy="false" id="S4.E3.m1.2.3.2.3.2.1" xref="S4.E3.m1.2.3.2.cmml">(</mo><mi id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml">θ</mi><mo stretchy="false" id="S4.E3.m1.2.3.2.3.2.2" xref="S4.E3.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S4.E3.m1.2.3.1" xref="S4.E3.m1.2.3.1.cmml">=</mo><mrow id="S4.E3.m1.2.3.3" xref="S4.E3.m1.2.3.3.cmml"><munder id="S4.E3.m1.2.3.3.2" xref="S4.E3.m1.2.3.3.2.cmml"><mi id="S4.E3.m1.2.3.3.2.2" xref="S4.E3.m1.2.3.3.2.2.cmml">min</mi><mi id="S4.E3.m1.2.3.3.2.3" xref="S4.E3.m1.2.3.3.2.3.cmml">θ</mi></munder><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.3.3.1" xref="S4.E3.m1.2.3.3.1.cmml">​</mo><mrow id="S4.E3.m1.2.3.3.3" xref="S4.E3.m1.2.3.3.3.cmml"><munderover id="S4.E3.m1.2.3.3.3.1" xref="S4.E3.m1.2.3.3.3.1.cmml"><mo movablelimits="false" id="S4.E3.m1.2.3.3.3.1.2.2" xref="S4.E3.m1.2.3.3.3.1.2.2.cmml">∑</mo><mrow id="S4.E3.m1.2.3.3.3.1.2.3" xref="S4.E3.m1.2.3.3.3.1.2.3.cmml"><mi id="S4.E3.m1.2.3.3.3.1.2.3.2" xref="S4.E3.m1.2.3.3.3.1.2.3.2.cmml">k</mi><mo id="S4.E3.m1.2.3.3.3.1.2.3.1" xref="S4.E3.m1.2.3.3.3.1.2.3.1.cmml">=</mo><mn id="S4.E3.m1.2.3.3.3.1.2.3.3" xref="S4.E3.m1.2.3.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E3.m1.2.3.3.3.1.3" xref="S4.E3.m1.2.3.3.3.1.3.cmml">K</mi></munderover><mrow id="S4.E3.m1.2.3.3.3.2" xref="S4.E3.m1.2.3.3.3.2.cmml"><mfrac id="S4.E3.m1.2.3.3.3.2.2" xref="S4.E3.m1.2.3.3.3.2.2.cmml"><msub id="S4.E3.m1.2.3.3.3.2.2.2" xref="S4.E3.m1.2.3.3.3.2.2.2.cmml"><mi id="S4.E3.m1.2.3.3.3.2.2.2.2" xref="S4.E3.m1.2.3.3.3.2.2.2.2.cmml">n</mi><mi id="S4.E3.m1.2.3.3.3.2.2.2.3" xref="S4.E3.m1.2.3.3.3.2.2.2.3.cmml">k</mi></msub><mi id="S4.E3.m1.2.3.3.3.2.2.3" xref="S4.E3.m1.2.3.3.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.3.3.3.2.1" xref="S4.E3.m1.2.3.3.3.2.1.cmml">​</mo><msub id="S4.E3.m1.2.3.3.3.2.3" xref="S4.E3.m1.2.3.3.3.2.3.cmml"><mi id="S4.E3.m1.2.3.3.3.2.3.2" xref="S4.E3.m1.2.3.3.3.2.3.2.cmml">F</mi><mi id="S4.E3.m1.2.3.3.3.2.3.3" xref="S4.E3.m1.2.3.3.3.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.3.3.3.2.1a" xref="S4.E3.m1.2.3.3.3.2.1.cmml">​</mo><mrow id="S4.E3.m1.2.3.3.3.2.4.2" xref="S4.E3.m1.2.3.3.3.2.cmml"><mo stretchy="false" id="S4.E3.m1.2.3.3.3.2.4.2.1" xref="S4.E3.m1.2.3.3.3.2.cmml">(</mo><mi id="S4.E3.m1.2.2" xref="S4.E3.m1.2.2.cmml">θ</mi><mo stretchy="false" id="S4.E3.m1.2.3.3.3.2.4.2.2" xref="S4.E3.m1.2.3.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.2b"><apply id="S4.E3.m1.2.3.cmml" xref="S4.E3.m1.2.3"><eq id="S4.E3.m1.2.3.1.cmml" xref="S4.E3.m1.2.3.1"></eq><apply id="S4.E3.m1.2.3.2.cmml" xref="S4.E3.m1.2.3.2"><times id="S4.E3.m1.2.3.2.1.cmml" xref="S4.E3.m1.2.3.2.1"></times><apply id="S4.E3.m1.2.3.2.2.cmml" xref="S4.E3.m1.2.3.2.2"><apply id="S4.E3.m1.2.3.2.2.1.cmml" xref="S4.E3.m1.2.3.2.2.1"><csymbol cd="ambiguous" id="S4.E3.m1.2.3.2.2.1.1.cmml" xref="S4.E3.m1.2.3.2.2.1">subscript</csymbol><min id="S4.E3.m1.2.3.2.2.1.2.cmml" xref="S4.E3.m1.2.3.2.2.1.2"></min><ci id="S4.E3.m1.2.3.2.2.1.3.cmml" xref="S4.E3.m1.2.3.2.2.1.3">𝜃</ci></apply><ci id="S4.E3.m1.2.3.2.2.2.cmml" xref="S4.E3.m1.2.3.2.2.2">𝐹</ci></apply><ci id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1">𝜃</ci></apply><apply id="S4.E3.m1.2.3.3.cmml" xref="S4.E3.m1.2.3.3"><times id="S4.E3.m1.2.3.3.1.cmml" xref="S4.E3.m1.2.3.3.1"></times><apply id="S4.E3.m1.2.3.3.2.cmml" xref="S4.E3.m1.2.3.3.2"><csymbol cd="ambiguous" id="S4.E3.m1.2.3.3.2.1.cmml" xref="S4.E3.m1.2.3.3.2">subscript</csymbol><min id="S4.E3.m1.2.3.3.2.2.cmml" xref="S4.E3.m1.2.3.3.2.2"></min><ci id="S4.E3.m1.2.3.3.2.3.cmml" xref="S4.E3.m1.2.3.3.2.3">𝜃</ci></apply><apply id="S4.E3.m1.2.3.3.3.cmml" xref="S4.E3.m1.2.3.3.3"><apply id="S4.E3.m1.2.3.3.3.1.cmml" xref="S4.E3.m1.2.3.3.3.1"><csymbol cd="ambiguous" id="S4.E3.m1.2.3.3.3.1.1.cmml" xref="S4.E3.m1.2.3.3.3.1">superscript</csymbol><apply id="S4.E3.m1.2.3.3.3.1.2.cmml" xref="S4.E3.m1.2.3.3.3.1"><csymbol cd="ambiguous" id="S4.E3.m1.2.3.3.3.1.2.1.cmml" xref="S4.E3.m1.2.3.3.3.1">subscript</csymbol><sum id="S4.E3.m1.2.3.3.3.1.2.2.cmml" xref="S4.E3.m1.2.3.3.3.1.2.2"></sum><apply id="S4.E3.m1.2.3.3.3.1.2.3.cmml" xref="S4.E3.m1.2.3.3.3.1.2.3"><eq id="S4.E3.m1.2.3.3.3.1.2.3.1.cmml" xref="S4.E3.m1.2.3.3.3.1.2.3.1"></eq><ci id="S4.E3.m1.2.3.3.3.1.2.3.2.cmml" xref="S4.E3.m1.2.3.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S4.E3.m1.2.3.3.3.1.2.3.3.cmml" xref="S4.E3.m1.2.3.3.3.1.2.3.3">1</cn></apply></apply><ci id="S4.E3.m1.2.3.3.3.1.3.cmml" xref="S4.E3.m1.2.3.3.3.1.3">𝐾</ci></apply><apply id="S4.E3.m1.2.3.3.3.2.cmml" xref="S4.E3.m1.2.3.3.3.2"><times id="S4.E3.m1.2.3.3.3.2.1.cmml" xref="S4.E3.m1.2.3.3.3.2.1"></times><apply id="S4.E3.m1.2.3.3.3.2.2.cmml" xref="S4.E3.m1.2.3.3.3.2.2"><divide id="S4.E3.m1.2.3.3.3.2.2.1.cmml" xref="S4.E3.m1.2.3.3.3.2.2"></divide><apply id="S4.E3.m1.2.3.3.3.2.2.2.cmml" xref="S4.E3.m1.2.3.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.E3.m1.2.3.3.3.2.2.2.1.cmml" xref="S4.E3.m1.2.3.3.3.2.2.2">subscript</csymbol><ci id="S4.E3.m1.2.3.3.3.2.2.2.2.cmml" xref="S4.E3.m1.2.3.3.3.2.2.2.2">𝑛</ci><ci id="S4.E3.m1.2.3.3.3.2.2.2.3.cmml" xref="S4.E3.m1.2.3.3.3.2.2.2.3">𝑘</ci></apply><ci id="S4.E3.m1.2.3.3.3.2.2.3.cmml" xref="S4.E3.m1.2.3.3.3.2.2.3">𝑁</ci></apply><apply id="S4.E3.m1.2.3.3.3.2.3.cmml" xref="S4.E3.m1.2.3.3.3.2.3"><csymbol cd="ambiguous" id="S4.E3.m1.2.3.3.3.2.3.1.cmml" xref="S4.E3.m1.2.3.3.3.2.3">subscript</csymbol><ci id="S4.E3.m1.2.3.3.3.2.3.2.cmml" xref="S4.E3.m1.2.3.3.3.2.3.2">𝐹</ci><ci id="S4.E3.m1.2.3.3.3.2.3.3.cmml" xref="S4.E3.m1.2.3.3.3.2.3.3">𝑘</ci></apply><ci id="S4.E3.m1.2.2.cmml" xref="S4.E3.m1.2.2">𝜃</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.2c">\min_{\theta}F(\theta)=\min_{\theta}\sum_{k=1}^{K}\frac{n_{k}}{N}F_{k}(\theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.9" class="ltx_p">In this context, <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\theta</annotation></semantics></math> denotes the parameters of the global model to be learned, <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">K</annotation></semantics></math> represents the total number of clients, <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="n_{k}" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><msub id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">n</mi><mi id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">𝑛</ci><ci id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">n_{k}</annotation></semantics></math> signifies the number of data samples at client <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mi id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><ci id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">k</annotation></semantics></math>, <math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="N=\sum_{k=1}^{K}n_{k}" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mrow id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mi id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">N</mi><mo rspace="0.111em" id="S4.SS3.p2.5.m5.1.1.1" xref="S4.SS3.p2.5.m5.1.1.1.cmml">=</mo><mrow id="S4.SS3.p2.5.m5.1.1.3" xref="S4.SS3.p2.5.m5.1.1.3.cmml"><msubsup id="S4.SS3.p2.5.m5.1.1.3.1" xref="S4.SS3.p2.5.m5.1.1.3.1.cmml"><mo id="S4.SS3.p2.5.m5.1.1.3.1.2.2" xref="S4.SS3.p2.5.m5.1.1.3.1.2.2.cmml">∑</mo><mrow id="S4.SS3.p2.5.m5.1.1.3.1.2.3" xref="S4.SS3.p2.5.m5.1.1.3.1.2.3.cmml"><mi id="S4.SS3.p2.5.m5.1.1.3.1.2.3.2" xref="S4.SS3.p2.5.m5.1.1.3.1.2.3.2.cmml">k</mi><mo id="S4.SS3.p2.5.m5.1.1.3.1.2.3.1" xref="S4.SS3.p2.5.m5.1.1.3.1.2.3.1.cmml">=</mo><mn id="S4.SS3.p2.5.m5.1.1.3.1.2.3.3" xref="S4.SS3.p2.5.m5.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S4.SS3.p2.5.m5.1.1.3.1.3" xref="S4.SS3.p2.5.m5.1.1.3.1.3.cmml">K</mi></msubsup><msub id="S4.SS3.p2.5.m5.1.1.3.2" xref="S4.SS3.p2.5.m5.1.1.3.2.cmml"><mi id="S4.SS3.p2.5.m5.1.1.3.2.2" xref="S4.SS3.p2.5.m5.1.1.3.2.2.cmml">n</mi><mi id="S4.SS3.p2.5.m5.1.1.3.2.3" xref="S4.SS3.p2.5.m5.1.1.3.2.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><eq id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1.1"></eq><ci id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">𝑁</ci><apply id="S4.SS3.p2.5.m5.1.1.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3"><apply id="S4.SS3.p2.5.m5.1.1.3.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.1.1.3.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1">superscript</csymbol><apply id="S4.SS3.p2.5.m5.1.1.3.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.1.1.3.1.2.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1">subscript</csymbol><sum id="S4.SS3.p2.5.m5.1.1.3.1.2.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1.2.2"></sum><apply id="S4.SS3.p2.5.m5.1.1.3.1.2.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1.2.3"><eq id="S4.SS3.p2.5.m5.1.1.3.1.2.3.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1.2.3.1"></eq><ci id="S4.SS3.p2.5.m5.1.1.3.1.2.3.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="S4.SS3.p2.5.m5.1.1.3.1.2.3.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S4.SS3.p2.5.m5.1.1.3.1.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3.1.3">𝐾</ci></apply><apply id="S4.SS3.p2.5.m5.1.1.3.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS3.p2.5.m5.1.1.3.2.1.cmml" xref="S4.SS3.p2.5.m5.1.1.3.2">subscript</csymbol><ci id="S4.SS3.p2.5.m5.1.1.3.2.2.cmml" xref="S4.SS3.p2.5.m5.1.1.3.2.2">𝑛</ci><ci id="S4.SS3.p2.5.m5.1.1.3.2.3.cmml" xref="S4.SS3.p2.5.m5.1.1.3.2.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">N=\sum_{k=1}^{K}n_{k}</annotation></semantics></math> stands for the total number of data samples across all clients, and <math id="S4.SS3.p2.6.m6.1" class="ltx_Math" alttext="F_{k}(\theta)" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mrow id="S4.SS3.p2.6.m6.1.2" xref="S4.SS3.p2.6.m6.1.2.cmml"><msub id="S4.SS3.p2.6.m6.1.2.2" xref="S4.SS3.p2.6.m6.1.2.2.cmml"><mi id="S4.SS3.p2.6.m6.1.2.2.2" xref="S4.SS3.p2.6.m6.1.2.2.2.cmml">F</mi><mi id="S4.SS3.p2.6.m6.1.2.2.3" xref="S4.SS3.p2.6.m6.1.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p2.6.m6.1.2.1" xref="S4.SS3.p2.6.m6.1.2.1.cmml">​</mo><mrow id="S4.SS3.p2.6.m6.1.2.3.2" xref="S4.SS3.p2.6.m6.1.2.cmml"><mo stretchy="false" id="S4.SS3.p2.6.m6.1.2.3.2.1" xref="S4.SS3.p2.6.m6.1.2.cmml">(</mo><mi id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml">θ</mi><mo stretchy="false" id="S4.SS3.p2.6.m6.1.2.3.2.2" xref="S4.SS3.p2.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><apply id="S4.SS3.p2.6.m6.1.2.cmml" xref="S4.SS3.p2.6.m6.1.2"><times id="S4.SS3.p2.6.m6.1.2.1.cmml" xref="S4.SS3.p2.6.m6.1.2.1"></times><apply id="S4.SS3.p2.6.m6.1.2.2.cmml" xref="S4.SS3.p2.6.m6.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.p2.6.m6.1.2.2.1.cmml" xref="S4.SS3.p2.6.m6.1.2.2">subscript</csymbol><ci id="S4.SS3.p2.6.m6.1.2.2.2.cmml" xref="S4.SS3.p2.6.m6.1.2.2.2">𝐹</ci><ci id="S4.SS3.p2.6.m6.1.2.2.3.cmml" xref="S4.SS3.p2.6.m6.1.2.2.3">𝑘</ci></apply><ci id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">F_{k}(\theta)</annotation></semantics></math> indicates the local loss function computed on the data of client <math id="S4.SS3.p2.7.m7.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS3.p2.7.m7.1a"><mi id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><ci id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">k</annotation></semantics></math>. In <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a>, the goal is to find the global model parameters <math id="S4.SS3.p2.8.m8.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S4.SS3.p2.8.m8.1a"><mi id="S4.SS3.p2.8.m8.1.1" xref="S4.SS3.p2.8.m8.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.8.m8.1b"><ci id="S4.SS3.p2.8.m8.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.8.m8.1c">\theta</annotation></semantics></math> that minimize the global loss function <math id="S4.SS3.p2.9.m9.1" class="ltx_Math" alttext="F(\theta)" display="inline"><semantics id="S4.SS3.p2.9.m9.1a"><mrow id="S4.SS3.p2.9.m9.1.2" xref="S4.SS3.p2.9.m9.1.2.cmml"><mi id="S4.SS3.p2.9.m9.1.2.2" xref="S4.SS3.p2.9.m9.1.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.9.m9.1.2.1" xref="S4.SS3.p2.9.m9.1.2.1.cmml">​</mo><mrow id="S4.SS3.p2.9.m9.1.2.3.2" xref="S4.SS3.p2.9.m9.1.2.cmml"><mo stretchy="false" id="S4.SS3.p2.9.m9.1.2.3.2.1" xref="S4.SS3.p2.9.m9.1.2.cmml">(</mo><mi id="S4.SS3.p2.9.m9.1.1" xref="S4.SS3.p2.9.m9.1.1.cmml">θ</mi><mo stretchy="false" id="S4.SS3.p2.9.m9.1.2.3.2.2" xref="S4.SS3.p2.9.m9.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.9.m9.1b"><apply id="S4.SS3.p2.9.m9.1.2.cmml" xref="S4.SS3.p2.9.m9.1.2"><times id="S4.SS3.p2.9.m9.1.2.1.cmml" xref="S4.SS3.p2.9.m9.1.2.1"></times><ci id="S4.SS3.p2.9.m9.1.2.2.cmml" xref="S4.SS3.p2.9.m9.1.2.2">𝐹</ci><ci id="S4.SS3.p2.9.m9.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.9.m9.1c">F(\theta)</annotation></semantics></math>, which is an aggregate of the local loss functions from all participating clients. This process typically involves iterative updates to the model parameters using algorithms like federated averaging (FedAvg), where clients compute gradients or updates based on their local data and send these updates to a central server. The server then aggregates these updates to improve the global model.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Horizontal federated fearning (HFL)</span><span id="S4.I2.i1.p1.1.2" class="ltx_text" style="color:#000000;">:
In HFL, clients train a shared global model using their respective datasets, characterized by the same feature space but different sample spaces. Each client utilizes a local AI model, and their updates are aggregated by a central server without exposing raw data. The HFL training process involves: (1) initialization, (2) local training, (3) encryption of gradients, (4) secure aggregation, and (5) global model parameter updates. The objective function minimizes a global loss across all parties’ datasets </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.I2.i1.p1.1.3.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib97" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">97</span></a><span id="S4.I2.i1.p1.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.I2.i1.p1.1.5" class="ltx_text" style="color:#000000;">.</span></p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Vertical federated learning (VFL):</span><span id="S4.I2.i2.p1.1.2" class="ltx_text" style="color:#000000;">
VFL trains models on datasets sharing the same sample space but having different feature spaces. Through entity data alignment (EDA) and encrypted model trained (EMT), VFL allows clients to cooperatively train models without sharing raw data. The training process involves the same steps as HFL </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.I2.i2.p1.1.3.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib97" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">97</span></a><span id="S4.I2.i2.p1.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.I2.i2.p1.1.5" class="ltx_text" style="color:#000000;">.</span></p>
</div>
</li>
</ul>
</div>
<figure id="S4.F10" class="ltx_figure"><img src="/html/2403.01255/assets/x10.png" id="S4.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="402" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F10.4.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S4.F10.5.2" class="ltx_text" style="font-size:90%;">Federated learning principle: (a) Horizontal FL, (b) Vertical FL.</span></figcaption>
</figure>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text" style="color:#000000;">FL presents a paradigm shift in AI training, promoting collaboration while respecting data privacy. The working principle of HFL, and VFL is depicted on Figure <a href="#S4.F10" title="Figure 10 ‣ 4.3 FL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, they cater to various data distribution scenarios, offering flexible solutions for decentralized and secure <a href="#Sx1.30.30.30"><abbr href="#Sx1.30.30.30" title="machine learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ML</span></span></abbr></a>. The application of these FL frameworks extends across diverse domains, promising improved model accuracy and privacy preservation. The first work introducing <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a> in <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> is presented in
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">98</span></a>]</cite>. The authors introduced a FL platform that is easily generalizable, incorporating hierarchical optimization and a gradient selection algorithm to enhance training time and SR performance. Guliani et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">99</span></a>]</cite>
proposed a strategy to compensate
non-independent and identically distributed (non-IID) data in federated training of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>
systems. The proposed strategy involved random client data sampling, which resulted
in a cost-quality trade-off.
Zhu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">100</span></a>]</cite> addressed also FL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> in non-IID scenarios with personalized <a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a>. They introduced two approaches: adapting personalization layer-based FL for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>, involving local layers for personalized models, and proposing decoupled federated learning (DecoupleFL). DecoupleFL reduces computation on clients by shifting the computation burden to the server. Additionally, it communicates secure high-level features instead of model parameters, reducing communication costs, particularly for large models.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">101</span></a>]</cite>, the authors proposed a
client-adaptive federated training scheme to mitigate data heterogeneity when training
<a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> models. Nguyen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">102</span></a>]</cite> used FL to train an <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> model based on a wav2vec 2.0 model pre-trained by self supervision. Yang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">103</span></a>]</cite> proposed a decentralized feature extraction approach in
federated learning. This approach is built upon a quantum CNN (QCNN) composed of a quantum circuit encoder for feature extraction, and an RNN based end-to-end <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a>. This framework takes advantage of the quantum learning progress to secure models and to avoid privacy
leakage attacks. Gao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">104</span></a>]</cite> tackled a challenging and realistic <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> federated experimental setup with clients having heterogeneous data distributions, featuring thousands of different speakers, acoustic environments, and noises. Their empirical study focused on attention-based <a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a> End-to-End (E2E) <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> models, evaluating three aggregation weighting strategies: standard FedAvg, loss-based aggregation, and a novel WER-based aggregation.
Table <a href="#S4.T7" title="Table 7 ‣ 4.3 FL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> summarizes the most recent FL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> techniques.</span></p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:70%;color:#000000;"><span class="ltx_tag ltx_tag_table"><span id="S4.T7.15.3.1" class="ltx_text" style="font-size:129%;">Table 7</span>: </span><span id="S4.T7.4.2" class="ltx_text" style="font-size:129%;">Summary of recent proposed work in FL-based <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>. All the schemes are suggested for <a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a>. The symbol (<math id="S4.T7.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T7.3.1.m1.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T7.3.1.m1.1.1" xref="S4.T7.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.3.1.m1.1c"><ci id="S4.T7.3.1.m1.1.1.cmml" xref="S4.T7.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.3.1.m1.1d">\uparrow</annotation></semantics></math>) result increase, whereas (<math id="S4.T7.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T7.4.2.m2.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T7.4.2.m2.1.1" xref="S4.T7.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.4.2.m2.1c"><ci id="S4.T7.4.2.m2.1.1.cmml" xref="S4.T7.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.4.2.m2.1d">\downarrow</annotation></semantics></math>) signifies result decrease. In cases where multiple scenarios are examined, only the top-performing outcome is mentioned.</span></figcaption>
<table id="S4.T7.7" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.7.4" class="ltx_tr">
<td id="S4.T7.7.4.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T7.7.4.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Scheme</span></td>
<td id="S4.T7.7.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T7.7.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.4.2.1.1" class="ltx_p"><span id="S4.T7.7.4.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Based on</span></span>
</span>
</td>
<td id="S4.T7.7.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T7.7.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.4.3.1.1" class="ltx_p"><span id="S4.T7.7.4.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Speech recognition task</span></span>
</span>
</td>
<td id="S4.T7.7.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:85.4pt;">
<span id="S4.T7.7.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.4.4.1.1" class="ltx_p"><span id="S4.T7.7.4.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">FL technique</span></span>
</span>
</td>
<td id="S4.T7.7.4.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T7.7.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.4.5.1.1" class="ltx_p"><span id="S4.T7.7.4.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Metric and result</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.5" class="ltx_tr">
<td id="S4.T7.7.5.1" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib98" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">98</span></a><span id="S4.T7.7.5.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.5.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T7.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.5.2.1.1" class="ltx_p"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T7.7.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T7.7.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.5.3.1.1" class="ltx_p"><span id="S4.T7.7.5.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR</span></span>
</span>
</td>
<td id="S4.T7.7.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:85.4pt;">
<span id="S4.T7.7.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.5.4.1.1" class="ltx_p"><span id="S4.T7.7.5.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">FedAvg</span></span>
</span>
</td>
<td id="S4.T7.7.5.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T7.7.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.5.5.1.1" class="ltx_p"><span id="S4.T7.7.5.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER = 6%</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.6" class="ltx_tr">
<td id="S4.T7.7.6.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.6.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib99" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">99</span></a><span id="S4.T7.7.6.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.6.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.6.2.1.1" class="ltx_p"><span id="S4.T7.7.6.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">End-to-end RNN-T</span></span>
</span>
</td>
<td id="S4.T7.7.6.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.6.3.1.1" class="ltx_p"><span id="S4.T7.7.6.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">ASR on non-IDD data</span></span>
</span>
</td>
<td id="S4.T7.7.6.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.6.4.1.1" class="ltx_p"><span id="S4.T7.7.6.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">FedAvg</span></span>
</span>
</td>
<td id="S4.T7.7.6.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.6.5.1.1" class="ltx_p"><span id="S4.T7.7.6.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER=</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.5.1" class="ltx_tr">
<td id="S4.T7.5.1.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.5.1.2.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib100" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">100</span></a><span id="S4.T7.5.1.2.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.5.1.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.5.1.3.1.1" class="ltx_p"><span id="S4.T7.5.1.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">CNN+Transformer extractor</span></span>
</span>
</td>
<td id="S4.T7.5.1.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.5.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.5.1.4.1.1" class="ltx_p"><span id="S4.T7.5.1.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">ASR on non-IDD data</span></span>
</span>
</td>
<td id="S4.T7.5.1.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.5.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.5.1.5.1.1" class="ltx_p"><span id="S4.T7.5.1.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">DecoupleFL</span></span>
</span>
</td>
<td id="S4.T7.5.1.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.5.1.1.1.1" class="ltx_p"><span id="S4.T7.5.1.1.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">2.3- 3.4% WER </span><math id="S4.T7.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T7.5.1.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="70%" stretchy="false" id="S4.T7.5.1.1.1.1.m1.1.1" xref="S4.T7.5.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.5.1.1.1.1.m1.1b"><ci id="S4.T7.5.1.1.1.1.m1.1.1.cmml" xref="S4.T7.5.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.5.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math><span id="S4.T7.5.1.1.1.1.2" class="ltx_text" style="font-size:70%;color:#000000;"> compared with FedAvg</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.7" class="ltx_tr">
<td id="S4.T7.7.7.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.7.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib101" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">101</span></a><span id="S4.T7.7.7.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.7.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.7.2.1.1" class="ltx_p"><span id="S4.T7.7.7.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">LSTM</span></span>
</span>
</td>
<td id="S4.T7.7.7.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.7.3.1.1" class="ltx_p"><span id="S4.T7.7.7.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">ASR on non-IDD data</span></span>
</span>
</td>
<td id="S4.T7.7.7.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.7.4.1.1" class="ltx_p"><a href="#Sx1.7.7.7"><abbr href="#Sx1.7.7.7" title="client adaptive federated training" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CAFT</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T7.7.7.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.7.5.1.1" class="ltx_p"><span id="S4.T7.7.7.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER = 15.13%</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.8" class="ltx_tr">
<td id="S4.T7.7.8.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.8.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib102" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">102</span></a><span id="S4.T7.7.8.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.8.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.8.2.1.1" class="ltx_p"><span id="S4.T7.7.8.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">wav2vec 2.0</span></span>
</span>
</td>
<td id="S4.T7.7.8.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.8.3.1.1" class="ltx_p"><span id="S4.T7.7.8.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR</span></span>
</span>
</td>
<td id="S4.T7.7.8.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.8.4.1.1" class="ltx_p"><span id="S4.T7.7.8.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">FedAvg</span></span>
</span>
</td>
<td id="S4.T7.7.8.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.8.5.1.1" class="ltx_p"><span id="S4.T7.7.8.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER= 10.92% </span>
<br class="ltx_break"><span id="S4.T7.7.8.5.1.1.2" class="ltx_text" style="font-size:70%;color:#000000;">EER= 5-20%</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.9" class="ltx_tr">
<td id="S4.T7.7.9.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.9.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib103" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">103</span></a><span id="S4.T7.7.9.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.9.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.9.2.1.1" class="ltx_p"><span id="S4.T7.7.9.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">QCNN and RNN</span></span>
</span>
</td>
<td id="S4.T7.7.9.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.9.3.1.1" class="ltx_p"><span id="S4.T7.7.9.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve privacy-preservation in ASR</span></span>
</span>
</td>
<td id="S4.T7.7.9.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.9.4.1.1" class="ltx_p"><span id="S4.T7.7.9.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">VFL</span></span>
</span>
</td>
<td id="S4.T7.7.9.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.9.5.1.1" class="ltx_p"><span id="S4.T7.7.9.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Accuracy = 95.12%</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.10" class="ltx_tr">
<td id="S4.T7.7.10.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.10.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib104" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">104</span></a><span id="S4.T7.7.10.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.10.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.10.2.1.1" class="ltx_p"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T7.7.10.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.10.3.1.1" class="ltx_p"><span id="S4.T7.7.10.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">ASR on heterogeneous data distributions</span></span>
</span>
</td>
<td id="S4.T7.7.10.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.10.4.1.1" class="ltx_p"><span id="S4.T7.7.10.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">FedAvg</span></span>
</span>
</td>
<td id="S4.T7.7.10.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.10.5.1.1" class="ltx_p"><span id="S4.T7.7.10.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER= 19.98-23.86%</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.11" class="ltx_tr">
<td id="S4.T7.7.11.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.11.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib105" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">105</span></a><span id="S4.T7.7.11.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.11.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.11.2.1.1" class="ltx_p"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T7.7.11.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.11.3.1.1" class="ltx_p"><span id="S4.T7.7.11.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">ASR on private and unlabelled
user data.</span></span>
</span>
</td>
<td id="S4.T7.7.11.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.11.4.1.1" class="ltx_p"><a href="#Sx1.19.19.19"><abbr href="#Sx1.19.19.19" title="federated noisy student training" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FedNST</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T7.7.11.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.11.5.1.1" class="ltx_p"><span id="S4.T7.7.11.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER= 22.5%</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.12" class="ltx_tr">
<td id="S4.T7.7.12.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.12.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib106" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">106</span></a><span id="S4.T7.7.12.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.12.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.12.2.1.1" class="ltx_p"><span id="S4.T7.7.12.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Wav2vec 2.0 and Whisper</span></span>
</span>
</td>
<td id="S4.T7.7.12.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.12.3.1.1" class="ltx_p"><span id="S4.T7.7.12.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">ASR &amp; KWS for child exploitation settings</span></span>
</span>
</td>
<td id="S4.T7.7.12.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.12.4.1.1" class="ltx_p"><span id="S4.T7.7.12.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">FedAvg</span></span>
</span>
</td>
<td id="S4.T7.7.12.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.12.5.1.1" class="ltx_p"><span id="S4.T7.7.12.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER = 11-25%</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.13" class="ltx_tr">
<td id="S4.T7.7.13.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.13.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib107" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">107</span></a><span id="S4.T7.7.13.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.13.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.13.2.1.1" class="ltx_p"><span id="S4.T7.7.13.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Kaldi and backoff n-gram</span></span>
</span>
</td>
<td id="S4.T7.7.13.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.13.3.1.1" class="ltx_p"><span id="S4.T7.7.13.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve privacy-preservation in ASR</span></span>
</span>
</td>
<td id="S4.T7.7.13.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.13.4.1.1" class="ltx_p"><span id="S4.T7.7.13.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Merging models</span></span>
</span>
</td>
<td id="S4.T7.7.13.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.13.5.1.1" class="ltx_p"><span id="S4.T7.7.13.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER= 17.7%</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.14" class="ltx_tr">
<td id="S4.T7.7.14.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.14.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib108" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">108</span></a><span id="S4.T7.7.14.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.14.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.14.2.1.1" class="ltx_p"><span id="S4.T7.7.14.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">TDNN</span></span>
</span>
</td>
<td id="S4.T7.7.14.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.14.3.1.1" class="ltx_p"><span id="S4.T7.7.14.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve privacy-preservation in ASR</span></span>
</span>
</td>
<td id="S4.T7.7.14.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T7.7.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.14.4.1.1" class="ltx_p"><span id="S4.T7.7.14.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Aggregation</span></span>
</span>
</td>
<td id="S4.T7.7.14.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T7.7.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.14.5.1.1" class="ltx_p"><span id="S4.T7.7.14.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">EER = 1-2%.</span></span>
</span>
</td>
</tr>
<tr id="S4.T7.7.3" class="ltx_tr">
<td id="S4.T7.7.3.3" class="ltx_td ltx_align_left ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T7.7.3.3.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib109" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">109</span></a><span id="S4.T7.7.3.3.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T7.7.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:113.8pt;">
<span id="S4.T7.7.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.3.4.1.1" class="ltx_p"><span id="S4.T7.7.3.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Non-Streaming &amp; Streaming Conformer</span></span>
</span>
</td>
<td id="S4.T7.7.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:113.8pt;">
<span id="S4.T7.7.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.3.5.1.1" class="ltx_p"><span id="S4.T7.7.3.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Reduce client ASR model size</span></span>
</span>
</td>
<td id="S4.T7.7.3.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:85.4pt;">
<span id="S4.T7.7.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.3.6.1.1" class="ltx_p"><span id="S4.T7.7.3.6.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Federated Dropout</span></span>
</span>
</td>
<td id="S4.T7.7.3.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:113.8pt;">
<span id="S4.T7.7.3.2.2" class="ltx_inline-block ltx_align_top">
<span id="S4.T7.7.3.2.2.2" class="ltx_p"><span id="S4.T7.7.3.2.2.2.1" class="ltx_text" style="font-size:70%;color:#000000;">6-22% </span><math id="S4.T7.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T7.6.2.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="70%" stretchy="false" id="S4.T7.6.2.1.1.1.m1.1.1" xref="S4.T7.6.2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.6.2.1.1.1.m1.1b"><ci id="S4.T7.6.2.1.1.1.m1.1.1.cmml" xref="S4.T7.6.2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.6.2.1.1.1.m1.1c">\downarrow</annotation></semantics></math><span id="S4.T7.7.3.2.2.2.2" class="ltx_text" style="font-size:70%;color:#000000;"> Client size model; 34-3% WER </span><math id="S4.T7.7.3.2.2.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T7.7.3.2.2.2.m2.1a"><mo mathcolor="#000000" mathsize="70%" stretchy="false" id="S4.T7.7.3.2.2.2.m2.1.1" xref="S4.T7.7.3.2.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.7.3.2.2.2.m2.1b"><ci id="S4.T7.7.3.2.2.2.m2.1.1.cmml" xref="S4.T7.7.3.2.2.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.7.3.2.2.2.m2.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>RL-based ASR</h3>

<div id="S4.SS4.p1" class="ltx_para">
<span id="S4.SS4.p1.2" class="ltx_ERROR undefined">\Ac</span>
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text" style="color:#000000;">RL is a </span><a href="#Sx1.30.30.30"><abbr href="#Sx1.30.30.30" title="machine learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ML</span></span></abbr></a><span id="S4.SS4.p1.1.2" class="ltx_text" style="color:#000000;"> paradigm where an agent learns optimal decision-making by interacting with an environment. The agent receives feedback in the form of rewards or penalties, adapting its behavior to maximize cumulative reward over time through a trial-and-error process.  </span><a href="#Sx1.35.35.35"><span href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">reinforcement learning</span></span></span></a><span id="S4.SS4.p1.1.3" class="ltx_text" style="color:#000000;"> (</span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p1.1.4" class="ltx_text" style="color:#000000;">) involves several key concepts, as defined in the following terms: Environment model, serving as a representation of contextual dynamics; State (s), denoting the current situation perceived by the agent; Observation (o), a subset of the state directly perceived by the agent; Action (a), the decision made by the agent in response to the environment; Policy (</span><math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="\pi" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mi mathcolor="#000000" id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\pi</annotation></semantics></math><span id="S4.SS4.p1.1.5" class="ltx_text" style="color:#000000;">), describing how the agent converts environmental conditions into actions; Agent, the entity making decisions based on current states and past experiences; Reward, numerical values assigned by the environment to the agent based on state-action interactions. Figure </span><a href="#S4.F11" title="Figure 11 ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">11</span></a><span id="S4.SS4.p1.1.6" class="ltx_text" style="color:#000000;"> illustrate the principle of </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p1.1.7" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<figure id="S4.F11" class="ltx_figure"><img src="/html/2403.01255/assets/x11.png" id="S4.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="196" height="95" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F11.4.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S4.F11.5.2" class="ltx_text" style="font-size:90%;">RL principle.</span></figcaption>
</figure>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.7" class="ltx_p"><span id="S4.SS4.p2.7.1" class="ltx_text" style="color:#000000;">Markov Decision Process (MDP) is a fundamental framework for dynamic and stochastic decision-making, characterized by state space </span><math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mi mathcolor="#000000" id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><ci id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">S</annotation></semantics></math><span id="S4.SS4.p2.7.2" class="ltx_text" style="color:#000000;">, action space </span><math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="\mathbb{A}" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mi mathcolor="#000000" id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml">𝔸</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><ci id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1">𝔸</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">\mathbb{A}</annotation></semantics></math><span id="S4.SS4.p2.7.3" class="ltx_text" style="color:#000000;">, transition probabilities </span><math id="S4.SS4.p2.3.m3.1" class="ltx_Math" alttext="\mathbb{P}" display="inline"><semantics id="S4.SS4.p2.3.m3.1a"><mi mathcolor="#000000" id="S4.SS4.p2.3.m3.1.1" xref="S4.SS4.p2.3.m3.1.1.cmml">ℙ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.3.m3.1b"><ci id="S4.SS4.p2.3.m3.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1">ℙ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.3.m3.1c">\mathbb{P}</annotation></semantics></math><span id="S4.SS4.p2.7.4" class="ltx_text" style="color:#000000;">, and a reward function </span><math id="S4.SS4.p2.4.m4.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.SS4.p2.4.m4.1a"><mi mathcolor="#000000" id="S4.SS4.p2.4.m4.1.1" xref="S4.SS4.p2.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.4.m4.1b"><ci id="S4.SS4.p2.4.m4.1.1.cmml" xref="S4.SS4.p2.4.m4.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.4.m4.1c">R</annotation></semantics></math><span id="S4.SS4.p2.7.5" class="ltx_text" style="color:#000000;">. The primary objective in an MDP is to identify an optimal policy </span><math id="S4.SS4.p2.5.m5.1" class="ltx_Math" alttext="\pi^{*}" display="inline"><semantics id="S4.SS4.p2.5.m5.1a"><msup id="S4.SS4.p2.5.m5.1.1" xref="S4.SS4.p2.5.m5.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.5.m5.1.1.2" xref="S4.SS4.p2.5.m5.1.1.2.cmml">π</mi><mo mathcolor="#000000" id="S4.SS4.p2.5.m5.1.1.3" xref="S4.SS4.p2.5.m5.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.5.m5.1b"><apply id="S4.SS4.p2.5.m5.1.1.cmml" xref="S4.SS4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS4.p2.5.m5.1.1.1.cmml" xref="S4.SS4.p2.5.m5.1.1">superscript</csymbol><ci id="S4.SS4.p2.5.m5.1.1.2.cmml" xref="S4.SS4.p2.5.m5.1.1.2">𝜋</ci><times id="S4.SS4.p2.5.m5.1.1.3.cmml" xref="S4.SS4.p2.5.m5.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.5.m5.1c">\pi^{*}</annotation></semantics></math><span id="S4.SS4.p2.7.6" class="ltx_text" style="color:#000000;"> maximizing the expected discounted total reward over time, expressed as </span><math id="S4.SS4.p2.6.m6.1" class="ltx_Math" alttext="\pi^{*}=\max_{\pi}\mathbb{E}_{\pi}[\sum_{t=0}^{T}\gamma^{t}r_{t}(s_{t},\pi(s_{t}))]" display="inline"><semantics id="S4.SS4.p2.6.m6.1a"><mrow id="S4.SS4.p2.6.m6.1.1" xref="S4.SS4.p2.6.m6.1.1.cmml"><msup id="S4.SS4.p2.6.m6.1.1.3" xref="S4.SS4.p2.6.m6.1.1.3.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.3.2" xref="S4.SS4.p2.6.m6.1.1.3.2.cmml">π</mi><mo mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.3.3" xref="S4.SS4.p2.6.m6.1.1.3.3.cmml">∗</mo></msup><mo mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.2" xref="S4.SS4.p2.6.m6.1.1.2.cmml">=</mo><mrow id="S4.SS4.p2.6.m6.1.1.1" xref="S4.SS4.p2.6.m6.1.1.1.cmml"><mrow id="S4.SS4.p2.6.m6.1.1.1.3" xref="S4.SS4.p2.6.m6.1.1.1.3.cmml"><msub id="S4.SS4.p2.6.m6.1.1.1.3.1" xref="S4.SS4.p2.6.m6.1.1.1.3.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.3.1.2" xref="S4.SS4.p2.6.m6.1.1.1.3.1.2.cmml">max</mi><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.3.1.3" xref="S4.SS4.p2.6.m6.1.1.1.3.1.3.cmml">π</mi></msub><mo lspace="0.167em" id="S4.SS4.p2.6.m6.1.1.1.3a" xref="S4.SS4.p2.6.m6.1.1.1.3.cmml">⁡</mo><msub id="S4.SS4.p2.6.m6.1.1.1.3.2" xref="S4.SS4.p2.6.m6.1.1.1.3.2.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.3.2.2" xref="S4.SS4.p2.6.m6.1.1.1.3.2.2.cmml">𝔼</mi><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.3.2.3" xref="S4.SS4.p2.6.m6.1.1.1.3.2.3.cmml">π</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S4.SS4.p2.6.m6.1.1.1.2" xref="S4.SS4.p2.6.m6.1.1.1.2.cmml">​</mo><mrow id="S4.SS4.p2.6.m6.1.1.1.1.1" xref="S4.SS4.p2.6.m6.1.1.1.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p2.6.m6.1.1.1.1.1.2" xref="S4.SS4.p2.6.m6.1.1.1.1.2.1.cmml">[</mo><mrow id="S4.SS4.p2.6.m6.1.1.1.1.1.1" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.cmml"><msubsup id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.cmml"><mo lspace="0em" mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.2.cmml">∑</mo><mrow id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.2.cmml">t</mi><mo mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.1" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.1.cmml">=</mo><mn mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.3.cmml">0</mn></mrow><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.3.cmml">T</mi></msubsup><mrow id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.cmml"><msup id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.2.cmml">γ</mi><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.3.cmml">t</mi></msup><mo lspace="0em" rspace="0em" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.3.cmml">​</mo><msub id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.2.cmml">r</mi><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.3a" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.3.cmml">​</mo><mrow id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.2.cmml">s</mi><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.4" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.3.cmml">,</mo><mrow id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.3.cmml">π</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.2.cmml">​</mo><mrow id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.cmml">(</mo><msub id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.2" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.2.cmml">s</mi><mi mathcolor="#000000" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.3.cmml">t</mi></msub><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.3" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.5" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S4.SS4.p2.6.m6.1.1.1.1.1.3" xref="S4.SS4.p2.6.m6.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.6.m6.1b"><apply id="S4.SS4.p2.6.m6.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1"><eq id="S4.SS4.p2.6.m6.1.1.2.cmml" xref="S4.SS4.p2.6.m6.1.1.2"></eq><apply id="S4.SS4.p2.6.m6.1.1.3.cmml" xref="S4.SS4.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.3.1.cmml" xref="S4.SS4.p2.6.m6.1.1.3">superscript</csymbol><ci id="S4.SS4.p2.6.m6.1.1.3.2.cmml" xref="S4.SS4.p2.6.m6.1.1.3.2">𝜋</ci><times id="S4.SS4.p2.6.m6.1.1.3.3.cmml" xref="S4.SS4.p2.6.m6.1.1.3.3"></times></apply><apply id="S4.SS4.p2.6.m6.1.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1"><times id="S4.SS4.p2.6.m6.1.1.1.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.2"></times><apply id="S4.SS4.p2.6.m6.1.1.1.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3"><apply id="S4.SS4.p2.6.m6.1.1.1.3.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3.1"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.1.3.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3.1">subscript</csymbol><max id="S4.SS4.p2.6.m6.1.1.1.3.1.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3.1.2"></max><ci id="S4.SS4.p2.6.m6.1.1.1.3.1.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3.1.3">𝜋</ci></apply><apply id="S4.SS4.p2.6.m6.1.1.1.3.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.1.3.2.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3.2">subscript</csymbol><ci id="S4.SS4.p2.6.m6.1.1.1.3.2.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3.2.2">𝔼</ci><ci id="S4.SS4.p2.6.m6.1.1.1.3.2.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.3.2.3">𝜋</ci></apply></apply><apply id="S4.SS4.p2.6.m6.1.1.1.1.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1"><csymbol cd="latexml" id="S4.SS4.p2.6.m6.1.1.1.1.2.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1"><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3">superscript</csymbol><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3">subscript</csymbol><sum id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.2"></sum><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3"><eq id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.1"></eq><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.2">𝑡</ci><cn type="integer" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.2.3.3">0</cn></apply></apply><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.3.3">𝑇</ci></apply><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2"><times id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.3"></times><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4">superscript</csymbol><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.2">𝛾</ci><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.4.3">𝑡</ci></apply><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5">subscript</csymbol><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.2">𝑟</ci><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.5.3">𝑡</ci></apply><interval closure="open" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2"><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.2">𝑠</ci><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2"><times id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.2"></times><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.3">𝜋</ci><apply id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.1.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1">subscript</csymbol><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.2.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.2">𝑠</ci><ci id="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.3.cmml" xref="S4.SS4.p2.6.m6.1.1.1.1.1.1.2.2.2.2.1.1.1.3">𝑡</ci></apply></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.6.m6.1c">\pi^{*}=\max_{\pi}\mathbb{E}_{\pi}[\sum_{t=0}^{T}\gamma^{t}r_{t}(s_{t},\pi(s_{t}))]</annotation></semantics></math><span id="S4.SS4.p2.7.7" class="ltx_text" style="color:#000000;">, where </span><math id="S4.SS4.p2.7.m7.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.SS4.p2.7.m7.1a"><mi mathcolor="#000000" id="S4.SS4.p2.7.m7.1.1" xref="S4.SS4.p2.7.m7.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.7.m7.1b"><ci id="S4.SS4.p2.7.m7.1.1.cmml" xref="S4.SS4.p2.7.m7.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.7.m7.1c">\gamma</annotation></semantics></math><span id="S4.SS4.p2.7.8" class="ltx_text" style="color:#000000;"> is the discount factor. MDPs find extensive applications in addressing uncertainties in intelligent systems within dynamic wireless environments, including spectrum management, cognitive radios, and wireless security.</span></p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.6" class="ltx_p"><span id="S4.SS4.p3.6.1" class="ltx_text" style="color:#000000;">In the field of </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p3.6.2" class="ltx_text" style="color:#000000;">, </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p3.6.3" class="ltx_text" style="color:#000000;"> has primarily been proposed to tackle discrepancies between training and testing phases. Two main discrepancies leading to potential performance deterioration have been identified: 1) The conventional use of the cross-entropy criterion maximizes log-likelihood during training, while performance is assessed by </span><a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">WER</span></span></abbr></a><span id="S4.SS4.p3.6.4" class="ltx_text" style="color:#000000;">, not log-likelihood; 2) The teacher-forcing method, which relies on ground truth during training, implies that the model has never encountered its own predictions before testing. </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p3.6.5" class="ltx_text" style="color:#000000;"> addresses these discrepancies by bridging the gap between the training and testing phases. Several </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p3.6.6" class="ltx_text" style="color:#000000;">-based approaches for </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p3.6.7" class="ltx_text" style="color:#000000;"> have been proposed </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p3.6.8.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib110" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">110</span></a>, <a href="#bib.bib111" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">111</span></a>, <a href="#bib.bib112" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">112</span></a>, <a href="#bib.bib113" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">113</span></a>, <a href="#bib.bib114" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">114</span></a>, <a href="#bib.bib115" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">115</span></a>, <a href="#bib.bib116" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">116</span></a>, <a href="#bib.bib117" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">117</span></a>, <a href="#bib.bib118" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">118</span></a>, <a href="#bib.bib119" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">119</span></a><span id="S4.SS4.p3.6.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p3.6.10" class="ltx_text" style="color:#000000;">. For example, in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p3.6.11.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib110" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">110</span></a><span id="S4.SS4.p3.6.12.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p3.6.13" class="ltx_text" style="color:#000000;">, the authors introduced a </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p3.6.14" class="ltx_text" style="color:#000000;">-based optimization method for the </span><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a><span id="S4.SS4.p3.6.15" class="ltx_text" style="color:#000000;"> </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p3.6.16" class="ltx_text" style="color:#000000;"> task called Self-critical sequence training (SCST). This method can be conceptualized as a sequential decision model, depicted in Figure </span><a href="#S4.F12" title="Figure 12 ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">12</span></a><span id="S4.SS4.p3.6.17" class="ltx_text" style="color:#000000;">. The entire encoder-decoder neural network is treated as an agent. At each time step </span><math id="S4.SS4.p3.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS4.p3.1.m1.1a"><mi mathcolor="#000000" id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><ci id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">t</annotation></semantics></math><span id="S4.SS4.p3.6.18" class="ltx_text" style="color:#000000;">, the current state </span><math id="S4.SS4.p3.2.m2.1" class="ltx_Math" alttext="s_{t}" display="inline"><semantics id="S4.SS4.p3.2.m2.1a"><msub id="S4.SS4.p3.2.m2.1.1" xref="S4.SS4.p3.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p3.2.m2.1.1.2" xref="S4.SS4.p3.2.m2.1.1.2.cmml">s</mi><mi mathcolor="#000000" id="S4.SS4.p3.2.m2.1.1.3" xref="S4.SS4.p3.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.m2.1b"><apply id="S4.SS4.p3.2.m2.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.p3.2.m2.1.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.p3.2.m2.1.1.2.cmml" xref="S4.SS4.p3.2.m2.1.1.2">𝑠</ci><ci id="S4.SS4.p3.2.m2.1.1.3.cmml" xref="S4.SS4.p3.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.m2.1c">s_{t}</annotation></semantics></math><span id="S4.SS4.p3.6.19" class="ltx_text" style="color:#000000;"> is formed by concatenating the acoustic feature </span><math id="S4.SS4.p3.3.m3.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S4.SS4.p3.3.m3.1a"><msub id="S4.SS4.p3.3.m3.1.1" xref="S4.SS4.p3.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p3.3.m3.1.1.2" xref="S4.SS4.p3.3.m3.1.1.2.cmml">x</mi><mi mathcolor="#000000" id="S4.SS4.p3.3.m3.1.1.3" xref="S4.SS4.p3.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.3.m3.1b"><apply id="S4.SS4.p3.3.m3.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.p3.3.m3.1.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.p3.3.m3.1.1.2.cmml" xref="S4.SS4.p3.3.m3.1.1.2">𝑥</ci><ci id="S4.SS4.p3.3.m3.1.1.3.cmml" xref="S4.SS4.p3.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.3.m3.1c">x_{t}</annotation></semantics></math><span id="S4.SS4.p3.6.20" class="ltx_text" style="color:#000000;"> and the previous prediction </span><math id="S4.SS4.p3.4.m4.1" class="ltx_Math" alttext="Y_{t-1}" display="inline"><semantics id="S4.SS4.p3.4.m4.1a"><msub id="S4.SS4.p3.4.m4.1.1" xref="S4.SS4.p3.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p3.4.m4.1.1.2" xref="S4.SS4.p3.4.m4.1.1.2.cmml">Y</mi><mrow id="S4.SS4.p3.4.m4.1.1.3" xref="S4.SS4.p3.4.m4.1.1.3.cmml"><mi mathcolor="#000000" id="S4.SS4.p3.4.m4.1.1.3.2" xref="S4.SS4.p3.4.m4.1.1.3.2.cmml">t</mi><mo mathcolor="#000000" id="S4.SS4.p3.4.m4.1.1.3.1" xref="S4.SS4.p3.4.m4.1.1.3.1.cmml">−</mo><mn mathcolor="#000000" id="S4.SS4.p3.4.m4.1.1.3.3" xref="S4.SS4.p3.4.m4.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.4.m4.1b"><apply id="S4.SS4.p3.4.m4.1.1.cmml" xref="S4.SS4.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.p3.4.m4.1.1.1.cmml" xref="S4.SS4.p3.4.m4.1.1">subscript</csymbol><ci id="S4.SS4.p3.4.m4.1.1.2.cmml" xref="S4.SS4.p3.4.m4.1.1.2">𝑌</ci><apply id="S4.SS4.p3.4.m4.1.1.3.cmml" xref="S4.SS4.p3.4.m4.1.1.3"><minus id="S4.SS4.p3.4.m4.1.1.3.1.cmml" xref="S4.SS4.p3.4.m4.1.1.3.1"></minus><ci id="S4.SS4.p3.4.m4.1.1.3.2.cmml" xref="S4.SS4.p3.4.m4.1.1.3.2">𝑡</ci><cn type="integer" id="S4.SS4.p3.4.m4.1.1.3.3.cmml" xref="S4.SS4.p3.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.4.m4.1c">Y_{t-1}</annotation></semantics></math><span id="S4.SS4.p3.6.21" class="ltx_text" style="color:#000000;">. The output token serves as the action, updating the generated hypotheses sequence. SCST associates training loss and </span><a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">WER</span></span></abbr></a><span id="S4.SS4.p3.6.22" class="ltx_text" style="color:#000000;"> using a WER-related reward function, calculating the reward </span><math id="S4.SS4.p3.5.m5.1" class="ltx_Math" alttext="r_{t}" display="inline"><semantics id="S4.SS4.p3.5.m5.1a"><msub id="S4.SS4.p3.5.m5.1.1" xref="S4.SS4.p3.5.m5.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p3.5.m5.1.1.2" xref="S4.SS4.p3.5.m5.1.1.2.cmml">r</mi><mi mathcolor="#000000" id="S4.SS4.p3.5.m5.1.1.3" xref="S4.SS4.p3.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.5.m5.1b"><apply id="S4.SS4.p3.5.m5.1.1.cmml" xref="S4.SS4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS4.p3.5.m5.1.1.1.cmml" xref="S4.SS4.p3.5.m5.1.1">subscript</csymbol><ci id="S4.SS4.p3.5.m5.1.1.2.cmml" xref="S4.SS4.p3.5.m5.1.1.2">𝑟</ci><ci id="S4.SS4.p3.5.m5.1.1.3.cmml" xref="S4.SS4.p3.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.5.m5.1c">r_{t}</annotation></semantics></math><span id="S4.SS4.p3.6.23" class="ltx_text" style="color:#000000;"> at each token generation step by comparing it with the ground truth sequence </span><math id="S4.SS4.p3.6.m6.1" class="ltx_Math" alttext="Y^{*}" display="inline"><semantics id="S4.SS4.p3.6.m6.1a"><msup id="S4.SS4.p3.6.m6.1.1" xref="S4.SS4.p3.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p3.6.m6.1.1.2" xref="S4.SS4.p3.6.m6.1.1.2.cmml">Y</mi><mo mathcolor="#000000" id="S4.SS4.p3.6.m6.1.1.3" xref="S4.SS4.p3.6.m6.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.6.m6.1b"><apply id="S4.SS4.p3.6.m6.1.1.cmml" xref="S4.SS4.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS4.p3.6.m6.1.1.1.cmml" xref="S4.SS4.p3.6.m6.1.1">superscript</csymbol><ci id="S4.SS4.p3.6.m6.1.1.2.cmml" xref="S4.SS4.p3.6.m6.1.1.2">𝑌</ci><times id="S4.SS4.p3.6.m6.1.1.3.cmml" xref="S4.SS4.p3.6.m6.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.6.m6.1c">Y^{*}</annotation></semantics></math><span id="S4.SS4.p3.6.24" class="ltx_text" style="color:#000000;">. SCST uses the test-time beam search algorithm to sample hypotheses for reward normalization, assigning positive weights to high-reward hypotheses that outperform the current test-time system and negative weights to low-reward hypotheses. The framework is illustrated in Figure </span><a href="#S4.F12" title="Figure 12 ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">12</span></a><span id="S4.SS4.p3.6.25" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p"><span id="S4.SS4.p4.1.1" class="ltx_text" style="color:#000000;">In </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p4.1.2" class="ltx_text" style="color:#000000;">, RL has been primarily proposed to address mismatches between training and testing phases. Two main mismatches leading to potential performance degradation are identified: 1) The commonly used cross-entropy criterion maximizes log-likelihood during training, while performance is evaluated by WER, not log-likelihood; 2) The teacher-forcing method, relying on ground truth during training, implies that the model has never encountered its own predictions before testing. RL bridges the gap between the training and testing phases, addressing these mismatches.</span></p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.6" class="ltx_p"><span id="S4.SS4.p5.6.1" class="ltx_text" style="color:#000000;">Several RL-based </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p5.6.2" class="ltx_text" style="color:#000000;"> approaches have proposed </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p5.6.3.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib110" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">110</span></a>, <a href="#bib.bib111" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">111</span></a>, <a href="#bib.bib112" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">112</span></a>, <a href="#bib.bib113" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">113</span></a>, <a href="#bib.bib114" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">114</span></a>, <a href="#bib.bib115" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">115</span></a>, <a href="#bib.bib116" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">116</span></a>, <a href="#bib.bib117" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">117</span></a>, <a href="#bib.bib118" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">118</span></a>, <a href="#bib.bib119" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">119</span></a><span id="S4.SS4.p5.6.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p5.6.5" class="ltx_text" style="color:#000000;">. For instance, In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p5.6.6.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib110" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">110</span></a><span id="S4.SS4.p5.6.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p5.6.8" class="ltx_text" style="color:#000000;">, the authors presented a RL-based optimization method for </span><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a><span id="S4.SS4.p5.6.9" class="ltx_text" style="color:#000000;"> </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p5.6.10" class="ltx_text" style="color:#000000;"> task called self-critical sequence
training (SCST). This can be viewed as a sequential decision model as shown in Fig. </span><a href="#S4.F12" title="Figure 12 ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">12</span></a><span id="S4.SS4.p5.6.11" class="ltx_text" style="color:#000000;">. The whole encoder-decoder neural network can be viewed as
an agent. In each time step </span><math id="S4.SS4.p5.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS4.p5.1.m1.1a"><mi mathcolor="#000000" id="S4.SS4.p5.1.m1.1.1" xref="S4.SS4.p5.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.1.m1.1b"><ci id="S4.SS4.p5.1.m1.1.1.cmml" xref="S4.SS4.p5.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.1.m1.1c">t</annotation></semantics></math><span id="S4.SS4.p5.6.12" class="ltx_text" style="color:#000000;">, acoustic feature </span><math id="S4.SS4.p5.2.m2.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S4.SS4.p5.2.m2.1a"><msub id="S4.SS4.p5.2.m2.1.1" xref="S4.SS4.p5.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p5.2.m2.1.1.2" xref="S4.SS4.p5.2.m2.1.1.2.cmml">x</mi><mi mathcolor="#000000" id="S4.SS4.p5.2.m2.1.1.3" xref="S4.SS4.p5.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.2.m2.1b"><apply id="S4.SS4.p5.2.m2.1.1.cmml" xref="S4.SS4.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.p5.2.m2.1.1.1.cmml" xref="S4.SS4.p5.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.p5.2.m2.1.1.2.cmml" xref="S4.SS4.p5.2.m2.1.1.2">𝑥</ci><ci id="S4.SS4.p5.2.m2.1.1.3.cmml" xref="S4.SS4.p5.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.2.m2.1c">x_{t}</annotation></semantics></math><span id="S4.SS4.p5.6.13" class="ltx_text" style="color:#000000;"> and previous </span><math id="S4.SS4.p5.3.m3.1" class="ltx_Math" alttext="Y_{t-1}" display="inline"><semantics id="S4.SS4.p5.3.m3.1a"><msub id="S4.SS4.p5.3.m3.1.1" xref="S4.SS4.p5.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p5.3.m3.1.1.2" xref="S4.SS4.p5.3.m3.1.1.2.cmml">Y</mi><mrow id="S4.SS4.p5.3.m3.1.1.3" xref="S4.SS4.p5.3.m3.1.1.3.cmml"><mi mathcolor="#000000" id="S4.SS4.p5.3.m3.1.1.3.2" xref="S4.SS4.p5.3.m3.1.1.3.2.cmml">t</mi><mo mathcolor="#000000" id="S4.SS4.p5.3.m3.1.1.3.1" xref="S4.SS4.p5.3.m3.1.1.3.1.cmml">−</mo><mn mathcolor="#000000" id="S4.SS4.p5.3.m3.1.1.3.3" xref="S4.SS4.p5.3.m3.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.3.m3.1b"><apply id="S4.SS4.p5.3.m3.1.1.cmml" xref="S4.SS4.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.p5.3.m3.1.1.1.cmml" xref="S4.SS4.p5.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.p5.3.m3.1.1.2.cmml" xref="S4.SS4.p5.3.m3.1.1.2">𝑌</ci><apply id="S4.SS4.p5.3.m3.1.1.3.cmml" xref="S4.SS4.p5.3.m3.1.1.3"><minus id="S4.SS4.p5.3.m3.1.1.3.1.cmml" xref="S4.SS4.p5.3.m3.1.1.3.1"></minus><ci id="S4.SS4.p5.3.m3.1.1.3.2.cmml" xref="S4.SS4.p5.3.m3.1.1.3.2">𝑡</ci><cn type="integer" id="S4.SS4.p5.3.m3.1.1.3.3.cmml" xref="S4.SS4.p5.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.3.m3.1c">Y_{t-1}</annotation></semantics></math><span id="S4.SS4.p5.6.14" class="ltx_text" style="color:#000000;">
prediction are concatenated as current state </span><math id="S4.SS4.p5.4.m4.1" class="ltx_Math" alttext="s_{t}" display="inline"><semantics id="S4.SS4.p5.4.m4.1a"><msub id="S4.SS4.p5.4.m4.1.1" xref="S4.SS4.p5.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p5.4.m4.1.1.2" xref="S4.SS4.p5.4.m4.1.1.2.cmml">s</mi><mi mathcolor="#000000" id="S4.SS4.p5.4.m4.1.1.3" xref="S4.SS4.p5.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.4.m4.1b"><apply id="S4.SS4.p5.4.m4.1.1.cmml" xref="S4.SS4.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.p5.4.m4.1.1.1.cmml" xref="S4.SS4.p5.4.m4.1.1">subscript</csymbol><ci id="S4.SS4.p5.4.m4.1.1.2.cmml" xref="S4.SS4.p5.4.m4.1.1.2">𝑠</ci><ci id="S4.SS4.p5.4.m4.1.1.3.cmml" xref="S4.SS4.p5.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.4.m4.1c">s_{t}</annotation></semantics></math><span id="S4.SS4.p5.6.15" class="ltx_text" style="color:#000000;">. The output token is the action at that will update the generated hypotheses sequence. After comparing it with ground truth sequence </span><math id="S4.SS4.p5.5.m5.1" class="ltx_Math" alttext="Y^{*}" display="inline"><semantics id="S4.SS4.p5.5.m5.1a"><msup id="S4.SS4.p5.5.m5.1.1" xref="S4.SS4.p5.5.m5.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p5.5.m5.1.1.2" xref="S4.SS4.p5.5.m5.1.1.2.cmml">Y</mi><mo mathcolor="#000000" id="S4.SS4.p5.5.m5.1.1.3" xref="S4.SS4.p5.5.m5.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.5.m5.1b"><apply id="S4.SS4.p5.5.m5.1.1.cmml" xref="S4.SS4.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS4.p5.5.m5.1.1.1.cmml" xref="S4.SS4.p5.5.m5.1.1">superscript</csymbol><ci id="S4.SS4.p5.5.m5.1.1.2.cmml" xref="S4.SS4.p5.5.m5.1.1.2">𝑌</ci><times id="S4.SS4.p5.5.m5.1.1.3.cmml" xref="S4.SS4.p5.5.m5.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.5.m5.1c">Y^{*}</annotation></semantics></math><span id="S4.SS4.p5.6.16" class="ltx_text" style="color:#000000;">, a reward </span><math id="S4.SS4.p5.6.m6.1" class="ltx_Math" alttext="r_{t}" display="inline"><semantics id="S4.SS4.p5.6.m6.1a"><msub id="S4.SS4.p5.6.m6.1.1" xref="S4.SS4.p5.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p5.6.m6.1.1.2" xref="S4.SS4.p5.6.m6.1.1.2.cmml">r</mi><mi mathcolor="#000000" id="S4.SS4.p5.6.m6.1.1.3" xref="S4.SS4.p5.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.6.m6.1b"><apply id="S4.SS4.p5.6.m6.1.1.cmml" xref="S4.SS4.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS4.p5.6.m6.1.1.1.cmml" xref="S4.SS4.p5.6.m6.1.1">subscript</csymbol><ci id="S4.SS4.p5.6.m6.1.1.2.cmml" xref="S4.SS4.p5.6.m6.1.1.2">𝑟</ci><ci id="S4.SS4.p5.6.m6.1.1.3.cmml" xref="S4.SS4.p5.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.6.m6.1c">r_{t}</annotation></semantics></math><span id="S4.SS4.p5.6.17" class="ltx_text" style="color:#000000;"> of this time step is calculated. SCST associates the training loss and WER using WER-related reward function, which considers the intermediate reward at each token generation step. Furthermore, SCST utilizes the test-time beam search algorithm to sample a set of hypotheses for reward normalization. As a result, the high-reward hypotheses that outperform the current test-time system are given positive weights, while the low-reward hypotheses are given negative weights.</span></p>
</div>
<div id="S4.SS4.p6" class="ltx_para">
<p id="S4.SS4.p6.6" class="ltx_p"><span id="S4.SS4.p6.6.1" class="ltx_text" style="color:#000000;">The entire encoder-decoder neural network is treated as an agent. At each time step </span><math id="S4.SS4.p6.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS4.p6.1.m1.1a"><mi mathcolor="#000000" id="S4.SS4.p6.1.m1.1.1" xref="S4.SS4.p6.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p6.1.m1.1b"><ci id="S4.SS4.p6.1.m1.1.1.cmml" xref="S4.SS4.p6.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p6.1.m1.1c">t</annotation></semantics></math><span id="S4.SS4.p6.6.2" class="ltx_text" style="color:#000000;">, the current state </span><math id="S4.SS4.p6.2.m2.1" class="ltx_Math" alttext="s_{t}" display="inline"><semantics id="S4.SS4.p6.2.m2.1a"><msub id="S4.SS4.p6.2.m2.1.1" xref="S4.SS4.p6.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p6.2.m2.1.1.2" xref="S4.SS4.p6.2.m2.1.1.2.cmml">s</mi><mi mathcolor="#000000" id="S4.SS4.p6.2.m2.1.1.3" xref="S4.SS4.p6.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p6.2.m2.1b"><apply id="S4.SS4.p6.2.m2.1.1.cmml" xref="S4.SS4.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.p6.2.m2.1.1.1.cmml" xref="S4.SS4.p6.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.p6.2.m2.1.1.2.cmml" xref="S4.SS4.p6.2.m2.1.1.2">𝑠</ci><ci id="S4.SS4.p6.2.m2.1.1.3.cmml" xref="S4.SS4.p6.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p6.2.m2.1c">s_{t}</annotation></semantics></math><span id="S4.SS4.p6.6.3" class="ltx_text" style="color:#000000;"> is formed by concatenating the acoustic feature </span><math id="S4.SS4.p6.3.m3.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S4.SS4.p6.3.m3.1a"><msub id="S4.SS4.p6.3.m3.1.1" xref="S4.SS4.p6.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p6.3.m3.1.1.2" xref="S4.SS4.p6.3.m3.1.1.2.cmml">x</mi><mi mathcolor="#000000" id="S4.SS4.p6.3.m3.1.1.3" xref="S4.SS4.p6.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p6.3.m3.1b"><apply id="S4.SS4.p6.3.m3.1.1.cmml" xref="S4.SS4.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.p6.3.m3.1.1.1.cmml" xref="S4.SS4.p6.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.p6.3.m3.1.1.2.cmml" xref="S4.SS4.p6.3.m3.1.1.2">𝑥</ci><ci id="S4.SS4.p6.3.m3.1.1.3.cmml" xref="S4.SS4.p6.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p6.3.m3.1c">x_{t}</annotation></semantics></math><span id="S4.SS4.p6.6.4" class="ltx_text" style="color:#000000;"> and the previous prediction </span><math id="S4.SS4.p6.4.m4.1" class="ltx_Math" alttext="Y_{t-1}" display="inline"><semantics id="S4.SS4.p6.4.m4.1a"><msub id="S4.SS4.p6.4.m4.1.1" xref="S4.SS4.p6.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p6.4.m4.1.1.2" xref="S4.SS4.p6.4.m4.1.1.2.cmml">Y</mi><mrow id="S4.SS4.p6.4.m4.1.1.3" xref="S4.SS4.p6.4.m4.1.1.3.cmml"><mi mathcolor="#000000" id="S4.SS4.p6.4.m4.1.1.3.2" xref="S4.SS4.p6.4.m4.1.1.3.2.cmml">t</mi><mo mathcolor="#000000" id="S4.SS4.p6.4.m4.1.1.3.1" xref="S4.SS4.p6.4.m4.1.1.3.1.cmml">−</mo><mn mathcolor="#000000" id="S4.SS4.p6.4.m4.1.1.3.3" xref="S4.SS4.p6.4.m4.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p6.4.m4.1b"><apply id="S4.SS4.p6.4.m4.1.1.cmml" xref="S4.SS4.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.p6.4.m4.1.1.1.cmml" xref="S4.SS4.p6.4.m4.1.1">subscript</csymbol><ci id="S4.SS4.p6.4.m4.1.1.2.cmml" xref="S4.SS4.p6.4.m4.1.1.2">𝑌</ci><apply id="S4.SS4.p6.4.m4.1.1.3.cmml" xref="S4.SS4.p6.4.m4.1.1.3"><minus id="S4.SS4.p6.4.m4.1.1.3.1.cmml" xref="S4.SS4.p6.4.m4.1.1.3.1"></minus><ci id="S4.SS4.p6.4.m4.1.1.3.2.cmml" xref="S4.SS4.p6.4.m4.1.1.3.2">𝑡</ci><cn type="integer" id="S4.SS4.p6.4.m4.1.1.3.3.cmml" xref="S4.SS4.p6.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p6.4.m4.1c">Y_{t-1}</annotation></semantics></math><span id="S4.SS4.p6.6.5" class="ltx_text" style="color:#000000;">. The output token serves as the action, updating the generated hypotheses sequence. SCST associates training loss and WER using a WER-related reward function, calculating the reward </span><math id="S4.SS4.p6.5.m5.1" class="ltx_Math" alttext="r_{t}" display="inline"><semantics id="S4.SS4.p6.5.m5.1a"><msub id="S4.SS4.p6.5.m5.1.1" xref="S4.SS4.p6.5.m5.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p6.5.m5.1.1.2" xref="S4.SS4.p6.5.m5.1.1.2.cmml">r</mi><mi mathcolor="#000000" id="S4.SS4.p6.5.m5.1.1.3" xref="S4.SS4.p6.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p6.5.m5.1b"><apply id="S4.SS4.p6.5.m5.1.1.cmml" xref="S4.SS4.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS4.p6.5.m5.1.1.1.cmml" xref="S4.SS4.p6.5.m5.1.1">subscript</csymbol><ci id="S4.SS4.p6.5.m5.1.1.2.cmml" xref="S4.SS4.p6.5.m5.1.1.2">𝑟</ci><ci id="S4.SS4.p6.5.m5.1.1.3.cmml" xref="S4.SS4.p6.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p6.5.m5.1c">r_{t}</annotation></semantics></math><span id="S4.SS4.p6.6.6" class="ltx_text" style="color:#000000;">
at each token generation step by comparing it with the ground truth sequence </span><math id="S4.SS4.p6.6.m6.1" class="ltx_Math" alttext="Y^{*}" display="inline"><semantics id="S4.SS4.p6.6.m6.1a"><msup id="S4.SS4.p6.6.m6.1.1" xref="S4.SS4.p6.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.p6.6.m6.1.1.2" xref="S4.SS4.p6.6.m6.1.1.2.cmml">Y</mi><mo mathcolor="#000000" id="S4.SS4.p6.6.m6.1.1.3" xref="S4.SS4.p6.6.m6.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.p6.6.m6.1b"><apply id="S4.SS4.p6.6.m6.1.1.cmml" xref="S4.SS4.p6.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS4.p6.6.m6.1.1.1.cmml" xref="S4.SS4.p6.6.m6.1.1">superscript</csymbol><ci id="S4.SS4.p6.6.m6.1.1.2.cmml" xref="S4.SS4.p6.6.m6.1.1.2">𝑌</ci><times id="S4.SS4.p6.6.m6.1.1.3.cmml" xref="S4.SS4.p6.6.m6.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p6.6.m6.1c">Y^{*}</annotation></semantics></math><span id="S4.SS4.p6.6.7" class="ltx_text" style="color:#000000;">. SCST uses the test-time beam search algorithm to sample hypotheses for reward normalization, assigning positive weights to high-reward hypotheses that outperform the current test-time system and negative weights to low-reward hypotheses. The framework is illustrated in Figure </span><a href="#S4.F12" title="Figure 12 ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">12</span></a><span id="S4.SS4.p6.6.8" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<figure id="S4.F12" class="ltx_figure"><img src="/html/2403.01255/assets/x12.png" id="S4.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="177" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F12.8.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="S4.F12.9.2" class="ltx_text" style="font-size:90%;">SCST sequential decision model of <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">110</span></a>]</cite>.</span></figcaption>
</figure>
<div id="S4.SS4.p7" class="ltx_para">
<p id="S4.SS4.p7.1" class="ltx_p"><span id="S4.SS4.p7.1.1" class="ltx_text" style="color:#000000;">In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p7.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib111" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">111</span></a><span id="S4.SS4.p7.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p7.1.4" class="ltx_text" style="color:#000000;">, the authors developed a </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p7.1.5" class="ltx_text" style="color:#000000;"> framework for speech recognition systems using the policy gradient method. They introduced a </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p7.1.6" class="ltx_text" style="color:#000000;"> method within this framework, incorporating user feedback through hypothesis selection.
Tjandra et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p7.1.7.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib112" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">112</span></a>, <a href="#bib.bib113" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">113</span></a><span id="S4.SS4.p7.1.8.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p7.1.9" class="ltx_text" style="color:#000000;"> also employed policy gradient </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p7.1.10" class="ltx_text" style="color:#000000;"> to train a </span><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a><span id="S4.SS4.p7.1.11" class="ltx_text" style="color:#000000;"> </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p7.1.12" class="ltx_text" style="color:#000000;"> model.
In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p7.1.13.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib114" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">114</span></a><span id="S4.SS4.p7.1.14.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p7.1.15" class="ltx_text" style="color:#000000;">, the authors constructed a generic </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p7.1.16" class="ltx_text" style="color:#000000;">-based AutoML system. This system automatically optimizes per-layer compression ratios for a </span><a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a><span id="S4.SS4.p7.1.17" class="ltx_text" style="color:#000000;"> attention-based end-to-end </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p7.1.18" class="ltx_text" style="color:#000000;"> model, which consists of multiple </span><a href="#Sx1.26.26.26"><abbr href="#Sx1.26.26.26" title="long short term memory" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LSTM</span></span></abbr></a><span id="S4.SS4.p7.1.19" class="ltx_text" style="color:#000000;"> layers. The compression method employed in this work is singular value decomposition (SVD) low-rank matrix factorization. The authors improved this approach by combining iterative compression with AutoML-based rank searching, achieving over 5 x </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p7.1.20" class="ltx_text" style="color:#000000;"> compression without degrading the WER </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p7.1.21.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib115" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">115</span></a><span id="S4.SS4.p7.1.22.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p7.1.23" class="ltx_text" style="color:#000000;">.
Shen et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p7.1.24.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib116" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">116</span></a><span id="S4.SS4.p7.1.25.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p7.1.26" class="ltx_text" style="color:#000000;"> suggested employing </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p7.1.27" class="ltx_text" style="color:#000000;"> to optimize a speech enhancement model based on recognition results, aiming to directly enhance </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p7.1.28" class="ltx_text" style="color:#000000;"> performance. AutoML-based low-rank factorization (LRF) achieves up to 3.7× speedup. In the shade of this, Mehrotra et al. in their work </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p7.1.29.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib115" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">115</span></a><span id="S4.SS4.p7.1.30.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p7.1.31" class="ltx_text" style="color:#000000;"> propose an iterative AutoML-based LRF that employs </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S4.SS4.p7.1.32" class="ltx_text" style="color:#000000;"> for the iterative search, surpassing 5× compression without degrading </span><a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short-plural"><span class="ltx_text" style="font-size:80%;">WER</span>s</span></abbr></a><span id="S4.SS4.p7.1.33" class="ltx_text" style="color:#000000;">, advancing </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p7.1.34" class="ltx_text" style="color:#000000;">. Table </span><a href="#S4.T8" title="Table 8 ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">8</span></a><span id="S4.SS4.p7.1.35" class="ltx_text" style="color:#000000;"> summarizes the recent RL-based </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S4.SS4.p7.1.36" class="ltx_text" style="color:#000000;"> techniques.</span></p>
</div>
<figure id="S4.T8" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:70%;color:#000000;"><span class="ltx_tag ltx_tag_table"><span id="S4.T8.16.3.1" class="ltx_text" style="font-size:129%;">Table 8</span>: </span><span id="S4.T8.4.2" class="ltx_text" style="font-size:129%;">Summary of recent proposed works in RL-based ASR. The symbol (<math id="S4.T8.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T8.3.1.m1.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T8.3.1.m1.1.1" xref="S4.T8.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.3.1.m1.1c"><ci id="S4.T8.3.1.m1.1.1.cmml" xref="S4.T8.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.1.m1.1d">\uparrow</annotation></semantics></math>) result increase, whereas (<math id="S4.T8.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.4.2.m2.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T8.4.2.m2.1.1" xref="S4.T8.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.4.2.m2.1c"><ci id="S4.T8.4.2.m2.1.1.cmml" xref="S4.T8.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.4.2.m2.1d">\downarrow</annotation></semantics></math>) signifies result decrease. In cases where multiple scenarios are examined, only the top-performing outcome is mentioned.</span></figcaption>
<table id="S4.T8.10" class="ltx_tabular ltx_align_middle">
<tr id="S4.T8.10.7" class="ltx_tr">
<td id="S4.T8.10.7.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T8.10.7.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Scheme</span></td>
<td id="S4.T8.10.7.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:85.4pt;">
<span id="S4.T8.10.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.7.2.1.1" class="ltx_p"><span id="S4.T8.10.7.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Model-based</span></span>
</span>
</td>
<td id="S4.T8.10.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T8.10.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.7.3.1.1" class="ltx_p"><span id="S4.T8.10.7.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">ASR Tasks</span></span>
</span>
</td>
<td id="S4.T8.10.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:71.1pt;">
<span id="S4.T8.10.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.7.4.1.1" class="ltx_p"><span id="S4.T8.10.7.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">RL technique</span></span>
</span>
</td>
<td id="S4.T8.10.7.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T8.10.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.7.5.1.1" class="ltx_p"><span id="S4.T8.10.7.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Metric and result</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.5.1" class="ltx_tr">
<td id="S4.T8.5.1.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.5.1.2.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib110" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">110</span></a><span id="S4.T8.5.1.2.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.5.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:85.4pt;">
<span id="S4.T8.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.5.1.3.1.1" class="ltx_p"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a><span id="S4.T8.5.1.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;"> Conformer</span></span>
</span>
</td>
<td id="S4.T8.5.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T8.5.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.5.1.4.1.1" class="ltx_p"><span id="S4.T8.5.1.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR</span></span>
</span>
</td>
<td id="S4.T8.5.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:71.1pt;">
<span id="S4.T8.5.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.5.1.5.1.1" class="ltx_p"><span id="S4.T8.5.1.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Policy gradient</span></span>
</span>
</td>
<td id="S4.T8.5.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:113.8pt;">
<span id="S4.T8.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.5.1.1.1.1" class="ltx_p"><span id="S4.T8.5.1.1.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">8.7%-7.8% WER </span><math id="S4.T8.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.5.1.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="70%" stretchy="false" id="S4.T8.5.1.1.1.1.m1.1.1" xref="S4.T8.5.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.5.1.1.1.1.m1.1b"><ci id="S4.T8.5.1.1.1.1.m1.1.1.cmml" xref="S4.T8.5.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.5.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math><span id="S4.T8.5.1.1.1.1.2" class="ltx_text" style="font-size:70%;color:#000000;"> over Baseline model</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.10.8" class="ltx_tr">
<td id="S4.T8.10.8.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.10.8.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib111" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">111</span></a><span id="S4.T8.10.8.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.10.8.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T8.10.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.8.2.1.1" class="ltx_p"><span id="S4.T8.10.8.2.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">DNN-HMM</span></span>
</span>
</td>
<td id="S4.T8.10.8.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.10.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.8.3.1.1" class="ltx_p"><span id="S4.T8.10.8.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR for AM</span></span>
</span>
</td>
<td id="S4.T8.10.8.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T8.10.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.8.4.1.1" class="ltx_p"><span id="S4.T8.10.8.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Policy gradient</span></span>
</span>
</td>
<td id="S4.T8.10.8.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.10.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.8.5.1.1" class="ltx_p"><span id="S4.T8.10.8.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">WER=23.82-25.43%</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.10.9" class="ltx_tr">
<td id="S4.T8.10.9.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.10.9.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib112" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">112</span></a><span id="S4.T8.10.9.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.10.9.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T8.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.9.2.1.1" class="ltx_p"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T8.10.9.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.9.3.1.1" class="ltx_p"><span id="S4.T8.10.9.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR FOR am</span></span>
</span>
</td>
<td id="S4.T8.10.9.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T8.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.9.4.1.1" class="ltx_p"><span id="S4.T8.10.9.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Policy gradient</span></span>
</span>
</td>
<td id="S4.T8.10.9.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.9.5.1.1" class="ltx_p"><span id="S4.T8.10.9.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">CER=6.10%</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.10.10" class="ltx_tr">
<td id="S4.T8.10.10.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.10.10.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib113" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">113</span></a><span id="S4.T8.10.10.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.10.10.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T8.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.10.2.1.1" class="ltx_p"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T8.10.10.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.10.3.1.1" class="ltx_p"><span id="S4.T8.10.10.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR for AM</span></span>
</span>
</td>
<td id="S4.T8.10.10.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T8.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.10.4.1.1" class="ltx_p"><span id="S4.T8.10.10.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Policy gradient</span></span>
</span>
</td>
<td id="S4.T8.10.10.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.10.5.1.1" class="ltx_p"><span id="S4.T8.10.10.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">CER=6.10%</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.6.2" class="ltx_tr">
<td id="S4.T8.6.2.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.6.2.2.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib114" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">114</span></a><span id="S4.T8.6.2.2.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.6.2.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T8.6.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.6.2.3.1.1" class="ltx_p"><span id="S4.T8.6.2.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">End-to-end encoder-attention-
decoder</span></span>
</span>
</td>
<td id="S4.T8.6.2.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.6.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.6.2.4.1.1" class="ltx_p"><span id="S4.T8.6.2.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR Model compression for AM</span></span>
</span>
</td>
<td id="S4.T8.6.2.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T8.6.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.6.2.5.1.1" class="ltx_p"><span id="S4.T8.6.2.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Policy gradient</span></span>
</span>
</td>
<td id="S4.T8.6.2.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.6.2.1.1.1" class="ltx_p"><span id="S4.T8.6.2.1.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Up to </span><math id="S4.T8.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T8.6.2.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="70%" id="S4.T8.6.2.1.1.1.m1.1.1" xref="S4.T8.6.2.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T8.6.2.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T8.6.2.1.1.1.m1.1.1.cmml" xref="S4.T8.6.2.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.6.2.1.1.1.m1.1c">\sim</annotation></semantics></math><span id="S4.T8.6.2.1.1.1.2" class="ltx_text" style="font-size:70%;color:#000000;">3x compression; WER=8.06%</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.7.3" class="ltx_tr">
<td id="S4.T8.7.3.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.7.3.2.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib115" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">115</span></a><span id="S4.T8.7.3.2.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.7.3.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T8.7.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.3.3.1.1" class="ltx_p"><span id="S4.T8.7.3.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">End-to-end encoder-attention-
decoder</span></span>
</span>
</td>
<td id="S4.T8.7.3.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.7.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.3.4.1.1" class="ltx_p"><span id="S4.T8.7.3.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR Model compression for AM</span></span>
</span>
</td>
<td id="S4.T8.7.3.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T8.7.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.3.5.1.1" class="ltx_p"><span id="S4.T8.7.3.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Policy gradient</span></span>
</span>
</td>
<td id="S4.T8.7.3.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.7.3.1.1.1" class="ltx_p"><span id="S4.T8.7.3.1.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Up to </span><math id="S4.T8.7.3.1.1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.T8.7.3.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="70%" id="S4.T8.7.3.1.1.1.m1.1.1" xref="S4.T8.7.3.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T8.7.3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T8.7.3.1.1.1.m1.1.1.cmml" xref="S4.T8.7.3.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.7.3.1.1.1.m1.1c">\sim</annotation></semantics></math><span id="S4.T8.7.3.1.1.1.2" class="ltx_text" style="font-size:70%;color:#000000;">5x compression; WER=8.19%</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.8.4" class="ltx_tr">
<td id="S4.T8.8.4.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.8.4.2.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib116" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">116</span></a><span id="S4.T8.8.4.2.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.8.4.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T8.8.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.8.4.3.1.1" class="ltx_p"><span id="S4.T8.8.4.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">CD-DNN-HMM AM &amp; SRI LM</span></span>
</span>
</td>
<td id="S4.T8.8.4.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.8.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.8.4.4.1.1" class="ltx_p"><span id="S4.T8.8.4.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Speech enhancement for ASR for AM and LM</span></span>
</span>
</td>
<td id="S4.T8.8.4.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T8.8.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.8.4.5.1.1" class="ltx_p"><span id="S4.T8.8.4.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Q-learning</span></span>
</span>
</td>
<td id="S4.T8.8.4.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.8.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.8.4.1.1.1" class="ltx_p"><span id="S4.T8.8.4.1.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">12.40% and 19.23% CER </span><math id="S4.T8.8.4.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.8.4.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="70%" stretchy="false" id="S4.T8.8.4.1.1.1.m1.1.1" xref="S4.T8.8.4.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.8.4.1.1.1.m1.1b"><ci id="S4.T8.8.4.1.1.1.m1.1.1.cmml" xref="S4.T8.8.4.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.8.4.1.1.1.m1.1c">\downarrow</annotation></semantics></math><span id="S4.T8.8.4.1.1.1.2" class="ltx_text" style="font-size:70%;color:#000000;"> at 5 and 0 dB SNR conditions.</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.9.5" class="ltx_tr">
<td id="S4.T8.9.5.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.9.5.2.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib117" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">117</span></a><span id="S4.T8.9.5.2.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.9.5.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T8.9.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.9.5.3.1.1" class="ltx_p"><span id="S4.T8.9.5.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">LSTM</span></span>
</span>
</td>
<td id="S4.T8.9.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.9.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.9.5.4.1.1" class="ltx_p"><span id="S4.T8.9.5.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR for dialogue state tracking</span></span>
</span>
</td>
<td id="S4.T8.9.5.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T8.9.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.9.5.5.1.1" class="ltx_p"><span id="S4.T8.9.5.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">DQN</span></span>
</span>
</td>
<td id="S4.T8.9.5.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.9.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.9.5.1.1.1" class="ltx_p"><span id="S4.T8.9.5.1.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Acc= 3.1%</span><math id="S4.T8.9.5.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T8.9.5.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="70%" stretchy="false" id="S4.T8.9.5.1.1.1.m1.1.1" xref="S4.T8.9.5.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.9.5.1.1.1.m1.1b"><ci id="S4.T8.9.5.1.1.1.m1.1.1.cmml" xref="S4.T8.9.5.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.9.5.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T8.10.11" class="ltx_tr">
<td id="S4.T8.10.11.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.10.11.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib118" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">118</span></a><span id="S4.T8.10.11.1.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.10.11.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:85.4pt;">
<span id="S4.T8.10.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.11.2.1.1" class="ltx_p"><a href="#Sx1.39.39.39"><abbr href="#Sx1.39.39.39" title="sequence-to-sequence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">S2S</span></span></abbr></a></span>
</span>
</td>
<td id="S4.T8.10.11.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.10.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.11.3.1.1" class="ltx_p"><span id="S4.T8.10.11.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR for AM</span></span>
</span>
</td>
<td id="S4.T8.10.11.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:71.1pt;">
<span id="S4.T8.10.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.11.4.1.1" class="ltx_p"><span id="S4.T8.10.11.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Policy gradient</span></span>
</span>
</td>
<td id="S4.T8.10.11.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:113.8pt;">
<span id="S4.T8.10.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.11.5.1.1" class="ltx_p"><span id="S4.T8.10.11.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">CER=8.7%</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.10.6" class="ltx_tr">
<td id="S4.T8.10.6.2" class="ltx_td ltx_align_left ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T8.10.6.2.1.1" class="ltx_text" style="font-size:70%;color:#000000;">[</span><a href="#bib.bib119" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">119</span></a><span id="S4.T8.10.6.2.2.2" class="ltx_text" style="font-size:70%;color:#000000;">]</span></cite></td>
<td id="S4.T8.10.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:85.4pt;">
<span id="S4.T8.10.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.6.3.1.1" class="ltx_p"><span id="S4.T8.10.6.3.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Wav2vec 2.0</span></span>
</span>
</td>
<td id="S4.T8.10.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:113.8pt;">
<span id="S4.T8.10.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.6.4.1.1" class="ltx_p"><span id="S4.T8.10.6.4.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Improve ASR for AM</span></span>
</span>
</td>
<td id="S4.T8.10.6.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:71.1pt;">
<span id="S4.T8.10.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.6.5.1.1" class="ltx_p"><span id="S4.T8.10.6.5.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">Policy gradient</span></span>
</span>
</td>
<td id="S4.T8.10.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b" style="width:113.8pt;">
<span id="S4.T8.10.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.10.6.1.1.1" class="ltx_p"><span id="S4.T8.10.6.1.1.1.1" class="ltx_text" style="font-size:70%;color:#000000;">4% WER </span><math id="S4.T8.10.6.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.10.6.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="70%" stretchy="false" id="S4.T8.10.6.1.1.1.m1.1.1" xref="S4.T8.10.6.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.10.6.1.1.1.m1.1b"><ci id="S4.T8.10.6.1.1.1.m1.1.1.cmml" xref="S4.T8.10.6.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.10.6.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S4.SS4.p8" class="ltx_para">
<p id="S4.SS4.p8.1" class="ltx_p"><span id="S4.SS4.p8.1.1" class="ltx_text" style="color:#000000;">DTL for acoustic models (AMs)
Two types of deep learning-based AMs commonly used in ASR are the end-to-end model and the layered deep neural network-hidden Markov model (DNN-HMM) model. The DNN component is responsible for extracting high-level features, such as MFCCs and HMM lexical sequences, from acoustic signals. These features are then decoded into transcripts. The DNN takes acoustic characteristics as input and produces context-dependent lexical units (tri-phonemes) that are used as input for the downstream HMM component.</span></p>
</div>
<div id="S4.SS4.p9" class="ltx_para">
<p id="S4.SS4.p9.1" class="ltx_p"><span id="S4.SS4.p9.1.1" class="ltx_text" style="color:#000000;">In contrast, the end-to-end model is a DNN-based technique that directly takes acoustic characteristics (features) as input and outputs the recognition rate without the need for separate components like the DNN and HMM. A typical end-to-end framework for voice recognition is illustrated in Figure </span><a href="#S4.F13" title="Figure 13 ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">13</span></a><span id="S4.SS4.p9.1.2" class="ltx_text" style="color:#000000;">. The neural network in this framework generates embeddings from the input features, which are then passed through a stack of recurrent layers. These recurrent layers analyze patterns based on prior and current input information to produce the final output. The network is trained using back-propagation with the CTC loss </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p9.1.3.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">mridha2021study</span><span id="S4.SS4.p9.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.p9.1.5" class="ltx_text" style="color:#000000;">. Regarding domain transfer learning (DTL), three main strategies have been commonly employed with AMs.</span></p>
</div>
<figure id="S4.F13" class="ltx_figure"><img src="/html/2403.01255/assets/end2end.pdf" id="S4.F13.g1" class="ltx_graphics ltx_centering" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F13.7.1.1" class="ltx_text" style="font-size:90%;">Figure 13</span>: </span><span id="S4.F13.8.2" class="ltx_text" style="font-size:90%;"> An example of end-to-end source model for DTL-based ASR <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mridha2021study</span>]</cite>. </span></figcaption>
</figure>
<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Feature normalisation based-DTL</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p"><span id="S4.SS4.SSS1.p1.1.1" class="ltx_text" style="color:#000000;">The concept behind linear transformation is to normalize speech characteristics through a linear mapping process. This involves adding a transformation network or layer to an existing network. The transformation network is an effective method for adapting neural networks. Typically, the last hidden layer is designed to act as a bottleneck, reducing the number of parameters to be adjusted by using fewer neurons. Figure </span><a href="#S4.F14" title="Figure 14 ‣ 4.4.1 Feature normalisation based-DTL ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">14</span></a><span id="S4.SS4.SSS1.p1.1.2" class="ltx_text" style="color:#000000;"> illustrates this architecture. The transformation network can be either a linear input network or a linear output network.</span></p>
</div>
<figure id="S4.F14" class="ltx_figure"><img src="/html/2403.01255/assets/fig05.pdf" id="S4.F14.g1" class="ltx_graphics ltx_centering" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F14.4.1.1" class="ltx_text" style="font-size:90%;">Figure 14</span>: </span><span id="S4.F14.5.2" class="ltx_text" style="font-size:90%;">The basics of transformation in DTL involve estimating the weights connected to the links within the dashed rectangles, while leaving the remaining weights unchanged. In the case of mono-task DTL, feature normalization is applied as shown in Figure (a). For multi-task DTL, feature normalization is also performed, as illustrated in Figure (b).</span></figcaption>
</figure>
<div id="S4.SS4.SSS1.p2" class="ltx_para">
<p id="S4.SS4.SSS1.p2.4" class="ltx_p"><span id="S4.SS4.SSS1.p2.4.1" class="ltx_text" style="color:#000000;">Assuming that the last hidden network (LHN) functions as a feature extractor and the output layer serves as a discriminative source model (</span><math id="S4.SS4.SSS1.p2.1.m1.1" class="ltx_Math" alttext="M_{S}" display="inline"><semantics id="S4.SS4.SSS1.p2.1.m1.1a"><msub id="S4.SS4.SSS1.p2.1.m1.1.1" xref="S4.SS4.SSS1.p2.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS1.p2.1.m1.1.1.2" xref="S4.SS4.SSS1.p2.1.m1.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS1.p2.1.m1.1.1.3" xref="S4.SS4.SSS1.p2.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.1.m1.1b"><apply id="S4.SS4.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.1.m1.1.1.1.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p2.1.m1.1.1.2.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1.2">𝑀</ci><ci id="S4.SS4.SSS1.p2.1.m1.1.1.3.cmml" xref="S4.SS4.SSS1.p2.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.1.m1.1c">M_{S}</annotation></semantics></math><span id="S4.SS4.SSS1.p2.4.2" class="ltx_text" style="color:#000000;">), the weights of the linear transformation matrix </span><math id="S4.SS4.SSS1.p2.2.m2.1" class="ltx_Math" alttext="W_{L}" display="inline"><semantics id="S4.SS4.SSS1.p2.2.m2.1a"><msub id="S4.SS4.SSS1.p2.2.m2.1.1" xref="S4.SS4.SSS1.p2.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS1.p2.2.m2.1.1.2" xref="S4.SS4.SSS1.p2.2.m2.1.1.2.cmml">W</mi><mi mathcolor="#000000" id="S4.SS4.SSS1.p2.2.m2.1.1.3" xref="S4.SS4.SSS1.p2.2.m2.1.1.3.cmml">L</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.2.m2.1b"><apply id="S4.SS4.SSS1.p2.2.m2.1.1.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.2.m2.1.1.1.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p2.2.m2.1.1.2.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1.2">𝑊</ci><ci id="S4.SS4.SSS1.p2.2.m2.1.1.3.cmml" xref="S4.SS4.SSS1.p2.2.m2.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.2.m2.1c">W_{L}</annotation></semantics></math><span id="S4.SS4.SSS1.p2.4.3" class="ltx_text" style="color:#000000;"> in the output layer correspond to the parameters of the target model, </span><math id="S4.SS4.SSS1.p2.3.m3.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.SS4.SSS1.p2.3.m3.1a"><msub id="S4.SS4.SSS1.p2.3.m3.1.1" xref="S4.SS4.SSS1.p2.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS1.p2.3.m3.1.1.2" xref="S4.SS4.SSS1.p2.3.m3.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS1.p2.3.m3.1.1.3" xref="S4.SS4.SSS1.p2.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.3.m3.1b"><apply id="S4.SS4.SSS1.p2.3.m3.1.1.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.3.m3.1.1.1.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p2.3.m3.1.1.2.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1.2">𝑀</ci><ci id="S4.SS4.SSS1.p2.3.m3.1.1.3.cmml" xref="S4.SS4.SSS1.p2.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.3.m3.1c">M_{T}</annotation></semantics></math><span id="S4.SS4.SSS1.p2.4.4" class="ltx_text" style="color:#000000;">. The representation of </span><math id="S4.SS4.SSS1.p2.4.m4.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.SS4.SSS1.p2.4.m4.1a"><msub id="S4.SS4.SSS1.p2.4.m4.1.1" xref="S4.SS4.SSS1.p2.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS1.p2.4.m4.1.1.2" xref="S4.SS4.SSS1.p2.4.m4.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS1.p2.4.m4.1.1.3" xref="S4.SS4.SSS1.p2.4.m4.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p2.4.m4.1b"><apply id="S4.SS4.SSS1.p2.4.m4.1.1.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p2.4.m4.1.1.1.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p2.4.m4.1.1.2.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1.2">𝑀</ci><ci id="S4.SS4.SSS1.p2.4.m4.1.1.3.cmml" xref="S4.SS4.SSS1.p2.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p2.4.m4.1c">M_{T}</annotation></semantics></math><span id="S4.SS4.SSS1.p2.4.5" class="ltx_text" style="color:#000000;"> can be expressed as follows </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS1.p2.4.6.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2015maximum</span><span id="S4.SS4.SSS1.p2.4.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS1.p2.4.8" class="ltx_text" style="color:#000000;">:</span></p>
</div>
<div id="S4.SS4.SSS1.p3" class="ltx_para">
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E4.m1.1" class="ltx_Math" alttext="\mathrm{M_{T}=softmax(W_{L}M_{S})}." display="block"><semantics id="S4.E4.m1.1a"><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><msub id="S4.E4.m1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.3.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.E4.m1.1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.1.3.2.cmml">M</mi><mi mathcolor="#000000" mathvariant="normal" id="S4.E4.m1.1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.1.3.3.cmml">T</mi></msub><mo mathcolor="#000000" id="S4.E4.m1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.2.cmml">=</mo><mrow id="S4.E4.m1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S4.E4.m1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.3.cmml">softmax</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E4.m1.1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.E4.m1.1.1.1.1.1.1.1.1.2.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mi mathcolor="#000000" mathvariant="normal" id="S4.E4.m1.1.1.1.1.1.1.1.1.2.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml">L</mi></msub><mo lspace="0em" rspace="0em" id="S4.E4.m1.1.1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="S4.E4.m1.1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.E4.m1.1.1.1.1.1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml">M</mi><mi mathcolor="#000000" mathvariant="normal" id="S4.E4.m1.1.1.1.1.1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml">S</mi></msub></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" mathcolor="#000000" id="S4.E4.m1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.1b"><apply id="S4.E4.m1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><eq id="S4.E4.m1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.2"></eq><apply id="S4.E4.m1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.3.2">M</ci><ci id="S4.E4.m1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.1.3.3">T</ci></apply><apply id="S4.E4.m1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1"><times id="S4.E4.m1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.2"></times><ci id="S4.E4.m1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.3">softmax</ci><apply id="S4.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1"><times id="S4.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.1"></times><apply id="S4.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.2">W</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.2.3">L</ci></apply><apply id="S4.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.2">M</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.1.3.3">S</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.1c">\mathrm{M_{T}=softmax(W_{L}M_{S})}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS4.SSS1.p3.3" class="ltx_p"><span id="S4.SS4.SSS1.p3.3.1" class="ltx_text" style="color:#000000;">The activation of the last hidden layer in </span><math id="S4.SS4.SSS1.p3.1.m1.1" class="ltx_Math" alttext="M_{S}" display="inline"><semantics id="S4.SS4.SSS1.p3.1.m1.1a"><msub id="S4.SS4.SSS1.p3.1.m1.1.1" xref="S4.SS4.SSS1.p3.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS1.p3.1.m1.1.1.2" xref="S4.SS4.SSS1.p3.1.m1.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS1.p3.1.m1.1.1.3" xref="S4.SS4.SSS1.p3.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p3.1.m1.1b"><apply id="S4.SS4.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p3.1.m1.1.1.1.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p3.1.m1.1.1.2.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1.2">𝑀</ci><ci id="S4.SS4.SSS1.p3.1.m1.1.1.3.cmml" xref="S4.SS4.SSS1.p3.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p3.1.m1.1c">M_{S}</annotation></semantics></math><span id="S4.SS4.SSS1.p3.3.2" class="ltx_text" style="color:#000000;"> can serve as the extracted feature representation for the hidden layers in </span><math id="S4.SS4.SSS1.p3.2.m2.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.SS4.SSS1.p3.2.m2.1a"><msub id="S4.SS4.SSS1.p3.2.m2.1.1" xref="S4.SS4.SSS1.p3.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS1.p3.2.m2.1.1.2" xref="S4.SS4.SSS1.p3.2.m2.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS1.p3.2.m2.1.1.3" xref="S4.SS4.SSS1.p3.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p3.2.m2.1b"><apply id="S4.SS4.SSS1.p3.2.m2.1.1.cmml" xref="S4.SS4.SSS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p3.2.m2.1.1.1.cmml" xref="S4.SS4.SSS1.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p3.2.m2.1.1.2.cmml" xref="S4.SS4.SSS1.p3.2.m2.1.1.2">𝑀</ci><ci id="S4.SS4.SSS1.p3.2.m2.1.1.3.cmml" xref="S4.SS4.SSS1.p3.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p3.2.m2.1c">M_{T}</annotation></semantics></math><span id="S4.SS4.SSS1.p3.3.3" class="ltx_text" style="color:#000000;">. Transforming the model parameters using a transformation matrix </span><math id="S4.SS4.SSS1.p3.3.m3.1" class="ltx_Math" alttext="W_{LHN}" display="inline"><semantics id="S4.SS4.SSS1.p3.3.m3.1a"><msub id="S4.SS4.SSS1.p3.3.m3.1.1" xref="S4.SS4.SSS1.p3.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS1.p3.3.m3.1.1.2" xref="S4.SS4.SSS1.p3.3.m3.1.1.2.cmml">W</mi><mrow id="S4.SS4.SSS1.p3.3.m3.1.1.3" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS1.p3.3.m3.1.1.3.2" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p3.3.m3.1.1.3.1" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.1.cmml">​</mo><mi mathcolor="#000000" id="S4.SS4.SSS1.p3.3.m3.1.1.3.3" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.3.cmml">H</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS1.p3.3.m3.1.1.3.1a" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.1.cmml">​</mo><mi mathcolor="#000000" id="S4.SS4.SSS1.p3.3.m3.1.1.3.4" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.4.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS1.p3.3.m3.1b"><apply id="S4.SS4.SSS1.p3.3.m3.1.1.cmml" xref="S4.SS4.SSS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS1.p3.3.m3.1.1.1.cmml" xref="S4.SS4.SSS1.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.SSS1.p3.3.m3.1.1.2.cmml" xref="S4.SS4.SSS1.p3.3.m3.1.1.2">𝑊</ci><apply id="S4.SS4.SSS1.p3.3.m3.1.1.3.cmml" xref="S4.SS4.SSS1.p3.3.m3.1.1.3"><times id="S4.SS4.SSS1.p3.3.m3.1.1.3.1.cmml" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.1"></times><ci id="S4.SS4.SSS1.p3.3.m3.1.1.3.2.cmml" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.2">𝐿</ci><ci id="S4.SS4.SSS1.p3.3.m3.1.1.3.3.cmml" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.3">𝐻</ci><ci id="S4.SS4.SSS1.p3.3.m3.1.1.3.4.cmml" xref="S4.SS4.SSS1.p3.3.m3.1.1.3.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS1.p3.3.m3.1c">W_{LHN}</annotation></semantics></math><span id="S4.SS4.SSS1.p3.3.4" class="ltx_text" style="color:#000000;"> to generate an adapted set of model parameters is equivalent to incorporating an extended last hidden layer after the existing last hidden layer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS1.p3.3.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2015maximum</span><span id="S4.SS4.SSS1.p3.3.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS1.p3.3.7" class="ltx_text" style="color:#000000;">:</span></p>
</div>
<div id="S4.SS4.SSS1.p4" class="ltx_para">
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E5.m1.1" class="ltx_Math" alttext="\mathrm{M_{T}=softmax(W_{LHN}W_{L}M_{S})}." display="block"><semantics id="S4.E5.m1.1a"><mrow id="S4.E5.m1.1.1.1" xref="S4.E5.m1.1.1.1.1.cmml"><mrow id="S4.E5.m1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.cmml"><msub id="S4.E5.m1.1.1.1.1.3" xref="S4.E5.m1.1.1.1.1.3.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.E5.m1.1.1.1.1.3.2" xref="S4.E5.m1.1.1.1.1.3.2.cmml">M</mi><mi mathcolor="#000000" mathvariant="normal" id="S4.E5.m1.1.1.1.1.3.3" xref="S4.E5.m1.1.1.1.1.3.3.cmml">T</mi></msub><mo mathcolor="#000000" id="S4.E5.m1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.2.cmml">=</mo><mrow id="S4.E5.m1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S4.E5.m1.1.1.1.1.1.3" xref="S4.E5.m1.1.1.1.1.1.3.cmml">softmax</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E5.m1.1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.E5.m1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E5.m1.1.1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E5.m1.1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.E5.m1.1.1.1.1.1.1.1.1.2.2" xref="S4.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mi mathcolor="#000000" id="S4.E5.m1.1.1.1.1.1.1.1.1.2.3" xref="S4.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml">LHN</mi></msub><mo lspace="0em" rspace="0em" id="S4.E5.m1.1.1.1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="S4.E5.m1.1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.1.1.1.1.1.1.1.1.3.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.E5.m1.1.1.1.1.1.1.1.1.3.2" xref="S4.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml">W</mi><mi mathcolor="#000000" mathvariant="normal" id="S4.E5.m1.1.1.1.1.1.1.1.1.3.3" xref="S4.E5.m1.1.1.1.1.1.1.1.1.3.3.cmml">L</mi></msub><mo lspace="0em" rspace="0em" id="S4.E5.m1.1.1.1.1.1.1.1.1.1a" xref="S4.E5.m1.1.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="S4.E5.m1.1.1.1.1.1.1.1.1.4" xref="S4.E5.m1.1.1.1.1.1.1.1.1.4.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.E5.m1.1.1.1.1.1.1.1.1.4.2" xref="S4.E5.m1.1.1.1.1.1.1.1.1.4.2.cmml">M</mi><mi mathcolor="#000000" mathvariant="normal" id="S4.E5.m1.1.1.1.1.1.1.1.1.4.3" xref="S4.E5.m1.1.1.1.1.1.1.1.1.4.3.cmml">S</mi></msub></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E5.m1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" mathcolor="#000000" id="S4.E5.m1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.1b"><apply id="S4.E5.m1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1"><eq id="S4.E5.m1.1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.1.2"></eq><apply id="S4.E5.m1.1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.1.1.3.1.cmml" xref="S4.E5.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E5.m1.1.1.1.1.3.2.cmml" xref="S4.E5.m1.1.1.1.1.3.2">M</ci><ci id="S4.E5.m1.1.1.1.1.3.3.cmml" xref="S4.E5.m1.1.1.1.1.3.3">T</ci></apply><apply id="S4.E5.m1.1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1"><times id="S4.E5.m1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.1.1.2"></times><ci id="S4.E5.m1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.1.1.3">softmax</ci><apply id="S4.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1"><times id="S4.E5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.1"></times><apply id="S4.E5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.2.2">W</ci><ci id="S4.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.2.3">LHN</ci></apply><apply id="S4.E5.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.3.2">W</ci><ci id="S4.E5.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.3.3">L</ci></apply><apply id="S4.E5.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S4.E5.m1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.4.2">M</ci><ci id="S4.E5.m1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1.1.4.3">S</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.1c">\mathrm{M_{T}=softmax(W_{LHN}W_{L}M_{S})}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS4.SSS1.p5" class="ltx_para">
<p id="S4.SS4.SSS1.p5.1" class="ltx_p"><span id="S4.SS4.SSS1.p5.1.1" class="ltx_text" style="color:#000000;">Several ASR research studies have utilized linear transformation strategies to improve performance. In one example </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS1.p5.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">elaraby2016deep</span><span id="S4.SS4.SSS1.p5.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS1.p5.1.4" class="ltx_text" style="color:#000000;">, the authors aimed to enhance a computer-aided language learner (CAPL) system for teaching Arabic pronunciation for Quran recitation regulations. They implemented various improvements, including speaker adaptive training (SAT), integrating a hybrid DNN-HMM model, combining the hybrid DNN with minimum phone error (MPE), and using a grammar-based decoding graph during testing.
Another study </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS1.p5.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">mimura2016joint</span><span id="S4.SS4.SSS1.p5.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS1.p5.1.7" class="ltx_text" style="color:#000000;"> employed a multi-target learning approach to optimize the output of a denoising auto-encoder (DAE) and the input of a DNN. The DAE was trained in the first stage to reduce input-related errors propagated to the DNN. Then, a unified network of DAE and DNN was fine-tuned for phone state ASR, with an additional target of input voice augmentation applied to the DAE.
Additionally, in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS1.p5.1.8.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2017approaches</span><span id="S4.SS4.SSS1.p5.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS1.p5.1.10" class="ltx_text" style="color:#000000;">, an adaptation layer was introduced for fine-tuning, and non-linearity was incorporated to learn a more complex function than a linear transformation in the softmax layer. During fine-tuning, adjustments were made to the cluster softmax and NNadapt layers while keeping the other layers unchanged.
Table </span><a href="#S4.T6" title="Table 6 ‣ 4.2.2 Language domain ‣ 4.2 TL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S4.SS4.SSS1.p5.1.11" class="ltx_text" style="color:#000000;"> provides a summary of additional schemes that employ linear transformation techniques, along with their performance details.</span></p>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>Conservative training for DTL</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.6" class="ltx_p"><span id="S4.SS4.SSS2.p1.6.1" class="ltx_text" style="color:#000000;">The conservative training approach is commonly used for accent adaptation in ASR. It is an efficient method that requires only a limited amount of spoken data to achieve satisfactory results. However, it can lead to an excessive number of parameters, which may disrupt the model’s structure. To address this, KL-Divergence (KLD) is widely employed as a DNN-based DTL algorithm for ASR. KLD regularization provides a mathematical framework for DL training, aiming to minimize the loss and make the output distributions of the source model </span><math id="S4.SS4.SSS2.p1.1.m1.1" class="ltx_Math" alttext="M_{S}" display="inline"><semantics id="S4.SS4.SSS2.p1.1.m1.1a"><msub id="S4.SS4.SSS2.p1.1.m1.1.1" xref="S4.SS4.SSS2.p1.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.1.m1.1.1.2" xref="S4.SS4.SSS2.p1.1.m1.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.1.m1.1.1.3" xref="S4.SS4.SSS2.p1.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.1.m1.1b"><apply id="S4.SS4.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p1.1.m1.1.1.1.cmml" xref="S4.SS4.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p1.1.m1.1.1.2.cmml" xref="S4.SS4.SSS2.p1.1.m1.1.1.2">𝑀</ci><ci id="S4.SS4.SSS2.p1.1.m1.1.1.3.cmml" xref="S4.SS4.SSS2.p1.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.1.m1.1c">M_{S}</annotation></semantics></math><span id="S4.SS4.SSS2.p1.6.2" class="ltx_text" style="color:#000000;"> and target model </span><math id="S4.SS4.SSS2.p1.2.m2.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.SS4.SSS2.p1.2.m2.1a"><msub id="S4.SS4.SSS2.p1.2.m2.1.1" xref="S4.SS4.SSS2.p1.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.2.m2.1.1.2" xref="S4.SS4.SSS2.p1.2.m2.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.2.m2.1.1.3" xref="S4.SS4.SSS2.p1.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.2.m2.1b"><apply id="S4.SS4.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS4.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p1.2.m2.1.1.1.cmml" xref="S4.SS4.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p1.2.m2.1.1.2.cmml" xref="S4.SS4.SSS2.p1.2.m2.1.1.2">𝑀</ci><ci id="S4.SS4.SSS2.p1.2.m2.1.1.3.cmml" xref="S4.SS4.SSS2.p1.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.2.m2.1c">M_{T}</annotation></semantics></math><span id="S4.SS4.SSS2.p1.6.3" class="ltx_text" style="color:#000000;"> more similar. The KL-divergence prevents overfitting and helps to keep the adapted </span><math id="S4.SS4.SSS2.p1.3.m3.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.SS4.SSS2.p1.3.m3.1a"><msub id="S4.SS4.SSS2.p1.3.m3.1.1" xref="S4.SS4.SSS2.p1.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.3.m3.1.1.2" xref="S4.SS4.SSS2.p1.3.m3.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.3.m3.1.1.3" xref="S4.SS4.SSS2.p1.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.3.m3.1b"><apply id="S4.SS4.SSS2.p1.3.m3.1.1.cmml" xref="S4.SS4.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p1.3.m3.1.1.1.cmml" xref="S4.SS4.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p1.3.m3.1.1.2.cmml" xref="S4.SS4.SSS2.p1.3.m3.1.1.2">𝑀</ci><ci id="S4.SS4.SSS2.p1.3.m3.1.1.3.cmml" xref="S4.SS4.SSS2.p1.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.3.m3.1c">M_{T}</annotation></semantics></math><span id="S4.SS4.SSS2.p1.6.4" class="ltx_text" style="color:#000000;"> close to the domain of </span><math id="S4.SS4.SSS2.p1.4.m4.1" class="ltx_Math" alttext="M_{S}" display="inline"><semantics id="S4.SS4.SSS2.p1.4.m4.1a"><msub id="S4.SS4.SSS2.p1.4.m4.1.1" xref="S4.SS4.SSS2.p1.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.4.m4.1.1.2" xref="S4.SS4.SSS2.p1.4.m4.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.4.m4.1.1.3" xref="S4.SS4.SSS2.p1.4.m4.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.4.m4.1b"><apply id="S4.SS4.SSS2.p1.4.m4.1.1.cmml" xref="S4.SS4.SSS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p1.4.m4.1.1.1.cmml" xref="S4.SS4.SSS2.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p1.4.m4.1.1.2.cmml" xref="S4.SS4.SSS2.p1.4.m4.1.1.2">𝑀</ci><ci id="S4.SS4.SSS2.p1.4.m4.1.1.3.cmml" xref="S4.SS4.SSS2.p1.4.m4.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.4.m4.1c">M_{S}</annotation></semantics></math><span id="S4.SS4.SSS2.p1.6.5" class="ltx_text" style="color:#000000;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS2.p1.6.6.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib89" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">89</span></a>, <a href="#bib.bib90" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">90</span></a><span id="S4.SS4.SSS2.p1.6.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS2.p1.6.8" class="ltx_text" style="color:#000000;">. In terms of model-based DTL with KLD-regularization, assuming the loss functions for training DNNs in the source and target domains are </span><math id="S4.SS4.SSS2.p1.5.m5.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S4.SS4.SSS2.p1.5.m5.1a"><msub id="S4.SS4.SSS2.p1.5.m5.1.1" xref="S4.SS4.SSS2.p1.5.m5.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.5.m5.1.1.2" xref="S4.SS4.SSS2.p1.5.m5.1.1.2.cmml">𝔻</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.5.m5.1.1.3" xref="S4.SS4.SSS2.p1.5.m5.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.5.m5.1b"><apply id="S4.SS4.SSS2.p1.5.m5.1.1.cmml" xref="S4.SS4.SSS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p1.5.m5.1.1.1.cmml" xref="S4.SS4.SSS2.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p1.5.m5.1.1.2.cmml" xref="S4.SS4.SSS2.p1.5.m5.1.1.2">𝔻</ci><ci id="S4.SS4.SSS2.p1.5.m5.1.1.3.cmml" xref="S4.SS4.SSS2.p1.5.m5.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.5.m5.1c">\mathbb{D}_{S}</annotation></semantics></math><span id="S4.SS4.SSS2.p1.6.9" class="ltx_text" style="color:#000000;"> and </span><math id="S4.SS4.SSS2.p1.6.m6.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S4.SS4.SSS2.p1.6.m6.1a"><msub id="S4.SS4.SSS2.p1.6.m6.1.1" xref="S4.SS4.SSS2.p1.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.6.m6.1.1.2" xref="S4.SS4.SSS2.p1.6.m6.1.1.2.cmml">𝔻</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p1.6.m6.1.1.3" xref="S4.SS4.SSS2.p1.6.m6.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.6.m6.1b"><apply id="S4.SS4.SSS2.p1.6.m6.1.1.cmml" xref="S4.SS4.SSS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p1.6.m6.1.1.1.cmml" xref="S4.SS4.SSS2.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p1.6.m6.1.1.2.cmml" xref="S4.SS4.SSS2.p1.6.m6.1.1.2">𝔻</ci><ci id="S4.SS4.SSS2.p1.6.m6.1.1.3.cmml" xref="S4.SS4.SSS2.p1.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.6.m6.1c">\mathbb{D}_{T}</annotation></semantics></math><span id="S4.SS4.SSS2.p1.6.10" class="ltx_text" style="color:#000000;">, respectively, the conservative approach can be summarized mathematically as follows </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS2.p1.6.11.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib89" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">89</span></a>, <a href="#bib.bib90" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">90</span></a><span id="S4.SS4.SSS2.p1.6.12.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS2.p1.6.13" class="ltx_text" style="color:#000000;">:</span></p>
</div>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<table id="S4.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S4.E6.m1.1" class="ltx_Math" alttext="\mathbb{D}_{T}^{KLD}=(1-\rho)\mathbb{D}_{S}+\frac{\rho}{N}\sum P_{S}(x_{T}/x_{T})logP_{T}(y_{T}/x_{T})," display="block"><semantics id="S4.E6.m1.1a"><mrow id="S4.E6.m1.1.1.1" xref="S4.E6.m1.1.1.1.1.cmml"><mrow id="S4.E6.m1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.cmml"><msubsup id="S4.E6.m1.1.1.1.1.5" xref="S4.E6.m1.1.1.1.1.5.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.5.2.2" xref="S4.E6.m1.1.1.1.1.5.2.2.cmml">𝔻</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.5.2.3" xref="S4.E6.m1.1.1.1.1.5.2.3.cmml">T</mi><mrow id="S4.E6.m1.1.1.1.1.5.3" xref="S4.E6.m1.1.1.1.1.5.3.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.5.3.2" xref="S4.E6.m1.1.1.1.1.5.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.5.3.1" xref="S4.E6.m1.1.1.1.1.5.3.1.cmml">​</mo><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.5.3.3" xref="S4.E6.m1.1.1.1.1.5.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.5.3.1a" xref="S4.E6.m1.1.1.1.1.5.3.1.cmml">​</mo><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.5.3.4" xref="S4.E6.m1.1.1.1.1.5.3.4.cmml">D</mi></mrow></msubsup><mo mathcolor="#000000" id="S4.E6.m1.1.1.1.1.4" xref="S4.E6.m1.1.1.1.1.4.cmml">=</mo><mrow id="S4.E6.m1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.3.cmml"><mrow id="S4.E6.m1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.cmml"><mrow id="S4.E6.m1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.E6.m1.1.1.1.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E6.m1.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.cmml"><mn mathcolor="#000000" id="S4.E6.m1.1.1.1.1.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo mathcolor="#000000" id="S4.E6.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.3.cmml">ρ</mi></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E6.m1.1.1.1.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.1.1.2.cmml">​</mo><msub id="S4.E6.m1.1.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.1.1.3.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.1.1.3.2" xref="S4.E6.m1.1.1.1.1.1.1.3.2.cmml">𝔻</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.1.1.3.3" xref="S4.E6.m1.1.1.1.1.1.1.3.3.cmml">S</mi></msub></mrow><mo mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.4" xref="S4.E6.m1.1.1.1.1.3.4.cmml">+</mo><mrow id="S4.E6.m1.1.1.1.1.3.3" xref="S4.E6.m1.1.1.1.1.3.3.cmml"><mfrac mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.4" xref="S4.E6.m1.1.1.1.1.3.3.4.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.4.2" xref="S4.E6.m1.1.1.1.1.3.3.4.2.cmml">ρ</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.4.3" xref="S4.E6.m1.1.1.1.1.3.3.4.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.3.3.3" xref="S4.E6.m1.1.1.1.1.3.3.3.cmml">​</mo><mrow id="S4.E6.m1.1.1.1.1.3.3.2" xref="S4.E6.m1.1.1.1.1.3.3.2.cmml"><mo mathcolor="#000000" movablelimits="false" id="S4.E6.m1.1.1.1.1.3.3.2.3" xref="S4.E6.m1.1.1.1.1.3.3.2.3.cmml">∑</mo><mrow id="S4.E6.m1.1.1.1.1.3.3.2.2" xref="S4.E6.m1.1.1.1.1.3.3.2.2.cmml"><msub id="S4.E6.m1.1.1.1.1.3.3.2.2.4" xref="S4.E6.m1.1.1.1.1.3.3.2.2.4.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.4.2" xref="S4.E6.m1.1.1.1.1.3.3.2.2.4.2.cmml">P</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.4.3" xref="S4.E6.m1.1.1.1.1.3.3.2.2.4.3.cmml">S</mi></msub><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.3.3.2.2.3" xref="S4.E6.m1.1.1.1.1.3.3.2.2.3.cmml">​</mo><mrow id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.cmml"><msub id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.2" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.2.cmml">x</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.3" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.3.cmml">T</mi></msub><mo mathcolor="#000000" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.1.cmml">/</mo><msub id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.2" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.2.cmml">x</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.3" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.3.cmml">T</mi></msub></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.3.3.2.2.3a" xref="S4.E6.m1.1.1.1.1.3.3.2.2.3.cmml">​</mo><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.5" xref="S4.E6.m1.1.1.1.1.3.3.2.2.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.3.3.2.2.3b" xref="S4.E6.m1.1.1.1.1.3.3.2.2.3.cmml">​</mo><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.6" xref="S4.E6.m1.1.1.1.1.3.3.2.2.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.3.3.2.2.3c" xref="S4.E6.m1.1.1.1.1.3.3.2.2.3.cmml">​</mo><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.7" xref="S4.E6.m1.1.1.1.1.3.3.2.2.7.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.3.3.2.2.3d" xref="S4.E6.m1.1.1.1.1.3.3.2.2.3.cmml">​</mo><msub id="S4.E6.m1.1.1.1.1.3.3.2.2.8" xref="S4.E6.m1.1.1.1.1.3.3.2.2.8.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.8.2" xref="S4.E6.m1.1.1.1.1.3.3.2.2.8.2.cmml">P</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.8.3" xref="S4.E6.m1.1.1.1.1.3.3.2.2.8.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.1.3.3.2.2.3e" xref="S4.E6.m1.1.1.1.1.3.3.2.2.3.cmml">​</mo><mrow id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.2" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.cmml">(</mo><mrow id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.cmml"><msub id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.2" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.2.cmml">y</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.3" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.3.cmml">T</mi></msub><mo mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.1" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.1.cmml">/</mo><msub id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.cmml"><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.2" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.2.cmml">x</mi><mi mathcolor="#000000" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.3" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.3.cmml">T</mi></msub></mrow><mo mathcolor="#000000" stretchy="false" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.3" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo mathcolor="#000000" id="S4.E6.m1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.1b"><apply id="S4.E6.m1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1"><eq id="S4.E6.m1.1.1.1.1.4.cmml" xref="S4.E6.m1.1.1.1.1.4"></eq><apply id="S4.E6.m1.1.1.1.1.5.cmml" xref="S4.E6.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.5.1.cmml" xref="S4.E6.m1.1.1.1.1.5">superscript</csymbol><apply id="S4.E6.m1.1.1.1.1.5.2.cmml" xref="S4.E6.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.5.2.1.cmml" xref="S4.E6.m1.1.1.1.1.5">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.5.2.2.cmml" xref="S4.E6.m1.1.1.1.1.5.2.2">𝔻</ci><ci id="S4.E6.m1.1.1.1.1.5.2.3.cmml" xref="S4.E6.m1.1.1.1.1.5.2.3">𝑇</ci></apply><apply id="S4.E6.m1.1.1.1.1.5.3.cmml" xref="S4.E6.m1.1.1.1.1.5.3"><times id="S4.E6.m1.1.1.1.1.5.3.1.cmml" xref="S4.E6.m1.1.1.1.1.5.3.1"></times><ci id="S4.E6.m1.1.1.1.1.5.3.2.cmml" xref="S4.E6.m1.1.1.1.1.5.3.2">𝐾</ci><ci id="S4.E6.m1.1.1.1.1.5.3.3.cmml" xref="S4.E6.m1.1.1.1.1.5.3.3">𝐿</ci><ci id="S4.E6.m1.1.1.1.1.5.3.4.cmml" xref="S4.E6.m1.1.1.1.1.5.3.4">𝐷</ci></apply></apply><apply id="S4.E6.m1.1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.3"><plus id="S4.E6.m1.1.1.1.1.3.4.cmml" xref="S4.E6.m1.1.1.1.1.3.4"></plus><apply id="S4.E6.m1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1"><times id="S4.E6.m1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.2"></times><apply id="S4.E6.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.1"><minus id="S4.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.E6.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S4.E6.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.1.1.3">𝜌</ci></apply><apply id="S4.E6.m1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.1.1.3.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.3.2">𝔻</ci><ci id="S4.E6.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.3.3">𝑆</ci></apply></apply><apply id="S4.E6.m1.1.1.1.1.3.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3"><times id="S4.E6.m1.1.1.1.1.3.3.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.3"></times><apply id="S4.E6.m1.1.1.1.1.3.3.4.cmml" xref="S4.E6.m1.1.1.1.1.3.3.4"><divide id="S4.E6.m1.1.1.1.1.3.3.4.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.4"></divide><ci id="S4.E6.m1.1.1.1.1.3.3.4.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.4.2">𝜌</ci><ci id="S4.E6.m1.1.1.1.1.3.3.4.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.4.3">𝑁</ci></apply><apply id="S4.E6.m1.1.1.1.1.3.3.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2"><sum id="S4.E6.m1.1.1.1.1.3.3.2.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.3"></sum><apply id="S4.E6.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2"><times id="S4.E6.m1.1.1.1.1.3.3.2.2.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.3"></times><apply id="S4.E6.m1.1.1.1.1.3.3.2.2.4.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.4"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.3.2.2.4.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.4">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.4.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.4.2">𝑃</ci><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.4.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.4.3">𝑆</ci></apply><apply id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1"><divide id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.1"></divide><apply id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.1.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.2.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.2">𝑥</ci><ci id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.3.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.2.3">𝑇</ci></apply><apply id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.1.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.2.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.2">𝑥</ci><ci id="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.3.cmml" xref="S4.E6.m1.1.1.1.1.2.2.1.1.1.1.1.3.3">𝑇</ci></apply></apply><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.5.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.5">𝑙</ci><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.6.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.6">𝑜</ci><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.7.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.7">𝑔</ci><apply id="S4.E6.m1.1.1.1.1.3.3.2.2.8.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.8"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.3.2.2.8.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.8">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.8.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.8.2">𝑃</ci><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.8.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.8.3">𝑇</ci></apply><apply id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1"><divide id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.1"></divide><apply id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.2">𝑦</ci><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.2.3">𝑇</ci></apply><apply id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.1.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.2.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.2">𝑥</ci><ci id="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.3.cmml" xref="S4.E6.m1.1.1.1.1.3.3.2.2.2.1.1.3.3">𝑇</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.1c">\mathbb{D}_{T}^{KLD}=(1-\rho)\mathbb{D}_{S}+\frac{\rho}{N}\sum P_{S}(x_{T}/x_{T})logP_{T}(y_{T}/x_{T}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S4.SS4.SSS2.p2.6" class="ltx_p"><span id="S4.SS4.SSS2.p2.6.1" class="ltx_text" style="color:#000000;">In the context of DTL-based ASR, the conservative training approach with KLD-regularization is utilized to build a target AM. This approach involves training DNNs on speech samples collected from the target domain </span><math id="S4.SS4.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S4.SS4.SSS2.p2.1.m1.1a"><msub id="S4.SS4.SSS2.p2.1.m1.1.1" xref="S4.SS4.SSS2.p2.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.1.m1.1.1.2" xref="S4.SS4.SSS2.p2.1.m1.1.1.2.cmml">𝔻</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.1.m1.1.1.3" xref="S4.SS4.SSS2.p2.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.1.m1.1b"><apply id="S4.SS4.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.1.m1.1.1.1.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p2.1.m1.1.1.2.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1.2">𝔻</ci><ci id="S4.SS4.SSS2.p2.1.m1.1.1.3.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.1.m1.1c">\mathbb{D}_{T}</annotation></semantics></math><span id="S4.SS4.SSS2.p2.6.2" class="ltx_text" style="color:#000000;">, denoted as (</span><math id="S4.SS4.SSS2.p2.2.m2.2" class="ltx_Math" alttext="x_{T},y_{T}" display="inline"><semantics id="S4.SS4.SSS2.p2.2.m2.2a"><mrow id="S4.SS4.SSS2.p2.2.m2.2.2.2" xref="S4.SS4.SSS2.p2.2.m2.2.2.3.cmml"><msub id="S4.SS4.SSS2.p2.2.m2.1.1.1.1" xref="S4.SS4.SSS2.p2.2.m2.1.1.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.2.m2.1.1.1.1.2" xref="S4.SS4.SSS2.p2.2.m2.1.1.1.1.2.cmml">x</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.2.m2.1.1.1.1.3" xref="S4.SS4.SSS2.p2.2.m2.1.1.1.1.3.cmml">T</mi></msub><mo mathcolor="#000000" id="S4.SS4.SSS2.p2.2.m2.2.2.2.3" xref="S4.SS4.SSS2.p2.2.m2.2.2.3.cmml">,</mo><msub id="S4.SS4.SSS2.p2.2.m2.2.2.2.2" xref="S4.SS4.SSS2.p2.2.m2.2.2.2.2.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.2.m2.2.2.2.2.2" xref="S4.SS4.SSS2.p2.2.m2.2.2.2.2.2.cmml">y</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.2.m2.2.2.2.2.3" xref="S4.SS4.SSS2.p2.2.m2.2.2.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.2.m2.2b"><list id="S4.SS4.SSS2.p2.2.m2.2.2.3.cmml" xref="S4.SS4.SSS2.p2.2.m2.2.2.2"><apply id="S4.SS4.SSS2.p2.2.m2.1.1.1.1.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.2.m2.1.1.1.1.1.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p2.2.m2.1.1.1.1.2.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.1.1.2">𝑥</ci><ci id="S4.SS4.SSS2.p2.2.m2.1.1.1.1.3.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.1.1.3">𝑇</ci></apply><apply id="S4.SS4.SSS2.p2.2.m2.2.2.2.2.cmml" xref="S4.SS4.SSS2.p2.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.2.m2.2.2.2.2.1.cmml" xref="S4.SS4.SSS2.p2.2.m2.2.2.2.2">subscript</csymbol><ci id="S4.SS4.SSS2.p2.2.m2.2.2.2.2.2.cmml" xref="S4.SS4.SSS2.p2.2.m2.2.2.2.2.2">𝑦</ci><ci id="S4.SS4.SSS2.p2.2.m2.2.2.2.2.3.cmml" xref="S4.SS4.SSS2.p2.2.m2.2.2.2.2.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.2.m2.2c">x_{T},y_{T}</annotation></semantics></math><span id="S4.SS4.SSS2.p2.6.3" class="ltx_text" style="color:#000000;">), where </span><math id="S4.SS4.SSS2.p2.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS4.SSS2.p2.3.m3.1a"><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.3.m3.1.1" xref="S4.SS4.SSS2.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.3.m3.1b"><ci id="S4.SS4.SSS2.p2.3.m3.1.1.cmml" xref="S4.SS4.SSS2.p2.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.3.m3.1c">N</annotation></semantics></math><span id="S4.SS4.SSS2.p2.6.4" class="ltx_text" style="color:#000000;"> represents the number of speech samples in </span><math id="S4.SS4.SSS2.p2.4.m4.1" class="ltx_Math" alttext="\mathbb{D}_{T}" display="inline"><semantics id="S4.SS4.SSS2.p2.4.m4.1a"><msub id="S4.SS4.SSS2.p2.4.m4.1.1" xref="S4.SS4.SSS2.p2.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.4.m4.1.1.2" xref="S4.SS4.SSS2.p2.4.m4.1.1.2.cmml">𝔻</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.4.m4.1.1.3" xref="S4.SS4.SSS2.p2.4.m4.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.4.m4.1b"><apply id="S4.SS4.SSS2.p2.4.m4.1.1.cmml" xref="S4.SS4.SSS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.4.m4.1.1.1.cmml" xref="S4.SS4.SSS2.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p2.4.m4.1.1.2.cmml" xref="S4.SS4.SSS2.p2.4.m4.1.1.2">𝔻</ci><ci id="S4.SS4.SSS2.p2.4.m4.1.1.3.cmml" xref="S4.SS4.SSS2.p2.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.4.m4.1c">\mathbb{D}_{T}</annotation></semantics></math><span id="S4.SS4.SSS2.p2.6.5" class="ltx_text" style="color:#000000;">. The hyper-parameter </span><math id="S4.SS4.SSS2.p2.5.m5.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S4.SS4.SSS2.p2.5.m5.1a"><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.5.m5.1.1" xref="S4.SS4.SSS2.p2.5.m5.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.5.m5.1b"><ci id="S4.SS4.SSS2.p2.5.m5.1.1.cmml" xref="S4.SS4.SSS2.p2.5.m5.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.5.m5.1c">\rho</annotation></semantics></math><span id="S4.SS4.SSS2.p2.6.6" class="ltx_text" style="color:#000000;"> controls the transfer ratio from the source domain </span><math id="S4.SS4.SSS2.p2.6.m6.1" class="ltx_Math" alttext="\mathbb{D}_{S}" display="inline"><semantics id="S4.SS4.SSS2.p2.6.m6.1a"><msub id="S4.SS4.SSS2.p2.6.m6.1.1" xref="S4.SS4.SSS2.p2.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.6.m6.1.1.2" xref="S4.SS4.SSS2.p2.6.m6.1.1.2.cmml">𝔻</mi><mi mathcolor="#000000" id="S4.SS4.SSS2.p2.6.m6.1.1.3" xref="S4.SS4.SSS2.p2.6.m6.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.6.m6.1b"><apply id="S4.SS4.SSS2.p2.6.m6.1.1.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.6.m6.1.1.1.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p2.6.m6.1.1.2.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1.2">𝔻</ci><ci id="S4.SS4.SSS2.p2.6.m6.1.1.3.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.6.m6.1c">\mathbb{D}_{S}</annotation></semantics></math><span id="S4.SS4.SSS2.p2.6.7" class="ltx_text" style="color:#000000;">. An example of applying this DTL-based ASR approach with conservative training and KLD-regularization can be found in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS2.p2.6.8.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib89" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">89</span></a><span id="S4.SS4.SSS2.p2.6.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS2.p2.6.10" class="ltx_text" style="color:#000000;"> for building a target AM. Additionally, in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS2.p2.6.11.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib90" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">90</span></a><span id="S4.SS4.SSS2.p2.6.12.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS2.p2.6.13" class="ltx_text" style="color:#000000;">, both KLD and LHN techniques were employed for speaker adaptation using a pre-trained seq2seq ASR model. Table </span><a href="#S4.T6" title="Table 6 ‣ 4.2.2 Language domain ‣ 4.2 TL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S4.SS4.SSS2.p2.6.14" class="ltx_text" style="color:#000000;"> summarizes other techniques that employ conservative training along with their corresponding performance details.</span></p>
</div>
</section>
<section id="S4.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.4.3 </span>Subspace-based DTL</h4>

<div id="S4.SS4.SSS3.p1" class="ltx_para">
<p id="S4.SS4.SSS3.p1.1" class="ltx_p"><span id="S4.SS4.SSS3.p1.1.1" class="ltx_text" style="color:#000000;">Subspace-based DTL approaches in ASR utilize unsupervised techniques such as PCA, SVD, and NMF for data dimensionality reduction. These techniques aim to identify a subspace of model parameters or transformations that capture essential information. PCA maps high-dimensional data to lower-dimensional subspaces while preserving correlation and maximizing variance. SVD, similar to PCA, condenses networks by selecting a specific number of singular values. However, SVD introduces nonlinearity in the weight matrix, which can lead to information loss when constructing a linear projection layer. NMF algorithms require at least one nonnegative matrix and express the target matrix as a weighted sum of base matrix columns, making it more interpretable than SVD and PCA. In the study </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS3.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib88" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">88</span></a><span id="S4.SS4.SSS3.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS3.p1.1.4" class="ltx_text" style="color:#000000;">, Convex Nonnegative Matrix Factorization (CNMF), a variant of NMF, is employed to extract high-level features. Subsequently, DTL is applied to both high and low-level features through multilingual training and multi-task learning. These techniques yield significant performance improvements compared to state-of-the-art ASR studies. Other studies utilizing subspace techniques and their respective performance details can be found in Table </span><a href="#S4.T6" title="Table 6 ‣ 4.2.2 Language domain ‣ 4.2 TL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S4.SS4.SSS3.p1.1.5" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<div id="S4.SS4.SSS3.p2" class="ltx_para">
<p id="S4.SS4.SSS3.p2.1" class="ltx_p"><span id="S4.SS4.SSS3.p2.1.1" class="ltx_text" style="color:#000000;">LDA-based DTL
In the case of discrete data collection, generative probabilistic models, such as the latent Dirichlet allocation (LDA), are employed. Typically, LDA is a hierarchical Bayesian model with three levels, where each item in a collection is represented as a finite mixture over a set of underlying topics. Each topic, in turn, is modeled as an infinite mixture of topic probabilities. To capture the relationship between words and create language models for specific documents, topic model-based techniques, such as LDA, have been utilized as described in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS3.p2.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">song2019topic</span><span id="S4.SS4.SSS3.p2.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS3.p2.1.4" class="ltx_text" style="color:#000000;">. In the work presented in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS3.p2.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">hentschel2018feature</span><span id="S4.SS4.SSS3.p2.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS3.p2.1.7" class="ltx_text" style="color:#000000;">, LDA features are transformed using a linear layer consisting of a weight matrix and a bias vector. These transformed features are then utilized as inputs in the LHN (Local Hidden Node) during the training and evaluation of the network.</span></p>
</div>
</section>
<section id="S4.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.4.4 </span>NNLM-based DTL</h4>

<div id="S4.SS4.SSS4.p1" class="ltx_para">
<p id="S4.SS4.SSS4.p1.1" class="ltx_p"><span id="S4.SS4.SSS4.p1.1.1" class="ltx_text" style="color:#000000;">Neural network language models (NN-LMs) generally outperform count-based LM models in automatic speech recognition (ASR) across various tasks. Specifically, when applied to N-best rescoring, NN-LMs achieve WER as mentioned in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS4.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">hentschel2018feature</span><span id="S4.SS4.SSS4.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS4.p1.1.4" class="ltx_text" style="color:#000000;">. Adapting NN-LMs to new domains poses a research challenge, and current approaches can be categorized as either model-based or feature-based adaptations.
In feature-based adaptation, auxiliary features are incorporated into the input of an NN-LM, while model-based adaptation involves fine-tuning and adapting network layers. The authors of </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS4.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib91" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">91</span></a><span id="S4.SS4.SSS4.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS4.p1.1.7" class="ltx_text" style="color:#000000;"> propose a recurrent neural network-based LM (RNN-LM) approach where both types of adaptation are explored.
As an illustrative example, Figures </span><a href="#S4.F15" title="Figure 15 ‣ 4.4.4 NNLM-based DTL ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">15</span></a><span id="S4.SS4.SSS4.p1.1.8" class="ltx_text" style="color:#000000;"> (a) and (b) provide detailed explanations of the adopted RNN-based DTL in the study. Furthermore, the authors in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS4.p1.1.9.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib92" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">92</span></a><span id="S4.SS4.SSS4.p1.1.10.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS4.p1.1.11" class="ltx_text" style="color:#000000;"> suggest a DNN-based model for LM modification in ASR, employing a factorized time-delay neural network (TDNN-F). Specifically, the TDNN-F model is trained using a combination of cross-entropy and lattice-free maximum mutual information objective functions (LF-MMI). The effectiveness of TDNN-F is demonstrated in the recognition of English child speech </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS4.p1.1.12.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib92" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">92</span></a><span id="S4.SS4.SSS4.p1.1.13.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS4.p1.1.14" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<figure id="S4.F15" class="ltx_figure"><img src="/html/2403.01255/assets/RNN-LM.pdf" id="S4.F15.g1" class="ltx_graphics ltx_centering" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F15.4.1.1" class="ltx_text" style="font-size:90%;">Figure 15</span>: </span><span id="S4.F15.5.2" class="ltx_text" style="font-size:90%;">DTL-based RNNLM with different adaptation techniques, where the out-of-vocabulary (OOV) node represents an input word that does not belong to the specified vocabulary but can be included in the input. Similarly, out-of-shortlist (OOS) nodes can also be included in the output: (a) RNNLM with LHN adaptation layer. (b) RNNLM with feature-based adaptation layer.</span></figcaption>
</figure>
<div id="S4.SS4.SSS4.p2" class="ltx_para">
<p id="S4.SS4.SSS4.p2.1" class="ltx_p"><span id="S4.SS4.SSS4.p2.1.1" class="ltx_text" style="color:#000000;">LSTM-based DTL
Generally, the NNLM models used in ASR are still trained on a sentence-level corpus, despite the attempts to train them at the document level. This is due to various factors; for example, a more extended context may not be relevant for enhancing next-word prediction in conventional ASR systems.
It is also challenging to gather training data representing extended session contexts in many conversational circumstances.
Long-span models are becoming more common in scenarios where they are beneficial.
Long-span models will likely help scenarios, such as transcriptions of conversations and meetings, human-to-human communication, and document production by voice </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS4.p2.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">parthasarathy2019long</span><span id="S4.SS4.SSS4.p2.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS4.p2.1.4" class="ltx_text" style="color:#000000;">.
LSTM models are widely employed, and their architectures are well-suited to variable-length sequences. Therefore, they can exploit extreme long-range dependencies without using n-gram approximation.
For instance, by employing equal context, the authors in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS4.p2.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">tuske2018investigation</span><span id="S4.SS4.SSS4.p2.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS4.p2.1.7" class="ltx_text" style="color:#000000;"> demonstrate that the deep 4-gram LSTM outperforms big interpolated count models by performing considerably better backing off and smoothing.
In another example, the central part of a shared encoder is constructed using BLSTM </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS4.p2.1.8.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib94" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">94</span></a><span id="S4.SS4.SSS4.p2.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS4.p2.1.10" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<div id="S4.SS4.SSS4.p3" class="ltx_para">
<p id="S4.SS4.SSS4.p3.1" class="ltx_p"><span id="S4.SS4.SSS4.p3.1.1" class="ltx_text" style="color:#000000;">Cross-domain ASR</span></p>
</div>
</section>
<section id="S4.SS4.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.4.5 </span>Cross-language DTL</h4>

<div id="S4.SS4.SSS5.p1" class="ltx_para">
<p id="S4.SS4.SSS5.p1.1" class="ltx_p"><span id="S4.SS4.SSS5.p1.1.1" class="ltx_text" style="color:#000000;">Cross-language DTL is a particular application of cross-modality DTL. It serves as a commonly employed method for constructing ASR models for low resource languages by leveraging models trained on other languages. This approach is based on the assumption that phoneme features can be shared across languages. Additionally, a generic ASR model can be adapted to a specific narrow domain using DTL techniques. To address the issue of data sparsity, various knowledge transfer methods are explored in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS5.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2019investigation</span><span id="S4.SS4.SSS5.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS5.p1.1.4" class="ltx_text" style="color:#000000;"> with the assistance of high-resource languages. These methods include DTL and fine-tuning, where a well-trained neural network initializes the parameters of the LHN. Progressive neural networks (Prognets) are also examined, as they are resistant to the forgetting effect and excel at knowledge transfer due to the presence of lateral connections in the network architecture. Furthermore, the utilization of cross-lingual DNNs is explored, where bottleneck features are extracted to enhance the effectiveness of the ASR system. Recent approaches related to ASR using cross-language DTL and their respective performances are summarized in Tables </span><a href="#S4.T6" title="Table 6 ‣ 4.2.2 Language domain ‣ 4.2 TL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S4.SS4.SSS5.p1.1.5" class="ltx_text" style="color:#000000;"> and </span><a href="#S4.T9" title="Table 9 ‣ 4.4.5 Cross-language DTL ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">9</span></a><span id="S4.SS4.SSS5.p1.1.6" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<figure id="S4.T9" class="ltx_table">
<figcaption class="ltx_caption" style="color:#000000;"><span class="ltx_tag ltx_tag_table"><span id="S4.T9.18.3.1" class="ltx_text" style="font-size:90%;">Table 9</span>: </span><span id="S4.T9.4.2" class="ltx_text" style="font-size:90%;">A summary of the recent <span id="S4.T9.4.2.1" class="ltx_text ltx_font_italic">ASR-based cross-language DTL</span> technique. Whereas the marks (<math id="S4.T9.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T9.3.1.m1.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T9.3.1.m1.1.1" xref="S4.T9.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T9.3.1.m1.1c"><ci id="S4.T9.3.1.m1.1.1.cmml" xref="S4.T9.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.3.1.m1.1d">\uparrow</annotation></semantics></math>) and (<math id="S4.T9.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.4.2.m2.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T9.4.2.m2.1.1" xref="S4.T9.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T9.4.2.m2.1c"><ci id="S4.T9.4.2.m2.1.1.cmml" xref="S4.T9.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.4.2.m2.1d">\downarrow</annotation></semantics></math>) indicate improvement and reduction, respectively. If many scenarios has been conducted in one metric, only the best result is mentioned.</span></figcaption>
<table id="S4.T9.10" class="ltx_tabular ltx_align_middle">
<tr id="S4.T9.5.1" class="ltx_tr">
<td id="S4.T9.5.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T9.5.1.2.1" class="ltx_text" style="font-size:90%;color:#000000;">Scheme</span></td>
<td id="S4.T9.5.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.5.1.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.5.1.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Model-based</span></span>
</span>
</td>
<td id="S4.T9.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.5.1.1.1.1" class="ltx_p" style="width:213.4pt;"><span id="S4.T9.5.1.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">ASR Tasks (</span><math id="S4.T9.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S4.T9.5.1.1.1.1.m1.1a"><msub id="S4.T9.5.1.1.1.1.m1.1.1" xref="S4.T9.5.1.1.1.1.m1.1.1.cmml"><mi mathcolor="#000000" mathsize="90%" id="S4.T9.5.1.1.1.1.m1.1.1.2" xref="S4.T9.5.1.1.1.1.m1.1.1.2.cmml">𝕋</mi><mi mathcolor="#000000" mathsize="90%" id="S4.T9.5.1.1.1.1.m1.1.1.3" xref="S4.T9.5.1.1.1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T9.5.1.1.1.1.m1.1b"><apply id="S4.T9.5.1.1.1.1.m1.1.1.cmml" xref="S4.T9.5.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T9.5.1.1.1.1.m1.1.1.1.cmml" xref="S4.T9.5.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T9.5.1.1.1.1.m1.1.1.2.cmml" xref="S4.T9.5.1.1.1.1.m1.1.1.2">𝕋</ci><ci id="S4.T9.5.1.1.1.1.m1.1.1.3.cmml" xref="S4.T9.5.1.1.1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.5.1.1.1.1.m1.1c">\mathbb{T}_{T}</annotation></semantics></math><span id="S4.T9.5.1.1.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">)</span></span>
</span>
</td>
<td id="S4.T9.5.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.5.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.5.1.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.5.1.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Characteristic</span></span>
</span>
</td>
<td id="S4.T9.5.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T9.5.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.5.1.5.1.1" class="ltx_p" style="width:62.6pt;"><span id="S4.T9.5.1.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Performance</span></span>
</span>
</td>
</tr>
<tr id="S4.T9.6.2" class="ltx_tr">
<td id="S4.T9.6.2.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-bottom:17.07182pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T9.6.2.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">yusuf2019low</span><span id="S4.T9.6.2.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T9.6.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-bottom:17.07182pt;">
<span id="S4.T9.6.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.6.2.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.6.2.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">EDML</span></span>
</span>
</td>
<td id="S4.T9.6.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-bottom:17.07182pt;">
<span id="S4.T9.6.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.6.2.4.1.1" class="ltx_p" style="width:213.4pt;"><span id="S4.T9.6.2.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Framework of performing
the DTL that reduces the impact of the prevalence of out-of vocabulary terms.</span></span>
</span>
</td>
<td id="S4.T9.6.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-bottom:17.07182pt;">
<span id="S4.T9.6.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.6.2.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.6.2.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">query-by-example task</span></span>
</span>
</td>
<td id="S4.T9.6.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-bottom:17.07182pt;">
<span id="S4.T9.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.6.2.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S4.T9.6.2.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">74% TWV</span><math id="S4.T9.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T9.6.2.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T9.6.2.1.1.1.m1.1.1" xref="S4.T9.6.2.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T9.6.2.1.1.1.m1.1b"><ci id="S4.T9.6.2.1.1.1.m1.1.1.cmml" xref="S4.T9.6.2.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.6.2.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T9.7.3" class="ltx_tr">
<td id="S4.T9.7.3.2" class="ltx_td ltx_align_left" style="padding-bottom:17.07182pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T9.7.3.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2019investigation</span><span id="S4.T9.7.3.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T9.7.3.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:17.07182pt;">
<span id="S4.T9.7.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.7.3.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.7.3.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Prognets</span></span>
</span>
</td>
<td id="S4.T9.7.3.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:17.07182pt;">
<span id="S4.T9.7.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.7.3.4.1.1" class="ltx_p" style="width:213.4pt;"><span id="S4.T9.7.3.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Improving ASR scheme quality by overcoming the data sparsity problems by means of high-resource languages.</span></span>
</span>
</td>
<td id="S4.T9.7.3.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:17.07182pt;">
<span id="S4.T9.7.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.7.3.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.7.3.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fine-tuning </span>
<br class="ltx_break"><span id="S4.T9.7.3.5.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">LHN adapt.</span></span>
</span>
</td>
<td id="S4.T9.7.3.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:17.07182pt;">
<span id="S4.T9.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.7.3.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S4.T9.7.3.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">38.6% WER</span><math id="S4.T9.7.3.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.7.3.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T9.7.3.1.1.1.m1.1.1" xref="S4.T9.7.3.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T9.7.3.1.1.1.m1.1b"><ci id="S4.T9.7.3.1.1.1.m1.1.1.cmml" xref="S4.T9.7.3.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.7.3.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T9.8.4" class="ltx_tr">
<td id="S4.T9.8.4.2" class="ltx_td ltx_align_left" style="padding-bottom:17.07182pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T9.8.4.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2019low</span><span id="S4.T9.8.4.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T9.8.4.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:17.07182pt;">
<span id="S4.T9.8.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.8.4.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.8.4.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">FNN and CNN architectures</span></span>
</span>
</td>
<td id="S4.T9.8.4.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:17.07182pt;">
<span id="S4.T9.8.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.8.4.4.1.1" class="ltx_p" style="width:213.4pt;"><span id="S4.T9.8.4.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Indo-European
speech samples used to improve the identification
of African languages.</span></span>
</span>
</td>
<td id="S4.T9.8.4.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:17.07182pt;">
<span id="S4.T9.8.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.8.4.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.8.4.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Using PLP coeff. </span>
<br class="ltx_break"><span id="S4.T9.8.4.5.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T9.8.4.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:17.07182pt;">
<span id="S4.T9.8.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.8.4.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S4.T9.8.4.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">2.1% EER</span><math id="S4.T9.8.4.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.8.4.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T9.8.4.1.1.1.m1.1.1" xref="S4.T9.8.4.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T9.8.4.1.1.1.m1.1b"><ci id="S4.T9.8.4.1.1.1.m1.1.1.cmml" xref="S4.T9.8.4.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.8.4.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T9.9.5" class="ltx_tr">
<td id="S4.T9.9.5.2" class="ltx_td ltx_align_left" style="padding-bottom:36.98866pt;"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T9.9.5.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">sahraeian2018cross</span><span id="S4.T9.9.5.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T9.9.5.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:36.98866pt;">
<span id="S4.T9.9.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.9.5.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.9.5.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">DNN</span></span>
</span>
</td>
<td id="S4.T9.9.5.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:36.98866pt;">
<span id="S4.T9.9.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.9.5.4.1.1" class="ltx_p" style="width:213.4pt;"><span id="S4.T9.9.5.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Weighted averaging schemes are used to combine the ensemble’s constituents, with the combination weights being trained to minimize the cross-entropy objective function.</span></span>
</span>
</td>
<td id="S4.T9.9.5.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:36.98866pt;">
<span id="S4.T9.9.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.9.5.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.9.5.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Weights interpolation</span></span>
</span>
</td>
<td id="S4.T9.9.5.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-bottom:36.98866pt;">
<span id="S4.T9.9.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.9.5.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S4.T9.9.5.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">7.7% WER</span><math id="S4.T9.9.5.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.9.5.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T9.9.5.1.1.1.m1.1.1" xref="S4.T9.9.5.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T9.9.5.1.1.1.m1.1b"><ci id="S4.T9.9.5.1.1.1.m1.1.1.cmml" xref="S4.T9.9.5.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.9.5.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T9.10.6" class="ltx_tr">
<td id="S4.T9.10.6.2" class="ltx_td ltx_align_left ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T9.10.6.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">wilkinson2020semi</span><span id="S4.T9.10.6.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T9.10.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T9.10.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.10.6.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.10.6.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">CNN-GMM-HMM</span></span>
</span>
</td>
<td id="S4.T9.10.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T9.10.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.10.6.4.1.1" class="ltx_p" style="width:213.4pt;"><span id="S4.T9.10.6.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fully-automatic segmentation, semi-supervised training of ASR systems for five-lingual code-switched speech</span></span>
</span>
</td>
<td id="S4.T9.10.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T9.10.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.10.6.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T9.10.6.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Semi-supervised</span></span>
</span>
</td>
<td id="S4.T9.10.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T9.10.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T9.10.6.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S4.T9.10.6.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">1.1 % WER</span><math id="S4.T9.10.6.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.10.6.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T9.10.6.1.1.1.m1.1.1" xref="S4.T9.10.6.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T9.10.6.1.1.1.m1.1b"><ci id="S4.T9.10.6.1.1.1.m1.1.1.cmml" xref="S4.T9.10.6.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.10.6.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS4.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.4.6 </span> DTL-based ASR for emotion recognition:</h4>

<div id="S4.SS4.SSS6.p1" class="ltx_para">
<p id="S4.SS4.SSS6.p1.1" class="ltx_p"><span id="S4.SS4.SSS6.p1.1.1" class="ltx_text" style="color:#000000;">Combining language information with acoustic data has been shown to enhance the accuracy of speech emotion recognition (SER). Therefore, integrating both systems can be advantageous to enhance the capability of ASR systems to handle emotional speech and provide linguistic input to SER systems. Figure </span><a href="#S4.F16" title="Figure 16 ‣ 4.4.6 DTL-based ASR for emotion recognition: ‣ 4.4 RL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">16</span></a><span id="S4.SS4.SSS6.p1.1.2" class="ltx_text" style="color:#000000;"> illustrates a hybrid ASR-SER system </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS6.p1.1.3.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">fayek2016deep</span><span id="S4.SS4.SSS6.p1.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS6.p1.1.5" class="ltx_text" style="color:#000000;">, where a spectrogram is inputted into shared convolutional layers, followed by specialized layers that have shared levels to facilitate interaction between the two systems. This integration allows for improved performance in handling emotional speech and leveraging linguistic features.</span></p>
</div>
<figure id="S4.F16" class="ltx_figure"><img src="/html/2403.01255/assets/asr-ser.pdf" id="S4.F16.g1" class="ltx_graphics ltx_centering" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F16.7.1.1" class="ltx_text" style="font-size:90%;">Figure 16</span>: </span><span id="S4.F16.8.2" class="ltx_text" style="font-size:90%;"> A linguistic-paralinguistic hybrid system <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">fayek2016deep</span>]</cite>. (a) ASR-SER Hybrid system. (b) An example of DTL-based ASR-SER hybrid system.</span></figcaption>
</figure>
<div id="S4.SS4.SSS6.p2" class="ltx_para">
<p id="S4.SS4.SSS6.p2.1" class="ltx_p"><span id="S4.SS4.SSS6.p2.1.1" class="ltx_text" style="color:#000000;">The approach presented in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS6.p2.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">tits2018asr</span><span id="S4.SS4.SSS6.p2.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS6.p2.1.4" class="ltx_text" style="color:#000000;"> utilizes the internal representation of a speech-to-text system to explore the connection between valence/arousal and different modalities through the use of DTL. A speech-to-text or ASR system learns to map audio speech signals to their corresponding transcriptions. By employing DTL, the proposed method can estimate valence and arousal using features learned from an ASR task. This approach offers the advantage of combining large datasets of speech with transcriptions with smaller datasets annotated with emotional dimensions. In a similar vein, the work described in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS6.p2.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">ananthram2020multi</span><span id="S4.SS4.SSS6.p2.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS6.p2.1.7" class="ltx_text" style="color:#000000;"> fine-tunes a TDNN-based speaker recognition model for the task of emotion detection using the crema-D multi-modal emotion dataset and canonical label clustering. By adapting the model using fine-tuning, the authors aim to improve its performance on emotion detection. The study presented in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS6.p2.1.8.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">boateng2020speech</span><span id="S4.SS4.SSS6.p2.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS6.p2.1.10" class="ltx_text" style="color:#000000;"> focuses on extracting features from audio segments with extreme positive and negative ratings, as well as the ending of the audio. They employ the peak-end rule and a DTL approach to extract acoustic features. The authors utilize a pre-trained CNN speech model called YAMNet and a linear SVM for binary classification of partner valence.</span></p>
</div>
</section>
<section id="S4.SS4.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.4.7 </span>Cross-corpus SER (CC-SER)</h4>

<div id="S4.SS4.SSS7.p1" class="ltx_para">
<p id="S4.SS4.SSS7.p1.1" class="ltx_p"><span id="S4.SS4.SSS7.p1.1.1" class="ltx_text" style="color:#000000;">In the context of Speech Emotion Recognition (SER), it is typically assumed that speech utterances in the training and testing domains are recorded under the same conditions. However, in real-world scenarios, speech data is often collected from diverse environments or devices, resulting in a domain discrepancy that adversely affects recognition performance. As a solution, researchers have recently investigated the problem of cross-corpus SER (CC-SER) and explored various DTL models.</span></p>
</div>
<div id="S4.SS4.SSS7.p2" class="ltx_para">
<p id="S4.SS4.SSS7.p2.1" class="ltx_p"><span id="S4.SS4.SSS7.p2.1.1" class="ltx_text" style="color:#000000;">For example, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p2.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">song2019transfer</span><span id="S4.SS4.SSS7.p2.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p2.1.4" class="ltx_text" style="color:#000000;"> proposes a transfer linear subspace learning (TLSL) scheme to develop a CC-SER framework. This approach facilitates the learning of shared feature space for both the source and target domains. The similarity between different corpora is estimated using a nearest-neighbor graph algorithm. Additionally, a feature grouping method is devised to partition emotional features into highly transferable parts (HTP) and low transferable parts (LTP).</span></p>
</div>
<div id="S4.SS4.SSS7.p3" class="ltx_para">
<p id="S4.SS4.SSS7.p3.1" class="ltx_p"><span id="S4.SS4.SSS7.p3.1.1" class="ltx_text" style="color:#000000;">In the case of unsupervised CC-SER examined in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p3.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2018unsupervised</span><span id="S4.SS4.SSS7.p3.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p3.1.4" class="ltx_text" style="color:#000000;">, only the training data is annotated. The authors introduce a domain-adaptive subspace learning (DoSL) technique to learn a projection matrix that transforms the source and target speech data from the initial domain to the labeled domain. This allows the classifier trained on the labeled source domain data to effectively predict the emotional states of the unlabeled target domain data. Furthermore, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p3.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2021transfer</span><span id="S4.SS4.SSS7.p3.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p3.1.7" class="ltx_text" style="color:#000000;"> presents an improvement to the DoSL-based CC-SER method by introducing transfer subspace learning (TRaSL). In another study by </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p3.1.8.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">luo2019cross</span><span id="S4.SS4.SSS7.p3.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p3.1.10" class="ltx_text" style="color:#000000;">, a semi-supervised CC-SER approach is proposed using non-negative matrix factorization (NMF). This approach incorporates training corpus labels into NMF and seeks a latent low-rank feature space where the differences in conditional and marginal distributions between the two corpora can be simultaneously minimized.</span></p>
</div>
<div id="S4.SS4.SSS7.p4" class="ltx_para">
<p id="S4.SS4.SSS7.p4.4" class="ltx_p"><span id="S4.SS4.SSS7.p4.4.1" class="ltx_text" style="color:#000000;">Advancing further, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p4.4.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019transfer</span><span id="S4.SS4.SSS7.p4.4.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p4.4.4" class="ltx_text" style="color:#000000;"> proposes a transfer sparse discriminant subspace learning (TSDSL) method to discover a shared feature subspace among multiple corpora. This is achieved by incorporating the </span><math id="S4.SS4.SSS7.p4.1.m1.2" class="ltx_Math" alttext="\ell_{2,1}" display="inline"><semantics id="S4.SS4.SSS7.p4.1.m1.2a"><msub id="S4.SS4.SSS7.p4.1.m1.2.3" xref="S4.SS4.SSS7.p4.1.m1.2.3.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.SS4.SSS7.p4.1.m1.2.3.2" xref="S4.SS4.SSS7.p4.1.m1.2.3.2.cmml">ℓ</mi><mrow id="S4.SS4.SSS7.p4.1.m1.2.2.2.4" xref="S4.SS4.SSS7.p4.1.m1.2.2.2.3.cmml"><mn mathcolor="#000000" id="S4.SS4.SSS7.p4.1.m1.1.1.1.1" xref="S4.SS4.SSS7.p4.1.m1.1.1.1.1.cmml">2</mn><mo mathcolor="#000000" id="S4.SS4.SSS7.p4.1.m1.2.2.2.4.1" xref="S4.SS4.SSS7.p4.1.m1.2.2.2.3.cmml">,</mo><mn mathcolor="#000000" id="S4.SS4.SSS7.p4.1.m1.2.2.2.2" xref="S4.SS4.SSS7.p4.1.m1.2.2.2.2.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS7.p4.1.m1.2b"><apply id="S4.SS4.SSS7.p4.1.m1.2.3.cmml" xref="S4.SS4.SSS7.p4.1.m1.2.3"><csymbol cd="ambiguous" id="S4.SS4.SSS7.p4.1.m1.2.3.1.cmml" xref="S4.SS4.SSS7.p4.1.m1.2.3">subscript</csymbol><ci id="S4.SS4.SSS7.p4.1.m1.2.3.2.cmml" xref="S4.SS4.SSS7.p4.1.m1.2.3.2">ℓ</ci><list id="S4.SS4.SSS7.p4.1.m1.2.2.2.3.cmml" xref="S4.SS4.SSS7.p4.1.m1.2.2.2.4"><cn type="integer" id="S4.SS4.SSS7.p4.1.m1.1.1.1.1.cmml" xref="S4.SS4.SSS7.p4.1.m1.1.1.1.1">2</cn><cn type="integer" id="S4.SS4.SSS7.p4.1.m1.2.2.2.2.cmml" xref="S4.SS4.SSS7.p4.1.m1.2.2.2.2">1</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS7.p4.1.m1.2c">\ell_{2,1}</annotation></semantics></math><span id="S4.SS4.SSS7.p4.4.5" class="ltx_text" style="color:#000000;">-norm penalty and discriminative learning, facilitating the identification of the most discriminative characteristics across the corpora. Similarly, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p4.4.6.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">luo2020nonnegative</span><span id="S4.SS4.SSS7.p4.4.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p4.4.8" class="ltx_text" style="color:#000000;"> introduces a non-negative matrix factorization-based transfer subspace learning (NMFTSL) scheme. The goal is to minimize the distances between the marginal and conditional distributions in the common subspace. The distances are estimated using the maximum mean discrepancy (MMD) criterion. In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p4.4.9.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2021cross</span><span id="S4.SS4.SSS7.p4.4.10.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p4.4.11" class="ltx_text" style="color:#000000;">, a joint transfer subspace learning and regression (JTSLR) technique is employed. It learns a latent subspace using discriminative MMD as the discrepancy metric, followed by modeling the relationships between features and annotations using a regression function in the latent subspace. A label graph is utilized to enhance knowledge transfer from the source domain (SD) data to the target domain (TD) data. Similarly, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p4.4.12.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019target</span><span id="S4.SS4.SSS7.p4.4.13.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p4.4.14" class="ltx_text" style="color:#000000;"> presents a target-adapted subspace learning (TaSL) approach for CC-SER. It aims to find a projection subspace that enables more accurate regression of labels from the features. This effectively bridges the gap in feature distributions between the TD and SD. The projection matrix is optimized by combining </span><math id="S4.SS4.SSS7.p4.2.m2.1" class="ltx_Math" alttext="\ell_{1}" display="inline"><semantics id="S4.SS4.SSS7.p4.2.m2.1a"><msub id="S4.SS4.SSS7.p4.2.m2.1.1" xref="S4.SS4.SSS7.p4.2.m2.1.1.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.SS4.SSS7.p4.2.m2.1.1.2" xref="S4.SS4.SSS7.p4.2.m2.1.1.2.cmml">ℓ</mi><mn mathcolor="#000000" id="S4.SS4.SSS7.p4.2.m2.1.1.3" xref="S4.SS4.SSS7.p4.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS7.p4.2.m2.1b"><apply id="S4.SS4.SSS7.p4.2.m2.1.1.cmml" xref="S4.SS4.SSS7.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS7.p4.2.m2.1.1.1.cmml" xref="S4.SS4.SSS7.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.SSS7.p4.2.m2.1.1.2.cmml" xref="S4.SS4.SSS7.p4.2.m2.1.1.2">ℓ</ci><cn type="integer" id="S4.SS4.SSS7.p4.2.m2.1.1.3.cmml" xref="S4.SS4.SSS7.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS7.p4.2.m2.1c">\ell_{1}</annotation></semantics></math><span id="S4.SS4.SSS7.p4.4.15" class="ltx_text" style="color:#000000;">-norm and </span><math id="S4.SS4.SSS7.p4.3.m3.2" class="ltx_Math" alttext="\ell_{2,1}" display="inline"><semantics id="S4.SS4.SSS7.p4.3.m3.2a"><msub id="S4.SS4.SSS7.p4.3.m3.2.3" xref="S4.SS4.SSS7.p4.3.m3.2.3.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.SS4.SSS7.p4.3.m3.2.3.2" xref="S4.SS4.SSS7.p4.3.m3.2.3.2.cmml">ℓ</mi><mrow id="S4.SS4.SSS7.p4.3.m3.2.2.2.4" xref="S4.SS4.SSS7.p4.3.m3.2.2.2.3.cmml"><mn mathcolor="#000000" id="S4.SS4.SSS7.p4.3.m3.1.1.1.1" xref="S4.SS4.SSS7.p4.3.m3.1.1.1.1.cmml">2</mn><mo mathcolor="#000000" id="S4.SS4.SSS7.p4.3.m3.2.2.2.4.1" xref="S4.SS4.SSS7.p4.3.m3.2.2.2.3.cmml">,</mo><mn mathcolor="#000000" id="S4.SS4.SSS7.p4.3.m3.2.2.2.2" xref="S4.SS4.SSS7.p4.3.m3.2.2.2.2.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS7.p4.3.m3.2b"><apply id="S4.SS4.SSS7.p4.3.m3.2.3.cmml" xref="S4.SS4.SSS7.p4.3.m3.2.3"><csymbol cd="ambiguous" id="S4.SS4.SSS7.p4.3.m3.2.3.1.cmml" xref="S4.SS4.SSS7.p4.3.m3.2.3">subscript</csymbol><ci id="S4.SS4.SSS7.p4.3.m3.2.3.2.cmml" xref="S4.SS4.SSS7.p4.3.m3.2.3.2">ℓ</ci><list id="S4.SS4.SSS7.p4.3.m3.2.2.2.3.cmml" xref="S4.SS4.SSS7.p4.3.m3.2.2.2.4"><cn type="integer" id="S4.SS4.SSS7.p4.3.m3.1.1.1.1.cmml" xref="S4.SS4.SSS7.p4.3.m3.1.1.1.1">2</cn><cn type="integer" id="S4.SS4.SSS7.p4.3.m3.2.2.2.2.cmml" xref="S4.SS4.SSS7.p4.3.m3.2.2.2.2">1</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS7.p4.3.m3.2c">\ell_{2,1}</annotation></semantics></math><span id="S4.SS4.SSS7.p4.4.16" class="ltx_text" style="color:#000000;">-norm penalty terms with other regularization terms. Furthermore, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p4.4.17.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2021cross</span><span id="S4.SS4.SSS7.p4.4.18.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p4.4.19" class="ltx_text" style="color:#000000;"> employs sparse subspace transfer learning (SSTL) to develop a CC-SER technique. It learns a robust common subspace projection using discriminative subspace learning and transfers knowledge from the source corpus to the target corpus through sparse reconstruction based on </span><math id="S4.SS4.SSS7.p4.4.m4.2" class="ltx_Math" alttext="\ell_{2,1}" display="inline"><semantics id="S4.SS4.SSS7.p4.4.m4.2a"><msub id="S4.SS4.SSS7.p4.4.m4.2.3" xref="S4.SS4.SSS7.p4.4.m4.2.3.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S4.SS4.SSS7.p4.4.m4.2.3.2" xref="S4.SS4.SSS7.p4.4.m4.2.3.2.cmml">ℓ</mi><mrow id="S4.SS4.SSS7.p4.4.m4.2.2.2.4" xref="S4.SS4.SSS7.p4.4.m4.2.2.2.3.cmml"><mn mathcolor="#000000" id="S4.SS4.SSS7.p4.4.m4.1.1.1.1" xref="S4.SS4.SSS7.p4.4.m4.1.1.1.1.cmml">2</mn><mo mathcolor="#000000" id="S4.SS4.SSS7.p4.4.m4.2.2.2.4.1" xref="S4.SS4.SSS7.p4.4.m4.2.2.2.3.cmml">,</mo><mn mathcolor="#000000" id="S4.SS4.SSS7.p4.4.m4.2.2.2.2" xref="S4.SS4.SSS7.p4.4.m4.2.2.2.2.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS7.p4.4.m4.2b"><apply id="S4.SS4.SSS7.p4.4.m4.2.3.cmml" xref="S4.SS4.SSS7.p4.4.m4.2.3"><csymbol cd="ambiguous" id="S4.SS4.SSS7.p4.4.m4.2.3.1.cmml" xref="S4.SS4.SSS7.p4.4.m4.2.3">subscript</csymbol><ci id="S4.SS4.SSS7.p4.4.m4.2.3.2.cmml" xref="S4.SS4.SSS7.p4.4.m4.2.3.2">ℓ</ci><list id="S4.SS4.SSS7.p4.4.m4.2.2.2.3.cmml" xref="S4.SS4.SSS7.p4.4.m4.2.2.2.4"><cn type="integer" id="S4.SS4.SSS7.p4.4.m4.1.1.1.1.cmml" xref="S4.SS4.SSS7.p4.4.m4.1.1.1.1">2</cn><cn type="integer" id="S4.SS4.SSS7.p4.4.m4.2.2.2.2.cmml" xref="S4.SS4.SSS7.p4.4.m4.2.2.2.2">1</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS7.p4.4.m4.2c">\ell_{2,1}</annotation></semantics></math><span id="S4.SS4.SSS7.p4.4.20" class="ltx_text" style="color:#000000;">-norm. The target samples are suitably represented as linear combinations of the SD data. On a different note, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.SSS7.p4.4.21.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">braunschweiler2021study</span><span id="S4.SS4.SSS7.p4.4.22.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS4.SSS7.p4.4.23" class="ltx_text" style="color:#000000;"> investigates the impact of cross-corpus data complementation and data augmentation on the performance of SER models. The study focuses on six emotional speech corpora, considering factors such as single and multiple speakers, as well as variations in emotion style (natural, elicited, and acted).</span></p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Adversarial TL-based ASR</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p"><span id="S4.SS5.p1.1.1" class="ltx_text" style="color:#000000;">In many cases, the source model is trained using multilingual training, where abundant speech data is available in multiple languages </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib88" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">88</span></a>, <a href="#bib.bib94" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">94</span></a><span id="S4.SS5.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS5.p1.1.4" class="ltx_text" style="color:#000000;">. Multilingual training involves shared hidden layers (SHL) and language-specific layers or classifier layers for different languages. The SHL of the source model acts as a feature converter, transforming language-specific features into a common feature space </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2019investigation</span><span id="S4.SS5.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS5.p1.1.7" class="ltx_text" style="color:#000000;">. However, there might be language-dependent features present in the common feature space, which hinders effective cross-lingual knowledge transfer. To address this issue, language-adversarial training is employed. Adversarial training helps in creating a language-invariant feature space. Once the source model is prepared, the first </span><math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><mi mathcolor="#000000" id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><ci id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">n</annotation></semantics></math><span id="S4.SS5.p1.1.8" class="ltx_text" style="color:#000000;"> SHL can be transferred to the target model of an unknown language. In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p1.1.9.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2018language</span><span id="S4.SS5.p1.1.10.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS5.p1.1.11" class="ltx_text" style="color:#000000;">, the authors propose language-adversarial transfer learning as a solution to mitigate the performance degradation of the target model caused by shared features that may contain unnecessary language-dependent information. Fig. </span><a href="#S4.F17" title="Figure 17 ‣ 4.5 Adversarial TL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">17</span></a><span id="S4.SS5.p1.1.12" class="ltx_text" style="color:#000000;"> illustrates the architecture of the suggested language-adversarial transfer learning method </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p1.1.13.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2018language</span><span id="S4.SS5.p1.1.14.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS5.p1.1.15" class="ltx_text" style="color:#000000;">. The source model, also known as the adversarial SHL model, is shown on the left, while the target model is depicted on the right. The presence of an additional language discriminator in the SHL model is denoted. The fully connected layer is represented as FC. The gradient reversal layer (GRL) ensures that the feature distributions across all languages are made as similar as possible for the language discriminator. The output labels of the language discriminator indicate the languages.</span></p>
</div>
<figure id="S4.F17" class="ltx_figure"><img src="/html/2403.01255/assets/fig011.pdf" id="S4.F17.g1" class="ltx_graphics ltx_centering" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F17.7.1.1" class="ltx_text" style="font-size:90%;">Figure 17</span>: </span><span id="S4.F17.8.2" class="ltx_text" style="font-size:90%;"> An example of proposed model architecture language-adversarial TL for limited ASR resource <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2018language</span>]</cite>. Senones refers to feature cluster’s name, representing similar acoustic states/events.</span></figcaption>
</figure>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p"><span id="S4.SS5.p2.1.1" class="ltx_text" style="color:#000000;">To enhance the effectiveness of ASR in low-resource scenarios, a combination of semi-supervised training and language adversarial TL is explored in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p2.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">kumar2021exploration</span><span id="S4.SS5.p2.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS5.p2.1.4" class="ltx_text" style="color:#000000;">. The research presented in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p2.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2020adversarial</span><span id="S4.SS5.p2.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS5.p2.1.7" class="ltx_text" style="color:#000000;"> suggests utilizing adversarial transfer learning to improve punctuation prediction performance. Specifically, a pre-trained BERT model is employed to transfer bidirectional representations to punctuation prediction models. The proposed approach is applied to the ASR task as the target task. Table </span><a href="#S4.T10" title="Table 10 ‣ 4.5 Adversarial TL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">10</span></a><span id="S4.SS5.p2.1.8" class="ltx_text" style="color:#000000;"> provides a summary of the performance achieved in recent studies involving adversarial TL for ASR.</span></p>
</div>
<figure id="S4.T10" class="ltx_table">
<figcaption class="ltx_caption" style="color:#000000;"><span class="ltx_tag ltx_tag_table"><span id="S4.T10.16.3.1" class="ltx_text" style="font-size:90%;">Table 10</span>: </span><span id="S4.T10.4.2" class="ltx_text" style="font-size:90%;">A summary of the recent <span id="S4.T10.4.2.1" class="ltx_text ltx_font_italic">ASR-based adversarial-language TL</span> technique. Whereas the marks (<math id="S4.T10.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T10.3.1.m1.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T10.3.1.m1.1.1" xref="S4.T10.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T10.3.1.m1.1c"><ci id="S4.T10.3.1.m1.1.1.cmml" xref="S4.T10.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T10.3.1.m1.1d">\uparrow</annotation></semantics></math>) and (<math id="S4.T10.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T10.4.2.m2.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T10.4.2.m2.1.1" xref="S4.T10.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T10.4.2.m2.1c"><ci id="S4.T10.4.2.m2.1.1.cmml" xref="S4.T10.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T10.4.2.m2.1d">\downarrow</annotation></semantics></math>) indicate improvement and reduction, respectively. If many scenarios has been conducted in one metric, only the best result is mentioned.</span></figcaption>
<table id="S4.T10.8" class="ltx_tabular ltx_align_middle">
<tr id="S4.T10.5.1" class="ltx_tr">
<td id="S4.T10.5.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T10.5.1.2.1" class="ltx_text" style="font-size:90%;color:#000000;">Scheme</span></td>
<td id="S4.T10.5.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.5.1.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T10.5.1.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Model-based</span></span>
</span>
</td>
<td id="S4.T10.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.5.1.1.1.1" class="ltx_p" style="width:165.0pt;"><span id="S4.T10.5.1.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">ASR Tasks (</span><math id="S4.T10.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S4.T10.5.1.1.1.1.m1.1a"><msub id="S4.T10.5.1.1.1.1.m1.1.1" xref="S4.T10.5.1.1.1.1.m1.1.1.cmml"><mi mathcolor="#000000" mathsize="90%" id="S4.T10.5.1.1.1.1.m1.1.1.2" xref="S4.T10.5.1.1.1.1.m1.1.1.2.cmml">𝕋</mi><mi mathcolor="#000000" mathsize="90%" id="S4.T10.5.1.1.1.1.m1.1.1.3" xref="S4.T10.5.1.1.1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T10.5.1.1.1.1.m1.1b"><apply id="S4.T10.5.1.1.1.1.m1.1.1.cmml" xref="S4.T10.5.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T10.5.1.1.1.1.m1.1.1.1.cmml" xref="S4.T10.5.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T10.5.1.1.1.1.m1.1.1.2.cmml" xref="S4.T10.5.1.1.1.1.m1.1.1.2">𝕋</ci><ci id="S4.T10.5.1.1.1.1.m1.1.1.3.cmml" xref="S4.T10.5.1.1.1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T10.5.1.1.1.1.m1.1c">\mathbb{T}_{T}</annotation></semantics></math><span id="S4.T10.5.1.1.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">)</span></span>
</span>
</td>
<td id="S4.T10.5.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.5.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.5.1.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T10.5.1.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Characteristic</span></span>
</span>
</td>
<td id="S4.T10.5.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.5.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.5.1.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T10.5.1.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Performance</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.6.2" class="ltx_tr">
<td id="S4.T10.6.2.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T10.6.2.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">kumar2021exploration</span><span id="S4.T10.6.2.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T10.6.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.6.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.6.2.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T10.6.2.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Adversarial SHL-Mode </span>
<br class="ltx_break"><span id="S4.T10.6.2.3.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">( SincNet-CNN-LiGRU )</span></span>
</span>
</td>
<td id="S4.T10.6.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.6.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.6.2.4.1.1" class="ltx_p" style="width:165.0pt;"><span id="S4.T10.6.2.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Use three Indian languages ( Hindi, Marathi, and Bengali ) cross-lingual to improve Hindi ASR</span></span>
</span>
</td>
<td id="S4.T10.6.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.6.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.6.2.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T10.6.2.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Semi-supervised</span></span>
</span>
</td>
<td id="S4.T10.6.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T10.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.6.2.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T10.6.2.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">WER=5.5% </span>
<br class="ltx_break"><span id="S4.T10.6.2.1.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">(25.65% WER </span><math id="S4.T10.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T10.6.2.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T10.6.2.1.1.1.m1.1.1" xref="S4.T10.6.2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T10.6.2.1.1.1.m1.1b"><ci id="S4.T10.6.2.1.1.1.m1.1.1.cmml" xref="S4.T10.6.2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T10.6.2.1.1.1.m1.1c">\downarrow</annotation></semantics></math><span id="S4.T10.6.2.1.1.1.3" class="ltx_text" style="font-size:90%;color:#000000;">)</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.7.3" class="ltx_tr">
<td id="S4.T10.7.3.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T10.7.3.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2018language</span><span id="S4.T10.7.3.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T10.7.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T10.7.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.7.3.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T10.7.3.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">SHL Model</span></span>
</span>
</td>
<td id="S4.T10.7.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T10.7.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.7.3.4.1.1" class="ltx_p" style="width:165.0pt;"><span id="S4.T10.7.3.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Improve the performance of low-resource ASR</span></span>
</span>
</td>
<td id="S4.T10.7.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T10.7.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.7.3.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T10.7.3.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Cross-lingual</span></span>
</span>
</td>
<td id="S4.T10.7.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T10.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.7.3.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T10.7.3.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">10.1 % WER </span><math id="S4.T10.7.3.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T10.7.3.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T10.7.3.1.1.1.m1.1.1" xref="S4.T10.7.3.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T10.7.3.1.1.1.m1.1b"><ci id="S4.T10.7.3.1.1.1.m1.1.1.cmml" xref="S4.T10.7.3.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T10.7.3.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T10.8.4" class="ltx_tr">
<td id="S4.T10.8.4.2" class="ltx_td ltx_align_left ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T10.8.4.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2020adversarial</span><span id="S4.T10.8.4.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T10.8.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T10.8.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.8.4.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T10.8.4.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">BERT</span></span>
</span>
</td>
<td id="S4.T10.8.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T10.8.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.8.4.4.1.1" class="ltx_p" style="width:165.0pt;"><span id="S4.T10.8.4.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Improve
the performance of punctuation predicting</span></span>
</span>
</td>
<td id="S4.T10.8.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T10.8.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.8.4.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T10.8.4.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Multi-task</span></span>
</span>
</td>
<td id="S4.T10.8.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T10.8.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.8.4.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T10.8.4.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">9.4% F1-score </span><math id="S4.T10.8.4.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T10.8.4.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T10.8.4.1.1.1.m1.1.1" xref="S4.T10.8.4.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T10.8.4.1.1.1.m1.1b"><ci id="S4.T10.8.4.1.1.1.m1.1.1.cmml" xref="S4.T10.8.4.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T10.8.4.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>DTL-based ASR for medical diagnosis </h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p"><span id="S4.SS6.p1.1.1" class="ltx_text" style="color:#000000;">DTL-based ASR has made significant advancements in the field of medicine, particularly in the early detection of diseases. These advancements have been observed in various medical domains, as outlined in Table </span><a href="#S4.T11" title="Table 11 ‣ 4.6.3 Other medical diagnosis ‣ 4.6 DTL-based ASR for medical diagnosis ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">11</span></a><span id="S4.SS6.p1.1.2" class="ltx_text" style="color:#000000;">, which includes:</span></p>
</div>
<section id="S4.SS6.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.6.1 </span>Heart sound classification</h4>

<div id="S4.SS6.SSS1.p1" class="ltx_para">
<p id="S4.SS6.SSS1.p1.1" class="ltx_p"><span id="S4.SS6.SSS1.p1.1.1" class="ltx_text" style="color:#000000;">The components of the heart sound encompass various elements. The first (S1) and second (S2) heart sounds are considered normal, whereas the third (S3) and fourth (S4) heart sounds are often associated with murmurs, and ejection clicks typically indicate certain illnesses or abnormalities. Koike et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS1.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">koike2020audio</span><span id="S4.SS6.SSS1.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS1.p1.1.4" class="ltx_text" style="color:#000000;"> introduced a novel DTL approach based on Probabilistic Audio Neural Networks (PANNs), which involves pre-training a model on a large-scale audio dataset for the purpose of classifying heart sounds. Another approach for heart sound classification was proposed by Boulares et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS1.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">boulares2020transfer</span><span id="S4.SS6.SSS1.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS1.p1.1.7" class="ltx_text" style="color:#000000;">. Their method utilizes DTL on the Pascal public dataset, without any denoising or cleaning procedures, to establish an experimental benchmark. The primary objective is to provide a foundation of experimental results that can serve as a starting point for future research on cardiovascular disease (CVD) recognition using phonocardiogram (PCG)-based cardiac cycle vibration sounds. This proposed scheme addresses the absence of a CVD recognition benchmark and the lack of objective comparability among classification results, which tend to vary significantly.</span></p>
</div>
</section>
<section id="S4.SS6.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.6.2 </span>Parkinson disease detection</h4>

<div id="S4.SS6.SSS2.p1" class="ltx_para">
<p id="S4.SS6.SSS2.p1.1" class="ltx_p"><span id="S4.SS6.SSS2.p1.1.1" class="ltx_text" style="color:#000000;">Parkinson’s disease (PD) is a progressive neurodegenerative condition with a global impact. Accurate diagnosis of PD is crucial for improving daily activities and extending patients’ lives. However, predicting symptom changes and their impact on patients’ lives is challenging due to the variability in symptoms and disease progression. Traditional PD detection methods are often manual and require specialized expertise. Language impairment and atrophy are common early symptoms in over 90% of PD patients, characterized by reduced voice volume, monotonous and rapid speech, and eventual loss of audibility. Karaman et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS2.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">43</span></a><span id="S4.SS6.SSS2.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS2.p1.1.4" class="ltx_text" style="color:#000000;"> proposed a robust automated PD detection approach using DTL-based ASR, where pre-trained models like SqueezeNet1_1, ResNet101, and DenseNet161 were fine-tuned and retrained. This scheme showed promising results in PD detection. To address the scarcity of speech data for PD and the distribution inconsistency among subjects, Li et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS2.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">42</span></a><span id="S4.SS6.SSS2.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS2.p1.1.7" class="ltx_text" style="color:#000000;"> introduced a two-step unsupervised DTL algorithm called two-step sparse transfer learning (TSTL). This algorithm helps extract useful information from large amounts of unlabeled speech data, align the distribution of training and test sets, and preserve the original sample structure simultaneously. Another strategy proposed by Qing et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS2.p1.1.8.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">45</span></a><span id="S4.SS6.SSS2.p1.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS2.p1.1.10" class="ltx_text" style="color:#000000;"> involves enhancing ASR for Parkinson’s patients using a pre-trained long short-term memory (LSTM) neural network model. To mitigate overfitting and reduce WER, the scheme employs frequency spectrogram masking data augmentation.</span></p>
</div>
</section>
<section id="S4.SS6.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.6.3 </span>Other medical diagnosis</h4>

<div id="S4.SS6.SSS3.p1" class="ltx_para">
<p id="S4.SS6.SSS3.p1.1" class="ltx_p"><span id="S4.SS6.SSS3.p1.1.1" class="ltx_text" style="color:#000000;">In the field of speech-based depression prediction, Harati et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS3.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">harati2021speech</span><span id="S4.SS6.SSS3.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS3.p1.1.4" class="ltx_text" style="color:#000000;"> proposed a DTL method that utilizes a lightweight encoder and transfers only the encoder weights. This approach simplifies the runtime model for depression prediction. For individuals with dysarthria, Xiong et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS3.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">xiong2020source</span><span id="S4.SS6.SSS3.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS3.p1.1.7" class="ltx_text" style="color:#000000;"> developed an improved DTL framework for robust personalized speech recognition models. They adapted the CNN-TDNN-F ASR AM onto the target dysarthric speakers using neural network weight adaptation. In the context of dysarthria speaking identification, Takashima et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS3.p1.1.8.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">takashima2019knowledge</span><span id="S4.SS6.SSS3.p1.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS3.p1.1.10" class="ltx_text" style="color:#000000;"> proposed a method that transfers two types of knowledge from different datasets: the language-dependent characteristics of unimpaired speech and the language-independent characteristics of dysarthric speech. They focused on Japanese people with articulation disorders. Additionally, Sertolli et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS6.SSS3.p1.1.11.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">sertolli2021representation</span><span id="S4.SS6.SSS3.p1.1.12.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS6.SSS3.p1.1.13" class="ltx_text" style="color:#000000;"> presented a novel feature representation for health states identification using an end-to-end DTL-based ASR framework. They utilized ASR DNNs as feature extractors, combined multiple feature representations using compact bilinear pooling (CBP), and employed an optimized RNN classifier for inference.</span></p>
</div>
<figure id="S4.T11" class="ltx_table">
<figcaption class="ltx_caption" style="color:#000000;"><span class="ltx_tag ltx_tag_table"><span id="S4.T11.17.3.1" class="ltx_text" style="font-size:90%;">Table 11</span>: </span><span id="S4.T11.4.2" class="ltx_text" style="font-size:90%;">A summary of a DTL-based ASR technique in medical diagnosis, whereas the marks (<math id="S4.T11.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T11.3.1.m1.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T11.3.1.m1.1.1" xref="S4.T11.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T11.3.1.m1.1c"><ci id="S4.T11.3.1.m1.1.1.cmml" xref="S4.T11.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.3.1.m1.1d">\uparrow</annotation></semantics></math>) and (<math id="S4.T11.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T11.4.2.m2.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T11.4.2.m2.1.1" xref="S4.T11.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T11.4.2.m2.1c"><ci id="S4.T11.4.2.m2.1.1.cmml" xref="S4.T11.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.4.2.m2.1d">\downarrow</annotation></semantics></math>) indicate the improvement and reduction, respectively. If many scenarios have been conducted in one metric, only the best result is mentioned.</span></figcaption>
<table id="S4.T11.11" class="ltx_tabular ltx_align_middle">
<tr id="S4.T11.6.2" class="ltx_tr">
<td id="S4.T11.6.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T11.6.2.3.1" class="ltx_text" style="font-size:90%;color:#000000;">Scheme</span></td>
<td id="S4.T11.6.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.6.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.6.2.4.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.6.2.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Model-based</span></span>
</span>
</td>
<td id="S4.T11.6.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.6.2.2.2" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.6.2.2.2.2" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.6.2.2.2.2.1" class="ltx_text" style="font-size:90%;color:#000000;">ASR Tasks (</span><math id="S4.T11.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S4.T11.5.1.1.1.1.m1.1a"><msub id="S4.T11.5.1.1.1.1.m1.1.1" xref="S4.T11.5.1.1.1.1.m1.1.1.cmml"><mi mathcolor="#000000" mathsize="90%" id="S4.T11.5.1.1.1.1.m1.1.1.2" xref="S4.T11.5.1.1.1.1.m1.1.1.2.cmml">𝕋</mi><mi mathcolor="#000000" mathsize="90%" id="S4.T11.5.1.1.1.1.m1.1.1.3" xref="S4.T11.5.1.1.1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T11.5.1.1.1.1.m1.1b"><apply id="S4.T11.5.1.1.1.1.m1.1.1.cmml" xref="S4.T11.5.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T11.5.1.1.1.1.m1.1.1.1.cmml" xref="S4.T11.5.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T11.5.1.1.1.1.m1.1.1.2.cmml" xref="S4.T11.5.1.1.1.1.m1.1.1.2">𝕋</ci><ci id="S4.T11.5.1.1.1.1.m1.1.1.3.cmml" xref="S4.T11.5.1.1.1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.5.1.1.1.1.m1.1c">\mathbb{T}_{T}</annotation></semantics></math><span id="S4.T11.6.2.2.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">) </span><math id="S4.T11.6.2.2.2.2.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T11.6.2.2.2.2.m2.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T11.6.2.2.2.2.m2.1.1" xref="S4.T11.6.2.2.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T11.6.2.2.2.2.m2.1b"><ci id="S4.T11.6.2.2.2.2.m2.1.1.cmml" xref="S4.T11.6.2.2.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.6.2.2.2.2.m2.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T11.6.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.6.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.6.2.5.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.6.2.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">DTL Type</span></span>
</span>
</td>
<td id="S4.T11.6.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.6.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.6.2.6.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.6.2.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Performance</span></span>
</span>
</td>
</tr>
<tr id="S4.T11.11.8" class="ltx_tr">
<td id="S4.T11.11.8.1" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.11.8.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">43</span></a><span id="S4.T11.11.8.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.11.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.11.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.8.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.11.8.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">DenseNet-161</span></span>
</span>
</td>
<td id="S4.T11.11.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.11.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.8.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.11.8.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">PD detection</span></span>
</span>
</td>
<td id="S4.T11.11.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.11.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.8.4.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.11.8.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T11.11.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T11.11.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.8.5.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.11.8.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Accuracy= 91.17%</span></span>
</span>
</td>
</tr>
<tr id="S4.T11.11.9" class="ltx_tr">
<td id="S4.T11.11.9.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.11.9.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">42</span></a><span id="S4.T11.11.9.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.11.9.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.9.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.11.9.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">TSTL-based CSC&amp;SF</span></span>
</span>
</td>
<td id="S4.T11.11.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.9.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.11.9.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">PD speech diagnosis</span></span>
</span>
</td>
<td id="S4.T11.11.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.9.4.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.11.9.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Unsupervised</span></span>
</span>
</td>
<td id="S4.T11.11.9.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.9.5.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.11.9.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Accuracy= 97.50%</span></span>
</span>
</td>
</tr>
<tr id="S4.T11.7.3" class="ltx_tr">
<td id="S4.T11.7.3.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.7.3.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">45</span></a><span id="S4.T11.7.3.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.7.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.7.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.7.3.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.7.3.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Proposed four layers</span></span>
</span>
</td>
<td id="S4.T11.7.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.7.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.7.3.4.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.7.3.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">PD
speech</span></span>
</span>
</td>
<td id="S4.T11.7.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.7.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.7.3.5.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.7.3.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T11.7.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.7.3.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.7.3.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">13.5% WER</span><math id="S4.T11.7.3.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T11.7.3.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T11.7.3.1.1.1.m1.1.1" xref="S4.T11.7.3.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T11.7.3.1.1.1.m1.1b"><ci id="S4.T11.7.3.1.1.1.m1.1.1.cmml" xref="S4.T11.7.3.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.7.3.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T11.11.10" class="ltx_tr">
<td id="S4.T11.11.10.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.11.10.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">koike2020audio</span><span id="S4.T11.11.10.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.11.10.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.10.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.11.10.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">PANN CNN14</span></span>
</span>
</td>
<td id="S4.T11.11.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.10.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.11.10.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Heart sound classification</span></span>
</span>
</td>
<td id="S4.T11.11.10.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.10.4.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.11.10.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T11.11.10.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.10.5.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.11.10.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">UAR= 89.7%</span></span>
</span>
</td>
</tr>
<tr id="S4.T11.11.11" class="ltx_tr">
<td id="S4.T11.11.11.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.11.11.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">boulares2020transfer</span><span id="S4.T11.11.11.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.11.11.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.11.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.11.11.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">InceptionResNet-v2</span></span>
</span>
</td>
<td id="S4.T11.11.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.11.3.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.11.11.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">PCG-based CVD classification</span></span>
</span>
</td>
<td id="S4.T11.11.11.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.11.4.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.11.11.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fine-tuning</span></span>
</span>
</td>
<td id="S4.T11.11.11.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.11.5.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.11.11.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Accuracy= 0.89%</span></span>
</span>
</td>
</tr>
<tr id="S4.T11.8.4" class="ltx_tr">
<td id="S4.T11.8.4.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.8.4.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">harati2021speech</span><span id="S4.T11.8.4.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.8.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.8.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.8.4.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.8.4.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">EH-AC</span></span>
</span>
</td>
<td id="S4.T11.8.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.8.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.8.4.4.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.8.4.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Depression prediction</span></span>
</span>
</td>
<td id="S4.T11.8.4.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.8.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.8.4.5.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.8.4.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">LHN (encoder weights)</span></span>
</span>
</td>
<td id="S4.T11.8.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.8.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.8.4.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.8.4.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">27% AUC </span><math id="S4.T11.8.4.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T11.8.4.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T11.8.4.1.1.1.m1.1.1" xref="S4.T11.8.4.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T11.8.4.1.1.1.m1.1b"><ci id="S4.T11.8.4.1.1.1.m1.1.1.cmml" xref="S4.T11.8.4.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.8.4.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T11.9.5" class="ltx_tr">
<td id="S4.T11.9.5.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.9.5.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">xiong2020source</span><span id="S4.T11.9.5.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.9.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.9.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.9.5.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.9.5.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">CNN-TDNN-F</span></span>
</span>
</td>
<td id="S4.T11.9.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.9.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.9.5.4.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.9.5.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Dysarthric speech</span></span>
</span>
</td>
<td id="S4.T11.9.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.9.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.9.5.5.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.9.5.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Neural weight adapter</span></span>
</span>
</td>
<td id="S4.T11.9.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.9.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.9.5.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.9.5.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">11.6% WER</span><math id="S4.T11.9.5.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T11.9.5.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T11.9.5.1.1.1.m1.1.1" xref="S4.T11.9.5.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T11.9.5.1.1.1.m1.1b"><ci id="S4.T11.9.5.1.1.1.m1.1.1.cmml" xref="S4.T11.9.5.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.9.5.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T11.10.6" class="ltx_tr">
<td id="S4.T11.10.6.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.10.6.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">takashima2019knowledge</span><span id="S4.T11.10.6.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.10.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.10.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.10.6.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.10.6.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">LAS</span></span>
</span>
</td>
<td id="S4.T11.10.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.10.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.10.6.4.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.10.6.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Dysarthric Speech</span></span>
</span>
</td>
<td id="S4.T11.10.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.10.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.10.6.5.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.10.6.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Multilingual</span></span>
</span>
</td>
<td id="S4.T11.10.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T11.10.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.10.6.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.10.6.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">45.9% PER</span><math id="S4.T11.10.6.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T11.10.6.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T11.10.6.1.1.1.m1.1.1" xref="S4.T11.10.6.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T11.10.6.1.1.1.m1.1b"><ci id="S4.T11.10.6.1.1.1.m1.1.1.cmml" xref="S4.T11.10.6.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.10.6.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T11.11.7" class="ltx_tr">
<td id="S4.T11.11.7.2" class="ltx_td ltx_align_left ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T11.11.7.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">sertolli2021representation</span><span id="S4.T11.11.7.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T11.11.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T11.11.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.7.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T11.11.7.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Wav2Letter and </span>
<br class="ltx_break"><span id="S4.T11.11.7.3.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">DeepSpeech</span></span>
</span>
</td>
<td id="S4.T11.11.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T11.11.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.7.4.1.1" class="ltx_p" style="width:99.6pt;"><span id="S4.T11.11.7.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Health states classification</span></span>
</span>
</td>
<td id="S4.T11.11.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T11.11.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.7.5.1.1" class="ltx_p" style="width:102.4pt;"><span id="S4.T11.11.7.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Transductive</span></span>
</span>
</td>
<td id="S4.T11.11.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T11.11.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T11.11.7.1.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T11.11.7.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">UAR= 73.0% (8.6% </span><math id="S4.T11.11.7.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T11.11.7.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T11.11.7.1.1.1.m1.1.1" xref="S4.T11.11.7.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T11.11.7.1.1.1.m1.1b"><ci id="S4.T11.11.7.1.1.1.m1.1.1.cmml" xref="S4.T11.11.7.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.11.7.1.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S4.T11.11.7.1.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">)</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>DTL-based ASR attacks and security</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p"><span id="S4.SS7.p1.1.1" class="ltx_text" style="color:#000000;">Adversarial examples are created by introducing small perturbations or noise to valid audio files or speech characteristics in order to manipulate or deceive ASR systems. These perturbations, although often imperceptible to the human auditory system and may be perceived as background noise by the ASR model, can lead to correct or incorrect classification of the inputs. For instance, by introducing a slight disturbance to the speech "At the still point, there the dance is," an ASR system may produce the incorrect transcription "At the tail point, there the tense is" </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS7.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2019adversarial</span><span id="S4.SS7.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS7.p1.1.4" class="ltx_text" style="color:#000000;">. The concept behind attacking ASR systems lies in the vulnerability of these models to adversarial examples, which has prompted speech researchers to explore the creation of such examples. By generating adversarial examples for different representations of speech in the time or frequency domain, which capture various speech features and can be used as inputs to neural networks, researchers can manipulate ASR performance, either improving it or decreasing it. DTL plays a key role in achieving transferability, whereby adversarial examples crafted to attack a source model can also be effective in attacking target models that classify the same type of data. In this context, adversarial attacks on DTL-based ASR models can be categorized into two groups, as illustrated in Fig. </span><a href="#S4.F18" title="Figure 18 ‣ 4.7 DTL-based ASR attacks and security ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">18</span></a><span id="S4.SS7.p1.1.5" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<figure id="S4.F18" class="ltx_figure"><img src="/html/2403.01255/assets/Attacks-ASR.pdf" id="S4.F18.g1" class="ltx_graphics ltx_centering" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="color:#000000;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F18.4.1.1" class="ltx_text" style="font-size:90%;">Figure 18</span>: </span><span id="S4.F18.5.2" class="ltx_text" style="font-size:90%;"> Possible adversarial attacks in DTL-based ASR schemes.</span></figcaption>
</figure>
<section id="S4.SS7.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.7.1 </span>Positive adversarial attacks</h4>

<div id="S4.SS7.SSS1.p1" class="ltx_para">
<p id="S4.SS7.SSS1.p1.1" class="ltx_p"><span id="S4.SS7.SSS1.p1.1.1" class="ltx_text" style="color:#000000;">Encompassing various techniques that aim to enhance or ensure the efficacy of current ASR systems, these methods strive to improve the robustness and performance of acoustic models. In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS7.SSS1.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018training</span><span id="S4.SS7.SSS1.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS7.SSS1.p1.1.4" class="ltx_text" style="color:#000000;">, the authors introduced a methodology that combines natural data with adversarial data to train a resilient acoustic model. Specifically, they focused on utilizing MFCC features and employed a gradient-based approach to generate adversarial MFCC features, taking into account the network model and input parameters for each mini-batch. By applying the teacher/student training concept, the neural network was trained using a combination of natural data and the generated adversarial data. The effectiveness of the proposed approach was validated through experiments conducted on the CHiME-4 and Aurora-4 tasks, utilizing a customized convolutional neural network (CNN).</span></p>
</div>
</section>
<section id="S4.SS7.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsubsection">4.7.2 </span>Negative adversarial attacks</h4>

<div id="S4.SS7.SSS2.p1" class="ltx_para">
<p id="S4.SS7.SSS2.p1.1" class="ltx_p"><span id="S4.SS7.SSS2.p1.1.1" class="ltx_text" style="color:#000000;">Encompassing various techniques that aim to diminish or undermine the effectiveness of existing ASR systems, these methods pose potential threats to the performance and robustness of acoustic models. In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS7.SSS2.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">abdullah2021hear</span><span id="S4.SS7.SSS2.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS7.SSS2.p1.1.4" class="ltx_text" style="color:#000000;">, the authors propose a framework that utilizes the Google (Phone) model as the source model and investigates the impact of adversarial attacks on the target model (DeepSpeech 1). The adversarial attacks are applied to the audio waveform, specifically after the signal decomposition and thresholding processes, and the resulting manipulated input is fed into the ASR source model. According to </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS7.SSS2.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2019adversarial</span><span id="S4.SS7.SSS2.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS7.SSS2.p1.1.7" class="ltx_text" style="color:#000000;">, the adversarial attack models can be categorized into two types based on the adversary’s objectives, knowledge, and background, as illustrated in Figure </span><a href="#S4.F18" title="Figure 18 ‣ 4.7 DTL-based ASR attacks and security ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">18</span></a><span id="S4.SS7.SSS2.p1.1.8" class="ltx_text" style="color:#000000;">:</span></p>
</div>
<div id="S4.SS7.SSS2.p2" class="ltx_para">
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.2" class="ltx_p"><span id="S4.I3.i1.p1.2.1" class="ltx_text ltx_font_bold" style="color:#000000;">Adversary knowledge:</span><span id="S4.I3.i1.p1.2.2" class="ltx_text" style="color:#000000;"> It is divided into two types: white-box attack, which assumes the adversary has complete knowledge of </span><math id="S4.I3.i1.p1.1.m1.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.I3.i1.p1.1.m1.1a"><msub id="S4.I3.i1.p1.1.m1.1.1" xref="S4.I3.i1.p1.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S4.I3.i1.p1.1.m1.1.1.2" xref="S4.I3.i1.p1.1.m1.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.I3.i1.p1.1.m1.1.1.3" xref="S4.I3.i1.p1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I3.i1.p1.1.m1.1b"><apply id="S4.I3.i1.p1.1.m1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.I3.i1.p1.1.m1.1.1.1.cmml" xref="S4.I3.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.I3.i1.p1.1.m1.1.1.2.cmml" xref="S4.I3.i1.p1.1.m1.1.1.2">𝑀</ci><ci id="S4.I3.i1.p1.1.m1.1.1.3.cmml" xref="S4.I3.i1.p1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i1.p1.1.m1.1c">M_{T}</annotation></semantics></math><span id="S4.I3.i1.p1.2.3" class="ltx_text" style="color:#000000;"> including its architecture, training weights, and parameters; and black-box attack, which assumes the adversary has no access to </span><math id="S4.I3.i1.p1.2.m2.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.I3.i1.p1.2.m2.1a"><msub id="S4.I3.i1.p1.2.m2.1.1" xref="S4.I3.i1.p1.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S4.I3.i1.p1.2.m2.1.1.2" xref="S4.I3.i1.p1.2.m2.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.I3.i1.p1.2.m2.1.1.3" xref="S4.I3.i1.p1.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I3.i1.p1.2.m2.1b"><apply id="S4.I3.i1.p1.2.m2.1.1.cmml" xref="S4.I3.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.I3.i1.p1.2.m2.1.1.1.cmml" xref="S4.I3.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.I3.i1.p1.2.m2.1.1.2.cmml" xref="S4.I3.i1.p1.2.m2.1.1.2">𝑀</ci><ci id="S4.I3.i1.p1.2.m2.1.1.3.cmml" xref="S4.I3.i1.p1.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i1.p1.2.m2.1c">M_{T}</annotation></semantics></math><span id="S4.I3.i1.p1.2.4" class="ltx_text" style="color:#000000;"> and only knows its output like a regular user.</span></p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.2" class="ltx_p"><span id="S4.I3.i2.p1.2.1" class="ltx_text ltx_font_bold" style="color:#000000;">Adversarial specificity:</span><span id="S4.I3.i2.p1.2.2" class="ltx_text" style="color:#000000;"> It is divided into two types: non-targeted attack, which aims to make the adversarial example’s </span><math id="S4.I3.i2.p1.1.m1.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.I3.i2.p1.1.m1.1a"><msub id="S4.I3.i2.p1.1.m1.1.1" xref="S4.I3.i2.p1.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S4.I3.i2.p1.1.m1.1.1.2" xref="S4.I3.i2.p1.1.m1.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.I3.i2.p1.1.m1.1.1.3" xref="S4.I3.i2.p1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.1.m1.1b"><apply id="S4.I3.i2.p1.1.m1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.I3.i2.p1.1.m1.1.1.1.cmml" xref="S4.I3.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.I3.i2.p1.1.m1.1.1.2.cmml" xref="S4.I3.i2.p1.1.m1.1.1.2">𝑀</ci><ci id="S4.I3.i2.p1.1.m1.1.1.3.cmml" xref="S4.I3.i2.p1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.1.m1.1c">M_{T}</annotation></semantics></math><span id="S4.I3.i2.p1.2.3" class="ltx_text" style="color:#000000;"> predict any incorrect class with the sole goal of compromising the ASR algorithm, and targeted attack, which aims to deceive </span><math id="S4.I3.i2.p1.2.m2.1" class="ltx_Math" alttext="M_{T}" display="inline"><semantics id="S4.I3.i2.p1.2.m2.1a"><msub id="S4.I3.i2.p1.2.m2.1.1" xref="S4.I3.i2.p1.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S4.I3.i2.p1.2.m2.1.1.2" xref="S4.I3.i2.p1.2.m2.1.1.2.cmml">M</mi><mi mathcolor="#000000" id="S4.I3.i2.p1.2.m2.1.1.3" xref="S4.I3.i2.p1.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I3.i2.p1.2.m2.1b"><apply id="S4.I3.i2.p1.2.m2.1.1.cmml" xref="S4.I3.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.I3.i2.p1.2.m2.1.1.1.cmml" xref="S4.I3.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.I3.i2.p1.2.m2.1.1.2.cmml" xref="S4.I3.i2.p1.2.m2.1.1.2">𝑀</ci><ci id="S4.I3.i2.p1.2.m2.1.1.3.cmml" xref="S4.I3.i2.p1.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I3.i2.p1.2.m2.1c">M_{T}</annotation></semantics></math><span id="S4.I3.i2.p1.2.4" class="ltx_text" style="color:#000000;"> into assigning the adversarial example to a specific class selected by the attacker, imposing specific instructions on the ASR scheme.</span></p>
</div>
</li>
</ul>
</div>
<div id="S4.SS7.SSS2.p3" class="ltx_para">
<p id="S4.SS7.SSS2.p3.1" class="ltx_p"><span id="S4.SS7.SSS2.p3.1.1" class="ltx_text" style="color:#000000;">Moving on, Table </span><a href="#S4.T12" title="Table 12 ‣ 4.7.2 Negative adversarial attacks ‣ 4.7 DTL-based ASR attacks and security ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">12</span></a><span id="S4.SS7.SSS2.p3.1.2" class="ltx_text" style="color:#000000;"> shows a summary of DTL-based adversarial models for existing works.</span></p>
</div>
<figure id="S4.T12" class="ltx_table">
<figcaption class="ltx_caption" style="color:#000000;"><span class="ltx_tag ltx_tag_table"><span id="S4.T12.13.3.1" class="ltx_text" style="font-size:90%;">Table 12</span>: </span><span id="S4.T12.4.2" class="ltx_text" style="font-size:90%;">A summary of the recent DTL-based ASR for adversarial attacks. Whereas the marks (<math id="S4.T12.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T12.3.1.m1.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T12.3.1.m1.1.1" xref="S4.T12.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T12.3.1.m1.1c"><ci id="S4.T12.3.1.m1.1.1.cmml" xref="S4.T12.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T12.3.1.m1.1d">\uparrow</annotation></semantics></math>)and (<math id="S4.T12.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T12.4.2.m2.1b"><mo mathcolor="#000000" stretchy="false" id="S4.T12.4.2.m2.1.1" xref="S4.T12.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T12.4.2.m2.1c"><ci id="S4.T12.4.2.m2.1.1.cmml" xref="S4.T12.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T12.4.2.m2.1d">\downarrow</annotation></semantics></math>), indicate improvement and reduction respectively.</span></figcaption>
<table id="S4.T12.7" class="ltx_tabular ltx_align_middle">
<tr id="S4.T12.5.1" class="ltx_tr">
<td id="S4.T12.5.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T12.5.1.2.1" class="ltx_text" style="font-size:90%;color:#000000;">Scheme</span></td>
<td id="S4.T12.5.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.5.1.3.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T12.5.1.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Model-based</span></span>
</span>
</td>
<td id="S4.T12.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.5.1.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.5.1.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">ASR Tasks (</span><math id="S4.T12.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathbb{T}_{T}" display="inline"><semantics id="S4.T12.5.1.1.1.1.m1.1a"><msub id="S4.T12.5.1.1.1.1.m1.1.1" xref="S4.T12.5.1.1.1.1.m1.1.1.cmml"><mi mathcolor="#000000" mathsize="90%" id="S4.T12.5.1.1.1.1.m1.1.1.2" xref="S4.T12.5.1.1.1.1.m1.1.1.2.cmml">𝕋</mi><mi mathcolor="#000000" mathsize="90%" id="S4.T12.5.1.1.1.1.m1.1.1.3" xref="S4.T12.5.1.1.1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T12.5.1.1.1.1.m1.1b"><apply id="S4.T12.5.1.1.1.1.m1.1.1.cmml" xref="S4.T12.5.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T12.5.1.1.1.1.m1.1.1.1.cmml" xref="S4.T12.5.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T12.5.1.1.1.1.m1.1.1.2.cmml" xref="S4.T12.5.1.1.1.1.m1.1.1.2">𝕋</ci><ci id="S4.T12.5.1.1.1.1.m1.1.1.3.cmml" xref="S4.T12.5.1.1.1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T12.5.1.1.1.1.m1.1c">\mathbb{T}_{T}</annotation></semantics></math><span id="S4.T12.5.1.1.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">)</span></span>
</span>
</td>
<td id="S4.T12.5.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.5.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.5.1.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.5.1.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Target object</span></span>
</span>
</td>
<td id="S4.T12.5.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.5.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.5.1.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.5.1.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Adversary knowledge</span></span>
</span>
</td>
<td id="S4.T12.5.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.5.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.5.1.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.5.1.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Adversarial specificity</span></span>
</span>
</td>
<td id="S4.T12.5.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.5.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.5.1.7.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.5.1.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Performance</span></span>
</span>
</td>
</tr>
<tr id="S4.T12.6.2" class="ltx_tr">
<td id="S4.T12.6.2.2" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T12.6.2.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018training</span><span id="S4.T12.6.2.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T12.6.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.6.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.6.2.3.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T12.6.2.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Aurora-4</span></span>
</span>
</td>
<td id="S4.T12.6.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.6.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.6.2.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.6.2.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Boost</span></span>
</span>
</td>
<td id="S4.T12.6.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.6.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.6.2.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.6.2.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">MFCC</span></span>
</span>
</td>
<td id="S4.T12.6.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.6.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.6.2.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.6.2.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">White-box</span></span>
</span>
</td>
<td id="S4.T12.6.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.6.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.6.2.7.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.6.2.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Targeted</span></span>
</span>
</td>
<td id="S4.T12.6.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T12.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.6.2.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.6.2.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">23% WER </span><math id="S4.T12.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T12.6.2.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T12.6.2.1.1.1.m1.1.1" xref="S4.T12.6.2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T12.6.2.1.1.1.m1.1b"><ci id="S4.T12.6.2.1.1.1.m1.1.1.cmml" xref="S4.T12.6.2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T12.6.2.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T12.7.4" class="ltx_tr">
<td id="S4.T12.7.4.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T12.7.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">schonherr2018adversarial</span><span id="S4.T12.7.4.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T12.7.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.4.2.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T12.7.4.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">DNN-HMM (Kaldi)</span></span>
</span>
</td>
<td id="S4.T12.7.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.4.3.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.4.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Boost</span></span>
</span>
</td>
<td id="S4.T12.7.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.4.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.4.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Waveform</span></span>
</span>
</td>
<td id="S4.T12.7.4.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.4.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.4.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">White-box</span></span>
</span>
</td>
<td id="S4.T12.7.4.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.4.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.4.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Targeted</span></span>
</span>
</td>
<td id="S4.T12.7.4.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.4.7.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.4.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Accuracy= 98 %</span></span>
</span>
</td>
</tr>
<tr id="S4.T12.7.3" class="ltx_tr">
<td id="S4.T12.7.3.2" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T12.7.3.2.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">zelasko2021adversarial</span><span id="S4.T12.7.3.2.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T12.7.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.3.3.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T12.7.3.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">DeepSpeech</span></span>
</span>
</td>
<td id="S4.T12.7.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.3.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.3.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fool</span></span>
</span>
</td>
<td id="S4.T12.7.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.3.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.3.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Waveform</span></span>
</span>
</td>
<td id="S4.T12.7.3.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.3.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.3.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">White-box</span></span>
</span>
</td>
<td id="S4.T12.7.3.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.3.7.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.3.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Targeted</span></span>
</span>
</td>
<td id="S4.T12.7.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.3.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.3.1.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">4-5% WER</span><math id="S4.T12.7.3.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T12.7.3.1.1.1.m1.1a"><mo mathcolor="#000000" mathsize="90%" stretchy="false" id="S4.T12.7.3.1.1.1.m1.1.1" xref="S4.T12.7.3.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T12.7.3.1.1.1.m1.1b"><ci id="S4.T12.7.3.1.1.1.m1.1.1.cmml" xref="S4.T12.7.3.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T12.7.3.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S4.T12.7.5" class="ltx_tr">
<td id="S4.T12.7.5.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T12.7.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">subramanian2020study</span><span id="S4.T12.7.5.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T12.7.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.5.2.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T12.7.5.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">VGG13</span></span>
</span>
</td>
<td id="S4.T12.7.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.5.3.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.5.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fool (Dense_mel)</span></span>
</span>
</td>
<td id="S4.T12.7.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.5.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.5.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Mel-spectrogram</span></span>
</span>
</td>
<td id="S4.T12.7.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.5.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.5.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">White-box</span></span>
</span>
</td>
<td id="S4.T12.7.5.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.5.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.5.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Non-targeted</span></span>
</span>
</td>
<td id="S4.T12.7.5.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.5.7.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.5.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">SNR=29.06 dB</span></span>
</span>
</td>
</tr>
<tr id="S4.T12.7.6" class="ltx_tr">
<td id="S4.T12.7.6.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T12.7.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">carlini2018audio</span><span id="S4.T12.7.6.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T12.7.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.6.2.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T12.7.6.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">DeepSpeech</span></span>
</span>
</td>
<td id="S4.T12.7.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.6.3.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.6.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fool (Speech-to-Text)</span></span>
</span>
</td>
<td id="S4.T12.7.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.6.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.6.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Waveform</span></span>
</span>
</td>
<td id="S4.T12.7.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.6.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.6.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">White-box</span></span>
</span>
</td>
<td id="S4.T12.7.6.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.6.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.6.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Targeted</span></span>
</span>
</td>
<td id="S4.T12.7.6.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.6.7.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.6.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Attack success rate= 100%</span></span>
</span>
</td>
</tr>
<tr id="S4.T12.7.7" class="ltx_tr">
<td id="S4.T12.7.7.1" class="ltx_td ltx_align_left"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T12.7.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">abdullah2021hear</span><span id="S4.T12.7.7.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T12.7.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.7.2.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T12.7.7.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Google </span>
<br class="ltx_break"><span id="S4.T12.7.7.2.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">(Phone)</span></span>
</span>
</td>
<td id="S4.T12.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.7.3.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.7.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fool </span>
<br class="ltx_break"><span id="S4.T12.7.7.3.1.1.2" class="ltx_text" style="font-size:90%;color:#000000;">(Deep-Speech 1)</span></span>
</span>
</td>
<td id="S4.T12.7.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.7.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.7.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Waveform</span></span>
</span>
</td>
<td id="S4.T12.7.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.7.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.7.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Black-box</span></span>
</span>
</td>
<td id="S4.T12.7.7.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.7.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.7.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Non-targeted</span></span>
</span>
</td>
<td id="S4.T12.7.7.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T12.7.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.7.7.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.7.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Attack success rate=87%</span></span>
</span>
</td>
</tr>
<tr id="S4.T12.7.8" class="ltx_tr">
<td id="S4.T12.7.8.1" class="ltx_td ltx_align_left ltx_border_b"><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T12.7.8.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">kwon2019selective</span><span id="S4.T12.7.8.1.2.2" class="ltx_text" style="font-size:90%;color:#000000;">]</span></cite></td>
<td id="S4.T12.7.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T12.7.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.8.2.1.1" class="ltx_p" style="width:79.7pt;"><span id="S4.T12.7.8.2.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">DeepSpeech</span></span>
</span>
</td>
<td id="S4.T12.7.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T12.7.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.8.3.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.8.3.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Fool (victime DeepSpeech)</span></span>
</span>
</td>
<td id="S4.T12.7.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T12.7.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.8.4.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.8.4.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Mel-frequency
cepstrum</span></span>
</span>
</td>
<td id="S4.T12.7.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T12.7.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.8.5.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.8.5.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">White-box</span></span>
</span>
</td>
<td id="S4.T12.7.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T12.7.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.8.6.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T12.7.8.6.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Targeted</span></span>
</span>
</td>
<td id="S4.T12.7.8.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S4.T12.7.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T12.7.8.7.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T12.7.8.7.1.1.1" class="ltx_text" style="font-size:90%;color:#000000;">Attack success rate=91.67%)</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S4.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">4.8 </span>DTL-based ASR for other applications</h3>

<div id="S4.SS8.p1" class="ltx_para">
<p id="S4.SS8.p1.1" class="ltx_p"><span id="S4.SS8.p1.1.1" class="ltx_text" style="color:#000000;">DTL-based ASR has been applied in various fields. In the work by Boes et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">12</span></a><span id="S4.SS8.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.4" class="ltx_text" style="color:#000000;">, DTL is explored for audio tagging and sound event detection tasks, where pre-trained auditory and visual features are incorporated into a baseline system using feature fusion. Arora et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">arora2017study</span><span id="S4.SS8.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.7" class="ltx_text" style="color:#000000;"> use DTL to address the lack of annotated databases for audio event detection. Wang et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.8.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020cross</span><span id="S4.SS8.p1.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.10" class="ltx_text" style="color:#000000;"> propose an environment adaptation technique using DTL for deep speech enhancement models. Chen et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.11.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2018transfer</span><span id="S4.SS8.p1.1.12.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.13" class="ltx_text" style="color:#000000;"> employ DTL for wearable devices to evaluate social speech in natural daily situations. Wu et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.14.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2020self</span><span id="S4.SS8.p1.1.15.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.16" class="ltx_text" style="color:#000000;"> investigate self-supervised pre-trained speech for speech translation, while Zhu et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.17.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2021conwst</span><span id="S4.SS8.p1.1.18.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.19" class="ltx_text" style="color:#000000;"> propose a self-supervised bidirectional distillation system for low-resource speech translation. DTL is used in the speaker verification field by Hong et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.20.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">hong2017transfer</span><span id="S4.SS8.p1.1.21.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.22" class="ltx_text" style="color:#000000;"> for discriminative learning, and in the detection of marine mammal sounds by Lu et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.23.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">lu2021detection</span><span id="S4.SS8.p1.1.24.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.25" class="ltx_text" style="color:#000000;"> to classify different species using DTL with the AlexNet pre-trained model. Lastly, Azizah et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS8.p1.1.26.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">azizah2020hierarchical</span><span id="S4.SS8.p1.1.27.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S4.SS8.p1.1.28" class="ltx_text" style="color:#000000;"> employ hierarchical DTL for multilingual text-to-speech synthesis using DNNs for low-resource languages.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="color:#000000;">
<span class="ltx_tag ltx_tag_section">5 </span>Open Issues and of Key challenges</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text" style="color:#000000;">Integrating advanced techniques like </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S5.p1.1.2" class="ltx_text" style="color:#000000;">, </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S5.p1.1.3" class="ltx_text" style="color:#000000;">, and </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S5.p1.1.4" class="ltx_text" style="color:#000000;"> into </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.p1.1.5" class="ltx_text" style="color:#000000;"> systems presents exciting opportunities but comes with its set of challenges. This section delves into the distinct challenges associated with each approach, emphasizing the critical areas that demand attention and innovation.</span></p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>DTL and domain adaptation</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text" style="color:#000000;">This section discusses challenges and concepts related to </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S5.SS1.p1.1.2" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a><span id="S5.SS1.p1.1.3" class="ltx_text" style="color:#000000;"> in speech recognition, including distribution shift, feature space adaptation, label distribution shift, catastrophic forgetting, domain-invariant feature learning, sample selection bias, and hyperparameter optimization.</span></p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.19" class="ltx_p"><span id="S5.SS1.p2.19.1" class="ltx_text" style="color:#000000;">When applying a model trained on one domain (source) to another (target), a </span><span id="S5.SS1.p2.19.2" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">distribution shift</span><span id="S5.SS1.p2.19.3" class="ltx_text" style="color:#000000;"> often occurs, referred to as domain shift. Formally, if </span><math id="S5.SS1.p2.1.m1.2" class="ltx_Math" alttext="P_{S}(X,Y)" display="inline"><semantics id="S5.SS1.p2.1.m1.2a"><mrow id="S5.SS1.p2.1.m1.2.3" xref="S5.SS1.p2.1.m1.2.3.cmml"><msub id="S5.SS1.p2.1.m1.2.3.2" xref="S5.SS1.p2.1.m1.2.3.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.1.m1.2.3.2.2" xref="S5.SS1.p2.1.m1.2.3.2.2.cmml">P</mi><mi mathcolor="#000000" id="S5.SS1.p2.1.m1.2.3.2.3" xref="S5.SS1.p2.1.m1.2.3.2.3.cmml">S</mi></msub><mo lspace="0em" rspace="0em" id="S5.SS1.p2.1.m1.2.3.1" xref="S5.SS1.p2.1.m1.2.3.1.cmml">​</mo><mrow id="S5.SS1.p2.1.m1.2.3.3.2" xref="S5.SS1.p2.1.m1.2.3.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.1.m1.2.3.3.2.1" xref="S5.SS1.p2.1.m1.2.3.3.1.cmml">(</mo><mi mathcolor="#000000" id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">X</mi><mo mathcolor="#000000" id="S5.SS1.p2.1.m1.2.3.3.2.2" xref="S5.SS1.p2.1.m1.2.3.3.1.cmml">,</mo><mi mathcolor="#000000" id="S5.SS1.p2.1.m1.2.2" xref="S5.SS1.p2.1.m1.2.2.cmml">Y</mi><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.1.m1.2.3.3.2.3" xref="S5.SS1.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.2b"><apply id="S5.SS1.p2.1.m1.2.3.cmml" xref="S5.SS1.p2.1.m1.2.3"><times id="S5.SS1.p2.1.m1.2.3.1.cmml" xref="S5.SS1.p2.1.m1.2.3.1"></times><apply id="S5.SS1.p2.1.m1.2.3.2.cmml" xref="S5.SS1.p2.1.m1.2.3.2"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.2.3.2.1.cmml" xref="S5.SS1.p2.1.m1.2.3.2">subscript</csymbol><ci id="S5.SS1.p2.1.m1.2.3.2.2.cmml" xref="S5.SS1.p2.1.m1.2.3.2.2">𝑃</ci><ci id="S5.SS1.p2.1.m1.2.3.2.3.cmml" xref="S5.SS1.p2.1.m1.2.3.2.3">𝑆</ci></apply><interval closure="open" id="S5.SS1.p2.1.m1.2.3.3.1.cmml" xref="S5.SS1.p2.1.m1.2.3.3.2"><ci id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">𝑋</ci><ci id="S5.SS1.p2.1.m1.2.2.cmml" xref="S5.SS1.p2.1.m1.2.2">𝑌</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.2c">P_{S}(X,Y)</annotation></semantics></math><span id="S5.SS1.p2.19.4" class="ltx_text" style="color:#000000;"> and </span><math id="S5.SS1.p2.2.m2.2" class="ltx_Math" alttext="P_{T}(X,Y)" display="inline"><semantics id="S5.SS1.p2.2.m2.2a"><mrow id="S5.SS1.p2.2.m2.2.3" xref="S5.SS1.p2.2.m2.2.3.cmml"><msub id="S5.SS1.p2.2.m2.2.3.2" xref="S5.SS1.p2.2.m2.2.3.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.2.m2.2.3.2.2" xref="S5.SS1.p2.2.m2.2.3.2.2.cmml">P</mi><mi mathcolor="#000000" id="S5.SS1.p2.2.m2.2.3.2.3" xref="S5.SS1.p2.2.m2.2.3.2.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S5.SS1.p2.2.m2.2.3.1" xref="S5.SS1.p2.2.m2.2.3.1.cmml">​</mo><mrow id="S5.SS1.p2.2.m2.2.3.3.2" xref="S5.SS1.p2.2.m2.2.3.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.2.m2.2.3.3.2.1" xref="S5.SS1.p2.2.m2.2.3.3.1.cmml">(</mo><mi mathcolor="#000000" id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">X</mi><mo mathcolor="#000000" id="S5.SS1.p2.2.m2.2.3.3.2.2" xref="S5.SS1.p2.2.m2.2.3.3.1.cmml">,</mo><mi mathcolor="#000000" id="S5.SS1.p2.2.m2.2.2" xref="S5.SS1.p2.2.m2.2.2.cmml">Y</mi><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.2.m2.2.3.3.2.3" xref="S5.SS1.p2.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.2b"><apply id="S5.SS1.p2.2.m2.2.3.cmml" xref="S5.SS1.p2.2.m2.2.3"><times id="S5.SS1.p2.2.m2.2.3.1.cmml" xref="S5.SS1.p2.2.m2.2.3.1"></times><apply id="S5.SS1.p2.2.m2.2.3.2.cmml" xref="S5.SS1.p2.2.m2.2.3.2"><csymbol cd="ambiguous" id="S5.SS1.p2.2.m2.2.3.2.1.cmml" xref="S5.SS1.p2.2.m2.2.3.2">subscript</csymbol><ci id="S5.SS1.p2.2.m2.2.3.2.2.cmml" xref="S5.SS1.p2.2.m2.2.3.2.2">𝑃</ci><ci id="S5.SS1.p2.2.m2.2.3.2.3.cmml" xref="S5.SS1.p2.2.m2.2.3.2.3">𝑇</ci></apply><interval closure="open" id="S5.SS1.p2.2.m2.2.3.3.1.cmml" xref="S5.SS1.p2.2.m2.2.3.3.2"><ci id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">𝑋</ci><ci id="S5.SS1.p2.2.m2.2.2.cmml" xref="S5.SS1.p2.2.m2.2.2">𝑌</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.2c">P_{T}(X,Y)</annotation></semantics></math><span id="S5.SS1.p2.19.5" class="ltx_text" style="color:#000000;"> represent the joint distributions of features </span><math id="S5.SS1.p2.3.m3.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S5.SS1.p2.3.m3.1a"><mi mathcolor="#000000" id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><ci id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">X</annotation></semantics></math><span id="S5.SS1.p2.19.6" class="ltx_text" style="color:#000000;"> and labels </span><math id="S5.SS1.p2.4.m4.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S5.SS1.p2.4.m4.1a"><mi mathcolor="#000000" id="S5.SS1.p2.4.m4.1.1" xref="S5.SS1.p2.4.m4.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.1b"><ci id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.1c">Y</annotation></semantics></math><span id="S5.SS1.p2.19.7" class="ltx_text" style="color:#000000;"> in the source and target domains, respectively, the challenge arises when </span><math id="S5.SS1.p2.5.m5.4" class="ltx_Math" alttext="P_{S}(X,Y)\neq P_{T}(X,Y)" display="inline"><semantics id="S5.SS1.p2.5.m5.4a"><mrow id="S5.SS1.p2.5.m5.4.5" xref="S5.SS1.p2.5.m5.4.5.cmml"><mrow id="S5.SS1.p2.5.m5.4.5.2" xref="S5.SS1.p2.5.m5.4.5.2.cmml"><msub id="S5.SS1.p2.5.m5.4.5.2.2" xref="S5.SS1.p2.5.m5.4.5.2.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.5.m5.4.5.2.2.2" xref="S5.SS1.p2.5.m5.4.5.2.2.2.cmml">P</mi><mi mathcolor="#000000" id="S5.SS1.p2.5.m5.4.5.2.2.3" xref="S5.SS1.p2.5.m5.4.5.2.2.3.cmml">S</mi></msub><mo lspace="0em" rspace="0em" id="S5.SS1.p2.5.m5.4.5.2.1" xref="S5.SS1.p2.5.m5.4.5.2.1.cmml">​</mo><mrow id="S5.SS1.p2.5.m5.4.5.2.3.2" xref="S5.SS1.p2.5.m5.4.5.2.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.5.m5.4.5.2.3.2.1" xref="S5.SS1.p2.5.m5.4.5.2.3.1.cmml">(</mo><mi mathcolor="#000000" id="S5.SS1.p2.5.m5.1.1" xref="S5.SS1.p2.5.m5.1.1.cmml">X</mi><mo mathcolor="#000000" id="S5.SS1.p2.5.m5.4.5.2.3.2.2" xref="S5.SS1.p2.5.m5.4.5.2.3.1.cmml">,</mo><mi mathcolor="#000000" id="S5.SS1.p2.5.m5.2.2" xref="S5.SS1.p2.5.m5.2.2.cmml">Y</mi><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.5.m5.4.5.2.3.2.3" xref="S5.SS1.p2.5.m5.4.5.2.3.1.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S5.SS1.p2.5.m5.4.5.1" xref="S5.SS1.p2.5.m5.4.5.1.cmml">≠</mo><mrow id="S5.SS1.p2.5.m5.4.5.3" xref="S5.SS1.p2.5.m5.4.5.3.cmml"><msub id="S5.SS1.p2.5.m5.4.5.3.2" xref="S5.SS1.p2.5.m5.4.5.3.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.5.m5.4.5.3.2.2" xref="S5.SS1.p2.5.m5.4.5.3.2.2.cmml">P</mi><mi mathcolor="#000000" id="S5.SS1.p2.5.m5.4.5.3.2.3" xref="S5.SS1.p2.5.m5.4.5.3.2.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S5.SS1.p2.5.m5.4.5.3.1" xref="S5.SS1.p2.5.m5.4.5.3.1.cmml">​</mo><mrow id="S5.SS1.p2.5.m5.4.5.3.3.2" xref="S5.SS1.p2.5.m5.4.5.3.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.5.m5.4.5.3.3.2.1" xref="S5.SS1.p2.5.m5.4.5.3.3.1.cmml">(</mo><mi mathcolor="#000000" id="S5.SS1.p2.5.m5.3.3" xref="S5.SS1.p2.5.m5.3.3.cmml">X</mi><mo mathcolor="#000000" id="S5.SS1.p2.5.m5.4.5.3.3.2.2" xref="S5.SS1.p2.5.m5.4.5.3.3.1.cmml">,</mo><mi mathcolor="#000000" id="S5.SS1.p2.5.m5.4.4" xref="S5.SS1.p2.5.m5.4.4.cmml">Y</mi><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.5.m5.4.5.3.3.2.3" xref="S5.SS1.p2.5.m5.4.5.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.5.m5.4b"><apply id="S5.SS1.p2.5.m5.4.5.cmml" xref="S5.SS1.p2.5.m5.4.5"><neq id="S5.SS1.p2.5.m5.4.5.1.cmml" xref="S5.SS1.p2.5.m5.4.5.1"></neq><apply id="S5.SS1.p2.5.m5.4.5.2.cmml" xref="S5.SS1.p2.5.m5.4.5.2"><times id="S5.SS1.p2.5.m5.4.5.2.1.cmml" xref="S5.SS1.p2.5.m5.4.5.2.1"></times><apply id="S5.SS1.p2.5.m5.4.5.2.2.cmml" xref="S5.SS1.p2.5.m5.4.5.2.2"><csymbol cd="ambiguous" id="S5.SS1.p2.5.m5.4.5.2.2.1.cmml" xref="S5.SS1.p2.5.m5.4.5.2.2">subscript</csymbol><ci id="S5.SS1.p2.5.m5.4.5.2.2.2.cmml" xref="S5.SS1.p2.5.m5.4.5.2.2.2">𝑃</ci><ci id="S5.SS1.p2.5.m5.4.5.2.2.3.cmml" xref="S5.SS1.p2.5.m5.4.5.2.2.3">𝑆</ci></apply><interval closure="open" id="S5.SS1.p2.5.m5.4.5.2.3.1.cmml" xref="S5.SS1.p2.5.m5.4.5.2.3.2"><ci id="S5.SS1.p2.5.m5.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1">𝑋</ci><ci id="S5.SS1.p2.5.m5.2.2.cmml" xref="S5.SS1.p2.5.m5.2.2">𝑌</ci></interval></apply><apply id="S5.SS1.p2.5.m5.4.5.3.cmml" xref="S5.SS1.p2.5.m5.4.5.3"><times id="S5.SS1.p2.5.m5.4.5.3.1.cmml" xref="S5.SS1.p2.5.m5.4.5.3.1"></times><apply id="S5.SS1.p2.5.m5.4.5.3.2.cmml" xref="S5.SS1.p2.5.m5.4.5.3.2"><csymbol cd="ambiguous" id="S5.SS1.p2.5.m5.4.5.3.2.1.cmml" xref="S5.SS1.p2.5.m5.4.5.3.2">subscript</csymbol><ci id="S5.SS1.p2.5.m5.4.5.3.2.2.cmml" xref="S5.SS1.p2.5.m5.4.5.3.2.2">𝑃</ci><ci id="S5.SS1.p2.5.m5.4.5.3.2.3.cmml" xref="S5.SS1.p2.5.m5.4.5.3.2.3">𝑇</ci></apply><interval closure="open" id="S5.SS1.p2.5.m5.4.5.3.3.1.cmml" xref="S5.SS1.p2.5.m5.4.5.3.3.2"><ci id="S5.SS1.p2.5.m5.3.3.cmml" xref="S5.SS1.p2.5.m5.3.3">𝑋</ci><ci id="S5.SS1.p2.5.m5.4.4.cmml" xref="S5.SS1.p2.5.m5.4.4">𝑌</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.5.m5.4c">P_{S}(X,Y)\neq P_{T}(X,Y)</annotation></semantics></math><span id="S5.SS1.p2.19.8" class="ltx_text" style="color:#000000;">. To address this, techniques focus on learning a transformation of the feature space to minimize the difference between the source and target distributions. This involves finding a mapping function </span><math id="S5.SS1.p2.6.m6.1" class="ltx_Math" alttext="f:X\rightarrow Z" display="inline"><semantics id="S5.SS1.p2.6.m6.1a"><mrow id="S5.SS1.p2.6.m6.1.1" xref="S5.SS1.p2.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.6.m6.1.1.2" xref="S5.SS1.p2.6.m6.1.1.2.cmml">f</mi><mo lspace="0.278em" mathcolor="#000000" rspace="0.278em" id="S5.SS1.p2.6.m6.1.1.1" xref="S5.SS1.p2.6.m6.1.1.1.cmml">:</mo><mrow id="S5.SS1.p2.6.m6.1.1.3" xref="S5.SS1.p2.6.m6.1.1.3.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.6.m6.1.1.3.2" xref="S5.SS1.p2.6.m6.1.1.3.2.cmml">X</mi><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.6.m6.1.1.3.1" xref="S5.SS1.p2.6.m6.1.1.3.1.cmml">→</mo><mi mathcolor="#000000" id="S5.SS1.p2.6.m6.1.1.3.3" xref="S5.SS1.p2.6.m6.1.1.3.3.cmml">Z</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.6.m6.1b"><apply id="S5.SS1.p2.6.m6.1.1.cmml" xref="S5.SS1.p2.6.m6.1.1"><ci id="S5.SS1.p2.6.m6.1.1.1.cmml" xref="S5.SS1.p2.6.m6.1.1.1">:</ci><ci id="S5.SS1.p2.6.m6.1.1.2.cmml" xref="S5.SS1.p2.6.m6.1.1.2">𝑓</ci><apply id="S5.SS1.p2.6.m6.1.1.3.cmml" xref="S5.SS1.p2.6.m6.1.1.3"><ci id="S5.SS1.p2.6.m6.1.1.3.1.cmml" xref="S5.SS1.p2.6.m6.1.1.3.1">→</ci><ci id="S5.SS1.p2.6.m6.1.1.3.2.cmml" xref="S5.SS1.p2.6.m6.1.1.3.2">𝑋</ci><ci id="S5.SS1.p2.6.m6.1.1.3.3.cmml" xref="S5.SS1.p2.6.m6.1.1.3.3">𝑍</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.6.m6.1c">f:X\rightarrow Z</annotation></semantics></math><span id="S5.SS1.p2.19.9" class="ltx_text" style="color:#000000;">, where </span><math id="S5.SS1.p2.7.m7.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S5.SS1.p2.7.m7.1a"><mi mathcolor="#000000" id="S5.SS1.p2.7.m7.1.1" xref="S5.SS1.p2.7.m7.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.7.m7.1b"><ci id="S5.SS1.p2.7.m7.1.1.cmml" xref="S5.SS1.p2.7.m7.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.7.m7.1c">Z</annotation></semantics></math><span id="S5.SS1.p2.19.10" class="ltx_text" style="color:#000000;"> is a latent space in which the distributions of transformed features </span><math id="S5.SS1.p2.8.m8.1" class="ltx_Math" alttext="f(X_{S})" display="inline"><semantics id="S5.SS1.p2.8.m8.1a"><mrow id="S5.SS1.p2.8.m8.1.1" xref="S5.SS1.p2.8.m8.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.8.m8.1.1.3" xref="S5.SS1.p2.8.m8.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p2.8.m8.1.1.2" xref="S5.SS1.p2.8.m8.1.1.2.cmml">​</mo><mrow id="S5.SS1.p2.8.m8.1.1.1.1" xref="S5.SS1.p2.8.m8.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.8.m8.1.1.1.1.2" xref="S5.SS1.p2.8.m8.1.1.1.1.1.cmml">(</mo><msub id="S5.SS1.p2.8.m8.1.1.1.1.1" xref="S5.SS1.p2.8.m8.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.8.m8.1.1.1.1.1.2" xref="S5.SS1.p2.8.m8.1.1.1.1.1.2.cmml">X</mi><mi mathcolor="#000000" id="S5.SS1.p2.8.m8.1.1.1.1.1.3" xref="S5.SS1.p2.8.m8.1.1.1.1.1.3.cmml">S</mi></msub><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.8.m8.1.1.1.1.3" xref="S5.SS1.p2.8.m8.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.8.m8.1b"><apply id="S5.SS1.p2.8.m8.1.1.cmml" xref="S5.SS1.p2.8.m8.1.1"><times id="S5.SS1.p2.8.m8.1.1.2.cmml" xref="S5.SS1.p2.8.m8.1.1.2"></times><ci id="S5.SS1.p2.8.m8.1.1.3.cmml" xref="S5.SS1.p2.8.m8.1.1.3">𝑓</ci><apply id="S5.SS1.p2.8.m8.1.1.1.1.1.cmml" xref="S5.SS1.p2.8.m8.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.8.m8.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.8.m8.1.1.1.1">subscript</csymbol><ci id="S5.SS1.p2.8.m8.1.1.1.1.1.2.cmml" xref="S5.SS1.p2.8.m8.1.1.1.1.1.2">𝑋</ci><ci id="S5.SS1.p2.8.m8.1.1.1.1.1.3.cmml" xref="S5.SS1.p2.8.m8.1.1.1.1.1.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.8.m8.1c">f(X_{S})</annotation></semantics></math><span id="S5.SS1.p2.19.11" class="ltx_text" style="color:#000000;"> and </span><math id="S5.SS1.p2.9.m9.1" class="ltx_Math" alttext="f(X_{T})" display="inline"><semantics id="S5.SS1.p2.9.m9.1a"><mrow id="S5.SS1.p2.9.m9.1.1" xref="S5.SS1.p2.9.m9.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.9.m9.1.1.3" xref="S5.SS1.p2.9.m9.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p2.9.m9.1.1.2" xref="S5.SS1.p2.9.m9.1.1.2.cmml">​</mo><mrow id="S5.SS1.p2.9.m9.1.1.1.1" xref="S5.SS1.p2.9.m9.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.9.m9.1.1.1.1.2" xref="S5.SS1.p2.9.m9.1.1.1.1.1.cmml">(</mo><msub id="S5.SS1.p2.9.m9.1.1.1.1.1" xref="S5.SS1.p2.9.m9.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.9.m9.1.1.1.1.1.2" xref="S5.SS1.p2.9.m9.1.1.1.1.1.2.cmml">X</mi><mi mathcolor="#000000" id="S5.SS1.p2.9.m9.1.1.1.1.1.3" xref="S5.SS1.p2.9.m9.1.1.1.1.1.3.cmml">T</mi></msub><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.9.m9.1.1.1.1.3" xref="S5.SS1.p2.9.m9.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.9.m9.1b"><apply id="S5.SS1.p2.9.m9.1.1.cmml" xref="S5.SS1.p2.9.m9.1.1"><times id="S5.SS1.p2.9.m9.1.1.2.cmml" xref="S5.SS1.p2.9.m9.1.1.2"></times><ci id="S5.SS1.p2.9.m9.1.1.3.cmml" xref="S5.SS1.p2.9.m9.1.1.3">𝑓</ci><apply id="S5.SS1.p2.9.m9.1.1.1.1.1.cmml" xref="S5.SS1.p2.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.9.m9.1.1.1.1.1.1.cmml" xref="S5.SS1.p2.9.m9.1.1.1.1">subscript</csymbol><ci id="S5.SS1.p2.9.m9.1.1.1.1.1.2.cmml" xref="S5.SS1.p2.9.m9.1.1.1.1.1.2">𝑋</ci><ci id="S5.SS1.p2.9.m9.1.1.1.1.1.3.cmml" xref="S5.SS1.p2.9.m9.1.1.1.1.1.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.9.m9.1c">f(X_{T})</annotation></semantics></math><span id="S5.SS1.p2.19.12" class="ltx_text" style="color:#000000;"> are more similar, quantified using measures such as the maximum mean discrepancy (MMD). </span><span id="S5.SS1.p2.19.13" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">Label distribution shift occurs</span><span id="S5.SS1.p2.19.14" class="ltx_text" style="color:#000000;"> when the distributions of labels (</span><math id="S5.SS1.p2.10.m10.1" class="ltx_Math" alttext="P_{S}(Y)" display="inline"><semantics id="S5.SS1.p2.10.m10.1a"><mrow id="S5.SS1.p2.10.m10.1.2" xref="S5.SS1.p2.10.m10.1.2.cmml"><msub id="S5.SS1.p2.10.m10.1.2.2" xref="S5.SS1.p2.10.m10.1.2.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.10.m10.1.2.2.2" xref="S5.SS1.p2.10.m10.1.2.2.2.cmml">P</mi><mi mathcolor="#000000" id="S5.SS1.p2.10.m10.1.2.2.3" xref="S5.SS1.p2.10.m10.1.2.2.3.cmml">S</mi></msub><mo lspace="0em" rspace="0em" id="S5.SS1.p2.10.m10.1.2.1" xref="S5.SS1.p2.10.m10.1.2.1.cmml">​</mo><mrow id="S5.SS1.p2.10.m10.1.2.3.2" xref="S5.SS1.p2.10.m10.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.10.m10.1.2.3.2.1" xref="S5.SS1.p2.10.m10.1.2.cmml">(</mo><mi mathcolor="#000000" id="S5.SS1.p2.10.m10.1.1" xref="S5.SS1.p2.10.m10.1.1.cmml">Y</mi><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.10.m10.1.2.3.2.2" xref="S5.SS1.p2.10.m10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.10.m10.1b"><apply id="S5.SS1.p2.10.m10.1.2.cmml" xref="S5.SS1.p2.10.m10.1.2"><times id="S5.SS1.p2.10.m10.1.2.1.cmml" xref="S5.SS1.p2.10.m10.1.2.1"></times><apply id="S5.SS1.p2.10.m10.1.2.2.cmml" xref="S5.SS1.p2.10.m10.1.2.2"><csymbol cd="ambiguous" id="S5.SS1.p2.10.m10.1.2.2.1.cmml" xref="S5.SS1.p2.10.m10.1.2.2">subscript</csymbol><ci id="S5.SS1.p2.10.m10.1.2.2.2.cmml" xref="S5.SS1.p2.10.m10.1.2.2.2">𝑃</ci><ci id="S5.SS1.p2.10.m10.1.2.2.3.cmml" xref="S5.SS1.p2.10.m10.1.2.2.3">𝑆</ci></apply><ci id="S5.SS1.p2.10.m10.1.1.cmml" xref="S5.SS1.p2.10.m10.1.1">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.10.m10.1c">P_{S}(Y)</annotation></semantics></math><span id="S5.SS1.p2.19.15" class="ltx_text" style="color:#000000;"> vs. </span><math id="S5.SS1.p2.11.m11.1" class="ltx_Math" alttext="P_{T}(Y)" display="inline"><semantics id="S5.SS1.p2.11.m11.1a"><mrow id="S5.SS1.p2.11.m11.1.2" xref="S5.SS1.p2.11.m11.1.2.cmml"><msub id="S5.SS1.p2.11.m11.1.2.2" xref="S5.SS1.p2.11.m11.1.2.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.11.m11.1.2.2.2" xref="S5.SS1.p2.11.m11.1.2.2.2.cmml">P</mi><mi mathcolor="#000000" id="S5.SS1.p2.11.m11.1.2.2.3" xref="S5.SS1.p2.11.m11.1.2.2.3.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S5.SS1.p2.11.m11.1.2.1" xref="S5.SS1.p2.11.m11.1.2.1.cmml">​</mo><mrow id="S5.SS1.p2.11.m11.1.2.3.2" xref="S5.SS1.p2.11.m11.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.11.m11.1.2.3.2.1" xref="S5.SS1.p2.11.m11.1.2.cmml">(</mo><mi mathcolor="#000000" id="S5.SS1.p2.11.m11.1.1" xref="S5.SS1.p2.11.m11.1.1.cmml">Y</mi><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p2.11.m11.1.2.3.2.2" xref="S5.SS1.p2.11.m11.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.11.m11.1b"><apply id="S5.SS1.p2.11.m11.1.2.cmml" xref="S5.SS1.p2.11.m11.1.2"><times id="S5.SS1.p2.11.m11.1.2.1.cmml" xref="S5.SS1.p2.11.m11.1.2.1"></times><apply id="S5.SS1.p2.11.m11.1.2.2.cmml" xref="S5.SS1.p2.11.m11.1.2.2"><csymbol cd="ambiguous" id="S5.SS1.p2.11.m11.1.2.2.1.cmml" xref="S5.SS1.p2.11.m11.1.2.2">subscript</csymbol><ci id="S5.SS1.p2.11.m11.1.2.2.2.cmml" xref="S5.SS1.p2.11.m11.1.2.2.2">𝑃</ci><ci id="S5.SS1.p2.11.m11.1.2.2.3.cmml" xref="S5.SS1.p2.11.m11.1.2.2.3">𝑇</ci></apply><ci id="S5.SS1.p2.11.m11.1.1.cmml" xref="S5.SS1.p2.11.m11.1.1">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.11.m11.1c">P_{T}(Y)</annotation></semantics></math><span id="S5.SS1.p2.19.16" class="ltx_text" style="color:#000000;">) differ, even if the feature distributions align. This poses challenges, especially with underrepresented classes in the target domain. Addressing this mathematically involves adjusting the model or learning process, possibly by re-weighting the loss function based on class distribution estimates. </span><span id="S5.SS1.p2.19.17" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">Catastrophic Forgetting</span><span id="S5.SS1.p2.19.18" class="ltx_text" style="color:#000000;"> is a risk during fine-tuning on a new domain, where the model may lose its performance on the original task. Balancing loss functions (</span><math id="S5.SS1.p2.12.m12.1" class="ltx_Math" alttext="L_{S}" display="inline"><semantics id="S5.SS1.p2.12.m12.1a"><msub id="S5.SS1.p2.12.m12.1.1" xref="S5.SS1.p2.12.m12.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.12.m12.1.1.2" xref="S5.SS1.p2.12.m12.1.1.2.cmml">L</mi><mi mathcolor="#000000" id="S5.SS1.p2.12.m12.1.1.3" xref="S5.SS1.p2.12.m12.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.12.m12.1b"><apply id="S5.SS1.p2.12.m12.1.1.cmml" xref="S5.SS1.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.12.m12.1.1.1.cmml" xref="S5.SS1.p2.12.m12.1.1">subscript</csymbol><ci id="S5.SS1.p2.12.m12.1.1.2.cmml" xref="S5.SS1.p2.12.m12.1.1.2">𝐿</ci><ci id="S5.SS1.p2.12.m12.1.1.3.cmml" xref="S5.SS1.p2.12.m12.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.12.m12.1c">L_{S}</annotation></semantics></math><span id="S5.SS1.p2.19.19" class="ltx_text" style="color:#000000;"> for the source and </span><math id="S5.SS1.p2.13.m13.1" class="ltx_Math" alttext="L_{T}" display="inline"><semantics id="S5.SS1.p2.13.m13.1a"><msub id="S5.SS1.p2.13.m13.1.1" xref="S5.SS1.p2.13.m13.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.13.m13.1.1.2" xref="S5.SS1.p2.13.m13.1.1.2.cmml">L</mi><mi mathcolor="#000000" id="S5.SS1.p2.13.m13.1.1.3" xref="S5.SS1.p2.13.m13.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.13.m13.1b"><apply id="S5.SS1.p2.13.m13.1.1.cmml" xref="S5.SS1.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.13.m13.1.1.1.cmml" xref="S5.SS1.p2.13.m13.1.1">subscript</csymbol><ci id="S5.SS1.p2.13.m13.1.1.2.cmml" xref="S5.SS1.p2.13.m13.1.1.2">𝐿</ci><ci id="S5.SS1.p2.13.m13.1.1.3.cmml" xref="S5.SS1.p2.13.m13.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.13.m13.1c">L_{T}</annotation></semantics></math><span id="S5.SS1.p2.19.20" class="ltx_text" style="color:#000000;"> for the target) is crucial, often weighted by a hyperparameter </span><math id="S5.SS1.p2.14.m14.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS1.p2.14.m14.1a"><mi mathcolor="#000000" id="S5.SS1.p2.14.m14.1.1" xref="S5.SS1.p2.14.m14.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.14.m14.1b"><ci id="S5.SS1.p2.14.m14.1.1.cmml" xref="S5.SS1.p2.14.m14.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.14.m14.1c">\lambda</annotation></semantics></math><span id="S5.SS1.p2.19.21" class="ltx_text" style="color:#000000;"> to control their importance. </span><span id="S5.SS1.p2.19.22" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">Domain-invariant feature learning</span><span id="S5.SS1.p2.19.23" class="ltx_text" style="color:#000000;"> aims to learn features invariant across domains while remaining predictive. It involves optimizing a feature extractor </span><math id="S5.SS1.p2.15.m15.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S5.SS1.p2.15.m15.1a"><mi mathcolor="#000000" id="S5.SS1.p2.15.m15.1.1" xref="S5.SS1.p2.15.m15.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.15.m15.1b"><ci id="S5.SS1.p2.15.m15.1.1.cmml" xref="S5.SS1.p2.15.m15.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.15.m15.1c">f</annotation></semantics></math><span id="S5.SS1.p2.19.24" class="ltx_text" style="color:#000000;"> and predictor </span><math id="S5.SS1.p2.16.m16.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S5.SS1.p2.16.m16.1a"><mi mathcolor="#000000" id="S5.SS1.p2.16.m16.1.1" xref="S5.SS1.p2.16.m16.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.16.m16.1b"><ci id="S5.SS1.p2.16.m16.1.1.cmml" xref="S5.SS1.p2.16.m16.1.1">𝑔</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.16.m16.1c">g</annotation></semantics></math><span id="S5.SS1.p2.19.25" class="ltx_text" style="color:#000000;"> to minimize the </span><math id="S5.SS1.p2.17.m17.1" class="ltx_Math" alttext="D_{S}" display="inline"><semantics id="S5.SS1.p2.17.m17.1a"><msub id="S5.SS1.p2.17.m17.1.1" xref="S5.SS1.p2.17.m17.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.17.m17.1.1.2" xref="S5.SS1.p2.17.m17.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S5.SS1.p2.17.m17.1.1.3" xref="S5.SS1.p2.17.m17.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.17.m17.1b"><apply id="S5.SS1.p2.17.m17.1.1.cmml" xref="S5.SS1.p2.17.m17.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.17.m17.1.1.1.cmml" xref="S5.SS1.p2.17.m17.1.1">subscript</csymbol><ci id="S5.SS1.p2.17.m17.1.1.2.cmml" xref="S5.SS1.p2.17.m17.1.1.2">𝐷</ci><ci id="S5.SS1.p2.17.m17.1.1.3.cmml" xref="S5.SS1.p2.17.m17.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.17.m17.1c">D_{S}</annotation></semantics></math><span id="S5.SS1.p2.19.26" class="ltx_text" style="color:#000000;"> loss </span><math id="S5.SS1.p2.18.m18.1" class="ltx_Math" alttext="L_{S}" display="inline"><semantics id="S5.SS1.p2.18.m18.1a"><msub id="S5.SS1.p2.18.m18.1.1" xref="S5.SS1.p2.18.m18.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p2.18.m18.1.1.2" xref="S5.SS1.p2.18.m18.1.1.2.cmml">L</mi><mi mathcolor="#000000" id="S5.SS1.p2.18.m18.1.1.3" xref="S5.SS1.p2.18.m18.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.18.m18.1b"><apply id="S5.SS1.p2.18.m18.1.1.cmml" xref="S5.SS1.p2.18.m18.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.18.m18.1.1.1.cmml" xref="S5.SS1.p2.18.m18.1.1">subscript</csymbol><ci id="S5.SS1.p2.18.m18.1.1.2.cmml" xref="S5.SS1.p2.18.m18.1.1.2">𝐿</ci><ci id="S5.SS1.p2.18.m18.1.1.3.cmml" xref="S5.SS1.p2.18.m18.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.18.m18.1c">L_{S}</annotation></semantics></math><span id="S5.SS1.p2.19.27" class="ltx_text" style="color:#000000;"> and the domain discrepancy (e.g., MMD). The problem of </span><span id="S5.SS1.p2.19.28" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">sample selection bias</span><span id="S5.SS1.p2.19.29" class="ltx_text" style="color:#000000;"> occurs in selecting samples for </span><a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a><span id="S5.SS1.p2.19.30" class="ltx_text" style="color:#000000;">, affecting the effectiveness of adaptation strategies. Mathematically, addressing this bias involves weighting or selecting samples to minimize it, often using importance sampling or re-weighting techniques. </span><span id="S5.SS1.p2.19.31" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">Hyperparameter optimization</span><span id="S5.SS1.p2.19.32" class="ltx_text" style="color:#000000;"> is critical in </span><a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a><span id="S5.SS1.p2.19.33" class="ltx_text" style="color:#000000;">, where the choice of hyperparameters (e.g., </span><math id="S5.SS1.p2.19.m19.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS1.p2.19.m19.1a"><mi mathcolor="#000000" id="S5.SS1.p2.19.m19.1.1" xref="S5.SS1.p2.19.m19.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.19.m19.1b"><ci id="S5.SS1.p2.19.m19.1.1.cmml" xref="S5.SS1.p2.19.m19.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.19.m19.1c">\lambda</annotation></semantics></math><span id="S5.SS1.p2.19.34" class="ltx_text" style="color:#000000;">) significantly impacts performance. Finding the optimal hyperparameters typically involves solving complex optimization problems using techniques like grid search, random search, or Bayesian optimization on a validation set.</span></p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text" style="color:#000000;">MMD</span><span id="S5.SS1.p3.1.2" class="ltx_text" style="color:#000000;">^2[f(X_S), f(X_T)] = </span>∥1n<span id="S5.SS1.p3.1.4.3.2.1.1.1" class="ltx_text" style="font-size:70%;">S</span><span id="S5.SS1.p3.1.5" class="ltx_text" style="color:#000000;">∑_i=1^n_S</span><span id="S5.SS1.p3.1.6" class="ltx_text ltx_font_italic" style="color:#000000;">ϕ</span><span id="S5.SS1.p3.1.7" class="ltx_text" style="color:#000000;">(x_S_i) - </span>1n<span id="S5.SS1.p3.1.8.3.2.1.1.1" class="ltx_text" style="font-size:70%;">T</span><span id="S5.SS1.p3.1.9" class="ltx_text" style="color:#000000;">∑_j=1^n_T</span><span id="S5.SS1.p3.1.10" class="ltx_text ltx_font_italic" style="color:#000000;">ϕ</span><span id="S5.SS1.p3.1.11" class="ltx_text" style="color:#000000;">(x_T_j)</span>∥<span id="S5.SS1.p3.1.13" class="ltx_text" style="color:#000000;">^2</span></p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.3" class="ltx_p"><span id="S5.SS1.p4.3.1" class="ltx_text" style="color:#000000;">where </span><math id="S5.SS1.p4.1.m1.1" class="ltx_Math" alttext="\phi(\cdot)" display="inline"><semantics id="S5.SS1.p4.1.m1.1a"><mrow id="S5.SS1.p4.1.m1.1.2" xref="S5.SS1.p4.1.m1.1.2.cmml"><mi mathcolor="#000000" id="S5.SS1.p4.1.m1.1.2.2" xref="S5.SS1.p4.1.m1.1.2.2.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p4.1.m1.1.2.1" xref="S5.SS1.p4.1.m1.1.2.1.cmml">​</mo><mrow id="S5.SS1.p4.1.m1.1.2.3.2" xref="S5.SS1.p4.1.m1.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p4.1.m1.1.2.3.2.1" xref="S5.SS1.p4.1.m1.1.2.cmml">(</mo><mo lspace="0em" mathcolor="#000000" rspace="0em" id="S5.SS1.p4.1.m1.1.1" xref="S5.SS1.p4.1.m1.1.1.cmml">⋅</mo><mo mathcolor="#000000" stretchy="false" id="S5.SS1.p4.1.m1.1.2.3.2.2" xref="S5.SS1.p4.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.1b"><apply id="S5.SS1.p4.1.m1.1.2.cmml" xref="S5.SS1.p4.1.m1.1.2"><times id="S5.SS1.p4.1.m1.1.2.1.cmml" xref="S5.SS1.p4.1.m1.1.2.1"></times><ci id="S5.SS1.p4.1.m1.1.2.2.cmml" xref="S5.SS1.p4.1.m1.1.2.2">italic-ϕ</ci><ci id="S5.SS1.p4.1.m1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.1c">\phi(\cdot)</annotation></semantics></math><span id="S5.SS1.p4.3.2" class="ltx_text" style="color:#000000;"> represents the mapping to a reproducing kernel Hilbert space (RKHS), and </span><math id="S5.SS1.p4.2.m2.1" class="ltx_Math" alttext="n_{S}" display="inline"><semantics id="S5.SS1.p4.2.m2.1a"><msub id="S5.SS1.p4.2.m2.1.1" xref="S5.SS1.p4.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p4.2.m2.1.1.2" xref="S5.SS1.p4.2.m2.1.1.2.cmml">n</mi><mi mathcolor="#000000" id="S5.SS1.p4.2.m2.1.1.3" xref="S5.SS1.p4.2.m2.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.m2.1b"><apply id="S5.SS1.p4.2.m2.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.2.m2.1.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p4.2.m2.1.1.2.cmml" xref="S5.SS1.p4.2.m2.1.1.2">𝑛</ci><ci id="S5.SS1.p4.2.m2.1.1.3.cmml" xref="S5.SS1.p4.2.m2.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.2.m2.1c">n_{S}</annotation></semantics></math><span id="S5.SS1.p4.3.3" class="ltx_text" style="color:#000000;">, </span><math id="S5.SS1.p4.3.m3.1" class="ltx_Math" alttext="n_{T}" display="inline"><semantics id="S5.SS1.p4.3.m3.1a"><msub id="S5.SS1.p4.3.m3.1.1" xref="S5.SS1.p4.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S5.SS1.p4.3.m3.1.1.2" xref="S5.SS1.p4.3.m3.1.1.2.cmml">n</mi><mi mathcolor="#000000" id="S5.SS1.p4.3.m3.1.1.3" xref="S5.SS1.p4.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.3.m3.1b"><apply id="S5.SS1.p4.3.m3.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.3.m3.1.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.p4.3.m3.1.1.2.cmml" xref="S5.SS1.p4.3.m3.1.1.2">𝑛</ci><ci id="S5.SS1.p4.3.m3.1.1.3.cmml" xref="S5.SS1.p4.3.m3.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.3.m3.1c">n_{T}</annotation></semantics></math><span id="S5.SS1.p4.3.4" class="ltx_text" style="color:#000000;"> are the numbers of samples in the source and target domains, respectively.</span></p>
</div>
<div id="S5.SS1.p5" class="ltx_para">
<p id="S5.SS1.p5.1" class="ltx_p"><span id="S5.SS1.p5.1.1" class="ltx_text" style="color:#000000;">Moreover, </span><span id="S5.SS1.p5.1.2" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">the unification of <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a></span><span id="S5.SS1.p5.1.3" class="ltx_text" style="color:#000000;"> in </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS1.p5.1.4" class="ltx_text" style="color:#000000;"> poses a challenge due to the varied mathematical formulations used in different studies. While efforts
have been made to unify definitions and formulations, further work is needed for a consistent understanding of </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S5.SS1.p5.1.5" class="ltx_text" style="color:#000000;">. Speech-based </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S5.SS1.p5.1.6" class="ltx_text" style="color:#000000;"> processing faces challenges compared to image-based processing due to potential mismatches between source and target databases arising from factors like language, speakers, age groups, ethnicity, and acoustic environments. The </span><a href="#Sx1.11.11.11"><abbr href="#Sx1.11.11.11" title="connectionist temporal classification" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CTC</span></span></abbr></a><span id="S5.SS1.p5.1.7" class="ltx_text" style="color:#000000;"> approach, while promising, is limited by the assumption of frame independence. Cross-lingual </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S5.SS1.p5.1.8" class="ltx_text" style="color:#000000;"> challenges include incorporating linguistic characteristics from multiple sources and integrating knowledge at different hierarchical levels, considering linguistic differences. Finally, </span><span id="S5.SS1.p5.1.9" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">computational burden</span><span id="S5.SS1.p5.1.10" class="ltx_text" style="color:#000000;"> remains a significant challenge in </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S5.SS1.p5.1.11" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a><span id="S5.SS1.p5.1.12" class="ltx_text" style="color:#000000;"> processes. Knowledge transfer between domains can incur additional computational costs, especially considering the extensive computational resources required for deep architectures inherent in </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S5.SS1.p5.1.13" class="ltx_text" style="color:#000000;"> techniques.</span></p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>FL-based</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p"><span id="S5.SS2.p1.1.1" class="ltx_text" style="color:#000000;">FL has significant potential for ASR systems, particularly in enhancing privacy and personalization. However, deploying this technology in ASR also comes with a set of challenges.
Typically, in FL, data is inherently decentralized and can vary significantly across devices. This </span><span id="S5.SS2.p1.1.2" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">heterogeneity in speech</span><span id="S5.SS2.p1.1.3" class="ltx_text" style="color:#000000;"> data—due to differences in accents, dialects, languages, and background noise—can make it challenging to train a model that performs well across all nodes. Ensuring robustness and generalization of the ASR model under these conditions is a complex task. Moving on, FL requires periodic communication between the central server and the devices to update the model. For ASR systems, where models can be quite large, this can result in </span><span id="S5.SS2.p1.1.4" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">substantial communication overhead</span><span id="S5.SS2.p1.1.5" class="ltx_text" style="color:#000000;">. Optimizing the efficiency of these updates, in terms of both bandwidth usage and energy consumption, especially on mobile devices, is a significant challenge. Besides, although FL is designed to enhance privacy by not sharing raw data, there are still </span><span id="S5.SS2.p1.1.6" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">privacy challenges</span><span id="S5.SS2.p1.1.7" class="ltx_text" style="color:#000000;">. For instance, it’s possible to infer sensitive information from model updates. Ensuring that these updates do not leak private information about the users’ speech data is a critical concern that requires sophisticated privacy-preserving techniques like differential privacy or secure multi-party computation.</span></p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text" style="color:#000000;">Additionally, one of the advantages of FL is the ability to personalize models based on local data. However, </span><span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">balancing personalization</span><span id="S5.SS2.p2.1.3" class="ltx_text" style="color:#000000;"> with the need for a generally effective model—especially in a diverse ecosystem with varying speech patterns—is challenging. Achieving this balance without compromising the model’s overall performance or the personalization benefits is a key challenge. Moving forward, FL systems need to manage potentially thousands or millions of devices participating in the training process. </span><span id="S5.SS2.p2.1.4" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">Scalability issues</span><span id="S5.SS2.p2.1.5" class="ltx_text" style="color:#000000;">, including managing updates from such a large and potentially unreliable network of devices, ensuring consistent model improvements, and handling devices joining or leaving the network, are significant technical hurdles. Lastly, in FL, the distribution of data across devices is often non-identically distributed (non-IID). This means that the speech data on one device might be very different from that on another, leading to challenges in training a model that generalizes well across all devices. Overcoming the bias introduced by </span><span id="S5.SS2.p2.1.6" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">non-IID data</span><span id="S5.SS2.p2.1.7" class="ltx_text" style="color:#000000;"> is a major challenge in </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S5.SS2.p2.1.8" class="ltx_text" style="color:#000000;"> for </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS2.p2.1.9" class="ltx_text" style="color:#000000;">.</span></p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>RL-based</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p"><span id="S5.SS3.p1.1.1" class="ltx_text" style="color:#000000;">Using RL in </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p1.1.2" class="ltx_text" style="color:#000000;"> systems offers promising avenues for improvement but also presents several challenges. Specifically, one of the primary challenges in applying </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S5.SS3.p1.1.3" class="ltx_text" style="color:#000000;"> to </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p1.1.4" class="ltx_text" style="color:#000000;"> is the issue of </span><span id="S5.SS3.p1.1.5" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">sparse and delayed rewards</span><span id="S5.SS3.p1.1.6" class="ltx_text" style="color:#000000;">. In many </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p1.1.7" class="ltx_text" style="color:#000000;"> tasks, the system only receives feedback (rewards or penalties) after processing lengthy sequences of speech, making it difficult to attribute the reward to specific actions or decisions. This delay complicates the learning process, as the model struggles to identify which actions led to successful outcomes.
Moreover, </span><span id="S5.SS3.p1.1.8" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">balancing exploration</span><span id="S5.SS3.p1.1.9" class="ltx_text" style="color:#000000;">, trying new actions to discover their effects, with exploitation, using known actions that yield the best results, is a critical challenge in RL. In the context of </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p1.1.10" class="ltx_text" style="color:#000000;">, this means the system must balance between adhering to known speech patterns and exploring new patterns or interpretations. Overemphasis on exploration can lead to inaccurate transcriptions, while excessive exploitation may prevent the model from adapting to new speakers or accents. Additionally, RL models typically require a significant amount of interaction data to learn effectively. In </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p1.1.11" class="ltx_text" style="color:#000000;">, obtaining </span><span id="S5.SS3.p1.1.12" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">large volumes of labeled speech</span><span id="S5.SS3.p1.1.13" class="ltx_text" style="color:#000000;"> data, especially with user feedback, can be challenging and expensive. Additionally, RL algorithms can be sample-inefficient, meaning they need a lot of data before they start performing well, which can be a </span><span id="S5.SS3.p1.1.14" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">bottleneck</span><span id="S5.SS3.p1.1.15" class="ltx_text" style="color:#000000;"> in practical applications.</span></p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p"><span id="S5.SS3.p2.1.1" class="ltx_text" style="color:#000000;">Moving forward, most </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p2.1.2" class="ltx_text" style="color:#000000;"> systems are built using supervised learning techniques that rely on vast amounts of annotated data. Integrating RL into these systems poses technical challenges, as it requires a different training paradigm that focuses on learning from user interactions and feedback rather than static datasets. Besides, using RL in </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p2.1.3" class="ltx_text" style="color:#000000;"> often involves collecting and analyzing user feedback and interactions to improve the model. This raises concerns about </span><span id="S5.SS3.p2.1.4" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">user privacy and data security</span><span id="S5.SS3.p2.1.5" class="ltx_text" style="color:#000000;">, as sensitive information might be inadvertently captured and used for training. Ensuring that data is handled securely and in compliance with privacy regulations is a significant challenge.</span></p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p"><span id="S5.SS3.p3.1.1" class="ltx_text" style="color:#000000;">Designing an </span><span id="S5.SS3.p3.1.2" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">appropriate reward</span><span id="S5.SS3.p3.1.3" class="ltx_text" style="color:#000000;"> function that accurately reflects the desired outcomes in </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p3.1.4" class="ltx_text" style="color:#000000;"> is challenging. The reward function must capture the nuances of speech recognition, such as accuracy, naturalness, and user satisfaction, which can be difficult to quantify. Poorly designed reward functions can lead to suboptimal learning outcomes or unintended behaviors. Lestly, </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p3.1.5" class="ltx_text" style="color:#000000;"> systems are used in a wide range of environments, from quiet offices to noisy streets. RL models need to adapt to these </span><span id="S5.SS3.p3.1.6" class="ltx_text ltx_font_bold ltx_font_italic" style="color:#000000;">varying conditions</span><span id="S5.SS3.p3.1.7" class="ltx_text" style="color:#000000;">, but training them to handle such diversity can be complex. The environment’s variability requires models that can generalize well across different acoustic conditions, which remains a challenge for RL-based </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S5.SS3.p3.1.8" class="ltx_text" style="color:#000000;"> systems.</span></p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="color:#000000;">
<span class="ltx_tag ltx_tag_section">6 </span>Future directions</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Personalized data augmentation for dysarthric and older people</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p"><span id="S6.SS1.p1.1.1" class="ltx_text" style="color:#000000;">While ASR technologies have advanced significantly, especially in recognizing typical speech patterns, they still struggle to accurately identify speech from individuals with dysarthria or older adults </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS1.p1.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib120" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">120</span></a><span id="S6.SS1.p1.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS1.p1.1.4" class="ltx_text" style="color:#000000;">. Gathering extensive datasets from these groups is challenging due to mobility limitations often associated with these populations. In this context, personalized data augmentation plays a crucial role </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS1.p1.1.5.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib121" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">121</span></a>, <a href="#bib.bib122" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">122</span></a><span id="S6.SS1.p1.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS1.p1.1.7" class="ltx_text" style="color:#000000;">.
Personalized data augmentation tailores the training process to accommodate the unique speech patterns and challenges associated with these groups. Dysarthria, a motor speech disorder, and the natural aging process can lead to speech that deviates from the normative models typically used to train ASR systems, making accurate recognition difficult </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS1.p1.1.8.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib123" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">123</span></a><span id="S6.SS1.p1.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS1.p1.1.10" class="ltx_text" style="color:#000000;">. Personalized data augmentation introduces a wider range of speech variations into the training dataset, including those specific to dysarthric speakers or older adults. This can include variations in speech rate, pitch, articulation, and clarity. By training on this augmented dataset, the ASR system learns to recognize and accurately transcribe speech that exhibits these characteristics </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS1.p1.1.11.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib124" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">124</span></a><span id="S6.SS1.p1.1.12.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS1.p1.1.13" class="ltx_text" style="color:#000000;">.
Moreover, this helps the ASR models generalize better to unseen examples of speech from dysarthric speakers or older adults. This enhanced generalization is crucial for real-world applications where the system encounters a wide range of speech variations. Moving forward, personalized data augmentation can employ specific techniques tailored to the needs of dysarthric speakers or older adults, such as simulating the slurring of words, varying speech tempo, or introducing background noise </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS1.p1.1.14.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib125" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">125</span></a><span id="S6.SS1.p1.1.15.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS1.p1.1.16" class="ltx_text" style="color:#000000;">, commonly challenging for these groups </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS1.p1.1.17.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib126" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">126</span></a><span id="S6.SS1.p1.1.18.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS1.p1.1.19" class="ltx_text" style="color:#000000;">. Techniques like pitch perturbation, temporal stretching, and adding noise can simulate real-world conditions more accurately for these users.
A typical example is presented in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS1.p1.1.20.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">127</span></a><span id="S6.SS1.p1.1.21.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS1.p1.1.22" class="ltx_text" style="color:#000000;">, where a unique approach utilizes speaker-dependent </span><a href="#Sx1.54.54.54"><span href="#Sx1.54.54.54" title="generative adversarial network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long-plural"><span class="ltx_text" style="font-size:80%;">generative adversarial network</span>s</span></span></a><span id="S6.SS1.p1.1.23" class="ltx_text" style="color:#000000;"> has been proposed.</span></p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Multitask learning for ASR</h3>

<div id="S6.SS2.p1" class="ltx_para">
<span id="S6.SS2.p1.1" class="ltx_ERROR undefined">\Ac</span>
<p id="S6.SS2.p1.2" class="ltx_p"><span id="S6.SS2.p1.2.1" class="ltx_text" style="color:#000000;">MTL enhances the performance of ASR systems by leveraging the inherent relatedness of multiple learning tasks to improve the generalization of the primary </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p1.2.2" class="ltx_text" style="color:#000000;"> task. This approach allows the </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p1.2.3" class="ltx_text" style="color:#000000;"> model to learn shared representations that capture underlying patterns across different but related tasks, leading to several key benefits </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS2.p1.2.4.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib128" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">128</span></a><span id="S6.SS2.p1.2.5.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS2.p1.2.6" class="ltx_text" style="color:#000000;">. Typically, MTL encourages the </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p1.2.7" class="ltx_text" style="color:#000000;"> system to learn representations that are beneficial across multiple tasks. This can lead to more robust feature extraction, as the model is not optimized solely for transcribing speech but also for other related tasks, such as speaker identification or emotion recognition. This shared learning process helps in capturing a broader range of speech characteristics, which can improve the </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p1.2.8" class="ltx_text" style="color:#000000;"> system’s ability to handle varied speech inputs. Moving one, By simultaneously learning related tasks, MTL acts as a form of regularization, reducing the risk of overfitting on the primary </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p1.2.9" class="ltx_text" style="color:#000000;"> task. This is because the model must find a solution that performs well across all tasks, preventing it from relying too heavily on noise or idiosyncrasies specific to the training data of the main task. Besides, learning auxiliary tasks alongside the main </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p1.2.10" class="ltx_text" style="color:#000000;"> task can improve the model’s generalization capabilities. For example, learning to identify the speaker or the language can provide additional contextual clues that help the </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p1.2.11" class="ltx_text" style="color:#000000;"> system better understand and transcribe ambiguous audio signals.</span></p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p"><span id="S6.SS2.p2.1.1" class="ltx_text" style="color:#000000;">Additionally, MTL can make more efficient use of available data by leveraging auxiliary tasks for which more data might be available. In scenarios where annotated data for </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p2.1.2" class="ltx_text" style="color:#000000;"> is limited, incorporating additional tasks with more abundant data can help improve the learning process and performance of the </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p2.1.3" class="ltx_text" style="color:#000000;"> system. Moreover, MTL allows </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p2.1.4" class="ltx_text" style="color:#000000;"> systems to better handle acoustic variability in speech, such as accents, dialects, or noisy environments, by incorporating tasks that directly or indirectly encourage the model to learn features that are invariant to these variations. Last but not least, modern </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS2.p2.1.5" class="ltx_text" style="color:#000000;"> systems often employ </span><a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a><span id="S6.SS2.p2.1.6" class="ltx_text" style="color:#000000;"> architectures that can benefit from end-to-end learning strategies. MTL fits naturally into this paradigm, allowing for the joint optimization of multiple objectives within a single model architecture. This can simplify the training process and reduce the need for separately trained models or handcrafted features.</span></p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Federated multi-task learning and distillation for ASR</h3>

<div id="S6.SS3.p1" class="ltx_para">
<span id="S6.SS3.p1.1" class="ltx_ERROR undefined">\Ac</span>
<p id="S6.SS3.p1.2" class="ltx_p"><span id="S6.SS3.p1.2.1" class="ltx_text" style="color:#000000;">FMTL extends the concept of FL by allowing each client to learn a personalized model that addresses its specific task, while still benefiting from collaboration with other clients.This approach recognizes the heterogeneity in clients’ data distributions and tasks. Mathematically and compared with </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S6.SS3.p1.2.2" class="ltx_text" style="color:#000000;"> (Equation </span><a href="#S4.E3" title="In 4.3 FL-based ASR ‣ 4 Advanced ASR methods and applications ‣ Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey" class="ltx_ref" style="color:#000000;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S6.SS3.p1.2.3" class="ltx_text" style="color:#000000;">),  </span><a href="#Sx1.56.56.56"><span href="#Sx1.56.56.56" title="federated multi-task learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">federated multi-task learning</span></span></span></a><span id="S6.SS3.p1.2.4" class="ltx_text" style="color:#000000;"> (</span><a href="#Sx1.56.56.56"><abbr href="#Sx1.56.56.56" title="federated multi-task learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FMTL</span></span></abbr></a><span id="S6.SS3.p1.2.5" class="ltx_text" style="color:#000000;">) can be formulated as:</span></p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<table id="S6.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S6.E7.m1.9" class="ltx_Math" alttext="\min_{\theta_{1},\theta_{2},...,\theta_{K}}\sum_{k=1}^{K}F_{k}(\theta_{k})+\lambda R(\theta_{1},\theta_{2},...,\theta_{K})" display="block"><semantics id="S6.E7.m1.9a"><mrow id="S6.E7.m1.9.9" xref="S6.E7.m1.9.9.cmml"><mrow id="S6.E7.m1.6.6.1" xref="S6.E7.m1.6.6.1.cmml"><munder id="S6.E7.m1.6.6.1.3" xref="S6.E7.m1.6.6.1.3.cmml"><mi mathcolor="#000000" id="S6.E7.m1.6.6.1.3.2" xref="S6.E7.m1.6.6.1.3.2.cmml">min</mi><mrow id="S6.E7.m1.4.4.4.4" xref="S6.E7.m1.4.4.4.5.cmml"><msub id="S6.E7.m1.2.2.2.2.1" xref="S6.E7.m1.2.2.2.2.1.cmml"><mi mathcolor="#000000" id="S6.E7.m1.2.2.2.2.1.2" xref="S6.E7.m1.2.2.2.2.1.2.cmml">θ</mi><mn mathcolor="#000000" id="S6.E7.m1.2.2.2.2.1.3" xref="S6.E7.m1.2.2.2.2.1.3.cmml">1</mn></msub><mo mathcolor="#000000" id="S6.E7.m1.4.4.4.4.4" xref="S6.E7.m1.4.4.4.5.cmml">,</mo><msub id="S6.E7.m1.3.3.3.3.2" xref="S6.E7.m1.3.3.3.3.2.cmml"><mi mathcolor="#000000" id="S6.E7.m1.3.3.3.3.2.2" xref="S6.E7.m1.3.3.3.3.2.2.cmml">θ</mi><mn mathcolor="#000000" id="S6.E7.m1.3.3.3.3.2.3" xref="S6.E7.m1.3.3.3.3.2.3.cmml">2</mn></msub><mo mathcolor="#000000" id="S6.E7.m1.4.4.4.4.5" xref="S6.E7.m1.4.4.4.5.cmml">,</mo><mi mathcolor="#000000" mathvariant="normal" id="S6.E7.m1.1.1.1.1" xref="S6.E7.m1.1.1.1.1.cmml">…</mi><mo mathcolor="#000000" id="S6.E7.m1.4.4.4.4.6" xref="S6.E7.m1.4.4.4.5.cmml">,</mo><msub id="S6.E7.m1.4.4.4.4.3" xref="S6.E7.m1.4.4.4.4.3.cmml"><mi mathcolor="#000000" id="S6.E7.m1.4.4.4.4.3.2" xref="S6.E7.m1.4.4.4.4.3.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.E7.m1.4.4.4.4.3.3" xref="S6.E7.m1.4.4.4.4.3.3.cmml">K</mi></msub></mrow></munder><mo lspace="0em" rspace="0em" id="S6.E7.m1.6.6.1.2" xref="S6.E7.m1.6.6.1.2.cmml">​</mo><mrow id="S6.E7.m1.6.6.1.1" xref="S6.E7.m1.6.6.1.1.cmml"><munderover id="S6.E7.m1.6.6.1.1.2" xref="S6.E7.m1.6.6.1.1.2.cmml"><mo mathcolor="#000000" movablelimits="false" id="S6.E7.m1.6.6.1.1.2.2.2" xref="S6.E7.m1.6.6.1.1.2.2.2.cmml">∑</mo><mrow id="S6.E7.m1.6.6.1.1.2.2.3" xref="S6.E7.m1.6.6.1.1.2.2.3.cmml"><mi mathcolor="#000000" id="S6.E7.m1.6.6.1.1.2.2.3.2" xref="S6.E7.m1.6.6.1.1.2.2.3.2.cmml">k</mi><mo mathcolor="#000000" id="S6.E7.m1.6.6.1.1.2.2.3.1" xref="S6.E7.m1.6.6.1.1.2.2.3.1.cmml">=</mo><mn mathcolor="#000000" id="S6.E7.m1.6.6.1.1.2.2.3.3" xref="S6.E7.m1.6.6.1.1.2.2.3.3.cmml">1</mn></mrow><mi mathcolor="#000000" id="S6.E7.m1.6.6.1.1.2.3" xref="S6.E7.m1.6.6.1.1.2.3.cmml">K</mi></munderover><mrow id="S6.E7.m1.6.6.1.1.1" xref="S6.E7.m1.6.6.1.1.1.cmml"><msub id="S6.E7.m1.6.6.1.1.1.3" xref="S6.E7.m1.6.6.1.1.1.3.cmml"><mi mathcolor="#000000" id="S6.E7.m1.6.6.1.1.1.3.2" xref="S6.E7.m1.6.6.1.1.1.3.2.cmml">F</mi><mi mathcolor="#000000" id="S6.E7.m1.6.6.1.1.1.3.3" xref="S6.E7.m1.6.6.1.1.1.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S6.E7.m1.6.6.1.1.1.2" xref="S6.E7.m1.6.6.1.1.1.2.cmml">​</mo><mrow id="S6.E7.m1.6.6.1.1.1.1.1" xref="S6.E7.m1.6.6.1.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E7.m1.6.6.1.1.1.1.1.2" xref="S6.E7.m1.6.6.1.1.1.1.1.1.cmml">(</mo><msub id="S6.E7.m1.6.6.1.1.1.1.1.1" xref="S6.E7.m1.6.6.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E7.m1.6.6.1.1.1.1.1.1.2" xref="S6.E7.m1.6.6.1.1.1.1.1.1.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.E7.m1.6.6.1.1.1.1.1.1.3" xref="S6.E7.m1.6.6.1.1.1.1.1.1.3.cmml">k</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.E7.m1.6.6.1.1.1.1.1.3" xref="S6.E7.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo mathcolor="#000000" id="S6.E7.m1.9.9.5" xref="S6.E7.m1.9.9.5.cmml">+</mo><mrow id="S6.E7.m1.9.9.4" xref="S6.E7.m1.9.9.4.cmml"><mi mathcolor="#000000" id="S6.E7.m1.9.9.4.5" xref="S6.E7.m1.9.9.4.5.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.9.9.4.4" xref="S6.E7.m1.9.9.4.4.cmml">​</mo><mi mathcolor="#000000" id="S6.E7.m1.9.9.4.6" xref="S6.E7.m1.9.9.4.6.cmml">R</mi><mo lspace="0em" rspace="0em" id="S6.E7.m1.9.9.4.4a" xref="S6.E7.m1.9.9.4.4.cmml">​</mo><mrow id="S6.E7.m1.9.9.4.3.3" xref="S6.E7.m1.9.9.4.3.4.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E7.m1.9.9.4.3.3.4" xref="S6.E7.m1.9.9.4.3.4.cmml">(</mo><msub id="S6.E7.m1.7.7.2.1.1.1" xref="S6.E7.m1.7.7.2.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E7.m1.7.7.2.1.1.1.2" xref="S6.E7.m1.7.7.2.1.1.1.2.cmml">θ</mi><mn mathcolor="#000000" id="S6.E7.m1.7.7.2.1.1.1.3" xref="S6.E7.m1.7.7.2.1.1.1.3.cmml">1</mn></msub><mo mathcolor="#000000" id="S6.E7.m1.9.9.4.3.3.5" xref="S6.E7.m1.9.9.4.3.4.cmml">,</mo><msub id="S6.E7.m1.8.8.3.2.2.2" xref="S6.E7.m1.8.8.3.2.2.2.cmml"><mi mathcolor="#000000" id="S6.E7.m1.8.8.3.2.2.2.2" xref="S6.E7.m1.8.8.3.2.2.2.2.cmml">θ</mi><mn mathcolor="#000000" id="S6.E7.m1.8.8.3.2.2.2.3" xref="S6.E7.m1.8.8.3.2.2.2.3.cmml">2</mn></msub><mo mathcolor="#000000" id="S6.E7.m1.9.9.4.3.3.6" xref="S6.E7.m1.9.9.4.3.4.cmml">,</mo><mi mathcolor="#000000" mathvariant="normal" id="S6.E7.m1.5.5" xref="S6.E7.m1.5.5.cmml">…</mi><mo mathcolor="#000000" id="S6.E7.m1.9.9.4.3.3.7" xref="S6.E7.m1.9.9.4.3.4.cmml">,</mo><msub id="S6.E7.m1.9.9.4.3.3.3" xref="S6.E7.m1.9.9.4.3.3.3.cmml"><mi mathcolor="#000000" id="S6.E7.m1.9.9.4.3.3.3.2" xref="S6.E7.m1.9.9.4.3.3.3.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.E7.m1.9.9.4.3.3.3.3" xref="S6.E7.m1.9.9.4.3.3.3.3.cmml">K</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.E7.m1.9.9.4.3.3.8" xref="S6.E7.m1.9.9.4.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E7.m1.9b"><apply id="S6.E7.m1.9.9.cmml" xref="S6.E7.m1.9.9"><plus id="S6.E7.m1.9.9.5.cmml" xref="S6.E7.m1.9.9.5"></plus><apply id="S6.E7.m1.6.6.1.cmml" xref="S6.E7.m1.6.6.1"><times id="S6.E7.m1.6.6.1.2.cmml" xref="S6.E7.m1.6.6.1.2"></times><apply id="S6.E7.m1.6.6.1.3.cmml" xref="S6.E7.m1.6.6.1.3"><csymbol cd="ambiguous" id="S6.E7.m1.6.6.1.3.1.cmml" xref="S6.E7.m1.6.6.1.3">subscript</csymbol><min id="S6.E7.m1.6.6.1.3.2.cmml" xref="S6.E7.m1.6.6.1.3.2"></min><list id="S6.E7.m1.4.4.4.5.cmml" xref="S6.E7.m1.4.4.4.4"><apply id="S6.E7.m1.2.2.2.2.1.cmml" xref="S6.E7.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S6.E7.m1.2.2.2.2.1.1.cmml" xref="S6.E7.m1.2.2.2.2.1">subscript</csymbol><ci id="S6.E7.m1.2.2.2.2.1.2.cmml" xref="S6.E7.m1.2.2.2.2.1.2">𝜃</ci><cn type="integer" id="S6.E7.m1.2.2.2.2.1.3.cmml" xref="S6.E7.m1.2.2.2.2.1.3">1</cn></apply><apply id="S6.E7.m1.3.3.3.3.2.cmml" xref="S6.E7.m1.3.3.3.3.2"><csymbol cd="ambiguous" id="S6.E7.m1.3.3.3.3.2.1.cmml" xref="S6.E7.m1.3.3.3.3.2">subscript</csymbol><ci id="S6.E7.m1.3.3.3.3.2.2.cmml" xref="S6.E7.m1.3.3.3.3.2.2">𝜃</ci><cn type="integer" id="S6.E7.m1.3.3.3.3.2.3.cmml" xref="S6.E7.m1.3.3.3.3.2.3">2</cn></apply><ci id="S6.E7.m1.1.1.1.1.cmml" xref="S6.E7.m1.1.1.1.1">…</ci><apply id="S6.E7.m1.4.4.4.4.3.cmml" xref="S6.E7.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="S6.E7.m1.4.4.4.4.3.1.cmml" xref="S6.E7.m1.4.4.4.4.3">subscript</csymbol><ci id="S6.E7.m1.4.4.4.4.3.2.cmml" xref="S6.E7.m1.4.4.4.4.3.2">𝜃</ci><ci id="S6.E7.m1.4.4.4.4.3.3.cmml" xref="S6.E7.m1.4.4.4.4.3.3">𝐾</ci></apply></list></apply><apply id="S6.E7.m1.6.6.1.1.cmml" xref="S6.E7.m1.6.6.1.1"><apply id="S6.E7.m1.6.6.1.1.2.cmml" xref="S6.E7.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S6.E7.m1.6.6.1.1.2.1.cmml" xref="S6.E7.m1.6.6.1.1.2">superscript</csymbol><apply id="S6.E7.m1.6.6.1.1.2.2.cmml" xref="S6.E7.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S6.E7.m1.6.6.1.1.2.2.1.cmml" xref="S6.E7.m1.6.6.1.1.2">subscript</csymbol><sum id="S6.E7.m1.6.6.1.1.2.2.2.cmml" xref="S6.E7.m1.6.6.1.1.2.2.2"></sum><apply id="S6.E7.m1.6.6.1.1.2.2.3.cmml" xref="S6.E7.m1.6.6.1.1.2.2.3"><eq id="S6.E7.m1.6.6.1.1.2.2.3.1.cmml" xref="S6.E7.m1.6.6.1.1.2.2.3.1"></eq><ci id="S6.E7.m1.6.6.1.1.2.2.3.2.cmml" xref="S6.E7.m1.6.6.1.1.2.2.3.2">𝑘</ci><cn type="integer" id="S6.E7.m1.6.6.1.1.2.2.3.3.cmml" xref="S6.E7.m1.6.6.1.1.2.2.3.3">1</cn></apply></apply><ci id="S6.E7.m1.6.6.1.1.2.3.cmml" xref="S6.E7.m1.6.6.1.1.2.3">𝐾</ci></apply><apply id="S6.E7.m1.6.6.1.1.1.cmml" xref="S6.E7.m1.6.6.1.1.1"><times id="S6.E7.m1.6.6.1.1.1.2.cmml" xref="S6.E7.m1.6.6.1.1.1.2"></times><apply id="S6.E7.m1.6.6.1.1.1.3.cmml" xref="S6.E7.m1.6.6.1.1.1.3"><csymbol cd="ambiguous" id="S6.E7.m1.6.6.1.1.1.3.1.cmml" xref="S6.E7.m1.6.6.1.1.1.3">subscript</csymbol><ci id="S6.E7.m1.6.6.1.1.1.3.2.cmml" xref="S6.E7.m1.6.6.1.1.1.3.2">𝐹</ci><ci id="S6.E7.m1.6.6.1.1.1.3.3.cmml" xref="S6.E7.m1.6.6.1.1.1.3.3">𝑘</ci></apply><apply id="S6.E7.m1.6.6.1.1.1.1.1.1.cmml" xref="S6.E7.m1.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.E7.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S6.E7.m1.6.6.1.1.1.1.1">subscript</csymbol><ci id="S6.E7.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S6.E7.m1.6.6.1.1.1.1.1.1.2">𝜃</ci><ci id="S6.E7.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S6.E7.m1.6.6.1.1.1.1.1.1.3">𝑘</ci></apply></apply></apply></apply><apply id="S6.E7.m1.9.9.4.cmml" xref="S6.E7.m1.9.9.4"><times id="S6.E7.m1.9.9.4.4.cmml" xref="S6.E7.m1.9.9.4.4"></times><ci id="S6.E7.m1.9.9.4.5.cmml" xref="S6.E7.m1.9.9.4.5">𝜆</ci><ci id="S6.E7.m1.9.9.4.6.cmml" xref="S6.E7.m1.9.9.4.6">𝑅</ci><vector id="S6.E7.m1.9.9.4.3.4.cmml" xref="S6.E7.m1.9.9.4.3.3"><apply id="S6.E7.m1.7.7.2.1.1.1.cmml" xref="S6.E7.m1.7.7.2.1.1.1"><csymbol cd="ambiguous" id="S6.E7.m1.7.7.2.1.1.1.1.cmml" xref="S6.E7.m1.7.7.2.1.1.1">subscript</csymbol><ci id="S6.E7.m1.7.7.2.1.1.1.2.cmml" xref="S6.E7.m1.7.7.2.1.1.1.2">𝜃</ci><cn type="integer" id="S6.E7.m1.7.7.2.1.1.1.3.cmml" xref="S6.E7.m1.7.7.2.1.1.1.3">1</cn></apply><apply id="S6.E7.m1.8.8.3.2.2.2.cmml" xref="S6.E7.m1.8.8.3.2.2.2"><csymbol cd="ambiguous" id="S6.E7.m1.8.8.3.2.2.2.1.cmml" xref="S6.E7.m1.8.8.3.2.2.2">subscript</csymbol><ci id="S6.E7.m1.8.8.3.2.2.2.2.cmml" xref="S6.E7.m1.8.8.3.2.2.2.2">𝜃</ci><cn type="integer" id="S6.E7.m1.8.8.3.2.2.2.3.cmml" xref="S6.E7.m1.8.8.3.2.2.2.3">2</cn></apply><ci id="S6.E7.m1.5.5.cmml" xref="S6.E7.m1.5.5">…</ci><apply id="S6.E7.m1.9.9.4.3.3.3.cmml" xref="S6.E7.m1.9.9.4.3.3.3"><csymbol cd="ambiguous" id="S6.E7.m1.9.9.4.3.3.3.1.cmml" xref="S6.E7.m1.9.9.4.3.3.3">subscript</csymbol><ci id="S6.E7.m1.9.9.4.3.3.3.2.cmml" xref="S6.E7.m1.9.9.4.3.3.3.2">𝜃</ci><ci id="S6.E7.m1.9.9.4.3.3.3.3.cmml" xref="S6.E7.m1.9.9.4.3.3.3.3">𝐾</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E7.m1.9c">\min_{\theta_{1},\theta_{2},...,\theta_{K}}\sum_{k=1}^{K}F_{k}(\theta_{k})+\lambda R(\theta_{1},\theta_{2},...,\theta_{K})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.4" class="ltx_p"><span id="S6.SS3.p3.4.1" class="ltx_text" style="color:#000000;">Different from </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S6.SS3.p3.4.2" class="ltx_text" style="color:#000000;">, </span><math id="S6.SS3.p3.1.m1.4" class="ltx_Math" alttext="R(\theta_{1},\theta_{2},...,\theta_{K})" display="inline"><semantics id="S6.SS3.p3.1.m1.4a"><mrow id="S6.SS3.p3.1.m1.4.4" xref="S6.SS3.p3.1.m1.4.4.cmml"><mi mathcolor="#000000" id="S6.SS3.p3.1.m1.4.4.5" xref="S6.SS3.p3.1.m1.4.4.5.cmml">R</mi><mo lspace="0em" rspace="0em" id="S6.SS3.p3.1.m1.4.4.4" xref="S6.SS3.p3.1.m1.4.4.4.cmml">​</mo><mrow id="S6.SS3.p3.1.m1.4.4.3.3" xref="S6.SS3.p3.1.m1.4.4.3.4.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.SS3.p3.1.m1.4.4.3.3.4" xref="S6.SS3.p3.1.m1.4.4.3.4.cmml">(</mo><msub id="S6.SS3.p3.1.m1.2.2.1.1.1" xref="S6.SS3.p3.1.m1.2.2.1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS3.p3.1.m1.2.2.1.1.1.2" xref="S6.SS3.p3.1.m1.2.2.1.1.1.2.cmml">θ</mi><mn mathcolor="#000000" id="S6.SS3.p3.1.m1.2.2.1.1.1.3" xref="S6.SS3.p3.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo mathcolor="#000000" id="S6.SS3.p3.1.m1.4.4.3.3.5" xref="S6.SS3.p3.1.m1.4.4.3.4.cmml">,</mo><msub id="S6.SS3.p3.1.m1.3.3.2.2.2" xref="S6.SS3.p3.1.m1.3.3.2.2.2.cmml"><mi mathcolor="#000000" id="S6.SS3.p3.1.m1.3.3.2.2.2.2" xref="S6.SS3.p3.1.m1.3.3.2.2.2.2.cmml">θ</mi><mn mathcolor="#000000" id="S6.SS3.p3.1.m1.3.3.2.2.2.3" xref="S6.SS3.p3.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo mathcolor="#000000" id="S6.SS3.p3.1.m1.4.4.3.3.6" xref="S6.SS3.p3.1.m1.4.4.3.4.cmml">,</mo><mi mathcolor="#000000" mathvariant="normal" id="S6.SS3.p3.1.m1.1.1" xref="S6.SS3.p3.1.m1.1.1.cmml">…</mi><mo mathcolor="#000000" id="S6.SS3.p3.1.m1.4.4.3.3.7" xref="S6.SS3.p3.1.m1.4.4.3.4.cmml">,</mo><msub id="S6.SS3.p3.1.m1.4.4.3.3.3" xref="S6.SS3.p3.1.m1.4.4.3.3.3.cmml"><mi mathcolor="#000000" id="S6.SS3.p3.1.m1.4.4.3.3.3.2" xref="S6.SS3.p3.1.m1.4.4.3.3.3.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.SS3.p3.1.m1.4.4.3.3.3.3" xref="S6.SS3.p3.1.m1.4.4.3.3.3.3.cmml">K</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.SS3.p3.1.m1.4.4.3.3.8" xref="S6.SS3.p3.1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p3.1.m1.4b"><apply id="S6.SS3.p3.1.m1.4.4.cmml" xref="S6.SS3.p3.1.m1.4.4"><times id="S6.SS3.p3.1.m1.4.4.4.cmml" xref="S6.SS3.p3.1.m1.4.4.4"></times><ci id="S6.SS3.p3.1.m1.4.4.5.cmml" xref="S6.SS3.p3.1.m1.4.4.5">𝑅</ci><vector id="S6.SS3.p3.1.m1.4.4.3.4.cmml" xref="S6.SS3.p3.1.m1.4.4.3.3"><apply id="S6.SS3.p3.1.m1.2.2.1.1.1.cmml" xref="S6.SS3.p3.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S6.SS3.p3.1.m1.2.2.1.1.1.1.cmml" xref="S6.SS3.p3.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S6.SS3.p3.1.m1.2.2.1.1.1.2.cmml" xref="S6.SS3.p3.1.m1.2.2.1.1.1.2">𝜃</ci><cn type="integer" id="S6.SS3.p3.1.m1.2.2.1.1.1.3.cmml" xref="S6.SS3.p3.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S6.SS3.p3.1.m1.3.3.2.2.2.cmml" xref="S6.SS3.p3.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S6.SS3.p3.1.m1.3.3.2.2.2.1.cmml" xref="S6.SS3.p3.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S6.SS3.p3.1.m1.3.3.2.2.2.2.cmml" xref="S6.SS3.p3.1.m1.3.3.2.2.2.2">𝜃</ci><cn type="integer" id="S6.SS3.p3.1.m1.3.3.2.2.2.3.cmml" xref="S6.SS3.p3.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S6.SS3.p3.1.m1.1.1.cmml" xref="S6.SS3.p3.1.m1.1.1">…</ci><apply id="S6.SS3.p3.1.m1.4.4.3.3.3.cmml" xref="S6.SS3.p3.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S6.SS3.p3.1.m1.4.4.3.3.3.1.cmml" xref="S6.SS3.p3.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S6.SS3.p3.1.m1.4.4.3.3.3.2.cmml" xref="S6.SS3.p3.1.m1.4.4.3.3.3.2">𝜃</ci><ci id="S6.SS3.p3.1.m1.4.4.3.3.3.3.cmml" xref="S6.SS3.p3.1.m1.4.4.3.3.3.3">𝐾</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p3.1.m1.4c">R(\theta_{1},\theta_{2},...,\theta_{K})</annotation></semantics></math><span id="S6.SS3.p3.4.3" class="ltx_text" style="color:#000000;"> is a regularization term that encourages some form of similarity or sharing among the model parameters of different tasks, promoting collaboration among clients. </span><math id="S6.SS3.p3.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S6.SS3.p3.2.m2.1a"><mi mathcolor="#000000" id="S6.SS3.p3.2.m2.1.1" xref="S6.SS3.p3.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.p3.2.m2.1b"><ci id="S6.SS3.p3.2.m2.1.1.cmml" xref="S6.SS3.p3.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p3.2.m2.1c">\lambda</annotation></semantics></math><span id="S6.SS3.p3.4.4" class="ltx_text" style="color:#000000;"> is a regularization coefficient that balances the trade-off between fitting the local data well and collaborating with other clients. FMTL has task-specific model parameters </span><math id="S6.SS3.p3.3.m3.1" class="ltx_Math" alttext="\theta_{k}" display="inline"><semantics id="S6.SS3.p3.3.m3.1a"><msub id="S6.SS3.p3.3.m3.1.1" xref="S6.SS3.p3.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S6.SS3.p3.3.m3.1.1.2" xref="S6.SS3.p3.3.m3.1.1.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.SS3.p3.3.m3.1.1.3" xref="S6.SS3.p3.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS3.p3.3.m3.1b"><apply id="S6.SS3.p3.3.m3.1.1.cmml" xref="S6.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S6.SS3.p3.3.m3.1.1.1.cmml" xref="S6.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S6.SS3.p3.3.m3.1.1.2.cmml" xref="S6.SS3.p3.3.m3.1.1.2">𝜃</ci><ci id="S6.SS3.p3.3.m3.1.1.3.cmml" xref="S6.SS3.p3.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p3.3.m3.1c">\theta_{k}</annotation></semantics></math><span id="S6.SS3.p3.4.5" class="ltx_text" style="color:#000000;"> for each client, where only a single global model parameter </span><math id="S6.SS3.p3.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S6.SS3.p3.4.m4.1a"><mi mathcolor="#000000" id="S6.SS3.p3.4.m4.1.1" xref="S6.SS3.p3.4.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.p3.4.m4.1b"><ci id="S6.SS3.p3.4.m4.1.1.cmml" xref="S6.SS3.p3.4.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p3.4.m4.1c">\theta</annotation></semantics></math><span id="S6.SS3.p3.4.6" class="ltx_text" style="color:#000000;"> in FL.</span></p>
</div>
<div id="S6.SS3.p4" class="ltx_para">
<p id="S6.SS3.p4.1" class="ltx_p"><span id="S6.SS3.p4.1.1" class="ltx_text" style="color:#000000;">In this regard, FMTL offers a promising approach to improving </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS3.p4.1.2" class="ltx_text" style="color:#000000;"> systems while also enhancing privacy and security measures. This learning paradigm extends the traditional </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S6.SS3.p4.1.3" class="ltx_text" style="color:#000000;"> model by enabling the simultaneous training of multiple tasks across distributed devices or nodes, without the need to share raw data </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p4.1.4.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">129</span></a><span id="S6.SS3.p4.1.5.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p4.1.6" class="ltx_text" style="color:#000000;">. </span><a href="#Sx1.56.56.56"><abbr href="#Sx1.56.56.56" title="federated multi-task learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FMTL</span></span></abbr></a><span id="S6.SS3.p4.1.7" class="ltx_text" style="color:#000000;"> leverages data from a wide range of devices and users, each potentially offering unique speech data, accents, dialects, and noise conditions. This diversity helps in training more robust </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS3.p4.1.8" class="ltx_text" style="color:#000000;"> models that can perform well across various speech patterns and environments </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p4.1.9.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib130" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">130</span></a><span id="S6.SS3.p4.1.10.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p4.1.11" class="ltx_text" style="color:#000000;">. By learning from many tasks simultaneously, FMTL can personalize </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS3.p4.1.12" class="ltx_text" style="color:#000000;"> models to individual users or specific groups without compromising the model’s general performance </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p4.1.13.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib131" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">131</span></a><span id="S6.SS3.p4.1.14.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p4.1.15" class="ltx_text" style="color:#000000;">. This is particularly beneficial for users with unique speech patterns, such as those with accents or speech impairments. Moreover, FMTL encourages the development of compact models that can handle multiple tasks efficiently. For </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS3.p4.1.16" class="ltx_text" style="color:#000000;"> systems, this means that a single model can potentially perform speech recognition, speaker identification, and even emotion detection, reducing the computational overhead on client devices </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p4.1.17.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib132" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">132</span></a><span id="S6.SS3.p4.1.18.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p4.1.19" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<div id="S6.SS3.p5" class="ltx_para">
<p id="S6.SS3.p5.1" class="ltx_p"><span id="S6.SS3.p5.1.1" class="ltx_text" style="color:#000000;">On the other hand, in FMTL, raw data remains on the user’s device and does not need to be shared or transferred to a central server. This inherently reduces the risk of data breaches and unauthorized access, as sensitive speech data is not centralized </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p5.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib133" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">133</span></a><span id="S6.SS3.p5.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p5.1.4" class="ltx_text" style="color:#000000;">. Additionally, FMTL can be combined with differential privacy techniques to further anonymize the model updates sent from devices to the central server. This ensures that the shared information does not reveal sensitive details about the data or the user, enhancing privacy protection </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p5.1.5.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib134" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">134</span></a><span id="S6.SS3.p5.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p5.1.7" class="ltx_text" style="color:#000000;">. Moving on, the aggregation process in FMTL can be secured using cryptographic techniques, ensuring that the aggregated model updates cannot be traced back to individual users. This secure aggregation process protects user privacy while allowing the benefits of collective learning </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p5.1.8.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib135" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">135</span></a><span id="S6.SS3.p5.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p5.1.10" class="ltx_text" style="color:#000000;">. Lastly, by aggregating model updates from a wide range of tasks and users, FMTL can improve the system’s robustness to malicious attempts at data poisoning. The diversity of inputs helps in diluting the impact of any adversarial data introduced to compromise the model.</span></p>
</div>
<div id="S6.SS3.p6" class="ltx_para">
<p id="S6.SS3.p6.1" class="ltx_p"><span id="S6.SS3.p6.1.1" class="ltx_text" style="color:#000000;">End-to-End ASR models
Continuing to develop and refine end-to-end deep learning models that directly map speech inputs to text outputs without the need for intermediate representations (like phonetic transcriptions) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p6.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">mamyrbayev2023hybrid</span><span id="S6.SS3.p6.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p6.1.4" class="ltx_text" style="color:#000000;">. Advances in models such as Transformer and Conformer architectures, which can capture long-range dependencies in speech, are promising for improving </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS3.p6.1.5" class="ltx_text" style="color:#000000;"> accuracy and efficiency </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p6.1.6.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023sfa</span><span id="S6.SS3.p6.1.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p6.1.8" class="ltx_text" style="color:#000000;">. Specifically, end-to-end models in </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS3.p6.1.9" class="ltx_text" style="color:#000000;"> aim to directly convert speech input into text output using a single neural network architecture. This simplifies the </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS3.p6.1.10" class="ltx_text" style="color:#000000;"> pipeline by bypassing traditional stages such as acoustic, pronunciation, and language modeling </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p6.1.11.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2023attention</span><span id="S6.SS3.p6.1.12.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p6.1.13" class="ltx_text" style="color:#000000;">.</span></p>
</div>
<div id="S6.SS3.p7" class="ltx_para">
<p id="S6.SS3.p7.4" class="ltx_p"><span id="S6.SS3.p7.4.1" class="ltx_text" style="color:#000000;">An end-to-end </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS3.p7.4.2" class="ltx_text" style="color:#000000;"> model maps an input sequence of speech features </span><math id="S6.SS3.p7.1.m1.4" class="ltx_Math" alttext="X=(x_{1},x_{2},\ldots,x_{T})" display="inline"><semantics id="S6.SS3.p7.1.m1.4a"><mrow id="S6.SS3.p7.1.m1.4.4" xref="S6.SS3.p7.1.m1.4.4.cmml"><mi mathcolor="#000000" id="S6.SS3.p7.1.m1.4.4.5" xref="S6.SS3.p7.1.m1.4.4.5.cmml">X</mi><mo mathcolor="#000000" id="S6.SS3.p7.1.m1.4.4.4" xref="S6.SS3.p7.1.m1.4.4.4.cmml">=</mo><mrow id="S6.SS3.p7.1.m1.4.4.3.3" xref="S6.SS3.p7.1.m1.4.4.3.4.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.SS3.p7.1.m1.4.4.3.3.4" xref="S6.SS3.p7.1.m1.4.4.3.4.cmml">(</mo><msub id="S6.SS3.p7.1.m1.2.2.1.1.1" xref="S6.SS3.p7.1.m1.2.2.1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS3.p7.1.m1.2.2.1.1.1.2" xref="S6.SS3.p7.1.m1.2.2.1.1.1.2.cmml">x</mi><mn mathcolor="#000000" id="S6.SS3.p7.1.m1.2.2.1.1.1.3" xref="S6.SS3.p7.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo mathcolor="#000000" id="S6.SS3.p7.1.m1.4.4.3.3.5" xref="S6.SS3.p7.1.m1.4.4.3.4.cmml">,</mo><msub id="S6.SS3.p7.1.m1.3.3.2.2.2" xref="S6.SS3.p7.1.m1.3.3.2.2.2.cmml"><mi mathcolor="#000000" id="S6.SS3.p7.1.m1.3.3.2.2.2.2" xref="S6.SS3.p7.1.m1.3.3.2.2.2.2.cmml">x</mi><mn mathcolor="#000000" id="S6.SS3.p7.1.m1.3.3.2.2.2.3" xref="S6.SS3.p7.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo mathcolor="#000000" id="S6.SS3.p7.1.m1.4.4.3.3.6" xref="S6.SS3.p7.1.m1.4.4.3.4.cmml">,</mo><mi mathcolor="#000000" mathvariant="normal" id="S6.SS3.p7.1.m1.1.1" xref="S6.SS3.p7.1.m1.1.1.cmml">…</mi><mo mathcolor="#000000" id="S6.SS3.p7.1.m1.4.4.3.3.7" xref="S6.SS3.p7.1.m1.4.4.3.4.cmml">,</mo><msub id="S6.SS3.p7.1.m1.4.4.3.3.3" xref="S6.SS3.p7.1.m1.4.4.3.3.3.cmml"><mi mathcolor="#000000" id="S6.SS3.p7.1.m1.4.4.3.3.3.2" xref="S6.SS3.p7.1.m1.4.4.3.3.3.2.cmml">x</mi><mi mathcolor="#000000" id="S6.SS3.p7.1.m1.4.4.3.3.3.3" xref="S6.SS3.p7.1.m1.4.4.3.3.3.3.cmml">T</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.SS3.p7.1.m1.4.4.3.3.8" xref="S6.SS3.p7.1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p7.1.m1.4b"><apply id="S6.SS3.p7.1.m1.4.4.cmml" xref="S6.SS3.p7.1.m1.4.4"><eq id="S6.SS3.p7.1.m1.4.4.4.cmml" xref="S6.SS3.p7.1.m1.4.4.4"></eq><ci id="S6.SS3.p7.1.m1.4.4.5.cmml" xref="S6.SS3.p7.1.m1.4.4.5">𝑋</ci><vector id="S6.SS3.p7.1.m1.4.4.3.4.cmml" xref="S6.SS3.p7.1.m1.4.4.3.3"><apply id="S6.SS3.p7.1.m1.2.2.1.1.1.cmml" xref="S6.SS3.p7.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S6.SS3.p7.1.m1.2.2.1.1.1.1.cmml" xref="S6.SS3.p7.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S6.SS3.p7.1.m1.2.2.1.1.1.2.cmml" xref="S6.SS3.p7.1.m1.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S6.SS3.p7.1.m1.2.2.1.1.1.3.cmml" xref="S6.SS3.p7.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S6.SS3.p7.1.m1.3.3.2.2.2.cmml" xref="S6.SS3.p7.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S6.SS3.p7.1.m1.3.3.2.2.2.1.cmml" xref="S6.SS3.p7.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S6.SS3.p7.1.m1.3.3.2.2.2.2.cmml" xref="S6.SS3.p7.1.m1.3.3.2.2.2.2">𝑥</ci><cn type="integer" id="S6.SS3.p7.1.m1.3.3.2.2.2.3.cmml" xref="S6.SS3.p7.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S6.SS3.p7.1.m1.1.1.cmml" xref="S6.SS3.p7.1.m1.1.1">…</ci><apply id="S6.SS3.p7.1.m1.4.4.3.3.3.cmml" xref="S6.SS3.p7.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S6.SS3.p7.1.m1.4.4.3.3.3.1.cmml" xref="S6.SS3.p7.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S6.SS3.p7.1.m1.4.4.3.3.3.2.cmml" xref="S6.SS3.p7.1.m1.4.4.3.3.3.2">𝑥</ci><ci id="S6.SS3.p7.1.m1.4.4.3.3.3.3.cmml" xref="S6.SS3.p7.1.m1.4.4.3.3.3.3">𝑇</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p7.1.m1.4c">X=(x_{1},x_{2},\ldots,x_{T})</annotation></semantics></math><span id="S6.SS3.p7.4.3" class="ltx_text" style="color:#000000;"> to an output sequence of tokens </span><math id="S6.SS3.p7.2.m2.4" class="ltx_Math" alttext="Y=(y_{1},y_{2},\ldots,y_{N})" display="inline"><semantics id="S6.SS3.p7.2.m2.4a"><mrow id="S6.SS3.p7.2.m2.4.4" xref="S6.SS3.p7.2.m2.4.4.cmml"><mi mathcolor="#000000" id="S6.SS3.p7.2.m2.4.4.5" xref="S6.SS3.p7.2.m2.4.4.5.cmml">Y</mi><mo mathcolor="#000000" id="S6.SS3.p7.2.m2.4.4.4" xref="S6.SS3.p7.2.m2.4.4.4.cmml">=</mo><mrow id="S6.SS3.p7.2.m2.4.4.3.3" xref="S6.SS3.p7.2.m2.4.4.3.4.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.SS3.p7.2.m2.4.4.3.3.4" xref="S6.SS3.p7.2.m2.4.4.3.4.cmml">(</mo><msub id="S6.SS3.p7.2.m2.2.2.1.1.1" xref="S6.SS3.p7.2.m2.2.2.1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS3.p7.2.m2.2.2.1.1.1.2" xref="S6.SS3.p7.2.m2.2.2.1.1.1.2.cmml">y</mi><mn mathcolor="#000000" id="S6.SS3.p7.2.m2.2.2.1.1.1.3" xref="S6.SS3.p7.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo mathcolor="#000000" id="S6.SS3.p7.2.m2.4.4.3.3.5" xref="S6.SS3.p7.2.m2.4.4.3.4.cmml">,</mo><msub id="S6.SS3.p7.2.m2.3.3.2.2.2" xref="S6.SS3.p7.2.m2.3.3.2.2.2.cmml"><mi mathcolor="#000000" id="S6.SS3.p7.2.m2.3.3.2.2.2.2" xref="S6.SS3.p7.2.m2.3.3.2.2.2.2.cmml">y</mi><mn mathcolor="#000000" id="S6.SS3.p7.2.m2.3.3.2.2.2.3" xref="S6.SS3.p7.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo mathcolor="#000000" id="S6.SS3.p7.2.m2.4.4.3.3.6" xref="S6.SS3.p7.2.m2.4.4.3.4.cmml">,</mo><mi mathcolor="#000000" mathvariant="normal" id="S6.SS3.p7.2.m2.1.1" xref="S6.SS3.p7.2.m2.1.1.cmml">…</mi><mo mathcolor="#000000" id="S6.SS3.p7.2.m2.4.4.3.3.7" xref="S6.SS3.p7.2.m2.4.4.3.4.cmml">,</mo><msub id="S6.SS3.p7.2.m2.4.4.3.3.3" xref="S6.SS3.p7.2.m2.4.4.3.3.3.cmml"><mi mathcolor="#000000" id="S6.SS3.p7.2.m2.4.4.3.3.3.2" xref="S6.SS3.p7.2.m2.4.4.3.3.3.2.cmml">y</mi><mi mathcolor="#000000" id="S6.SS3.p7.2.m2.4.4.3.3.3.3" xref="S6.SS3.p7.2.m2.4.4.3.3.3.3.cmml">N</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.SS3.p7.2.m2.4.4.3.3.8" xref="S6.SS3.p7.2.m2.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p7.2.m2.4b"><apply id="S6.SS3.p7.2.m2.4.4.cmml" xref="S6.SS3.p7.2.m2.4.4"><eq id="S6.SS3.p7.2.m2.4.4.4.cmml" xref="S6.SS3.p7.2.m2.4.4.4"></eq><ci id="S6.SS3.p7.2.m2.4.4.5.cmml" xref="S6.SS3.p7.2.m2.4.4.5">𝑌</ci><vector id="S6.SS3.p7.2.m2.4.4.3.4.cmml" xref="S6.SS3.p7.2.m2.4.4.3.3"><apply id="S6.SS3.p7.2.m2.2.2.1.1.1.cmml" xref="S6.SS3.p7.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S6.SS3.p7.2.m2.2.2.1.1.1.1.cmml" xref="S6.SS3.p7.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S6.SS3.p7.2.m2.2.2.1.1.1.2.cmml" xref="S6.SS3.p7.2.m2.2.2.1.1.1.2">𝑦</ci><cn type="integer" id="S6.SS3.p7.2.m2.2.2.1.1.1.3.cmml" xref="S6.SS3.p7.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S6.SS3.p7.2.m2.3.3.2.2.2.cmml" xref="S6.SS3.p7.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S6.SS3.p7.2.m2.3.3.2.2.2.1.cmml" xref="S6.SS3.p7.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S6.SS3.p7.2.m2.3.3.2.2.2.2.cmml" xref="S6.SS3.p7.2.m2.3.3.2.2.2.2">𝑦</ci><cn type="integer" id="S6.SS3.p7.2.m2.3.3.2.2.2.3.cmml" xref="S6.SS3.p7.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S6.SS3.p7.2.m2.1.1.cmml" xref="S6.SS3.p7.2.m2.1.1">…</ci><apply id="S6.SS3.p7.2.m2.4.4.3.3.3.cmml" xref="S6.SS3.p7.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S6.SS3.p7.2.m2.4.4.3.3.3.1.cmml" xref="S6.SS3.p7.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S6.SS3.p7.2.m2.4.4.3.3.3.2.cmml" xref="S6.SS3.p7.2.m2.4.4.3.3.3.2">𝑦</ci><ci id="S6.SS3.p7.2.m2.4.4.3.3.3.3.cmml" xref="S6.SS3.p7.2.m2.4.4.3.3.3.3">𝑁</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p7.2.m2.4c">Y=(y_{1},y_{2},\ldots,y_{N})</annotation></semantics></math><span id="S6.SS3.p7.4.4" class="ltx_text" style="color:#000000;">. The model function </span><math id="S6.SS3.p7.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S6.SS3.p7.3.m3.1a"><mi mathcolor="#000000" id="S6.SS3.p7.3.m3.1.1" xref="S6.SS3.p7.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.p7.3.m3.1b"><ci id="S6.SS3.p7.3.m3.1.1.cmml" xref="S6.SS3.p7.3.m3.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p7.3.m3.1c">f</annotation></semantics></math><span id="S6.SS3.p7.4.5" class="ltx_text" style="color:#000000;"> with parameters </span><math id="S6.SS3.p7.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S6.SS3.p7.4.m4.1a"><mi mathcolor="#000000" id="S6.SS3.p7.4.m4.1.1" xref="S6.SS3.p7.4.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.p7.4.m4.1b"><ci id="S6.SS3.p7.4.m4.1.1.cmml" xref="S6.SS3.p7.4.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p7.4.m4.1c">\theta</annotation></semantics></math><span id="S6.SS3.p7.4.6" class="ltx_text" style="color:#000000;"> aims to minimize the difference between the predicted sequence and the ground truth. Two common loss functions are used </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p7.4.7.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">almadhor2023e2e</span><span id="S6.SS3.p7.4.8.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p7.4.9" class="ltx_text" style="color:#000000;">:</span></p>
</div>
<div id="S6.SS3.p8" class="ltx_para">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.3" class="ltx_p"><span id="S6.I1.i1.p1.3.1" class="ltx_text ltx_font_bold" style="color:#000000;">CTC Loss</span><span id="S6.I1.i1.p1.3.2" class="ltx_text" style="color:#000000;">: Connectionist Temporal Classification (CTC) introduces a ’blank’ token for aligning sequences. The CTC loss is given by:</span></p>
<table id="S6.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S6.Ex2.m1.6" class="ltx_Math" alttext="\mathcal{L}_{\text{CTC}}(\theta)=-\sum_{(X,Y)\in\mathcal{D}}\log P(Y|X;\theta)" display="block"><semantics id="S6.Ex2.m1.6a"><mrow id="S6.Ex2.m1.6.6" xref="S6.Ex2.m1.6.6.cmml"><mrow id="S6.Ex2.m1.6.6.3" xref="S6.Ex2.m1.6.6.3.cmml"><msub id="S6.Ex2.m1.6.6.3.2" xref="S6.Ex2.m1.6.6.3.2.cmml"><mi class="ltx_font_mathcaligraphic" mathcolor="#000000" id="S6.Ex2.m1.6.6.3.2.2" xref="S6.Ex2.m1.6.6.3.2.2.cmml">ℒ</mi><mtext mathcolor="#000000" id="S6.Ex2.m1.6.6.3.2.3" xref="S6.Ex2.m1.6.6.3.2.3a.cmml">CTC</mtext></msub><mo lspace="0em" rspace="0em" id="S6.Ex2.m1.6.6.3.1" xref="S6.Ex2.m1.6.6.3.1.cmml">​</mo><mrow id="S6.Ex2.m1.6.6.3.3.2" xref="S6.Ex2.m1.6.6.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.Ex2.m1.6.6.3.3.2.1" xref="S6.Ex2.m1.6.6.3.cmml">(</mo><mi mathcolor="#000000" id="S6.Ex2.m1.3.3" xref="S6.Ex2.m1.3.3.cmml">θ</mi><mo mathcolor="#000000" stretchy="false" id="S6.Ex2.m1.6.6.3.3.2.2" xref="S6.Ex2.m1.6.6.3.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S6.Ex2.m1.6.6.2" xref="S6.Ex2.m1.6.6.2.cmml">=</mo><mrow id="S6.Ex2.m1.6.6.1" xref="S6.Ex2.m1.6.6.1.cmml"><mo mathcolor="#000000" id="S6.Ex2.m1.6.6.1a" xref="S6.Ex2.m1.6.6.1.cmml">−</mo><mrow id="S6.Ex2.m1.6.6.1.1" xref="S6.Ex2.m1.6.6.1.1.cmml"><munder id="S6.Ex2.m1.6.6.1.1.2" xref="S6.Ex2.m1.6.6.1.1.2.cmml"><mo mathcolor="#000000" movablelimits="false" id="S6.Ex2.m1.6.6.1.1.2.2" xref="S6.Ex2.m1.6.6.1.1.2.2.cmml">∑</mo><mrow id="S6.Ex2.m1.2.2.2" xref="S6.Ex2.m1.2.2.2.cmml"><mrow id="S6.Ex2.m1.2.2.2.4.2" xref="S6.Ex2.m1.2.2.2.4.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.Ex2.m1.2.2.2.4.2.1" xref="S6.Ex2.m1.2.2.2.4.1.cmml">(</mo><mi mathcolor="#000000" id="S6.Ex2.m1.1.1.1.1" xref="S6.Ex2.m1.1.1.1.1.cmml">X</mi><mo mathcolor="#000000" id="S6.Ex2.m1.2.2.2.4.2.2" xref="S6.Ex2.m1.2.2.2.4.1.cmml">,</mo><mi mathcolor="#000000" id="S6.Ex2.m1.2.2.2.2" xref="S6.Ex2.m1.2.2.2.2.cmml">Y</mi><mo mathcolor="#000000" stretchy="false" id="S6.Ex2.m1.2.2.2.4.2.3" xref="S6.Ex2.m1.2.2.2.4.1.cmml">)</mo></mrow><mo mathcolor="#000000" id="S6.Ex2.m1.2.2.2.3" xref="S6.Ex2.m1.2.2.2.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" mathcolor="#000000" id="S6.Ex2.m1.2.2.2.5" xref="S6.Ex2.m1.2.2.2.5.cmml">𝒟</mi></mrow></munder><mrow id="S6.Ex2.m1.6.6.1.1.1" xref="S6.Ex2.m1.6.6.1.1.1.cmml"><mrow id="S6.Ex2.m1.6.6.1.1.1.3" xref="S6.Ex2.m1.6.6.1.1.1.3.cmml"><mi mathcolor="#000000" id="S6.Ex2.m1.6.6.1.1.1.3.1" xref="S6.Ex2.m1.6.6.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S6.Ex2.m1.6.6.1.1.1.3a" xref="S6.Ex2.m1.6.6.1.1.1.3.cmml">⁡</mo><mi mathcolor="#000000" id="S6.Ex2.m1.6.6.1.1.1.3.2" xref="S6.Ex2.m1.6.6.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S6.Ex2.m1.6.6.1.1.1.2" xref="S6.Ex2.m1.6.6.1.1.1.2.cmml">​</mo><mrow id="S6.Ex2.m1.6.6.1.1.1.1.1" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.Ex2.m1.6.6.1.1.1.1.1.2" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.cmml">(</mo><mrow id="S6.Ex2.m1.6.6.1.1.1.1.1.1" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.Ex2.m1.6.6.1.1.1.1.1.1.2" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.2.cmml">Y</mi><mo fence="false" mathcolor="#000000" id="S6.Ex2.m1.6.6.1.1.1.1.1.1.1" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.1.cmml">|</mo><mrow id="S6.Ex2.m1.6.6.1.1.1.1.1.1.3.2" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.3.1.cmml"><mi mathcolor="#000000" id="S6.Ex2.m1.4.4" xref="S6.Ex2.m1.4.4.cmml">X</mi><mo mathcolor="#000000" id="S6.Ex2.m1.6.6.1.1.1.1.1.1.3.2.1" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.3.1.cmml">;</mo><mi mathcolor="#000000" id="S6.Ex2.m1.5.5" xref="S6.Ex2.m1.5.5.cmml">θ</mi></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S6.Ex2.m1.6.6.1.1.1.1.1.3" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.Ex2.m1.6b"><apply id="S6.Ex2.m1.6.6.cmml" xref="S6.Ex2.m1.6.6"><eq id="S6.Ex2.m1.6.6.2.cmml" xref="S6.Ex2.m1.6.6.2"></eq><apply id="S6.Ex2.m1.6.6.3.cmml" xref="S6.Ex2.m1.6.6.3"><times id="S6.Ex2.m1.6.6.3.1.cmml" xref="S6.Ex2.m1.6.6.3.1"></times><apply id="S6.Ex2.m1.6.6.3.2.cmml" xref="S6.Ex2.m1.6.6.3.2"><csymbol cd="ambiguous" id="S6.Ex2.m1.6.6.3.2.1.cmml" xref="S6.Ex2.m1.6.6.3.2">subscript</csymbol><ci id="S6.Ex2.m1.6.6.3.2.2.cmml" xref="S6.Ex2.m1.6.6.3.2.2">ℒ</ci><ci id="S6.Ex2.m1.6.6.3.2.3a.cmml" xref="S6.Ex2.m1.6.6.3.2.3"><mtext mathsize="70%" id="S6.Ex2.m1.6.6.3.2.3.cmml" xref="S6.Ex2.m1.6.6.3.2.3">CTC</mtext></ci></apply><ci id="S6.Ex2.m1.3.3.cmml" xref="S6.Ex2.m1.3.3">𝜃</ci></apply><apply id="S6.Ex2.m1.6.6.1.cmml" xref="S6.Ex2.m1.6.6.1"><minus id="S6.Ex2.m1.6.6.1.2.cmml" xref="S6.Ex2.m1.6.6.1"></minus><apply id="S6.Ex2.m1.6.6.1.1.cmml" xref="S6.Ex2.m1.6.6.1.1"><apply id="S6.Ex2.m1.6.6.1.1.2.cmml" xref="S6.Ex2.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S6.Ex2.m1.6.6.1.1.2.1.cmml" xref="S6.Ex2.m1.6.6.1.1.2">subscript</csymbol><sum id="S6.Ex2.m1.6.6.1.1.2.2.cmml" xref="S6.Ex2.m1.6.6.1.1.2.2"></sum><apply id="S6.Ex2.m1.2.2.2.cmml" xref="S6.Ex2.m1.2.2.2"><in id="S6.Ex2.m1.2.2.2.3.cmml" xref="S6.Ex2.m1.2.2.2.3"></in><interval closure="open" id="S6.Ex2.m1.2.2.2.4.1.cmml" xref="S6.Ex2.m1.2.2.2.4.2"><ci id="S6.Ex2.m1.1.1.1.1.cmml" xref="S6.Ex2.m1.1.1.1.1">𝑋</ci><ci id="S6.Ex2.m1.2.2.2.2.cmml" xref="S6.Ex2.m1.2.2.2.2">𝑌</ci></interval><ci id="S6.Ex2.m1.2.2.2.5.cmml" xref="S6.Ex2.m1.2.2.2.5">𝒟</ci></apply></apply><apply id="S6.Ex2.m1.6.6.1.1.1.cmml" xref="S6.Ex2.m1.6.6.1.1.1"><times id="S6.Ex2.m1.6.6.1.1.1.2.cmml" xref="S6.Ex2.m1.6.6.1.1.1.2"></times><apply id="S6.Ex2.m1.6.6.1.1.1.3.cmml" xref="S6.Ex2.m1.6.6.1.1.1.3"><log id="S6.Ex2.m1.6.6.1.1.1.3.1.cmml" xref="S6.Ex2.m1.6.6.1.1.1.3.1"></log><ci id="S6.Ex2.m1.6.6.1.1.1.3.2.cmml" xref="S6.Ex2.m1.6.6.1.1.1.3.2">𝑃</ci></apply><apply id="S6.Ex2.m1.6.6.1.1.1.1.1.1.cmml" xref="S6.Ex2.m1.6.6.1.1.1.1.1"><csymbol cd="latexml" id="S6.Ex2.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.1">conditional</csymbol><ci id="S6.Ex2.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.2">𝑌</ci><list id="S6.Ex2.m1.6.6.1.1.1.1.1.1.3.1.cmml" xref="S6.Ex2.m1.6.6.1.1.1.1.1.1.3.2"><ci id="S6.Ex2.m1.4.4.cmml" xref="S6.Ex2.m1.4.4">𝑋</ci><ci id="S6.Ex2.m1.5.5.cmml" xref="S6.Ex2.m1.5.5">𝜃</ci></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.Ex2.m1.6c">\mathcal{L}_{\text{CTC}}(\theta)=-\sum_{(X,Y)\in\mathcal{D}}\log P(Y|X;\theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
</tr></tbody>
</table>
<p id="S6.I1.i1.p1.2" class="ltx_p"><span id="S6.I1.i1.p1.2.1" class="ltx_text" style="color:#000000;">where </span><math id="S6.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S6.I1.i1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" mathcolor="#000000" id="S6.I1.i1.p1.1.m1.1.1" xref="S6.I1.i1.p1.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S6.I1.i1.p1.1.m1.1b"><ci id="S6.I1.i1.p1.1.m1.1.1.cmml" xref="S6.I1.i1.p1.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I1.i1.p1.1.m1.1c">\mathcal{D}</annotation></semantics></math><span id="S6.I1.i1.p1.2.2" class="ltx_text" style="color:#000000;"> is the dataset, and </span><math id="S6.I1.i1.p1.2.m2.3" class="ltx_Math" alttext="P(Y|X;\theta)" display="inline"><semantics id="S6.I1.i1.p1.2.m2.3a"><mrow id="S6.I1.i1.p1.2.m2.3.3" xref="S6.I1.i1.p1.2.m2.3.3.cmml"><mi mathcolor="#000000" id="S6.I1.i1.p1.2.m2.3.3.3" xref="S6.I1.i1.p1.2.m2.3.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S6.I1.i1.p1.2.m2.3.3.2" xref="S6.I1.i1.p1.2.m2.3.3.2.cmml">​</mo><mrow id="S6.I1.i1.p1.2.m2.3.3.1.1" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.I1.i1.p1.2.m2.3.3.1.1.2" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.cmml">(</mo><mrow id="S6.I1.i1.p1.2.m2.3.3.1.1.1" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.cmml"><mi mathcolor="#000000" id="S6.I1.i1.p1.2.m2.3.3.1.1.1.2" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.2.cmml">Y</mi><mo fence="false" mathcolor="#000000" id="S6.I1.i1.p1.2.m2.3.3.1.1.1.1" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.1.cmml">|</mo><mrow id="S6.I1.i1.p1.2.m2.3.3.1.1.1.3.2" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.3.1.cmml"><mi mathcolor="#000000" id="S6.I1.i1.p1.2.m2.1.1" xref="S6.I1.i1.p1.2.m2.1.1.cmml">X</mi><mo mathcolor="#000000" id="S6.I1.i1.p1.2.m2.3.3.1.1.1.3.2.1" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.3.1.cmml">;</mo><mi mathcolor="#000000" id="S6.I1.i1.p1.2.m2.2.2" xref="S6.I1.i1.p1.2.m2.2.2.cmml">θ</mi></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S6.I1.i1.p1.2.m2.3.3.1.1.3" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.I1.i1.p1.2.m2.3b"><apply id="S6.I1.i1.p1.2.m2.3.3.cmml" xref="S6.I1.i1.p1.2.m2.3.3"><times id="S6.I1.i1.p1.2.m2.3.3.2.cmml" xref="S6.I1.i1.p1.2.m2.3.3.2"></times><ci id="S6.I1.i1.p1.2.m2.3.3.3.cmml" xref="S6.I1.i1.p1.2.m2.3.3.3">𝑃</ci><apply id="S6.I1.i1.p1.2.m2.3.3.1.1.1.cmml" xref="S6.I1.i1.p1.2.m2.3.3.1.1"><csymbol cd="latexml" id="S6.I1.i1.p1.2.m2.3.3.1.1.1.1.cmml" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.1">conditional</csymbol><ci id="S6.I1.i1.p1.2.m2.3.3.1.1.1.2.cmml" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.2">𝑌</ci><list id="S6.I1.i1.p1.2.m2.3.3.1.1.1.3.1.cmml" xref="S6.I1.i1.p1.2.m2.3.3.1.1.1.3.2"><ci id="S6.I1.i1.p1.2.m2.1.1.cmml" xref="S6.I1.i1.p1.2.m2.1.1">𝑋</ci><ci id="S6.I1.i1.p1.2.m2.2.2.cmml" xref="S6.I1.i1.p1.2.m2.2.2">𝜃</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.I1.i1.p1.2.m2.3c">P(Y|X;\theta)</annotation></semantics></math><span id="S6.I1.i1.p1.2.3" class="ltx_text" style="color:#000000;"> is the sequence probability.</span></p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Attention-based Seq2Seq Loss</span><span id="S6.I1.i2.p1.1.2" class="ltx_text" style="color:#000000;">: This uses an encoder-decoder architecture with attention to predict each token. The loss is the negative log-likelihood:</span></p>
<table id="S6.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S6.Ex3.m1.6" class="ltx_Math" alttext="\mathcal{L}_{\text{Seq2Seq}}(\theta)=-\sum_{(X,Y)\in\mathcal{D}}\log P(Y|X;\theta)" display="block"><semantics id="S6.Ex3.m1.6a"><mrow id="S6.Ex3.m1.6.6" xref="S6.Ex3.m1.6.6.cmml"><mrow id="S6.Ex3.m1.6.6.3" xref="S6.Ex3.m1.6.6.3.cmml"><msub id="S6.Ex3.m1.6.6.3.2" xref="S6.Ex3.m1.6.6.3.2.cmml"><mi class="ltx_font_mathcaligraphic" mathcolor="#000000" id="S6.Ex3.m1.6.6.3.2.2" xref="S6.Ex3.m1.6.6.3.2.2.cmml">ℒ</mi><mtext mathcolor="#000000" id="S6.Ex3.m1.6.6.3.2.3" xref="S6.Ex3.m1.6.6.3.2.3a.cmml">Seq2Seq</mtext></msub><mo lspace="0em" rspace="0em" id="S6.Ex3.m1.6.6.3.1" xref="S6.Ex3.m1.6.6.3.1.cmml">​</mo><mrow id="S6.Ex3.m1.6.6.3.3.2" xref="S6.Ex3.m1.6.6.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.Ex3.m1.6.6.3.3.2.1" xref="S6.Ex3.m1.6.6.3.cmml">(</mo><mi mathcolor="#000000" id="S6.Ex3.m1.3.3" xref="S6.Ex3.m1.3.3.cmml">θ</mi><mo mathcolor="#000000" stretchy="false" id="S6.Ex3.m1.6.6.3.3.2.2" xref="S6.Ex3.m1.6.6.3.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S6.Ex3.m1.6.6.2" xref="S6.Ex3.m1.6.6.2.cmml">=</mo><mrow id="S6.Ex3.m1.6.6.1" xref="S6.Ex3.m1.6.6.1.cmml"><mo mathcolor="#000000" id="S6.Ex3.m1.6.6.1a" xref="S6.Ex3.m1.6.6.1.cmml">−</mo><mrow id="S6.Ex3.m1.6.6.1.1" xref="S6.Ex3.m1.6.6.1.1.cmml"><munder id="S6.Ex3.m1.6.6.1.1.2" xref="S6.Ex3.m1.6.6.1.1.2.cmml"><mo mathcolor="#000000" movablelimits="false" id="S6.Ex3.m1.6.6.1.1.2.2" xref="S6.Ex3.m1.6.6.1.1.2.2.cmml">∑</mo><mrow id="S6.Ex3.m1.2.2.2" xref="S6.Ex3.m1.2.2.2.cmml"><mrow id="S6.Ex3.m1.2.2.2.4.2" xref="S6.Ex3.m1.2.2.2.4.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.Ex3.m1.2.2.2.4.2.1" xref="S6.Ex3.m1.2.2.2.4.1.cmml">(</mo><mi mathcolor="#000000" id="S6.Ex3.m1.1.1.1.1" xref="S6.Ex3.m1.1.1.1.1.cmml">X</mi><mo mathcolor="#000000" id="S6.Ex3.m1.2.2.2.4.2.2" xref="S6.Ex3.m1.2.2.2.4.1.cmml">,</mo><mi mathcolor="#000000" id="S6.Ex3.m1.2.2.2.2" xref="S6.Ex3.m1.2.2.2.2.cmml">Y</mi><mo mathcolor="#000000" stretchy="false" id="S6.Ex3.m1.2.2.2.4.2.3" xref="S6.Ex3.m1.2.2.2.4.1.cmml">)</mo></mrow><mo mathcolor="#000000" id="S6.Ex3.m1.2.2.2.3" xref="S6.Ex3.m1.2.2.2.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" mathcolor="#000000" id="S6.Ex3.m1.2.2.2.5" xref="S6.Ex3.m1.2.2.2.5.cmml">𝒟</mi></mrow></munder><mrow id="S6.Ex3.m1.6.6.1.1.1" xref="S6.Ex3.m1.6.6.1.1.1.cmml"><mrow id="S6.Ex3.m1.6.6.1.1.1.3" xref="S6.Ex3.m1.6.6.1.1.1.3.cmml"><mi mathcolor="#000000" id="S6.Ex3.m1.6.6.1.1.1.3.1" xref="S6.Ex3.m1.6.6.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S6.Ex3.m1.6.6.1.1.1.3a" xref="S6.Ex3.m1.6.6.1.1.1.3.cmml">⁡</mo><mi mathcolor="#000000" id="S6.Ex3.m1.6.6.1.1.1.3.2" xref="S6.Ex3.m1.6.6.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S6.Ex3.m1.6.6.1.1.1.2" xref="S6.Ex3.m1.6.6.1.1.1.2.cmml">​</mo><mrow id="S6.Ex3.m1.6.6.1.1.1.1.1" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.Ex3.m1.6.6.1.1.1.1.1.2" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.cmml">(</mo><mrow id="S6.Ex3.m1.6.6.1.1.1.1.1.1" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.Ex3.m1.6.6.1.1.1.1.1.1.2" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.2.cmml">Y</mi><mo fence="false" mathcolor="#000000" id="S6.Ex3.m1.6.6.1.1.1.1.1.1.1" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.1.cmml">|</mo><mrow id="S6.Ex3.m1.6.6.1.1.1.1.1.1.3.2" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.3.1.cmml"><mi mathcolor="#000000" id="S6.Ex3.m1.4.4" xref="S6.Ex3.m1.4.4.cmml">X</mi><mo mathcolor="#000000" id="S6.Ex3.m1.6.6.1.1.1.1.1.1.3.2.1" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.3.1.cmml">;</mo><mi mathcolor="#000000" id="S6.Ex3.m1.5.5" xref="S6.Ex3.m1.5.5.cmml">θ</mi></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S6.Ex3.m1.6.6.1.1.1.1.1.3" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.Ex3.m1.6b"><apply id="S6.Ex3.m1.6.6.cmml" xref="S6.Ex3.m1.6.6"><eq id="S6.Ex3.m1.6.6.2.cmml" xref="S6.Ex3.m1.6.6.2"></eq><apply id="S6.Ex3.m1.6.6.3.cmml" xref="S6.Ex3.m1.6.6.3"><times id="S6.Ex3.m1.6.6.3.1.cmml" xref="S6.Ex3.m1.6.6.3.1"></times><apply id="S6.Ex3.m1.6.6.3.2.cmml" xref="S6.Ex3.m1.6.6.3.2"><csymbol cd="ambiguous" id="S6.Ex3.m1.6.6.3.2.1.cmml" xref="S6.Ex3.m1.6.6.3.2">subscript</csymbol><ci id="S6.Ex3.m1.6.6.3.2.2.cmml" xref="S6.Ex3.m1.6.6.3.2.2">ℒ</ci><ci id="S6.Ex3.m1.6.6.3.2.3a.cmml" xref="S6.Ex3.m1.6.6.3.2.3"><mtext mathsize="70%" id="S6.Ex3.m1.6.6.3.2.3.cmml" xref="S6.Ex3.m1.6.6.3.2.3">Seq2Seq</mtext></ci></apply><ci id="S6.Ex3.m1.3.3.cmml" xref="S6.Ex3.m1.3.3">𝜃</ci></apply><apply id="S6.Ex3.m1.6.6.1.cmml" xref="S6.Ex3.m1.6.6.1"><minus id="S6.Ex3.m1.6.6.1.2.cmml" xref="S6.Ex3.m1.6.6.1"></minus><apply id="S6.Ex3.m1.6.6.1.1.cmml" xref="S6.Ex3.m1.6.6.1.1"><apply id="S6.Ex3.m1.6.6.1.1.2.cmml" xref="S6.Ex3.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S6.Ex3.m1.6.6.1.1.2.1.cmml" xref="S6.Ex3.m1.6.6.1.1.2">subscript</csymbol><sum id="S6.Ex3.m1.6.6.1.1.2.2.cmml" xref="S6.Ex3.m1.6.6.1.1.2.2"></sum><apply id="S6.Ex3.m1.2.2.2.cmml" xref="S6.Ex3.m1.2.2.2"><in id="S6.Ex3.m1.2.2.2.3.cmml" xref="S6.Ex3.m1.2.2.2.3"></in><interval closure="open" id="S6.Ex3.m1.2.2.2.4.1.cmml" xref="S6.Ex3.m1.2.2.2.4.2"><ci id="S6.Ex3.m1.1.1.1.1.cmml" xref="S6.Ex3.m1.1.1.1.1">𝑋</ci><ci id="S6.Ex3.m1.2.2.2.2.cmml" xref="S6.Ex3.m1.2.2.2.2">𝑌</ci></interval><ci id="S6.Ex3.m1.2.2.2.5.cmml" xref="S6.Ex3.m1.2.2.2.5">𝒟</ci></apply></apply><apply id="S6.Ex3.m1.6.6.1.1.1.cmml" xref="S6.Ex3.m1.6.6.1.1.1"><times id="S6.Ex3.m1.6.6.1.1.1.2.cmml" xref="S6.Ex3.m1.6.6.1.1.1.2"></times><apply id="S6.Ex3.m1.6.6.1.1.1.3.cmml" xref="S6.Ex3.m1.6.6.1.1.1.3"><log id="S6.Ex3.m1.6.6.1.1.1.3.1.cmml" xref="S6.Ex3.m1.6.6.1.1.1.3.1"></log><ci id="S6.Ex3.m1.6.6.1.1.1.3.2.cmml" xref="S6.Ex3.m1.6.6.1.1.1.3.2">𝑃</ci></apply><apply id="S6.Ex3.m1.6.6.1.1.1.1.1.1.cmml" xref="S6.Ex3.m1.6.6.1.1.1.1.1"><csymbol cd="latexml" id="S6.Ex3.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.1">conditional</csymbol><ci id="S6.Ex3.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.2">𝑌</ci><list id="S6.Ex3.m1.6.6.1.1.1.1.1.1.3.1.cmml" xref="S6.Ex3.m1.6.6.1.1.1.1.1.1.3.2"><ci id="S6.Ex3.m1.4.4.cmml" xref="S6.Ex3.m1.4.4">𝑋</ci><ci id="S6.Ex3.m1.5.5.cmml" xref="S6.Ex3.m1.5.5">𝜃</ci></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.Ex3.m1.6c">\mathcal{L}_{\text{Seq2Seq}}(\theta)=-\sum_{(X,Y)\in\mathcal{D}}\log P(Y|X;\theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
</tr></tbody>
</table>
</div>
</li>
</ul>
</div>
<div id="S6.SS3.p9" class="ltx_para">
<p id="S6.SS3.p9.1" class="ltx_p"><span id="S6.SS3.p9.1.1" class="ltx_text" style="color:#000000;">Besides, model architectures can be described as follows:</span></p>
</div>
<div id="S6.SS3.p10" class="ltx_para">
<ul id="S6.I2" class="ltx_itemize">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p"><span id="S6.I2.i1.p1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Recurrent Neural Networks (RNNs)</span><span id="S6.I2.i1.p1.1.2" class="ltx_text" style="color:#000000;"> including Long Short-Term Memory (LSTM) networks for temporal dependencies </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.I2.i1.p1.1.3.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">vander2023using</span><span id="S6.I2.i1.p1.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.I2.i1.p1.1.5" class="ltx_text" style="color:#000000;">.</span></p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p"><span id="S6.I2.i2.p1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Convolutional Neural Networks (CNNs)</span><span id="S6.I2.i2.p1.1.2" class="ltx_text" style="color:#000000;"> for capturing local patterns in speech features.</span></p>
</div>
</li>
<li id="S6.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i3.p1" class="ltx_para">
<p id="S6.I2.i3.p1.1" class="ltx_p"><span id="S6.I2.i3.p1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Transformer Models</span><span id="S6.I2.i3.p1.1.2" class="ltx_text" style="color:#000000;"> utilize self-attention mechanisms for parallel processing and superior performance </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.I2.i3.p1.1.3.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022optimizing</span><span id="S6.I2.i3.p1.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.I2.i3.p1.1.5" class="ltx_text" style="color:#000000;">.</span></p>
</div>
</li>
</ul>
</div>
<div id="S6.SS3.p11" class="ltx_para">
<p id="S6.SS3.p11.1" class="ltx_p"><span id="S6.SS3.p11.1.1" class="ltx_text" style="color:#000000;">Gradient-based methods like stochastic gradient descent (SGD) or Adam are used to minimize the loss function, optimizing the model parameters </span><math id="S6.SS3.p11.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S6.SS3.p11.1.m1.1a"><mi mathcolor="#000000" id="S6.SS3.p11.1.m1.1.1" xref="S6.SS3.p11.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S6.SS3.p11.1.m1.1b"><ci id="S6.SS3.p11.1.m1.1.1.cmml" xref="S6.SS3.p11.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p11.1.m1.1c">\theta</annotation></semantics></math><span id="S6.SS3.p11.1.2" class="ltx_text" style="color:#000000;"> to improve the speech-to-text mapping. However, end-to-end models face challenges such as data scarcity for low-resource languages, computational resource demands, and integrating external language models for linguistic improvements </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS3.p11.1.3.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">qu2023emphasizing</span><span id="S6.SS3.p11.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS3.p11.1.5" class="ltx_text" style="color:#000000;">.</span></p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Domain-specific language modeling</h3>

<div id="S6.SS4.p1" class="ltx_para">
<span id="S6.SS4.p1.2" class="ltx_ERROR undefined">\Ac</span>
<p id="S6.SS4.p1.1" class="ltx_p"><span id="S6.SS4.p1.1.1" class="ltx_text" style="color:#000000;">DSLM represents a significant advancement in the field of </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS4.p1.1.2" class="ltx_text" style="color:#000000;">, especially as systems increasingly cater to specialized fields like healthcare, legal, or customer service </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS4.p1.1.3.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">jia2023deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023prompting</span><span id="S6.SS4.p1.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS4.p1.1.5" class="ltx_text" style="color:#000000;">. </span><span id="S6.SS4.p1.1.6" class="ltx_ERROR undefined">\Acp</span><span id="S6.SS4.p1.1.7" class="ltx_text" style="color:#000000;">LM provide probabilities of sequences of words, crucial for </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS4.p1.1.8" class="ltx_text" style="color:#000000;"> systems to predict the likelihood of subsequent words in a sentence </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS4.p1.1.9.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">38</span></a><span id="S6.SS4.p1.1.10.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS4.p1.1.11" class="ltx_text" style="color:#000000;">. A domain-specific LM is trained on text data from the target domain to capture its unique vocabulary and grammatical structures </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS4.p1.1.12.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">39</span></a><span id="S6.SS4.p1.1.13.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS4.p1.1.14" class="ltx_text" style="color:#000000;">. For n-gram models, this involves calculating the conditional probability of a word given the previous </span><math id="S6.SS4.p1.1.m1.1" class="ltx_Math" alttext="n-1" display="inline"><semantics id="S6.SS4.p1.1.m1.1a"><mrow id="S6.SS4.p1.1.m1.1.1" xref="S6.SS4.p1.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS4.p1.1.m1.1.1.2" xref="S6.SS4.p1.1.m1.1.1.2.cmml">n</mi><mo mathcolor="#000000" id="S6.SS4.p1.1.m1.1.1.1" xref="S6.SS4.p1.1.m1.1.1.1.cmml">−</mo><mn mathcolor="#000000" id="S6.SS4.p1.1.m1.1.1.3" xref="S6.SS4.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.1.m1.1b"><apply id="S6.SS4.p1.1.m1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1"><minus id="S6.SS4.p1.1.m1.1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1.1"></minus><ci id="S6.SS4.p1.1.m1.1.1.2.cmml" xref="S6.SS4.p1.1.m1.1.1.2">𝑛</ci><cn type="integer" id="S6.SS4.p1.1.m1.1.1.3.cmml" xref="S6.SS4.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.1.m1.1c">n-1</annotation></semantics></math><span id="S6.SS4.p1.1.15" class="ltx_text" style="color:#000000;"> words </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS4.p1.1.16.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">40</span></a><span id="S6.SS4.p1.1.17.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS4.p1.1.18" class="ltx_text" style="color:#000000;">:</span></p>
<table id="S6.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S6.E8.m1.11" class="ltx_Math" alttext="P(w_{n}|w_{n-1},w_{n-2},\ldots,w_{n-(n-1)})=\frac{C(w_{n-(n-1)},\ldots,w_{n})}{C(w_{n-(n-1)},\ldots,w_{n-1})}" display="block"><semantics id="S6.E8.m1.11a"><mrow id="S6.E8.m1.11.11" xref="S6.E8.m1.11.11.cmml"><mrow id="S6.E8.m1.11.11.1" xref="S6.E8.m1.11.11.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.11.11.1.3" xref="S6.E8.m1.11.11.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S6.E8.m1.11.11.1.2" xref="S6.E8.m1.11.11.1.2.cmml">​</mo><mrow id="S6.E8.m1.11.11.1.1.1" xref="S6.E8.m1.11.11.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.11.11.1.1.1.2" xref="S6.E8.m1.11.11.1.1.1.1.cmml">(</mo><mrow id="S6.E8.m1.11.11.1.1.1.1" xref="S6.E8.m1.11.11.1.1.1.1.cmml"><msub id="S6.E8.m1.11.11.1.1.1.1.5" xref="S6.E8.m1.11.11.1.1.1.1.5.cmml"><mi mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.5.2" xref="S6.E8.m1.11.11.1.1.1.1.5.2.cmml">w</mi><mi mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.5.3" xref="S6.E8.m1.11.11.1.1.1.1.5.3.cmml">n</mi></msub><mo fence="false" mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.4" xref="S6.E8.m1.11.11.1.1.1.1.4.cmml">|</mo><mrow id="S6.E8.m1.11.11.1.1.1.1.3.3" xref="S6.E8.m1.11.11.1.1.1.1.3.4.cmml"><msub id="S6.E8.m1.11.11.1.1.1.1.1.1.1" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.1.1.1.2" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.2.cmml">w</mi><mrow id="S6.E8.m1.11.11.1.1.1.1.1.1.1.3" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.cmml"><mi mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.2" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.2.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.1" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.3" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.3.3.4" xref="S6.E8.m1.11.11.1.1.1.1.3.4.cmml">,</mo><msub id="S6.E8.m1.11.11.1.1.1.1.2.2.2" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.cmml"><mi mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.2.2.2.2" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.2.cmml">w</mi><mrow id="S6.E8.m1.11.11.1.1.1.1.2.2.2.3" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.cmml"><mi mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.2" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.2.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.1" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.1.cmml">−</mo><mn mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.3" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.3.cmml">2</mn></mrow></msub><mo mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.3.3.5" xref="S6.E8.m1.11.11.1.1.1.1.3.4.cmml">,</mo><mi mathcolor="#000000" mathvariant="normal" id="S6.E8.m1.10.10" xref="S6.E8.m1.10.10.cmml">…</mi><mo mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.3.3.6" xref="S6.E8.m1.11.11.1.1.1.1.3.4.cmml">,</mo><msub id="S6.E8.m1.11.11.1.1.1.1.3.3.3" xref="S6.E8.m1.11.11.1.1.1.1.3.3.3.cmml"><mi mathcolor="#000000" id="S6.E8.m1.11.11.1.1.1.1.3.3.3.2" xref="S6.E8.m1.11.11.1.1.1.1.3.3.3.2.cmml">w</mi><mrow id="S6.E8.m1.1.1.1" xref="S6.E8.m1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.1.1.1.3" xref="S6.E8.m1.1.1.1.3.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.1.1.1.2" xref="S6.E8.m1.1.1.1.2.cmml">−</mo><mrow id="S6.E8.m1.1.1.1.1.1" xref="S6.E8.m1.1.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.1.1.1.1.1.2" xref="S6.E8.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S6.E8.m1.1.1.1.1.1.1" xref="S6.E8.m1.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.1.1.1.1.1.1.2" xref="S6.E8.m1.1.1.1.1.1.1.2.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.1.1.1.1.1.1.1" xref="S6.E8.m1.1.1.1.1.1.1.1.cmml">−</mo><mn mathcolor="#000000" id="S6.E8.m1.1.1.1.1.1.1.3" xref="S6.E8.m1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.1.1.1.1.1.3" xref="S6.E8.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.11.11.1.1.1.3" xref="S6.E8.m1.11.11.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S6.E8.m1.11.11.2" xref="S6.E8.m1.11.11.2.cmml">=</mo><mfrac mathcolor="#000000" id="S6.E8.m1.9.9" xref="S6.E8.m1.9.9.cmml"><mrow id="S6.E8.m1.5.5.4" xref="S6.E8.m1.5.5.4.cmml"><mi mathcolor="#000000" id="S6.E8.m1.5.5.4.6" xref="S6.E8.m1.5.5.4.6.cmml">C</mi><mo lspace="0em" rspace="0em" id="S6.E8.m1.5.5.4.5" xref="S6.E8.m1.5.5.4.5.cmml">​</mo><mrow id="S6.E8.m1.5.5.4.4.2" xref="S6.E8.m1.5.5.4.4.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.5.5.4.4.2.3" xref="S6.E8.m1.5.5.4.4.3.cmml">(</mo><msub id="S6.E8.m1.4.4.3.3.1.1" xref="S6.E8.m1.4.4.3.3.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.4.4.3.3.1.1.2" xref="S6.E8.m1.4.4.3.3.1.1.2.cmml">w</mi><mrow id="S6.E8.m1.2.2.1.1.1" xref="S6.E8.m1.2.2.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.2.2.1.1.1.3" xref="S6.E8.m1.2.2.1.1.1.3.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.2.2.1.1.1.2" xref="S6.E8.m1.2.2.1.1.1.2.cmml">−</mo><mrow id="S6.E8.m1.2.2.1.1.1.1.1" xref="S6.E8.m1.2.2.1.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.2.2.1.1.1.1.1.2" xref="S6.E8.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S6.E8.m1.2.2.1.1.1.1.1.1" xref="S6.E8.m1.2.2.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.2.2.1.1.1.1.1.1.2" xref="S6.E8.m1.2.2.1.1.1.1.1.1.2.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.2.2.1.1.1.1.1.1.1" xref="S6.E8.m1.2.2.1.1.1.1.1.1.1.cmml">−</mo><mn mathcolor="#000000" id="S6.E8.m1.2.2.1.1.1.1.1.1.3" xref="S6.E8.m1.2.2.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.2.2.1.1.1.1.1.3" xref="S6.E8.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub><mo mathcolor="#000000" id="S6.E8.m1.5.5.4.4.2.4" xref="S6.E8.m1.5.5.4.4.3.cmml">,</mo><mi mathcolor="#000000" mathvariant="normal" id="S6.E8.m1.3.3.2.2" xref="S6.E8.m1.3.3.2.2.cmml">…</mi><mo mathcolor="#000000" id="S6.E8.m1.5.5.4.4.2.5" xref="S6.E8.m1.5.5.4.4.3.cmml">,</mo><msub id="S6.E8.m1.5.5.4.4.2.2" xref="S6.E8.m1.5.5.4.4.2.2.cmml"><mi mathcolor="#000000" id="S6.E8.m1.5.5.4.4.2.2.2" xref="S6.E8.m1.5.5.4.4.2.2.2.cmml">w</mi><mi mathcolor="#000000" id="S6.E8.m1.5.5.4.4.2.2.3" xref="S6.E8.m1.5.5.4.4.2.2.3.cmml">n</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.5.5.4.4.2.6" xref="S6.E8.m1.5.5.4.4.3.cmml">)</mo></mrow></mrow><mrow id="S6.E8.m1.9.9.8" xref="S6.E8.m1.9.9.8.cmml"><mi mathcolor="#000000" id="S6.E8.m1.9.9.8.6" xref="S6.E8.m1.9.9.8.6.cmml">C</mi><mo lspace="0em" rspace="0em" id="S6.E8.m1.9.9.8.5" xref="S6.E8.m1.9.9.8.5.cmml">​</mo><mrow id="S6.E8.m1.9.9.8.4.2" xref="S6.E8.m1.9.9.8.4.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.9.9.8.4.2.3" xref="S6.E8.m1.9.9.8.4.3.cmml">(</mo><msub id="S6.E8.m1.8.8.7.3.1.1" xref="S6.E8.m1.8.8.7.3.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.8.8.7.3.1.1.2" xref="S6.E8.m1.8.8.7.3.1.1.2.cmml">w</mi><mrow id="S6.E8.m1.6.6.5.1.1" xref="S6.E8.m1.6.6.5.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.6.6.5.1.1.3" xref="S6.E8.m1.6.6.5.1.1.3.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.6.6.5.1.1.2" xref="S6.E8.m1.6.6.5.1.1.2.cmml">−</mo><mrow id="S6.E8.m1.6.6.5.1.1.1.1" xref="S6.E8.m1.6.6.5.1.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.6.6.5.1.1.1.1.2" xref="S6.E8.m1.6.6.5.1.1.1.1.1.cmml">(</mo><mrow id="S6.E8.m1.6.6.5.1.1.1.1.1" xref="S6.E8.m1.6.6.5.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E8.m1.6.6.5.1.1.1.1.1.2" xref="S6.E8.m1.6.6.5.1.1.1.1.1.2.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.6.6.5.1.1.1.1.1.1" xref="S6.E8.m1.6.6.5.1.1.1.1.1.1.cmml">−</mo><mn mathcolor="#000000" id="S6.E8.m1.6.6.5.1.1.1.1.1.3" xref="S6.E8.m1.6.6.5.1.1.1.1.1.3.cmml">1</mn></mrow><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.6.6.5.1.1.1.1.3" xref="S6.E8.m1.6.6.5.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub><mo mathcolor="#000000" id="S6.E8.m1.9.9.8.4.2.4" xref="S6.E8.m1.9.9.8.4.3.cmml">,</mo><mi mathcolor="#000000" mathvariant="normal" id="S6.E8.m1.7.7.6.2" xref="S6.E8.m1.7.7.6.2.cmml">…</mi><mo mathcolor="#000000" id="S6.E8.m1.9.9.8.4.2.5" xref="S6.E8.m1.9.9.8.4.3.cmml">,</mo><msub id="S6.E8.m1.9.9.8.4.2.2" xref="S6.E8.m1.9.9.8.4.2.2.cmml"><mi mathcolor="#000000" id="S6.E8.m1.9.9.8.4.2.2.2" xref="S6.E8.m1.9.9.8.4.2.2.2.cmml">w</mi><mrow id="S6.E8.m1.9.9.8.4.2.2.3" xref="S6.E8.m1.9.9.8.4.2.2.3.cmml"><mi mathcolor="#000000" id="S6.E8.m1.9.9.8.4.2.2.3.2" xref="S6.E8.m1.9.9.8.4.2.2.3.2.cmml">n</mi><mo mathcolor="#000000" id="S6.E8.m1.9.9.8.4.2.2.3.1" xref="S6.E8.m1.9.9.8.4.2.2.3.1.cmml">−</mo><mn mathcolor="#000000" id="S6.E8.m1.9.9.8.4.2.2.3.3" xref="S6.E8.m1.9.9.8.4.2.2.3.3.cmml">1</mn></mrow></msub><mo mathcolor="#000000" stretchy="false" id="S6.E8.m1.9.9.8.4.2.6" xref="S6.E8.m1.9.9.8.4.3.cmml">)</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S6.E8.m1.11b"><apply id="S6.E8.m1.11.11.cmml" xref="S6.E8.m1.11.11"><eq id="S6.E8.m1.11.11.2.cmml" xref="S6.E8.m1.11.11.2"></eq><apply id="S6.E8.m1.11.11.1.cmml" xref="S6.E8.m1.11.11.1"><times id="S6.E8.m1.11.11.1.2.cmml" xref="S6.E8.m1.11.11.1.2"></times><ci id="S6.E8.m1.11.11.1.3.cmml" xref="S6.E8.m1.11.11.1.3">𝑃</ci><apply id="S6.E8.m1.11.11.1.1.1.1.cmml" xref="S6.E8.m1.11.11.1.1.1"><csymbol cd="latexml" id="S6.E8.m1.11.11.1.1.1.1.4.cmml" xref="S6.E8.m1.11.11.1.1.1.1.4">conditional</csymbol><apply id="S6.E8.m1.11.11.1.1.1.1.5.cmml" xref="S6.E8.m1.11.11.1.1.1.1.5"><csymbol cd="ambiguous" id="S6.E8.m1.11.11.1.1.1.1.5.1.cmml" xref="S6.E8.m1.11.11.1.1.1.1.5">subscript</csymbol><ci id="S6.E8.m1.11.11.1.1.1.1.5.2.cmml" xref="S6.E8.m1.11.11.1.1.1.1.5.2">𝑤</ci><ci id="S6.E8.m1.11.11.1.1.1.1.5.3.cmml" xref="S6.E8.m1.11.11.1.1.1.1.5.3">𝑛</ci></apply><list id="S6.E8.m1.11.11.1.1.1.1.3.4.cmml" xref="S6.E8.m1.11.11.1.1.1.1.3.3"><apply id="S6.E8.m1.11.11.1.1.1.1.1.1.1.cmml" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.E8.m1.11.11.1.1.1.1.1.1.1.1.cmml" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1">subscript</csymbol><ci id="S6.E8.m1.11.11.1.1.1.1.1.1.1.2.cmml" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.2">𝑤</ci><apply id="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.cmml" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.3"><minus id="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.1.cmml" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.1"></minus><ci id="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.2.cmml" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.2">𝑛</ci><cn type="integer" id="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.3.cmml" xref="S6.E8.m1.11.11.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S6.E8.m1.11.11.1.1.1.1.2.2.2.cmml" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S6.E8.m1.11.11.1.1.1.1.2.2.2.1.cmml" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2">subscript</csymbol><ci id="S6.E8.m1.11.11.1.1.1.1.2.2.2.2.cmml" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.2">𝑤</ci><apply id="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.cmml" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.3"><minus id="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.1.cmml" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.1"></minus><ci id="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.2.cmml" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.2">𝑛</ci><cn type="integer" id="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.3.cmml" xref="S6.E8.m1.11.11.1.1.1.1.2.2.2.3.3">2</cn></apply></apply><ci id="S6.E8.m1.10.10.cmml" xref="S6.E8.m1.10.10">…</ci><apply id="S6.E8.m1.11.11.1.1.1.1.3.3.3.cmml" xref="S6.E8.m1.11.11.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S6.E8.m1.11.11.1.1.1.1.3.3.3.1.cmml" xref="S6.E8.m1.11.11.1.1.1.1.3.3.3">subscript</csymbol><ci id="S6.E8.m1.11.11.1.1.1.1.3.3.3.2.cmml" xref="S6.E8.m1.11.11.1.1.1.1.3.3.3.2">𝑤</ci><apply id="S6.E8.m1.1.1.1.cmml" xref="S6.E8.m1.1.1.1"><minus id="S6.E8.m1.1.1.1.2.cmml" xref="S6.E8.m1.1.1.1.2"></minus><ci id="S6.E8.m1.1.1.1.3.cmml" xref="S6.E8.m1.1.1.1.3">𝑛</ci><apply id="S6.E8.m1.1.1.1.1.1.1.cmml" xref="S6.E8.m1.1.1.1.1.1"><minus id="S6.E8.m1.1.1.1.1.1.1.1.cmml" xref="S6.E8.m1.1.1.1.1.1.1.1"></minus><ci id="S6.E8.m1.1.1.1.1.1.1.2.cmml" xref="S6.E8.m1.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S6.E8.m1.1.1.1.1.1.1.3.cmml" xref="S6.E8.m1.1.1.1.1.1.1.3">1</cn></apply></apply></apply></list></apply></apply><apply id="S6.E8.m1.9.9.cmml" xref="S6.E8.m1.9.9"><divide id="S6.E8.m1.9.9.9.cmml" xref="S6.E8.m1.9.9"></divide><apply id="S6.E8.m1.5.5.4.cmml" xref="S6.E8.m1.5.5.4"><times id="S6.E8.m1.5.5.4.5.cmml" xref="S6.E8.m1.5.5.4.5"></times><ci id="S6.E8.m1.5.5.4.6.cmml" xref="S6.E8.m1.5.5.4.6">𝐶</ci><vector id="S6.E8.m1.5.5.4.4.3.cmml" xref="S6.E8.m1.5.5.4.4.2"><apply id="S6.E8.m1.4.4.3.3.1.1.cmml" xref="S6.E8.m1.4.4.3.3.1.1"><csymbol cd="ambiguous" id="S6.E8.m1.4.4.3.3.1.1.1.cmml" xref="S6.E8.m1.4.4.3.3.1.1">subscript</csymbol><ci id="S6.E8.m1.4.4.3.3.1.1.2.cmml" xref="S6.E8.m1.4.4.3.3.1.1.2">𝑤</ci><apply id="S6.E8.m1.2.2.1.1.1.cmml" xref="S6.E8.m1.2.2.1.1.1"><minus id="S6.E8.m1.2.2.1.1.1.2.cmml" xref="S6.E8.m1.2.2.1.1.1.2"></minus><ci id="S6.E8.m1.2.2.1.1.1.3.cmml" xref="S6.E8.m1.2.2.1.1.1.3">𝑛</ci><apply id="S6.E8.m1.2.2.1.1.1.1.1.1.cmml" xref="S6.E8.m1.2.2.1.1.1.1.1"><minus id="S6.E8.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S6.E8.m1.2.2.1.1.1.1.1.1.1"></minus><ci id="S6.E8.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S6.E8.m1.2.2.1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S6.E8.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S6.E8.m1.2.2.1.1.1.1.1.1.3">1</cn></apply></apply></apply><ci id="S6.E8.m1.3.3.2.2.cmml" xref="S6.E8.m1.3.3.2.2">…</ci><apply id="S6.E8.m1.5.5.4.4.2.2.cmml" xref="S6.E8.m1.5.5.4.4.2.2"><csymbol cd="ambiguous" id="S6.E8.m1.5.5.4.4.2.2.1.cmml" xref="S6.E8.m1.5.5.4.4.2.2">subscript</csymbol><ci id="S6.E8.m1.5.5.4.4.2.2.2.cmml" xref="S6.E8.m1.5.5.4.4.2.2.2">𝑤</ci><ci id="S6.E8.m1.5.5.4.4.2.2.3.cmml" xref="S6.E8.m1.5.5.4.4.2.2.3">𝑛</ci></apply></vector></apply><apply id="S6.E8.m1.9.9.8.cmml" xref="S6.E8.m1.9.9.8"><times id="S6.E8.m1.9.9.8.5.cmml" xref="S6.E8.m1.9.9.8.5"></times><ci id="S6.E8.m1.9.9.8.6.cmml" xref="S6.E8.m1.9.9.8.6">𝐶</ci><vector id="S6.E8.m1.9.9.8.4.3.cmml" xref="S6.E8.m1.9.9.8.4.2"><apply id="S6.E8.m1.8.8.7.3.1.1.cmml" xref="S6.E8.m1.8.8.7.3.1.1"><csymbol cd="ambiguous" id="S6.E8.m1.8.8.7.3.1.1.1.cmml" xref="S6.E8.m1.8.8.7.3.1.1">subscript</csymbol><ci id="S6.E8.m1.8.8.7.3.1.1.2.cmml" xref="S6.E8.m1.8.8.7.3.1.1.2">𝑤</ci><apply id="S6.E8.m1.6.6.5.1.1.cmml" xref="S6.E8.m1.6.6.5.1.1"><minus id="S6.E8.m1.6.6.5.1.1.2.cmml" xref="S6.E8.m1.6.6.5.1.1.2"></minus><ci id="S6.E8.m1.6.6.5.1.1.3.cmml" xref="S6.E8.m1.6.6.5.1.1.3">𝑛</ci><apply id="S6.E8.m1.6.6.5.1.1.1.1.1.cmml" xref="S6.E8.m1.6.6.5.1.1.1.1"><minus id="S6.E8.m1.6.6.5.1.1.1.1.1.1.cmml" xref="S6.E8.m1.6.6.5.1.1.1.1.1.1"></minus><ci id="S6.E8.m1.6.6.5.1.1.1.1.1.2.cmml" xref="S6.E8.m1.6.6.5.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S6.E8.m1.6.6.5.1.1.1.1.1.3.cmml" xref="S6.E8.m1.6.6.5.1.1.1.1.1.3">1</cn></apply></apply></apply><ci id="S6.E8.m1.7.7.6.2.cmml" xref="S6.E8.m1.7.7.6.2">…</ci><apply id="S6.E8.m1.9.9.8.4.2.2.cmml" xref="S6.E8.m1.9.9.8.4.2.2"><csymbol cd="ambiguous" id="S6.E8.m1.9.9.8.4.2.2.1.cmml" xref="S6.E8.m1.9.9.8.4.2.2">subscript</csymbol><ci id="S6.E8.m1.9.9.8.4.2.2.2.cmml" xref="S6.E8.m1.9.9.8.4.2.2.2">𝑤</ci><apply id="S6.E8.m1.9.9.8.4.2.2.3.cmml" xref="S6.E8.m1.9.9.8.4.2.2.3"><minus id="S6.E8.m1.9.9.8.4.2.2.3.1.cmml" xref="S6.E8.m1.9.9.8.4.2.2.3.1"></minus><ci id="S6.E8.m1.9.9.8.4.2.2.3.2.cmml" xref="S6.E8.m1.9.9.8.4.2.2.3.2">𝑛</ci><cn type="integer" id="S6.E8.m1.9.9.8.4.2.2.3.3.cmml" xref="S6.E8.m1.9.9.8.4.2.2.3.3">1</cn></apply></apply></vector></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E8.m1.11c">P(w_{n}|w_{n-1},w_{n-2},\ldots,w_{n-(n-1)})=\frac{C(w_{n-(n-1)},\ldots,w_{n})}{C(w_{n-(n-1)},\ldots,w_{n-1})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="S6.SS4.p2" class="ltx_para">
<p id="S6.SS4.p2.2" class="ltx_p"><span id="S6.SS4.p2.2.1" class="ltx_text" style="color:#000000;">Additionally, data augmentation plays a crucial role in ASR-based </span><a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a><span id="S6.SS4.p2.2.2" class="ltx_text" style="color:#000000;">. Typically, data augmentation in domain-specific ASR involves generating synthetic training examples by altering existing recordings or using text-to-speech (TTS) systems to create new audio samples from domain-specific texts. Mathematically, augmentation techniques can include time stretching, pitch shifting, adding noise, or simulating room acoustics, each represented as transformations </span><math id="S6.SS4.p2.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S6.SS4.p2.1.m1.1a"><mi mathcolor="#000000" id="S6.SS4.p2.1.m1.1.1" xref="S6.SS4.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.1.m1.1b"><ci id="S6.SS4.p2.1.m1.1.1.cmml" xref="S6.SS4.p2.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.1.m1.1c">T</annotation></semantics></math><span id="S6.SS4.p2.2.3" class="ltx_text" style="color:#000000;"> applied to the original audio signal </span><math id="S6.SS4.p2.2.m2.1" class="ltx_Math" alttext="x(t)" display="inline"><semantics id="S6.SS4.p2.2.m2.1a"><mrow id="S6.SS4.p2.2.m2.1.2" xref="S6.SS4.p2.2.m2.1.2.cmml"><mi mathcolor="#000000" id="S6.SS4.p2.2.m2.1.2.2" xref="S6.SS4.p2.2.m2.1.2.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S6.SS4.p2.2.m2.1.2.1" xref="S6.SS4.p2.2.m2.1.2.1.cmml">​</mo><mrow id="S6.SS4.p2.2.m2.1.2.3.2" xref="S6.SS4.p2.2.m2.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.SS4.p2.2.m2.1.2.3.2.1" xref="S6.SS4.p2.2.m2.1.2.cmml">(</mo><mi mathcolor="#000000" id="S6.SS4.p2.2.m2.1.1" xref="S6.SS4.p2.2.m2.1.1.cmml">t</mi><mo mathcolor="#000000" stretchy="false" id="S6.SS4.p2.2.m2.1.2.3.2.2" xref="S6.SS4.p2.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.2.m2.1b"><apply id="S6.SS4.p2.2.m2.1.2.cmml" xref="S6.SS4.p2.2.m2.1.2"><times id="S6.SS4.p2.2.m2.1.2.1.cmml" xref="S6.SS4.p2.2.m2.1.2.1"></times><ci id="S6.SS4.p2.2.m2.1.2.2.cmml" xref="S6.SS4.p2.2.m2.1.2.2">𝑥</ci><ci id="S6.SS4.p2.2.m2.1.1.cmml" xref="S6.SS4.p2.2.m2.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.2.m2.1c">x(t)</annotation></semantics></math><span id="S6.SS4.p2.2.4" class="ltx_text" style="color:#000000;">:</span></p>
<table id="S6.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S6.E9.m1.4" class="ltx_Math" alttext="x^{\prime}(t)=T(x(t);\phi)" display="block"><semantics id="S6.E9.m1.4a"><mrow id="S6.E9.m1.4.4" xref="S6.E9.m1.4.4.cmml"><mrow id="S6.E9.m1.4.4.3" xref="S6.E9.m1.4.4.3.cmml"><msup id="S6.E9.m1.4.4.3.2" xref="S6.E9.m1.4.4.3.2.cmml"><mi mathcolor="#000000" id="S6.E9.m1.4.4.3.2.2" xref="S6.E9.m1.4.4.3.2.2.cmml">x</mi><mo mathcolor="#000000" id="S6.E9.m1.4.4.3.2.3" xref="S6.E9.m1.4.4.3.2.3.cmml">′</mo></msup><mo lspace="0em" rspace="0em" id="S6.E9.m1.4.4.3.1" xref="S6.E9.m1.4.4.3.1.cmml">​</mo><mrow id="S6.E9.m1.4.4.3.3.2" xref="S6.E9.m1.4.4.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E9.m1.4.4.3.3.2.1" xref="S6.E9.m1.4.4.3.cmml">(</mo><mi mathcolor="#000000" id="S6.E9.m1.1.1" xref="S6.E9.m1.1.1.cmml">t</mi><mo mathcolor="#000000" stretchy="false" id="S6.E9.m1.4.4.3.3.2.2" xref="S6.E9.m1.4.4.3.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S6.E9.m1.4.4.2" xref="S6.E9.m1.4.4.2.cmml">=</mo><mrow id="S6.E9.m1.4.4.1" xref="S6.E9.m1.4.4.1.cmml"><mi mathcolor="#000000" id="S6.E9.m1.4.4.1.3" xref="S6.E9.m1.4.4.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S6.E9.m1.4.4.1.2" xref="S6.E9.m1.4.4.1.2.cmml">​</mo><mrow id="S6.E9.m1.4.4.1.1.1" xref="S6.E9.m1.4.4.1.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E9.m1.4.4.1.1.1.2" xref="S6.E9.m1.4.4.1.1.2.cmml">(</mo><mrow id="S6.E9.m1.4.4.1.1.1.1" xref="S6.E9.m1.4.4.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E9.m1.4.4.1.1.1.1.2" xref="S6.E9.m1.4.4.1.1.1.1.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S6.E9.m1.4.4.1.1.1.1.1" xref="S6.E9.m1.4.4.1.1.1.1.1.cmml">​</mo><mrow id="S6.E9.m1.4.4.1.1.1.1.3.2" xref="S6.E9.m1.4.4.1.1.1.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E9.m1.4.4.1.1.1.1.3.2.1" xref="S6.E9.m1.4.4.1.1.1.1.cmml">(</mo><mi mathcolor="#000000" id="S6.E9.m1.2.2" xref="S6.E9.m1.2.2.cmml">t</mi><mo mathcolor="#000000" stretchy="false" id="S6.E9.m1.4.4.1.1.1.1.3.2.2" xref="S6.E9.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S6.E9.m1.4.4.1.1.1.3" xref="S6.E9.m1.4.4.1.1.2.cmml">;</mo><mi mathcolor="#000000" id="S6.E9.m1.3.3" xref="S6.E9.m1.3.3.cmml">ϕ</mi><mo mathcolor="#000000" stretchy="false" id="S6.E9.m1.4.4.1.1.1.4" xref="S6.E9.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E9.m1.4b"><apply id="S6.E9.m1.4.4.cmml" xref="S6.E9.m1.4.4"><eq id="S6.E9.m1.4.4.2.cmml" xref="S6.E9.m1.4.4.2"></eq><apply id="S6.E9.m1.4.4.3.cmml" xref="S6.E9.m1.4.4.3"><times id="S6.E9.m1.4.4.3.1.cmml" xref="S6.E9.m1.4.4.3.1"></times><apply id="S6.E9.m1.4.4.3.2.cmml" xref="S6.E9.m1.4.4.3.2"><csymbol cd="ambiguous" id="S6.E9.m1.4.4.3.2.1.cmml" xref="S6.E9.m1.4.4.3.2">superscript</csymbol><ci id="S6.E9.m1.4.4.3.2.2.cmml" xref="S6.E9.m1.4.4.3.2.2">𝑥</ci><ci id="S6.E9.m1.4.4.3.2.3.cmml" xref="S6.E9.m1.4.4.3.2.3">′</ci></apply><ci id="S6.E9.m1.1.1.cmml" xref="S6.E9.m1.1.1">𝑡</ci></apply><apply id="S6.E9.m1.4.4.1.cmml" xref="S6.E9.m1.4.4.1"><times id="S6.E9.m1.4.4.1.2.cmml" xref="S6.E9.m1.4.4.1.2"></times><ci id="S6.E9.m1.4.4.1.3.cmml" xref="S6.E9.m1.4.4.1.3">𝑇</ci><list id="S6.E9.m1.4.4.1.1.2.cmml" xref="S6.E9.m1.4.4.1.1.1"><apply id="S6.E9.m1.4.4.1.1.1.1.cmml" xref="S6.E9.m1.4.4.1.1.1.1"><times id="S6.E9.m1.4.4.1.1.1.1.1.cmml" xref="S6.E9.m1.4.4.1.1.1.1.1"></times><ci id="S6.E9.m1.4.4.1.1.1.1.2.cmml" xref="S6.E9.m1.4.4.1.1.1.1.2">𝑥</ci><ci id="S6.E9.m1.2.2.cmml" xref="S6.E9.m1.2.2">𝑡</ci></apply><ci id="S6.E9.m1.3.3.cmml" xref="S6.E9.m1.3.3">italic-ϕ</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E9.m1.4c">x^{\prime}(t)=T(x(t);\phi)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S6.SS4.p2.3" class="ltx_p"><span id="S6.SS4.p2.3.1" class="ltx_text" style="color:#000000;">where </span><math id="S6.SS4.p2.3.m1.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S6.SS4.p2.3.m1.1a"><mi mathcolor="#000000" id="S6.SS4.p2.3.m1.1.1" xref="S6.SS4.p2.3.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.3.m1.1b"><ci id="S6.SS4.p2.3.m1.1.1.cmml" xref="S6.SS4.p2.3.m1.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.3.m1.1c">\phi</annotation></semantics></math><span id="S6.SS4.p2.3.2" class="ltx_text" style="color:#000000;"> represents the parameters of the transformation. Moving on, regularization techniques are applied to prevent overfitting to the domain-specific data, ensuring the model maintains generalization capabilities. Techniques such as dropout, L1/L2 regularization, or elastic net involve adding terms to the loss function or modifying the optimization process to penalize large weights or complex models. For instance, L2 regularization adds a penalty equal to the square of the magnitude of coefficients:</span></p>
<table id="S6.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S6.E10.m1.5" class="ltx_Math" alttext="L^{\prime}(D;\theta)=L(D;\theta)+\lambda\|\theta\|^{2}" display="block"><semantics id="S6.E10.m1.5a"><mrow id="S6.E10.m1.5.6" xref="S6.E10.m1.5.6.cmml"><mrow id="S6.E10.m1.5.6.2" xref="S6.E10.m1.5.6.2.cmml"><msup id="S6.E10.m1.5.6.2.2" xref="S6.E10.m1.5.6.2.2.cmml"><mi mathcolor="#000000" id="S6.E10.m1.5.6.2.2.2" xref="S6.E10.m1.5.6.2.2.2.cmml">L</mi><mo mathcolor="#000000" id="S6.E10.m1.5.6.2.2.3" xref="S6.E10.m1.5.6.2.2.3.cmml">′</mo></msup><mo lspace="0em" rspace="0em" id="S6.E10.m1.5.6.2.1" xref="S6.E10.m1.5.6.2.1.cmml">​</mo><mrow id="S6.E10.m1.5.6.2.3.2" xref="S6.E10.m1.5.6.2.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E10.m1.5.6.2.3.2.1" xref="S6.E10.m1.5.6.2.3.1.cmml">(</mo><mi mathcolor="#000000" id="S6.E10.m1.1.1" xref="S6.E10.m1.1.1.cmml">D</mi><mo mathcolor="#000000" id="S6.E10.m1.5.6.2.3.2.2" xref="S6.E10.m1.5.6.2.3.1.cmml">;</mo><mi mathcolor="#000000" id="S6.E10.m1.2.2" xref="S6.E10.m1.2.2.cmml">θ</mi><mo mathcolor="#000000" stretchy="false" id="S6.E10.m1.5.6.2.3.2.3" xref="S6.E10.m1.5.6.2.3.1.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S6.E10.m1.5.6.1" xref="S6.E10.m1.5.6.1.cmml">=</mo><mrow id="S6.E10.m1.5.6.3" xref="S6.E10.m1.5.6.3.cmml"><mrow id="S6.E10.m1.5.6.3.2" xref="S6.E10.m1.5.6.3.2.cmml"><mi mathcolor="#000000" id="S6.E10.m1.5.6.3.2.2" xref="S6.E10.m1.5.6.3.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S6.E10.m1.5.6.3.2.1" xref="S6.E10.m1.5.6.3.2.1.cmml">​</mo><mrow id="S6.E10.m1.5.6.3.2.3.2" xref="S6.E10.m1.5.6.3.2.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E10.m1.5.6.3.2.3.2.1" xref="S6.E10.m1.5.6.3.2.3.1.cmml">(</mo><mi mathcolor="#000000" id="S6.E10.m1.3.3" xref="S6.E10.m1.3.3.cmml">D</mi><mo mathcolor="#000000" id="S6.E10.m1.5.6.3.2.3.2.2" xref="S6.E10.m1.5.6.3.2.3.1.cmml">;</mo><mi mathcolor="#000000" id="S6.E10.m1.4.4" xref="S6.E10.m1.4.4.cmml">θ</mi><mo mathcolor="#000000" stretchy="false" id="S6.E10.m1.5.6.3.2.3.2.3" xref="S6.E10.m1.5.6.3.2.3.1.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S6.E10.m1.5.6.3.1" xref="S6.E10.m1.5.6.3.1.cmml">+</mo><mrow id="S6.E10.m1.5.6.3.3" xref="S6.E10.m1.5.6.3.3.cmml"><mi mathcolor="#000000" id="S6.E10.m1.5.6.3.3.2" xref="S6.E10.m1.5.6.3.3.2.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S6.E10.m1.5.6.3.3.1" xref="S6.E10.m1.5.6.3.3.1.cmml">​</mo><msup id="S6.E10.m1.5.6.3.3.3" xref="S6.E10.m1.5.6.3.3.3.cmml"><mrow id="S6.E10.m1.5.6.3.3.3.2.2" xref="S6.E10.m1.5.6.3.3.3.2.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E10.m1.5.6.3.3.3.2.2.1" xref="S6.E10.m1.5.6.3.3.3.2.1.1.cmml">‖</mo><mi mathcolor="#000000" id="S6.E10.m1.5.5" xref="S6.E10.m1.5.5.cmml">θ</mi><mo mathcolor="#000000" stretchy="false" id="S6.E10.m1.5.6.3.3.3.2.2.2" xref="S6.E10.m1.5.6.3.3.3.2.1.1.cmml">‖</mo></mrow><mn mathcolor="#000000" id="S6.E10.m1.5.6.3.3.3.3" xref="S6.E10.m1.5.6.3.3.3.3.cmml">2</mn></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E10.m1.5b"><apply id="S6.E10.m1.5.6.cmml" xref="S6.E10.m1.5.6"><eq id="S6.E10.m1.5.6.1.cmml" xref="S6.E10.m1.5.6.1"></eq><apply id="S6.E10.m1.5.6.2.cmml" xref="S6.E10.m1.5.6.2"><times id="S6.E10.m1.5.6.2.1.cmml" xref="S6.E10.m1.5.6.2.1"></times><apply id="S6.E10.m1.5.6.2.2.cmml" xref="S6.E10.m1.5.6.2.2"><csymbol cd="ambiguous" id="S6.E10.m1.5.6.2.2.1.cmml" xref="S6.E10.m1.5.6.2.2">superscript</csymbol><ci id="S6.E10.m1.5.6.2.2.2.cmml" xref="S6.E10.m1.5.6.2.2.2">𝐿</ci><ci id="S6.E10.m1.5.6.2.2.3.cmml" xref="S6.E10.m1.5.6.2.2.3">′</ci></apply><list id="S6.E10.m1.5.6.2.3.1.cmml" xref="S6.E10.m1.5.6.2.3.2"><ci id="S6.E10.m1.1.1.cmml" xref="S6.E10.m1.1.1">𝐷</ci><ci id="S6.E10.m1.2.2.cmml" xref="S6.E10.m1.2.2">𝜃</ci></list></apply><apply id="S6.E10.m1.5.6.3.cmml" xref="S6.E10.m1.5.6.3"><plus id="S6.E10.m1.5.6.3.1.cmml" xref="S6.E10.m1.5.6.3.1"></plus><apply id="S6.E10.m1.5.6.3.2.cmml" xref="S6.E10.m1.5.6.3.2"><times id="S6.E10.m1.5.6.3.2.1.cmml" xref="S6.E10.m1.5.6.3.2.1"></times><ci id="S6.E10.m1.5.6.3.2.2.cmml" xref="S6.E10.m1.5.6.3.2.2">𝐿</ci><list id="S6.E10.m1.5.6.3.2.3.1.cmml" xref="S6.E10.m1.5.6.3.2.3.2"><ci id="S6.E10.m1.3.3.cmml" xref="S6.E10.m1.3.3">𝐷</ci><ci id="S6.E10.m1.4.4.cmml" xref="S6.E10.m1.4.4">𝜃</ci></list></apply><apply id="S6.E10.m1.5.6.3.3.cmml" xref="S6.E10.m1.5.6.3.3"><times id="S6.E10.m1.5.6.3.3.1.cmml" xref="S6.E10.m1.5.6.3.3.1"></times><ci id="S6.E10.m1.5.6.3.3.2.cmml" xref="S6.E10.m1.5.6.3.3.2">𝜆</ci><apply id="S6.E10.m1.5.6.3.3.3.cmml" xref="S6.E10.m1.5.6.3.3.3"><csymbol cd="ambiguous" id="S6.E10.m1.5.6.3.3.3.1.cmml" xref="S6.E10.m1.5.6.3.3.3">superscript</csymbol><apply id="S6.E10.m1.5.6.3.3.3.2.1.cmml" xref="S6.E10.m1.5.6.3.3.3.2.2"><csymbol cd="latexml" id="S6.E10.m1.5.6.3.3.3.2.1.1.cmml" xref="S6.E10.m1.5.6.3.3.3.2.2.1">norm</csymbol><ci id="S6.E10.m1.5.5.cmml" xref="S6.E10.m1.5.5">𝜃</ci></apply><cn type="integer" id="S6.E10.m1.5.6.3.3.3.3.cmml" xref="S6.E10.m1.5.6.3.3.3.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E10.m1.5c">L^{\prime}(D;\theta)=L(D;\theta)+\lambda\|\theta\|^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p id="S6.SS4.p2.4" class="ltx_p"><span id="S6.SS4.p2.4.1" class="ltx_text" style="color:#000000;">where </span><math id="S6.SS4.p2.4.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S6.SS4.p2.4.m1.1a"><mi mathcolor="#000000" id="S6.SS4.p2.4.m1.1.1" xref="S6.SS4.p2.4.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.4.m1.1b"><ci id="S6.SS4.p2.4.m1.1.1.cmml" xref="S6.SS4.p2.4.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.4.m1.1c">\lambda</annotation></semantics></math><span id="S6.SS4.p2.4.2" class="ltx_text" style="color:#000000;"> is a regularization parameter.</span></p>
</div>
<div id="S6.SS4.p3" class="ltx_para">
<p id="S6.SS4.p3.1" class="ltx_p"><span id="S6.SS4.p3.1.1" class="ltx_text" style="color:#000000;">While DSLM offers substantial benefits, challenges remain, such as data scarcity in niche domains, the need for continual model updates to keep pace with evolving language use, and ensuring privacy and security in sensitive domains like healthcare and finance. Addressing these challenges through innovative approaches in model training, data augmentation, and privacy-preserving technologies will be crucial for the advancement of domain-specific ASR systems.</span></p>
</div>
<div id="S6.SS4.p4" class="ltx_para">
<p id="S6.SS4.p4.1" class="ltx_p"><span id="S6.SS4.p4.1.1" class="ltx_text" style="color:#000000;">Privacy preservation
With the advancements in </span><a href="#Sx1.30.30.30"><abbr href="#Sx1.30.30.30" title="machine learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ML</span></span></abbr></a><span id="S6.SS4.p4.1.2" class="ltx_text" style="color:#000000;">, DL, and </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS4.p4.1.3" class="ltx_text" style="color:#000000;">, </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS4.p4.1.4" class="ltx_text" style="color:#000000;"> systems have become more practical and scalable. However, these systems also introduce serious privacy concerns due to the abundance of sensitive acoustic and textual information in speech data.</span></p>
</div>
<div id="S6.SS4.p5" class="ltx_para">
<p id="S6.SS4.p5.1" class="ltx_p"><span id="S6.SS4.p5.1.1" class="ltx_text" style="color:#000000;">While open-source and offline </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS4.p5.1.2" class="ltx_text" style="color:#000000;"> systems can mitigate privacy risks, online </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS4.p5.1.3" class="ltx_text" style="color:#000000;">-based systems can amplify these threats. Additionally, the transcription performance of offline and open-source </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS4.p5.1.4" class="ltx_text" style="color:#000000;"> systems is typically inferior to cloud-based </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS4.p5.1.5" class="ltx_text" style="color:#000000;"> systems, especially in real-world scenarios </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS4.p5.1.6.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">ahmed2020preech</span><span id="S6.SS4.p5.1.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS4.p5.1.8" class="ltx_text" style="color:#000000;">. In this context, the </span><math id="S6.SS4.p5.1.m1.1" class="ltx_Math" alttext="D_{S}" display="inline"><semantics id="S6.SS4.p5.1.m1.1a"><msub id="S6.SS4.p5.1.m1.1.1" xref="S6.SS4.p5.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS4.p5.1.m1.1.1.2" xref="S6.SS4.p5.1.m1.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS4.p5.1.m1.1.1.3" xref="S6.SS4.p5.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS4.p5.1.m1.1b"><apply id="S6.SS4.p5.1.m1.1.1.cmml" xref="S6.SS4.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S6.SS4.p5.1.m1.1.1.1.cmml" xref="S6.SS4.p5.1.m1.1.1">subscript</csymbol><ci id="S6.SS4.p5.1.m1.1.1.2.cmml" xref="S6.SS4.p5.1.m1.1.1.2">𝐷</ci><ci id="S6.SS4.p5.1.m1.1.1.3.cmml" xref="S6.SS4.p5.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p5.1.m1.1c">D_{S}</annotation></semantics></math><span id="S6.SS4.p5.1.9" class="ltx_text" style="color:#000000;"> data may contain sensitive information that needs to be protected. Thus, preserving users’ privacy during the knowledge transfer from the  </span><a href="#Sx1.40.40.40"><span href="#Sx1.40.40.40" title="source domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">source domain</span></span></span></a><span id="S6.SS4.p5.1.10" class="ltx_text" style="color:#000000;"> (</span><a href="#Sx1.40.40.40"><abbr href="#Sx1.40.40.40" title="source domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SD</span></span></abbr></a><span id="S6.SS4.p5.1.11" class="ltx_text" style="color:#000000;">) to the  </span><a href="#Sx1.48.48.48"><span href="#Sx1.48.48.48" title="target domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">target domain</span></span></span></a><span id="S6.SS4.p5.1.12" class="ltx_text" style="color:#000000;"> (</span><a href="#Sx1.48.48.48"><abbr href="#Sx1.48.48.48" title="target domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">TD</span></span></abbr></a><span id="S6.SS4.p5.1.13" class="ltx_text" style="color:#000000;">) becomes a critical issue.</span></p>
</div>
<div id="S6.SS4.p6" class="ltx_para">
<p id="S6.SS4.p6.1" class="ltx_p"><span id="S6.SS4.p6.1.1" class="ltx_text" style="color:#000000;">To address this challenge, future research efforts should focus on integrating effective security and privacy protection strategies. Examples include decentralized </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS4.p6.1.2" class="ltx_text" style="color:#000000;"> approaches utilizing blockchain technology </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS4.p6.1.3.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">ul2020decentralized</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2021enabling</span><span id="S6.SS4.p6.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS4.p6.1.5" class="ltx_text" style="color:#000000;"> and federated </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS4.p6.1.6" class="ltx_text" style="color:#000000;"> methods </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS4.p6.1.7.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2021federated</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">maurya2021federated</span><span id="S6.SS4.p6.1.8.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS4.p6.1.9" class="ltx_text" style="color:#000000;">. These approaches aim to ensure privacy-preserving knowledge transfer in </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS4.p6.1.10" class="ltx_text" style="color:#000000;">-based </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS4.p6.1.11" class="ltx_text" style="color:#000000;"> systems.</span></p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Interpretation of <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a> models</h3>

<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p"><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS5.p1.1.1" class="ltx_text" style="color:#000000;">-based </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS5.p1.1.2" class="ltx_text" style="color:#000000;"> models, despite their success, are often considered as "black box" systems lacking interpretability. This lack of interpretability raises doubts about the credibility and repeatability of their decisions, making it crucial to explain the reasoning behind their predictions. The field of explainable and interpretable </span><a href="#Sx1.30.30.30"><abbr href="#Sx1.30.30.30" title="machine learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ML</span></span></abbr></a><span id="S6.SS5.p1.1.3" class="ltx_text" style="color:#000000;">/DL has gained increasing interest in various applications, including speech processing.</span></p>
</div>
<div id="S6.SS5.p2" class="ltx_para">
<p id="S6.SS5.p2.1" class="ltx_p"><span id="S6.SS5.p2.1.1" class="ltx_text" style="color:#000000;">Several studies have explored the interpretability of </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS5.p2.1.2" class="ltx_text" style="color:#000000;"> models. In one study </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS5.p2.1.3.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">ramakrishnan2016towards</span><span id="S6.SS5.p2.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS5.p2.1.5" class="ltx_text" style="color:#000000;">, an agent was designed to explain how it learns a new task using prior common knowledge, aiming to enhance users’ trust and acceptance of the system results. Another study </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS5.p2.1.6.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2019the</span><span id="S6.SS5.p2.1.7.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS5.p2.1.8" class="ltx_text" style="color:#000000;"> defined interpretable features in a </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS5.p2.1.9" class="ltx_text" style="color:#000000;"> algorithm and examined the relationship between the </span><a href="#Sx1.40.40.40"><abbr href="#Sx1.40.40.40" title="source domain" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SD</span></span></abbr></a><span id="S6.SS5.p2.1.10" class="ltx_text" style="color:#000000;"> and TD in the task, focusing on the interpretability of the pretrained </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS5.p2.1.11" class="ltx_text" style="color:#000000;"> model.</span></p>
</div>
<div id="S6.SS5.p3" class="ltx_para">
<p id="S6.SS5.p3.1" class="ltx_p"><span id="S6.SS5.p3.1.1" class="ltx_text" style="color:#000000;">The work by Lee et al. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS5.p3.1.2.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">lee2021interpretable</span><span id="S6.SS5.p3.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS5.p3.1.4" class="ltx_text" style="color:#000000;"> introduced a knowledge distillation approach that generated interpretable embedding procedure (IEP) knowledge based on PCA and transferred it to the student network using a message passing neural network. This approach enhanced interpretability while maintaining accuracy through multi-task learning. Additionally, Carr et al. proposed an interpretable staged TL (iSTL) scheme for accurate and explainable classification of optical coherence tomography (OCT) scans with a small sample size </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS5.p3.1.5.1" class="ltx_text" style="color:#000000;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">carr2021interpretable</span><span id="S6.SS5.p3.1.6.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS5.p3.1.7" class="ltx_text" style="color:#000000;">. iSTL outperformed </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS5.p3.1.8" class="ltx_text" style="color:#000000;"> techniques on unseen data, utilizing clinical features for predictions with interpretable attention maps.</span></p>
</div>
<div id="S6.SS5.p4" class="ltx_para">
<p id="S6.SS5.p4.1" class="ltx_p"><span id="S6.SS5.p4.1.1" class="ltx_text" style="color:#000000;">Delving deeper into techniques for FL distillation (optimizing model size) within </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S6.SS5.p4.1.2" class="ltx_text" style="color:#000000;"> frameworks is essential. This exploration involves researching methods to compress neural </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS5.p4.1.3" class="ltx_text" style="color:#000000;"> models effectively while ensuring their performance remains intact, especially tailored for edge devices with storage and computational constraints. It is imperative to investigate the trade-offs associated with reducing model size while maintaining performance metrics like </span><a href="#Sx1.52.52.52"><abbr href="#Sx1.52.52.52" title="word error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">WER</span></span></abbr></a><span id="S6.SS5.p4.1.4" class="ltx_text" style="color:#000000;">. Developing strategies to strike a balance between downsizing models and preserving satisfactory performance levels within federated learning environments is crucial.</span></p>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.6 </span>Recent RL techniques for <a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a>
</h3>

<div id="S6.SS6.p1" class="ltx_para">
<p id="S6.SS6.p1.1" class="ltx_p"><span id="S6.SS6.p1.1.1" class="ltx_text" style="color:#000000;">Exploring incremental </span><a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a><span id="S6.SS6.p1.1.2" class="ltx_text" style="color:#000000;"> approaches </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS6.p1.1.3.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib136" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">136</span></a>, <a href="#bib.bib137" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">137</span></a>, <a href="#bib.bib138" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">138</span></a><span id="S6.SS6.p1.1.4.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS6.p1.1.5" class="ltx_text" style="color:#000000;"> in DRL-based </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS6.p1.1.6" class="ltx_text" style="color:#000000;"> systems, could be very interesting. This approach involves the model continuously learning from newly acquired data and dynamically adjusting its ASR functionalities over time. By incrementally updating its knowledge base, the model can enhance its performance without necessitating full retraining, thus enabling continual enhancement of </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS6.p1.1.7" class="ltx_text" style="color:#000000;"> systems. This capability not only fosters greater resilience and adaptability in speech recognition capabilities but also offers potential applications in scenarios where real-time adaptation to changing conditions is crucial, such as in noisy environments or with varying speaker accents. Moreover, incremental RL can potentially lead to more efficient use of computational resources, as the model only needs to focus on learning from new data, rather than reprocessing the entire dataset. Further research in this area could unlock new possibilities for </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS6.p1.1.8" class="ltx_text" style="color:#000000;"> systems to evolve and improve over time, ultimately enhancing their usability and effectiveness in diverse real-world settings.</span></p>
</div>
<div id="S6.SS6.p2" class="ltx_para">
<p id="S6.SS6.p2.1" class="ltx_p"><span id="S6.SS6.p2.1.1" class="ltx_text" style="color:#000000;">Although some ASR schemes based on RL have been proposed, there remains a notable scarcity in the application of RL techniques to enhance ASR methods. While policy gradient and Q-learning are commonly employed, the realm of RL encompasses various subcategories such as  </span><a href="#Sx1.59.59.59"><span href="#Sx1.59.59.59" title="double deep Q-network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">double deep Q-network</span></span></span></a><span id="S6.SS6.p2.1.2" class="ltx_text" style="color:#000000;"> (</span><a href="#Sx1.59.59.59"><abbr href="#Sx1.59.59.59" title="double deep Q-network" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DDQN</span></span></abbr></a><span id="S6.SS6.p2.1.3" class="ltx_text" style="color:#000000;">),  </span><a href="#Sx1.60.60.60"><span href="#Sx1.60.60.60" title="actor-critic" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">actor-critic</span></span></span></a><span id="S6.SS6.p2.1.4" class="ltx_text" style="color:#000000;"> (</span><a href="#Sx1.60.60.60"><abbr href="#Sx1.60.60.60" title="actor-critic" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AC</span></span></abbr></a><span id="S6.SS6.p2.1.5" class="ltx_text" style="color:#000000;">),  </span><a href="#Sx1.62.62.62"><span href="#Sx1.62.62.62" title="deep deterministic policy gradien" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">deep deterministic policy gradien</span></span></span></a><span id="S6.SS6.p2.1.6" class="ltx_text" style="color:#000000;"> (</span><a href="#Sx1.62.62.62"><abbr href="#Sx1.62.62.62" title="deep deterministic policy gradien" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DDPG</span></span></abbr></a><span id="S6.SS6.p2.1.7" class="ltx_text" style="color:#000000;">), and more </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS6.p2.1.8.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib139" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">139</span></a><span id="S6.SS6.p2.1.9.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS6.p2.1.10" class="ltx_text" style="color:#000000;">, which hold promise for advancing ASR with innovative approaches. Researchers are encouraged to delve into these diverse DRL-based methods to further enrich the field of ASR for both </span><a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a><span id="S6.SS6.p2.1.11" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a><span id="S6.SS6.p2.1.12" class="ltx_text" style="color:#000000;"> fields.</span></p>
</div>
</section>
<section id="S6.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.7 </span>Online <a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a>
</h3>

<div id="S6.SS7.p1" class="ltx_para">
<p id="S6.SS7.p1.10" class="ltx_p"><span id="S6.SS7.p1.10.1" class="ltx_text" style="color:#000000;">Online DTL combines the principles of TL and online learning with deep neural networks, enabling models to adapt in real-time to new tasks or data distributions. This approach is beneficial in dynamic environments where data arrives sequentially. </span><a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a><span id="S6.SS7.p1.10.2" class="ltx_text" style="color:#000000;"> models, specifically Deep Neural Networks (DNNs), learn through optimizing the weights </span><math id="S6.SS7.p1.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S6.SS7.p1.1.m1.1a"><mi mathcolor="#000000" id="S6.SS7.p1.1.m1.1.1" xref="S6.SS7.p1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.1.m1.1b"><ci id="S6.SS7.p1.1.m1.1.1.cmml" xref="S6.SS7.p1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.1.m1.1c">\theta</annotation></semantics></math><span id="S6.SS7.p1.10.3" class="ltx_text" style="color:#000000;"> to minimize a loss function </span><math id="S6.SS7.p1.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S6.SS7.p1.2.m2.1a"><mi mathcolor="#000000" id="S6.SS7.p1.2.m2.1.1" xref="S6.SS7.p1.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.2.m2.1b"><ci id="S6.SS7.p1.2.m2.1.1.cmml" xref="S6.SS7.p1.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.2.m2.1c">L</annotation></semantics></math><span id="S6.SS7.p1.10.4" class="ltx_text" style="color:#000000;">, which measures the discrepancy between predicted outputs </span><math id="S6.SS7.p1.3.m3.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="S6.SS7.p1.3.m3.1a"><mover accent="true" id="S6.SS7.p1.3.m3.1.1" xref="S6.SS7.p1.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.3.m3.1.1.2" xref="S6.SS7.p1.3.m3.1.1.2.cmml">y</mi><mo mathcolor="#000000" id="S6.SS7.p1.3.m3.1.1.1" xref="S6.SS7.p1.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.3.m3.1b"><apply id="S6.SS7.p1.3.m3.1.1.cmml" xref="S6.SS7.p1.3.m3.1.1"><ci id="S6.SS7.p1.3.m3.1.1.1.cmml" xref="S6.SS7.p1.3.m3.1.1.1">^</ci><ci id="S6.SS7.p1.3.m3.1.1.2.cmml" xref="S6.SS7.p1.3.m3.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.3.m3.1c">\hat{y}</annotation></semantics></math><span id="S6.SS7.p1.10.5" class="ltx_text" style="color:#000000;"> and true outputs </span><math id="S6.SS7.p1.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S6.SS7.p1.4.m4.1a"><mi mathcolor="#000000" id="S6.SS7.p1.4.m4.1.1" xref="S6.SS7.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.4.m4.1b"><ci id="S6.SS7.p1.4.m4.1.1.cmml" xref="S6.SS7.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.4.m4.1c">y</annotation></semantics></math><span id="S6.SS7.p1.10.6" class="ltx_text" style="color:#000000;">: </span><math id="S6.SS7.p1.5.m5.2" class="ltx_Math" alttext="\theta^{*}=\arg\min_{\theta}L(D;\theta)" display="inline"><semantics id="S6.SS7.p1.5.m5.2a"><mrow id="S6.SS7.p1.5.m5.2.3" xref="S6.SS7.p1.5.m5.2.3.cmml"><msup id="S6.SS7.p1.5.m5.2.3.2" xref="S6.SS7.p1.5.m5.2.3.2.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.5.m5.2.3.2.2" xref="S6.SS7.p1.5.m5.2.3.2.2.cmml">θ</mi><mo mathcolor="#000000" id="S6.SS7.p1.5.m5.2.3.2.3" xref="S6.SS7.p1.5.m5.2.3.2.3.cmml">∗</mo></msup><mo mathcolor="#000000" id="S6.SS7.p1.5.m5.2.3.1" xref="S6.SS7.p1.5.m5.2.3.1.cmml">=</mo><mrow id="S6.SS7.p1.5.m5.2.3.3" xref="S6.SS7.p1.5.m5.2.3.3.cmml"><mrow id="S6.SS7.p1.5.m5.2.3.3.2" xref="S6.SS7.p1.5.m5.2.3.3.2.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.5.m5.2.3.3.2.1" xref="S6.SS7.p1.5.m5.2.3.3.2.1.cmml">arg</mi><mo lspace="0.167em" id="S6.SS7.p1.5.m5.2.3.3.2a" xref="S6.SS7.p1.5.m5.2.3.3.2.cmml">⁡</mo><mrow id="S6.SS7.p1.5.m5.2.3.3.2.2" xref="S6.SS7.p1.5.m5.2.3.3.2.2.cmml"><msub id="S6.SS7.p1.5.m5.2.3.3.2.2.1" xref="S6.SS7.p1.5.m5.2.3.3.2.2.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.5.m5.2.3.3.2.2.1.2" xref="S6.SS7.p1.5.m5.2.3.3.2.2.1.2.cmml">min</mi><mi mathcolor="#000000" id="S6.SS7.p1.5.m5.2.3.3.2.2.1.3" xref="S6.SS7.p1.5.m5.2.3.3.2.2.1.3.cmml">θ</mi></msub><mo lspace="0.167em" id="S6.SS7.p1.5.m5.2.3.3.2.2a" xref="S6.SS7.p1.5.m5.2.3.3.2.2.cmml">⁡</mo><mi mathcolor="#000000" id="S6.SS7.p1.5.m5.2.3.3.2.2.2" xref="S6.SS7.p1.5.m5.2.3.3.2.2.2.cmml">L</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S6.SS7.p1.5.m5.2.3.3.1" xref="S6.SS7.p1.5.m5.2.3.3.1.cmml">​</mo><mrow id="S6.SS7.p1.5.m5.2.3.3.3.2" xref="S6.SS7.p1.5.m5.2.3.3.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.SS7.p1.5.m5.2.3.3.3.2.1" xref="S6.SS7.p1.5.m5.2.3.3.3.1.cmml">(</mo><mi mathcolor="#000000" id="S6.SS7.p1.5.m5.1.1" xref="S6.SS7.p1.5.m5.1.1.cmml">D</mi><mo mathcolor="#000000" id="S6.SS7.p1.5.m5.2.3.3.3.2.2" xref="S6.SS7.p1.5.m5.2.3.3.3.1.cmml">;</mo><mi mathcolor="#000000" id="S6.SS7.p1.5.m5.2.2" xref="S6.SS7.p1.5.m5.2.2.cmml">θ</mi><mo mathcolor="#000000" stretchy="false" id="S6.SS7.p1.5.m5.2.3.3.3.2.3" xref="S6.SS7.p1.5.m5.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.5.m5.2b"><apply id="S6.SS7.p1.5.m5.2.3.cmml" xref="S6.SS7.p1.5.m5.2.3"><eq id="S6.SS7.p1.5.m5.2.3.1.cmml" xref="S6.SS7.p1.5.m5.2.3.1"></eq><apply id="S6.SS7.p1.5.m5.2.3.2.cmml" xref="S6.SS7.p1.5.m5.2.3.2"><csymbol cd="ambiguous" id="S6.SS7.p1.5.m5.2.3.2.1.cmml" xref="S6.SS7.p1.5.m5.2.3.2">superscript</csymbol><ci id="S6.SS7.p1.5.m5.2.3.2.2.cmml" xref="S6.SS7.p1.5.m5.2.3.2.2">𝜃</ci><times id="S6.SS7.p1.5.m5.2.3.2.3.cmml" xref="S6.SS7.p1.5.m5.2.3.2.3"></times></apply><apply id="S6.SS7.p1.5.m5.2.3.3.cmml" xref="S6.SS7.p1.5.m5.2.3.3"><times id="S6.SS7.p1.5.m5.2.3.3.1.cmml" xref="S6.SS7.p1.5.m5.2.3.3.1"></times><apply id="S6.SS7.p1.5.m5.2.3.3.2.cmml" xref="S6.SS7.p1.5.m5.2.3.3.2"><arg id="S6.SS7.p1.5.m5.2.3.3.2.1.cmml" xref="S6.SS7.p1.5.m5.2.3.3.2.1"></arg><apply id="S6.SS7.p1.5.m5.2.3.3.2.2.cmml" xref="S6.SS7.p1.5.m5.2.3.3.2.2"><apply id="S6.SS7.p1.5.m5.2.3.3.2.2.1.cmml" xref="S6.SS7.p1.5.m5.2.3.3.2.2.1"><csymbol cd="ambiguous" id="S6.SS7.p1.5.m5.2.3.3.2.2.1.1.cmml" xref="S6.SS7.p1.5.m5.2.3.3.2.2.1">subscript</csymbol><min id="S6.SS7.p1.5.m5.2.3.3.2.2.1.2.cmml" xref="S6.SS7.p1.5.m5.2.3.3.2.2.1.2"></min><ci id="S6.SS7.p1.5.m5.2.3.3.2.2.1.3.cmml" xref="S6.SS7.p1.5.m5.2.3.3.2.2.1.3">𝜃</ci></apply><ci id="S6.SS7.p1.5.m5.2.3.3.2.2.2.cmml" xref="S6.SS7.p1.5.m5.2.3.3.2.2.2">𝐿</ci></apply></apply><list id="S6.SS7.p1.5.m5.2.3.3.3.1.cmml" xref="S6.SS7.p1.5.m5.2.3.3.3.2"><ci id="S6.SS7.p1.5.m5.1.1.cmml" xref="S6.SS7.p1.5.m5.1.1">𝐷</ci><ci id="S6.SS7.p1.5.m5.2.2.cmml" xref="S6.SS7.p1.5.m5.2.2">𝜃</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.5.m5.2c">\theta^{*}=\arg\min_{\theta}L(D;\theta)</annotation></semantics></math><span id="S6.SS7.p1.10.7" class="ltx_text" style="color:#000000;">. On the other hand, TL improves learning in a new target task through the transfer of knowledge from a related source task, adapting a pre-trained model </span><math id="S6.SS7.p1.6.m6.1" class="ltx_Math" alttext="\theta_{S}" display="inline"><semantics id="S6.SS7.p1.6.m6.1a"><msub id="S6.SS7.p1.6.m6.1.1" xref="S6.SS7.p1.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.6.m6.1.1.2" xref="S6.SS7.p1.6.m6.1.1.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.SS7.p1.6.m6.1.1.3" xref="S6.SS7.p1.6.m6.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.6.m6.1b"><apply id="S6.SS7.p1.6.m6.1.1.cmml" xref="S6.SS7.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S6.SS7.p1.6.m6.1.1.1.cmml" xref="S6.SS7.p1.6.m6.1.1">subscript</csymbol><ci id="S6.SS7.p1.6.m6.1.1.2.cmml" xref="S6.SS7.p1.6.m6.1.1.2">𝜃</ci><ci id="S6.SS7.p1.6.m6.1.1.3.cmml" xref="S6.SS7.p1.6.m6.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.6.m6.1c">\theta_{S}</annotation></semantics></math><span id="S6.SS7.p1.10.8" class="ltx_text" style="color:#000000;"> on </span><math id="S6.SS7.p1.7.m7.1" class="ltx_Math" alttext="D_{S}" display="inline"><semantics id="S6.SS7.p1.7.m7.1a"><msub id="S6.SS7.p1.7.m7.1.1" xref="S6.SS7.p1.7.m7.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.7.m7.1.1.2" xref="S6.SS7.p1.7.m7.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS7.p1.7.m7.1.1.3" xref="S6.SS7.p1.7.m7.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.7.m7.1b"><apply id="S6.SS7.p1.7.m7.1.1.cmml" xref="S6.SS7.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S6.SS7.p1.7.m7.1.1.1.cmml" xref="S6.SS7.p1.7.m7.1.1">subscript</csymbol><ci id="S6.SS7.p1.7.m7.1.1.2.cmml" xref="S6.SS7.p1.7.m7.1.1.2">𝐷</ci><ci id="S6.SS7.p1.7.m7.1.1.3.cmml" xref="S6.SS7.p1.7.m7.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.7.m7.1c">D_{S}</annotation></semantics></math><span id="S6.SS7.p1.10.9" class="ltx_text" style="color:#000000;"> to a </span><math id="S6.SS7.p1.8.m8.1" class="ltx_Math" alttext="D_{T}" display="inline"><semantics id="S6.SS7.p1.8.m8.1a"><msub id="S6.SS7.p1.8.m8.1.1" xref="S6.SS7.p1.8.m8.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.8.m8.1.1.2" xref="S6.SS7.p1.8.m8.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS7.p1.8.m8.1.1.3" xref="S6.SS7.p1.8.m8.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.8.m8.1b"><apply id="S6.SS7.p1.8.m8.1.1.cmml" xref="S6.SS7.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S6.SS7.p1.8.m8.1.1.1.cmml" xref="S6.SS7.p1.8.m8.1.1">subscript</csymbol><ci id="S6.SS7.p1.8.m8.1.1.2.cmml" xref="S6.SS7.p1.8.m8.1.1.2">𝐷</ci><ci id="S6.SS7.p1.8.m8.1.1.3.cmml" xref="S6.SS7.p1.8.m8.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.8.m8.1c">D_{T}</annotation></semantics></math><span id="S6.SS7.p1.10.10" class="ltx_text" style="color:#000000;">: </span><math id="S6.SS7.p1.9.m9.2" class="ltx_Math" alttext="\theta_{T}^{*}=\arg\min_{\theta}L(D_{T};\theta_{T})" display="inline"><semantics id="S6.SS7.p1.9.m9.2a"><mrow id="S6.SS7.p1.9.m9.2.2" xref="S6.SS7.p1.9.m9.2.2.cmml"><msubsup id="S6.SS7.p1.9.m9.2.2.4" xref="S6.SS7.p1.9.m9.2.2.4.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.4.2.2" xref="S6.SS7.p1.9.m9.2.2.4.2.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.4.2.3" xref="S6.SS7.p1.9.m9.2.2.4.2.3.cmml">T</mi><mo mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.4.3" xref="S6.SS7.p1.9.m9.2.2.4.3.cmml">∗</mo></msubsup><mo mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.3" xref="S6.SS7.p1.9.m9.2.2.3.cmml">=</mo><mrow id="S6.SS7.p1.9.m9.2.2.2" xref="S6.SS7.p1.9.m9.2.2.2.cmml"><mrow id="S6.SS7.p1.9.m9.2.2.2.4" xref="S6.SS7.p1.9.m9.2.2.2.4.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.2.4.1" xref="S6.SS7.p1.9.m9.2.2.2.4.1.cmml">arg</mi><mo lspace="0.167em" id="S6.SS7.p1.9.m9.2.2.2.4a" xref="S6.SS7.p1.9.m9.2.2.2.4.cmml">⁡</mo><mrow id="S6.SS7.p1.9.m9.2.2.2.4.2" xref="S6.SS7.p1.9.m9.2.2.2.4.2.cmml"><msub id="S6.SS7.p1.9.m9.2.2.2.4.2.1" xref="S6.SS7.p1.9.m9.2.2.2.4.2.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.2.4.2.1.2" xref="S6.SS7.p1.9.m9.2.2.2.4.2.1.2.cmml">min</mi><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.2.4.2.1.3" xref="S6.SS7.p1.9.m9.2.2.2.4.2.1.3.cmml">θ</mi></msub><mo lspace="0.167em" id="S6.SS7.p1.9.m9.2.2.2.4.2a" xref="S6.SS7.p1.9.m9.2.2.2.4.2.cmml">⁡</mo><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.2.4.2.2" xref="S6.SS7.p1.9.m9.2.2.2.4.2.2.cmml">L</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S6.SS7.p1.9.m9.2.2.2.3" xref="S6.SS7.p1.9.m9.2.2.2.3.cmml">​</mo><mrow id="S6.SS7.p1.9.m9.2.2.2.2.2" xref="S6.SS7.p1.9.m9.2.2.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.SS7.p1.9.m9.2.2.2.2.2.3" xref="S6.SS7.p1.9.m9.2.2.2.2.3.cmml">(</mo><msub id="S6.SS7.p1.9.m9.1.1.1.1.1.1" xref="S6.SS7.p1.9.m9.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.1.1.1.1.1.1.2" xref="S6.SS7.p1.9.m9.1.1.1.1.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.1.1.1.1.1.1.3" xref="S6.SS7.p1.9.m9.1.1.1.1.1.1.3.cmml">T</mi></msub><mo mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.2.2.2.4" xref="S6.SS7.p1.9.m9.2.2.2.2.3.cmml">;</mo><msub id="S6.SS7.p1.9.m9.2.2.2.2.2.2" xref="S6.SS7.p1.9.m9.2.2.2.2.2.2.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.2.2.2.2.2" xref="S6.SS7.p1.9.m9.2.2.2.2.2.2.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.SS7.p1.9.m9.2.2.2.2.2.2.3" xref="S6.SS7.p1.9.m9.2.2.2.2.2.2.3.cmml">T</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.SS7.p1.9.m9.2.2.2.2.2.5" xref="S6.SS7.p1.9.m9.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.9.m9.2b"><apply id="S6.SS7.p1.9.m9.2.2.cmml" xref="S6.SS7.p1.9.m9.2.2"><eq id="S6.SS7.p1.9.m9.2.2.3.cmml" xref="S6.SS7.p1.9.m9.2.2.3"></eq><apply id="S6.SS7.p1.9.m9.2.2.4.cmml" xref="S6.SS7.p1.9.m9.2.2.4"><csymbol cd="ambiguous" id="S6.SS7.p1.9.m9.2.2.4.1.cmml" xref="S6.SS7.p1.9.m9.2.2.4">superscript</csymbol><apply id="S6.SS7.p1.9.m9.2.2.4.2.cmml" xref="S6.SS7.p1.9.m9.2.2.4"><csymbol cd="ambiguous" id="S6.SS7.p1.9.m9.2.2.4.2.1.cmml" xref="S6.SS7.p1.9.m9.2.2.4">subscript</csymbol><ci id="S6.SS7.p1.9.m9.2.2.4.2.2.cmml" xref="S6.SS7.p1.9.m9.2.2.4.2.2">𝜃</ci><ci id="S6.SS7.p1.9.m9.2.2.4.2.3.cmml" xref="S6.SS7.p1.9.m9.2.2.4.2.3">𝑇</ci></apply><times id="S6.SS7.p1.9.m9.2.2.4.3.cmml" xref="S6.SS7.p1.9.m9.2.2.4.3"></times></apply><apply id="S6.SS7.p1.9.m9.2.2.2.cmml" xref="S6.SS7.p1.9.m9.2.2.2"><times id="S6.SS7.p1.9.m9.2.2.2.3.cmml" xref="S6.SS7.p1.9.m9.2.2.2.3"></times><apply id="S6.SS7.p1.9.m9.2.2.2.4.cmml" xref="S6.SS7.p1.9.m9.2.2.2.4"><arg id="S6.SS7.p1.9.m9.2.2.2.4.1.cmml" xref="S6.SS7.p1.9.m9.2.2.2.4.1"></arg><apply id="S6.SS7.p1.9.m9.2.2.2.4.2.cmml" xref="S6.SS7.p1.9.m9.2.2.2.4.2"><apply id="S6.SS7.p1.9.m9.2.2.2.4.2.1.cmml" xref="S6.SS7.p1.9.m9.2.2.2.4.2.1"><csymbol cd="ambiguous" id="S6.SS7.p1.9.m9.2.2.2.4.2.1.1.cmml" xref="S6.SS7.p1.9.m9.2.2.2.4.2.1">subscript</csymbol><min id="S6.SS7.p1.9.m9.2.2.2.4.2.1.2.cmml" xref="S6.SS7.p1.9.m9.2.2.2.4.2.1.2"></min><ci id="S6.SS7.p1.9.m9.2.2.2.4.2.1.3.cmml" xref="S6.SS7.p1.9.m9.2.2.2.4.2.1.3">𝜃</ci></apply><ci id="S6.SS7.p1.9.m9.2.2.2.4.2.2.cmml" xref="S6.SS7.p1.9.m9.2.2.2.4.2.2">𝐿</ci></apply></apply><list id="S6.SS7.p1.9.m9.2.2.2.2.3.cmml" xref="S6.SS7.p1.9.m9.2.2.2.2.2"><apply id="S6.SS7.p1.9.m9.1.1.1.1.1.1.cmml" xref="S6.SS7.p1.9.m9.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS7.p1.9.m9.1.1.1.1.1.1.1.cmml" xref="S6.SS7.p1.9.m9.1.1.1.1.1.1">subscript</csymbol><ci id="S6.SS7.p1.9.m9.1.1.1.1.1.1.2.cmml" xref="S6.SS7.p1.9.m9.1.1.1.1.1.1.2">𝐷</ci><ci id="S6.SS7.p1.9.m9.1.1.1.1.1.1.3.cmml" xref="S6.SS7.p1.9.m9.1.1.1.1.1.1.3">𝑇</ci></apply><apply id="S6.SS7.p1.9.m9.2.2.2.2.2.2.cmml" xref="S6.SS7.p1.9.m9.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S6.SS7.p1.9.m9.2.2.2.2.2.2.1.cmml" xref="S6.SS7.p1.9.m9.2.2.2.2.2.2">subscript</csymbol><ci id="S6.SS7.p1.9.m9.2.2.2.2.2.2.2.cmml" xref="S6.SS7.p1.9.m9.2.2.2.2.2.2.2">𝜃</ci><ci id="S6.SS7.p1.9.m9.2.2.2.2.2.2.3.cmml" xref="S6.SS7.p1.9.m9.2.2.2.2.2.2.3">𝑇</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.9.m9.2c">\theta_{T}^{*}=\arg\min_{\theta}L(D_{T};\theta_{T})</annotation></semantics></math><span id="S6.SS7.p1.10.11" class="ltx_text" style="color:#000000;">. In this regard, online learning updates the model incrementally as new data </span><math id="S6.SS7.p1.10.m10.2" class="ltx_Math" alttext="(x_{t},y_{t})" display="inline"><semantics id="S6.SS7.p1.10.m10.2a"><mrow id="S6.SS7.p1.10.m10.2.2.2" xref="S6.SS7.p1.10.m10.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.SS7.p1.10.m10.2.2.2.3" xref="S6.SS7.p1.10.m10.2.2.3.cmml">(</mo><msub id="S6.SS7.p1.10.m10.1.1.1.1" xref="S6.SS7.p1.10.m10.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.10.m10.1.1.1.1.2" xref="S6.SS7.p1.10.m10.1.1.1.1.2.cmml">x</mi><mi mathcolor="#000000" id="S6.SS7.p1.10.m10.1.1.1.1.3" xref="S6.SS7.p1.10.m10.1.1.1.1.3.cmml">t</mi></msub><mo mathcolor="#000000" id="S6.SS7.p1.10.m10.2.2.2.4" xref="S6.SS7.p1.10.m10.2.2.3.cmml">,</mo><msub id="S6.SS7.p1.10.m10.2.2.2.2" xref="S6.SS7.p1.10.m10.2.2.2.2.cmml"><mi mathcolor="#000000" id="S6.SS7.p1.10.m10.2.2.2.2.2" xref="S6.SS7.p1.10.m10.2.2.2.2.2.cmml">y</mi><mi mathcolor="#000000" id="S6.SS7.p1.10.m10.2.2.2.2.3" xref="S6.SS7.p1.10.m10.2.2.2.2.3.cmml">t</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.SS7.p1.10.m10.2.2.2.5" xref="S6.SS7.p1.10.m10.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS7.p1.10.m10.2b"><interval closure="open" id="S6.SS7.p1.10.m10.2.2.3.cmml" xref="S6.SS7.p1.10.m10.2.2.2"><apply id="S6.SS7.p1.10.m10.1.1.1.1.cmml" xref="S6.SS7.p1.10.m10.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS7.p1.10.m10.1.1.1.1.1.cmml" xref="S6.SS7.p1.10.m10.1.1.1.1">subscript</csymbol><ci id="S6.SS7.p1.10.m10.1.1.1.1.2.cmml" xref="S6.SS7.p1.10.m10.1.1.1.1.2">𝑥</ci><ci id="S6.SS7.p1.10.m10.1.1.1.1.3.cmml" xref="S6.SS7.p1.10.m10.1.1.1.1.3">𝑡</ci></apply><apply id="S6.SS7.p1.10.m10.2.2.2.2.cmml" xref="S6.SS7.p1.10.m10.2.2.2.2"><csymbol cd="ambiguous" id="S6.SS7.p1.10.m10.2.2.2.2.1.cmml" xref="S6.SS7.p1.10.m10.2.2.2.2">subscript</csymbol><ci id="S6.SS7.p1.10.m10.2.2.2.2.2.cmml" xref="S6.SS7.p1.10.m10.2.2.2.2.2">𝑦</ci><ci id="S6.SS7.p1.10.m10.2.2.2.2.3.cmml" xref="S6.SS7.p1.10.m10.2.2.2.2.3">𝑡</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p1.10.m10.2c">(x_{t},y_{t})</annotation></semantics></math><span id="S6.SS7.p1.10.12" class="ltx_text" style="color:#000000;"> arrives:</span></p>
</div>
<div id="S6.SS7.p2" class="ltx_para">
<table id="S6.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S6.E11.m1.2" class="ltx_Math" alttext="\theta_{t+1}=\theta_{t}-\alpha_{t}\nabla_{\theta}L(y_{t},f(x_{t};\theta_{t}))" display="block"><semantics id="S6.E11.m1.2a"><mrow id="S6.E11.m1.2.2" xref="S6.E11.m1.2.2.cmml"><msub id="S6.E11.m1.2.2.4" xref="S6.E11.m1.2.2.4.cmml"><mi mathcolor="#000000" id="S6.E11.m1.2.2.4.2" xref="S6.E11.m1.2.2.4.2.cmml">θ</mi><mrow id="S6.E11.m1.2.2.4.3" xref="S6.E11.m1.2.2.4.3.cmml"><mi mathcolor="#000000" id="S6.E11.m1.2.2.4.3.2" xref="S6.E11.m1.2.2.4.3.2.cmml">t</mi><mo mathcolor="#000000" id="S6.E11.m1.2.2.4.3.1" xref="S6.E11.m1.2.2.4.3.1.cmml">+</mo><mn mathcolor="#000000" id="S6.E11.m1.2.2.4.3.3" xref="S6.E11.m1.2.2.4.3.3.cmml">1</mn></mrow></msub><mo mathcolor="#000000" id="S6.E11.m1.2.2.3" xref="S6.E11.m1.2.2.3.cmml">=</mo><mrow id="S6.E11.m1.2.2.2" xref="S6.E11.m1.2.2.2.cmml"><msub id="S6.E11.m1.2.2.2.4" xref="S6.E11.m1.2.2.2.4.cmml"><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.4.2" xref="S6.E11.m1.2.2.2.4.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.4.3" xref="S6.E11.m1.2.2.2.4.3.cmml">t</mi></msub><mo mathcolor="#000000" id="S6.E11.m1.2.2.2.3" xref="S6.E11.m1.2.2.2.3.cmml">−</mo><mrow id="S6.E11.m1.2.2.2.2" xref="S6.E11.m1.2.2.2.2.cmml"><msub id="S6.E11.m1.2.2.2.2.4" xref="S6.E11.m1.2.2.2.2.4.cmml"><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.4.2" xref="S6.E11.m1.2.2.2.2.4.2.cmml">α</mi><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.4.3" xref="S6.E11.m1.2.2.2.2.4.3.cmml">t</mi></msub><mo lspace="0.167em" rspace="0em" id="S6.E11.m1.2.2.2.2.3" xref="S6.E11.m1.2.2.2.2.3.cmml">​</mo><mrow id="S6.E11.m1.2.2.2.2.5" xref="S6.E11.m1.2.2.2.2.5.cmml"><msub id="S6.E11.m1.2.2.2.2.5.1" xref="S6.E11.m1.2.2.2.2.5.1.cmml"><mo mathcolor="#000000" rspace="0.167em" id="S6.E11.m1.2.2.2.2.5.1.2" xref="S6.E11.m1.2.2.2.2.5.1.2.cmml">∇</mo><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.5.1.3" xref="S6.E11.m1.2.2.2.2.5.1.3.cmml">θ</mi></msub><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.5.2" xref="S6.E11.m1.2.2.2.2.5.2.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S6.E11.m1.2.2.2.2.3a" xref="S6.E11.m1.2.2.2.2.3.cmml">​</mo><mrow id="S6.E11.m1.2.2.2.2.2.2" xref="S6.E11.m1.2.2.2.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E11.m1.2.2.2.2.2.2.3" xref="S6.E11.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S6.E11.m1.1.1.1.1.1.1.1" xref="S6.E11.m1.1.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E11.m1.1.1.1.1.1.1.1.2" xref="S6.E11.m1.1.1.1.1.1.1.1.2.cmml">y</mi><mi mathcolor="#000000" id="S6.E11.m1.1.1.1.1.1.1.1.3" xref="S6.E11.m1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo mathcolor="#000000" id="S6.E11.m1.2.2.2.2.2.2.4" xref="S6.E11.m1.2.2.2.2.2.3.cmml">,</mo><mrow id="S6.E11.m1.2.2.2.2.2.2.2" xref="S6.E11.m1.2.2.2.2.2.2.2.cmml"><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.2.2.2.4" xref="S6.E11.m1.2.2.2.2.2.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S6.E11.m1.2.2.2.2.2.2.2.3" xref="S6.E11.m1.2.2.2.2.2.2.2.3.cmml">​</mo><mrow id="S6.E11.m1.2.2.2.2.2.2.2.2.2" xref="S6.E11.m1.2.2.2.2.2.2.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.E11.m1.2.2.2.2.2.2.2.2.2.3" xref="S6.E11.m1.2.2.2.2.2.2.2.2.3.cmml">(</mo><msub id="S6.E11.m1.2.2.2.2.2.2.2.1.1.1" xref="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.cmml"><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.2" xref="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.2.cmml">x</mi><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.3" xref="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.3.cmml">t</mi></msub><mo mathcolor="#000000" id="S6.E11.m1.2.2.2.2.2.2.2.2.2.4" xref="S6.E11.m1.2.2.2.2.2.2.2.2.3.cmml">;</mo><msub id="S6.E11.m1.2.2.2.2.2.2.2.2.2.2" xref="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.cmml"><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.2" xref="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.2.cmml">θ</mi><mi mathcolor="#000000" id="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.3" xref="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.3.cmml">t</mi></msub><mo mathcolor="#000000" stretchy="false" id="S6.E11.m1.2.2.2.2.2.2.2.2.2.5" xref="S6.E11.m1.2.2.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S6.E11.m1.2.2.2.2.2.2.5" xref="S6.E11.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E11.m1.2b"><apply id="S6.E11.m1.2.2.cmml" xref="S6.E11.m1.2.2"><eq id="S6.E11.m1.2.2.3.cmml" xref="S6.E11.m1.2.2.3"></eq><apply id="S6.E11.m1.2.2.4.cmml" xref="S6.E11.m1.2.2.4"><csymbol cd="ambiguous" id="S6.E11.m1.2.2.4.1.cmml" xref="S6.E11.m1.2.2.4">subscript</csymbol><ci id="S6.E11.m1.2.2.4.2.cmml" xref="S6.E11.m1.2.2.4.2">𝜃</ci><apply id="S6.E11.m1.2.2.4.3.cmml" xref="S6.E11.m1.2.2.4.3"><plus id="S6.E11.m1.2.2.4.3.1.cmml" xref="S6.E11.m1.2.2.4.3.1"></plus><ci id="S6.E11.m1.2.2.4.3.2.cmml" xref="S6.E11.m1.2.2.4.3.2">𝑡</ci><cn type="integer" id="S6.E11.m1.2.2.4.3.3.cmml" xref="S6.E11.m1.2.2.4.3.3">1</cn></apply></apply><apply id="S6.E11.m1.2.2.2.cmml" xref="S6.E11.m1.2.2.2"><minus id="S6.E11.m1.2.2.2.3.cmml" xref="S6.E11.m1.2.2.2.3"></minus><apply id="S6.E11.m1.2.2.2.4.cmml" xref="S6.E11.m1.2.2.2.4"><csymbol cd="ambiguous" id="S6.E11.m1.2.2.2.4.1.cmml" xref="S6.E11.m1.2.2.2.4">subscript</csymbol><ci id="S6.E11.m1.2.2.2.4.2.cmml" xref="S6.E11.m1.2.2.2.4.2">𝜃</ci><ci id="S6.E11.m1.2.2.2.4.3.cmml" xref="S6.E11.m1.2.2.2.4.3">𝑡</ci></apply><apply id="S6.E11.m1.2.2.2.2.cmml" xref="S6.E11.m1.2.2.2.2"><times id="S6.E11.m1.2.2.2.2.3.cmml" xref="S6.E11.m1.2.2.2.2.3"></times><apply id="S6.E11.m1.2.2.2.2.4.cmml" xref="S6.E11.m1.2.2.2.2.4"><csymbol cd="ambiguous" id="S6.E11.m1.2.2.2.2.4.1.cmml" xref="S6.E11.m1.2.2.2.2.4">subscript</csymbol><ci id="S6.E11.m1.2.2.2.2.4.2.cmml" xref="S6.E11.m1.2.2.2.2.4.2">𝛼</ci><ci id="S6.E11.m1.2.2.2.2.4.3.cmml" xref="S6.E11.m1.2.2.2.2.4.3">𝑡</ci></apply><apply id="S6.E11.m1.2.2.2.2.5.cmml" xref="S6.E11.m1.2.2.2.2.5"><apply id="S6.E11.m1.2.2.2.2.5.1.cmml" xref="S6.E11.m1.2.2.2.2.5.1"><csymbol cd="ambiguous" id="S6.E11.m1.2.2.2.2.5.1.1.cmml" xref="S6.E11.m1.2.2.2.2.5.1">subscript</csymbol><ci id="S6.E11.m1.2.2.2.2.5.1.2.cmml" xref="S6.E11.m1.2.2.2.2.5.1.2">∇</ci><ci id="S6.E11.m1.2.2.2.2.5.1.3.cmml" xref="S6.E11.m1.2.2.2.2.5.1.3">𝜃</ci></apply><ci id="S6.E11.m1.2.2.2.2.5.2.cmml" xref="S6.E11.m1.2.2.2.2.5.2">𝐿</ci></apply><interval closure="open" id="S6.E11.m1.2.2.2.2.2.3.cmml" xref="S6.E11.m1.2.2.2.2.2.2"><apply id="S6.E11.m1.1.1.1.1.1.1.1.cmml" xref="S6.E11.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.E11.m1.1.1.1.1.1.1.1.1.cmml" xref="S6.E11.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S6.E11.m1.1.1.1.1.1.1.1.2.cmml" xref="S6.E11.m1.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S6.E11.m1.1.1.1.1.1.1.1.3.cmml" xref="S6.E11.m1.1.1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S6.E11.m1.2.2.2.2.2.2.2.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2"><times id="S6.E11.m1.2.2.2.2.2.2.2.3.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.3"></times><ci id="S6.E11.m1.2.2.2.2.2.2.2.4.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.4">𝑓</ci><list id="S6.E11.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.2.2"><apply id="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.1.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.1.1.1">subscript</csymbol><ci id="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.2.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.2">𝑥</ci><ci id="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.3.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.1.1.1.3">𝑡</ci></apply><apply id="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.1.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.2.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.2">𝜃</ci><ci id="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.3.cmml" xref="S6.E11.m1.2.2.2.2.2.2.2.2.2.2.3">𝑡</ci></apply></list></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E11.m1.2c">\theta_{t+1}=\theta_{t}-\alpha_{t}\nabla_{\theta}L(y_{t},f(x_{t};\theta_{t}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
</div>
<div id="S6.SS7.p3" class="ltx_para ltx_noindent">
<p id="S6.SS7.p3.7" class="ltx_p"><span id="S6.SS7.p3.7.1" class="ltx_text" style="color:#000000;">Where </span><math id="S6.SS7.p3.1.m1.1" class="ltx_Math" alttext="\alpha_{t}" display="inline"><semantics id="S6.SS7.p3.1.m1.1a"><msub id="S6.SS7.p3.1.m1.1.1" xref="S6.SS7.p3.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.1.m1.1.1.2" xref="S6.SS7.p3.1.m1.1.1.2.cmml">α</mi><mi mathcolor="#000000" id="S6.SS7.p3.1.m1.1.1.3" xref="S6.SS7.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p3.1.m1.1b"><apply id="S6.SS7.p3.1.m1.1.1.cmml" xref="S6.SS7.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S6.SS7.p3.1.m1.1.1.1.cmml" xref="S6.SS7.p3.1.m1.1.1">subscript</csymbol><ci id="S6.SS7.p3.1.m1.1.1.2.cmml" xref="S6.SS7.p3.1.m1.1.1.2">𝛼</ci><ci id="S6.SS7.p3.1.m1.1.1.3.cmml" xref="S6.SS7.p3.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p3.1.m1.1c">\alpha_{t}</annotation></semantics></math><span id="S6.SS7.p3.7.2" class="ltx_text" style="color:#000000;"> is the learning rate, and </span><math id="S6.SS7.p3.2.m2.1" class="ltx_Math" alttext="\nabla_{\theta}L" display="inline"><semantics id="S6.SS7.p3.2.m2.1a"><mrow id="S6.SS7.p3.2.m2.1.1" xref="S6.SS7.p3.2.m2.1.1.cmml"><msub id="S6.SS7.p3.2.m2.1.1.1" xref="S6.SS7.p3.2.m2.1.1.1.cmml"><mo mathcolor="#000000" id="S6.SS7.p3.2.m2.1.1.1.2" xref="S6.SS7.p3.2.m2.1.1.1.2.cmml">∇</mo><mi mathcolor="#000000" id="S6.SS7.p3.2.m2.1.1.1.3" xref="S6.SS7.p3.2.m2.1.1.1.3.cmml">θ</mi></msub><mi mathcolor="#000000" id="S6.SS7.p3.2.m2.1.1.2" xref="S6.SS7.p3.2.m2.1.1.2.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.SS7.p3.2.m2.1b"><apply id="S6.SS7.p3.2.m2.1.1.cmml" xref="S6.SS7.p3.2.m2.1.1"><apply id="S6.SS7.p3.2.m2.1.1.1.cmml" xref="S6.SS7.p3.2.m2.1.1.1"><csymbol cd="ambiguous" id="S6.SS7.p3.2.m2.1.1.1.1.cmml" xref="S6.SS7.p3.2.m2.1.1.1">subscript</csymbol><ci id="S6.SS7.p3.2.m2.1.1.1.2.cmml" xref="S6.SS7.p3.2.m2.1.1.1.2">∇</ci><ci id="S6.SS7.p3.2.m2.1.1.1.3.cmml" xref="S6.SS7.p3.2.m2.1.1.1.3">𝜃</ci></apply><ci id="S6.SS7.p3.2.m2.1.1.2.cmml" xref="S6.SS7.p3.2.m2.1.1.2">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p3.2.m2.1c">\nabla_{\theta}L</annotation></semantics></math><span id="S6.SS7.p3.7.3" class="ltx_text" style="color:#000000;"> is the gradient of the loss with respect to </span><math id="S6.SS7.p3.3.m3.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S6.SS7.p3.3.m3.1a"><mi mathcolor="#000000" id="S6.SS7.p3.3.m3.1.1" xref="S6.SS7.p3.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S6.SS7.p3.3.m3.1b"><ci id="S6.SS7.p3.3.m3.1.1.cmml" xref="S6.SS7.p3.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p3.3.m3.1c">\theta</annotation></semantics></math><span id="S6.SS7.p3.7.4" class="ltx_text" style="color:#000000;">. Moving on, online TL integrates these concepts to continuously adapt a deep learning model to new tasks or data streams, often involving techniques such as feature extraction, fine-tuning, model adaptation, and continual learning. The adaptation process at each time step </span><math id="S6.SS7.p3.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S6.SS7.p3.4.m4.1a"><mi mathcolor="#000000" id="S6.SS7.p3.4.m4.1.1" xref="S6.SS7.p3.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S6.SS7.p3.4.m4.1b"><ci id="S6.SS7.p3.4.m4.1.1.cmml" xref="S6.SS7.p3.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p3.4.m4.1c">t</annotation></semantics></math><span id="S6.SS7.p3.7.5" class="ltx_text" style="color:#000000;"> can be viewed as </span><math id="S6.SS7.p3.5.m5.2" class="ltx_Math" alttext="\theta_{t+1}^{*}=\arg\min_{\theta}L(D_{T_{t}};\theta_{T_{t}})" display="inline"><semantics id="S6.SS7.p3.5.m5.2a"><mrow id="S6.SS7.p3.5.m5.2.2" xref="S6.SS7.p3.5.m5.2.2.cmml"><msubsup id="S6.SS7.p3.5.m5.2.2.4" xref="S6.SS7.p3.5.m5.2.2.4.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.4.2.2" xref="S6.SS7.p3.5.m5.2.2.4.2.2.cmml">θ</mi><mrow id="S6.SS7.p3.5.m5.2.2.4.2.3" xref="S6.SS7.p3.5.m5.2.2.4.2.3.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.4.2.3.2" xref="S6.SS7.p3.5.m5.2.2.4.2.3.2.cmml">t</mi><mo mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.4.2.3.1" xref="S6.SS7.p3.5.m5.2.2.4.2.3.1.cmml">+</mo><mn mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.4.2.3.3" xref="S6.SS7.p3.5.m5.2.2.4.2.3.3.cmml">1</mn></mrow><mo mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.4.3" xref="S6.SS7.p3.5.m5.2.2.4.3.cmml">∗</mo></msubsup><mo mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.3" xref="S6.SS7.p3.5.m5.2.2.3.cmml">=</mo><mrow id="S6.SS7.p3.5.m5.2.2.2" xref="S6.SS7.p3.5.m5.2.2.2.cmml"><mrow id="S6.SS7.p3.5.m5.2.2.2.4" xref="S6.SS7.p3.5.m5.2.2.2.4.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.2.4.1" xref="S6.SS7.p3.5.m5.2.2.2.4.1.cmml">arg</mi><mo lspace="0.167em" id="S6.SS7.p3.5.m5.2.2.2.4a" xref="S6.SS7.p3.5.m5.2.2.2.4.cmml">⁡</mo><mrow id="S6.SS7.p3.5.m5.2.2.2.4.2" xref="S6.SS7.p3.5.m5.2.2.2.4.2.cmml"><msub id="S6.SS7.p3.5.m5.2.2.2.4.2.1" xref="S6.SS7.p3.5.m5.2.2.2.4.2.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.2.4.2.1.2" xref="S6.SS7.p3.5.m5.2.2.2.4.2.1.2.cmml">min</mi><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.2.4.2.1.3" xref="S6.SS7.p3.5.m5.2.2.2.4.2.1.3.cmml">θ</mi></msub><mo lspace="0.167em" id="S6.SS7.p3.5.m5.2.2.2.4.2a" xref="S6.SS7.p3.5.m5.2.2.2.4.2.cmml">⁡</mo><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.2.4.2.2" xref="S6.SS7.p3.5.m5.2.2.2.4.2.2.cmml">L</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S6.SS7.p3.5.m5.2.2.2.3" xref="S6.SS7.p3.5.m5.2.2.2.3.cmml">​</mo><mrow id="S6.SS7.p3.5.m5.2.2.2.2.2" xref="S6.SS7.p3.5.m5.2.2.2.2.3.cmml"><mo mathcolor="#000000" stretchy="false" id="S6.SS7.p3.5.m5.2.2.2.2.2.3" xref="S6.SS7.p3.5.m5.2.2.2.2.3.cmml">(</mo><msub id="S6.SS7.p3.5.m5.1.1.1.1.1.1" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.1.1.1.1.1.1.2" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.2.cmml">D</mi><msub id="S6.SS7.p3.5.m5.1.1.1.1.1.1.3" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.2" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.2.cmml">T</mi><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.3" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.3.cmml">t</mi></msub></msub><mo mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.2.2.2.4" xref="S6.SS7.p3.5.m5.2.2.2.2.3.cmml">;</mo><msub id="S6.SS7.p3.5.m5.2.2.2.2.2.2" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.2.2.2.2.2" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.2.cmml">θ</mi><msub id="S6.SS7.p3.5.m5.2.2.2.2.2.2.3" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.2" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.2.cmml">T</mi><mi mathcolor="#000000" id="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.3" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.3.cmml">t</mi></msub></msub><mo mathcolor="#000000" stretchy="false" id="S6.SS7.p3.5.m5.2.2.2.2.2.5" xref="S6.SS7.p3.5.m5.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS7.p3.5.m5.2b"><apply id="S6.SS7.p3.5.m5.2.2.cmml" xref="S6.SS7.p3.5.m5.2.2"><eq id="S6.SS7.p3.5.m5.2.2.3.cmml" xref="S6.SS7.p3.5.m5.2.2.3"></eq><apply id="S6.SS7.p3.5.m5.2.2.4.cmml" xref="S6.SS7.p3.5.m5.2.2.4"><csymbol cd="ambiguous" id="S6.SS7.p3.5.m5.2.2.4.1.cmml" xref="S6.SS7.p3.5.m5.2.2.4">superscript</csymbol><apply id="S6.SS7.p3.5.m5.2.2.4.2.cmml" xref="S6.SS7.p3.5.m5.2.2.4"><csymbol cd="ambiguous" id="S6.SS7.p3.5.m5.2.2.4.2.1.cmml" xref="S6.SS7.p3.5.m5.2.2.4">subscript</csymbol><ci id="S6.SS7.p3.5.m5.2.2.4.2.2.cmml" xref="S6.SS7.p3.5.m5.2.2.4.2.2">𝜃</ci><apply id="S6.SS7.p3.5.m5.2.2.4.2.3.cmml" xref="S6.SS7.p3.5.m5.2.2.4.2.3"><plus id="S6.SS7.p3.5.m5.2.2.4.2.3.1.cmml" xref="S6.SS7.p3.5.m5.2.2.4.2.3.1"></plus><ci id="S6.SS7.p3.5.m5.2.2.4.2.3.2.cmml" xref="S6.SS7.p3.5.m5.2.2.4.2.3.2">𝑡</ci><cn type="integer" id="S6.SS7.p3.5.m5.2.2.4.2.3.3.cmml" xref="S6.SS7.p3.5.m5.2.2.4.2.3.3">1</cn></apply></apply><times id="S6.SS7.p3.5.m5.2.2.4.3.cmml" xref="S6.SS7.p3.5.m5.2.2.4.3"></times></apply><apply id="S6.SS7.p3.5.m5.2.2.2.cmml" xref="S6.SS7.p3.5.m5.2.2.2"><times id="S6.SS7.p3.5.m5.2.2.2.3.cmml" xref="S6.SS7.p3.5.m5.2.2.2.3"></times><apply id="S6.SS7.p3.5.m5.2.2.2.4.cmml" xref="S6.SS7.p3.5.m5.2.2.2.4"><arg id="S6.SS7.p3.5.m5.2.2.2.4.1.cmml" xref="S6.SS7.p3.5.m5.2.2.2.4.1"></arg><apply id="S6.SS7.p3.5.m5.2.2.2.4.2.cmml" xref="S6.SS7.p3.5.m5.2.2.2.4.2"><apply id="S6.SS7.p3.5.m5.2.2.2.4.2.1.cmml" xref="S6.SS7.p3.5.m5.2.2.2.4.2.1"><csymbol cd="ambiguous" id="S6.SS7.p3.5.m5.2.2.2.4.2.1.1.cmml" xref="S6.SS7.p3.5.m5.2.2.2.4.2.1">subscript</csymbol><min id="S6.SS7.p3.5.m5.2.2.2.4.2.1.2.cmml" xref="S6.SS7.p3.5.m5.2.2.2.4.2.1.2"></min><ci id="S6.SS7.p3.5.m5.2.2.2.4.2.1.3.cmml" xref="S6.SS7.p3.5.m5.2.2.2.4.2.1.3">𝜃</ci></apply><ci id="S6.SS7.p3.5.m5.2.2.2.4.2.2.cmml" xref="S6.SS7.p3.5.m5.2.2.2.4.2.2">𝐿</ci></apply></apply><list id="S6.SS7.p3.5.m5.2.2.2.2.3.cmml" xref="S6.SS7.p3.5.m5.2.2.2.2.2"><apply id="S6.SS7.p3.5.m5.1.1.1.1.1.1.cmml" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S6.SS7.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="S6.SS7.p3.5.m5.1.1.1.1.1.1.2.cmml" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.2">𝐷</ci><apply id="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.cmml" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.1.cmml" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.3">subscript</csymbol><ci id="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.2.cmml" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.2">𝑇</ci><ci id="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.3.cmml" xref="S6.SS7.p3.5.m5.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply><apply id="S6.SS7.p3.5.m5.2.2.2.2.2.2.cmml" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S6.SS7.p3.5.m5.2.2.2.2.2.2.1.cmml" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2">subscript</csymbol><ci id="S6.SS7.p3.5.m5.2.2.2.2.2.2.2.cmml" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.2">𝜃</ci><apply id="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.cmml" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.1.cmml" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.3">subscript</csymbol><ci id="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.2.cmml" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.2">𝑇</ci><ci id="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.3.cmml" xref="S6.SS7.p3.5.m5.2.2.2.2.2.2.3.3">𝑡</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p3.5.m5.2c">\theta_{t+1}^{*}=\arg\min_{\theta}L(D_{T_{t}};\theta_{T_{t}})</annotation></semantics></math><span id="S6.SS7.p3.7.6" class="ltx_text" style="color:#000000;">. Where </span><math id="S6.SS7.p3.6.m6.1" class="ltx_Math" alttext="D_{T_{t}}" display="inline"><semantics id="S6.SS7.p3.6.m6.1a"><msub id="S6.SS7.p3.6.m6.1.1" xref="S6.SS7.p3.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.6.m6.1.1.2" xref="S6.SS7.p3.6.m6.1.1.2.cmml">D</mi><msub id="S6.SS7.p3.6.m6.1.1.3" xref="S6.SS7.p3.6.m6.1.1.3.cmml"><mi mathcolor="#000000" id="S6.SS7.p3.6.m6.1.1.3.2" xref="S6.SS7.p3.6.m6.1.1.3.2.cmml">T</mi><mi mathcolor="#000000" id="S6.SS7.p3.6.m6.1.1.3.3" xref="S6.SS7.p3.6.m6.1.1.3.3.cmml">t</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p3.6.m6.1b"><apply id="S6.SS7.p3.6.m6.1.1.cmml" xref="S6.SS7.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S6.SS7.p3.6.m6.1.1.1.cmml" xref="S6.SS7.p3.6.m6.1.1">subscript</csymbol><ci id="S6.SS7.p3.6.m6.1.1.2.cmml" xref="S6.SS7.p3.6.m6.1.1.2">𝐷</ci><apply id="S6.SS7.p3.6.m6.1.1.3.cmml" xref="S6.SS7.p3.6.m6.1.1.3"><csymbol cd="ambiguous" id="S6.SS7.p3.6.m6.1.1.3.1.cmml" xref="S6.SS7.p3.6.m6.1.1.3">subscript</csymbol><ci id="S6.SS7.p3.6.m6.1.1.3.2.cmml" xref="S6.SS7.p3.6.m6.1.1.3.2">𝑇</ci><ci id="S6.SS7.p3.6.m6.1.1.3.3.cmml" xref="S6.SS7.p3.6.m6.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p3.6.m6.1c">D_{T_{t}}</annotation></semantics></math><span id="S6.SS7.p3.7.7" class="ltx_text" style="color:#000000;"> represents the data available at time </span><math id="S6.SS7.p3.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S6.SS7.p3.7.m7.1a"><mi mathcolor="#000000" id="S6.SS7.p3.7.m7.1.1" xref="S6.SS7.p3.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S6.SS7.p3.7.m7.1b"><ci id="S6.SS7.p3.7.m7.1.1.cmml" xref="S6.SS7.p3.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p3.7.m7.1c">t</annotation></semantics></math><span id="S6.SS7.p3.7.8" class="ltx_text" style="color:#000000;">, including new target domain data.</span></p>
</div>
<div id="S6.SS7.p4" class="ltx_para">
<p id="S6.SS7.p4.5" class="ltx_p"><span id="S6.SS7.p4.5.1" class="ltx_text" style="color:#000000;">The approach of online DTL offers a forward-looking solution to this issue. Particularly, discrepancies in class distributions and the representation of features between the </span><math id="S6.SS7.p4.1.m1.1" class="ltx_Math" alttext="D_{S}" display="inline"><semantics id="S6.SS7.p4.1.m1.1a"><msub id="S6.SS7.p4.1.m1.1.1" xref="S6.SS7.p4.1.m1.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p4.1.m1.1.1.2" xref="S6.SS7.p4.1.m1.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS7.p4.1.m1.1.1.3" xref="S6.SS7.p4.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p4.1.m1.1b"><apply id="S6.SS7.p4.1.m1.1.1.cmml" xref="S6.SS7.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S6.SS7.p4.1.m1.1.1.1.cmml" xref="S6.SS7.p4.1.m1.1.1">subscript</csymbol><ci id="S6.SS7.p4.1.m1.1.1.2.cmml" xref="S6.SS7.p4.1.m1.1.1.2">𝐷</ci><ci id="S6.SS7.p4.1.m1.1.1.3.cmml" xref="S6.SS7.p4.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p4.1.m1.1c">D_{S}</annotation></semantics></math><span id="S6.SS7.p4.5.2" class="ltx_text" style="color:#000000;"> and </span><math id="S6.SS7.p4.2.m2.1" class="ltx_Math" alttext="D_{T}" display="inline"><semantics id="S6.SS7.p4.2.m2.1a"><msub id="S6.SS7.p4.2.m2.1.1" xref="S6.SS7.p4.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p4.2.m2.1.1.2" xref="S6.SS7.p4.2.m2.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS7.p4.2.m2.1.1.3" xref="S6.SS7.p4.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p4.2.m2.1b"><apply id="S6.SS7.p4.2.m2.1.1.cmml" xref="S6.SS7.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S6.SS7.p4.2.m2.1.1.1.cmml" xref="S6.SS7.p4.2.m2.1.1">subscript</csymbol><ci id="S6.SS7.p4.2.m2.1.1.2.cmml" xref="S6.SS7.p4.2.m2.1.1.2">𝐷</ci><ci id="S6.SS7.p4.2.m2.1.1.3.cmml" xref="S6.SS7.p4.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p4.2.m2.1c">D_{T}</annotation></semantics></math><span id="S6.SS7.p4.5.3" class="ltx_text" style="color:#000000;"> amplify the complexity of online DTL </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS7.p4.5.4.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib140" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">140</span></a><span id="S6.SS7.p4.5.5.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS7.p4.5.6" class="ltx_text" style="color:#000000;">.
To navigate the complexities mentioned, online DTL has been dissected into two primary methodologies. The first, known as homogeneous online DTL, operates on the premise of a unified feature space across both domains. Conversely, heterogeneous online DTL acknowledges the distinct feature spaces intrinsic to each domain </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS7.p4.5.7.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib141" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">141</span></a><span id="S6.SS7.p4.5.8.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS7.p4.5.9" class="ltx_text" style="color:#000000;">. An exemplary solution to the challenges of heterogeneous online DTL includes leveraging unlabeled instances of co-occurrence to forge a connective bridge between the </span><math id="S6.SS7.p4.3.m3.1" class="ltx_Math" alttext="D_{S}" display="inline"><semantics id="S6.SS7.p4.3.m3.1a"><msub id="S6.SS7.p4.3.m3.1.1" xref="S6.SS7.p4.3.m3.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p4.3.m3.1.1.2" xref="S6.SS7.p4.3.m3.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS7.p4.3.m3.1.1.3" xref="S6.SS7.p4.3.m3.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p4.3.m3.1b"><apply id="S6.SS7.p4.3.m3.1.1.cmml" xref="S6.SS7.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S6.SS7.p4.3.m3.1.1.1.cmml" xref="S6.SS7.p4.3.m3.1.1">subscript</csymbol><ci id="S6.SS7.p4.3.m3.1.1.2.cmml" xref="S6.SS7.p4.3.m3.1.1.2">𝐷</ci><ci id="S6.SS7.p4.3.m3.1.1.3.cmml" xref="S6.SS7.p4.3.m3.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p4.3.m3.1c">D_{S}</annotation></semantics></math><span id="S6.SS7.p4.5.10" class="ltx_text" style="color:#000000;"> and </span><math id="S6.SS7.p4.4.m4.1" class="ltx_Math" alttext="D_{T}" display="inline"><semantics id="S6.SS7.p4.4.m4.1a"><msub id="S6.SS7.p4.4.m4.1.1" xref="S6.SS7.p4.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p4.4.m4.1.1.2" xref="S6.SS7.p4.4.m4.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS7.p4.4.m4.1.1.3" xref="S6.SS7.p4.4.m4.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p4.4.m4.1b"><apply id="S6.SS7.p4.4.m4.1.1.cmml" xref="S6.SS7.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S6.SS7.p4.4.m4.1.1.1.cmml" xref="S6.SS7.p4.4.m4.1.1">subscript</csymbol><ci id="S6.SS7.p4.4.m4.1.1.2.cmml" xref="S6.SS7.p4.4.m4.1.1.2">𝐷</ci><ci id="S6.SS7.p4.4.m4.1.1.3.cmml" xref="S6.SS7.p4.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p4.4.m4.1c">D_{T}</annotation></semantics></math><span id="S6.SS7.p4.5.11" class="ltx_text" style="color:#000000;">, facilitating the precursor to knowledge transfer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS7.p4.5.12.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib142" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">142</span></a><span id="S6.SS7.p4.5.13.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS7.p4.5.14" class="ltx_text" style="color:#000000;">.
Furthering the discourse, online DTL augmented with extreme learning machines introduces a novel framework </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.SS7.p4.5.15.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib143" title="" class="ltx_ref"><span class="ltx_text" style="color:#000000;">143</span></a><span id="S6.SS7.p4.5.16.2" class="ltx_text" style="color:#000000;">]</span></cite><span id="S6.SS7.p4.5.17" class="ltx_text" style="color:#000000;">. Addressing the challenge of limited data in the </span><math id="S6.SS7.p4.5.m5.1" class="ltx_Math" alttext="D_{T}" display="inline"><semantics id="S6.SS7.p4.5.m5.1a"><msub id="S6.SS7.p4.5.m5.1.1" xref="S6.SS7.p4.5.m5.1.1.cmml"><mi mathcolor="#000000" id="S6.SS7.p4.5.m5.1.1.2" xref="S6.SS7.p4.5.m5.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S6.SS7.p4.5.m5.1.1.3" xref="S6.SS7.p4.5.m5.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S6.SS7.p4.5.m5.1b"><apply id="S6.SS7.p4.5.m5.1.1.cmml" xref="S6.SS7.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S6.SS7.p4.5.m5.1.1.1.cmml" xref="S6.SS7.p4.5.m5.1.1">subscript</csymbol><ci id="S6.SS7.p4.5.m5.1.1.2.cmml" xref="S6.SS7.p4.5.m5.1.1.2">𝐷</ci><ci id="S6.SS7.p4.5.m5.1.1.3.cmml" xref="S6.SS7.p4.5.m5.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS7.p4.5.m5.1c">D_{T}</annotation></semantics></math><span id="S6.SS7.p4.5.18" class="ltx_text" style="color:#000000;">, the technique of transfer learning with lag (TLL), rooted in shallow neural network embeddings, has been applied. This method ensures the continuity of knowledge transfer, notwithstanding fluctuations in the feature set.</span></p>
</div>
</section>
<section id="S6.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.8 </span>Transformers and LLMs-based ASR</h3>

<div id="S6.SS8.p1" class="ltx_para">
<span id="S6.SS8.p1.1" class="ltx_ERROR undefined">\Acp</span>
<p id="S6.SS8.p1.2" class="ltx_p"><span id="S6.SS8.p1.2.1" class="ltx_text" style="color:#000000;">LLM and transformers represent the forefront of </span><a href="#Sx1.1.1.1"><abbr href="#Sx1.1.1.1" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AI</span></span></abbr></a><span id="S6.SS8.p1.2.2" class="ltx_text" style="color:#000000;">, trained on vast datasets spanning various domains, including text, speech, images, and multi-modal inputs. Despite extensive research on </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS8.p1.2.3" class="ltx_text" style="color:#000000;">, existing </span><a href="#Sx1.44.44.44"><abbr href="#Sx1.44.44.44" title="state-of-the-art" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">SOTA</span></span></abbr></a><span id="S6.SS8.p1.2.4" class="ltx_text" style="color:#000000;"> approaches often lack integration of advanced </span><a href="#Sx1.1.1.1"><abbr href="#Sx1.1.1.1" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AI</span></span></abbr></a><span id="S6.SS8.p1.2.5" class="ltx_text" style="color:#000000;"> techniques like </span><a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a><span id="S6.SS8.p1.2.6" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S6.SS8.p1.2.7" class="ltx_text" style="color:#000000;"> into both </span><a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a><span id="S6.SS8.p1.2.8" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a><span id="S6.SS8.p1.2.9" class="ltx_text" style="color:#000000;"> domains. For example, </span><span id="S6.SS8.p1.2.10" class="ltx_ERROR undefined">\Ac</span><span id="S6.SS8.p1.2.11" class="ltx_text" style="color:#000000;">LLM based on </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS8.p1.2.12" class="ltx_text" style="color:#000000;"> has demonstrated significant potential for </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS8.p1.2.13" class="ltx_text" style="color:#000000;"> tasks, particularly for both </span><a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a><span id="S6.SS8.p1.2.14" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a><span id="S6.SS8.p1.2.15" class="ltx_text" style="color:#000000;"> components. The incorporation of TL techniques into  </span><a href="#Sx1.58.58.58"><span href="#Sx1.58.58.58" title="large language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_long"><span class="ltx_text" style="font-size:80%;">large language model</span></span></span></a><span id="S6.SS8.p1.2.16" class="ltx_text" style="color:#000000;"> (</span><a href="#Sx1.58.58.58"><abbr href="#Sx1.58.58.58" title="large language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LLM</span></span></abbr></a><span id="S6.SS8.p1.2.17" class="ltx_text" style="color:#000000;">) facilitates the transfer of knowledge from extensive pre-training tasks to enhance </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS8.p1.2.18" class="ltx_text" style="color:#000000;"> effectiveness. In terms of </span><a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a><span id="S6.SS8.p1.2.19" class="ltx_text" style="color:#000000;">, fine-tuning </span><a href="#Sx1.58.58.58"><abbr href="#Sx1.58.58.58" title="large language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LLM</span></span></abbr></a><span id="S6.SS8.p1.2.20" class="ltx_text" style="color:#000000;"> can leverage insights gained from pre-trained models exposed to sample acoustic data. This enables the </span><a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a><span id="S6.SS8.p1.2.21" class="ltx_text" style="color:#000000;"> component to grasp acoustic features like spectrograms or Mel-frequency cepstral coefficients (MFCCs) and utilize pre-trained knowledge to improve speech recognition accuracy. Through fine-tuning, the model can adjust and specialize in specific datasets or acoustic domains, leading to enhanced </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS8.p1.2.22" class="ltx_text" style="color:#000000;"> performance.</span></p>
</div>
<div id="S6.SS8.p2" class="ltx_para">
<p id="S6.SS8.p2.1" class="ltx_p"><span id="S6.SS8.p2.1.1" class="ltx_text" style="color:#000000;">Similarly, the </span><a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a><span id="S6.SS8.p2.1.2" class="ltx_text" style="color:#000000;"> aspect of </span><a href="#Sx1.58.58.58"><abbr href="#Sx1.58.58.58" title="large language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LLM</span></span></abbr></a><span id="S6.SS8.p2.1.3" class="ltx_text" style="color:#000000;"> based on </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S6.SS8.p2.1.4" class="ltx_text" style="color:#000000;"> can enhance </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS8.p2.1.5" class="ltx_text" style="color:#000000;"> by leveraging TL. Pre-training </span><a href="#Sx1.58.58.58"><abbr href="#Sx1.58.58.58" title="large language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LLM</span></span></abbr></a><span id="S6.SS8.p2.1.6" class="ltx_text" style="color:#000000;"> on vast text corpora equips it with extensive language representations, aiding in addressing diverse language challenges. Fine-tuning enables adaptation to specific language characteristics, improving transcription accuracy and contextual appropriateness. Both </span><a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a><span id="S6.SS8.p2.1.7" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a><span id="S6.SS8.p2.1.8" class="ltx_text" style="color:#000000;"> fine-tuning can benefit from </span><a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a><span id="S6.SS8.p2.1.9" class="ltx_text" style="color:#000000;">, incorporating target domain data to tailor models, reducing domain mismatch, and enhancing effectiveness and generalization. Utilizing </span><a href="#Sx1.58.58.58"><abbr href="#Sx1.58.58.58" title="large language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LLM</span></span></abbr></a><span id="S6.SS8.p2.1.10" class="ltx_text" style="color:#000000;"> for objective </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS8.p2.1.11" class="ltx_text" style="color:#000000;"> testing and MOS evaluation involves compiling diverse datasets, fine-tuning </span><a href="#Sx1.58.58.58"><abbr href="#Sx1.58.58.58" title="large language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LLM</span></span></abbr></a><span id="S6.SS8.p2.1.12" class="ltx_text" style="color:#000000;">, and integrating it into the </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS8.p2.1.13" class="ltx_text" style="color:#000000;"> system. Evaluation metrics like </span><a href="#Sx1.8.8.8"><abbr href="#Sx1.8.8.8" title="character error rate" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">CER</span></span></abbr></a><span id="S6.SS8.p2.1.14" class="ltx_text" style="color:#000000;"> and Pearson’s correlation gauge system performance, guiding further fine-tuning iterations for improved results. This iterative process ensures the </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S6.SS8.p2.1.15" class="ltx_text" style="color:#000000;"> system’s continual enhancement and accurate MOS scale generation. Researchers are invited to explore these gaps and advance the integration of more advanced </span><a href="#Sx1.1.1.1"><abbr href="#Sx1.1.1.1" title="artificial intelligence" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AI</span></span></abbr></a><span id="S6.SS8.p2.1.16" class="ltx_text" style="color:#000000;"> techniques such as </span><a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a><span id="S6.SS8.p2.1.17" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S6.SS8.p2.1.18" class="ltx_text" style="color:#000000;"> into both </span><a href="#Sx1.2.2.2"><abbr href="#Sx1.2.2.2" title="acoustic model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">AM</span></span></abbr></a><span id="S6.SS8.p2.1.19" class="ltx_text" style="color:#000000;"> and </span><a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a><span id="S6.SS8.p2.1.20" class="ltx_text" style="color:#000000;"> domains within transformer-based models. Additionally, there is a need for further investigation into Transformers and DTL-based ASR schemes specifically tailored for the </span><a href="#Sx1.24.24.24"><abbr href="#Sx1.24.24.24" title="language model" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">LM</span></span></abbr></a><span id="S6.SS8.p2.1.21" class="ltx_text" style="color:#000000;"> domain. Closing these gaps will contribute to the development of more robust and effective language models across various applications.</span></p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="color:#000000;">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p"><span id="S7.p1.1.1" class="ltx_text" style="color:#000000;">In conclusion, recent advancements in deep learning have presented both challenges and opportunities for</span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S7.p1.1.2" class="ltx_text" style="color:#000000;">. Traditional </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S7.p1.1.3" class="ltx_text" style="color:#000000;"> systems require extensive training datasets, often including confidential information, and consume significant computational resources. However, the demand for adaptive systems capable of performing well in dynamic environments has spurred the development of advanced deep learning techniques such as </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S7.p1.1.4" class="ltx_text" style="color:#000000;">, </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S7.p1.1.5" class="ltx_text" style="color:#000000;">, and </span><a href="#Sx1.15.15.15"><abbr href="#Sx1.15.15.15" title="deep reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DRL</span></span></abbr></a><span id="S7.p1.1.6" class="ltx_text" style="color:#000000;">, with all their variant techniques. These advanced techniques address issues related to </span><a href="#Sx1.13.13.13"><abbr href="#Sx1.13.13.13" title="domain adaptation" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DA</span></span></abbr></a><span id="S7.p1.1.7" class="ltx_text" style="color:#000000;">, privacy preservation, and dynamic decision-making, thereby enhancing </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S7.p1.1.8" class="ltx_text" style="color:#000000;"> performance and reducing computational costs.</span></p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p"><span id="S7.p2.1.1" class="ltx_text" style="color:#000000;">This survey has provided a comprehensive review of </span><a href="#Sx1.16.16.16"><abbr href="#Sx1.16.16.16" title="deep transfer learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DTL</span></span></abbr></a><span id="S7.p2.1.2" class="ltx_text" style="color:#000000;">, </span><a href="#Sx1.20.20.20"><abbr href="#Sx1.20.20.20" title="federated learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">FL</span></span></abbr></a><span id="S7.p2.1.3" class="ltx_text" style="color:#000000;">, and </span><a href="#Sx1.35.35.35"><abbr href="#Sx1.35.35.35" title="reinforcement learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">RL</span></span></abbr></a><span id="S7.p2.1.4" class="ltx_text" style="color:#000000;">-based ASR frameworks, offering insights into the latest developments and helping researchers and professionals understand current challenges. Additionally, the integration of transformers, powerful </span><a href="#Sx1.14.14.14"><abbr href="#Sx1.14.14.14" title="deep learning" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">DL</span></span></abbr></a><span id="S7.p2.1.5" class="ltx_text" style="color:#000000;"> models, has been explored for their ability to capture complex dependencies in ASR sequences. By presenting a structured taxonomy and conducting critical analyses, this paper has shed light on the strengths and weaknesses of existing frameworks, as well as highlighted ongoing challenges. Moving forward, further research is needed to overcome these challenges and unlock the full potential of advanced DL techniques in ASR. Future work should focus on refining existing approaches, addressing privacy concerns in FL, improving RL algorithms for ASR optimization, and exploring innovative ways to leverage transformers for more efficient and accurate speech recognition. By continuing to innovate and collaborate across disciplines, we can push the boundaries of </span><a href="#Sx1.4.4.4"><abbr href="#Sx1.4.4.4" title="automatic speech recognition" class="ltx_glossaryref"><span class="ltx_text ltx_glossary_short"><span class="ltx_text" style="font-size:80%;">ASR</span></span></abbr></a><span id="S7.p2.1.6" class="ltx_text" style="color:#000000;"> technology and realize its transformative impact on various fields, including healthcare, communication, and accessibility.</span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="color:#000000;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text" style="color:#000000;">[1]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.4.1" class="ltx_text" style="color:#000000;">
H. Haneche, A. Ouahabi, B. Boudraa, Compressed sensing-speech coding scheme for
mobile communications, Circuits, Systems, and Signal Processing (2021) 1–21.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.2.2.1" class="ltx_text" style="color:#000000;">[2]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.4.1" class="ltx_text" style="color:#000000;">
D. Michelsanti, Z.-H. Tan, S.-X. Zhang, Y. Xu, M. Yu, D. Yu, J. Jensen, An
overview of deep-learning-based audio-visual speech enhancement and
separation, IEEE/ACM Transactions on Audio, Speech, and Language Processing
(2021).
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.2.2.1" class="ltx_text" style="color:#000000;">[3]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.4.1" class="ltx_text" style="color:#000000;">
Y. Luo, C. Han, N. Mesgarani, Group communication with context codec for
lightweight source separation, IEEE/ACM Transactions on Audio, Speech, and
Language Processing 29 (2021) 1752–1761.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.2.2.1" class="ltx_text" style="color:#000000;">[4]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text" style="color:#000000;">
H. Kheddar, M. Bouzid, D. Megías, Pitch and fourier magnitude based
steganography for hiding 2.4 kbps melp bitstream, IET Signal Processing
13 (3) (2019) 396–407.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.2.2.1" class="ltx_text" style="color:#000000;">[5]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.4.1" class="ltx_text" style="color:#000000;">
H. Kheddar, A. C. Mazari, G. H. Ilk, Speech steganography based on double
approximation of lsfs parameters in amr coding, in: 2022 7th International
Conference on Image and Signal Processing and their Applications (ISPA),
IEEE, 2022, pp. 1–8.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.2.2.1" class="ltx_text" style="color:#000000;">[6]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.4.1" class="ltx_text" style="color:#000000;">
H. Kheddar, D. Megias, M. Bouzid, Fourier magnitude-based steganography for
hiding 2.4 kbpsmelp secret speech, in: 2018 International Conference on
Applied Smart Systems (ICASS), IEEE, 2018, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.2.2.1" class="ltx_text" style="color:#000000;">[7]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text" style="color:#000000;">
H. Yassine, B. Bachir, K. Aziz, A secure and high robust audio watermarking
system for copyright protection, International Journal of Computer
Applications 53 (17) (2012) 33–39.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.2.2.1" class="ltx_text" style="color:#000000;">[8]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.4.1" class="ltx_text" style="color:#000000;">
M. Yamni, H. Karmouni, M. Sayyouri, H. Qjidaa, Efficient watermarking algorithm
for digital audio/speech signal, Digital Signal Processing 120 (2022) 103251.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.2.2.1" class="ltx_text" style="color:#000000;">[9]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text" style="color:#000000;">
H. Chen, B. D. Rouhani, F. Koushanfar, Specmark: A spectral watermarking
framework for ip protection of speech recognition systems., in: INTERSPEECH,
2020, pp. 2312–2316.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.2.2.1" class="ltx_text" style="color:#000000;">[10]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.4.1" class="ltx_text" style="color:#000000;">
M. Olivieri, R. Malvermi, M. Pezzoli, M. Zanoni, S. Gonzalez, F. Antonacci,
A. Sarti, Audio information retrieval and musical acoustics, IEEE
Instrumentation &amp; Measurement Magazine 24 (7) (2021) 10–20.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.2.2.1" class="ltx_text" style="color:#000000;">[11]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.4.1" class="ltx_text" style="color:#000000;">
E. Wold, T. Blum, D. Keislar, J. Wheaten, Content-based classification, search,
and retrieval of audio, IEEE multimedia 3 (3) (1996) 27–36.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.2.2.1" class="ltx_text" style="color:#000000;">[12]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.4.1" class="ltx_text" style="color:#000000;">
W. Boes, et al., Audiovisual transfer learning for audio tagging and sound
event detection, Proceedings Interspeech 2021 (2021).
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.2.2.1" class="ltx_text" style="color:#000000;">[13]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.4.1" class="ltx_text" style="color:#000000;">
Y. Tang, J. Pino, C. Wang, X. Ma, D. Genzel, A general multi-task learning
framework to leverage text data for speech to text tasks, in: ICASSP
2021-2021 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP), IEEE, 2021, pp. 6209–6213.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.2.2.1" class="ltx_text" style="color:#000000;">[14]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text" style="color:#000000;">
F. M. Plaza-del Arco, M. D. Molina-González, L. A. Ureña-López,
M. T. Martín-Valdivia, Comparing pre-trained language models for spanish
hate speech detection, Expert Systems with Applications 166 (2021) 114120.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.2.2.1" class="ltx_text" style="color:#000000;">[15]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.4.1" class="ltx_text" style="color:#000000;">
A. C. Mazari, H. Kheddar, Deep learning-based analysis of algerian dialect
dataset targeted hate speech, offensive language and cyberbullying,
International Journal of Computing and Digital Systems (2023).
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.2.2.1" class="ltx_text" style="color:#000000;">[16]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.4.1" class="ltx_text" style="color:#000000;">
D. Meghraoui, B. Boudraa, T. Merazi, P. G. Vilda, A novel pre-processing
technique in pathologic voice detection: Application to parkinson’s disease
phonation, Biomedical Signal Processing and Control 68 (2021) 102604.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.2.2.1" class="ltx_text" style="color:#000000;">[17]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.4.1" class="ltx_text" style="color:#000000;">
Y.-Y. Lin, W.-Z. Zheng, W. C. Chu, J.-Y. Han, Y.-H. Hung, G.-M. Ho, C.-Y.
Chang, Y.-H. Lai, A speech command control-based recognition system for
dysarthric patients based on deep learning technology, Applied Sciences
11 (6) (2021) 2477.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.2.2.1" class="ltx_text" style="color:#000000;">[18]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.4.1" class="ltx_text" style="color:#000000;">
Y. Kumar, S. Gupta, W. Singh, A novel deep transfer learning models for
recognition of birds sounds in different environment, Soft Computing 26 (3)
(2022) 1003–1023.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.2.2.1" class="ltx_text" style="color:#000000;">[19]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.4.1" class="ltx_text" style="color:#000000;">
S. Padi, S. O. Sadjadi, R. D. Sriram, D. Manocha, Improved speech emotion
recognition using transfer learning and spectrogram augmentation, in:
Proceedings of the 2021 International Conference on Multimodal Interaction,
2021, pp. 645–652.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.2.2.1" class="ltx_text" style="color:#000000;">[20]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.4.1" class="ltx_text" style="color:#000000;">
Y. Himeur, M. Elnour, F. Fadli, N. Meskin, I. Petri, Y. Rezgui, F. Bensaali,
A. Amra, Next-generation energy systems for sustainable smart cities: Roles
of transfer learning, Sustainable Cities and Society (2022) 1–35.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.2.2.1" class="ltx_text" style="color:#000000;">[21]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.4.1" class="ltx_text" style="color:#000000;">
S. Niu, Y. Liu, J. Wang, H. Song, A decade survey of transfer learning
(2010–2020), IEEE Transactions on Artificial Intelligence 1 (2) (2020)
151–166.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.2.2.1" class="ltx_text" style="color:#000000;">[22]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.4.1" class="ltx_text" style="color:#000000;">
H. Kheddar, D. Megías, High capacity speech steganography for the g723. 1
coder based on quantised line spectral pairs interpolation and cnn
auto-encoding, Applied Intelligence (2022) 1–19.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.2.2.1" class="ltx_text" style="color:#000000;">[23]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.4.1" class="ltx_text" style="color:#000000;">
T. A. de Lima, M. Da Costa-Abreu, A survey on automatic speech recognition
systems for portuguese language and its variations, Computer Speech &amp;
Language 62 (2020) 101055.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.2.2.1" class="ltx_text" style="color:#000000;">[24]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.4.1" class="ltx_text" style="color:#000000;">
A. Singh, V. Kadyan, M. Kumar, N. Bassan, Asroil: a comprehensive survey for
automatic speech recognition of indian languages, Artificial Intelligence
Review 53 (2020) 3673–3704.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.2.2.1" class="ltx_text" style="color:#000000;">[25]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.4.1" class="ltx_text" style="color:#000000;">
R. S. Arslan, N. BARIŞÇI, A detailed survey of turkish automatic
speech recognition, Turkish journal of electrical engineering and computer
sciences 28 (6) (2020) 3253–3269.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.2.2.1" class="ltx_text" style="color:#000000;">[26]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.4.1" class="ltx_text" style="color:#000000;">
A. Dhouib, A. Othman, O. El Ghoul, M. K. Khribi, A. Al Sinani, Arabic automatic
speech recognition: a systematic literature review, Applied Sciences 12 (17)
(2022) 8898.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.2.2.1" class="ltx_text" style="color:#000000;">[27]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.4.1" class="ltx_text" style="color:#000000;">
J. Kaur, A. Singh, V. Kadyan, Automatic speech recognition system for tonal
languages: State-of-the-art survey, Archives of Computational Methods in
Engineering 28 (2021) 1039–1068.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.2.2.1" class="ltx_text" style="color:#000000;">[28]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.4.1" class="ltx_text" style="color:#000000;">
A. A. Abushariah, H.-N. Ting, M. B. P. Mustafa, A. S. M. Khairuddin, M. A.
Abushariah, T.-P. Tan, Bilingual automatic speech recognition: A review,
taxonomy and open challenges, IEEE Access (2022).
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.2.2.1" class="ltx_text" style="color:#000000;">[29]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.4.1" class="ltx_text" style="color:#000000;">
J. L. K. E. Fendji, D. C. Tala, B. O. Yenke, M. Atemkeng, Automatic speech
recognition using limited vocabulary: A survey, Applied Artificial
Intelligence 36 (1) (2022) 2095039.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.2.2.1" class="ltx_text" style="color:#000000;">[30]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.4.1" class="ltx_text" style="color:#000000;">
V. Bhardwaj, M. T. Ben Othman, V. Kukreja, Y. Belkhier, M. Bajaj, B. S. Goud,
A. U. Rehman, M. Shafiq, H. Hamam, Automatic speech recognition (asr) systems
for children: A systematic literature review, Applied Sciences 12 (9) (2022)
4419.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.2.2.1" class="ltx_text" style="color:#000000;">[31]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.4.1" class="ltx_text" style="color:#000000;">
R. Errattahi, A. El Hannani, H. Ouahmane, Automatic speech recognition errors
detection and correction: A review, Procedia Computer Science 128 (2018)
32–37.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.2.2.1" class="ltx_text" style="color:#000000;">[32]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.4.1" class="ltx_text" style="color:#000000;">
H. Aldarmaki, A. Ullah, S. Ram, N. Zaki, Unsupervised automatic speech
recognition: A review, Speech Communication 139 (2022) 76–91.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.2.2.1" class="ltx_text" style="color:#000000;">[33]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.4.1" class="ltx_text" style="color:#000000;">
A. S. Dhanjal, W. Singh, A comprehensive survey on automatic speech recognition
using neural networks, Multimedia Tools and Applications (2023) 1–46.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.2.2.1" class="ltx_text" style="color:#000000;">[34]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.4.1" class="ltx_text" style="color:#000000;">
A. B. Nassif, I. Shahin, I. Attili, M. Azzeh, K. Shaalan, Speech recognition
using deep neural networks: A systematic review, IEEE access 7 (2019)
19143–19165.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.2.2.1" class="ltx_text" style="color:#000000;">[35]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.4.1" class="ltx_text" style="color:#000000;">
M. Malik, M. K. Malik, K. Mehmood, I. Makhdoom, Automatic speech recognition: a
survey, Multimedia Tools and Applications 80 (6) (2021) 9411–9457.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.2.2.1" class="ltx_text" style="color:#000000;">[36]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.4.1" class="ltx_text" style="color:#000000;">
H. Kheddar, Y. Himeur, S. Al-Maadeed, A. Amira, F. Bensaali, Deep transfer
learning for automatic speech recognition: Towards better generalization,
Knowledge-Based Systems 277 (2023) 110851.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.2.2.1" class="ltx_text" style="color:#000000;">[37]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.4.1" class="ltx_text" style="color:#000000;">
F. Filippidou, L. Moussiades, A benchmarking of ibm, google and wit automatic
speech recognition systems, in: IFIP International Conference on Artificial
Intelligence Applications and Innovations, Springer, 2020, pp. 73–82.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.2.2.1" class="ltx_text" style="color:#000000;">[38]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.4.1" class="ltx_text" style="color:#000000;">
M. Suzuki, H. Sakaji, M. Hirano, K. Izumi, Constructing and analyzing
domain-specific language model for financial text mining, Information
Processing &amp; Management 60 (2) (2023) 103194.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.2.2.1" class="ltx_text" style="color:#000000;">[39]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.4.1" class="ltx_text" style="color:#000000;">
C.-H. H. Yang, Y. Gu, Y.-C. Liu, S. Ghosh, I. Bulyko, A. Stolcke, Generative
speech recognition error correction with large language models and
task-activating prompting, in: 2023 IEEE Automatic Speech Recognition and
Understanding Workshop (ASRU), IEEE, 2023, pp. 1–8.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.2.2.1" class="ltx_text" style="color:#000000;">[40]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.4.1" class="ltx_text" style="color:#000000;">
Z. Dong, Q. Ding, W. Zhai, M. Zhou, A speech recognition method based on
domain-specific datasets and confidence decision networks, Sensors 23 (13)
(2023) 6036.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.2.2.1" class="ltx_text" style="color:#000000;">[41]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.4.1" class="ltx_text" style="color:#000000;">
H. Kheddar, Y. Himeur, A. I. Awad, Deep transfer learning for intrusion
detection in industrial control networks: A comprehensive review, Journal of
Network and Computer Applications 220 (2023) 103760.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.2.2.1" class="ltx_text" style="color:#000000;">[42]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.4.1" class="ltx_text" style="color:#000000;">
Y. Li, X. Zhang, P. Wang, X. Zhang, Y. Liu, Insight into an unsupervised
two-step sparse transfer learning algorithm for speech diagnosis of
parkinson’s disease, Neural Computing and Applications (2021) 1–18.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.2.2.1" class="ltx_text" style="color:#000000;">[43]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.4.1" class="ltx_text" style="color:#000000;">
O. Karaman, H. Çakın, A. Alhudhaif, K. Polat, Robust automated
parkinson disease detection based on voice signals with transfer learning,
Expert Systems with Applications 178 (2021) 115013.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.2.2.1" class="ltx_text" style="color:#000000;">[44]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.4.1" class="ltx_text" style="color:#000000;">
R. A. Ramadan, Detecting adversarial attacks on audio-visual speech recognition
using deep learning method, International Journal of Speech Technology (2021)
1–7.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.2.2.1" class="ltx_text" style="color:#000000;">[45]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.4.1" class="ltx_text" style="color:#000000;">
Q. Yu, Y. Ma, Y. Li, Enhancing speech recognition for parkinson’s disease
patient using transfer learning technique, Journal of Shanghai Jiaotong
University (Science) (2021) 1–9.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.2.2.1" class="ltx_text" style="color:#000000;">[46]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.4.1" class="ltx_text" style="color:#000000;">
Y. Bai, J. Yi, J. Tao, Z. Tian, Z. Wen, S. Zhang, Fast end-to-end speech
recognition via non-autoregressive models and cross-modal knowledge
transferring from bert, IEEE/ACM Transactions on Audio, Speech, and Language
Processing 29 (2021) 1897–1911.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.2.2.1" class="ltx_text" style="color:#000000;">[47]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.4.1" class="ltx_text" style="color:#000000;">
I.-T. Recommendation, Perceptual evaluation of speech quality (pesq): An
objective method for end-to-end speech quality assessment of narrow-band
telephone networks and speech codecs, Rec. ITU-T P. 862 (2001).
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.2.2.1" class="ltx_text" style="color:#000000;">[48]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.4.1" class="ltx_text" style="color:#000000;">
S. Zhang, E. Loweimi, P. Bell, S. Renals, On the usefulness of self-attention
for automatic speech recognition with transformers, in: 2021 IEEE Spoken
Language Technology Workshop (SLT), IEEE, 2021, pp. 89–96.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.2.2.1" class="ltx_text" style="color:#000000;">[49]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.4.1" class="ltx_text" style="color:#000000;">
O. Hrinchuk, M. Popova, B. Ginsburg, Correction of automatic speech recognition
with transformer sequence-to-sequence model, in: Icassp 2020-2020 ieee
international conference on acoustics, speech and signal processing (icassp),
IEEE, 2020, pp. 7074–7078.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.2.2.1" class="ltx_text" style="color:#000000;">[50]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.4.1" class="ltx_text" style="color:#000000;">
J. Li, R. Su, X. Xie, N. Yan, L. Wang, A multi-level acoustic feature
extraction framework for transformer based end-to-end speech recognition,
arXiv preprint arXiv:2108.07980 (2021).
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.2.2.1" class="ltx_text" style="color:#000000;">[51]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.4.1" class="ltx_text" style="color:#000000;">
A. Baade, P. Peng, D. Harwath, Mae-ast: Masked autoencoding audio spectrogram
transformer, arXiv preprint arXiv:2203.16691 (2022).
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.2.2.1" class="ltx_text" style="color:#000000;">[52]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.4.1" class="ltx_text" style="color:#000000;">
J. Bai, J. Chen, M. Wang, M. S. Ayub, Q. Yan, A squeeze-and-excitation and
transformer based cross-task model for environmental sound recognition, IEEE
Transactions on Cognitive and Developmental Systems (2022).
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.2.2.1" class="ltx_text" style="color:#000000;">[53]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.4.1" class="ltx_text" style="color:#000000;">
K. Chen, J. Wang, F. Deng, X. Wang, icnn-transformer: An improved
cnn-transformer with channel-spatial attention and keyword prediction for
automated audio captioning, in: INTERSPEECH, 2022, pp. 4167–4171.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.2.2.1" class="ltx_text" style="color:#000000;">[54]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.4.1" class="ltx_text" style="color:#000000;">
K. Deng, S. Cao, Y. Zhang, L. Ma, Improving hybrid ctc/attention end-to-end
speech recognition with pretrained acoustic and language models, in: 2021
IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), IEEE,
2021, pp. 76–82.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.2.2.1" class="ltx_text" style="color:#000000;">[55]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.4.1" class="ltx_text" style="color:#000000;">
X. Zhou, E. Yılmaz, Y. Long, Y. Li, H. Li, Multi-encoder-decoder transformer
for code-switching speech recognition, arXiv preprint arXiv:2006.10414
(2020).
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.2.2.1" class="ltx_text" style="color:#000000;">[56]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.4.1" class="ltx_text" style="color:#000000;">
G. I. Winata, S. Cahyawijaya, Z. Lin, Z. Liu, P. Fung, Lightweight and
efficient end-to-end speech recognition using low-rank transformer, in:
ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP), IEEE, 2020, pp. 6144–6148.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.2.2.1" class="ltx_text" style="color:#000000;">[57]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.4.1" class="ltx_text" style="color:#000000;">
M.-H. Lee, S.-E. Lee, J.-S. Seong, J.-H. Chang, H. Kwon, C. Park, Regularizing
transformer-based acoustic models by penalizing attention weights for robust
speech recognition, in: Proceedings of the Annual Conference of the
International Speech Communication Association, INTERSPEECH, Vol. 2022,
International Speech Communication Association, 2022, pp. 56–60.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.2.2.1" class="ltx_text" style="color:#000000;">[58]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.4.1" class="ltx_text" style="color:#000000;">
S. R. Shareef, Y. F. Mohammed, Collaborative training of acoustic encoder for
recognizing the impaired children speech, in: 2022 Fifth College of Science
International Conference of Recent Trends in Information Technology (CSCTIT),
IEEE, 2022, pp. 79–85.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.2.2.1" class="ltx_text" style="color:#000000;">[59]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.4.1" class="ltx_text" style="color:#000000;">
R. Fan, W. Chu, P. Chang, A. Alwan, A ctc alignment-based non-autoregressive
transformer for end-to-end automatic speech recognition, IEEE/ACM
Transactions on Audio, Speech, and Language Processing 31 (2023) 1436–1448.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.2.2.1" class="ltx_text" style="color:#000000;">[60]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.4.1" class="ltx_text" style="color:#000000;">
J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep
bidirectional transformers for language understanding (2019).
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1810.04805" title="" class="ltx_ref ltx_href" style="color:#000000;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">arXiv:1810.04805</span></a><span id="bib.bib60.5.1" class="ltx_text" style="color:#000000;">.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.2.2.1" class="ltx_text" style="color:#000000;">[61]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.4.1" class="ltx_text" style="color:#000000;">
C.-C. Chiu, T. N. Sainath, Y. Wu, R. Prabhavalkar, P. Nguyen, Z. Chen,
A. Kannan, R. J. Weiss, K. Rao, E. Gonina, et al., State-of-the-art speech
recognition with sequence-to-sequence models, in: 2018 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2018,
pp. 4774–4778.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.2.2.1" class="ltx_text" style="color:#000000;">[62]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.4.1" class="ltx_text" style="color:#000000;">
Y. Wang, Y. Shi, F. Zhang, C. Wu, J. Chan, C.-F. Yeh, A. Xiao, Transformer in
action: a comparative study of transformer-based acoustic models for large
scale speech recognition applications, in: ICASSP 2021-2021 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
IEEE, 2021, pp. 6778–6782.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.2.2.1" class="ltx_text" style="color:#000000;">[63]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.4.1" class="ltx_text" style="color:#000000;">
A. Aroudi, S. Uhlich, M. F. Font, Trunet: Transformer-recurrent-u network for
multi-channel reverberant sound source separation, arXiv preprint
arXiv:2110.04047 (2021).
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.2.2.1" class="ltx_text" style="color:#000000;">[64]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.4.1" class="ltx_text" style="color:#000000;">
L. Wang, W. Wei, Y. Chen, Y. Hu, D 2 net: A denoising and dereverberation
network based on two-branch encoder and dual-path transformer, in: 2022
Asia-Pacific Signal and Information Processing Association Annual Summit and
Conference (APSIPA ASC), IEEE, 2022, pp. 1649–1654.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib65.2.2.1" class="ltx_text" style="color:#000000;">[65]</span></span>
<span class="ltx_bibblock"><span id="bib.bib65.4.1" class="ltx_text" style="color:#000000;">
P. Swietojanski, S. Braun, D. Can, T. F. Da Silva, A. Ghoshal, T. Hori,
R. Hsiao, H. Mason, E. McDermott, H. Silovsky, et al., Variable attention
masking for configurable transformer transducer speech recognition, in:
ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP), IEEE, 2023, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib66.2.2.1" class="ltx_text" style="color:#000000;">[66]</span></span>
<span class="ltx_bibblock"><span id="bib.bib66.4.1" class="ltx_text" style="color:#000000;">
N. Moritz, G. Wichern, T. Hori, J. Le Roux, All-in-one transformer: Unifying
speech recognition, audio tagging, and event detection., in: INTERSPEECH,
2020, pp. 3112–3116.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib67.2.2.1" class="ltx_text" style="color:#000000;">[67]</span></span>
<span class="ltx_bibblock"><span id="bib.bib67.4.1" class="ltx_text" style="color:#000000;">
W. Huang, W. Hu, Y. T. Yeung, X. Chen, Conv-transformer transducer: Low
latency, low frame rate, streamable end-to-end speech recognition, arXiv
preprint arXiv:2008.05750 (2020).
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib68.2.2.1" class="ltx_text" style="color:#000000;">[68]</span></span>
<span class="ltx_bibblock"><span id="bib.bib68.4.1" class="ltx_text" style="color:#000000;">
R. Fan, W. Chu, P. Chang, J. Xiao, Cass-nat: Ctc alignment-based single step
non-autoregressive transformer for speech recognition, in: ICASSP 2021-2021
IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP), IEEE, 2021, pp. 5889–5893.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib69.2.2.1" class="ltx_text" style="color:#000000;">[69]</span></span>
<span class="ltx_bibblock"><span id="bib.bib69.4.1" class="ltx_text" style="color:#000000;">
M. Hadwan, H. A. Alsayadi, S. AL-Hagree, An end-to-end transformer-based
automatic speech recognition for qur’an reciters., Computers, Materials &amp;
Continua 74 (2) (2023).
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib70.2.2.1" class="ltx_text" style="color:#000000;">[70]</span></span>
<span class="ltx_bibblock"><span id="bib.bib70.4.1" class="ltx_text" style="color:#000000;">
L. Smietanka, T. Maka, Augmented transformer for speech detection in adverse
acoustical conditions, in: 2023 Signal Processing: Algorithms, Architectures,
Arrangements, and Applications (SPA), IEEE, 2023, pp. 14–18.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib71.2.2.1" class="ltx_text" style="color:#000000;">[71]</span></span>
<span class="ltx_bibblock"><span id="bib.bib71.4.1" class="ltx_text" style="color:#000000;">
Y. Li, D. Luo, Adversarial audio detection method based on transformer, in:
2022 International Conference on Machine Learning and Intelligent Systems
Engineering (MLISE), IEEE, 2022, pp. 77–82.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib72.2.2.1" class="ltx_text" style="color:#000000;">[72]</span></span>
<span class="ltx_bibblock"><span id="bib.bib72.4.1" class="ltx_text" style="color:#000000;">
C. Wang, M. Jia, Y. Zhang, L. Li, Parallel-path transformer network for
time-domain monaural speech separation, in: 2023 International Conference on
Cyber-Physical Social Intelligence (ICCSI), IEEE, 2023, pp. 509–514.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib73.2.2.1" class="ltx_text" style="color:#000000;">[73]</span></span>
<span class="ltx_bibblock"><span id="bib.bib73.4.1" class="ltx_text" style="color:#000000;">
Y. Wang, A. Mohamed, D. Le, C. Liu, A. Xiao, J. Mahadeokar, H. Huang,
A. Tjandra, X. Zhang, F. Zhang, et al., Transformer-based acoustic modeling
for hybrid speech recognition, in: ICASSP 2020-2020 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2020,
pp. 6874–6878.
</span>
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib74.2.2.1" class="ltx_text" style="color:#000000;">[74]</span></span>
<span class="ltx_bibblock"><span id="bib.bib74.4.1" class="ltx_text" style="color:#000000;">
K. Wang, B. He, W.-P. Zhu, Tstnn: Two-stage transformer based neural network
for speech enhancement in the time domain, in: ICASSP 2021-2021 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
IEEE, 2021, pp. 7098–7102.
</span>
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib75.2.2.1" class="ltx_text" style="color:#000000;">[75]</span></span>
<span class="ltx_bibblock"><span id="bib.bib75.4.1" class="ltx_text" style="color:#000000;">
Y. Gong, C.-I. Lai, Y.-A. Chung, J. Glass, Ssast: Self-supervised audio
spectrogram transformer, in: Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 36, 2022, pp. 10699–10709.
</span>
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib76.2.2.1" class="ltx_text" style="color:#000000;">[76]</span></span>
<span class="ltx_bibblock"><span id="bib.bib76.4.1" class="ltx_text" style="color:#000000;">
C. Wu, Y. Wang, Y. Shi, C.-F. Yeh, F. Zhang, Streaming transformer-based
acoustic models using self-attention with augmented memory, arXiv preprint
arXiv:2005.08042 (2020).
</span>
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib77.2.2.1" class="ltx_text" style="color:#000000;">[77]</span></span>
<span class="ltx_bibblock"><span id="bib.bib77.4.1" class="ltx_text" style="color:#000000;">
V. Nagaraja, Y. Shi, G. Venkatesh, O. Kalinli, M. L. Seltzer, V. Chandra,
Collaborative training of acoustic encoders for speech recognition, arXiv
preprint arXiv:2106.08960 (2021).
</span>
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib78.2.2.1" class="ltx_text" style="color:#000000;">[78]</span></span>
<span class="ltx_bibblock"><span id="bib.bib78.4.1" class="ltx_text" style="color:#000000;">
G. Ahmed, A. A. Lawaye, T. A. Mir, P. Rana, Toward developing attention-based
end-to-end automatic speech recognition, in: International Conference On
Innovative Computing And Communication, Springer, 2023, pp. 147–161.
</span>
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib79.2.2.1" class="ltx_text" style="color:#000000;">[79]</span></span>
<span class="ltx_bibblock"><span id="bib.bib79.4.1" class="ltx_text" style="color:#000000;">
Y. Himeur, S. Al-Maadeed, H. Kheddar, N. Al-Maadeed, K. Abualsaud, A. Mohamed,
T. Khattab, Video surveillance using deep transfer learning and deep domain
adaptation: Towards better generalization, Engineering Applications of
Artificial Intelligence 119 (2023) 105698.
</span>
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib80.2.2.1" class="ltx_text" style="color:#000000;">[80]</span></span>
<span class="ltx_bibblock"><span id="bib.bib80.4.1" class="ltx_text" style="color:#000000;">
H. Kheddar, M. Hemis, Y. Himeur, D. Megías, A. Amira, Deep learning for
diverse data types steganalysis: A review, arXiv preprint arXiv:2308.04522
(2023).
</span>
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib81.2.2.1" class="ltx_text" style="color:#000000;">[81]</span></span>
<span class="ltx_bibblock"><span id="bib.bib81.4.1" class="ltx_text" style="color:#000000;">
S. Schneider, A. Baevski, R. Collobert, M. Auli, wav2vec: Unsupervised
pre-training for speech recognition, arXiv preprint arXiv:1904.05862 (2019).
</span>
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib82.2.2.1" class="ltx_text" style="color:#000000;">[82]</span></span>
<span class="ltx_bibblock"><span id="bib.bib82.4.1" class="ltx_text" style="color:#000000;">
J. Thienpondt, K. Demuynck, Transfer learning for robust low-resource
children’s speech asr with transformers and source-filter warping, arXiv
preprint arXiv:2206.09396 (2022).
</span>
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib83.2.2.1" class="ltx_text" style="color:#000000;">[83]</span></span>
<span class="ltx_bibblock"><span id="bib.bib83.4.1" class="ltx_text" style="color:#000000;">
Z. Dan, Y. Zhao, X. Bi, L. Wu, Q. Ji, Multi-task transformer with adaptive
cross-entropy loss for multi-dialect speech recognition, Entropy 24 (10)
(2022) 1429.
</span>
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib84.2.2.1" class="ltx_text" style="color:#000000;">[84]</span></span>
<span class="ltx_bibblock"><span id="bib.bib84.4.1" class="ltx_text" style="color:#000000;">
T. Pellegrini, I. Khalfaoui-Hassani, E. Labbé, T. Masquelier, Adapting a
convnext model to audio classification on audioset, arXiv preprint
arXiv:2306.00830 (2023).
</span>
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib85.2.2.1" class="ltx_text" style="color:#000000;">[85]</span></span>
<span class="ltx_bibblock"><span id="bib.bib85.4.1" class="ltx_text" style="color:#000000;">
Y. Xin, D. Yang, Y. Zou, Audio pyramid transformer with domain adaption for
weakly supervised sound event detection and audio classification, in: Proc.
Interspeech 2022, 2022, pp. 1546–1550.
</span>
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib86.2.2.1" class="ltx_text" style="color:#000000;">[86]</span></span>
<span class="ltx_bibblock"><span id="bib.bib86.4.1" class="ltx_text" style="color:#000000;">
J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of deep
bidirectional transformers for language understanding, arXiv preprint
arXiv:1810.04805 (2018).
</span>
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib87.2.2.1" class="ltx_text" style="color:#000000;">[87]</span></span>
<span class="ltx_bibblock"><span id="bib.bib87.4.1" class="ltx_text" style="color:#000000;">
Y. Song, D. Jiang, X. Zhao, Q. Xu, R. C.-W. Wong, L. Fan, Q. Yang, L2rs: a
learning-to-rescore mechanism for automatic speech recognition, arXiv
preprint arXiv:1910.11496 (2019).
</span>
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib88.2.2.1" class="ltx_text" style="color:#000000;">[88]</span></span>
<span class="ltx_bibblock"><span id="bib.bib88.4.1" class="ltx_text" style="color:#000000;">
C.-X. Qin, D. Qu, L.-H. Zhang, Towards end-to-end speech recognition with
transfer learning, EURASIP Journal on Audio, Speech, and Music Processing
2018 (1) (2018) 1–9.
</span>
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib89.2.2.1" class="ltx_text" style="color:#000000;">[89]</span></span>
<span class="ltx_bibblock"><span id="bib.bib89.4.1" class="ltx_text" style="color:#000000;">
D. Jiang, C. Tan, J. Peng, C. Chen, X. Wu, W. Zhao, Y. Song, Y. Tong, C. Liu,
Q. Xu, et al., A gdpr-compliant ecosystem for speech recognition with
transfer, federated, and evolutionary learning, ACM Transactions on
Intelligent Systems and Technology (TIST) 12 (3) (2021) 1–19.
</span>
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib90.2.2.1" class="ltx_text" style="color:#000000;">[90]</span></span>
<span class="ltx_bibblock"><span id="bib.bib90.4.1" class="ltx_text" style="color:#000000;">
F. Weninger, J. Andrés-Ferrer, X. Li, P. Zhan, Listen, attend, spell and
adapt: Speaker adapted sequence-to-sequence asr, arXiv preprint
arXiv:1907.04916 (2019).
</span>
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib91.2.2.1" class="ltx_text" style="color:#000000;">[91]</span></span>
<span class="ltx_bibblock"><span id="bib.bib91.4.1" class="ltx_text" style="color:#000000;">
S. Deena, M. Hasan, M. Doulaty, O. Saz, T. Hain, Recurrent neural network
language model adaptation for multi-genre broadcast speech recognition and
alignment, IEEE/ACM Transactions on Audio, Speech, and Language Processing
27 (3) (2018) 572–582.
</span>
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib92.2.2.1" class="ltx_text" style="color:#000000;">[92]</span></span>
<span class="ltx_bibblock"><span id="bib.bib92.4.1" class="ltx_text" style="color:#000000;">
S.-I. Ng, W. Liu, Z. Peng, S. Feng, H.-P. Huang, O. Scharenborg, T. Lee, The
cuhk-tudelft system for the slt 2021 children speech recognition challenge,
arXiv preprint arXiv:2011.06239 (2020).
</span>
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib93.2.2.1" class="ltx_text" style="color:#000000;">[93]</span></span>
<span class="ltx_bibblock"><span id="bib.bib93.4.1" class="ltx_text" style="color:#000000;">
K. Manohar, G. G. Menon, A. Abraham, R. Rajan, A. Jayan, Automatic recognition
of continuous malayalam speech using pretrained multilingual transformers,
in: 2023 International Conference on Intelligent Systems for Communication,
IoT and Security (ICISCoIS), IEEE, 2023, pp. 671–675.
</span>
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib94.2.2.1" class="ltx_text" style="color:#000000;">[94]</span></span>
<span class="ltx_bibblock"><span id="bib.bib94.4.1" class="ltx_text" style="color:#000000;">
J. Cho, M. K. Baskar, R. Li, M. Wiesner, S. H. Mallidi, N. Yalta, M. Karafiat,
S. Watanabe, T. Hori, Multilingual sequence-to-sequence speech recognition:
architecture, transfer learning, and language modeling, in: 2018 IEEE Spoken
Language Technology Workshop (SLT), IEEE, 2018, pp. 521–527.
</span>
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib95.2.2.1" class="ltx_text" style="color:#000000;">[95]</span></span>
<span class="ltx_bibblock"><span id="bib.bib95.4.1" class="ltx_text" style="color:#000000;">
K. Li, Y. Song, I. McLoughlin, L. Liu, J. Li, L.-R. Dai, Fine-tuning audio
spectrogram transformer with task-aware adapters for sound event detection.
</span>
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib96.2.2.1" class="ltx_text" style="color:#000000;">[96]</span></span>
<span class="ltx_bibblock"><span id="bib.bib96.4.1" class="ltx_text" style="color:#000000;">
C. Wang, S. Dai, Y. Wang, F. Yang, M. Qiu, K. Chen, W. Zhou, J. Huang, Arobert:
An asr robust pre-trained language model for spoken language understanding,
IEEE/ACM Transactions on Audio, Speech, and Language Processing (2022).
</span>
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib97.2.2.1" class="ltx_text" style="color:#000000;">[97]</span></span>
<span class="ltx_bibblock"><span id="bib.bib97.4.1" class="ltx_text" style="color:#000000;">
Y. Himeur, I. Varlamis, H. Kheddar, A. Amira, S. Atalla, Y. Singh, F. Bensaali,
W. Mansoor, Federated learning for computer vision, arXiv preprint
arXiv:2308.13558 (2023).
</span>
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib98.2.2.1" class="ltx_text" style="color:#000000;">[98]</span></span>
<span class="ltx_bibblock"><span id="bib.bib98.4.1" class="ltx_text" style="color:#000000;">
D. Dimitriadis, R. G. Ken’ichi Kumatani, R. Gmyr, Y. Gaur, S. E. Eskimez, A
federated approach in training acoustic models., in: Interspeech, 2020, pp.
981–985.
</span>
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib99.2.2.1" class="ltx_text" style="color:#000000;">[99]</span></span>
<span class="ltx_bibblock"><span id="bib.bib99.4.1" class="ltx_text" style="color:#000000;">
D. Guliani, F. Beaufays, G. Motta, Training speech recognition models with
federated learning: A quality/cost framework, in: ICASSP 2021-2021 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
IEEE, 2021, pp. 3080–3084.
</span>
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib100.2.2.1" class="ltx_text" style="color:#000000;">[100]</span></span>
<span class="ltx_bibblock"><span id="bib.bib100.4.1" class="ltx_text" style="color:#000000;">
H. Zhu, J. Wang, G. Cheng, P. Zhang, Y. Yan, Decoupled federated learning for
asr with non-iid data, arXiv preprint arXiv:2206.09102 (2022).
</span>
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib101.2.2.1" class="ltx_text" style="color:#000000;">[101]</span></span>
<span class="ltx_bibblock"><span id="bib.bib101.4.1" class="ltx_text" style="color:#000000;">
X. Cui, S. Lu, B. Kingsbury, Federated acoustic modeling for automatic speech
recognition, in: ICASSP 2021-2021 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), IEEE, 2021, pp. 6748–6752.
</span>
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib102.2.2.1" class="ltx_text" style="color:#000000;">[102]</span></span>
<span class="ltx_bibblock"><span id="bib.bib102.4.1" class="ltx_text" style="color:#000000;">
T. Nguyen, S. Mdhaffar, N. Tomashenko, J.-F. Bonastre, Y. Estève, Federated
learning for asr based on wav2vec 2.0, in: ICASSP 2023-2023 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
IEEE, 2023, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib103.2.2.1" class="ltx_text" style="color:#000000;">[103]</span></span>
<span class="ltx_bibblock"><span id="bib.bib103.4.1" class="ltx_text" style="color:#000000;">
C.-H. H. Yang, J. Qi, S. Y.-C. Chen, P.-Y. Chen, S. M. Siniscalchi, X. Ma,
C.-H. Lee, Decentralizing feature extraction with quantum convolutional
neural network for automatic speech recognition, in: ICASSP 2021-2021 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
IEEE, 2021, pp. 6523–6527.
</span>
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib104.2.2.1" class="ltx_text" style="color:#000000;">[104]</span></span>
<span class="ltx_bibblock"><span id="bib.bib104.4.1" class="ltx_text" style="color:#000000;">
Y. Gao, T. Parcollet, S. Zaiem, J. Fernandez-Marques, P. P. de Gusmao, D. J.
Beutel, N. D. Lane, End-to-end speech recognition from federated acoustic
models, in: ICASSP 2022-2022 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), IEEE, 2022, pp. 7227–7231.
</span>
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib105.2.2.1" class="ltx_text" style="color:#000000;">[105]</span></span>
<span class="ltx_bibblock"><span id="bib.bib105.4.1" class="ltx_text" style="color:#000000;">
H. Mehmood, A. Dobrowolska, K. Saravanan, M. Ozay, Fednst: Federated noisy
student training for automatic speech recognition, arXiv preprint
arXiv:2206.02797 (2022).
</span>
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib106.2.2.1" class="ltx_text" style="color:#000000;">[106]</span></span>
<span class="ltx_bibblock"><span id="bib.bib106.4.1" class="ltx_text" style="color:#000000;">
J. C. Vásquez-Correa, A. Álvarez Muniain, Novel speech recognition
systems applied to forensics within child exploitation: Wav2vec2. 0 vs.
whisper, Sensors 23 (4) (2023) 1843.
</span>
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib107.2.2.1" class="ltx_text" style="color:#000000;">[107]</span></span>
<span class="ltx_bibblock"><span id="bib.bib107.4.1" class="ltx_text" style="color:#000000;">
C. Tan, D. Jiang, H. Mo, J. Peng, Y. Tong, W. Zhao, C. Chen, R. Lian, Y. Song,
Q. Xu, Federated acoustic model optimization for automatic speech
recognition, in: Database Systems for Advanced Applications: 25th
International Conference, DASFAA 2020, Jeju, South Korea, September 24–27,
2020, Proceedings, Part III 25, Springer, 2020, pp. 771–774.
</span>
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib108.2.2.1" class="ltx_text" style="color:#000000;">[108]</span></span>
<span class="ltx_bibblock"><span id="bib.bib108.4.1" class="ltx_text" style="color:#000000;">
N. Tomashenko, S. Mdhaffar, M. Tommasi, Y. Estève, J.-F. Bonastre, Privacy
attacks for automatic speech recognition acoustic models in a federated
learning framework, in: ICASSP 2022-2022 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2022, pp. 6972–6976.
</span>
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib109.2.2.1" class="ltx_text" style="color:#000000;">[109]</span></span>
<span class="ltx_bibblock"><span id="bib.bib109.4.1" class="ltx_text" style="color:#000000;">
D. Guliani, L. Zhou, C. Ryu, T.-J. Yang, H. Zhang, Y. Xiao, F. Beaufays,
G. Motta, Enabling on-device training of speech recognition models with
federated dropout, in: ICASSP 2022-2022 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2022, pp. 8757–8761.
</span>
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib110.2.2.1" class="ltx_text" style="color:#000000;">[110]</span></span>
<span class="ltx_bibblock"><span id="bib.bib110.4.1" class="ltx_text" style="color:#000000;">
C. Chen, Y. Hu, N. Hou, X. Qi, H. Zou, E. S. Chng, Self-critical sequence
training for automatic speech recognition, in: ICASSP 2022-2022 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
IEEE, 2022, pp. 3688–3692.
</span>
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib111.2.2.1" class="ltx_text" style="color:#000000;">[111]</span></span>
<span class="ltx_bibblock"><span id="bib.bib111.4.1" class="ltx_text" style="color:#000000;">
T. Kala, T. Shinozaki, Reinforcement learning of speech recognition system
based on policy gradient and hypothesis selection, in: 2018 IEEE
international conference on acoustics, speech and signal processing (ICASSP),
IEEE, 2018, pp. 5759–5763.
</span>
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib112.2.2.1" class="ltx_text" style="color:#000000;">[112]</span></span>
<span class="ltx_bibblock"><span id="bib.bib112.4.1" class="ltx_text" style="color:#000000;">
A. Tjandra, S. Sakti, S. Nakamura, Sequence-to-sequence asr optimization via
reinforcement learning, in: 2018 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), IEEE, 2018, pp. 5829–5833.
</span>
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib113.2.2.1" class="ltx_text" style="color:#000000;">[113]</span></span>
<span class="ltx_bibblock"><span id="bib.bib113.4.1" class="ltx_text" style="color:#000000;">
A. Tjandra, S. Sakti, S. Nakamura, End-to-end speech recognition sequence
training with reinforcement learning, IEEE Access 7 (2019) 79758–79769.
</span>
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib114.2.2.1" class="ltx_text" style="color:#000000;">[114]</span></span>
<span class="ltx_bibblock"><span id="bib.bib114.4.1" class="ltx_text" style="color:#000000;">
Ł. Dudziak, M. S. Abdelfattah, R. Vipperla, S. Laskaridis, N. D. Lane,
Shrinkml: End-to-end asr model compression using reinforcement learning,
arXiv preprint arXiv:1907.03540 (2019).
</span>
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib115.2.2.1" class="ltx_text" style="color:#000000;">[115]</span></span>
<span class="ltx_bibblock"><span id="bib.bib115.4.1" class="ltx_text" style="color:#000000;">
A. Mehrotra, Ł. Dudziak, J. Yeo, Y.-y. Lee, R. Vipperla, M. S. Abdelfattah,
S. Bhattacharya, S. Ishtiaq, A. G. C. Ramos, S. Lee, et al., Iterative
compression of end-to-end asr model using automl, arXiv preprint
arXiv:2008.02897 (2020).
</span>
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib116.2.2.1" class="ltx_text" style="color:#000000;">[116]</span></span>
<span class="ltx_bibblock"><span id="bib.bib116.4.1" class="ltx_text" style="color:#000000;">
Y.-L. Shen, C.-Y. Huang, S.-S. Wang, Y. Tsao, H.-M. Wang, T.-S. Chi,
Reinforcement learning based speech enhancement for robust speech
recognition, in: ICASSP 2019-2019 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), IEEE, 2019, pp. 6750–6754.
</span>
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib117.2.2.1" class="ltx_text" style="color:#000000;">[117]</span></span>
<span class="ltx_bibblock"><span id="bib.bib117.4.1" class="ltx_text" style="color:#000000;">
R. T.-H. Tsai, C.-H. Chen, C.-K. Wu, Y.-C. Hsiao, H.-y. Lee, Using deep-q
network to select candidates from n-best speech recognition hypotheses for
enhancing dialogue state tracking, in: ICASSP 2019-2019 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2019,
pp. 7375–7379.
</span>
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib118.2.2.1" class="ltx_text" style="color:#000000;">[118]</span></span>
<span class="ltx_bibblock"><span id="bib.bib118.4.1" class="ltx_text" style="color:#000000;">
H. Chung, H.-B. Jeon, J. G. Park, Semi-supervised training for
sequence-to-sequence speech recognition using reinforcement learning, in:
2020 international joint conference on neural networks (IJCNN), IEEE, 2020,
pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib119.2.2.1" class="ltx_text" style="color:#000000;">[119]</span></span>
<span class="ltx_bibblock"><span id="bib.bib119.4.1" class="ltx_text" style="color:#000000;">
Z. Chen, W. Zhang, End-to-end speech recognition with reinforcement learning,
in: Eighth International Conference on Electronic Technology and Information
Science (ICETIS 2023), Vol. 12715, SPIE, 2023, pp. 392–398.
</span>
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib120.2.2.1" class="ltx_text" style="color:#000000;">[120]</span></span>
<span class="ltx_bibblock"><span id="bib.bib120.4.1" class="ltx_text" style="color:#000000;">
A. Hamza, D. Addou, H. Kheddar, Machine learning approaches for automated
detection and classification of dysarthria severity, in: 2023 2nd
International Conference on Electronics, Energy and Measurement (IC2EM),
Vol. 1, IEEE, 2023, pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib121.2.2.1" class="ltx_text" style="color:#000000;">[121]</span></span>
<span class="ltx_bibblock"><span id="bib.bib121.4.1" class="ltx_text" style="color:#000000;">
S. Feng, B. M. Halpern, O. Kudina, O. Scharenborg, Towards inclusive automatic
speech recognition, Computer Speech &amp; Language 84 (2024) 101567.
</span>
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib122.2.2.1" class="ltx_text" style="color:#000000;">[122]</span></span>
<span class="ltx_bibblock"><span id="bib.bib122.4.1" class="ltx_text" style="color:#000000;">
Z. Zhou, J. Chen, N. Wang, L. Li, D. Wang, Adversarial data augmentation for
robust speaker verification, arXiv preprint arXiv:2402.02699 (2024).
</span>
</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib123.2.2.1" class="ltx_text" style="color:#000000;">[123]</span></span>
<span class="ltx_bibblock"><span id="bib.bib123.4.1" class="ltx_text" style="color:#000000;">
Adastreamlite: Environment-adaptive streaming speech recognition on mobile
devices, Proceedings of the ACM on Interactive, Mobile, Wearable and
Ubiquitous Technologies 7 (4) (2024) 1–29.
</span>
</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib124.2.2.1" class="ltx_text" style="color:#000000;">[124]</span></span>
<span class="ltx_bibblock"><span id="bib.bib124.4.1" class="ltx_text" style="color:#000000;">
J. H. Yeo, M. Kim, J. Choi, D. H. Kim, Y. M. Ro, Akvsr: Audio knowledge
empowered visual speech recognition by compressing audio knowledge of a
pretrained model, IEEE Transactions on Multimedia (2024).
</span>
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib125.2.2.1" class="ltx_text" style="color:#000000;">[125]</span></span>
<span class="ltx_bibblock"><span id="bib.bib125.4.1" class="ltx_text" style="color:#000000;">
N. Djeffal, D. Addou, H. Kheddar, S. A. Selouani, Noise-robust speech
recognition: A comparative analysis of lstm and cnn approaches, in: 2023 2nd
International Conference on Electronics, Energy and Measurement (IC2EM),
Vol. 1, IEEE, 2023, pp. 1–6.
</span>
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib126.2.2.1" class="ltx_text" style="color:#000000;">[126]</span></span>
<span class="ltx_bibblock"><span id="bib.bib126.4.1" class="ltx_text" style="color:#000000;">
Q. Zhao, L. Yang, N. Lyu, A driver stress detection model via data augmentation
based on deep convolutional recurrent neural network, Expert Systems with
Applications 238 (2024) 122056.
</span>
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib127.2.2.1" class="ltx_text" style="color:#000000;">[127]</span></span>
<span class="ltx_bibblock"><span id="bib.bib127.4.1" class="ltx_text" style="color:#000000;">
Z. Jin, M. Geng, J. Deng, T. Wang, S. Hu, G. Li, X. Liu, Personalized
adversarial data augmentation for dysarthric and elderly speech recognition,
IEEE/ACM Transactions on Audio, Speech, and Language Processing (2023).
</span>
</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib128.2.2.1" class="ltx_text" style="color:#000000;">[128]</span></span>
<span class="ltx_bibblock"><span id="bib.bib128.4.1" class="ltx_text" style="color:#000000;">
A. Brack, E. Entrup, M. Stamatakis, P. Buschermöhle, A. Hoppe, R. Ewerth,
Sequential sentence classification in research papers using cross-domain
multi-task learning, International Journal on Digital Libraries (2024) 1–24.
</span>
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib129.2.2.1" class="ltx_text" style="color:#000000;">[129]</span></span>
<span class="ltx_bibblock"><span id="bib.bib129.4.1" class="ltx_text" style="color:#000000;">
H. Zhang, M. Tao, Y. Shi, X. Bi, K. B. Letaief, Federated multi-task learning
with non-stationary and heterogeneous data in wireless networks, IEEE
Transactions on Wireless Communications (2023).
</span>
</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib130.2.2.1" class="ltx_text" style="color:#000000;">[130]</span></span>
<span class="ltx_bibblock"><span id="bib.bib130.4.1" class="ltx_text" style="color:#000000;">
A. Singh, S. Chandrasekar, T. Sen, S. Saha, Federated multi-task learning for
complaint identification using graph attention network, IEEE Transactions on
Artificial Intelligence (2023).
</span>
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib131.2.2.1" class="ltx_text" style="color:#000000;">[131]</span></span>
<span class="ltx_bibblock"><span id="bib.bib131.4.1" class="ltx_text" style="color:#000000;">
X. Jiang, J. Zhang, L. Zhang, Fedradar: Federated multi-task transfer learning
for radar-based internet of medical things, IEEE Transactions on Network and
Service Management (2023).
</span>
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib132.2.2.1" class="ltx_text" style="color:#000000;">[132]</span></span>
<span class="ltx_bibblock"><span id="bib.bib132.4.1" class="ltx_text" style="color:#000000;">
B. Azadi, M. Haslgrübler, B. Anzengruber-Tanase, G. Sopidis, A. Ferscha,
Robust feature representation using multi-task learning for human activity
recognition, Sensors 24 (2) (2024) 681.
</span>
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib133.2.2.1" class="ltx_text" style="color:#000000;">[133]</span></span>
<span class="ltx_bibblock"><span id="bib.bib133.4.1" class="ltx_text" style="color:#000000;">
J. Ji, Z. Shu, H. Li, K. X. Lai, M. Lu, G. Jiang, W. Wang, Y. Zheng, X. Jiang,
Edge-computing based knowledge distillation and multi-task learning for
partial discharge recognition, IEEE Transactions on Instrumentation and
Measurement (2024).
</span>
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib134.2.2.1" class="ltx_text" style="color:#000000;">[134]</span></span>
<span class="ltx_bibblock"><span id="bib.bib134.4.1" class="ltx_text" style="color:#000000;">
R. Šajina, N. Tanković, I. Ipšić, Multi-task peer-to-peer
learning using an encoder-only transformer model, Future Generation Computer
Systems 152 (2024) 170–178.
</span>
</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib135.2.2.1" class="ltx_text" style="color:#000000;">[135]</span></span>
<span class="ltx_bibblock"><span id="bib.bib135.4.1" class="ltx_text" style="color:#000000;">
C. Ye, H. Zheng, Z. Hu, M. Zheng, Pfedsa: Personalized federated multi-task
learning via similarity awareness, in: 2023 IEEE International Parallel and
Distributed Processing Symposium (IPDPS), IEEE, 2023, pp. 480–488.
</span>
</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib136.2.2.1" class="ltx_text" style="color:#000000;">[136]</span></span>
<span class="ltx_bibblock"><span id="bib.bib136.4.1" class="ltx_text" style="color:#000000;">
Z. Wang, C. Chen, D. Dong, Lifelong incremental reinforcement learning with
online bayesian inference, IEEE Transactions on Neural Networks and Learning
Systems 33 (8) (2021) 4003–4016.
</span>
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib137.2.2.1" class="ltx_text" style="color:#000000;">[137]</span></span>
<span class="ltx_bibblock"><span id="bib.bib137.4.1" class="ltx_text" style="color:#000000;">
J. Wang, J. Cao, S. Wang, Z. Yao, W. Li, Irda: Incremental reinforcement
learning for dynamic resource allocation, IEEE Transactions on Big Data 8 (3)
(2020) 770–783.
</span>
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib138.2.2.1" class="ltx_text" style="color:#000000;">[138]</span></span>
<span class="ltx_bibblock"><span id="bib.bib138.4.1" class="ltx_text" style="color:#000000;">
Z. Wang, C. Chen, H.-X. Li, D. Dong, T.-J. Tarn, Incremental reinforcement
learning with prioritized sweeping for dynamic environments, IEEE/ASME
Transactions on Mechatronics 24 (2) (2019) 621–632.
</span>
</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib139.2.2.1" class="ltx_text" style="color:#000000;">[139]</span></span>
<span class="ltx_bibblock"><span id="bib.bib139.4.1" class="ltx_text" style="color:#000000;">
A. Gueriani, H. Kheddar, A. C. Mazari, Deep reinforcement learning for
intrusion detection in iot: A survey, in: 2023 2nd International Conference
on Electronics, Energy and Measurement (IC2EM), Vol. 1, IEEE, 2023, pp. 1–7.
</span>
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib140.2.2.1" class="ltx_text" style="color:#000000;">[140]</span></span>
<span class="ltx_bibblock"><span id="bib.bib140.4.1" class="ltx_text" style="color:#000000;">
P. Zhao, S. C. Hoi, J. Wang, B. Li, Online transfer learning, Artificial
intelligence 216 (2014) 76–102.
</span>
</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib141.2.2.1" class="ltx_text" style="color:#000000;">[141]</span></span>
<span class="ltx_bibblock"><span id="bib.bib141.4.1" class="ltx_text" style="color:#000000;">
Q. Wu, H. Wu, X. Zhou, M. Tan, Y. Xu, Y. Yan, T. Hao, Online transfer learning
with multiple homogeneous or heterogeneous sources, IEEE Transactions on
Knowledge and Data Engineering 29 (7) (2017) 1494–1507.
</span>
</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib142.2.2.1" class="ltx_text" style="color:#000000;">[142]</span></span>
<span class="ltx_bibblock"><span id="bib.bib142.4.1" class="ltx_text" style="color:#000000;">
H. Wu, Y. Yan, Y. Ye, H. Min, M. K. Ng, Q. Wu, Online heterogeneous transfer
learning by knowledge transition, ACM Transactions on Intelligent Systems and
Technology (TIST) 10 (3) (2019) 1–19.
</span>
</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib143.2.2.1" class="ltx_text" style="color:#000000;">[143]</span></span>
<span class="ltx_bibblock"><span id="bib.bib143.4.1" class="ltx_text" style="color:#000000;">
R. Alasbahi, X. Zheng, An online transfer learning framework with extreme
learning machine for automated credit scoring, IEEE Access 10 (2022)
46697–46716.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/ACCESS.2022.3171569" title="" class="ltx_ref ltx_href" style="color:#000000;"><span class="ltx_ref ltx_nolink ltx_path ltx_font_typewriter">doi:10.1109/ACCESS.2022.3171569</span></a><span id="bib.bib143.5.1" class="ltx_text" style="color:#000000;">.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.01254" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.01255" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.01255">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.01255" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.01258" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 15:24:13 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
