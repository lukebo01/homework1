<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.15835] dMel: Speech Tokenization made Simple</title><meta property="og:description" content="Large language models have revolutionized natural language processing by leveraging self-supervised pretraining on vast textual data.
Inspired by this success, researchers have investigated complicated speech tokenizatâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="dMel: Speech Tokenization made Simple">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="dMel: Speech Tokenization made Simple">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.15835">

<!--Generated on Mon Aug  5 17:54:19 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
<span id="id1.id1" class="ltx_text ltx_font_typewriter">dMel</span>: Speech Tokenization made Simple</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">He Bai 
<br class="ltx_break">Apple
<br class="ltx_break"><span id="id2.1.id1" class="ltx_text ltx_font_typewriter">hbai22@apple.com</span> 
<br class="ltx_break">&amp;Tatiana Likhomanenko 
<br class="ltx_break">Apple 
<br class="ltx_break"><span id="id3.2.id2" class="ltx_text ltx_font_typewriter">antares@apple.com</span> 
<br class="ltx_break">&amp;Ruixiang Zhang 
<br class="ltx_break">Apple 
<br class="ltx_break"><span id="id4.3.id3" class="ltx_text ltx_font_typewriter">ruixiangz@apple.com</span> 
<br class="ltx_break">&amp;Zijin Gu 
<br class="ltx_break">Apple 
<br class="ltx_break"><span id="id5.4.id4" class="ltx_text ltx_font_typewriter">zgu26@apple.com</span> 
<br class="ltx_break">&amp;Zakaria Aldeneh 
<br class="ltx_break">Apple 
<br class="ltx_break"><span id="id6.5.id5" class="ltx_text ltx_font_typewriter">zaldeneh@apple.com</span>
&amp;Navdeep Jaitly 
<br class="ltx_break">Apple 
<br class="ltx_break"><span id="id7.6.id6" class="ltx_text ltx_font_typewriter">njaitly@apple.com</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">Large language models have revolutionized natural language processing by leveraging self-supervised pretraining on vast textual data.
Inspired by this success, researchers have investigated complicated speech tokenization methods to discretize continuous speech signals so that language modeling techniques can be applied to speech data.
However, existing approaches either model semantic tokens, potentially losing acoustic information, or model acoustic tokens, risking the loss of semantic information.
Having multiple token types also complicates the architecture and requires additional pretraining.
Here we show that discretizing mel-filterbank channels into discrete intensity bins produces a simple representation (<span id="id8.id1.1" class="ltx_text ltx_font_typewriter">dMel</span>), that performs better than other existing speech tokenization methods.
Using a transformer decoder-only architecture for speech-text modeling, we comprehensively evaluate different speech tokenization methods on speech recognition (ASR) and speech synthesis (TTS).
Our results demonstrate the effectiveness of <span id="id8.id1.2" class="ltx_text ltx_font_typewriter">dMel</span> in achieving high performance on both tasks within a unified framework, paving the way for efficient and effective joint modeling of speech and text. Our code will be published soon.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Large language models (LLMs) have achieved remarkable success in various natural language processing tasks by leveraging self-supervised pretraining on massive amounts of textual dataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
Inspired by this success, numerous worksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> have sought to extend the language modeling approach to speech processing, aiming to build unified models capable of both speech understanding and generation tasks.
However, a key challenge lies in the continuous nature of speech signals, necessitating effective tokenization methods to discretize the input for language model-based processing.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Current speech tokenization approaches can be broadly categorized into two types: semantic tokens and acoustic tokens.
Semantic tokens, extracted from self-supervised (SSL) pretrained speech modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, where the speech signal is first encoded into speech representations and then clustered into semantic tokens with <math id="S1.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S1.p2.1.m1.1a"><mi id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><ci id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">k</annotation></semantics></math>-means method.
However, such SSL pretrained models are not useful for high fidelity speech synthesis as speaker identity and other details of raw speech are lost in trainingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
Conversely, acoustic tokens can be obtained from audio compression models that are trained to compress the speech signal into codebook indices with residual vector quantizationÂ (RVQ) and reconstruction objectivesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
These tokens prioritize acoustic reconstruction but lose semantic information which can lead to poorer results in generating audioÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To combine the advantages of both semantic and acoustic tokens, AudioLMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> proposed to model both semantic tokens and acoustic tokens with 3 stages: semantic modeling, coarse acoustic modeling, and fine acoustic modeling.
The coarse-to-fine modeling strategy is designed to match the residual structure of RVQ based acoustic tokens.
This solution addresses both content and speech quality, but its multi-stage hierarchical structure complicates the model and can lead to slower training and inference.
Another solution is to combine the semantic and acoustic features together. <cite class="ltx_cite ltx_citemacro_citet">Zhang etÂ al. [<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> proposed to distill the semantic tokens into the acoustic tokenâ€™s first residual channel during the training of the RVQ model in a teacher-student manner.
In this way, they showed that the new feature can preserve the semantic information better and also reconstruct high quality speech signals.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we raise the following fundamental question â€“ <span id="S1.p4.1.1" class="ltx_text ltx_font_bold ltx_font_italic">do we really need to separate speech into semantic and acoustic tokens first, and process them with idiosyncratic architectures ?</span>
We propose a simple alternative called <span id="S1.p4.1.2" class="ltx_text ltx_font_typewriter">dMel</span> (see FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) that discretizes mel-filterbanks energies directly into ordinal bins. Intriguingly, we find that discretizing Mel spectrograms has little impact on the ability of off-the-shelf mel-filterbank vocoders to reconstruct waveforms.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We used vocoders from <a target="_blank" href="https://github.com/kan-bayashi/ParallelWaveGAN." title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kan-bayashi/ParallelWaveGAN.</a></span></span></span></p>
</div>
<figure id="S1.T1" class="ltx_table ltx_align_floatright">
<figcaption class="ltx_caption" style="font-size:50%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Impact of discretization.</figcaption>
<table id="S1.T1.3" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.3.1" class="ltx_tr">
<td id="S1.T1.3.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S1.T1.3.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S1.T1.3.1.2.1" class="ltx_text" style="font-size:50%;">WER of Reconstruction</span></td>
</tr>
<tr id="S1.T1.3.2" class="ltx_tr">
<td id="S1.T1.3.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S1.T1.3.2.1.1" class="ltx_text" style="font-size:50%;">Ground-truth</span></td>
<td id="S1.T1.3.2.2" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S1.T1.3.2.2.1" class="ltx_text" style="font-size:50%;">2.02</span></td>
</tr>
<tr id="S1.T1.3.3" class="ltx_tr">
<td id="S1.T1.3.3.1" class="ltx_td ltx_border_t"></td>
<td id="S1.T1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.3.3.2.1" class="ltx_text" style="font-size:50%;">Parallel-WavGAN</span></td>
<td id="S1.T1.3.3.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S1.T1.3.3.3.1" class="ltx_text" style="font-size:50%;">HifiGAN</span></td>
</tr>
<tr id="S1.T1.3.4" class="ltx_tr">
<td id="S1.T1.3.4.1" class="ltx_td ltx_align_left"><span id="S1.T1.3.4.1.1" class="ltx_text" style="font-size:50%;">Mel</span></td>
<td id="S1.T1.3.4.2" class="ltx_td ltx_align_center"><span id="S1.T1.3.4.2.1" class="ltx_text" style="font-size:50%;">2.13</span></td>
<td id="S1.T1.3.4.3" class="ltx_td ltx_align_right"><span id="S1.T1.3.4.3.1" class="ltx_text" style="font-size:50%;">2.08</span></td>
</tr>
<tr id="S1.T1.3.5" class="ltx_tr">
<td id="S1.T1.3.5.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S1.T1.3.5.1.1" class="ltx_text ltx_font_typewriter" style="font-size:50%;">dMel</span></td>
<td id="S1.T1.3.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S1.T1.3.5.2.1" class="ltx_text" style="font-size:50%;">2.23</span></td>
<td id="S1.T1.3.5.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S1.T1.3.5.3.1" class="ltx_text" style="font-size:50%;">2.11</span></td>
</tr>
</table>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In TableÂ <a href="#S1.T1" title="Table 1 â€£ 1 Introduction â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> we use two different vocoders to reconstruct waveforms from mel-filterbanks (Mel) and discretized mel-filterbanks (<span id="S1.p5.1.1" class="ltx_text ltx_font_typewriter">dMel</span>) computed on them. We find that the word error rate (WER) of an ASR system run on the reconstructed waveforms, is quite similar to the WER of the same system run on the ground-truth audio
showing that discretizing Mel has limited impact on information content.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">By operating on the mel-filterbanks and preserving the frequency and intensity information (with some loss of resolution from discretization), <span id="S1.p6.1.1" class="ltx_text ltx_font_typewriter">dMel</span> <span id="S1.p6.1.2" class="ltx_text ltx_font_italic">inherently preserves both semantic and acoustic information in a unified representation</span>, without the need for separate tokenization or additional pretraining of a tokenization model. There are many advantages to discretizing mel-filterbanks:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Mel-filterbanks is an interpretable representation of speech signal, where both the semantic and acoustic information is preserved and discretization has little impact.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> is a <span id="S1.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">model-free representation grounded in raw acoustic space</span>. As a result it can be converted to waveforms by any mel-filterbank vocoder, unlike other tokenization schemes that have feature representations that are intricately coupled to both the encoder and the decoder.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Different channels of <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> do not have the complex hierarchical dependencies on each other that is typical of coarse-to-fine acoustic tokens; we find that they can be <span id="S1.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">modeled independently</span> in each frame using a simple decoder-only transformer architecture.</p>
</div>
</li>
</ul>
<p id="S1.p6.2" class="ltx_p">Through comprehensive evaluations, we show that using <span id="S1.p6.2.1" class="ltx_text ltx_font_typewriter">dMel</span> allows us to use a single decoder-only model, and achieve high performance on both ASR and TTS tasks.
The ASR task validates that <span id="S1.p6.2.2" class="ltx_text ltx_font_typewriter">dMel</span> preserves semantic information, while the TTS task shows that <span id="S1.p6.2.3" class="ltx_text ltx_font_typewriter">dMel</span> are useful for high-fidelity acoustic reconstruction of speech.
We also compare <span id="S1.p6.2.4" class="ltx_text ltx_font_typewriter">dMel</span> to other tokenization methods and find that <span id="S1.p6.2.5" class="ltx_text ltx_font_typewriter">dMel</span> achieves the best WER for ASR task, which indicates that the semantic information is well preserved.
Also, <span id="S1.p6.2.6" class="ltx_text ltx_font_typewriter">dMel</span> achieves the lower WER score for TTS task when using WhisperXÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> for automatic evaluation and we find model trained with <span id="S1.p6.2.7" class="ltx_text ltx_font_typewriter">dMel</span> can generate long and natural speech samples (See Supplementary Material).</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2407.15835/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="233" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Prior works on speech tokenization use either heavy self-supervised pretrained encodersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> to extract semantic tokens (and train a separate decoder for it)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> or learn compression encoder-decoder models with residual vector quantizationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> to obtain acoustic tokens. By contrast we eliminate the encoder and simply discretize mel-filerbanks (<span id="S1.F1.2.1" class="ltx_text ltx_font_typewriter">dMel</span>) to encode audio, and use a simple mel-filterbank vocoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> to reconstruct speech signals.
</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we first introduce our proposed <span id="S2.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> speech tokenization method, which discretizes mel-filterbanks energies directly into bins. We then describe our unified transformer decoder-only model for ASR and TTS tasks, which leverages <span id="S2.p1.1.2" class="ltx_text ltx_font_typewriter">dMel</span> for speech tokenization. The model architecture is illustrated in FigureÂ <a href="#S2.F2" title="Figure 2 â€£ 2.2 Unified Speech-Text Transformer Decoder â€£ 2 Method â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span id="S2.SS1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> Speech Tokenizer</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Different from existing VQ-VAEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> based speech tokenizers, we propose a discretized mel-filterbanks based speech tokenizer.
The outline of the discretization method is shown in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Later in the paper, we show that this tokenizer allows the model to process the input speech signal efficiently and capture the relevant acoustic features for both ASR and TTS tasks.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.6" class="ltx_p">We denote tensors as <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">ğ—</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">ğ—</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\mathbf{X}</annotation></semantics></math> while <math id="S2.SS1.p2.2.m2.2" class="ltx_Math" alttext="\mathbf{X}_{i,...}" display="inline"><semantics id="S2.SS1.p2.2.m2.2a"><msub id="S2.SS1.p2.2.m2.2.3" xref="S2.SS1.p2.2.m2.2.3.cmml"><mi id="S2.SS1.p2.2.m2.2.3.2" xref="S2.SS1.p2.2.m2.2.3.2.cmml">ğ—</mi><mrow id="S2.SS1.p2.2.m2.2.2.2.4" xref="S2.SS1.p2.2.m2.2.2.2.3.cmml"><mi id="S2.SS1.p2.2.m2.1.1.1.1" xref="S2.SS1.p2.2.m2.1.1.1.1.cmml">i</mi><mo id="S2.SS1.p2.2.m2.2.2.2.4.1" xref="S2.SS1.p2.2.m2.2.2.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p2.2.m2.2.2.2.2" xref="S2.SS1.p2.2.m2.2.2.2.2.cmml">â€¦</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.2b"><apply id="S2.SS1.p2.2.m2.2.3.cmml" xref="S2.SS1.p2.2.m2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.2.3.1.cmml" xref="S2.SS1.p2.2.m2.2.3">subscript</csymbol><ci id="S2.SS1.p2.2.m2.2.3.2.cmml" xref="S2.SS1.p2.2.m2.2.3.2">ğ—</ci><list id="S2.SS1.p2.2.m2.2.2.2.3.cmml" xref="S2.SS1.p2.2.m2.2.2.2.4"><ci id="S2.SS1.p2.2.m2.1.1.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1.1.1">ğ‘–</ci><ci id="S2.SS1.p2.2.m2.2.2.2.2.cmml" xref="S2.SS1.p2.2.m2.2.2.2.2">â€¦</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.2c">\mathbf{X}_{i,...}</annotation></semantics></math> denote the <math id="S2.SS1.p2.3.m3.2" class="ltx_Math" alttext="(i,...)" display="inline"><semantics id="S2.SS1.p2.3.m3.2a"><mrow id="S2.SS1.p2.3.m3.2.3.2" xref="S2.SS1.p2.3.m3.2.3.1.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.2.3.2.1" xref="S2.SS1.p2.3.m3.2.3.1.cmml">(</mo><mi id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">i</mi><mo id="S2.SS1.p2.3.m3.2.3.2.2" xref="S2.SS1.p2.3.m3.2.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p2.3.m3.2.2" xref="S2.SS1.p2.3.m3.2.2.cmml">â€¦</mi><mo stretchy="false" id="S2.SS1.p2.3.m3.2.3.2.3" xref="S2.SS1.p2.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.2b"><interval closure="open" id="S2.SS1.p2.3.m3.2.3.1.cmml" xref="S2.SS1.p2.3.m3.2.3.2"><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">ğ‘–</ci><ci id="S2.SS1.p2.3.m3.2.2.cmml" xref="S2.SS1.p2.3.m3.2.2">â€¦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.2c">(i,...)</annotation></semantics></math>-th component of tensor <math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">ğ—</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">ğ—</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">\mathbf{X}</annotation></semantics></math>. First, the speech tokenizer takes the input speech signal <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><mi id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml">ğ±</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><ci id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">ğ±</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">\mathbf{x}</annotation></semantics></math> and computes the mel-filterbanks representation <math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="\mathbf{M}" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><mi id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">ğŒ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">ğŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">\mathbf{M}</annotation></semantics></math>:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\mathbf{M}=\text{Mel}(\mathbf{x})," display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.2" xref="S2.E1.m1.2.2.1.1.2.cmml">ğŒ</mi><mo id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.2.2.1.1.3" xref="S2.E1.m1.2.2.1.1.3.cmml"><mtext id="S2.E1.m1.2.2.1.1.3.2" xref="S2.E1.m1.2.2.1.1.3.2a.cmml">Mel</mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.3.1" xref="S2.E1.m1.2.2.1.1.3.1.cmml">â€‹</mo><mrow id="S2.E1.m1.2.2.1.1.3.3.2" xref="S2.E1.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.3.3.2.1" xref="S2.E1.m1.2.2.1.1.3.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">ğ±</mi><mo stretchy="false" id="S2.E1.m1.2.2.1.1.3.3.2.2" xref="S2.E1.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1"><eq id="S2.E1.m1.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1"></eq><ci id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2">ğŒ</ci><apply id="S2.E1.m1.2.2.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.3"><times id="S2.E1.m1.2.2.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.1"></times><ci id="S2.E1.m1.2.2.1.1.3.2a.cmml" xref="S2.E1.m1.2.2.1.1.3.2"><mtext id="S2.E1.m1.2.2.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2">Mel</mtext></ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">ğ±</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\mathbf{M}=\text{Mel}(\mathbf{x}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p2.10" class="ltx_p">where <math id="S2.SS1.p2.7.m1.1" class="ltx_Math" alttext="\text{Mel}(\cdot)" display="inline"><semantics id="S2.SS1.p2.7.m1.1a"><mrow id="S2.SS1.p2.7.m1.1.2" xref="S2.SS1.p2.7.m1.1.2.cmml"><mtext id="S2.SS1.p2.7.m1.1.2.2" xref="S2.SS1.p2.7.m1.1.2.2a.cmml">Mel</mtext><mo lspace="0em" rspace="0em" id="S2.SS1.p2.7.m1.1.2.1" xref="S2.SS1.p2.7.m1.1.2.1.cmml">â€‹</mo><mrow id="S2.SS1.p2.7.m1.1.2.3.2" xref="S2.SS1.p2.7.m1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p2.7.m1.1.2.3.2.1" xref="S2.SS1.p2.7.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS1.p2.7.m1.1.1" xref="S2.SS1.p2.7.m1.1.1.cmml">â‹…</mo><mo stretchy="false" id="S2.SS1.p2.7.m1.1.2.3.2.2" xref="S2.SS1.p2.7.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m1.1b"><apply id="S2.SS1.p2.7.m1.1.2.cmml" xref="S2.SS1.p2.7.m1.1.2"><times id="S2.SS1.p2.7.m1.1.2.1.cmml" xref="S2.SS1.p2.7.m1.1.2.1"></times><ci id="S2.SS1.p2.7.m1.1.2.2a.cmml" xref="S2.SS1.p2.7.m1.1.2.2"><mtext id="S2.SS1.p2.7.m1.1.2.2.cmml" xref="S2.SS1.p2.7.m1.1.2.2">Mel</mtext></ci><ci id="S2.SS1.p2.7.m1.1.1.cmml" xref="S2.SS1.p2.7.m1.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m1.1c">\text{Mel}(\cdot)</annotation></semantics></math> represents the function that computes the mel-filterbanks, <math id="S2.SS1.p2.8.m2.1" class="ltx_Math" alttext="\mathbf{M}\in\mathbb{R}^{T\times N}" display="inline"><semantics id="S2.SS1.p2.8.m2.1a"><mrow id="S2.SS1.p2.8.m2.1.1" xref="S2.SS1.p2.8.m2.1.1.cmml"><mi id="S2.SS1.p2.8.m2.1.1.2" xref="S2.SS1.p2.8.m2.1.1.2.cmml">ğŒ</mi><mo id="S2.SS1.p2.8.m2.1.1.1" xref="S2.SS1.p2.8.m2.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS1.p2.8.m2.1.1.3" xref="S2.SS1.p2.8.m2.1.1.3.cmml"><mi id="S2.SS1.p2.8.m2.1.1.3.2" xref="S2.SS1.p2.8.m2.1.1.3.2.cmml">â„</mi><mrow id="S2.SS1.p2.8.m2.1.1.3.3" xref="S2.SS1.p2.8.m2.1.1.3.3.cmml"><mi id="S2.SS1.p2.8.m2.1.1.3.3.2" xref="S2.SS1.p2.8.m2.1.1.3.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p2.8.m2.1.1.3.3.1" xref="S2.SS1.p2.8.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S2.SS1.p2.8.m2.1.1.3.3.3" xref="S2.SS1.p2.8.m2.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m2.1b"><apply id="S2.SS1.p2.8.m2.1.1.cmml" xref="S2.SS1.p2.8.m2.1.1"><in id="S2.SS1.p2.8.m2.1.1.1.cmml" xref="S2.SS1.p2.8.m2.1.1.1"></in><ci id="S2.SS1.p2.8.m2.1.1.2.cmml" xref="S2.SS1.p2.8.m2.1.1.2">ğŒ</ci><apply id="S2.SS1.p2.8.m2.1.1.3.cmml" xref="S2.SS1.p2.8.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.8.m2.1.1.3.1.cmml" xref="S2.SS1.p2.8.m2.1.1.3">superscript</csymbol><ci id="S2.SS1.p2.8.m2.1.1.3.2.cmml" xref="S2.SS1.p2.8.m2.1.1.3.2">â„</ci><apply id="S2.SS1.p2.8.m2.1.1.3.3.cmml" xref="S2.SS1.p2.8.m2.1.1.3.3"><times id="S2.SS1.p2.8.m2.1.1.3.3.1.cmml" xref="S2.SS1.p2.8.m2.1.1.3.3.1"></times><ci id="S2.SS1.p2.8.m2.1.1.3.3.2.cmml" xref="S2.SS1.p2.8.m2.1.1.3.3.2">ğ‘‡</ci><ci id="S2.SS1.p2.8.m2.1.1.3.3.3.cmml" xref="S2.SS1.p2.8.m2.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m2.1c">\mathbf{M}\in\mathbb{R}^{T\times N}</annotation></semantics></math>, <math id="S2.SS1.p2.9.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS1.p2.9.m3.1a"><mi id="S2.SS1.p2.9.m3.1.1" xref="S2.SS1.p2.9.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m3.1b"><ci id="S2.SS1.p2.9.m3.1.1.cmml" xref="S2.SS1.p2.9.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m3.1c">N</annotation></semantics></math> is the number of filterbanks and <math id="S2.SS1.p2.10.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS1.p2.10.m4.1a"><mi id="S2.SS1.p2.10.m4.1.1" xref="S2.SS1.p2.10.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m4.1b"><ci id="S2.SS1.p2.10.m4.1.1.cmml" xref="S2.SS1.p2.10.m4.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m4.1c">T</annotation></semantics></math> is the number of frames in the spectrogram.</p>
</div>
<section id="S2.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Tokenization</h5>

<div id="S2.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px1.p1.3" class="ltx_p">To discretize the mel-filterbanks representation <math id="S2.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{M}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">ğŒ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.1.m1.1.1">ğŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.1.m1.1c">\mathbf{M}</annotation></semantics></math> into speech tokens, we adopt a codebook <math id="S2.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{C}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.2.m2.1a"><mi id="S2.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">ğ‚</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.2.m2.1b"><ci id="S2.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.2.m2.1.1">ğ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.2.m2.1c">\mathbf{C}</annotation></semantics></math>.
In this paper, we apply a simple linear discretization, so that the codebook <math id="S2.SS1.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{C}\in\mathbb{R}^{2^{K}}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.3.m3.1a"><mrow id="S2.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.2" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml">ğ‚</mi><mo id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.1" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mi id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">â„</mi><msup id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.cmml"><mn id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.2" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.2.cmml">2</mn><mi id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.cmml">K</mi></msup></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.3.m3.1b"><apply id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1"><in id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.1"></in><ci id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.2">ğ‚</ci><apply id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.2">â„</ci><apply id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3">superscript</csymbol><cn type="integer" id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.2">2</cn><ci id="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.3">ğ¾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.3.m3.1c">\mathbf{C}\in\mathbb{R}^{2^{K}}</annotation></semantics></math> and its values are evenly spaced in the range of the mel-filterbanks values:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.9" class="ltx_Math" alttext="m=\min_{t,i}(\mathbf{M}_{t,i}),\qquad M=\max_{t,i}(\mathbf{M}_{t,i})\qquad\delta=\frac{M-m}{2^{K}}," display="block"><semantics id="S2.E2.m1.9a"><mrow id="S2.E2.m1.9.9.1"><mrow id="S2.E2.m1.9.9.1.1.2" xref="S2.E2.m1.9.9.1.1.3.cmml"><mrow id="S2.E2.m1.9.9.1.1.1.1" xref="S2.E2.m1.9.9.1.1.1.1.cmml"><mi id="S2.E2.m1.9.9.1.1.1.1.4" xref="S2.E2.m1.9.9.1.1.1.1.4.cmml">m</mi><mo id="S2.E2.m1.9.9.1.1.1.1.3" xref="S2.E2.m1.9.9.1.1.1.1.3.cmml">=</mo><mrow id="S2.E2.m1.9.9.1.1.1.1.2.2" xref="S2.E2.m1.9.9.1.1.1.1.2.3.cmml"><munder id="S2.E2.m1.9.9.1.1.1.1.1.1.1" xref="S2.E2.m1.9.9.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.9.9.1.1.1.1.1.1.1.2" xref="S2.E2.m1.9.9.1.1.1.1.1.1.1.2.cmml">min</mi><mrow id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">t</mi><mo id="S2.E2.m1.2.2.2.4.1" xref="S2.E2.m1.2.2.2.3.cmml">,</mo><mi id="S2.E2.m1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.cmml">i</mi></mrow></munder><mo id="S2.E2.m1.9.9.1.1.1.1.2.2a" xref="S2.E2.m1.9.9.1.1.1.1.2.3.cmml">â¡</mo><mrow id="S2.E2.m1.9.9.1.1.1.1.2.2.2" xref="S2.E2.m1.9.9.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S2.E2.m1.9.9.1.1.1.1.2.2.2.2" xref="S2.E2.m1.9.9.1.1.1.1.2.3.cmml">(</mo><msub id="S2.E2.m1.9.9.1.1.1.1.2.2.2.1" xref="S2.E2.m1.9.9.1.1.1.1.2.2.2.1.cmml"><mi id="S2.E2.m1.9.9.1.1.1.1.2.2.2.1.2" xref="S2.E2.m1.9.9.1.1.1.1.2.2.2.1.2.cmml">ğŒ</mi><mrow id="S2.E2.m1.4.4.2.4" xref="S2.E2.m1.4.4.2.3.cmml"><mi id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml">t</mi><mo id="S2.E2.m1.4.4.2.4.1" xref="S2.E2.m1.4.4.2.3.cmml">,</mo><mi id="S2.E2.m1.4.4.2.2" xref="S2.E2.m1.4.4.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.E2.m1.9.9.1.1.1.1.2.2.2.3" xref="S2.E2.m1.9.9.1.1.1.1.2.3.cmml">)</mo></mrow></mrow></mrow><mo rspace="2.167em" id="S2.E2.m1.9.9.1.1.2.3" xref="S2.E2.m1.9.9.1.1.3a.cmml">,</mo><mrow id="S2.E2.m1.9.9.1.1.2.2.2" xref="S2.E2.m1.9.9.1.1.2.2.3.cmml"><mrow id="S2.E2.m1.9.9.1.1.2.2.1.1" xref="S2.E2.m1.9.9.1.1.2.2.1.1.cmml"><mi id="S2.E2.m1.9.9.1.1.2.2.1.1.4" xref="S2.E2.m1.9.9.1.1.2.2.1.1.4.cmml">M</mi><mo id="S2.E2.m1.9.9.1.1.2.2.1.1.3" xref="S2.E2.m1.9.9.1.1.2.2.1.1.3.cmml">=</mo><mrow id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.3.cmml"><munder id="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1" xref="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1.cmml"><mi id="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1.2" xref="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1.2.cmml">max</mi><mrow id="S2.E2.m1.6.6.2.4" xref="S2.E2.m1.6.6.2.3.cmml"><mi id="S2.E2.m1.5.5.1.1" xref="S2.E2.m1.5.5.1.1.cmml">t</mi><mo id="S2.E2.m1.6.6.2.4.1" xref="S2.E2.m1.6.6.2.3.cmml">,</mo><mi id="S2.E2.m1.6.6.2.2" xref="S2.E2.m1.6.6.2.2.cmml">i</mi></mrow></munder><mo id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2a" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.3.cmml">â¡</mo><mrow id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.3.cmml"><mo stretchy="false" id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.2" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.3.cmml">(</mo><msub id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1.cmml"><mi id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1.2" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1.2.cmml">ğŒ</mi><mrow id="S2.E2.m1.8.8.2.4" xref="S2.E2.m1.8.8.2.3.cmml"><mi id="S2.E2.m1.7.7.1.1" xref="S2.E2.m1.7.7.1.1.cmml">t</mi><mo id="S2.E2.m1.8.8.2.4.1" xref="S2.E2.m1.8.8.2.3.cmml">,</mo><mi id="S2.E2.m1.8.8.2.2" xref="S2.E2.m1.8.8.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.3" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.3.cmml">)</mo></mrow></mrow></mrow><mspace width="2em" id="S2.E2.m1.9.9.1.1.2.2.2.3" xref="S2.E2.m1.9.9.1.1.2.2.3a.cmml"></mspace><mrow id="S2.E2.m1.9.9.1.1.2.2.2.2" xref="S2.E2.m1.9.9.1.1.2.2.2.2.cmml"><mi id="S2.E2.m1.9.9.1.1.2.2.2.2.2" xref="S2.E2.m1.9.9.1.1.2.2.2.2.2.cmml">Î´</mi><mo id="S2.E2.m1.9.9.1.1.2.2.2.2.1" xref="S2.E2.m1.9.9.1.1.2.2.2.2.1.cmml">=</mo><mfrac id="S2.E2.m1.9.9.1.1.2.2.2.2.3" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.cmml"><mrow id="S2.E2.m1.9.9.1.1.2.2.2.2.3.2" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.cmml"><mi id="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.2" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.2.cmml">M</mi><mo id="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.1" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.1.cmml">âˆ’</mo><mi id="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.3" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.3.cmml">m</mi></mrow><msup id="S2.E2.m1.9.9.1.1.2.2.2.2.3.3" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.cmml"><mn id="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.2" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.2.cmml">2</mn><mi id="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.3" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.3.cmml">K</mi></msup></mfrac></mrow></mrow></mrow><mo id="S2.E2.m1.9.9.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.9b"><apply id="S2.E2.m1.9.9.1.1.3.cmml" xref="S2.E2.m1.9.9.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.1.1.3a.cmml" xref="S2.E2.m1.9.9.1.1.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.9.9.1.1.1.1.cmml" xref="S2.E2.m1.9.9.1.1.1.1"><eq id="S2.E2.m1.9.9.1.1.1.1.3.cmml" xref="S2.E2.m1.9.9.1.1.1.1.3"></eq><ci id="S2.E2.m1.9.9.1.1.1.1.4.cmml" xref="S2.E2.m1.9.9.1.1.1.1.4">ğ‘š</ci><apply id="S2.E2.m1.9.9.1.1.1.1.2.3.cmml" xref="S2.E2.m1.9.9.1.1.1.1.2.2"><apply id="S2.E2.m1.9.9.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.9.9.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.9.9.1.1.1.1.1.1.1">subscript</csymbol><min id="S2.E2.m1.9.9.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.9.9.1.1.1.1.1.1.1.2"></min><list id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.4"><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">ğ‘¡</ci><ci id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2">ğ‘–</ci></list></apply><apply id="S2.E2.m1.9.9.1.1.1.1.2.2.2.1.cmml" xref="S2.E2.m1.9.9.1.1.1.1.2.2.2.1"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.1.1.1.1.2.2.2.1.1.cmml" xref="S2.E2.m1.9.9.1.1.1.1.2.2.2.1">subscript</csymbol><ci id="S2.E2.m1.9.9.1.1.1.1.2.2.2.1.2.cmml" xref="S2.E2.m1.9.9.1.1.1.1.2.2.2.1.2">ğŒ</ci><list id="S2.E2.m1.4.4.2.3.cmml" xref="S2.E2.m1.4.4.2.4"><ci id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1.1">ğ‘¡</ci><ci id="S2.E2.m1.4.4.2.2.cmml" xref="S2.E2.m1.4.4.2.2">ğ‘–</ci></list></apply></apply></apply><apply id="S2.E2.m1.9.9.1.1.2.2.3.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.1.1.2.2.3a.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.9.9.1.1.2.2.1.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1"><eq id="S2.E2.m1.9.9.1.1.2.2.1.1.3.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.3"></eq><ci id="S2.E2.m1.9.9.1.1.2.2.1.1.4.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.4">ğ‘€</ci><apply id="S2.E2.m1.9.9.1.1.2.2.1.1.2.3.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.2"><apply id="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1">subscript</csymbol><max id="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.1.1.1.2"></max><list id="S2.E2.m1.6.6.2.3.cmml" xref="S2.E2.m1.6.6.2.4"><ci id="S2.E2.m1.5.5.1.1.cmml" xref="S2.E2.m1.5.5.1.1">ğ‘¡</ci><ci id="S2.E2.m1.6.6.2.2.cmml" xref="S2.E2.m1.6.6.2.2">ğ‘–</ci></list></apply><apply id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1">subscript</csymbol><ci id="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1.2.cmml" xref="S2.E2.m1.9.9.1.1.2.2.1.1.2.2.2.1.2">ğŒ</ci><list id="S2.E2.m1.8.8.2.3.cmml" xref="S2.E2.m1.8.8.2.4"><ci id="S2.E2.m1.7.7.1.1.cmml" xref="S2.E2.m1.7.7.1.1">ğ‘¡</ci><ci id="S2.E2.m1.8.8.2.2.cmml" xref="S2.E2.m1.8.8.2.2">ğ‘–</ci></list></apply></apply></apply><apply id="S2.E2.m1.9.9.1.1.2.2.2.2.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2"><eq id="S2.E2.m1.9.9.1.1.2.2.2.2.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.1"></eq><ci id="S2.E2.m1.9.9.1.1.2.2.2.2.2.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.2">ğ›¿</ci><apply id="S2.E2.m1.9.9.1.1.2.2.2.2.3.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3"><divide id="S2.E2.m1.9.9.1.1.2.2.2.2.3.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3"></divide><apply id="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.2"><minus id="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.1"></minus><ci id="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.2.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.2">ğ‘€</ci><ci id="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.3.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.2.3">ğ‘š</ci></apply><apply id="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.1.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.3">superscript</csymbol><cn type="integer" id="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.2.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.2">2</cn><ci id="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.3.cmml" xref="S2.E2.m1.9.9.1.1.2.2.2.2.3.3.3">ğ¾</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.9c">m=\min_{t,i}(\mathbf{M}_{t,i}),\qquad M=\max_{t,i}(\mathbf{M}_{t,i})\qquad\delta=\frac{M-m}{2^{K}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.3" class="ltx_Math" alttext="\mathbf{C}=\left[m,\,m+\delta,\,m+2\delta,\,\dots,\,m+(2^{K}-1)\delta\right]." display="block"><semantics id="S2.E3.m1.3a"><mrow id="S2.E3.m1.3.3.1" xref="S2.E3.m1.3.3.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1" xref="S2.E3.m1.3.3.1.1.cmml"><mi id="S2.E3.m1.3.3.1.1.5" xref="S2.E3.m1.3.3.1.1.5.cmml">ğ‚</mi><mo id="S2.E3.m1.3.3.1.1.4" xref="S2.E3.m1.3.3.1.1.4.cmml">=</mo><mrow id="S2.E3.m1.3.3.1.1.3.3" xref="S2.E3.m1.3.3.1.1.3.4.cmml"><mo id="S2.E3.m1.3.3.1.1.3.3.4" xref="S2.E3.m1.3.3.1.1.3.4.cmml">[</mo><mi id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">m</mi><mo rspace="0.337em" id="S2.E3.m1.3.3.1.1.3.3.5" xref="S2.E3.m1.3.3.1.1.3.4.cmml">,</mo><mrow id="S2.E3.m1.3.3.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.cmml"><mi id="S2.E3.m1.3.3.1.1.1.1.1.2" xref="S2.E3.m1.3.3.1.1.1.1.1.2.cmml">m</mi><mo id="S2.E3.m1.3.3.1.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.cmml">+</mo><mi id="S2.E3.m1.3.3.1.1.1.1.1.3" xref="S2.E3.m1.3.3.1.1.1.1.1.3.cmml">Î´</mi></mrow><mo rspace="0.337em" id="S2.E3.m1.3.3.1.1.3.3.6" xref="S2.E3.m1.3.3.1.1.3.4.cmml">,</mo><mrow id="S2.E3.m1.3.3.1.1.2.2.2" xref="S2.E3.m1.3.3.1.1.2.2.2.cmml"><mi id="S2.E3.m1.3.3.1.1.2.2.2.2" xref="S2.E3.m1.3.3.1.1.2.2.2.2.cmml">m</mi><mo id="S2.E3.m1.3.3.1.1.2.2.2.1" xref="S2.E3.m1.3.3.1.1.2.2.2.1.cmml">+</mo><mrow id="S2.E3.m1.3.3.1.1.2.2.2.3" xref="S2.E3.m1.3.3.1.1.2.2.2.3.cmml"><mn id="S2.E3.m1.3.3.1.1.2.2.2.3.2" xref="S2.E3.m1.3.3.1.1.2.2.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.E3.m1.3.3.1.1.2.2.2.3.1" xref="S2.E3.m1.3.3.1.1.2.2.2.3.1.cmml">â€‹</mo><mi id="S2.E3.m1.3.3.1.1.2.2.2.3.3" xref="S2.E3.m1.3.3.1.1.2.2.2.3.3.cmml">Î´</mi></mrow></mrow><mo rspace="0.337em" id="S2.E3.m1.3.3.1.1.3.3.7" xref="S2.E3.m1.3.3.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml">â€¦</mi><mo rspace="0.337em" id="S2.E3.m1.3.3.1.1.3.3.8" xref="S2.E3.m1.3.3.1.1.3.4.cmml">,</mo><mrow id="S2.E3.m1.3.3.1.1.3.3.3" xref="S2.E3.m1.3.3.1.1.3.3.3.cmml"><mi id="S2.E3.m1.3.3.1.1.3.3.3.3" xref="S2.E3.m1.3.3.1.1.3.3.3.3.cmml">m</mi><mo id="S2.E3.m1.3.3.1.1.3.3.3.2" xref="S2.E3.m1.3.3.1.1.3.3.3.2.cmml">+</mo><mrow id="S2.E3.m1.3.3.1.1.3.3.3.1" xref="S2.E3.m1.3.3.1.1.3.3.3.1.cmml"><mrow id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.2" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.cmml"><msup id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.cmml"><mn id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.2" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.2.cmml">2</mn><mi id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.3" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.3.cmml">K</mi></msup><mo id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.1.cmml">âˆ’</mo><mn id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.3" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.3" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E3.m1.3.3.1.1.3.3.3.1.2" xref="S2.E3.m1.3.3.1.1.3.3.3.1.2.cmml">â€‹</mo><mi id="S2.E3.m1.3.3.1.1.3.3.3.1.3" xref="S2.E3.m1.3.3.1.1.3.3.3.1.3.cmml">Î´</mi></mrow></mrow><mo id="S2.E3.m1.3.3.1.1.3.3.9" xref="S2.E3.m1.3.3.1.1.3.4.cmml">]</mo></mrow></mrow><mo lspace="0em" id="S2.E3.m1.3.3.1.2" xref="S2.E3.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.3b"><apply id="S2.E3.m1.3.3.1.1.cmml" xref="S2.E3.m1.3.3.1"><eq id="S2.E3.m1.3.3.1.1.4.cmml" xref="S2.E3.m1.3.3.1.1.4"></eq><ci id="S2.E3.m1.3.3.1.1.5.cmml" xref="S2.E3.m1.3.3.1.1.5">ğ‚</ci><list id="S2.E3.m1.3.3.1.1.3.4.cmml" xref="S2.E3.m1.3.3.1.1.3.3"><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">ğ‘š</ci><apply id="S2.E3.m1.3.3.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1"><plus id="S2.E3.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1"></plus><ci id="S2.E3.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.2">ğ‘š</ci><ci id="S2.E3.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.3">ğ›¿</ci></apply><apply id="S2.E3.m1.3.3.1.1.2.2.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2"><plus id="S2.E3.m1.3.3.1.1.2.2.2.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1"></plus><ci id="S2.E3.m1.3.3.1.1.2.2.2.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.2">ğ‘š</ci><apply id="S2.E3.m1.3.3.1.1.2.2.2.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.3"><times id="S2.E3.m1.3.3.1.1.2.2.2.3.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.3.1"></times><cn type="integer" id="S2.E3.m1.3.3.1.1.2.2.2.3.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.3.2">2</cn><ci id="S2.E3.m1.3.3.1.1.2.2.2.3.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.3.3">ğ›¿</ci></apply></apply><ci id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2">â€¦</ci><apply id="S2.E3.m1.3.3.1.1.3.3.3.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3"><plus id="S2.E3.m1.3.3.1.1.3.3.3.2.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.2"></plus><ci id="S2.E3.m1.3.3.1.1.3.3.3.3.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.3">ğ‘š</ci><apply id="S2.E3.m1.3.3.1.1.3.3.3.1.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1"><times id="S2.E3.m1.3.3.1.1.3.3.3.1.2.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.2"></times><apply id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1"><minus id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.1"></minus><apply id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.1.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.2.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.2">2</cn><ci id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.3.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.2.3">ğ¾</ci></apply><cn type="integer" id="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.3.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.1.1.1.3">1</cn></apply><ci id="S2.E3.m1.3.3.1.1.3.3.3.1.3.cmml" xref="S2.E3.m1.3.3.1.1.3.3.3.1.3">ğ›¿</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.3c">\mathbf{C}=\left[m,\,m+\delta,\,m+2\delta,\,\dots,\,m+(2^{K}-1)\delta\right].</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.SSS0.Px1.p1.10" class="ltx_p">In practice, we compute the minimum <math id="S2.SS1.SSS0.Px1.p1.4.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.4.m1.1a"><mi id="S2.SS1.SSS0.Px1.p1.4.m1.1.1" xref="S2.SS1.SSS0.Px1.p1.4.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.4.m1.1b"><ci id="S2.SS1.SSS0.Px1.p1.4.m1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.4.m1.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.4.m1.1c">m</annotation></semantics></math> and maximum <math id="S2.SS1.SSS0.Px1.p1.5.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.5.m2.1a"><mi id="S2.SS1.SSS0.Px1.p1.5.m2.1.1" xref="S2.SS1.SSS0.Px1.p1.5.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.5.m2.1b"><ci id="S2.SS1.SSS0.Px1.p1.5.m2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.5.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.5.m2.1c">M</annotation></semantics></math> values of mel-filterbanks across the entire dataset to define the codebook <math id="S2.SS1.SSS0.Px1.p1.6.m3.1" class="ltx_Math" alttext="\mathbf{C}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.6.m3.1a"><mi id="S2.SS1.SSS0.Px1.p1.6.m3.1.1" xref="S2.SS1.SSS0.Px1.p1.6.m3.1.1.cmml">ğ‚</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.6.m3.1b"><ci id="S2.SS1.SSS0.Px1.p1.6.m3.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.6.m3.1.1">ğ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.6.m3.1c">\mathbf{C}</annotation></semantics></math>.
Then we map a magnitude <math id="S2.SS1.SSS0.Px1.p1.7.m4.2" class="ltx_Math" alttext="\mathbf{M}_{t,i}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.7.m4.2a"><msub id="S2.SS1.SSS0.Px1.p1.7.m4.2.3" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.3.cmml"><mi id="S2.SS1.SSS0.Px1.p1.7.m4.2.3.2" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.3.2.cmml">ğŒ</mi><mrow id="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.4" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.3.cmml"><mi id="S2.SS1.SSS0.Px1.p1.7.m4.1.1.1.1" xref="S2.SS1.SSS0.Px1.p1.7.m4.1.1.1.1.cmml">t</mi><mo id="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.4.1" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.3.cmml">,</mo><mi id="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.2" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.7.m4.2b"><apply id="S2.SS1.SSS0.Px1.p1.7.m4.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.7.m4.2.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.3">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.7.m4.2.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.3.2">ğŒ</ci><list id="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.4"><ci id="S2.SS1.SSS0.Px1.p1.7.m4.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.7.m4.1.1.1.1">ğ‘¡</ci><ci id="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.7.m4.2.2.2.2">ğ‘–</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.7.m4.2c">\mathbf{M}_{t,i}</annotation></semantics></math> of every frequency channel <math id="S2.SS1.SSS0.Px1.p1.8.m5.1" class="ltx_Math" alttext="i=1\dots N" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.8.m5.1a"><mrow id="S2.SS1.SSS0.Px1.p1.8.m5.1.1" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.2" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.2.cmml">i</mi><mo id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.1" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.1.cmml">=</mo><mrow id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.cmml"><mn id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.2" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.1" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.3" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.3.cmml">â€¦</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.1a" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.4" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.4.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.8.m5.1b"><apply id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1"><eq id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.1"></eq><ci id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.2">ğ‘–</ci><apply id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3"><times id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.1"></times><cn type="integer" id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.2">1</cn><ci id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.3">â€¦</ci><ci id="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.4.cmml" xref="S2.SS1.SSS0.Px1.p1.8.m5.1.1.3.4">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.8.m5.1c">i=1\dots N</annotation></semantics></math> for the time frame <math id="S2.SS1.SSS0.Px1.p1.9.m6.1" class="ltx_Math" alttext="t=1\dots T" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.9.m6.1a"><mrow id="S2.SS1.SSS0.Px1.p1.9.m6.1.1" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.2" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.2.cmml">t</mi><mo id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.1" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.1.cmml">=</mo><mrow id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.cmml"><mn id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.2" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.1" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.1.cmml">â€‹</mo><mi mathvariant="normal" id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.3" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.3.cmml">â€¦</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.1a" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.1.cmml">â€‹</mo><mi id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.4" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.4.cmml">T</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.9.m6.1b"><apply id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1"><eq id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.1"></eq><ci id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.2">ğ‘¡</ci><apply id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3"><times id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.1"></times><cn type="integer" id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.2">1</cn><ci id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.3">â€¦</ci><ci id="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.4.cmml" xref="S2.SS1.SSS0.Px1.p1.9.m6.1.1.3.4">ğ‘‡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.9.m6.1c">t=1\dots T</annotation></semantics></math> into a bin index of the codebook <math id="S2.SS1.SSS0.Px1.p1.10.m7.1" class="ltx_Math" alttext="\mathbf{C}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.10.m7.1a"><mi id="S2.SS1.SSS0.Px1.p1.10.m7.1.1" xref="S2.SS1.SSS0.Px1.p1.10.m7.1.1.cmml">ğ‚</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.10.m7.1b"><ci id="S2.SS1.SSS0.Px1.p1.10.m7.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.10.m7.1.1">ğ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.10.m7.1c">\mathbf{C}</annotation></semantics></math> in the following way:</p>
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.8" class="ltx_Math" alttext="\mathbf{S}_{t,i}=\text{Discretize}(\mathbf{M}_{t,i})=\text{argmin}_{j}|\mathbf{M}_{t,i}-\mathbf{C}_{j}|" display="block"><semantics id="S2.E4.m1.8a"><mrow id="S2.E4.m1.8.8" xref="S2.E4.m1.8.8.cmml"><msub id="S2.E4.m1.8.8.4" xref="S2.E4.m1.8.8.4.cmml"><mi id="S2.E4.m1.8.8.4.2" xref="S2.E4.m1.8.8.4.2.cmml">ğ’</mi><mrow id="S2.E4.m1.2.2.2.4" xref="S2.E4.m1.2.2.2.3.cmml"><mi id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml">t</mi><mo id="S2.E4.m1.2.2.2.4.1" xref="S2.E4.m1.2.2.2.3.cmml">,</mo><mi id="S2.E4.m1.2.2.2.2" xref="S2.E4.m1.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S2.E4.m1.8.8.5" xref="S2.E4.m1.8.8.5.cmml">=</mo><mrow id="S2.E4.m1.7.7.1" xref="S2.E4.m1.7.7.1.cmml"><mtext id="S2.E4.m1.7.7.1.3" xref="S2.E4.m1.7.7.1.3a.cmml">Discretize</mtext><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.1.2" xref="S2.E4.m1.7.7.1.2.cmml">â€‹</mo><mrow id="S2.E4.m1.7.7.1.1.1" xref="S2.E4.m1.7.7.1.1.1.1.cmml"><mo stretchy="false" id="S2.E4.m1.7.7.1.1.1.2" xref="S2.E4.m1.7.7.1.1.1.1.cmml">(</mo><msub id="S2.E4.m1.7.7.1.1.1.1" xref="S2.E4.m1.7.7.1.1.1.1.cmml"><mi id="S2.E4.m1.7.7.1.1.1.1.2" xref="S2.E4.m1.7.7.1.1.1.1.2.cmml">ğŒ</mi><mrow id="S2.E4.m1.4.4.2.4" xref="S2.E4.m1.4.4.2.3.cmml"><mi id="S2.E4.m1.3.3.1.1" xref="S2.E4.m1.3.3.1.1.cmml">t</mi><mo id="S2.E4.m1.4.4.2.4.1" xref="S2.E4.m1.4.4.2.3.cmml">,</mo><mi id="S2.E4.m1.4.4.2.2" xref="S2.E4.m1.4.4.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.E4.m1.7.7.1.1.1.3" xref="S2.E4.m1.7.7.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.8.8.6" xref="S2.E4.m1.8.8.6.cmml">=</mo><mrow id="S2.E4.m1.8.8.2" xref="S2.E4.m1.8.8.2.cmml"><msub id="S2.E4.m1.8.8.2.3" xref="S2.E4.m1.8.8.2.3.cmml"><mtext id="S2.E4.m1.8.8.2.3.2" xref="S2.E4.m1.8.8.2.3.2a.cmml">argmin</mtext><mi id="S2.E4.m1.8.8.2.3.3" xref="S2.E4.m1.8.8.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.8.8.2.2" xref="S2.E4.m1.8.8.2.2.cmml">â€‹</mo><mrow id="S2.E4.m1.8.8.2.1.1" xref="S2.E4.m1.8.8.2.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.8.8.2.1.1.2" xref="S2.E4.m1.8.8.2.1.2.1.cmml">|</mo><mrow id="S2.E4.m1.8.8.2.1.1.1" xref="S2.E4.m1.8.8.2.1.1.1.cmml"><msub id="S2.E4.m1.8.8.2.1.1.1.2" xref="S2.E4.m1.8.8.2.1.1.1.2.cmml"><mi id="S2.E4.m1.8.8.2.1.1.1.2.2" xref="S2.E4.m1.8.8.2.1.1.1.2.2.cmml">ğŒ</mi><mrow id="S2.E4.m1.6.6.2.4" xref="S2.E4.m1.6.6.2.3.cmml"><mi id="S2.E4.m1.5.5.1.1" xref="S2.E4.m1.5.5.1.1.cmml">t</mi><mo id="S2.E4.m1.6.6.2.4.1" xref="S2.E4.m1.6.6.2.3.cmml">,</mo><mi id="S2.E4.m1.6.6.2.2" xref="S2.E4.m1.6.6.2.2.cmml">i</mi></mrow></msub><mo id="S2.E4.m1.8.8.2.1.1.1.1" xref="S2.E4.m1.8.8.2.1.1.1.1.cmml">âˆ’</mo><msub id="S2.E4.m1.8.8.2.1.1.1.3" xref="S2.E4.m1.8.8.2.1.1.1.3.cmml"><mi id="S2.E4.m1.8.8.2.1.1.1.3.2" xref="S2.E4.m1.8.8.2.1.1.1.3.2.cmml">ğ‚</mi><mi id="S2.E4.m1.8.8.2.1.1.1.3.3" xref="S2.E4.m1.8.8.2.1.1.1.3.3.cmml">j</mi></msub></mrow><mo stretchy="false" id="S2.E4.m1.8.8.2.1.1.3" xref="S2.E4.m1.8.8.2.1.2.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.8b"><apply id="S2.E4.m1.8.8.cmml" xref="S2.E4.m1.8.8"><and id="S2.E4.m1.8.8a.cmml" xref="S2.E4.m1.8.8"></and><apply id="S2.E4.m1.8.8b.cmml" xref="S2.E4.m1.8.8"><eq id="S2.E4.m1.8.8.5.cmml" xref="S2.E4.m1.8.8.5"></eq><apply id="S2.E4.m1.8.8.4.cmml" xref="S2.E4.m1.8.8.4"><csymbol cd="ambiguous" id="S2.E4.m1.8.8.4.1.cmml" xref="S2.E4.m1.8.8.4">subscript</csymbol><ci id="S2.E4.m1.8.8.4.2.cmml" xref="S2.E4.m1.8.8.4.2">ğ’</ci><list id="S2.E4.m1.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.4"><ci id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1">ğ‘¡</ci><ci id="S2.E4.m1.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2">ğ‘–</ci></list></apply><apply id="S2.E4.m1.7.7.1.cmml" xref="S2.E4.m1.7.7.1"><times id="S2.E4.m1.7.7.1.2.cmml" xref="S2.E4.m1.7.7.1.2"></times><ci id="S2.E4.m1.7.7.1.3a.cmml" xref="S2.E4.m1.7.7.1.3"><mtext id="S2.E4.m1.7.7.1.3.cmml" xref="S2.E4.m1.7.7.1.3">Discretize</mtext></ci><apply id="S2.E4.m1.7.7.1.1.1.1.cmml" xref="S2.E4.m1.7.7.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.1.1.1">subscript</csymbol><ci id="S2.E4.m1.7.7.1.1.1.1.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.2">ğŒ</ci><list id="S2.E4.m1.4.4.2.3.cmml" xref="S2.E4.m1.4.4.2.4"><ci id="S2.E4.m1.3.3.1.1.cmml" xref="S2.E4.m1.3.3.1.1">ğ‘¡</ci><ci id="S2.E4.m1.4.4.2.2.cmml" xref="S2.E4.m1.4.4.2.2">ğ‘–</ci></list></apply></apply></apply><apply id="S2.E4.m1.8.8c.cmml" xref="S2.E4.m1.8.8"><eq id="S2.E4.m1.8.8.6.cmml" xref="S2.E4.m1.8.8.6"></eq><share href="#S2.E4.m1.7.7.1.cmml" id="S2.E4.m1.8.8d.cmml" xref="S2.E4.m1.8.8"></share><apply id="S2.E4.m1.8.8.2.cmml" xref="S2.E4.m1.8.8.2"><times id="S2.E4.m1.8.8.2.2.cmml" xref="S2.E4.m1.8.8.2.2"></times><apply id="S2.E4.m1.8.8.2.3.cmml" xref="S2.E4.m1.8.8.2.3"><csymbol cd="ambiguous" id="S2.E4.m1.8.8.2.3.1.cmml" xref="S2.E4.m1.8.8.2.3">subscript</csymbol><ci id="S2.E4.m1.8.8.2.3.2a.cmml" xref="S2.E4.m1.8.8.2.3.2"><mtext id="S2.E4.m1.8.8.2.3.2.cmml" xref="S2.E4.m1.8.8.2.3.2">argmin</mtext></ci><ci id="S2.E4.m1.8.8.2.3.3.cmml" xref="S2.E4.m1.8.8.2.3.3">ğ‘—</ci></apply><apply id="S2.E4.m1.8.8.2.1.2.cmml" xref="S2.E4.m1.8.8.2.1.1"><abs id="S2.E4.m1.8.8.2.1.2.1.cmml" xref="S2.E4.m1.8.8.2.1.1.2"></abs><apply id="S2.E4.m1.8.8.2.1.1.1.cmml" xref="S2.E4.m1.8.8.2.1.1.1"><minus id="S2.E4.m1.8.8.2.1.1.1.1.cmml" xref="S2.E4.m1.8.8.2.1.1.1.1"></minus><apply id="S2.E4.m1.8.8.2.1.1.1.2.cmml" xref="S2.E4.m1.8.8.2.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.8.8.2.1.1.1.2.1.cmml" xref="S2.E4.m1.8.8.2.1.1.1.2">subscript</csymbol><ci id="S2.E4.m1.8.8.2.1.1.1.2.2.cmml" xref="S2.E4.m1.8.8.2.1.1.1.2.2">ğŒ</ci><list id="S2.E4.m1.6.6.2.3.cmml" xref="S2.E4.m1.6.6.2.4"><ci id="S2.E4.m1.5.5.1.1.cmml" xref="S2.E4.m1.5.5.1.1">ğ‘¡</ci><ci id="S2.E4.m1.6.6.2.2.cmml" xref="S2.E4.m1.6.6.2.2">ğ‘–</ci></list></apply><apply id="S2.E4.m1.8.8.2.1.1.1.3.cmml" xref="S2.E4.m1.8.8.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.8.8.2.1.1.1.3.1.cmml" xref="S2.E4.m1.8.8.2.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.8.8.2.1.1.1.3.2.cmml" xref="S2.E4.m1.8.8.2.1.1.1.3.2">ğ‚</ci><ci id="S2.E4.m1.8.8.2.1.1.1.3.3.cmml" xref="S2.E4.m1.8.8.2.1.1.1.3.3">ğ‘—</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.8c">\mathbf{S}_{t,i}=\text{Discretize}(\mathbf{M}_{t,i})=\text{argmin}_{j}|\mathbf{M}_{t,i}-\mathbf{C}_{j}|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.SSS0.Px1.p1.20" class="ltx_p">where <math id="S2.SS1.SSS0.Px1.p1.11.m1.1" class="ltx_Math" alttext="\mathbf{S}\in\mathbf{B}^{T\times N}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.11.m1.1a"><mrow id="S2.SS1.SSS0.Px1.p1.11.m1.1.1" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.2" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.2.cmml">ğ’</mi><mo id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.1" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.cmml"><mi id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.2" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.2.cmml">ğ</mi><mrow id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.cmml"><mi id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.2" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.1" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.3" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.11.m1.1b"><apply id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1"><in id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.1"></in><ci id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.2">ğ’</ci><apply id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3">superscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.2">ğ</ci><apply id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3"><times id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.1"></times><ci id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.2">ğ‘‡</ci><ci id="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.11.m1.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.11.m1.1c">\mathbf{S}\in\mathbf{B}^{T\times N}</annotation></semantics></math> represents the discretized mel-filterbanks (<span id="S2.SS1.SSS0.Px1.p1.20.1" class="ltx_text ltx_font_typewriter">dMel</span>) with <math id="S2.SS1.SSS0.Px1.p1.12.m2.5" class="ltx_Math" alttext="\mathbf{B}=\{j|j=1,2,3,\dots 2^{K}\}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.12.m2.5a"><mrow id="S2.SS1.SSS0.Px1.p1.12.m2.5.5" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.cmml"><mi id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.3" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.3.cmml">ğ</mi><mo id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.2" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.2.cmml">=</mo><mrow id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.2" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.2.1.cmml">{</mo><mi id="S2.SS1.SSS0.Px1.p1.12.m2.4.4" xref="S2.SS1.SSS0.Px1.p1.12.m2.4.4.cmml">j</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.3" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.2.1.cmml">|</mo><mrow id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.3" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.3.cmml">j</mi><mo id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.2" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.2.cmml">=</mo><mrow id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.2.cmml"><mn id="S2.SS1.SSS0.Px1.p1.12.m2.1.1" xref="S2.SS1.SSS0.Px1.p1.12.m2.1.1.cmml">1</mn><mo id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.2" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.2.cmml">,</mo><mn id="S2.SS1.SSS0.Px1.p1.12.m2.2.2" xref="S2.SS1.SSS0.Px1.p1.12.m2.2.2.cmml">2</mn><mo id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.3" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.2.cmml">,</mo><mn id="S2.SS1.SSS0.Px1.p1.12.m2.3.3" xref="S2.SS1.SSS0.Px1.p1.12.m2.3.3.cmml">3</mn><mo id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.4" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.2.cmml">,</mo><mrow id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.2" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.2.cmml">â€¦</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.1" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.1.cmml">â€‹</mo><msup id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.cmml"><mn id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.2" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.2.cmml">2</mn><mi id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.3" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.3.cmml">K</mi></msup></mrow></mrow></mrow><mo stretchy="false" id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.4" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.2.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.12.m2.5b"><apply id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5"><eq id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.2.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.2"></eq><ci id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.3.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.3">ğ</ci><apply id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1"><csymbol cd="latexml" id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.2">conditional-set</csymbol><ci id="S2.SS1.SSS0.Px1.p1.12.m2.4.4.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.4.4">ğ‘—</ci><apply id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1"><eq id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.2"></eq><ci id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.3">ğ‘—</ci><list id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1"><cn type="integer" id="S2.SS1.SSS0.Px1.p1.12.m2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.1.1">1</cn><cn type="integer" id="S2.SS1.SSS0.Px1.p1.12.m2.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.2.2">2</cn><cn type="integer" id="S2.SS1.SSS0.Px1.p1.12.m2.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.3.3">3</cn><apply id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1"><times id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.1"></times><ci id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.2">â€¦</ci><apply id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3">superscript</csymbol><cn type="integer" id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.2">2</cn><ci id="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.12.m2.5.5.1.1.1.1.1.1.3.3">ğ¾</ci></apply></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.12.m2.5c">\mathbf{B}=\{j|j=1,2,3,\dots 2^{K}\}</annotation></semantics></math> and <math id="S2.SS1.SSS0.Px1.p1.13.m3.1" class="ltx_Math" alttext="\mathbf{S}_{t}\in\mathbf{B}^{N}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.13.m3.1a"><mrow id="S2.SS1.SSS0.Px1.p1.13.m3.1.1" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.cmml"><msub id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.cmml"><mi id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.2" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.2.cmml">ğ’</mi><mi id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.3" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.3.cmml">t</mi></msub><mo id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.1" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.cmml"><mi id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.2" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.2.cmml">ğ</mi><mi id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.3" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.3.cmml">N</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.13.m3.1b"><apply id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1"><in id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.1"></in><apply id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2">subscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.2.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.2">ğ’</ci><ci id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.2.3">ğ‘¡</ci></apply><apply id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3">superscript</csymbol><ci id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.2">ğ</ci><ci id="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.13.m3.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.13.m3.1c">\mathbf{S}_{t}\in\mathbf{B}^{N}</annotation></semantics></math> being the <math id="S2.SS1.SSS0.Px1.p1.14.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.14.m4.1a"><mi id="S2.SS1.SSS0.Px1.p1.14.m4.1.1" xref="S2.SS1.SSS0.Px1.p1.14.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.14.m4.1b"><ci id="S2.SS1.SSS0.Px1.p1.14.m4.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.14.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.14.m4.1c">t</annotation></semantics></math>-th speech token.
As the codebook <math id="S2.SS1.SSS0.Px1.p1.15.m5.1" class="ltx_Math" alttext="\mathbf{C}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.15.m5.1a"><mi id="S2.SS1.SSS0.Px1.p1.15.m5.1.1" xref="S2.SS1.SSS0.Px1.p1.15.m5.1.1.cmml">ğ‚</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.15.m5.1b"><ci id="S2.SS1.SSS0.Px1.p1.15.m5.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.15.m5.1.1">ğ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.15.m5.1c">\mathbf{C}</annotation></semantics></math> has <math id="S2.SS1.SSS0.Px1.p1.16.m6.1" class="ltx_Math" alttext="2^{K}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.16.m6.1a"><msup id="S2.SS1.SSS0.Px1.p1.16.m6.1.1" xref="S2.SS1.SSS0.Px1.p1.16.m6.1.1.cmml"><mn id="S2.SS1.SSS0.Px1.p1.16.m6.1.1.2" xref="S2.SS1.SSS0.Px1.p1.16.m6.1.1.2.cmml">2</mn><mi id="S2.SS1.SSS0.Px1.p1.16.m6.1.1.3" xref="S2.SS1.SSS0.Px1.p1.16.m6.1.1.3.cmml">K</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.16.m6.1b"><apply id="S2.SS1.SSS0.Px1.p1.16.m6.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.16.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.16.m6.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.16.m6.1.1">superscript</csymbol><cn type="integer" id="S2.SS1.SSS0.Px1.p1.16.m6.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.16.m6.1.1.2">2</cn><ci id="S2.SS1.SSS0.Px1.p1.16.m6.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.16.m6.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.16.m6.1c">2^{K}</annotation></semantics></math> distinct values and thus number of bins <math id="S2.SS1.SSS0.Px1.p1.17.m7.1" class="ltx_Math" alttext="|\mathbf{B}|=2^{K}" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.17.m7.1a"><mrow id="S2.SS1.SSS0.Px1.p1.17.m7.1.2" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.cmml"><mrow id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.2" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.1.cmml"><mo stretchy="false" id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.2.1" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.1.1.cmml">|</mo><mi id="S2.SS1.SSS0.Px1.p1.17.m7.1.1" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.1.cmml">ğ</mi><mo stretchy="false" id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.2.2" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.1.1.cmml">|</mo></mrow><mo id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.1" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.1.cmml">=</mo><msup id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.cmml"><mn id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.2" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.2.cmml">2</mn><mi id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.3" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.3.cmml">K</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.17.m7.1b"><apply id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2"><eq id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.1"></eq><apply id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.1.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.2"><abs id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.2.2.1"></abs><ci id="S2.SS1.SSS0.Px1.p1.17.m7.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.1">ğ</ci></apply><apply id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.1.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3">superscript</csymbol><cn type="integer" id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.2.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.2">2</cn><ci id="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.3.cmml" xref="S2.SS1.SSS0.Px1.p1.17.m7.1.2.3.3">ğ¾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.17.m7.1c">|\mathbf{B}|=2^{K}</annotation></semantics></math>, each speech token is represented by <math id="S2.SS1.SSS0.Px1.p1.18.m8.1" class="ltx_Math" alttext="N\cdot K" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.18.m8.1a"><mrow id="S2.SS1.SSS0.Px1.p1.18.m8.1.1" xref="S2.SS1.SSS0.Px1.p1.18.m8.1.1.cmml"><mi id="S2.SS1.SSS0.Px1.p1.18.m8.1.1.2" xref="S2.SS1.SSS0.Px1.p1.18.m8.1.1.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.SSS0.Px1.p1.18.m8.1.1.1" xref="S2.SS1.SSS0.Px1.p1.18.m8.1.1.1.cmml">â‹…</mo><mi id="S2.SS1.SSS0.Px1.p1.18.m8.1.1.3" xref="S2.SS1.SSS0.Px1.p1.18.m8.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.18.m8.1b"><apply id="S2.SS1.SSS0.Px1.p1.18.m8.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.18.m8.1.1"><ci id="S2.SS1.SSS0.Px1.p1.18.m8.1.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.18.m8.1.1.1">â‹…</ci><ci id="S2.SS1.SSS0.Px1.p1.18.m8.1.1.2.cmml" xref="S2.SS1.SSS0.Px1.p1.18.m8.1.1.2">ğ‘</ci><ci id="S2.SS1.SSS0.Px1.p1.18.m8.1.1.3.cmml" xref="S2.SS1.SSS0.Px1.p1.18.m8.1.1.3">ğ¾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.18.m8.1c">N\cdot K</annotation></semantics></math> bits where every <math id="S2.SS1.SSS0.Px1.p1.19.m9.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.19.m9.1a"><mi id="S2.SS1.SSS0.Px1.p1.19.m9.1.1" xref="S2.SS1.SSS0.Px1.p1.19.m9.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.19.m9.1b"><ci id="S2.SS1.SSS0.Px1.p1.19.m9.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.19.m9.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.19.m9.1c">K</annotation></semantics></math> bits are used to represent one of <math id="S2.SS1.SSS0.Px1.p1.20.m10.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS1.SSS0.Px1.p1.20.m10.1a"><mi id="S2.SS1.SSS0.Px1.p1.20.m10.1.1" xref="S2.SS1.SSS0.Px1.p1.20.m10.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px1.p1.20.m10.1b"><ci id="S2.SS1.SSS0.Px1.p1.20.m10.1.1.cmml" xref="S2.SS1.SSS0.Px1.p1.20.m10.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px1.p1.20.m10.1c">N</annotation></semantics></math> frequency channels.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Detokenization</h5>

<div id="S2.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px2.p1.3" class="ltx_p">To reconstruct the speech signal <math id="S2.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.1.m1.1a"><mi id="S2.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">ğ±</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.1.m1.1.1">ğ±</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.1.m1.1c">\mathbf{x}</annotation></semantics></math> from the speech tokens <math id="S2.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{S}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.2.m2.1a"><mi id="S2.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.2.m2.1b"><ci id="S2.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.2.m2.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.2.m2.1c">\mathbf{S}</annotation></semantics></math>, we first transform bin indices back to the mel-filterbanks representation via the codebook <math id="S2.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{C}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.3.m3.1a"><mi id="S2.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1.cmml">ğ‚</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.3.m3.1b"><ci id="S2.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.3.m3.1.1">ğ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.3.m3.1c">\mathbf{C}</annotation></semantics></math>:</p>
<table id="S2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E5.m1.5" class="ltx_Math" alttext="\hat{\mathbf{M}}_{t,i}=\mathbf{C}_{\mathbf{S}_{t,i}}." display="block"><semantics id="S2.E5.m1.5a"><mrow id="S2.E5.m1.5.5.1" xref="S2.E5.m1.5.5.1.1.cmml"><mrow id="S2.E5.m1.5.5.1.1" xref="S2.E5.m1.5.5.1.1.cmml"><msub id="S2.E5.m1.5.5.1.1.2" xref="S2.E5.m1.5.5.1.1.2.cmml"><mover accent="true" id="S2.E5.m1.5.5.1.1.2.2" xref="S2.E5.m1.5.5.1.1.2.2.cmml"><mi id="S2.E5.m1.5.5.1.1.2.2.2" xref="S2.E5.m1.5.5.1.1.2.2.2.cmml">ğŒ</mi><mo id="S2.E5.m1.5.5.1.1.2.2.1" xref="S2.E5.m1.5.5.1.1.2.2.1.cmml">^</mo></mover><mrow id="S2.E5.m1.2.2.2.4" xref="S2.E5.m1.2.2.2.3.cmml"><mi id="S2.E5.m1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.cmml">t</mi><mo id="S2.E5.m1.2.2.2.4.1" xref="S2.E5.m1.2.2.2.3.cmml">,</mo><mi id="S2.E5.m1.2.2.2.2" xref="S2.E5.m1.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S2.E5.m1.5.5.1.1.1" xref="S2.E5.m1.5.5.1.1.1.cmml">=</mo><msub id="S2.E5.m1.5.5.1.1.3" xref="S2.E5.m1.5.5.1.1.3.cmml"><mi id="S2.E5.m1.5.5.1.1.3.2" xref="S2.E5.m1.5.5.1.1.3.2.cmml">ğ‚</mi><msub id="S2.E5.m1.4.4.2" xref="S2.E5.m1.4.4.2.cmml"><mi id="S2.E5.m1.4.4.2.4" xref="S2.E5.m1.4.4.2.4.cmml">ğ’</mi><mrow id="S2.E5.m1.4.4.2.2.2.4" xref="S2.E5.m1.4.4.2.2.2.3.cmml"><mi id="S2.E5.m1.3.3.1.1.1.1" xref="S2.E5.m1.3.3.1.1.1.1.cmml">t</mi><mo id="S2.E5.m1.4.4.2.2.2.4.1" xref="S2.E5.m1.4.4.2.2.2.3.cmml">,</mo><mi id="S2.E5.m1.4.4.2.2.2.2" xref="S2.E5.m1.4.4.2.2.2.2.cmml">i</mi></mrow></msub></msub></mrow><mo lspace="0em" id="S2.E5.m1.5.5.1.2" xref="S2.E5.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.5b"><apply id="S2.E5.m1.5.5.1.1.cmml" xref="S2.E5.m1.5.5.1"><eq id="S2.E5.m1.5.5.1.1.1.cmml" xref="S2.E5.m1.5.5.1.1.1"></eq><apply id="S2.E5.m1.5.5.1.1.2.cmml" xref="S2.E5.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.E5.m1.5.5.1.1.2.1.cmml" xref="S2.E5.m1.5.5.1.1.2">subscript</csymbol><apply id="S2.E5.m1.5.5.1.1.2.2.cmml" xref="S2.E5.m1.5.5.1.1.2.2"><ci id="S2.E5.m1.5.5.1.1.2.2.1.cmml" xref="S2.E5.m1.5.5.1.1.2.2.1">^</ci><ci id="S2.E5.m1.5.5.1.1.2.2.2.cmml" xref="S2.E5.m1.5.5.1.1.2.2.2">ğŒ</ci></apply><list id="S2.E5.m1.2.2.2.3.cmml" xref="S2.E5.m1.2.2.2.4"><ci id="S2.E5.m1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1">ğ‘¡</ci><ci id="S2.E5.m1.2.2.2.2.cmml" xref="S2.E5.m1.2.2.2.2">ğ‘–</ci></list></apply><apply id="S2.E5.m1.5.5.1.1.3.cmml" xref="S2.E5.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.5.5.1.1.3.1.cmml" xref="S2.E5.m1.5.5.1.1.3">subscript</csymbol><ci id="S2.E5.m1.5.5.1.1.3.2.cmml" xref="S2.E5.m1.5.5.1.1.3.2">ğ‚</ci><apply id="S2.E5.m1.4.4.2.cmml" xref="S2.E5.m1.4.4.2"><csymbol cd="ambiguous" id="S2.E5.m1.4.4.2.3.cmml" xref="S2.E5.m1.4.4.2">subscript</csymbol><ci id="S2.E5.m1.4.4.2.4.cmml" xref="S2.E5.m1.4.4.2.4">ğ’</ci><list id="S2.E5.m1.4.4.2.2.2.3.cmml" xref="S2.E5.m1.4.4.2.2.2.4"><ci id="S2.E5.m1.3.3.1.1.1.1.cmml" xref="S2.E5.m1.3.3.1.1.1.1">ğ‘¡</ci><ci id="S2.E5.m1.4.4.2.2.2.2.cmml" xref="S2.E5.m1.4.4.2.2.2.2">ğ‘–</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.5c">\hat{\mathbf{M}}_{t,i}=\mathbf{C}_{\mathbf{S}_{t,i}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.SSS0.Px2.p1.5" class="ltx_p">Then, we apply a vocoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> to transform reconstructed mel-filterbanks <math id="S2.SS1.SSS0.Px2.p1.4.m1.2" class="ltx_Math" alttext="\hat{\mathbf{M}}_{t,i}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.4.m1.2a"><msub id="S2.SS1.SSS0.Px2.p1.4.m1.2.3" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3.cmml"><mover accent="true" id="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.cmml"><mi id="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.2" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.2.cmml">ğŒ</mi><mo id="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.1" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.1.cmml">^</mo></mover><mrow id="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.4" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.3.cmml"><mi id="S2.SS1.SSS0.Px2.p1.4.m1.1.1.1.1" xref="S2.SS1.SSS0.Px2.p1.4.m1.1.1.1.1.cmml">t</mi><mo id="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.4.1" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.3.cmml">,</mo><mi id="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.2" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.4.m1.2b"><apply id="S2.SS1.SSS0.Px2.p1.4.m1.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3"><csymbol cd="ambiguous" id="S2.SS1.SSS0.Px2.p1.4.m1.2.3.1.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3">subscript</csymbol><apply id="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2"><ci id="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.1.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.1">^</ci><ci id="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.3.2.2">ğŒ</ci></apply><list id="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.3.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.4"><ci id="S2.SS1.SSS0.Px2.p1.4.m1.1.1.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m1.1.1.1.1">ğ‘¡</ci><ci id="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.2.cmml" xref="S2.SS1.SSS0.Px2.p1.4.m1.2.2.2.2">ğ‘–</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.4.m1.2c">\hat{\mathbf{M}}_{t,i}</annotation></semantics></math> back into the time domain signal <math id="S2.SS1.SSS0.Px2.p1.5.m2.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S2.SS1.SSS0.Px2.p1.5.m2.1a"><mi id="S2.SS1.SSS0.Px2.p1.5.m2.1.1" xref="S2.SS1.SSS0.Px2.p1.5.m2.1.1.cmml">ğ±</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS0.Px2.p1.5.m2.1b"><ci id="S2.SS1.SSS0.Px2.p1.5.m2.1.1.cmml" xref="S2.SS1.SSS0.Px2.p1.5.m2.1.1">ğ±</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS0.Px2.p1.5.m2.1c">\mathbf{x}</annotation></semantics></math>.
The vocoder is trained independently and is not part of the transformer decoder-based model.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Unified Speech-Text Transformer Decoder</h3>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2407.15835/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Unified Speech-Text Transformer Decoder.</figcaption>
</figure>
<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Modeling speech and text sequences jointly is essential for a model to understand and generate both modalities.
However, it is challenging to design a unified model that can handle both speech-to-text and text-to-speech effectively.
In this work, we apply a unified transformer decoder-only model that takes speech and text tokens as input and generates the output tokens in the target sequence.
The model is trained in end-to-end on a combined dataset of speech and text pairs, enabling it to learn the joint representations for ASR and TTS tasks.
As we show in the rest of the paper, the crucial part for the joint model training is the proper speech tokenization which <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> provides.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Token Representation</h5>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.5" class="ltx_p">For text data, we apply a character-level tokenizer to convert the input text into a sequence of text tokens.
The text tokens are passed through an embedding layer, <math id="S2.SS2.SSS0.Px1.p1.1.m1.5" class="ltx_Math" alttext="\text{Embed}(\cdot):\{j|j=1,2,3\dots L\}\to\mathbb{R}^{D}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.5a"><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.5.5" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.cmml"><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.cmml"><mtext id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.2a.cmml">Embed</mtext><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.1.cmml">â€‹</mo><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.3.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.3.2.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">â‹…</mo><mo rspace="0.278em" stretchy="false" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.3.2.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.2.cmml">:</mo><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.cmml"><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.2.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.2.1.cmml">{</mo><mi id="S2.SS2.SSS0.Px1.p1.1.m1.4.4" xref="S2.SS2.SSS0.Px1.p1.1.m1.4.4.cmml">j</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.2.1.cmml">|</mo><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.3.cmml">j</mi><mo id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.2.cmml">=</mo><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.2.cmml"><mn id="S2.SS2.SSS0.Px1.p1.1.m1.2.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.2.2.cmml">1</mn><mo id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.2.cmml">,</mo><mn id="S2.SS2.SSS0.Px1.p1.1.m1.3.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.3.3.cmml">2</mn><mo id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.2.cmml">,</mo><mrow id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.cmml"><mn id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.3.cmml">â€¦</mi><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.1a" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.4" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.4.cmml">L</mi></mrow></mrow></mrow><mo stretchy="false" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.4" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.2.1.cmml">}</mo></mrow><mo stretchy="false" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.2.cmml">â†’</mo><msup id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.2.cmml">â„</mi><mi id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.3.cmml">D</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.5b"><apply id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5"><ci id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.2">:</ci><apply id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3"><times id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.1"></times><ci id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.2a.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.2"><mtext id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.3.2">Embed</mtext></ci><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1">â‹…</ci></apply><apply id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1"><ci id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.2">â†’</ci><apply id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1"><csymbol cd="latexml" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.2">conditional-set</csymbol><ci id="S2.SS2.SSS0.Px1.p1.1.m1.4.4.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.4.4">ğ‘—</ci><apply id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1"><eq id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.2"></eq><ci id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.3">ğ‘—</ci><list id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1"><cn type="integer" id="S2.SS2.SSS0.Px1.p1.1.m1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.2.2">1</cn><cn type="integer" id="S2.SS2.SSS0.Px1.p1.1.m1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.3.3">2</cn><apply id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1"><times id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.1"></times><cn type="integer" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.2">3</cn><ci id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.3">â€¦</ci><ci id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.4.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.1.1.1.1.1.1.4">ğ¿</ci></apply></list></apply></apply><apply id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.2">â„</ci><ci id="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.5.5.1.3.3">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.5c">\text{Embed}(\cdot):\{j|j=1,2,3\dots L\}\to\mathbb{R}^{D}</annotation></semantics></math>, where <math id="S2.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.2.m2.1a"><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.2.m2.1c">D</annotation></semantics></math> is the embedding dimension and <math id="S2.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.3.m3.1a"><mi id="S2.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.3.m3.1b"><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.3.m3.1c">L</annotation></semantics></math> is the vocabulary size.
The dimension of the speech token embedding is set to be the same as the text token embedding <math id="S2.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.4.m4.1a"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.4.m4.1b"><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.4.m4.1c">D</annotation></semantics></math> and no further mapping is required.
The motivation for using a character-level tokenizer is to reduce the vocabulary size <math id="S2.SS2.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.5.m5.1a"><mi id="S2.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.5.m5.1b"><ci id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.5.m5.1c">L</annotation></semantics></math> and improve the modelâ€™s generalization ability.
Also, character tokens can capture the fine-grained linguistic features that are essential for both ASR and TTS tasks.</p>
</div>
<div id="S2.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p2.4" class="ltx_p">For speech signal, we apply the <span id="S2.SS2.SSS0.Px1.p2.4.1" class="ltx_text ltx_font_typewriter">dMel</span> speech tokenizer to convert the input speech signal into a sequence of speech tokens. Then, the speech tokens <math id="S2.SS2.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{S}\in\mathbf{B}^{T\times N}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.1.m1.1a"><mrow id="S2.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.2" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml">ğ’</mi><mo id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.1" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.2" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.2.cmml">ğ</mi><mrow id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.2" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.1" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.3" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.1.m1.1b"><apply id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1"><in id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.1"></in><ci id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.2">ğ’</ci><apply id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.2">ğ</ci><apply id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3"><times id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.1"></times><ci id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.2">ğ‘‡</ci><ci id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.1.m1.1c">\mathbf{S}\in\mathbf{B}^{T\times N}</annotation></semantics></math> are passed through a learnable embedding layer, <math id="S2.SS2.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="\text{Embed}(\cdot):\mathbf{B}\to\mathbb{R}^{d}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.2.m2.1a"><mrow id="S2.SS2.SSS0.Px1.p2.2.m2.1.2" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.cmml"><mrow id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.cmml"><mtext id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.2" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.2a.cmml">Embed</mtext><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.1" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.1.cmml">â€‹</mo><mrow id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.3.2" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.3.2.1" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p2.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1.cmml">â‹…</mo><mo rspace="0.278em" stretchy="false" id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.3.2.2" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.1" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.1.cmml">:</mo><mrow id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.2" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.2.cmml">ğ</mi><mo stretchy="false" id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.1" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.1.cmml">â†’</mo><msup id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.2" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.2.cmml">â„</mi><mi id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.3" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.3.cmml">d</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.2.m2.1b"><apply id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2"><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.1">:</ci><apply id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2"><times id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.1"></times><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.2a.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.2"><mtext id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.2.2">Embed</mtext></ci><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1">â‹…</ci></apply><apply id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3"><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.1">â†’</ci><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.2">ğ</ci><apply id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.2">â„</ci><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.2.3.3.3">ğ‘‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.2.m2.1c">\text{Embed}(\cdot):\mathbf{B}\to\mathbb{R}^{d}</annotation></semantics></math>, and a learnable linear layer, <math id="S2.SS2.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="\text{Linear}(\cdot):\mathbb{R}^{N\times d}\to\mathbb{R}^{D}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.3.m3.1a"><mrow id="S2.SS2.SSS0.Px1.p2.3.m3.1.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.cmml"><mrow id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.cmml"><mtext id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.2a.cmml">Linear</mtext><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.1.cmml">â€‹</mo><mrow id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.3.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.3.2.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p2.3.m3.1.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.cmml">â‹…</mo><mo rspace="0.278em" stretchy="false" id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.3.2.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.1.cmml">:</mo><mrow id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.cmml"><msup id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.cmml"><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.2.cmml">â„</mi><mrow id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.1.cmml">Ã—</mo><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.3.cmml">d</mi></mrow></msup><mo stretchy="false" id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.1.cmml">â†’</mo><msup id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.2.cmml">â„</mi><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.3.cmml">D</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.3.m3.1b"><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2"><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.1">:</ci><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2"><times id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.1"></times><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.2a.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.2"><mtext id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.2.2">Linear</mtext></ci><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1">â‹…</ci></apply><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3"><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.1">â†’</ci><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.2">â„</ci><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3"><times id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.1"></times><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.2">ğ‘</ci><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.2.3.3">ğ‘‘</ci></apply></apply><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.2">â„</ci><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.2.3.3.3">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.3.m3.1c">\text{Linear}(\cdot):\mathbb{R}^{N\times d}\to\mathbb{R}^{D}</annotation></semantics></math>, to obtain the speech token representation <math id="S2.SS2.SSS0.Px1.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{E}\in\mathbb{R}^{T\times D}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.4.m4.1a"><mrow id="S2.SS2.SSS0.Px1.p2.4.m4.1.1" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml">ğ„</mi><mo id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.1" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.2" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.2.cmml">â„</mi><mrow id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.2" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.1" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.1.cmml">Ã—</mo><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.3" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.4.m4.1b"><apply id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1"><in id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.1"></in><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2">ğ„</ci><apply id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.2">â„</ci><apply id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3"><times id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.1"></times><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.2">ğ‘‡</ci><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.3">ğ·</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.4.m4.1c">\mathbf{E}\in\mathbb{R}^{T\times D}</annotation></semantics></math>:</p>
<table id="A5.EGx1" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S2.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E6.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{E^{\prime}}_{t}" display="inline"><semantics id="S2.E6.m1.1a"><mmultiscripts id="S2.E6.m1.1.1" xref="S2.E6.m1.1.1.cmml"><mi id="S2.E6.m1.1.1.2.2" xref="S2.E6.m1.1.1.2.2.cmml">ğ„</mi><mrow id="S2.E6.m1.1.1a" xref="S2.E6.m1.1.1.cmml"></mrow><mo id="S2.E6.m1.1.1.2.3" xref="S2.E6.m1.1.1.2.3.cmml">â€²</mo><mi id="S2.E6.m1.1.1.3" xref="S2.E6.m1.1.1.3.cmml">t</mi><mrow id="S2.E6.m1.1.1b" xref="S2.E6.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S2.E6.m1.1b"><apply id="S2.E6.m1.1.1.cmml" xref="S2.E6.m1.1.1"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.1.cmml" xref="S2.E6.m1.1.1">subscript</csymbol><apply id="S2.E6.m1.1.1.2.cmml" xref="S2.E6.m1.1.1"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.2.1.cmml" xref="S2.E6.m1.1.1">superscript</csymbol><ci id="S2.E6.m1.1.1.2.2.cmml" xref="S2.E6.m1.1.1.2.2">ğ„</ci><ci id="S2.E6.m1.1.1.2.3.cmml" xref="S2.E6.m1.1.1.2.3">â€²</ci></apply><ci id="S2.E6.m1.1.1.3.cmml" xref="S2.E6.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.1c">\displaystyle\mathbf{E^{\prime}}_{t}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S2.E6.m2.1" class="ltx_Math" alttext="\displaystyle=" display="inline"><semantics id="S2.E6.m2.1a"><mo id="S2.E6.m2.1.1" xref="S2.E6.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.E6.m2.1b"><eq id="S2.E6.m2.1.1.cmml" xref="S2.E6.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m2.1c">\displaystyle=</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E6.m3.8" class="ltx_Math" alttext="\displaystyle\text{Concatenate}([\text{Embed}(\mathbf{S}_{t,1}),\text{Embed}(\mathbf{S}_{t,2}),\ldots,\text{Embed}(\mathbf{S}_{t,N})])" display="inline"><semantics id="S2.E6.m3.8a"><mrow id="S2.E6.m3.8.8" xref="S2.E6.m3.8.8.cmml"><mtext id="S2.E6.m3.8.8.3" xref="S2.E6.m3.8.8.3a.cmml">Concatenate</mtext><mo lspace="0em" rspace="0em" id="S2.E6.m3.8.8.2" xref="S2.E6.m3.8.8.2.cmml">â€‹</mo><mrow id="S2.E6.m3.8.8.1.1" xref="S2.E6.m3.8.8.cmml"><mo stretchy="false" id="S2.E6.m3.8.8.1.1.2" xref="S2.E6.m3.8.8.cmml">(</mo><mrow id="S2.E6.m3.8.8.1.1.1.3" xref="S2.E6.m3.8.8.1.1.1.4.cmml"><mo stretchy="false" id="S2.E6.m3.8.8.1.1.1.3.4" xref="S2.E6.m3.8.8.1.1.1.4.cmml">[</mo><mrow id="S2.E6.m3.8.8.1.1.1.1.1" xref="S2.E6.m3.8.8.1.1.1.1.1.cmml"><mtext id="S2.E6.m3.8.8.1.1.1.1.1.3" xref="S2.E6.m3.8.8.1.1.1.1.1.3a.cmml">Embed</mtext><mo lspace="0em" rspace="0em" id="S2.E6.m3.8.8.1.1.1.1.1.2" xref="S2.E6.m3.8.8.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E6.m3.8.8.1.1.1.1.1.1.1" xref="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E6.m3.8.8.1.1.1.1.1.1.1.2" xref="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E6.m3.8.8.1.1.1.1.1.1.1.1" xref="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.2" xref="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.2.cmml">ğ’</mi><mrow id="S2.E6.m3.2.2.2.4" xref="S2.E6.m3.2.2.2.3.cmml"><mi id="S2.E6.m3.1.1.1.1" xref="S2.E6.m3.1.1.1.1.cmml">t</mi><mo id="S2.E6.m3.2.2.2.4.1" xref="S2.E6.m3.2.2.2.3.cmml">,</mo><mn id="S2.E6.m3.2.2.2.2" xref="S2.E6.m3.2.2.2.2.cmml">1</mn></mrow></msub><mo stretchy="false" id="S2.E6.m3.8.8.1.1.1.1.1.1.1.3" xref="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E6.m3.8.8.1.1.1.3.5" xref="S2.E6.m3.8.8.1.1.1.4.cmml">,</mo><mrow id="S2.E6.m3.8.8.1.1.1.2.2" xref="S2.E6.m3.8.8.1.1.1.2.2.cmml"><mtext id="S2.E6.m3.8.8.1.1.1.2.2.3" xref="S2.E6.m3.8.8.1.1.1.2.2.3a.cmml">Embed</mtext><mo lspace="0em" rspace="0em" id="S2.E6.m3.8.8.1.1.1.2.2.2" xref="S2.E6.m3.8.8.1.1.1.2.2.2.cmml">â€‹</mo><mrow id="S2.E6.m3.8.8.1.1.1.2.2.1.1" xref="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.E6.m3.8.8.1.1.1.2.2.1.1.2" xref="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.cmml">(</mo><msub id="S2.E6.m3.8.8.1.1.1.2.2.1.1.1" xref="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.cmml"><mi id="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.2" xref="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.2.cmml">ğ’</mi><mrow id="S2.E6.m3.4.4.2.4" xref="S2.E6.m3.4.4.2.3.cmml"><mi id="S2.E6.m3.3.3.1.1" xref="S2.E6.m3.3.3.1.1.cmml">t</mi><mo id="S2.E6.m3.4.4.2.4.1" xref="S2.E6.m3.4.4.2.3.cmml">,</mo><mn id="S2.E6.m3.4.4.2.2" xref="S2.E6.m3.4.4.2.2.cmml">2</mn></mrow></msub><mo stretchy="false" id="S2.E6.m3.8.8.1.1.1.2.2.1.1.3" xref="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E6.m3.8.8.1.1.1.3.6" xref="S2.E6.m3.8.8.1.1.1.4.cmml">,</mo><mi mathvariant="normal" id="S2.E6.m3.7.7" xref="S2.E6.m3.7.7.cmml">â€¦</mi><mo id="S2.E6.m3.8.8.1.1.1.3.7" xref="S2.E6.m3.8.8.1.1.1.4.cmml">,</mo><mrow id="S2.E6.m3.8.8.1.1.1.3.3" xref="S2.E6.m3.8.8.1.1.1.3.3.cmml"><mtext id="S2.E6.m3.8.8.1.1.1.3.3.3" xref="S2.E6.m3.8.8.1.1.1.3.3.3a.cmml">Embed</mtext><mo lspace="0em" rspace="0em" id="S2.E6.m3.8.8.1.1.1.3.3.2" xref="S2.E6.m3.8.8.1.1.1.3.3.2.cmml">â€‹</mo><mrow id="S2.E6.m3.8.8.1.1.1.3.3.1.1" xref="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.E6.m3.8.8.1.1.1.3.3.1.1.2" xref="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.cmml">(</mo><msub id="S2.E6.m3.8.8.1.1.1.3.3.1.1.1" xref="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.cmml"><mi id="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.2" xref="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.2.cmml">ğ’</mi><mrow id="S2.E6.m3.6.6.2.4" xref="S2.E6.m3.6.6.2.3.cmml"><mi id="S2.E6.m3.5.5.1.1" xref="S2.E6.m3.5.5.1.1.cmml">t</mi><mo id="S2.E6.m3.6.6.2.4.1" xref="S2.E6.m3.6.6.2.3.cmml">,</mo><mi id="S2.E6.m3.6.6.2.2" xref="S2.E6.m3.6.6.2.2.cmml">N</mi></mrow></msub><mo stretchy="false" id="S2.E6.m3.8.8.1.1.1.3.3.1.1.3" xref="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E6.m3.8.8.1.1.1.3.8" xref="S2.E6.m3.8.8.1.1.1.4.cmml">]</mo></mrow><mo stretchy="false" id="S2.E6.m3.8.8.1.1.3" xref="S2.E6.m3.8.8.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m3.8b"><apply id="S2.E6.m3.8.8.cmml" xref="S2.E6.m3.8.8"><times id="S2.E6.m3.8.8.2.cmml" xref="S2.E6.m3.8.8.2"></times><ci id="S2.E6.m3.8.8.3a.cmml" xref="S2.E6.m3.8.8.3"><mtext id="S2.E6.m3.8.8.3.cmml" xref="S2.E6.m3.8.8.3">Concatenate</mtext></ci><list id="S2.E6.m3.8.8.1.1.1.4.cmml" xref="S2.E6.m3.8.8.1.1.1.3"><apply id="S2.E6.m3.8.8.1.1.1.1.1.cmml" xref="S2.E6.m3.8.8.1.1.1.1.1"><times id="S2.E6.m3.8.8.1.1.1.1.1.2.cmml" xref="S2.E6.m3.8.8.1.1.1.1.1.2"></times><ci id="S2.E6.m3.8.8.1.1.1.1.1.3a.cmml" xref="S2.E6.m3.8.8.1.1.1.1.1.3"><mtext id="S2.E6.m3.8.8.1.1.1.1.1.3.cmml" xref="S2.E6.m3.8.8.1.1.1.1.1.3">Embed</mtext></ci><apply id="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.cmml" xref="S2.E6.m3.8.8.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E6.m3.8.8.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E6.m3.8.8.1.1.1.1.1.1.1.1.2">ğ’</ci><list id="S2.E6.m3.2.2.2.3.cmml" xref="S2.E6.m3.2.2.2.4"><ci id="S2.E6.m3.1.1.1.1.cmml" xref="S2.E6.m3.1.1.1.1">ğ‘¡</ci><cn type="integer" id="S2.E6.m3.2.2.2.2.cmml" xref="S2.E6.m3.2.2.2.2">1</cn></list></apply></apply><apply id="S2.E6.m3.8.8.1.1.1.2.2.cmml" xref="S2.E6.m3.8.8.1.1.1.2.2"><times id="S2.E6.m3.8.8.1.1.1.2.2.2.cmml" xref="S2.E6.m3.8.8.1.1.1.2.2.2"></times><ci id="S2.E6.m3.8.8.1.1.1.2.2.3a.cmml" xref="S2.E6.m3.8.8.1.1.1.2.2.3"><mtext id="S2.E6.m3.8.8.1.1.1.2.2.3.cmml" xref="S2.E6.m3.8.8.1.1.1.2.2.3">Embed</mtext></ci><apply id="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.cmml" xref="S2.E6.m3.8.8.1.1.1.2.2.1.1"><csymbol cd="ambiguous" id="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.1.cmml" xref="S2.E6.m3.8.8.1.1.1.2.2.1.1">subscript</csymbol><ci id="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.2.cmml" xref="S2.E6.m3.8.8.1.1.1.2.2.1.1.1.2">ğ’</ci><list id="S2.E6.m3.4.4.2.3.cmml" xref="S2.E6.m3.4.4.2.4"><ci id="S2.E6.m3.3.3.1.1.cmml" xref="S2.E6.m3.3.3.1.1">ğ‘¡</ci><cn type="integer" id="S2.E6.m3.4.4.2.2.cmml" xref="S2.E6.m3.4.4.2.2">2</cn></list></apply></apply><ci id="S2.E6.m3.7.7.cmml" xref="S2.E6.m3.7.7">â€¦</ci><apply id="S2.E6.m3.8.8.1.1.1.3.3.cmml" xref="S2.E6.m3.8.8.1.1.1.3.3"><times id="S2.E6.m3.8.8.1.1.1.3.3.2.cmml" xref="S2.E6.m3.8.8.1.1.1.3.3.2"></times><ci id="S2.E6.m3.8.8.1.1.1.3.3.3a.cmml" xref="S2.E6.m3.8.8.1.1.1.3.3.3"><mtext id="S2.E6.m3.8.8.1.1.1.3.3.3.cmml" xref="S2.E6.m3.8.8.1.1.1.3.3.3">Embed</mtext></ci><apply id="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.cmml" xref="S2.E6.m3.8.8.1.1.1.3.3.1.1"><csymbol cd="ambiguous" id="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.1.cmml" xref="S2.E6.m3.8.8.1.1.1.3.3.1.1">subscript</csymbol><ci id="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.2.cmml" xref="S2.E6.m3.8.8.1.1.1.3.3.1.1.1.2">ğ’</ci><list id="S2.E6.m3.6.6.2.3.cmml" xref="S2.E6.m3.6.6.2.4"><ci id="S2.E6.m3.5.5.1.1.cmml" xref="S2.E6.m3.5.5.1.1">ğ‘¡</ci><ci id="S2.E6.m3.6.6.2.2.cmml" xref="S2.E6.m3.6.6.2.2">ğ‘</ci></list></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m3.8c">\displaystyle\text{Concatenate}([\text{Embed}(\mathbf{S}_{t,1}),\text{Embed}(\mathbf{S}_{t,2}),\ldots,\text{Embed}(\mathbf{S}_{t,N})])</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
<tbody id="S2.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E7.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{E}_{t}" display="inline"><semantics id="S2.E7.m1.1a"><msub id="S2.E7.m1.1.1" xref="S2.E7.m1.1.1.cmml"><mi id="S2.E7.m1.1.1.2" xref="S2.E7.m1.1.1.2.cmml">ğ„</mi><mi id="S2.E7.m1.1.1.3" xref="S2.E7.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E7.m1.1b"><apply id="S2.E7.m1.1.1.cmml" xref="S2.E7.m1.1.1"><csymbol cd="ambiguous" id="S2.E7.m1.1.1.1.cmml" xref="S2.E7.m1.1.1">subscript</csymbol><ci id="S2.E7.m1.1.1.2.cmml" xref="S2.E7.m1.1.1.2">ğ„</ci><ci id="S2.E7.m1.1.1.3.cmml" xref="S2.E7.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m1.1c">\displaystyle\mathbf{E}_{t}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S2.E7.m2.1" class="ltx_Math" alttext="\displaystyle=" display="inline"><semantics id="S2.E7.m2.1a"><mo id="S2.E7.m2.1.1" xref="S2.E7.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S2.E7.m2.1b"><eq id="S2.E7.m2.1.1.cmml" xref="S2.E7.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m2.1c">\displaystyle=</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E7.m3.1" class="ltx_Math" alttext="\displaystyle\text{Linear}(\mathbf{E^{\prime}}_{t})," display="inline"><semantics id="S2.E7.m3.1a"><mrow id="S2.E7.m3.1.1.1" xref="S2.E7.m3.1.1.1.1.cmml"><mrow id="S2.E7.m3.1.1.1.1" xref="S2.E7.m3.1.1.1.1.cmml"><mtext id="S2.E7.m3.1.1.1.1.3" xref="S2.E7.m3.1.1.1.1.3a.cmml">Linear</mtext><mo lspace="0em" rspace="0em" id="S2.E7.m3.1.1.1.1.2" xref="S2.E7.m3.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E7.m3.1.1.1.1.1.1" xref="S2.E7.m3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E7.m3.1.1.1.1.1.1.2" xref="S2.E7.m3.1.1.1.1.1.1.1.cmml">(</mo><mmultiscripts id="S2.E7.m3.1.1.1.1.1.1.1" xref="S2.E7.m3.1.1.1.1.1.1.1.cmml"><mi id="S2.E7.m3.1.1.1.1.1.1.1.2.2" xref="S2.E7.m3.1.1.1.1.1.1.1.2.2.cmml">ğ„</mi><mrow id="S2.E7.m3.1.1.1.1.1.1.1a" xref="S2.E7.m3.1.1.1.1.1.1.1.cmml"></mrow><mo id="S2.E7.m3.1.1.1.1.1.1.1.2.3" xref="S2.E7.m3.1.1.1.1.1.1.1.2.3.cmml">â€²</mo><mi id="S2.E7.m3.1.1.1.1.1.1.1.3" xref="S2.E7.m3.1.1.1.1.1.1.1.3.cmml">t</mi><mrow id="S2.E7.m3.1.1.1.1.1.1.1b" xref="S2.E7.m3.1.1.1.1.1.1.1.cmml"></mrow></mmultiscripts><mo stretchy="false" id="S2.E7.m3.1.1.1.1.1.1.3" xref="S2.E7.m3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E7.m3.1.1.1.2" xref="S2.E7.m3.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E7.m3.1b"><apply id="S2.E7.m3.1.1.1.1.cmml" xref="S2.E7.m3.1.1.1"><times id="S2.E7.m3.1.1.1.1.2.cmml" xref="S2.E7.m3.1.1.1.1.2"></times><ci id="S2.E7.m3.1.1.1.1.3a.cmml" xref="S2.E7.m3.1.1.1.1.3"><mtext id="S2.E7.m3.1.1.1.1.3.cmml" xref="S2.E7.m3.1.1.1.1.3">Linear</mtext></ci><apply id="S2.E7.m3.1.1.1.1.1.1.1.cmml" xref="S2.E7.m3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E7.m3.1.1.1.1.1.1.1.1.cmml" xref="S2.E7.m3.1.1.1.1.1.1">subscript</csymbol><apply id="S2.E7.m3.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E7.m3.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E7.m3.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E7.m3.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E7.m3.1.1.1.1.1.1.1.2.2">ğ„</ci><ci id="S2.E7.m3.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E7.m3.1.1.1.1.1.1.1.2.3">â€²</ci></apply><ci id="S2.E7.m3.1.1.1.1.1.1.1.3.cmml" xref="S2.E7.m3.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m3.1c">\displaystyle\text{Linear}(\mathbf{E^{\prime}}_{t}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS0.Px1.p2.12" class="ltx_p">where <math id="S2.SS2.SSS0.Px1.p2.5.m1.1" class="ltx_Math" alttext="\mathbf{E}_{t}\in\mathbb{R}^{D}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.5.m1.1a"><mrow id="S2.SS2.SSS0.Px1.p2.5.m1.1.1" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.cmml"><msub id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.2" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.2.cmml">ğ„</mi><mi id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.3" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.3.cmml">t</mi></msub><mo id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.1" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.2" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.2.cmml">â„</mi><mi id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.3" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.5.m1.1b"><apply id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1"><in id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.1"></in><apply id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.2">ğ„</ci><ci id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.2.3">ğ‘¡</ci></apply><apply id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.2">â„</ci><ci id="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m1.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.5.m1.1c">\mathbf{E}_{t}\in\mathbb{R}^{D}</annotation></semantics></math> is the speech token representation.
Here, for every time frame <math id="S2.SS2.SSS0.Px1.p2.6.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.6.m2.1a"><mi id="S2.SS2.SSS0.Px1.p2.6.m2.1.1" xref="S2.SS2.SSS0.Px1.p2.6.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.6.m2.1b"><ci id="S2.SS2.SSS0.Px1.p2.6.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.6.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.6.m2.1c">t</annotation></semantics></math> a speech token <math id="S2.SS2.SSS0.Px1.p2.7.m3.1" class="ltx_Math" alttext="\mathbf{S}_{t}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.7.m3.1a"><msub id="S2.SS2.SSS0.Px1.p2.7.m3.1.1" xref="S2.SS2.SSS0.Px1.p2.7.m3.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.7.m3.1.1.2" xref="S2.SS2.SSS0.Px1.p2.7.m3.1.1.2.cmml">ğ’</mi><mi id="S2.SS2.SSS0.Px1.p2.7.m3.1.1.3" xref="S2.SS2.SSS0.Px1.p2.7.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.7.m3.1b"><apply id="S2.SS2.SSS0.Px1.p2.7.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.7.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m3.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.7.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m3.1.1.2">ğ’</ci><ci id="S2.SS2.SSS0.Px1.p2.7.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.7.m3.1c">\mathbf{S}_{t}</annotation></semantics></math> is processed <span id="S2.SS2.SSS0.Px1.p2.12.1" class="ltx_text ltx_font_italic">in parallel and independently</span> for every frequency channel <math id="S2.SS2.SSS0.Px1.p2.8.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.8.m4.1a"><mi id="S2.SS2.SSS0.Px1.p2.8.m4.1.1" xref="S2.SS2.SSS0.Px1.p2.8.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.8.m4.1b"><ci id="S2.SS2.SSS0.Px1.p2.8.m4.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.8.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.8.m4.1c">i</annotation></semantics></math> by <math id="S2.SS2.SSS0.Px1.p2.9.m5.3" class="ltx_Math" alttext="\text{Embed}(\mathbf{S}_{t,i})" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.9.m5.3a"><mrow id="S2.SS2.SSS0.Px1.p2.9.m5.3.3" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.cmml"><mtext id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.3" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.3a.cmml">Embed</mtext><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.2" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.2.cmml">â€‹</mo><mrow id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.2" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.cmml">(</mo><msub id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.2" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.2.cmml">ğ’</mi><mrow id="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.4" xref="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.9.m5.1.1.1.1" xref="S2.SS2.SSS0.Px1.p2.9.m5.1.1.1.1.cmml">t</mi><mo id="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.4.1" xref="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.3.cmml">,</mo><mi id="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.2" xref="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.3" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.9.m5.3b"><apply id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3"><times id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.2"></times><ci id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.3a.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.3"><mtext id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.3">Embed</mtext></ci><apply id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.3.3.1.1.1.2">ğ’</ci><list id="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.3.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.4"><ci id="S2.SS2.SSS0.Px1.p2.9.m5.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.1.1.1.1">ğ‘¡</ci><ci id="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m5.2.2.2.2">ğ‘–</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.9.m5.3c">\text{Embed}(\mathbf{S}_{t,i})</annotation></semantics></math> mapping, and then embeddings of all frequency channels are stacked together to form one vector representation <math id="S2.SS2.SSS0.Px1.p2.10.m6.1" class="ltx_Math" alttext="\mathbf{E^{\prime}}_{t}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.10.m6.1a"><mmultiscripts id="S2.SS2.SSS0.Px1.p2.10.m6.1.1" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.2" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.2.cmml">ğ„</mi><mrow id="S2.SS2.SSS0.Px1.p2.10.m6.1.1a" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.cmml"></mrow><mo id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.3" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.3.cmml">â€²</mo><mi id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.3" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.3.cmml">t</mi><mrow id="S2.SS2.SSS0.Px1.p2.10.m6.1.1b" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.10.m6.1b"><apply id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.2">ğ„</ci><ci id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.2.3">â€²</ci></apply><ci id="S2.SS2.SSS0.Px1.p2.10.m6.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.10.m6.1c">\mathbf{E^{\prime}}_{t}</annotation></semantics></math> for the frameÂ <math id="S2.SS2.SSS0.Px1.p2.11.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.11.m7.1a"><mi id="S2.SS2.SSS0.Px1.p2.11.m7.1.1" xref="S2.SS2.SSS0.Px1.p2.11.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.11.m7.1b"><ci id="S2.SS2.SSS0.Px1.p2.11.m7.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.11.m7.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.11.m7.1c">t</annotation></semantics></math>.
Finally, the speech token embeddings <math id="S2.SS2.SSS0.Px1.p2.12.m8.1" class="ltx_Math" alttext="\mathbf{E}_{t}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.12.m8.1a"><msub id="S2.SS2.SSS0.Px1.p2.12.m8.1.1" xref="S2.SS2.SSS0.Px1.p2.12.m8.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.12.m8.1.1.2" xref="S2.SS2.SSS0.Px1.p2.12.m8.1.1.2.cmml">ğ„</mi><mi id="S2.SS2.SSS0.Px1.p2.12.m8.1.1.3" xref="S2.SS2.SSS0.Px1.p2.12.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.12.m8.1b"><apply id="S2.SS2.SSS0.Px1.p2.12.m8.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.12.m8.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.12.m8.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.12.m8.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.12.m8.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.12.m8.1.1.2">ğ„</ci><ci id="S2.SS2.SSS0.Px1.p2.12.m8.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.12.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.12.m8.1c">\mathbf{E}_{t}</annotation></semantics></math> are fed into the decoder-only transformer models for further processing.</p>
</div>
<div id="S2.SS2.SSS0.Px1.p3" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p3.1" class="ltx_p">We also implemented other popular speech tokenizers including HuBERT-KMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and SpeechTokenizerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> for comparison.
The main difference among these speech tokenizers is the codebook size and codes dimension, which are shown in TableÂ <a href="#S2.T2" title="Table 2 â€£ Token Representation â€£ 2.2 Unified Speech-Text Transformer Decoder â€£ 2 Method â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
For both HuBERT-KM and SpeechTokenizer the speech tokens are mapped via a learnable linear layer from their dimension to the text embedding dimension <math id="S2.SS2.SSS0.Px1.p3.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS2.SSS0.Px1.p3.1.m1.1a"><mi id="S2.SS2.SSS0.Px1.p3.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p3.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p3.1.m1.1b"><ci id="S2.SS2.SSS0.Px1.p3.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p3.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p3.1.m1.1c">D</annotation></semantics></math> before feeding into the transformer decoder-only model.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison between different speech tokenizers: <span id="S2.T2.9.1" class="ltx_text ltx_font_typewriter">dMel</span> (ours), HuBERT-LM and SpeechTokenizer. For <span id="S2.T2.10.2" class="ltx_text ltx_font_typewriter">dMel</span> we use <math id="S2.T2.4.m1.1" class="ltx_Math" alttext="N=80" display="inline"><semantics id="S2.T2.4.m1.1b"><mrow id="S2.T2.4.m1.1.1" xref="S2.T2.4.m1.1.1.cmml"><mi id="S2.T2.4.m1.1.1.2" xref="S2.T2.4.m1.1.1.2.cmml">N</mi><mo id="S2.T2.4.m1.1.1.1" xref="S2.T2.4.m1.1.1.1.cmml">=</mo><mn id="S2.T2.4.m1.1.1.3" xref="S2.T2.4.m1.1.1.3.cmml">80</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.4.m1.1c"><apply id="S2.T2.4.m1.1.1.cmml" xref="S2.T2.4.m1.1.1"><eq id="S2.T2.4.m1.1.1.1.cmml" xref="S2.T2.4.m1.1.1.1"></eq><ci id="S2.T2.4.m1.1.1.2.cmml" xref="S2.T2.4.m1.1.1.2">ğ‘</ci><cn type="integer" id="S2.T2.4.m1.1.1.3.cmml" xref="S2.T2.4.m1.1.1.3">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.4.m1.1d">N=80</annotation></semantics></math> mel-filterbanks and <math id="S2.T2.5.m2.1" class="ltx_Math" alttext="2^{K}=16" display="inline"><semantics id="S2.T2.5.m2.1b"><mrow id="S2.T2.5.m2.1.1" xref="S2.T2.5.m2.1.1.cmml"><msup id="S2.T2.5.m2.1.1.2" xref="S2.T2.5.m2.1.1.2.cmml"><mn id="S2.T2.5.m2.1.1.2.2" xref="S2.T2.5.m2.1.1.2.2.cmml">2</mn><mi id="S2.T2.5.m2.1.1.2.3" xref="S2.T2.5.m2.1.1.2.3.cmml">K</mi></msup><mo id="S2.T2.5.m2.1.1.1" xref="S2.T2.5.m2.1.1.1.cmml">=</mo><mn id="S2.T2.5.m2.1.1.3" xref="S2.T2.5.m2.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.T2.5.m2.1c"><apply id="S2.T2.5.m2.1.1.cmml" xref="S2.T2.5.m2.1.1"><eq id="S2.T2.5.m2.1.1.1.cmml" xref="S2.T2.5.m2.1.1.1"></eq><apply id="S2.T2.5.m2.1.1.2.cmml" xref="S2.T2.5.m2.1.1.2"><csymbol cd="ambiguous" id="S2.T2.5.m2.1.1.2.1.cmml" xref="S2.T2.5.m2.1.1.2">superscript</csymbol><cn type="integer" id="S2.T2.5.m2.1.1.2.2.cmml" xref="S2.T2.5.m2.1.1.2.2">2</cn><ci id="S2.T2.5.m2.1.1.2.3.cmml" xref="S2.T2.5.m2.1.1.2.3">ğ¾</ci></apply><cn type="integer" id="S2.T2.5.m2.1.1.3.cmml" xref="S2.T2.5.m2.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.5.m2.1d">2^{K}=16</annotation></semantics></math> values of the codebook <math id="S2.T2.6.m3.1" class="ltx_Math" alttext="\mathbf{C}" display="inline"><semantics id="S2.T2.6.m3.1b"><mi id="S2.T2.6.m3.1.1" xref="S2.T2.6.m3.1.1.cmml">ğ‚</mi><annotation-xml encoding="MathML-Content" id="S2.T2.6.m3.1c"><ci id="S2.T2.6.m3.1.1.cmml" xref="S2.T2.6.m3.1.1">ğ‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.6.m3.1d">\mathbf{C}</annotation></semantics></math>.</figcaption>
<table id="S2.T2.11" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T2.11.1" class="ltx_tr">
<td id="S2.T2.11.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S2.T2.11.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.11.1.2.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span></td>
<td id="S2.T2.11.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.11.1.3.1" class="ltx_text" style="font-size:90%;">HuBERT-KM</span></td>
<td id="S2.T2.11.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.11.1.4.1" class="ltx_text" style="font-size:90%;">SpeechTokenizer</span></td>
</tr>
<tr id="S2.T2.11.2" class="ltx_tr">
<td id="S2.T2.11.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.11.2.1.1" class="ltx_text" style="font-size:90%;">Codebook Size</span></td>
<td id="S2.T2.11.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.11.2.2.1" class="ltx_text" style="font-size:90%;">16</span></td>
<td id="S2.T2.11.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.11.2.3.1" class="ltx_text" style="font-size:90%;">200</span></td>
<td id="S2.T2.11.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.11.2.4.1" class="ltx_text" style="font-size:90%;">1024</span></td>
</tr>
<tr id="S2.T2.11.3" class="ltx_tr">
<td id="S2.T2.11.3.1" class="ltx_td ltx_align_left"><span id="S2.T2.11.3.1.1" class="ltx_text" style="font-size:90%;">Code Dimension</span></td>
<td id="S2.T2.11.3.2" class="ltx_td ltx_align_center"><span id="S2.T2.11.3.2.1" class="ltx_text" style="font-size:90%;">80</span></td>
<td id="S2.T2.11.3.3" class="ltx_td ltx_align_center"><span id="S2.T2.11.3.3.1" class="ltx_text" style="font-size:90%;">1</span></td>
<td id="S2.T2.11.3.4" class="ltx_td ltx_align_center"><span id="S2.T2.11.3.4.1" class="ltx_text" style="font-size:90%;">8</span></td>
</tr>
<tr id="S2.T2.11.4" class="ltx_tr">
<td id="S2.T2.11.4.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T2.11.4.1.1" class="ltx_text" style="font-size:90%;">Training-free?</span></td>
<td id="S2.T2.11.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.11.4.2.1" class="ltx_text" style="font-size:90%;">âœ“</span></td>
<td id="S2.T2.11.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.11.4.3.1" class="ltx_text" style="font-size:90%;">âœ—</span></td>
<td id="S2.T2.11.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.11.4.4.1" class="ltx_text" style="font-size:90%;">âœ—</span></td>
</tr>
</table>
</figure>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Speaker Representation</h5>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.1" class="ltx_p">To properly model multi-speaker data, we also include speaker embeddings as input to the transformer decoder.
The speaker embeddings are extracted from an independent dvectorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> model.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We use a pretrained model â€œSpeaker Encoderâ€ from the YourTTSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> repository <a target="_blank" href="https://github.com/Edresson/YourTTS" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Edresson/YourTTS</a>.</span></span></span>
We use a learnable linear layer to map the speaker embeddings to the same dimension as the speech and text token embeddings <math id="S2.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.1.m1.1c">D</annotation></semantics></math>.
The speaker representation is optional for ASR task, but required for TTS task.
Hence, during the training, it is applied for text-to-speech and ignored for speech-to-text.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Transformer Decoder</h5>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p1.1" class="ltx_p">The transformer decoder is trained end-to-end on a combined dataset of speech and text pairs.
For TTS training, the input sequence is constructed by concatenating the speaker embedding (extracted from a random audio for the same speaker of the current sample), text tokens, and speech tokens.
For ASR training, the input sequence is constructed by concatenating the speech tokens and text tokens.
Both tasks are trained with causal masking, where the model is trained to predict the next token based on the previous tokens.
The loss is calculated using the cross-entropy loss between the predicted tokens and the ground-truth tokens. Loss calculation is skipped on the speech tokens for ASR task and on the text tokens for TTS task. <span id="S2.SS2.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">Note, that all frequency channels at time frame <math id="S2.SS2.SSS0.Px3.p1.1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS2.SSS0.Px3.p1.1.1.m1.1a"><mi id="S2.SS2.SSS0.Px3.p1.1.1.m1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.1.1.m1.1b"><ci id="S2.SS2.SSS0.Px3.p1.1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.1.1.m1.1c">t</annotation></semantics></math> for <span id="S2.SS2.SSS0.Px3.p1.1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> tokenizer are predicted independently and in parallel.</span></p>
</div>
<div id="S2.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p2.1" class="ltx_p">To capture the relative distances between tokens in the input sequence we apply multiplicative relative positional embedding RoPEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.
This allows the model to learn the positional relationships between speech tokens, text tokens, and speaker embeddings, enhancing its ability to generate coherent output sequences.
For positional embeddings we do not distinguish between text, speech and speaker embeddings having global positions notation across all kind of tokens.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Robust Training</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Compared to language modeling, audio frames are highly redundant with strong local correlations.
This makes long form generation difficult for models due to exposure biasÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
To mitigate exposure bias during training, we apply span-maskingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> to the speech token context, masking out multiple random spans of speech frames.
The model is trained to predict the next token based on the masked context.
This context-masking strategy helps the model learn to generate accurate speech tokens in the presence of missing information, improving its robustness and generalization. It forces the model to attend to the text rather than copying previously inferred speech tokens due to learnt correlations. We also find that span-masking text tokens improves the ASR task.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we conduct ASR and TTS experiments using <span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> tokens with a unified transformer decoder-only model.
We evaluate the performance of our model mainly on the LibriSpeech dataset and compare it with state-of-the-art speech tokenization methods, ASR and TTS models.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Training Data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We use several open-sourced datasets with paired speech and text transcription to conduct experiments: i) LibriSpeechÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> dataset (CC BY 4.0) consists of English speech recordings (960h, 16kHz) from various speakers (<math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mo id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><csymbol cd="latexml" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\sim</annotation></semantics></math>2k) and conditions; ii) LibriTTSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> (CC BY 4.0) dataset derived from LibriSpeech improves over it with the proper sentence split, text normalization and keeping 24kHz. It has around 500h; iii) VCTKÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> contains 44 hours of English speech (108 speakers); iv) LJSpeechÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> dataset (public domain in USA) is a single speaker English audio recordings of 16kHz with read speech from LibriVox.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://librivox.org/pages/public-domain/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://librivox.org/pages/public-domain/</a></span></span></span>
While LibriSpeech is used to train ASR, TTS and joint models, LibriTTS, VCTK and LJSpeech are used to train TTS model only.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training Configuration</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We train decoder-only transformers in three different sizes: Small, Base, and Large (see Appendix TableÂ <a href="#A4.T9" title="Table 9 â€£ Appendix D Training Details â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>).
By default, the Base model is used in all experiments if not stated otherwise.
All models use pre-LayerNorm with dropout set to 0.1 for residual, attention and embedding and 0.3 for positional embedding.
<span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> uses 16 discrete bins for each channel while text is tokenized with a character vocabulary; the speaker embedding dvector has 512 dimensions(see AppendxÂ <a href="#A4" title="Appendix D Training Details â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a> for details).</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Main Results</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In this section, we first evaluate different tokenization methods on speech reconstruction.
Then we report the TTS and ASR results using an LM-styleÂ (decoder-only) model with different speech tokens.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Speech Reconstruction</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, we randomly sample 300 speech utterances and their ground truth transcriptions from the LibriSpeech <span id="S3.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_italic">test-clean</span> dataset.
We use the speech2unit and unit2speech modules to convert the speech signal to speech tokens and then reconstruct the speech signal from the speech tokens.
We compute the WER between the ASR outputs from HuBERT-LargeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite><span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We use checkpoint <a target="_blank" href="https://huggingface.co/facebook/hubert-large-ls960-ft%****%20experiments.tex%20Line%2025%20****" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/facebook/hubert-large-ls960-ft%****â£experiments.texâ£Lineâ£25â£****</a>.</span></span></span> on the audio samples and their ground truth transcripts.
We also report MOS-LQOÂ (Mean Opinion Score - Listening Quality Objective) score to measure the reconstruction quality using ViSQOLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
Finally, use human evaluation to measure the naturalness of the reconstructed speech using a MOS score.
We instruct the human evaluators to rate the naturalness of the reconstructed speech on a scale of 1 to 5, where 1 is the worst and 5 is the best.
The results are shown in TableÂ <a href="#S3.T3" title="Table 3 â€£ 3.3.1 Speech Reconstruction â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Speech reconstruction results on 300 random samples from LibriSpeech <span id="S3.T3.2.1" class="ltx_text ltx_font_italic">test-clean</span> set.
For each tokenizer, we list its frame rate and the model parameter sizes of its speech2unit and unit2speech modules. WER is evaluated with HuBERT-Large and MOS-LQO with ViSQOL.</figcaption>
<table id="S3.T3.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.3.1" class="ltx_tr">
<td id="S3.T3.3.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Tokenizer</span></td>
<td id="S3.T3.3.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S3.T3.3.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Speech2unit</span></td>
<td id="S3.T3.3.1.3" class="ltx_td ltx_align_right ltx_border_tt"><span id="S3.T3.3.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Unit2speech</span></td>
<td id="S3.T3.3.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.3.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Frame Rate</span></td>
<td id="S3.T3.3.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.3.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">WER</span></td>
<td id="S3.T3.3.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.3.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">MOS-LQO</span></td>
<td id="S3.T3.3.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.3.1.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">MOS</span></td>
</tr>
<tr id="S3.T3.3.2" class="ltx_tr">
<td id="S3.T3.3.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T3.3.2.1.1" class="ltx_text" style="font-size:90%;">GroundTruth</span></td>
<td id="S3.T3.3.2.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T3.3.2.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T3.3.2.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T3.3.2.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T3.3.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.2.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T3.3.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.2.5.1" class="ltx_text" style="font-size:90%;">2.02</span></td>
<td id="S3.T3.3.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.2.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T3.3.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.2.7.1" class="ltx_text" style="font-size:90%;">3.91</span></td>
</tr>
<tr id="S3.T3.3.3" class="ltx_tr">
<td id="S3.T3.3.3.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T3.3.3.1.1" class="ltx_text" style="font-size:90%;">HuBERT-KMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.3.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S3.T3.3.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T3.3.3.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T3.3.3.2.1" class="ltx_text" style="font-size:90%;">95M</span></td>
<td id="S3.T3.3.3.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T3.3.3.3.1" class="ltx_text" style="font-size:90%;">111M</span></td>
<td id="S3.T3.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.3.4.1" class="ltx_text" style="font-size:90%;">50Hz</span></td>
<td id="S3.T3.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.3.5.1" class="ltx_text" style="font-size:90%;">8.71</span></td>
<td id="S3.T3.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.3.6.1" class="ltx_text" style="font-size:90%;">2.06</span></td>
<td id="S3.T3.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.3.7.1" class="ltx_text" style="font-size:90%;">2.78</span></td>
</tr>
<tr id="S3.T3.3.4" class="ltx_tr">
<td id="S3.T3.3.4.1" class="ltx_td ltx_align_left">
<span id="S3.T3.3.4.1.1" class="ltx_text" style="font-size:90%;">EnCodecÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.3.4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S3.T3.3.4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T3.3.4.2" class="ltx_td ltx_align_right"><span id="S3.T3.3.4.2.1" class="ltx_text" style="font-size:90%;">7M</span></td>
<td id="S3.T3.3.4.3" class="ltx_td ltx_align_right"><span id="S3.T3.3.4.3.1" class="ltx_text" style="font-size:90%;">7M</span></td>
<td id="S3.T3.3.4.4" class="ltx_td ltx_align_center"><span id="S3.T3.3.4.4.1" class="ltx_text" style="font-size:90%;">75Hz</span></td>
<td id="S3.T3.3.4.5" class="ltx_td ltx_align_center"><span id="S3.T3.3.4.5.1" class="ltx_text" style="font-size:90%;">2.03</span></td>
<td id="S3.T3.3.4.6" class="ltx_td ltx_align_center"><span id="S3.T3.3.4.6.1" class="ltx_text" style="font-size:90%;">4.03</span></td>
<td id="S3.T3.3.4.7" class="ltx_td ltx_align_center"><span id="S3.T3.3.4.7.1" class="ltx_text" style="font-size:90%;">3.77</span></td>
</tr>
<tr id="S3.T3.3.5" class="ltx_tr">
<td id="S3.T3.3.5.1" class="ltx_td ltx_align_left">
<span id="S3.T3.3.5.1.1" class="ltx_text" style="font-size:90%;">SpeechTokenizerÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.3.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a><span id="S3.T3.3.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T3.3.5.2" class="ltx_td ltx_align_right"><span id="S3.T3.3.5.2.1" class="ltx_text" style="font-size:90%;">65M</span></td>
<td id="S3.T3.3.5.3" class="ltx_td ltx_align_right"><span id="S3.T3.3.5.3.1" class="ltx_text" style="font-size:90%;">34M</span></td>
<td id="S3.T3.3.5.4" class="ltx_td ltx_align_center"><span id="S3.T3.3.5.4.1" class="ltx_text" style="font-size:90%;">50Hz</span></td>
<td id="S3.T3.3.5.5" class="ltx_td ltx_align_center"><span id="S3.T3.3.5.5.1" class="ltx_text" style="font-size:90%;">2.41</span></td>
<td id="S3.T3.3.5.6" class="ltx_td ltx_align_center"><span id="S3.T3.3.5.6.1" class="ltx_text" style="font-size:90%;">4.19</span></td>
<td id="S3.T3.3.5.7" class="ltx_td ltx_align_center"><span id="S3.T3.3.5.7.1" class="ltx_text" style="font-size:90%;">3.89</span></td>
</tr>
<tr id="S3.T3.3.6" class="ltx_tr">
<td id="S3.T3.3.6.1" class="ltx_td ltx_align_left ltx_border_tt">
<span id="S3.T3.3.6.1.1" class="ltx_text" style="font-size:90%;">Mel-HifiGANÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.3.6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S3.T3.3.6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T3.3.6.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S3.T3.3.6.2.1" class="ltx_text" style="font-size:90%;">n/a</span></td>
<td id="S3.T3.3.6.3" class="ltx_td ltx_align_right ltx_border_tt"><span id="S3.T3.3.6.3.1" class="ltx_text" style="font-size:90%;">12M</span></td>
<td id="S3.T3.3.6.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.3.6.4.1" class="ltx_text" style="font-size:90%;">80Hz</span></td>
<td id="S3.T3.3.6.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.3.6.5.1" class="ltx_text" style="font-size:90%;">2.08</span></td>
<td id="S3.T3.3.6.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.3.6.6.1" class="ltx_text" style="font-size:90%;">4.52</span></td>
<td id="S3.T3.3.6.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.3.6.7.1" class="ltx_text" style="font-size:90%;">3.85</span></td>
</tr>
<tr id="S3.T3.3.7" class="ltx_tr">
<td id="S3.T3.3.7.1" class="ltx_td ltx_align_left">
<span id="S3.T3.3.7.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span><span id="S3.T3.3.7.1.2" class="ltx_text" style="font-size:90%;">-HifiGAN</span>
</td>
<td id="S3.T3.3.7.2" class="ltx_td ltx_align_right"><span id="S3.T3.3.7.2.1" class="ltx_text" style="font-size:90%;">n/a</span></td>
<td id="S3.T3.3.7.3" class="ltx_td ltx_align_right"><span id="S3.T3.3.7.3.1" class="ltx_text" style="font-size:90%;">12M</span></td>
<td id="S3.T3.3.7.4" class="ltx_td ltx_align_center"><span id="S3.T3.3.7.4.1" class="ltx_text" style="font-size:90%;">80Hz</span></td>
<td id="S3.T3.3.7.5" class="ltx_td ltx_align_center"><span id="S3.T3.3.7.5.1" class="ltx_text" style="font-size:90%;">2.11</span></td>
<td id="S3.T3.3.7.6" class="ltx_td ltx_align_center"><span id="S3.T3.3.7.6.1" class="ltx_text" style="font-size:90%;">4.47</span></td>
<td id="S3.T3.3.7.7" class="ltx_td ltx_align_center"><span id="S3.T3.3.7.7.1" class="ltx_text" style="font-size:90%;">3.73</span></td>
</tr>
<tr id="S3.T3.3.8" class="ltx_tr">
<td id="S3.T3.3.8.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T3.3.8.1.1" class="ltx_text" style="font-size:90%;">Mel-PWGÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T3.3.8.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib36" title="" class="ltx_ref">36</a><span id="S3.T3.3.8.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T3.3.8.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T3.3.8.2.1" class="ltx_text" style="font-size:90%;">n/a</span></td>
<td id="S3.T3.3.8.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T3.3.8.3.1" class="ltx_text" style="font-size:90%;">1M</span></td>
<td id="S3.T3.3.8.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.8.4.1" class="ltx_text" style="font-size:90%;">80Hz</span></td>
<td id="S3.T3.3.8.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.8.5.1" class="ltx_text" style="font-size:90%;">2.13</span></td>
<td id="S3.T3.3.8.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.8.6.1" class="ltx_text" style="font-size:90%;">4.40</span></td>
<td id="S3.T3.3.8.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.8.7.1" class="ltx_text" style="font-size:90%;">3.19</span></td>
</tr>
<tr id="S3.T3.3.9" class="ltx_tr">
<td id="S3.T3.3.9.1" class="ltx_td ltx_align_left">
<span id="S3.T3.3.9.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span><span id="S3.T3.3.9.1.2" class="ltx_text" style="font-size:90%;">-PWG</span>
</td>
<td id="S3.T3.3.9.2" class="ltx_td ltx_align_right"><span id="S3.T3.3.9.2.1" class="ltx_text" style="font-size:90%;">n/a</span></td>
<td id="S3.T3.3.9.3" class="ltx_td ltx_align_right"><span id="S3.T3.3.9.3.1" class="ltx_text" style="font-size:90%;">1M</span></td>
<td id="S3.T3.3.9.4" class="ltx_td ltx_align_center"><span id="S3.T3.3.9.4.1" class="ltx_text" style="font-size:90%;">80Hz</span></td>
<td id="S3.T3.3.9.5" class="ltx_td ltx_align_center"><span id="S3.T3.3.9.5.1" class="ltx_text" style="font-size:90%;">2.23</span></td>
<td id="S3.T3.3.9.6" class="ltx_td ltx_align_center"><span id="S3.T3.3.9.6.1" class="ltx_text" style="font-size:90%;">4.37</span></td>
<td id="S3.T3.3.9.7" class="ltx_td ltx_align_center"><span id="S3.T3.3.9.7.1" class="ltx_text" style="font-size:90%;">3.07</span></td>
</tr>
<tr id="S3.T3.3.10" class="ltx_tr">
<td id="S3.T3.3.10.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T3.3.10.1.1" class="ltx_text" style="font-size:90%;">Mel-PWG</span></td>
<td id="S3.T3.3.10.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T3.3.10.2.1" class="ltx_text" style="font-size:90%;">n/a</span></td>
<td id="S3.T3.3.10.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T3.3.10.3.1" class="ltx_text" style="font-size:90%;">1M</span></td>
<td id="S3.T3.3.10.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.10.4.1" class="ltx_text" style="font-size:90%;">40Hz</span></td>
<td id="S3.T3.3.10.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.10.5.1" class="ltx_text" style="font-size:90%;">2.36</span></td>
<td id="S3.T3.3.10.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.10.6.1" class="ltx_text" style="font-size:90%;">4.34</span></td>
<td id="S3.T3.3.10.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.10.7.1" class="ltx_text" style="font-size:90%;">2.90</span></td>
</tr>
<tr id="S3.T3.3.11" class="ltx_tr">
<td id="S3.T3.3.11.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T3.3.11.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span><span id="S3.T3.3.11.1.2" class="ltx_text" style="font-size:90%;">-PWG</span>
</td>
<td id="S3.T3.3.11.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T3.3.11.2.1" class="ltx_text" style="font-size:90%;">n/a</span></td>
<td id="S3.T3.3.11.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T3.3.11.3.1" class="ltx_text" style="font-size:90%;">1M</span></td>
<td id="S3.T3.3.11.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.3.11.4.1" class="ltx_text" style="font-size:90%;">40Hz</span></td>
<td id="S3.T3.3.11.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.3.11.5.1" class="ltx_text" style="font-size:90%;">2.51</span></td>
<td id="S3.T3.3.11.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.3.11.6.1" class="ltx_text" style="font-size:90%;">4.29</span></td>
<td id="S3.T3.3.11.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.3.11.7.1" class="ltx_text" style="font-size:90%;">2.76</span></td>
</tr>
</table>
</figure>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">From TableÂ <a href="#S3.T3" title="Table 3 â€£ 3.3.1 Speech Reconstruction â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we can see that semantic tokenization (HuBERT-KM) is not good for speech reconstruction.
Meanwhile, acoustic tokenizers that are optimized to reconstruct the signal directly (EnCodec and SpeechTokenizer) do well.</p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">We apply different vocoders to reconstruct the speech signal from mel-filterbanks, and find that the WER of the reconstructed speech signal is comparable to the acoustic tokenization methods with a fraction of the parameters.
Also, mel-filterbanks achieve a better MOS-LQO score, which indicates that the reconstructed audio is more similar to the original audio.
By comparing Mel and <span id="S3.SS3.SSS1.p3.1.1" class="ltx_text ltx_font_typewriter">dMel</span>, we can see that discretization has little impact on WER and MOS-LQO scores.
We also find that the exact vocoder matters much less than the frame rate of tokenization: the WER goes from 2.08 to 2.13 when switching from HifiGAN to ParallelWaveGAN, but it falls from 2.13 to 2.36 when the frame rate is changed from 80Hz to 40Hz.
However, even a 1M parameter vocoder operating at a 40Hz frame rate is comparable to the much larger SpeechTokenizer on WER and MOS-LQO metrics.</p>
</div>
<div id="S3.SS3.SSS1.p4" class="ltx_para">
<p id="S3.SS3.SSS1.p4.1" class="ltx_p"><span id="S3.SS3.SSS1.p4.1.1" class="ltx_text ltx_font_italic">Considering the efficiency and performance, we choose the <span id="S3.SS3.SSS1.p4.1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> speech tokenizer in 40Hz with ParallelWaveGAN vocoder for the following experiments.</span></p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>LM-Style Text-to-Speech</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">Here we compare the accuracy and naturalness of speech synthesized by LM-style text-to-speechÂ (TTS) models trained on different tokenization methods.
For TTS evaluation, we utilize WhisperXÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> (â€œbase.enâ€ fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>) to transcribe our generated speech into text and calculate the WER and the character error rateÂ (CER).
We report both WER and CER to facilitate comparisons to prior works which have reported only one or the other.</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">We trained the TTS model using the same architecture but with three different tokenization methods: HuBERT+KM (with 200 clusters), SpeechTokenizer, and <span id="S3.SS3.SSS2.p2.1.1" class="ltx_text ltx_font_typewriter">dMel</span>.
Additionally, we present the results from VOXTLMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and USLMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> for comparison.
VOXTLM is a larger model trained on more data that is initialized from a pretrained LLMÂ (OPT) using HuBERT-KM as the speech tokenizer.
USLM comprises an autoregressive (AR) model and a non-autoregressive (NAR) model, both trained with the SpeechTokenizer.</p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p">As shown in TableÂ <a href="#S3.T4" title="Table 4 â€£ 3.3.2 LM-Style Text-to-Speech â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> for training on LibriSpeech dataset, our decoder-only model with <span id="S3.SS3.SSS2.p3.1.1" class="ltx_text ltx_font_typewriter">dMel</span> tokenization achieves a WER of 4.3 and a CER of 1.8, significantly outperforming the baseline methods. This indicates that our model can generate more accurate speech with less hallucination and distortion.
Furthermore, we observed that the AR model trained on SpeechTokenizer-trained model exhibits a much higher WER compared to the idiosyncratic coarse to fine models (labeled AR+NAR) developed for these residual tokenizers â€“ indicating that <span id="S3.SS3.SSS2.p3.1.2" class="ltx_text ltx_font_typewriter">dMel</span> lies on a simpler data manifold.</p>
</div>
<div id="S3.SS3.SSS2.p4" class="ltx_para">
<p id="S3.SS3.SSS2.p4.1" class="ltx_p">Given the success of our decoder-only <span id="S3.SS3.SSS2.p4.1.1" class="ltx_text ltx_font_typewriter">dMel</span> TTS model, dubbed <span id="S3.SS3.SSS2.p4.1.2" class="ltx_text ltx_font_typewriter">RichTTS</span>, we further evaluate it on various datasets, including LJSpeechÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, VCTKÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, and LibriTTSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, and compare it with popular TTS models, including Tacotron2Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, FastSpeech2Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, and VITSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
We conduct human evaluation to measure the naturalness of 50 randomly sampled synthesized speech from VCTK test set.
The results are shown in TableÂ <a href="#S3.T5" title="Table 5 â€£ 3.3.2 LM-Style Text-to-Speech â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
Our model achieves competitive performance on the TTS task in terms of both MOS and WER, demonstrating its effectiveness in generating high-quality synthesized speech.
Interestingly, we find that VITS performs poorly on the VCTK WER.
We suspect that this is because VITS tends to make more mistakes at the beginning of each sequence, and since VCTK comprises short sequences, even one or two word errors can lead to a high WER.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Text-to-speech results for different tokenizers. All models are trained on LibriSpeech 960h dataset. Evaluation is done via speech generation on the full <span id="S3.T4.4.1" class="ltx_text ltx_font_italic">test-clean</span> transcriptions and speakers, and then evaluated WER with WhisperX base.en. We use â€ Â  to annotate results from the reference paper. <span id="S3.T4.5.2" class="ltx_text ltx_font_typewriter">RichTTS</span> is our model trained with <span id="S3.T4.6.3" class="ltx_text ltx_font_typewriter">dMel</span> tokenization. </figcaption>
<table id="S3.T4.7" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T4.7.1" class="ltx_tr">
<td id="S3.T4.7.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T4.7.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S3.T4.7.1.2.1" class="ltx_text" style="font-size:90%;">WER (%)</span></td>
<td id="S3.T4.7.1.3" class="ltx_td ltx_align_right ltx_border_tt"><span id="S3.T4.7.1.3.1" class="ltx_text" style="font-size:90%;">CER (%)</span></td>
</tr>
<tr id="S3.T4.7.2" class="ltx_tr">
<td id="S3.T4.7.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T4.7.2.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="S3.T4.7.2.1.2" class="ltx_text" style="font-size:90%;"> (HuBERT+KM), 258M</span>
</td>
<td id="S3.T4.7.2.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T4.7.2.2.1" class="ltx_text" style="font-size:90%;">9.5</span></td>
<td id="S3.T4.7.2.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T4.7.2.3.1" class="ltx_text" style="font-size:90%;">4.3</span></td>
</tr>
<tr id="S3.T4.7.3" class="ltx_tr">
<td id="S3.T4.7.3.1" class="ltx_td ltx_align_left">
<span id="S3.T4.7.3.1.1" class="ltx_text" style="font-size:90%;">VOXTLM (HuBERT+KM)â€ Â </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.7.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S3.T4.7.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.T4.7.3.1.4" class="ltx_text" style="font-size:90%;">, 350M</span>
</td>
<td id="S3.T4.7.3.2" class="ltx_td ltx_align_right"><span id="S3.T4.7.3.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T4.7.3.3" class="ltx_td ltx_align_right"><span id="S3.T4.7.3.3.1" class="ltx_text" style="font-size:90%;">3.5</span></td>
</tr>
<tr id="S3.T4.7.4" class="ltx_tr">
<td id="S3.T4.7.4.1" class="ltx_td ltx_align_left">
<span id="S3.T4.7.4.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="S3.T4.7.4.1.2" class="ltx_text" style="font-size:90%;"> (SpeechTokenizer), AR, 258M</span>
</td>
<td id="S3.T4.7.4.2" class="ltx_td ltx_align_right"><span id="S3.T4.7.4.2.1" class="ltx_text" style="font-size:90%;">11.4</span></td>
<td id="S3.T4.7.4.3" class="ltx_td ltx_align_right"><span id="S3.T4.7.4.3.1" class="ltx_text" style="font-size:90%;">5.9</span></td>
</tr>
<tr id="S3.T4.7.5" class="ltx_tr">
<td id="S3.T4.7.5.1" class="ltx_td ltx_align_left">
<span id="S3.T4.7.5.1.1" class="ltx_text" style="font-size:90%;">USLM (SpeechTokenizer)â€ , AR+NARÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.7.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a><span id="S3.T4.7.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.T4.7.5.1.4" class="ltx_text" style="font-size:90%;">, 356M</span>
</td>
<td id="S3.T4.7.5.2" class="ltx_td ltx_align_right"><span id="S3.T4.7.5.2.1" class="ltx_text" style="font-size:90%;">6.5</span></td>
<td id="S3.T4.7.5.3" class="ltx_td ltx_align_right"><span id="S3.T4.7.5.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S3.T4.7.6" class="ltx_tr">
<td id="S3.T4.7.6.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T4.7.6.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="S3.T4.7.6.1.2" class="ltx_text" style="font-size:90%;"> (</span><span id="S3.T4.7.6.1.3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span><span id="S3.T4.7.6.1.4" class="ltx_text" style="font-size:90%;">), 258M</span>
</td>
<td id="S3.T4.7.6.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T4.7.6.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.3</span></td>
<td id="S3.T4.7.6.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T4.7.6.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">1.8</span></td>
</tr>
</table>
</figure>
<figure id="S3.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>WER (%) (evaluated with WhisperX base.en ASR model) of different TTS modelsâ€™ generations using transcriptions from the evaluation set of each dataset. Each column corresponds to the training and evaluation dataset. We used ESP-NetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> to generate the results for prior work.</figcaption>
<table id="S3.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T5.1.1" class="ltx_tr">
<td id="S3.T5.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T5.1.1.2.1" class="ltx_text" style="font-size:90%;">WER</span></td>
<td id="S3.T5.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T5.1.1.3.1" class="ltx_text" style="font-size:90%;">MOS</span></td>
</tr>
<tr id="S3.T5.1.2" class="ltx_tr">
<td id="S3.T5.1.2.1" class="ltx_td"></td>
<td id="S3.T5.1.2.2" class="ltx_td ltx_align_right"><span id="S3.T5.1.2.2.1" class="ltx_text" style="font-size:90%;">LJSpeech</span></td>
<td id="S3.T5.1.2.3" class="ltx_td ltx_align_right"><span id="S3.T5.1.2.3.1" class="ltx_text" style="font-size:90%;">VCTK</span></td>
<td id="S3.T5.1.2.4" class="ltx_td ltx_align_right ltx_border_r"><span id="S3.T5.1.2.4.1" class="ltx_text" style="font-size:90%;">LibriTTS</span></td>
<td id="S3.T5.1.2.5" class="ltx_td ltx_align_center"><span id="S3.T5.1.2.5.1" class="ltx_text" style="font-size:90%;">VCTK</span></td>
</tr>
<tr id="S3.T5.1.3" class="ltx_tr">
<td id="S3.T5.1.3.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T5.1.3.1.1" class="ltx_text" style="font-size:90%;">Tacotron2Â </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T5.1.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S3.T5.1.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T5.1.3.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T5.1.3.2.1" class="ltx_text" style="font-size:90%;">4.4</span></td>
<td id="S3.T5.1.3.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T5.1.3.3.1" class="ltx_text" style="font-size:90%;">4.9</span></td>
<td id="S3.T5.1.3.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span id="S3.T5.1.3.4.1" class="ltx_text" style="font-size:90%;">7.3</span></td>
<td id="S3.T5.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T5.1.3.5.1" class="ltx_text" style="font-size:90%;">1.3</span></td>
</tr>
<tr id="S3.T5.1.4" class="ltx_tr">
<td id="S3.T5.1.4.1" class="ltx_td ltx_align_left">
<span id="S3.T5.1.4.1.1" class="ltx_text" style="font-size:90%;">FastSpeech2Â </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T5.1.4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S3.T5.1.4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T5.1.4.2" class="ltx_td ltx_align_right"><span id="S3.T5.1.4.2.1" class="ltx_text" style="font-size:90%;">6.1</span></td>
<td id="S3.T5.1.4.3" class="ltx_td ltx_align_right"><span id="S3.T5.1.4.3.1" class="ltx_text" style="font-size:90%;">8.7</span></td>
<td id="S3.T5.1.4.4" class="ltx_td ltx_align_right ltx_border_r"><span id="S3.T5.1.4.4.1" class="ltx_text" style="font-size:90%;">10.2</span></td>
<td id="S3.T5.1.4.5" class="ltx_td ltx_align_center"><span id="S3.T5.1.4.5.1" class="ltx_text" style="font-size:90%;">1.3</span></td>
</tr>
<tr id="S3.T5.1.5" class="ltx_tr">
<td id="S3.T5.1.5.1" class="ltx_td ltx_align_left">
<span id="S3.T5.1.5.1.1" class="ltx_text" style="font-size:90%;">VITSÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T5.1.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S3.T5.1.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T5.1.5.2" class="ltx_td ltx_align_right"><span id="S3.T5.1.5.2.1" class="ltx_text" style="font-size:90%;">6.4</span></td>
<td id="S3.T5.1.5.3" class="ltx_td ltx_align_right"><span id="S3.T5.1.5.3.1" class="ltx_text" style="font-size:90%;">24.1</span></td>
<td id="S3.T5.1.5.4" class="ltx_td ltx_align_right ltx_border_r"><span id="S3.T5.1.5.4.1" class="ltx_text" style="font-size:90%;">8.3</span></td>
<td id="S3.T5.1.5.5" class="ltx_td ltx_align_center"><span id="S3.T5.1.5.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.1</span></td>
</tr>
<tr id="S3.T5.1.6" class="ltx_tr">
<td id="S3.T5.1.6.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T5.1.6.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="S3.T5.1.6.1.2" class="ltx_text" style="font-size:90%;"> (Ours)</span>
</td>
<td id="S3.T5.1.6.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T5.1.6.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.0</span></td>
<td id="S3.T5.1.6.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T5.1.6.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">2.2</span></td>
<td id="S3.T5.1.6.4" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r"><span id="S3.T5.1.6.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.5</span></td>
<td id="S3.T5.1.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T5.1.6.5.1" class="ltx_text" style="font-size:90%;">3.9</span></td>
</tr>
</table>
</figure>
<div id="S3.SS3.SSS2.p5" class="ltx_para">
<p id="S3.SS3.SSS2.p5.1" class="ltx_p">Furthermore, we observed that our model with <span id="S3.SS3.SSS2.p5.1.1" class="ltx_text ltx_font_typewriter">dMel</span> tokenization can generate long audio sequences with high quality. Here, we evaluate the performance of our model on different lengths of text sequences using the LJSpeech test set.
TableÂ <a href="#S3.T6" title="Table 6 â€£ 3.3.2 LM-Style Text-to-Speech â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the WER results for our model on text sequences with 10-20 words and more than 20 words.
We ignore text sequences with fewer than 10 words, as they are too short and not robust for WER evaluation.
From TableÂ <a href="#S3.T6" title="Table 6 â€£ 3.3.2 LM-Style Text-to-Speech â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we observe that our model achieves competitive performance across different text lengths, demonstrating its robustness and generalization ability in generating synthesized speech for varying text inputs lengths.
Additionally, we find that the non-autoregressive (NAR) model FastSpeech2 achieves the lowest WER on shorter sequences but the highest WER on longer sequences. This suggests that NAR models may not be well-suited for generating long audio sequences.</p>
</div>
<figure id="S3.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Text-to-speech results for models trained on Librispeech 960h data and evaluated on the transcriptions from LJSpeech test set. We show WER (%) evaluated by WhisperX base.en ASR model on text grouped by sequence length.</figcaption>
<table id="S3.T6.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T6.1.1" class="ltx_tr">
<td id="S3.T6.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T6.1.1.1.1" class="ltx_text" style="font-size:90%;">WER</span></td>
<td id="S3.T6.1.1.2" class="ltx_td ltx_align_right ltx_border_tt">
<span id="S3.T6.1.1.2.1" class="ltx_text" style="font-size:90%;">Tacotron2Â </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T6.1.1.2.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S3.T6.1.1.2.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T6.1.1.3" class="ltx_td ltx_align_right ltx_border_tt">
<span id="S3.T6.1.1.3.1" class="ltx_text" style="font-size:90%;">FastSpeech2Â </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T6.1.1.3.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S3.T6.1.1.3.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T6.1.1.4" class="ltx_td ltx_align_right ltx_border_tt">
<span id="S3.T6.1.1.4.1" class="ltx_text" style="font-size:90%;">VITS(YourTTS)Â </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T6.1.1.4.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S3.T6.1.1.4.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S3.T6.1.1.5" class="ltx_td ltx_align_right ltx_border_tt">
<span id="S3.T6.1.1.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="S3.T6.1.1.5.2" class="ltx_text" style="font-size:90%;"> (Ours)</span>
</td>
</tr>
<tr id="S3.T6.1.2" class="ltx_tr">
<td id="S3.T6.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T6.1.2.1.1" class="ltx_text" style="font-size:90%;">total</span></td>
<td id="S3.T6.1.2.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T6.1.2.2.1" class="ltx_text" style="font-size:90%;">4.4</span></td>
<td id="S3.T6.1.2.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T6.1.2.3.1" class="ltx_text" style="font-size:90%;">6.1</span></td>
<td id="S3.T6.1.2.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T6.1.2.4.1" class="ltx_text" style="font-size:90%;">6.4</span></td>
<td id="S3.T6.1.2.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T6.1.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.0</span></td>
</tr>
<tr id="S3.T6.1.3" class="ltx_tr">
<td id="S3.T6.1.3.1" class="ltx_td ltx_align_left"><span id="S3.T6.1.3.1.1" class="ltx_text" style="font-size:90%;">10-20 words</span></td>
<td id="S3.T6.1.3.2" class="ltx_td ltx_align_right"><span id="S3.T6.1.3.2.1" class="ltx_text" style="font-size:90%;">5.5</span></td>
<td id="S3.T6.1.3.3" class="ltx_td ltx_align_right"><span id="S3.T6.1.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.1</span></td>
<td id="S3.T6.1.3.4" class="ltx_td ltx_align_right"><span id="S3.T6.1.3.4.1" class="ltx_text" style="font-size:90%;">7.4</span></td>
<td id="S3.T6.1.3.5" class="ltx_td ltx_align_right"><span id="S3.T6.1.3.5.1" class="ltx_text" style="font-size:90%;">3.5</span></td>
</tr>
<tr id="S3.T6.1.4" class="ltx_tr">
<td id="S3.T6.1.4.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T6.1.4.1.1" class="ltx_text" style="font-size:90%;">more than 20 words</span></td>
<td id="S3.T6.1.4.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T6.1.4.2.1" class="ltx_text" style="font-size:90%;">3.3</span></td>
<td id="S3.T6.1.4.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T6.1.4.3.1" class="ltx_text" style="font-size:90%;">9.1</span></td>
<td id="S3.T6.1.4.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T6.1.4.4.1" class="ltx_text" style="font-size:90%;">5.3</span></td>
<td id="S3.T6.1.4.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T6.1.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.0</span></td>
</tr>
</table>
</figure>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>LM-Style Speech-to-Text</h4>

<figure id="S3.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Our Base ASRÂ (258M) models are trained on LibriSpeech 960h and evaluated for different speech tokenizers (greedy decoding is reported). We compare also with prior SOTA work on decoder-only model for ASR (VOXTLM). Results are shown across 2 runs with mean WER and standard deviation.</figcaption>
<table id="S3.T7.12" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T7.12.13" class="ltx_tr">
<td id="S3.T7.12.13.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T7.12.13.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T7.12.13.2.1" class="ltx_text" style="font-size:90%;">dev-clean</span></td>
<td id="S3.T7.12.13.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T7.12.13.3.1" class="ltx_text" style="font-size:90%;">dev-other</span></td>
<td id="S3.T7.12.13.4" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T7.12.13.4.1" class="ltx_text" style="font-size:90%;">test-clean</span></td>
<td id="S3.T7.12.13.5" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T7.12.13.5.1" class="ltx_text" style="font-size:90%;">test-other</span></td>
</tr>
<tr id="S3.T7.12.14" class="ltx_tr">
<td id="S3.T7.12.14.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T7.12.14.1.1" class="ltx_text" style="font-size:90%;">VOXTLMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T7.12.14.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S3.T7.12.14.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.T7.12.14.1.4" class="ltx_text" style="font-size:90%;"> (HuBERT+KMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T7.12.14.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S3.T7.12.14.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.T7.12.14.1.7" class="ltx_text" style="font-size:90%;">), 350M</span>
</td>
<td id="S3.T7.12.14.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T7.12.14.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T7.12.14.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T7.12.14.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T7.12.14.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T7.12.14.4.1" class="ltx_text" style="font-size:90%;">6.5</span></td>
<td id="S3.T7.12.14.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T7.12.14.5.1" class="ltx_text" style="font-size:90%;">17.6</span></td>
</tr>
<tr id="S3.T7.12.15" class="ltx_tr">
<td id="S3.T7.12.15.1" class="ltx_td ltx_align_left">
<span id="S3.T7.12.15.1.1" class="ltx_text" style="font-size:90%;">VOXTLMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T7.12.15.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S3.T7.12.15.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.T7.12.15.1.4" class="ltx_text" style="font-size:90%;"> (HuBERT+KMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T7.12.15.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S3.T7.12.15.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.T7.12.15.1.7" class="ltx_text" style="font-size:90%;">), 1.3B</span>
</td>
<td id="S3.T7.12.15.2" class="ltx_td ltx_align_left"><span id="S3.T7.12.15.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T7.12.15.3" class="ltx_td ltx_align_left"><span id="S3.T7.12.15.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T7.12.15.4" class="ltx_td ltx_align_left"><span id="S3.T7.12.15.4.1" class="ltx_text" style="font-size:90%;">4.6</span></td>
<td id="S3.T7.12.15.5" class="ltx_td ltx_align_left"><span id="S3.T7.12.15.5.1" class="ltx_text" style="font-size:90%;">12.1</span></td>
</tr>
<tr id="S3.T7.4.4" class="ltx_tr">
<td id="S3.T7.4.4.5" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T7.4.4.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichASR</span><span id="S3.T7.4.4.5.2" class="ltx_text" style="font-size:90%;"> (SpeechTokenizerÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T7.4.4.5.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a><span id="S3.T7.4.4.5.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.T7.4.4.5.5" class="ltx_text" style="font-size:90%;">)</span>
</td>
<td id="S3.T7.1.1.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T7.1.1.1.1" class="ltx_text" style="font-size:90%;">6.5</span><math id="S3.T7.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.1.1.1.m1.1a"><mo mathsize="90%" id="S3.T7.1.1.1.m1.1.1" xref="S3.T7.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T7.1.1.1.m1.1.1.cmml" xref="S3.T7.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S3.T7.1.1.1.2" class="ltx_text" style="font-size:90%;">0.3</span>
</td>
<td id="S3.T7.2.2.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T7.2.2.2.1" class="ltx_text" style="font-size:90%;">16.9</span><math id="S3.T7.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.2.2.2.m1.1a"><mo mathsize="90%" id="S3.T7.2.2.2.m1.1.1" xref="S3.T7.2.2.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.2.2.2.m1.1b"><csymbol cd="latexml" id="S3.T7.2.2.2.m1.1.1.cmml" xref="S3.T7.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.2.2.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T7.2.2.2.2" class="ltx_text" style="font-size:90%;">0.7</span>
</td>
<td id="S3.T7.3.3.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T7.3.3.3.1" class="ltx_text" style="font-size:90%;">6.9</span><math id="S3.T7.3.3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.3.3.3.m1.1a"><mo mathsize="90%" id="S3.T7.3.3.3.m1.1.1" xref="S3.T7.3.3.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.3.3.3.m1.1b"><csymbol cd="latexml" id="S3.T7.3.3.3.m1.1.1.cmml" xref="S3.T7.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.3.3.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T7.3.3.3.2" class="ltx_text" style="font-size:90%;">0.4</span>
</td>
<td id="S3.T7.4.4.4" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T7.4.4.4.1" class="ltx_text" style="font-size:90%;">17.5</span><math id="S3.T7.4.4.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.4.4.4.m1.1a"><mo mathsize="90%" id="S3.T7.4.4.4.m1.1.1" xref="S3.T7.4.4.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.4.4.4.m1.1b"><csymbol cd="latexml" id="S3.T7.4.4.4.m1.1.1.cmml" xref="S3.T7.4.4.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.4.4.4.m1.1c">\pm</annotation></semantics></math><span id="S3.T7.4.4.4.2" class="ltx_text" style="font-size:90%;">0.5</span>
</td>
</tr>
<tr id="S3.T7.8.8" class="ltx_tr">
<td id="S3.T7.8.8.5" class="ltx_td ltx_align_left">
<span id="S3.T7.8.8.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichASR</span><span id="S3.T7.8.8.5.2" class="ltx_text" style="font-size:90%;"> (HuBERT+KMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T7.8.8.5.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S3.T7.8.8.5.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.T7.8.8.5.5" class="ltx_text" style="font-size:90%;">)</span>
</td>
<td id="S3.T7.5.5.1" class="ltx_td ltx_align_left">
<span id="S3.T7.5.5.1.1" class="ltx_text" style="font-size:90%;">5.3</span><math id="S3.T7.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.5.5.1.m1.1a"><mo mathsize="90%" id="S3.T7.5.5.1.m1.1.1" xref="S3.T7.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.5.5.1.m1.1b"><csymbol cd="latexml" id="S3.T7.5.5.1.m1.1.1.cmml" xref="S3.T7.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.5.5.1.m1.1c">\pm</annotation></semantics></math><span id="S3.T7.5.5.1.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="S3.T7.6.6.2" class="ltx_td ltx_align_left">
<span id="S3.T7.6.6.2.1" class="ltx_text" style="font-size:90%;">13.7</span><math id="S3.T7.6.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.6.6.2.m1.1a"><mo mathsize="90%" id="S3.T7.6.6.2.m1.1.1" xref="S3.T7.6.6.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.6.6.2.m1.1b"><csymbol cd="latexml" id="S3.T7.6.6.2.m1.1.1.cmml" xref="S3.T7.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.6.6.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T7.6.6.2.2" class="ltx_text" style="font-size:90%;">0.2</span>
</td>
<td id="S3.T7.7.7.3" class="ltx_td ltx_align_left">
<span id="S3.T7.7.7.3.1" class="ltx_text" style="font-size:90%;">5.8</span><math id="S3.T7.7.7.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.7.7.3.m1.1a"><mo mathsize="90%" id="S3.T7.7.7.3.m1.1.1" xref="S3.T7.7.7.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.7.7.3.m1.1b"><csymbol cd="latexml" id="S3.T7.7.7.3.m1.1.1.cmml" xref="S3.T7.7.7.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.7.7.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T7.7.7.3.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="S3.T7.8.8.4" class="ltx_td ltx_align_left">
<span id="S3.T7.8.8.4.1" class="ltx_text" style="font-size:90%;">13.8</span><math id="S3.T7.8.8.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.8.8.4.m1.1a"><mo mathsize="90%" id="S3.T7.8.8.4.m1.1.1" xref="S3.T7.8.8.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.8.8.4.m1.1b"><csymbol cd="latexml" id="S3.T7.8.8.4.m1.1.1.cmml" xref="S3.T7.8.8.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.8.8.4.m1.1c">\pm</annotation></semantics></math><span id="S3.T7.8.8.4.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
</tr>
<tr id="S3.T7.12.12" class="ltx_tr">
<td id="S3.T7.12.12.5" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T7.12.12.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichASR</span><span id="S3.T7.12.12.5.2" class="ltx_text" style="font-size:90%;"> (</span><span id="S3.T7.12.12.5.3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span><span id="S3.T7.12.12.5.4" class="ltx_text" style="font-size:90%;">)</span>
</td>
<td id="S3.T7.9.9.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T7.9.9.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.8<math id="S3.T7.9.9.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.9.9.1.1.m1.1a"><mo id="S3.T7.9.9.1.1.m1.1.1" xref="S3.T7.9.9.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.9.9.1.1.m1.1b"><csymbol cd="latexml" id="S3.T7.9.9.1.1.m1.1.1.cmml" xref="S3.T7.9.9.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.9.9.1.1.m1.1c">\pm</annotation></semantics></math></span><span id="S3.T7.9.9.1.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="S3.T7.10.10.2" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T7.10.10.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">10.3<math id="S3.T7.10.10.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.10.10.2.1.m1.1a"><mo id="S3.T7.10.10.2.1.m1.1.1" xref="S3.T7.10.10.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.10.10.2.1.m1.1b"><csymbol cd="latexml" id="S3.T7.10.10.2.1.m1.1.1.cmml" xref="S3.T7.10.10.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.10.10.2.1.m1.1c">\pm</annotation></semantics></math></span><span id="S3.T7.10.10.2.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="S3.T7.11.11.3" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T7.11.11.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.2<math id="S3.T7.11.11.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.11.11.3.1.m1.1a"><mo id="S3.T7.11.11.3.1.m1.1.1" xref="S3.T7.11.11.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.11.11.3.1.m1.1b"><csymbol cd="latexml" id="S3.T7.11.11.3.1.m1.1.1.cmml" xref="S3.T7.11.11.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.11.11.3.1.m1.1c">\pm</annotation></semantics></math></span><span id="S3.T7.11.11.3.2" class="ltx_text" style="font-size:90%;">0.2</span>
</td>
<td id="S3.T7.12.12.4" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T7.12.12.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">10.4<math id="S3.T7.12.12.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T7.12.12.4.1.m1.1a"><mo id="S3.T7.12.12.4.1.m1.1.1" xref="S3.T7.12.12.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T7.12.12.4.1.m1.1b"><csymbol cd="latexml" id="S3.T7.12.12.4.1.m1.1.1.cmml" xref="S3.T7.12.12.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.12.12.4.1.m1.1c">\pm</annotation></semantics></math></span><span id="S3.T7.12.12.4.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
</tr>
</table>
</figure>
<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">Training an LM-style speech-to-textÂ (ASR) model can test if the speech tokens can preserve the semantic information in the speech signal and support the speech understanding task.
TableÂ <a href="#S3.T7" title="Table 7 â€£ 3.3.3 LM-Style Speech-to-Text â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows results of our model <span id="S3.SS3.SSS3.p1.1.1" class="ltx_text ltx_font_typewriter">RichASR</span> trained with different tokenizations including <span id="S3.SS3.SSS3.p1.1.2" class="ltx_text ltx_font_typewriter">dMel</span> for the ASR task. Our decoder-only model with <span id="S3.SS3.SSS3.p1.1.3" class="ltx_text ltx_font_typewriter">dMel</span> speech tokenization achieves 4.2% WER on the <span id="S3.SS3.SSS3.p1.1.4" class="ltx_text ltx_font_italic">test-clean</span> and 10.4% WER on the <span id="S3.SS3.SSS3.p1.1.5" class="ltx_text ltx_font_italic">test-other</span> sets outperforming both HuBERT-KM and SpeechTokenizer.
We also observe that our model with HuBERT-KMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> outperforms the SpeechTokenizerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> for ASR, which is reasonable as semantic tokens are more suitable for the ASR task.
Additionally, our method outperforms VOXTLMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, which is a larger model trained with more data and initialized from a pretrained LLM (OPT) using HuBERT-KM (we use exactly the same tokenization with 200 clusters) as the speech tokenizer.
The ASR results clearly demonstrate the benefit of using our speech tokenizer for the speech understanding task, as it better preserves the semantic information in the speech signal. Further details and ablations on data size and model size can be found in AppendixÂ <a href="#A4" title="Appendix D Training Details â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a> and AppendixÂ <a href="#A5" title="Appendix E Ablations â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a> TableÂ <a href="#A5.T11" title="Table 11 â€£ E.2 LM-Style Speech-to-Text â€£ Appendix E Ablations â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
</section>
<section id="S3.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4 </span>Joint Speech-Text Modeling</h4>

<figure id="S3.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Results of ASR and TTS jointly trained model on LibriSpeech dataset.</figcaption>
<table id="S3.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T8.1.1" class="ltx_tr">
<td id="S3.T8.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T8.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T8.1.1.2.1" class="ltx_text" style="font-size:90%;">ASR</span></td>
<td id="S3.T8.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T8.1.1.3.1" class="ltx_text" style="font-size:90%;">TTS</span></td>
</tr>
<tr id="S3.T8.1.2" class="ltx_tr">
<td id="S3.T8.1.2.1" class="ltx_td"></td>
<td id="S3.T8.1.2.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T8.1.2.2.1" class="ltx_text" style="font-size:90%;">test-clean</span></td>
<td id="S3.T8.1.2.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T8.1.2.3.1" class="ltx_text" style="font-size:90%;">test-other</span></td>
<td id="S3.T8.1.2.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T8.1.2.4.1" class="ltx_text" style="font-size:90%;">WER</span></td>
<td id="S3.T8.1.2.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T8.1.2.5.1" class="ltx_text" style="font-size:90%;">CER</span></td>
</tr>
<tr id="S3.T8.1.3" class="ltx_tr">
<td id="S3.T8.1.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T8.1.3.1.1" class="ltx_text" style="font-size:90%;">VOXTLM+OPT, 350M</span></td>
<td id="S3.T8.1.3.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T8.1.3.2.1" class="ltx_text" style="font-size:90%;">3.5</span></td>
<td id="S3.T8.1.3.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T8.1.3.3.1" class="ltx_text" style="font-size:90%;">8.7</span></td>
<td id="S3.T8.1.3.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T8.1.3.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T8.1.3.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T8.1.3.5.1" class="ltx_text" style="font-size:90%;">3.5</span></td>
</tr>
<tr id="S3.T8.1.4" class="ltx_tr">
<td id="S3.T8.1.4.1" class="ltx_td ltx_align_left">
<span id="S3.T8.1.4.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichASR</span><span id="S3.T8.1.4.1.2" class="ltx_text" style="font-size:90%;">-</span><span id="S3.T8.1.4.1.3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="S3.T8.1.4.1.4" class="ltx_text" style="font-size:90%;">, single models, 258M</span>
</td>
<td id="S3.T8.1.4.2" class="ltx_td ltx_align_right"><span id="S3.T8.1.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.2</span></td>
<td id="S3.T8.1.4.3" class="ltx_td ltx_align_right"><span id="S3.T8.1.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">10.4</span></td>
<td id="S3.T8.1.4.4" class="ltx_td ltx_align_right"><span id="S3.T8.1.4.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.3</span></td>
<td id="S3.T8.1.4.5" class="ltx_td ltx_align_right"><span id="S3.T8.1.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">1.8</span></td>
</tr>
<tr id="S3.T8.1.5" class="ltx_tr">
<td id="S3.T8.1.5.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T8.1.5.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichASR</span><span id="S3.T8.1.5.1.2" class="ltx_text" style="font-size:90%;">-</span><span id="S3.T8.1.5.1.3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="S3.T8.1.5.1.4" class="ltx_text" style="font-size:90%;">, joint model, 258M</span>
</td>
<td id="S3.T8.1.5.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T8.1.5.2.1" class="ltx_text" style="font-size:90%;">7.6</span></td>
<td id="S3.T8.1.5.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T8.1.5.3.1" class="ltx_text" style="font-size:90%;">20.0</span></td>
<td id="S3.T8.1.5.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T8.1.5.4.1" class="ltx_text" style="font-size:90%;">4.4</span></td>
<td id="S3.T8.1.5.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T8.1.5.5.1" class="ltx_text" style="font-size:90%;">1.9</span></td>
</tr>
</table>
</figure>
<div id="S3.SS3.SSS4.p1" class="ltx_para">
<p id="S3.SS3.SSS4.p1.1" class="ltx_p">Our model design allows us to train a single model for both ASR and TTS tasks leading to a simpler setup.
We train a single model with the same architecture and tokenization as <span id="S3.SS3.SSS4.p1.1.1" class="ltx_text ltx_font_typewriter">RichTTS</span>, by constructing the training data with &lt;text, speech&gt; and &lt;speech, text&gt; pairs for ASR and TTS tasks, respectively.
By mixing these two types of data, we can train a single model for both tasks.</p>
</div>
<div id="S3.SS3.SSS4.p2" class="ltx_para">
<p id="S3.SS3.SSS4.p2.1" class="ltx_p">TableÂ <a href="#S3.T8" title="Table 8 â€£ 3.3.4 Joint Speech-Text Modeling â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows that the joint model is worse on both tasks, but ASR is affected more than TTS.
Comparing our results to VOXTLMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, which initializes its model from pretrained LLM (OPT) and finetunes it with multiple tasks and datasets, we speculate that our joint model needs text-only training to learn a good LM for better ASR performance. Our model structure trivially allows for this text-only training, but we leave those experiments for future work.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Related Work</h2>

<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Speech Tokenization</h5>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">Speech tokenization is a critical step in speech processing tasks, enabling the discretization of continuous speech signals into tokens for language model-based processing. Existing speech tokenization methods can be broadly categorized into two types: semantic tokens and acoustic tokens. Semantic tokens are extracted from self-supervised pretrained speech models, where the speech signal is first encoded into speech representations and then clustered into semantic tokens with <math id="S4.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S4.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.1.m1.1c">k</annotation></semantics></math>-means clusteringÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Acoustic tokens are obtained from pretrained audio compression models, which compress the speech signal into codebook indices with residual vector quantizationÂ (RVQ) and reconstruction objectivesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
To combine the advantage of both semantic and acoustic tokens, AudioLMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> proposed to modeling both semantic tokens and acoustic tokens with 3 stages: semantic modeling, coarse acoustic modeling, and fine acoustic modeling.
This solution covers both the content and speech quality, but its multi-stage hierarchical structure complicates the model and slows the training and inference.
AudioPalmÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> follows a similar approach, and show that the scale of speech tokenizerâ€™s training data and model parameters are critical for this multi-stage modeling.
This observation indicates the speech compression model is far from lossless, and not generalizable to low-resource scenarios.
Another solution is combining the semantic and acoustic feature together, and formulate a new token that capture both the semantic and acoustic information.
<cite class="ltx_cite ltx_citemacro_citet">Zhang etÂ al. [<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> proposed to distill the semantic tokens into the acoustic tokenâ€™s first residual channel during the training of the RVQ model in a teacher-student manner.
However, such combined methods are complex and require additional pretraining, complicating the model architecture and increasing computational overhead.
Also, the model architecture is still not a single stage model, where only the semantic modeling is skipped.
In comparison, <span id="S4.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> is a train-free speech tokenization method that discretizes mel-filterbanks directly into bins, inherently preserving both semantic and acoustic information in a unified representation.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Speech-Text Modeling</h5>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">Modeling speech and text jointly is a challenging task, as speech signals are continuous and while text is discrete.
Existing works have explored various approaches to address this challenge, including usage of separate encoders for different modalitiesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Bai etÂ al. [<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> proposed an encoder only model A3T for speech-text modeling, by introducing alignment embedding to encourage cross-modal transfer between text and speech.
Although A3T achieved good performance on speech synthesis and editing tasks, it cannot generate text and cannot generalize to longform generation because of its encoder-only architecture and mask-reconstruction training strategy.
VioLAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> also targets a unified speech-text model which can generate speech and text with a single model, but it is specifically designed for the EncodecÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> style feature, and compelled to model speech tokens in a multi-stage hierarchical manner.
<cite class="ltx_cite ltx_citemacro_citet">Maiti etÂ al. [<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> proposed a decoder-only language model VOXTLM, to model speech and text jointly.
However, VOXTLM is only models the HuBERT semantic tokens, and relies on an external generation model to transform semantic tokens into waveform, but the speaker and acoustic information are lost.
In comparison, the model architecture in this paper is a simple, single stage decoder-only transformer language model, and can handle both the speech generation and text generation tasks.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we proposed <span id="S5.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span>, a novel train-free speech tokenization method that discretizes mel-filterbank energies directly into bins. By operating on the authentic mel-filterbank representation, <span id="S5.p1.1.2" class="ltx_text ltx_font_typewriter">dMel</span> inherently preserves both semantic and acoustic information in a unified tokenized representation. Our key contribution is the evaluation of <span id="S5.p1.1.3" class="ltx_text ltx_font_typewriter">dMel</span> within a unified transformer decoder-only architecture for speech recognition (ASR) and speech synthesis (TTS) tasks.
Our <span id="S5.p1.1.4" class="ltx_text ltx_font_typewriter">dMel</span>-based ASR model, <span id="S5.p1.1.5" class="ltx_text ltx_font_typewriter">RichASR</span>, achieved the lowest word error rate among tokenization methods, robustly preserving semantic content. For TTS, <span id="S5.p1.1.6" class="ltx_text ltx_font_typewriter">dMel</span>â€™s generation yielded the lowest WER, accurately reconstructing speech waveforms. Our <span id="S5.p1.1.7" class="ltx_text ltx_font_typewriter">dMel</span>-based TTS model, <span id="S5.p1.1.8" class="ltx_text ltx_font_typewriter">RichTTS</span>, achieved competitive naturalness, lowest error rates, and long audio generation capabilities.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_typewriter">dMel</span>â€™s simplicity circumvents separate tokenizers or multi-stage modeling, reducing computational overhead and dependence on pretrained models. By unifying semantic and acoustic modeling, <span id="S5.p2.1.2" class="ltx_text ltx_font_typewriter">dMel</span> enables efficient speech-text modeling frameworks.
While initial joint TTS-ASR training showed promise, further work is needed. Our primary contribution demonstrates <span id="S5.p2.1.3" class="ltx_text ltx_font_typewriter">dMel</span>â€™s effectiveness for high-performing separate TTS and ASR models within a unified decoder architecture.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Because TTS work is tremendously fragmented and clear protocols are not often available for training and evaluation, we reimplemented other tokenizers within our code base using publicly available, official implementations where available.
We trained our models on those tokenizations. While we made the best effort to tune the tokenization methods and the models, there is always a possibility we missed some details. However, our results seem to tell a consistent story when viewed from multiple angles, and when viewed on multiple datasets. For the joint model, we did not do extensive multi-task training using text only data and we intend to do that in the future work.
We also did not train on larger model sizes (&gt;1B parameters), larger datasets (&gt;1k hours), or using pretrained models.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgements</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We thank Dan Busbridge, Ronan Collobert and Jason Ramapuram for their helpful feedback and critical discussions at all stages of the research; Rick Chang, David Grangier, Barry Theobald for their helpful feedback on the initial paper draft. Names are in alphabetical order by last name within group.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ao etÂ al. [2021]</span>
<span class="ltx_bibblock">
Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, YuÂ Wu, Shujie Liu, Tom Ko, Qing Li, YuÂ Zhang, etÂ al.

</span>
<span class="ltx_bibblock">Speecht5: Unified-modal encoder-decoder pre-training for spoken language processing.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.07205</em>, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski etÂ al. [2020]</span>
<span class="ltx_bibblock">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:12449â€“12460, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai etÂ al. [2022]</span>
<span class="ltx_bibblock">
HeÂ Bai, Renjie Zheng, Junkun Chen, Mingbo Ma, Xintong Li, and Liang Huang.

</span>
<span class="ltx_bibblock">A<sup id="bib.bib3.2.1" class="ltx_sup">3</sup>T: Alignment-aware acoustic and text pretraining for speech synthesis and editing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages 1399â€“1411. PMLR, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bain etÂ al. [2023]</span>
<span class="ltx_bibblock">
Max Bain, Jaesung Huh, Tengda Han, and Andrew Zisserman.

</span>
<span class="ltx_bibblock">Whisperx: Time-accurate speech transcription of long-form audio.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH 2023</em>, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bapna etÂ al. [2021]</span>
<span class="ltx_bibblock">
Ankur Bapna, Yu-an Chung, Nan Wu, Anmol Gulati, YeÂ Jia, JonathanÂ H Clark, Melvin Johnson, Jason Riesa, Alexis Conneau, and YuÂ Zhang.

</span>
<span class="ltx_bibblock">Slam: A unified encoder for speech and language modeling via speech-text joint pre-training.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.10329</em>, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bengio etÂ al. [2015]</span>
<span class="ltx_bibblock">
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer.

</span>
<span class="ltx_bibblock">Scheduled sampling for sequence prediction with recurrent neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 28, 2015.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borsos etÂ al. [2023]</span>
<span class="ltx_bibblock">
ZalÃ¡n Borsos, RaphaÃ«l Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi, Dominik Roblek, Olivier Teboul, David Grangier, Marco Tagliasacchi, etÂ al.

</span>
<span class="ltx_bibblock">Audiolm: a language modeling approach to audio generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al. [2020]</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, JaredÂ D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, etÂ al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:1877â€“1901, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Casanova etÂ al. [2022]</span>
<span class="ltx_bibblock">
Edresson Casanova, Julian Weber, ChristopherÂ D Shulby, ArnaldoÂ Candido Junior, Eren GÃ¶lge, and MoacirÂ A Ponti.

</span>
<span class="ltx_bibblock">Yourtts: Towards zero-shot multi-speaker tts and zero-shot voice conversion for everyone.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages 2709â€“2720. PMLR, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. [2021]</span>
<span class="ltx_bibblock">
Mingjian Chen, XuÂ Tan, Bohan Li, Yanqing Liu, Tao Qin, Sheng Zhao, and Tie-Yan Liu.

</span>
<span class="ltx_bibblock">Adaspeech: Adaptive text to speech for custom voice.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.00993</em>, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DÃ©fossez etÂ al. [2022]</span>
<span class="ltx_bibblock">
Alexandre DÃ©fossez, Jade Copet, Gabriel Synnaeve, and Yossi Adi.

</span>
<span class="ltx_bibblock">High fidelity neural audio compression.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.13438</em>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dehghani etÂ al. [2023]</span>
<span class="ltx_bibblock">
Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan Heek, Justin Gilmer, AndreasÂ Peter Steiner, Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin, etÂ al.

</span>
<span class="ltx_bibblock">Scaling vision transformers to 22 billion parameters.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages 7480â€“7512. PMLR, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hines etÂ al. [2012]</span>
<span class="ltx_bibblock">
Andrew Hines, Jan Skoglund, Anil Kokaram, and Naomi Harte.

</span>
<span class="ltx_bibblock">Visqol: The virtual speech quality objective listener.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IWAENC 2012; international workshop on acoustic signal enhancement</em>, pages 1â€“4. VDE, 2012.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu etÂ al. [2021]</span>
<span class="ltx_bibblock">
Wei-Ning Hsu, Benjamin Bolte, Yao-HungÂ Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed.

</span>
<span class="ltx_bibblock">Hubert: Self-supervised speech representation learning by masked prediction of hidden units.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 29:3451â€“3460, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ito and Johnson [2017]</span>
<span class="ltx_bibblock">
Keith Ito and Linda Johnson.

</span>
<span class="ltx_bibblock">The lj speech dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://keithito.com/LJ-Speech-Dataset/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://keithito.com/LJ-Speech-Dataset/</a>, 2017.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. [2021]</span>
<span class="ltx_bibblock">
Jaehyeon Kim, Jungil Kong, and Juhee Son.

</span>
<span class="ltx_bibblock">Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages 5530â€“5540. PMLR, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. [2024]</span>
<span class="ltx_bibblock">
Jaehyeon Kim, Keon Lee, Seungjun Chung, and Jaewoong Cho.

</span>
<span class="ltx_bibblock">CLam-TTS: Improving neural codec language model for zero-shot text-to-speech.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">The Twelfth International Conference on Learning Representations</em>, 2024.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=ofzeypWosV" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=ofzeypWosV</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kong etÂ al. [2020]</span>
<span class="ltx_bibblock">
Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae.

</span>
<span class="ltx_bibblock">Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:17022â€“17033, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lakhotia etÂ al. [2021]</span>
<span class="ltx_bibblock">
Kushal Lakhotia, Eugene Kharitonov, Wei-Ning Hsu, Yossi Adi, Adam Polyak, Benjamin Bolte, Tu-Anh Nguyen, Jade Copet, Alexei Baevski, Abdelrahman Mohamed, etÂ al.

</span>
<span class="ltx_bibblock">On generative spoken language modeling from raw audio.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 9:1336â€“1354, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le etÂ al. [2023]</span>
<span class="ltx_bibblock">
Matthew Le, Apoorv Vyas, Bowen Shi, Brian Karrer, Leda Sari, Rashel Moritz, Mary Williamson, Vimal Manohar, Yossi Adi, Jay Mahadeokar, and Wei-Ning Hsu.

</span>
<span class="ltx_bibblock">Voicebox: Text-guided multilingual universal speech generation at scale, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maiti etÂ al. [2024]</span>
<span class="ltx_bibblock">
Soumi Maiti, Yifan Peng, Shukjae Choi, Jee-weon Jung, Xuankai Chang, and Shinji Watanabe.

</span>
<span class="ltx_bibblock">Voxtlm: Unified decoder-only models for consolidating speech recognition, synthesis and speech, text continuation tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 13326â€“13330. IEEE, 2024.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panayotov etÂ al. [2015]</span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Librispeech: an asr corpus based on public domain audio books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>, pages 5206â€“5210. IEEE, 2015.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park etÂ al. [2019]</span>
<span class="ltx_bibblock">
DanielÂ S. Park, William Chan, YuÂ Zhang, Chung-Cheng Chiu, Barret Zoph, EkinÂ D. Cubuk, and QuocÂ V. Le.

</span>
<span class="ltx_bibblock">Specaugment: A simple data augmentation method for automatic speech recognition.

</span>
<span class="ltx_bibblock">In Gernot Kubin and Zdravko Kacic, editors, <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Interspeech 2019, 20th Annual Conference of the International Speech Communication Association, Graz, Austria, 15-19 September 2019</em>, pages 2613â€“2617. ISCA, 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/INTERSPEECH.2019-2680</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.21437/Interspeech.2019-2680" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.21437/Interspeech.2019-2680</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. [2023]</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Robust speech recognition via large-scale weak supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages 28492â€“28518. PMLR, 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel etÂ al. [2020]</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and PeterÂ J Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Journal of machine learning research</em>, 21(140):1â€“67, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren etÂ al. [2020]</span>
<span class="ltx_bibblock">
YiÂ Ren, Chenxu Hu, XuÂ Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu.

</span>
<span class="ltx_bibblock">Fastspeech 2: Fast and high-quality end-to-end text to speech.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.04558</em>, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rubenstein etÂ al. [2023]</span>
<span class="ltx_bibblock">
PaulÂ K Rubenstein, Chulayuth Asawaroengchai, DucÂ Dung Nguyen, Ankur Bapna, ZalÃ¡n Borsos, FÃ©lix deÂ Chaumont Quitry, Peter Chen, DaliaÂ El Badawy, Wei Han, Eugene Kharitonov, etÂ al.

</span>
<span class="ltx_bibblock">Audiopalm: A large language model that can speak and listen.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.12925</em>, 2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen etÂ al. [2018]</span>
<span class="ltx_bibblock">
Jonathan Shen, Ruoming Pang, RonÂ J Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, YuÂ Zhang, Yuxuan Wang, RjÂ Skerrv-Ryan, etÂ al.

</span>
<span class="ltx_bibblock">Natural tts synthesis by conditioning wavenet on mel spectrogram predictions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>, pages 4779â€“4783. IEEE, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su etÂ al. [2024]</span>
<span class="ltx_bibblock">
Jianlin Su, Murtadha Ahmed, YuÂ Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, 568:127063, 2024.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Variani etÂ al. [2014]</span>
<span class="ltx_bibblock">
Ehsan Variani, Xin Lei, Erik McDermott, IgnacioÂ Lopez Moreno, and Javier Gonzalez-Dominguez.

</span>
<span class="ltx_bibblock">Deep neural networks for small footprint text-dependent speaker verification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">2014 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>, pages 4052â€“4056. IEEE, 2014.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2023a]</span>
<span class="ltx_bibblock">
Chengyi Wang, Sanyuan Chen, YuÂ Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, etÂ al.

</span>
<span class="ltx_bibblock">Neural codec language models are zero-shot text to speech synthesizers.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.02111</em>, 2023a.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2023b]</span>
<span class="ltx_bibblock">
Tianrui Wang, Long Zhou, Ziqiang Zhang, YuÂ Wu, Shujie Liu, Yashesh Gaur, Zhuo Chen, Jinyu Li, and Furu Wei.

</span>
<span class="ltx_bibblock">Viola: Unified codec language models for speech recognition, synthesis, and translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.16107</em>, 2023b.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Watanabe etÂ al. [2018]</span>
<span class="ltx_bibblock">
Shinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro Nishitoba, Yuya Unno, Nelson Enrique Yalta Soplin, Jahn Heymann, Matthew Wiesner, Nanxin Chen, Adithya Renduchintala, and Tsubasa Ochiai.

</span>
<span class="ltx_bibblock">ESPnet: End-to-end speech processing toolkit.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of Interspeech</em>, pages 2207â€“2211, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/Interspeech.2018-1456</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.21437/Interspeech.2018-1456" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.21437/Interspeech.2018-1456</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yamagishi etÂ al. [2019a]</span>
<span class="ltx_bibblock">
Junichi Yamagishi, Christophe Veaux, and Kirsten MacDonald.

</span>
<span class="ltx_bibblock">Cstr vctk corpus: English multi-speaker corpus for cstr voice cloning toolkit (version 0.92).

</span>
<span class="ltx_bibblock">University of Edinburgh. The Centre for Speech Technology Research (CSTR). <a target="_blank" href="https://datashare.ed.ac.uk/handle/10283/2950" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://datashare.ed.ac.uk/handle/10283/2950</a>, 2019a.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yamagishi etÂ al. [2019b]</span>
<span class="ltx_bibblock">
Junichi Yamagishi, Christophe Veaux, and Kirsten MacDonald.

</span>
<span class="ltx_bibblock">CSTR VCTK Corpus: English multi-speaker corpus for CSTR voice cloning toolkit (version 0.92), 2019b.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yamamoto etÂ al. [2020]</span>
<span class="ltx_bibblock">
Ryuichi Yamamoto, Eunwoo Song, and Jae-Min Kim.

</span>
<span class="ltx_bibblock">Parallel wavegan: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 6199â€“6203. IEEE, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeghidour etÂ al. [2021]</span>
<span class="ltx_bibblock">
Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco Tagliasacchi.

</span>
<span class="ltx_bibblock">Soundstream: An end-to-end neural audio codec.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 30:495â€“507, 2021.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zen etÂ al. [2019]</span>
<span class="ltx_bibblock">
Heiga Zen, Viet Dang, Rob Clark, YuÂ Zhang, RonÂ J Weiss, YeÂ Jia, Zhifeng Chen, and Yonghui Wu.

</span>
<span class="ltx_bibblock">Libritts: A corpus derived from librispeech for text-to-speech.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.02882</em>, 2019.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. [2023a]</span>
<span class="ltx_bibblock">
Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, and Xipeng Qiu.

</span>
<span class="ltx_bibblock">Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.11000</em>, 2023a.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. [2023b]</span>
<span class="ltx_bibblock">
Xin Zhang, Dong Zhang, Shimin Li, Yaqian Zhou, and Xipeng Qiu.

</span>
<span class="ltx_bibblock">Speechtokenizer: Unified speech tokenizer for speech large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.16692</em>, 2023b.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Ethics Statement</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">The development and deployment of speech technologies carry important ethical considerations. While our proposed <span id="A1.p1.1.1" class="ltx_text ltx_font_typewriter">dMel</span> method aims to advance the state-of-the-art in speech-text modeling, it is crucial to highlight potential ethical risks and raise the awareness so that new methods may be developed to mitigate these risks.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p">Our first main concern is the potential dual-use of speech synthesis technologies for nefarious purposes such as impersonation, misleading audio-visual content generation, or voice spoofing attacks.
Proactive measures, including watermarking techniques and robust speaker verification methods, should be explored to counter such risks.
The former attempts to build markers into the generated speech that make it easy to detect, while the latter focusses on distinguishing synthetic from real data.
Prior workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> has shown that neural networks can be trained to distinguish speech synthesized from their model from real speech, probably because of artifacts from the use of mel spectral vocoders.
While we did not train a network to do so in our work yet (we will create one before code release), the vocoders we use are similar to their work â€“ going from mel spectrogram to raw waveforms.
Our model also does not use prosody, phoneme duration and other predictions that more sophisticated TTS systems use to allow the model to perform very well on imitating speaker styles in zero-shot settings.
However our model can probably mimic the styles of training speakers very well.
It is our hope that releasing our methods will facilitate more research on fake speech verification and watermarking techniques â€“ even if current classifiers are able to perform this detection, the quality of the generative models is improving.
It is also our hope that future works will attempt to perform more credit assignment â€“ by providing metrics that show which real data samples a synthetic speech example copies its style and substance from.</p>
</div>
<div id="A1.p3" class="ltx_para">
<p id="A1.p3.1" class="ltx_p">Another concern is the perpetuation of societal biases encoded within training data. Speech datasets may exhibit biases along dimensions such as gender, race, age, or socioeconomic status, which could be propagated or amplified by trained models. Rigorous debiasing techniques and careful curation of representative training data are essential to mitigate these risks. On the mitigating side of this equation, we also hope that with better, more controllable TTS systems, ASR systems can improve because more data can be generated for underrepresented segments of the distribution from the TTS models.</p>
</div>
<div id="A1.p4" class="ltx_para">
<p id="A1.p4.1" class="ltx_p">Furthermore, the development and deployment of speech technologies should prioritize accessibility and inclusivity. Models should be evaluated for performance across diverse demographics, accents, and language varieties to ensure equitable access and quality of service.</p>
</div>
<div id="A1.p5" class="ltx_para">
<p id="A1.p5.1" class="ltx_p">Finally, it is important to foster transparency and accountability in the research and development process. Clear documentation of model capabilities, limitations, and potential failure modes should be provided to enable informed decision-making and responsible usage.</p>
</div>
<div id="A1.p6" class="ltx_para">
<p id="A1.p6.1" class="ltx_p">Addressing these ethical considerations requires a multistakeholder approach involving researchers, developers, policymakers, and end-users. By prioritizing ethical principles such as fairness, privacy, and accountability, we can work towards realizing the benefits of speech technologies while mitigating potential risks and adverse societal impacts.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Data, Code, Reproducibility</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We made the best effort to use publicly available data and official implementations of prior works where it is possible. All data we used are under permissive license for research. We provided as much as detail as is possible without code such as details on our model training and hyperparameters throughout the paper and in the Appendix. We plan to open-source our code upon paper acceptance.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p">We do not plan to open-source any pre-trained models for sake of privacy, safety and misuse.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Subjective Evaluation for TTS</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">We use crowd-sourcing to collect subjective ratings to compare the naturalness of the reconstructed speech from the different tokenizers. We evaluate the quality of the same (randomly sampled) 50 utterances for each model by collecting around seven ratings per sample. Overall, we collect 3500 ratings from 65 raters. The raters were English-speaking and were paid at least the minimum wage.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">We present the raters with a generated speech sample and instruct them to rate how natural it sounds on a five-point Likert scale, where 1 corresponds to very unnatural and 5 corresponds to very natural. FigureÂ <a href="#A3.F3" title="Figure 3 â€£ Appendix C Subjective Evaluation for TTS â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows a screenshot of our subjective test as seen by the rater.</p>
</div>
<figure id="A3.F3" class="ltx_figure"><img src="/html/2407.15835/assets/figs/crowdsource_screenshot.png" id="A3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="112" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>A screenshot of the assessment task, as the crowd-sourced rater sees it.</figcaption>
</figure>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Training Details</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">For our decoder-only model we stack together speaker embedding, speech tokens and text tokens. Both speech and text tokens have prepended begin of sentence token (&lt;bos&gt;) and appended end of sentence token (&lt;eos&gt;).</p>
</div>
<div id="A4.p2" class="ltx_para">
<p id="A4.p2.1" class="ltx_p">We train all models using the Adam optimizer with a learning rate of 1e-3, learning rate warmup of 4k steps for ASR and 5k for TTS, cosine learning rate schedule and gradient clipping of 1.0 for TTS and 0.1 for ASR and joint models.
We use dynamic batching to optimize the data packing with total batch size of 1.4h/1.4h/0.7h for ASR training and 1h/2h/2h for TTS training for Small/Base/Large models.
We train TTS models for 600k steps and ASR models 80k steps with mixed precision training and BF16 on A100 and H100 GPUs with 80GB.
Both ASR models and TTS models are trained with 8GPUs for less than a day and for 2-4 days for ASR and TTS respectively.</p>
</div>
<figure id="A4.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Decoder-only transformer model configurations for ASR, TTS and joint models training.</figcaption>
<table id="A4.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A4.T9.1.2" class="ltx_tr">
<td id="A4.T9.1.2.1" class="ltx_td ltx_border_tt"></td>
<td id="A4.T9.1.2.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="A4.T9.1.2.2.1" class="ltx_text" style="font-size:90%;">Small</span></td>
<td id="A4.T9.1.2.3" class="ltx_td ltx_align_right ltx_border_tt"><span id="A4.T9.1.2.3.1" class="ltx_text" style="font-size:90%;">Base</span></td>
<td id="A4.T9.1.2.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="A4.T9.1.2.4.1" class="ltx_text" style="font-size:90%;">Large</span></td>
</tr>
<tr id="A4.T9.1.3" class="ltx_tr">
<td id="A4.T9.1.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A4.T9.1.3.1.1" class="ltx_text" style="font-size:90%;"># of layers</span></td>
<td id="A4.T9.1.3.2" class="ltx_td ltx_align_right ltx_border_t"><span id="A4.T9.1.3.2.1" class="ltx_text" style="font-size:90%;">18</span></td>
<td id="A4.T9.1.3.3" class="ltx_td ltx_align_right ltx_border_t"><span id="A4.T9.1.3.3.1" class="ltx_text" style="font-size:90%;">36</span></td>
<td id="A4.T9.1.3.4" class="ltx_td ltx_align_right ltx_border_t"><span id="A4.T9.1.3.4.1" class="ltx_text" style="font-size:90%;">48</span></td>
</tr>
<tr id="A4.T9.1.4" class="ltx_tr">
<td id="A4.T9.1.4.1" class="ltx_td ltx_align_left"><span id="A4.T9.1.4.1.1" class="ltx_text" style="font-size:90%;"># of attention heads</span></td>
<td id="A4.T9.1.4.2" class="ltx_td ltx_align_right"><span id="A4.T9.1.4.2.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="A4.T9.1.4.3" class="ltx_td ltx_align_right"><span id="A4.T9.1.4.3.1" class="ltx_text" style="font-size:90%;">4</span></td>
<td id="A4.T9.1.4.4" class="ltx_td ltx_align_right"><span id="A4.T9.1.4.4.1" class="ltx_text" style="font-size:90%;">8</span></td>
</tr>
<tr id="A4.T9.1.1" class="ltx_tr">
<td id="A4.T9.1.1.1" class="ltx_td ltx_align_left">
<span id="A4.T9.1.1.1.1" class="ltx_text" style="font-size:90%;"># of hidden units (</span><math id="A4.T9.1.1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="A4.T9.1.1.1.m1.1a"><mi mathsize="90%" id="A4.T9.1.1.1.m1.1.1" xref="A4.T9.1.1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A4.T9.1.1.1.m1.1b"><ci id="A4.T9.1.1.1.m1.1.1.cmml" xref="A4.T9.1.1.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T9.1.1.1.m1.1c">D</annotation></semantics></math><span id="A4.T9.1.1.1.2" class="ltx_text" style="font-size:90%;">)</span>
</td>
<td id="A4.T9.1.1.2" class="ltx_td ltx_align_right"><span id="A4.T9.1.1.2.1" class="ltx_text" style="font-size:90%;">512</span></td>
<td id="A4.T9.1.1.3" class="ltx_td ltx_align_right"><span id="A4.T9.1.1.3.1" class="ltx_text" style="font-size:90%;">768</span></td>
<td id="A4.T9.1.1.4" class="ltx_td ltx_align_right"><span id="A4.T9.1.1.4.1" class="ltx_text" style="font-size:90%;">1536</span></td>
</tr>
<tr id="A4.T9.1.5" class="ltx_tr">
<td id="A4.T9.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="A4.T9.1.5.1.1" class="ltx_text" style="font-size:90%;"># of parameters</span></td>
<td id="A4.T9.1.5.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="A4.T9.1.5.2.1" class="ltx_text" style="font-size:90%;">59M</span></td>
<td id="A4.T9.1.5.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="A4.T9.1.5.3.1" class="ltx_text" style="font-size:90%;">258M</span></td>
<td id="A4.T9.1.5.4" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="A4.T9.1.5.4.1" class="ltx_text" style="font-size:90%;">1.3B</span></td>
</tr>
</table>
</figure>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>LM-Style Speech-to-Text</h3>

<div id="A4.SS1.p1" class="ltx_para">
<p id="A4.SS1.p1.1" class="ltx_p">For ASR training as an augmentation we apply SpecAugmentÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> with 2 frequency masks with max width 30 and 10 time masks with max width 50 and ratio 0.1.
With ablations we found that SpecAugment masking with average value instead of zero is slightly better.
Without applying SpecAugment performance of ASR is 7.3% WER on <span id="A4.SS1.p1.1.1" class="ltx_text ltx_font_italic">dev-clean</span> and 20.3% WER on <span id="A4.SS1.p1.1.2" class="ltx_text ltx_font_italic">dev-other</span>, which is further can be improved with usage of frequency masking only to 6.4% WER on <span id="A4.SS1.p1.1.3" class="ltx_text ltx_font_italic">dev-clean</span> and 16.6% WER on <span id="A4.SS1.p1.1.4" class="ltx_text ltx_font_italic">dev-other</span>. Usage of both frequency masking and time masking results in the best performance of TableÂ <a href="#S3.T7" title="Table 7 â€£ 3.3.3 LM-Style Speech-to-Text â€£ 3.3 Main Results â€£ 3 Experiments â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<div id="A4.SS1.p2" class="ltx_para">
<p id="A4.SS1.p2.1" class="ltx_p">During experiments with ASR decoder-only models and <span id="A4.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">dMel</span> tokenization we observed some model training instabilities resulting in the spikes in the gradient norm and thus sometimes spikes in training loss.
To stabilize training i) we reduce the gradient clipping from 1.0 used for TTS training to 0.1; ii) we add queries and keys normalizations via LayerNormÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> on the head dimension before computing attention matrix.</p>
</div>
<div id="A4.SS1.p3" class="ltx_para">
<p id="A4.SS1.p3.2" class="ltx_p">We found that span masking is key part of model training to enforce slef-attention to attend to speech part as well as to reduce exposure bias. The masking strategy is similar to the one used for TTS training: for every training step with probability <math id="A4.SS1.p3.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A4.SS1.p3.1.m1.1a"><mi id="A4.SS1.p3.1.m1.1.1" xref="A4.SS1.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A4.SS1.p3.1.m1.1b"><ci id="A4.SS1.p3.1.m1.1.1.cmml" xref="A4.SS1.p3.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p3.1.m1.1c">p</annotation></semantics></math> the sample in the minibatch is masked with the mean span of 3 tokens with masking ration of 0.5. We found that the mean span of 1 token or 5 tokens gives the same results; while the mask probability <math id="A4.SS1.p3.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A4.SS1.p3.2.m2.1a"><mi id="A4.SS1.p3.2.m2.1.1" xref="A4.SS1.p3.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A4.SS1.p3.2.m2.1b"><ci id="A4.SS1.p3.2.m2.1.1.cmml" xref="A4.SS1.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p3.2.m2.1c">p</annotation></semantics></math> is the most important hyper-parameter. The optimimal value for ASR is found to be 0.8, which is used in all final models.</p>
</div>
<div id="A4.SS1.p4" class="ltx_para">
<p id="A4.SS1.p4.1" class="ltx_p">As we found one best model configuration for the Base model with <span id="A4.SS1.p4.1.1" class="ltx_text ltx_font_typewriter">dMel</span> we then change only i) model size ii) speech tokenization iii) training data (here we increase model dropout to 0.3 for training on <span id="A4.SS1.p4.1.2" class="ltx_text ltx_font_italic">train-clean-360</span> and to 0.5 for training on <span id="A4.SS1.p4.1.3" class="ltx_text ltx_font_italic">train-clean-100</span> as otherwise models drastically overfits.); the rest of hyper-parameters stays the same.</p>
</div>
</section>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Ablations</h2>

<section id="A5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>LM-Style Text-to-Speech</h3>

<div id="A5.SS1.p1" class="ltx_para">
<p id="A5.SS1.p1.1" class="ltx_p">Scaling results for <span id="A5.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">RichTTS</span> are shown in TableÂ <a href="#A5.T10" title="Table 10 â€£ E.1 LM-Style Text-to-Speech â€£ Appendix E Ablations â€£ dMel: Speech Tokenization made Simple" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<figure id="A5.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Text-to-speech results for different model sizes with <span id="A5.T10.3.1" class="ltx_text ltx_font_typewriter">dMel</span>. All models are trained on LibriSpeech 960h dataset. Evaluation is done via speech generation on the full <span id="A5.T10.4.2" class="ltx_text ltx_font_italic">test-clean</span> transcriptions and speakers, and then evaluated WER with WhisperX base.en.</figcaption>
<table id="A5.T10.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A5.T10.5.1" class="ltx_tr">
<td id="A5.T10.5.1.1" class="ltx_td ltx_border_tt"></td>
<td id="A5.T10.5.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="A5.T10.5.1.2.1" class="ltx_text" style="font-size:90%;">WER (%)</span></td>
</tr>
<tr id="A5.T10.5.2" class="ltx_tr">
<td id="A5.T10.5.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="A5.T10.5.2.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="A5.T10.5.2.1.2" class="ltx_text" style="font-size:90%;"> (</span><span id="A5.T10.5.2.1.3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span><span id="A5.T10.5.2.1.4" class="ltx_text" style="font-size:90%;">), Small</span>
</td>
<td id="A5.T10.5.2.2" class="ltx_td ltx_align_right ltx_border_t"><span id="A5.T10.5.2.2.1" class="ltx_text" style="font-size:90%;">8.1</span></td>
</tr>
<tr id="A5.T10.5.3" class="ltx_tr">
<td id="A5.T10.5.3.1" class="ltx_td ltx_align_left">
<span id="A5.T10.5.3.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="A5.T10.5.3.1.2" class="ltx_text" style="font-size:90%;"> (</span><span id="A5.T10.5.3.1.3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span><span id="A5.T10.5.3.1.4" class="ltx_text" style="font-size:90%;">), Base</span>
</td>
<td id="A5.T10.5.3.2" class="ltx_td ltx_align_right"><span id="A5.T10.5.3.2.1" class="ltx_text" style="font-size:90%;">4.3</span></td>
</tr>
<tr id="A5.T10.5.4" class="ltx_tr">
<td id="A5.T10.5.4.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="A5.T10.5.4.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">RichTTS</span><span id="A5.T10.5.4.1.2" class="ltx_text" style="font-size:90%;"> (</span><span id="A5.T10.5.4.1.3" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span><span id="A5.T10.5.4.1.4" class="ltx_text" style="font-size:90%;">), Large</span>
</td>
<td id="A5.T10.5.4.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="A5.T10.5.4.2.1" class="ltx_text" style="font-size:90%;">5.4</span></td>
</tr>
</table>
</figure>
</section>
<section id="A5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>LM-Style Speech-to-Text</h3>

<figure id="A5.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Our ASR models trained on different subsets (<span id="A5.T11.35.1" class="ltx_text ltx_font_italic">train-clean-100</span> LS-100, <span id="A5.T11.36.2" class="ltx_text ltx_font_italic">train-clean-360</span> LS-360, full LibriSpeech LS-960) of LibriSpeech, with different model size and different speech tokenization (greedy decoding is reported). Results are shown across 2 runs with mean WER and standard deviation.</figcaption>
<table id="A5.T11.32" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A5.T11.32.33" class="ltx_tr">
<td id="A5.T11.32.33.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A5.T11.32.33.1.1" class="ltx_text" style="font-size:90%;">tokenization</span></td>
<td id="A5.T11.32.33.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="A5.T11.32.33.2.1" class="ltx_text" style="font-size:90%;">model size</span></td>
<td id="A5.T11.32.33.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="A5.T11.32.33.3.1" class="ltx_text" style="font-size:90%;">data</span></td>
<td id="A5.T11.32.33.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="A5.T11.32.33.4.1" class="ltx_text" style="font-size:90%;">dev-clean</span></td>
<td id="A5.T11.32.33.5" class="ltx_td ltx_align_right ltx_border_tt"><span id="A5.T11.32.33.5.1" class="ltx_text" style="font-size:90%;">dev-other</span></td>
<td id="A5.T11.32.33.6" class="ltx_td ltx_align_right ltx_border_tt"><span id="A5.T11.32.33.6.1" class="ltx_text" style="font-size:90%;">test-clean</span></td>
<td id="A5.T11.32.33.7" class="ltx_td ltx_align_right ltx_border_tt"><span id="A5.T11.32.33.7.1" class="ltx_text" style="font-size:90%;">test-other</span></td>
</tr>
<tr id="A5.T11.4.4" class="ltx_tr">
<td id="A5.T11.4.4.5" class="ltx_td ltx_align_left ltx_border_t"><span id="A5.T11.4.4.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span></td>
<td id="A5.T11.4.4.6" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="A5.T11.4.4.6.1" class="ltx_text" style="font-size:90%;">Base</span></td>
<td id="A5.T11.4.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T11.4.4.7.1" class="ltx_text" style="font-size:90%;">LS-100</span></td>
<td id="A5.T11.1.1.1" class="ltx_td ltx_align_right ltx_border_t">
<span id="A5.T11.1.1.1.1" class="ltx_text" style="font-size:90%;">18.1</span><math id="A5.T11.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.1.1.1.m1.1a"><mo mathsize="90%" id="A5.T11.1.1.1.m1.1.1" xref="A5.T11.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.1.1.1.m1.1b"><csymbol cd="latexml" id="A5.T11.1.1.1.m1.1.1.cmml" xref="A5.T11.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.1.1.1.2" class="ltx_text" style="font-size:90%;">1.0</span>
</td>
<td id="A5.T11.2.2.2" class="ltx_td ltx_align_right ltx_border_t">
<span id="A5.T11.2.2.2.1" class="ltx_text" style="font-size:90%;">39.4</span><math id="A5.T11.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.2.2.2.m1.1a"><mo mathsize="90%" id="A5.T11.2.2.2.m1.1.1" xref="A5.T11.2.2.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.2.2.2.m1.1b"><csymbol cd="latexml" id="A5.T11.2.2.2.m1.1.1.cmml" xref="A5.T11.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.2.2.2.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.2.2.2.2" class="ltx_text" style="font-size:90%;">1.2</span>
</td>
<td id="A5.T11.3.3.3" class="ltx_td ltx_align_right ltx_border_t">
<span id="A5.T11.3.3.3.1" class="ltx_text" style="font-size:90%;">19.0 </span><math id="A5.T11.3.3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.3.3.3.m1.1a"><mo mathsize="90%" id="A5.T11.3.3.3.m1.1.1" xref="A5.T11.3.3.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.3.3.3.m1.1b"><csymbol cd="latexml" id="A5.T11.3.3.3.m1.1.1.cmml" xref="A5.T11.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.3.3.3.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.3.3.3.2" class="ltx_text" style="font-size:90%;">1.0</span>
</td>
<td id="A5.T11.4.4.4" class="ltx_td ltx_align_right ltx_border_t">
<span id="A5.T11.4.4.4.1" class="ltx_text" style="font-size:90%;">41.3</span><math id="A5.T11.4.4.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.4.4.4.m1.1a"><mo mathsize="90%" id="A5.T11.4.4.4.m1.1.1" xref="A5.T11.4.4.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.4.4.4.m1.1b"><csymbol cd="latexml" id="A5.T11.4.4.4.m1.1.1.cmml" xref="A5.T11.4.4.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.4.4.4.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.4.4.4.2" class="ltx_text" style="font-size:90%;">1.1</span>
</td>
</tr>
<tr id="A5.T11.8.8" class="ltx_tr">
<td id="A5.T11.8.8.5" class="ltx_td ltx_align_left"><span id="A5.T11.8.8.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span></td>
<td id="A5.T11.8.8.6" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.6.1" class="ltx_text" style="font-size:90%;">LS-360</span></td>
<td id="A5.T11.5.5.1" class="ltx_td ltx_align_right">
<span id="A5.T11.5.5.1.1" class="ltx_text" style="font-size:90%;">6.4</span><math id="A5.T11.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.5.5.1.m1.1a"><mo mathsize="90%" id="A5.T11.5.5.1.m1.1.1" xref="A5.T11.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.5.5.1.m1.1b"><csymbol cd="latexml" id="A5.T11.5.5.1.m1.1.1.cmml" xref="A5.T11.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.5.5.1.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.5.5.1.2" class="ltx_text" style="font-size:90%;">0.4</span>
</td>
<td id="A5.T11.6.6.2" class="ltx_td ltx_align_right">
<span id="A5.T11.6.6.2.1" class="ltx_text" style="font-size:90%;">20.1</span><math id="A5.T11.6.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.6.6.2.m1.1a"><mo mathsize="90%" id="A5.T11.6.6.2.m1.1.1" xref="A5.T11.6.6.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.6.6.2.m1.1b"><csymbol cd="latexml" id="A5.T11.6.6.2.m1.1.1.cmml" xref="A5.T11.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.6.6.2.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.6.6.2.2" class="ltx_text" style="font-size:90%;">1.1</span>
</td>
<td id="A5.T11.7.7.3" class="ltx_td ltx_align_right">
<span id="A5.T11.7.7.3.1" class="ltx_text" style="font-size:90%;">6.9 </span><math id="A5.T11.7.7.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.7.7.3.m1.1a"><mo mathsize="90%" id="A5.T11.7.7.3.m1.1.1" xref="A5.T11.7.7.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.7.7.3.m1.1b"><csymbol cd="latexml" id="A5.T11.7.7.3.m1.1.1.cmml" xref="A5.T11.7.7.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.7.7.3.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.7.7.3.2" class="ltx_text" style="font-size:90%;">0.6</span>
</td>
<td id="A5.T11.8.8.4" class="ltx_td ltx_align_right">
<span id="A5.T11.8.8.4.1" class="ltx_text" style="font-size:90%;">20.5</span><math id="A5.T11.8.8.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.8.8.4.m1.1a"><mo mathsize="90%" id="A5.T11.8.8.4.m1.1.1" xref="A5.T11.8.8.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.8.8.4.m1.1b"><csymbol cd="latexml" id="A5.T11.8.8.4.m1.1.1.cmml" xref="A5.T11.8.8.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.8.8.4.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.8.8.4.2" class="ltx_text" style="font-size:90%;">0.9</span>
</td>
</tr>
<tr id="A5.T11.12.12" class="ltx_tr">
<td id="A5.T11.12.12.5" class="ltx_td ltx_align_left ltx_border_tt">
<span id="A5.T11.12.12.5.1" class="ltx_text" style="font-size:90%;">SpeechTokenizerÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A5.T11.12.12.5.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a><span id="A5.T11.12.12.5.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="A5.T11.12.12.6" class="ltx_td ltx_align_center ltx_border_tt" rowspan="3"><span id="A5.T11.12.12.6.1" class="ltx_text" style="font-size:90%;">Small</span></td>
<td id="A5.T11.12.12.7" class="ltx_td ltx_align_center ltx_border_tt" rowspan="3"><span id="A5.T11.12.12.7.1" class="ltx_text" style="font-size:90%;">LS-960</span></td>
<td id="A5.T11.9.9.1" class="ltx_td ltx_align_right ltx_border_tt">
<span id="A5.T11.9.9.1.1" class="ltx_text" style="font-size:90%;">6.2</span><math id="A5.T11.9.9.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.9.9.1.m1.1a"><mo mathsize="90%" id="A5.T11.9.9.1.m1.1.1" xref="A5.T11.9.9.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.9.9.1.m1.1b"><csymbol cd="latexml" id="A5.T11.9.9.1.m1.1.1.cmml" xref="A5.T11.9.9.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.9.9.1.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.9.9.1.2" class="ltx_text" style="font-size:90%;">0.2</span>
</td>
<td id="A5.T11.10.10.2" class="ltx_td ltx_align_right ltx_border_tt">
<span id="A5.T11.10.10.2.1" class="ltx_text" style="font-size:90%;">16.8</span><math id="A5.T11.10.10.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.10.10.2.m1.1a"><mo mathsize="90%" id="A5.T11.10.10.2.m1.1.1" xref="A5.T11.10.10.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.10.10.2.m1.1b"><csymbol cd="latexml" id="A5.T11.10.10.2.m1.1.1.cmml" xref="A5.T11.10.10.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.10.10.2.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.10.10.2.2" class="ltx_text" style="font-size:90%;">0.3</span>
</td>
<td id="A5.T11.11.11.3" class="ltx_td ltx_align_right ltx_border_tt">
<span id="A5.T11.11.11.3.1" class="ltx_text" style="font-size:90%;">6.5</span><math id="A5.T11.11.11.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.11.11.3.m1.1a"><mo mathsize="90%" id="A5.T11.11.11.3.m1.1.1" xref="A5.T11.11.11.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.11.11.3.m1.1b"><csymbol cd="latexml" id="A5.T11.11.11.3.m1.1.1.cmml" xref="A5.T11.11.11.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.11.11.3.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.11.11.3.2" class="ltx_text" style="font-size:90%;">0.2</span>
</td>
<td id="A5.T11.12.12.4" class="ltx_td ltx_align_right ltx_border_tt">
<span id="A5.T11.12.12.4.1" class="ltx_text" style="font-size:90%;">17.4</span><math id="A5.T11.12.12.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.12.12.4.m1.1a"><mo mathsize="90%" id="A5.T11.12.12.4.m1.1.1" xref="A5.T11.12.12.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.12.12.4.m1.1b"><csymbol cd="latexml" id="A5.T11.12.12.4.m1.1.1.cmml" xref="A5.T11.12.12.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.12.12.4.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.12.12.4.2" class="ltx_text" style="font-size:90%;">0.3</span>
</td>
</tr>
<tr id="A5.T11.16.16" class="ltx_tr">
<td id="A5.T11.16.16.5" class="ltx_td ltx_align_left">
<span id="A5.T11.16.16.5.1" class="ltx_text" style="font-size:90%;">HuBERT+KMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A5.T11.16.16.5.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="A5.T11.16.16.5.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="A5.T11.13.13.1" class="ltx_td ltx_align_right">
<span id="A5.T11.13.13.1.1" class="ltx_text" style="font-size:90%;">5.8</span><math id="A5.T11.13.13.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.13.13.1.m1.1a"><mo mathsize="90%" id="A5.T11.13.13.1.m1.1.1" xref="A5.T11.13.13.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.13.13.1.m1.1b"><csymbol cd="latexml" id="A5.T11.13.13.1.m1.1.1.cmml" xref="A5.T11.13.13.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.13.13.1.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.13.13.1.2" class="ltx_text" style="font-size:90%;">0.2</span>
</td>
<td id="A5.T11.14.14.2" class="ltx_td ltx_align_right">
<span id="A5.T11.14.14.2.1" class="ltx_text" style="font-size:90%;">14.6</span><math id="A5.T11.14.14.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.14.14.2.m1.1a"><mo mathsize="90%" id="A5.T11.14.14.2.m1.1.1" xref="A5.T11.14.14.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.14.14.2.m1.1b"><csymbol cd="latexml" id="A5.T11.14.14.2.m1.1.1.cmml" xref="A5.T11.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.14.14.2.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.14.14.2.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="A5.T11.15.15.3" class="ltx_td ltx_align_right">
<span id="A5.T11.15.15.3.1" class="ltx_text" style="font-size:90%;">6.0</span><math id="A5.T11.15.15.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.15.15.3.m1.1a"><mo mathsize="90%" id="A5.T11.15.15.3.m1.1.1" xref="A5.T11.15.15.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.15.15.3.m1.1b"><csymbol cd="latexml" id="A5.T11.15.15.3.m1.1.1.cmml" xref="A5.T11.15.15.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.15.15.3.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.15.15.3.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="A5.T11.16.16.4" class="ltx_td ltx_align_right">
<span id="A5.T11.16.16.4.1" class="ltx_text" style="font-size:90%;">14.9</span><math id="A5.T11.16.16.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.16.16.4.m1.1a"><mo mathsize="90%" id="A5.T11.16.16.4.m1.1.1" xref="A5.T11.16.16.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.16.16.4.m1.1b"><csymbol cd="latexml" id="A5.T11.16.16.4.m1.1.1.cmml" xref="A5.T11.16.16.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.16.16.4.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.16.16.4.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
</tr>
<tr id="A5.T11.20.20" class="ltx_tr">
<td id="A5.T11.20.20.5" class="ltx_td ltx_align_left"><span id="A5.T11.20.20.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span></td>
<td id="A5.T11.17.17.1" class="ltx_td ltx_align_right">
<span id="A5.T11.17.17.1.1" class="ltx_text" style="font-size:90%;">6.0</span><math id="A5.T11.17.17.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.17.17.1.m1.1a"><mo mathsize="90%" id="A5.T11.17.17.1.m1.1.1" xref="A5.T11.17.17.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.17.17.1.m1.1b"><csymbol cd="latexml" id="A5.T11.17.17.1.m1.1.1.cmml" xref="A5.T11.17.17.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.17.17.1.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.17.17.1.2" class="ltx_text" style="font-size:90%;">0.4</span>
</td>
<td id="A5.T11.18.18.2" class="ltx_td ltx_align_right">
<span id="A5.T11.18.18.2.1" class="ltx_text" style="font-size:90%;">15.2</span><math id="A5.T11.18.18.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.18.18.2.m1.1a"><mo mathsize="90%" id="A5.T11.18.18.2.m1.1.1" xref="A5.T11.18.18.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.18.18.2.m1.1b"><csymbol cd="latexml" id="A5.T11.18.18.2.m1.1.1.cmml" xref="A5.T11.18.18.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.18.18.2.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.18.18.2.2" class="ltx_text" style="font-size:90%;">0.8</span>
</td>
<td id="A5.T11.19.19.3" class="ltx_td ltx_align_right">
<span id="A5.T11.19.19.3.1" class="ltx_text" style="font-size:90%;">6.1</span><math id="A5.T11.19.19.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.19.19.3.m1.1a"><mo mathsize="90%" id="A5.T11.19.19.3.m1.1.1" xref="A5.T11.19.19.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.19.19.3.m1.1b"><csymbol cd="latexml" id="A5.T11.19.19.3.m1.1.1.cmml" xref="A5.T11.19.19.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.19.19.3.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.19.19.3.2" class="ltx_text" style="font-size:90%;">0.4</span>
</td>
<td id="A5.T11.20.20.4" class="ltx_td ltx_align_right">
<span id="A5.T11.20.20.4.1" class="ltx_text" style="font-size:90%;">15.7</span><math id="A5.T11.20.20.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.20.20.4.m1.1a"><mo mathsize="90%" id="A5.T11.20.20.4.m1.1.1" xref="A5.T11.20.20.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.20.20.4.m1.1b"><csymbol cd="latexml" id="A5.T11.20.20.4.m1.1.1.cmml" xref="A5.T11.20.20.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.20.20.4.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.20.20.4.2" class="ltx_text" style="font-size:90%;">0.7</span>
</td>
</tr>
<tr id="A5.T11.24.24" class="ltx_tr">
<td id="A5.T11.24.24.5" class="ltx_td ltx_align_left ltx_border_tt">
<span id="A5.T11.24.24.5.1" class="ltx_text" style="font-size:90%;">SpeechTokenizerÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A5.T11.24.24.5.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a><span id="A5.T11.24.24.5.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="A5.T11.24.24.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" rowspan="3"><span id="A5.T11.24.24.6.1" class="ltx_text" style="font-size:90%;">Base</span></td>
<td id="A5.T11.24.24.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_tt" rowspan="3"><span id="A5.T11.24.24.7.1" class="ltx_text" style="font-size:90%;">LS-960</span></td>
<td id="A5.T11.21.21.1" class="ltx_td ltx_align_right ltx_border_tt">
<span id="A5.T11.21.21.1.1" class="ltx_text" style="font-size:90%;">6.5</span><math id="A5.T11.21.21.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.21.21.1.m1.1a"><mo mathsize="90%" id="A5.T11.21.21.1.m1.1.1" xref="A5.T11.21.21.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.21.21.1.m1.1b"><csymbol cd="latexml" id="A5.T11.21.21.1.m1.1.1.cmml" xref="A5.T11.21.21.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.21.21.1.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.21.21.1.2" class="ltx_text" style="font-size:90%;">0.3</span>
</td>
<td id="A5.T11.22.22.2" class="ltx_td ltx_align_right ltx_border_tt">
<span id="A5.T11.22.22.2.1" class="ltx_text" style="font-size:90%;">16.9</span><math id="A5.T11.22.22.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.22.22.2.m1.1a"><mo mathsize="90%" id="A5.T11.22.22.2.m1.1.1" xref="A5.T11.22.22.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.22.22.2.m1.1b"><csymbol cd="latexml" id="A5.T11.22.22.2.m1.1.1.cmml" xref="A5.T11.22.22.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.22.22.2.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.22.22.2.2" class="ltx_text" style="font-size:90%;">0.7</span>
</td>
<td id="A5.T11.23.23.3" class="ltx_td ltx_align_right ltx_border_tt">
<span id="A5.T11.23.23.3.1" class="ltx_text" style="font-size:90%;">6.9</span><math id="A5.T11.23.23.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.23.23.3.m1.1a"><mo mathsize="90%" id="A5.T11.23.23.3.m1.1.1" xref="A5.T11.23.23.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.23.23.3.m1.1b"><csymbol cd="latexml" id="A5.T11.23.23.3.m1.1.1.cmml" xref="A5.T11.23.23.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.23.23.3.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.23.23.3.2" class="ltx_text" style="font-size:90%;">0.4</span>
</td>
<td id="A5.T11.24.24.4" class="ltx_td ltx_align_right ltx_border_tt">
<span id="A5.T11.24.24.4.1" class="ltx_text" style="font-size:90%;">17.5</span><math id="A5.T11.24.24.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.24.24.4.m1.1a"><mo mathsize="90%" id="A5.T11.24.24.4.m1.1.1" xref="A5.T11.24.24.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.24.24.4.m1.1b"><csymbol cd="latexml" id="A5.T11.24.24.4.m1.1.1.cmml" xref="A5.T11.24.24.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.24.24.4.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.24.24.4.2" class="ltx_text" style="font-size:90%;">0.5</span>
</td>
</tr>
<tr id="A5.T11.28.28" class="ltx_tr">
<td id="A5.T11.28.28.5" class="ltx_td ltx_align_left">
<span id="A5.T11.28.28.5.1" class="ltx_text" style="font-size:90%;">HuBERT+KMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A5.T11.28.28.5.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="A5.T11.28.28.5.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="A5.T11.25.25.1" class="ltx_td ltx_align_right">
<span id="A5.T11.25.25.1.1" class="ltx_text" style="font-size:90%;">5.3</span><math id="A5.T11.25.25.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.25.25.1.m1.1a"><mo mathsize="90%" id="A5.T11.25.25.1.m1.1.1" xref="A5.T11.25.25.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.25.25.1.m1.1b"><csymbol cd="latexml" id="A5.T11.25.25.1.m1.1.1.cmml" xref="A5.T11.25.25.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.25.25.1.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.25.25.1.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="A5.T11.26.26.2" class="ltx_td ltx_align_right">
<span id="A5.T11.26.26.2.1" class="ltx_text" style="font-size:90%;">13.7</span><math id="A5.T11.26.26.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.26.26.2.m1.1a"><mo mathsize="90%" id="A5.T11.26.26.2.m1.1.1" xref="A5.T11.26.26.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.26.26.2.m1.1b"><csymbol cd="latexml" id="A5.T11.26.26.2.m1.1.1.cmml" xref="A5.T11.26.26.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.26.26.2.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.26.26.2.2" class="ltx_text" style="font-size:90%;">0.2</span>
</td>
<td id="A5.T11.27.27.3" class="ltx_td ltx_align_right">
<span id="A5.T11.27.27.3.1" class="ltx_text" style="font-size:90%;">5.8</span><math id="A5.T11.27.27.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.27.27.3.m1.1a"><mo mathsize="90%" id="A5.T11.27.27.3.m1.1.1" xref="A5.T11.27.27.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.27.27.3.m1.1b"><csymbol cd="latexml" id="A5.T11.27.27.3.m1.1.1.cmml" xref="A5.T11.27.27.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.27.27.3.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.27.27.3.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="A5.T11.28.28.4" class="ltx_td ltx_align_right">
<span id="A5.T11.28.28.4.1" class="ltx_text" style="font-size:90%;">13.8</span><math id="A5.T11.28.28.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.28.28.4.m1.1a"><mo mathsize="90%" id="A5.T11.28.28.4.m1.1.1" xref="A5.T11.28.28.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.28.28.4.m1.1b"><csymbol cd="latexml" id="A5.T11.28.28.4.m1.1.1.cmml" xref="A5.T11.28.28.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.28.28.4.m1.1c">\pm</annotation></semantics></math><span id="A5.T11.28.28.4.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
</tr>
<tr id="A5.T11.32.32" class="ltx_tr">
<td id="A5.T11.32.32.5" class="ltx_td ltx_align_left ltx_border_bb"><span id="A5.T11.32.32.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dMel</span></td>
<td id="A5.T11.29.29.1" class="ltx_td ltx_align_right ltx_border_bb">
<span id="A5.T11.29.29.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">3.8<math id="A5.T11.29.29.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.29.29.1.1.m1.1a"><mo id="A5.T11.29.29.1.1.m1.1.1" xref="A5.T11.29.29.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.29.29.1.1.m1.1b"><csymbol cd="latexml" id="A5.T11.29.29.1.1.m1.1.1.cmml" xref="A5.T11.29.29.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.29.29.1.1.m1.1c">\pm</annotation></semantics></math></span><span id="A5.T11.29.29.1.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="A5.T11.30.30.2" class="ltx_td ltx_align_right ltx_border_bb">
<span id="A5.T11.30.30.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">10.3<math id="A5.T11.30.30.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.30.30.2.1.m1.1a"><mo id="A5.T11.30.30.2.1.m1.1.1" xref="A5.T11.30.30.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.30.30.2.1.m1.1b"><csymbol cd="latexml" id="A5.T11.30.30.2.1.m1.1.1.cmml" xref="A5.T11.30.30.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.30.30.2.1.m1.1c">\pm</annotation></semantics></math></span><span id="A5.T11.30.30.2.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
<td id="A5.T11.31.31.3" class="ltx_td ltx_align_right ltx_border_bb">
<span id="A5.T11.31.31.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">4.2<math id="A5.T11.31.31.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.31.31.3.1.m1.1a"><mo id="A5.T11.31.31.3.1.m1.1.1" xref="A5.T11.31.31.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.31.31.3.1.m1.1b"><csymbol cd="latexml" id="A5.T11.31.31.3.1.m1.1.1.cmml" xref="A5.T11.31.31.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.31.31.3.1.m1.1c">\pm</annotation></semantics></math></span><span id="A5.T11.31.31.3.2" class="ltx_text" style="font-size:90%;">0.2</span>
</td>
<td id="A5.T11.32.32.4" class="ltx_td ltx_align_right ltx_border_bb">
<span id="A5.T11.32.32.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">10.4<math id="A5.T11.32.32.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="A5.T11.32.32.4.1.m1.1a"><mo id="A5.T11.32.32.4.1.m1.1.1" xref="A5.T11.32.32.4.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="A5.T11.32.32.4.1.m1.1b"><csymbol cd="latexml" id="A5.T11.32.32.4.1.m1.1.1.cmml" xref="A5.T11.32.32.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.32.32.4.1.m1.1c">\pm</annotation></semantics></math></span><span id="A5.T11.32.32.4.2" class="ltx_text" style="font-size:90%;">0.1</span>
</td>
</tr>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.15834" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.15835" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.15835">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.15835" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.15836" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 17:54:19 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
