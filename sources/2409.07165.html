<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.07165] Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition</title><meta property="og:description" content="Automatic speech recognition (ASR) with an encoder equipped with self-attention, whether streaming or non-streaming, takes quadratic time in the length of the speech utterance. This slows down training and decoding, in…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.07165">

<!--Generated on Sun Oct  6 01:39:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Batthacharya
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_font_italic">Samsung AI Center - Cambridge</span>
<br class="ltx_break">Cambridge, United Kingdom 
<br class="ltx_break">{t.parcollet,r.vandalen,s1.zhang,sourav.b1}@samsung.com
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Automatic speech recognition (ASR) with an encoder equipped with self-attention, whether streaming or non-streaming, takes quadratic time in the length of the speech utterance. This slows down training and decoding, increase their cost, and limit the deployment of the ASR in constrained devices. SummaryMixing is a promising linear-time complexity alternative to self-attention for non-streaming speech recognition that, for the first time, preserves or outperforms the accuracy of self-attention models. Unfortunately, the original definition of SummaryMixing is not suited to streaming speech recognition. Hence, this work extends SummaryMixing to a Conformer Transducer that works in both a streaming and an offline mode. It shows that this new linear-time complexity speech encoder outperforms self-attention in both scenarios while requiring less compute and memory during training and decoding.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Streaming and non-streaming automatic speech recognition (ASR) have followed the general trend in deep learning and increased steadily both in model size and architecture complexity. A few speech encoders have reached billions of neural parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> while improving the recognition accuracies. As a consequence of this success, ASR systems are now part of numerous real-life products <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Such an increase in required computing and memory resources, however, is in conflict with the surging demand for constrained-resources deployment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> of on-device ASR models. Streaming ASR is a great example as the perceived latency at decoding time from the end-user is almost as important as the word error rate (WER).</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Multi-head self-attention (MHSA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> is one of the core components of most ASR systems. Its success lies in the ability to capture fine-grained global interactions between pairs of acoustic frames. In an offline, or non-streaming ASR scenario, self-attention will be computed over the whole speech utterance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. For streaming, the self-attention output of a given time step often depends only on all or a subset of the past frames. Future context can also be added via chunked streaming ASR as a few future frames can be cached and attended by self-attention, at the cost of a slightly higher latency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Unfortunately, MHSA complexity grows quadratically with the input sequence length. This limits in practice, for memory and run-time reasons, the number of past frames that may be used by self-attention, reducing the recognition accuracy compared to an infinite past context. Hence, it appears critical to find an alternative to self-attention that may deal without issue with a growing and infinite past contact for both accuracy and efficiency reasons.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Typical efficient changes to self-attention outside of the speech modality are low-rank approximation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, linearization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, or sparsification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. For ASR more specifically, the Squeezeformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, the Efficient Conformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and the Emformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> aim to reduce the impact of the quadratic complexity by reducing the sequence length. Using these methods, the memory and training time are indeed reduced, but the quadratic time complexity remains. Instead, we aim to remove entirely the quadratic time complexity. In that direction, the Fastformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> proposed to linearise self-attention. It was successfully applied to non-streaming ASR exhibiting faster training times but at the cost of slightly degraded accuracies against MHSA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">More recently, a few articles reported that under certain conditions, pair-wise MHSA operations in trained ASR models including transformers and conformers, behave like simple feed-forward layers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. This observation led to the development of SummaryMixing for ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, an alternative to MHSA that takes linear time in the sequence length. For the first time, and in non-streaming ASR scenarios, SummaryMixing-equipped state-of-the-art models including conformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and branchformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> reduced significantly the memory and training time while outperforming both MHSA and Fastformer on achieved WERs. These findings have also been validated with self-supervised learning (SSL) and different downstream speech tasks including ASR, speaker verification, intent classification and emotion recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. In short, SummaryMixing summarises the whole sequence in a single vector modelling global relations between frames. This summary vector is then concatenated back to each frame of the input sequence. Frames are also individually transformed non-linearly to model local interactions. Unfortunately, the definition of SummaryMixing is not compatible with streaming ASR.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">This article extends SummaryMixing to streaming ASR (Section <a href="#S2" title="II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>) and evaluates its performance in a unified streaming and non-streaming training and decoding framework using dynamic chunk training (DCT) and dynamic chunk convolution (DCCONV) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> on two ASR datasets (Section <a href="#S3" title="III Experiments ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>). The behavior of SummaryMixing is then compared to MHSA with varying sequence lengths and an infinite past context in terms of inference real-time factor, WERs, and memory consumption. Experiments conducted with a state-of-the-art streaming and non-streaming conformer Transducer show that SummaryMixing achieves equivalent or better WER than MHSA while reducing the training and decoding time as well as the memory footprint both during training and inference. The code is released as a recipe of the SpeechBrain toolkit<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code is available under the licence CC-BY-NC 4.0 at: <a target="_blank" href="https://github.com/SamsungLabs/SummaryMixing" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/SamsungLabs/SummaryMixing</a></span></span></span>. We also release in the SpeechBrain toolkit a half-precision Transducer loss effectively halving the peak memory required during training.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Streaming and Non-Streaming SummaryMixing</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section introduces all the necessary components to perform streaming and non-streaming ASR (section <a href="#S2.SS1" title="II-A Dynamic Chunk Convolutions and Training ‣ II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-A</span></span></a>) with a conformer transducer architecture and SummaryMixing (Section <a href="#S2.SS2" title="II-B Streaming SummaryMixing ‣ II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">II-B</span></span></a>).</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Dynamic Chunk Convolutions and Training</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Dynamic chunk training (DCT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> makes an ASR system capable of operating both in a streaming and offline settings. This is achieved by exposing the ASR model to a variety of context lengths, or <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">dynamic chunks</span>, during training. Indeed, in the streaming setting, the model cannot be allowed to look ahead far as small chunks of audio are processed at a time. Conversely, for offline ASR, the model can process the whole speech utterance.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.10" class="ltx_p">What the model is allowed to see can be expressed as a mask <math id="S2.SS1.p2.1.m1.2" class="ltx_Math" alttext="\mathbf{M}\in\{0,1\}^{T\times T}" display="inline"><semantics id="S2.SS1.p2.1.m1.2a"><mrow id="S2.SS1.p2.1.m1.2.3" xref="S2.SS1.p2.1.m1.2.3.cmml"><mi id="S2.SS1.p2.1.m1.2.3.2" xref="S2.SS1.p2.1.m1.2.3.2.cmml">𝐌</mi><mo id="S2.SS1.p2.1.m1.2.3.1" xref="S2.SS1.p2.1.m1.2.3.1.cmml">∈</mo><msup id="S2.SS1.p2.1.m1.2.3.3" xref="S2.SS1.p2.1.m1.2.3.3.cmml"><mrow id="S2.SS1.p2.1.m1.2.3.3.2.2" xref="S2.SS1.p2.1.m1.2.3.3.2.1.cmml"><mo stretchy="false" id="S2.SS1.p2.1.m1.2.3.3.2.2.1" xref="S2.SS1.p2.1.m1.2.3.3.2.1.cmml">{</mo><mn id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">0</mn><mo id="S2.SS1.p2.1.m1.2.3.3.2.2.2" xref="S2.SS1.p2.1.m1.2.3.3.2.1.cmml">,</mo><mn id="S2.SS1.p2.1.m1.2.2" xref="S2.SS1.p2.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S2.SS1.p2.1.m1.2.3.3.2.2.3" xref="S2.SS1.p2.1.m1.2.3.3.2.1.cmml">}</mo></mrow><mrow id="S2.SS1.p2.1.m1.2.3.3.3" xref="S2.SS1.p2.1.m1.2.3.3.3.cmml"><mi id="S2.SS1.p2.1.m1.2.3.3.3.2" xref="S2.SS1.p2.1.m1.2.3.3.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p2.1.m1.2.3.3.3.1" xref="S2.SS1.p2.1.m1.2.3.3.3.1.cmml">×</mo><mi id="S2.SS1.p2.1.m1.2.3.3.3.3" xref="S2.SS1.p2.1.m1.2.3.3.3.3.cmml">T</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.2b"><apply id="S2.SS1.p2.1.m1.2.3.cmml" xref="S2.SS1.p2.1.m1.2.3"><in id="S2.SS1.p2.1.m1.2.3.1.cmml" xref="S2.SS1.p2.1.m1.2.3.1"></in><ci id="S2.SS1.p2.1.m1.2.3.2.cmml" xref="S2.SS1.p2.1.m1.2.3.2">𝐌</ci><apply id="S2.SS1.p2.1.m1.2.3.3.cmml" xref="S2.SS1.p2.1.m1.2.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.2.3.3.1.cmml" xref="S2.SS1.p2.1.m1.2.3.3">superscript</csymbol><set id="S2.SS1.p2.1.m1.2.3.3.2.1.cmml" xref="S2.SS1.p2.1.m1.2.3.3.2.2"><cn type="integer" id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">0</cn><cn type="integer" id="S2.SS1.p2.1.m1.2.2.cmml" xref="S2.SS1.p2.1.m1.2.2">1</cn></set><apply id="S2.SS1.p2.1.m1.2.3.3.3.cmml" xref="S2.SS1.p2.1.m1.2.3.3.3"><times id="S2.SS1.p2.1.m1.2.3.3.3.1.cmml" xref="S2.SS1.p2.1.m1.2.3.3.3.1"></times><ci id="S2.SS1.p2.1.m1.2.3.3.3.2.cmml" xref="S2.SS1.p2.1.m1.2.3.3.3.2">𝑇</ci><ci id="S2.SS1.p2.1.m1.2.3.3.3.3.cmml" xref="S2.SS1.p2.1.m1.2.3.3.3.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.2c">\mathbf{M}\in\{0,1\}^{T\times T}</annotation></semantics></math> with <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">T</annotation></semantics></math> the number of frames or time steps in the sequence. The element <math id="S2.SS1.p2.3.m3.2" class="ltx_Math" alttext="m_{t,u}" display="inline"><semantics id="S2.SS1.p2.3.m3.2a"><msub id="S2.SS1.p2.3.m3.2.3" xref="S2.SS1.p2.3.m3.2.3.cmml"><mi id="S2.SS1.p2.3.m3.2.3.2" xref="S2.SS1.p2.3.m3.2.3.2.cmml">m</mi><mrow id="S2.SS1.p2.3.m3.2.2.2.4" xref="S2.SS1.p2.3.m3.2.2.2.3.cmml"><mi id="S2.SS1.p2.3.m3.1.1.1.1" xref="S2.SS1.p2.3.m3.1.1.1.1.cmml">t</mi><mo id="S2.SS1.p2.3.m3.2.2.2.4.1" xref="S2.SS1.p2.3.m3.2.2.2.3.cmml">,</mo><mi id="S2.SS1.p2.3.m3.2.2.2.2" xref="S2.SS1.p2.3.m3.2.2.2.2.cmml">u</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.2b"><apply id="S2.SS1.p2.3.m3.2.3.cmml" xref="S2.SS1.p2.3.m3.2.3"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.2.3.1.cmml" xref="S2.SS1.p2.3.m3.2.3">subscript</csymbol><ci id="S2.SS1.p2.3.m3.2.3.2.cmml" xref="S2.SS1.p2.3.m3.2.3.2">𝑚</ci><list id="S2.SS1.p2.3.m3.2.2.2.3.cmml" xref="S2.SS1.p2.3.m3.2.2.2.4"><ci id="S2.SS1.p2.3.m3.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1.1.1">𝑡</ci><ci id="S2.SS1.p2.3.m3.2.2.2.2.cmml" xref="S2.SS1.p2.3.m3.2.2.2.2">𝑢</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.2c">m_{t,u}</annotation></semantics></math> of the mask indicates whether at time step <math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">t</annotation></semantics></math> the model is allowed to see the input, from time <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><mi id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><ci id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">u</annotation></semantics></math>.
The whole batch uses the same mask, which is constructed as follows.
A chunk size <math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><mi id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">C</annotation></semantics></math> is drawn randomly from <math id="S2.SS1.p2.7.m7.2" class="ltx_Math" alttext="[1,T]" display="inline"><semantics id="S2.SS1.p2.7.m7.2a"><mrow id="S2.SS1.p2.7.m7.2.3.2" xref="S2.SS1.p2.7.m7.2.3.1.cmml"><mo stretchy="false" id="S2.SS1.p2.7.m7.2.3.2.1" xref="S2.SS1.p2.7.m7.2.3.1.cmml">[</mo><mn id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml">1</mn><mo id="S2.SS1.p2.7.m7.2.3.2.2" xref="S2.SS1.p2.7.m7.2.3.1.cmml">,</mo><mi id="S2.SS1.p2.7.m7.2.2" xref="S2.SS1.p2.7.m7.2.2.cmml">T</mi><mo stretchy="false" id="S2.SS1.p2.7.m7.2.3.2.3" xref="S2.SS1.p2.7.m7.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.2b"><interval closure="closed" id="S2.SS1.p2.7.m7.2.3.1.cmml" xref="S2.SS1.p2.7.m7.2.3.2"><cn type="integer" id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">1</cn><ci id="S2.SS1.p2.7.m7.2.2.cmml" xref="S2.SS1.p2.7.m7.2.2">𝑇</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.2c">[1,T]</annotation></semantics></math>.
To restrict the quadratic complexity of self-attention, the left context is often limited to <math id="S2.SS1.p2.8.m8.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.SS1.p2.8.m8.1a"><mi id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><ci id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">L</annotation></semantics></math> chunks, with <math id="S2.SS1.p2.9.m9.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.SS1.p2.9.m9.1a"><mi id="S2.SS1.p2.9.m9.1.1" xref="S2.SS1.p2.9.m9.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m9.1b"><ci id="S2.SS1.p2.9.m9.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m9.1c">L</annotation></semantics></math> drawn from <math id="S2.SS1.p2.10.m10.3" class="ltx_Math" alttext="\big{[}0,\lceil\frac{T}{C}\rceil\big{]}" display="inline"><semantics id="S2.SS1.p2.10.m10.3a"><mrow id="S2.SS1.p2.10.m10.3.3.1" xref="S2.SS1.p2.10.m10.3.3.2.cmml"><mo maxsize="120%" minsize="120%" id="S2.SS1.p2.10.m10.3.3.1.2" xref="S2.SS1.p2.10.m10.3.3.2.cmml">[</mo><mn id="S2.SS1.p2.10.m10.2.2" xref="S2.SS1.p2.10.m10.2.2.cmml">0</mn><mo id="S2.SS1.p2.10.m10.3.3.1.3" xref="S2.SS1.p2.10.m10.3.3.2.cmml">,</mo><mrow id="S2.SS1.p2.10.m10.3.3.1.1.2" xref="S2.SS1.p2.10.m10.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.10.m10.3.3.1.1.2.1" xref="S2.SS1.p2.10.m10.3.3.1.1.1.1.cmml">⌈</mo><mfrac id="S2.SS1.p2.10.m10.1.1" xref="S2.SS1.p2.10.m10.1.1.cmml"><mi id="S2.SS1.p2.10.m10.1.1.2" xref="S2.SS1.p2.10.m10.1.1.2.cmml">T</mi><mi id="S2.SS1.p2.10.m10.1.1.3" xref="S2.SS1.p2.10.m10.1.1.3.cmml">C</mi></mfrac><mo stretchy="false" id="S2.SS1.p2.10.m10.3.3.1.1.2.2" xref="S2.SS1.p2.10.m10.3.3.1.1.1.1.cmml">⌉</mo></mrow><mo maxsize="120%" minsize="120%" id="S2.SS1.p2.10.m10.3.3.1.4" xref="S2.SS1.p2.10.m10.3.3.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m10.3b"><interval closure="closed" id="S2.SS1.p2.10.m10.3.3.2.cmml" xref="S2.SS1.p2.10.m10.3.3.1"><cn type="integer" id="S2.SS1.p2.10.m10.2.2.cmml" xref="S2.SS1.p2.10.m10.2.2">0</cn><apply id="S2.SS1.p2.10.m10.3.3.1.1.1.cmml" xref="S2.SS1.p2.10.m10.3.3.1.1.2"><ceiling id="S2.SS1.p2.10.m10.3.3.1.1.1.1.cmml" xref="S2.SS1.p2.10.m10.3.3.1.1.2.1"></ceiling><apply id="S2.SS1.p2.10.m10.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1"><divide id="S2.SS1.p2.10.m10.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1"></divide><ci id="S2.SS1.p2.10.m10.1.1.2.cmml" xref="S2.SS1.p2.10.m10.1.1.2">𝑇</ci><ci id="S2.SS1.p2.10.m10.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.3">𝐶</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m10.3c">\big{[}0,\lceil\frac{T}{C}\rceil\big{]}</annotation></semantics></math>.
The mask is then set to:</p>
<table id="S4.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E3.m1.2" class="ltx_Math" alttext="\displaystyle m_{t,u}" display="inline"><semantics id="S2.E3.m1.2a"><msub id="S2.E3.m1.2.3" xref="S2.E3.m1.2.3.cmml"><mi id="S2.E3.m1.2.3.2" xref="S2.E3.m1.2.3.2.cmml">m</mi><mrow id="S2.E3.m1.2.2.2.4" xref="S2.E3.m1.2.2.2.3.cmml"><mi id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">t</mi><mo id="S2.E3.m1.2.2.2.4.1" xref="S2.E3.m1.2.2.2.3.cmml">,</mo><mi id="S2.E3.m1.2.2.2.2" xref="S2.E3.m1.2.2.2.2.cmml">u</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.E3.m1.2b"><apply id="S2.E3.m1.2.3.cmml" xref="S2.E3.m1.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.3.1.cmml" xref="S2.E3.m1.2.3">subscript</csymbol><ci id="S2.E3.m1.2.3.2.cmml" xref="S2.E3.m1.2.3.2">𝑚</ci><list id="S2.E3.m1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.4"><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">𝑡</ci><ci id="S2.E3.m1.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2">𝑢</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.2c">\displaystyle m_{t,u}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E3.m2.1" class="ltx_Math" alttext="\displaystyle=\left\{\begin{array}[]{ll}1&amp;\text{if~{}}\left\lfloor\frac{u}{C}\right\rfloor-L\leq\left\lfloor\frac{t}{C}\right\rfloor\leq\left\lfloor\frac{u}{C}\right\rfloor;\\
0&amp;\text{otherwise.}\end{array}\right." display="inline"><semantics id="S2.E3.m2.1a"><mrow id="S2.E3.m2.1.2" xref="S2.E3.m2.1.2.cmml"><mi id="S2.E3.m2.1.2.2" xref="S2.E3.m2.1.2.2.cmml"></mi><mo id="S2.E3.m2.1.2.1" xref="S2.E3.m2.1.2.1.cmml">=</mo><mrow id="S2.E3.m2.1.2.3.2" xref="S2.E3.m2.1.2.3.1.cmml"><mo id="S2.E3.m2.1.2.3.2.1" xref="S2.E3.m2.1.2.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S2.E3.m2.1.1" xref="S2.E3.m2.1.1.cmml"><mtr id="S2.E3.m2.1.1a" xref="S2.E3.m2.1.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m2.1.1b" xref="S2.E3.m2.1.1.cmml"><mn id="S2.E1.5.1" xref="S2.E1.5.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m2.1.1c" xref="S2.E3.m2.1.1.cmml"><mrow id="S2.E1.4.4.4" xref="S2.E1.4.4.4.1.cmml"><mrow id="S2.E1.4.4.4.1" xref="S2.E1.4.4.4.1.cmml"><mrow id="S2.E1.4.4.4.1.2" xref="S2.E1.4.4.4.1.2.cmml"><mrow id="S2.E1.4.4.4.1.2.2" xref="S2.E1.4.4.4.1.2.2.cmml"><mtext id="S2.E1.4.4.4.1.2.2.2" xref="S2.E1.4.4.4.1.2.2.2a.cmml">if </mtext><mo lspace="0em" rspace="0em" id="S2.E1.4.4.4.1.2.2.1" xref="S2.E1.4.4.4.1.2.2.1.cmml">​</mo><mrow id="S2.E1.4.4.4.1.2.2.3.2" xref="S2.E1.4.4.4.1.2.2.3.1.cmml"><mo id="S2.E1.4.4.4.1.2.2.3.2.1" xref="S2.E1.4.4.4.1.2.2.3.1.1.cmml">⌊</mo><mfrac id="S2.E1.1.1.1" xref="S2.E1.1.1.1.cmml"><mi id="S2.E1.1.1.1.2" xref="S2.E1.1.1.1.2.cmml">u</mi><mi id="S2.E1.1.1.1.3" xref="S2.E1.1.1.1.3.cmml">C</mi></mfrac><mo id="S2.E1.4.4.4.1.2.2.3.2.2" xref="S2.E1.4.4.4.1.2.2.3.1.1.cmml">⌋</mo></mrow></mrow><mo id="S2.E1.4.4.4.1.2.1" xref="S2.E1.4.4.4.1.2.1.cmml">−</mo><mi id="S2.E1.4.4.4.1.2.3" xref="S2.E1.4.4.4.1.2.3.cmml">L</mi></mrow><mo id="S2.E1.4.4.4.1.3" xref="S2.E1.4.4.4.1.3.cmml">≤</mo><mrow id="S2.E1.4.4.4.1.4.2" xref="S2.E1.4.4.4.1.4.1.cmml"><mo id="S2.E1.4.4.4.1.4.2.1" xref="S2.E1.4.4.4.1.4.1.1.cmml">⌊</mo><mfrac id="S2.E1.2.2.2" xref="S2.E1.2.2.2.cmml"><mi id="S2.E1.2.2.2.2" xref="S2.E1.2.2.2.2.cmml">t</mi><mi id="S2.E1.2.2.2.3" xref="S2.E1.2.2.2.3.cmml">C</mi></mfrac><mo id="S2.E1.4.4.4.1.4.2.2" xref="S2.E1.4.4.4.1.4.1.1.cmml">⌋</mo></mrow><mo id="S2.E1.4.4.4.1.5" xref="S2.E1.4.4.4.1.5.cmml">≤</mo><mrow id="S2.E1.4.4.4.1.6.2" xref="S2.E1.4.4.4.1.6.1.cmml"><mo id="S2.E1.4.4.4.1.6.2.1" xref="S2.E1.4.4.4.1.6.1.1.cmml">⌊</mo><mfrac id="S2.E1.3.3.3" xref="S2.E1.3.3.3.cmml"><mi id="S2.E1.3.3.3.2" xref="S2.E1.3.3.3.2.cmml">u</mi><mi id="S2.E1.3.3.3.3" xref="S2.E1.3.3.3.3.cmml">C</mi></mfrac><mo id="S2.E1.4.4.4.1.6.2.2" xref="S2.E1.4.4.4.1.6.1.1.cmml">⌋</mo></mrow></mrow><mo id="S2.E1.4.4.4.2" xref="S2.E1.4.4.4.1.cmml">;</mo></mrow></mtd></mtr><mtr id="S2.E3.m2.1.1d" xref="S2.E3.m2.1.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m2.1.1e" xref="S2.E3.m2.1.1.cmml"><mn id="S2.E2.1.1" xref="S2.E2.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E3.m2.1.1f" xref="S2.E3.m2.1.1.cmml"><mtext id="S2.E2.2.1" xref="S2.E2.2.1a.cmml">otherwise.</mtext></mtd></mtr></mtable><mi id="S2.E3.m2.1.2.3.2.2" xref="S2.E3.m2.1.2.3.1.1.cmml"></mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m2.1b"><apply id="S2.E3.m2.1.2.cmml" xref="S2.E3.m2.1.2"><eq id="S2.E3.m2.1.2.1.cmml" xref="S2.E3.m2.1.2.1"></eq><csymbol cd="latexml" id="S2.E3.m2.1.2.2.cmml" xref="S2.E3.m2.1.2.2">absent</csymbol><apply id="S2.E3.m2.1.2.3.1.cmml" xref="S2.E3.m2.1.2.3.2"><csymbol cd="latexml" id="S2.E3.m2.1.2.3.1.1.cmml" xref="S2.E3.m2.1.2.3.2.1">cases</csymbol><matrix id="S2.E3.m2.1.1.cmml" xref="S2.E3.m2.1.1"><matrixrow id="S2.E3.m2.1.1a.cmml" xref="S2.E3.m2.1.1"><cn type="integer" id="S2.E1.5.1.cmml" xref="S2.E1.5.1">1</cn><apply id="S2.E1.4.4.4.1.cmml" xref="S2.E1.4.4.4"><and id="S2.E1.4.4.4.1a.cmml" xref="S2.E1.4.4.4"></and><apply id="S2.E1.4.4.4.1b.cmml" xref="S2.E1.4.4.4"><leq id="S2.E1.4.4.4.1.3.cmml" xref="S2.E1.4.4.4.1.3"></leq><apply id="S2.E1.4.4.4.1.2.cmml" xref="S2.E1.4.4.4.1.2"><minus id="S2.E1.4.4.4.1.2.1.cmml" xref="S2.E1.4.4.4.1.2.1"></minus><apply id="S2.E1.4.4.4.1.2.2.cmml" xref="S2.E1.4.4.4.1.2.2"><times id="S2.E1.4.4.4.1.2.2.1.cmml" xref="S2.E1.4.4.4.1.2.2.1"></times><ci id="S2.E1.4.4.4.1.2.2.2a.cmml" xref="S2.E1.4.4.4.1.2.2.2"><mtext id="S2.E1.4.4.4.1.2.2.2.cmml" xref="S2.E1.4.4.4.1.2.2.2">if </mtext></ci><apply id="S2.E1.4.4.4.1.2.2.3.1.cmml" xref="S2.E1.4.4.4.1.2.2.3.2"><floor id="S2.E1.4.4.4.1.2.2.3.1.1.cmml" xref="S2.E1.4.4.4.1.2.2.3.2.1"></floor><apply id="S2.E1.1.1.1.cmml" xref="S2.E1.1.1.1"><divide id="S2.E1.1.1.1.1.cmml" xref="S2.E1.1.1.1"></divide><ci id="S2.E1.1.1.1.2.cmml" xref="S2.E1.1.1.1.2">𝑢</ci><ci id="S2.E1.1.1.1.3.cmml" xref="S2.E1.1.1.1.3">𝐶</ci></apply></apply></apply><ci id="S2.E1.4.4.4.1.2.3.cmml" xref="S2.E1.4.4.4.1.2.3">𝐿</ci></apply><apply id="S2.E1.4.4.4.1.4.1.cmml" xref="S2.E1.4.4.4.1.4.2"><floor id="S2.E1.4.4.4.1.4.1.1.cmml" xref="S2.E1.4.4.4.1.4.2.1"></floor><apply id="S2.E1.2.2.2.cmml" xref="S2.E1.2.2.2"><divide id="S2.E1.2.2.2.1.cmml" xref="S2.E1.2.2.2"></divide><ci id="S2.E1.2.2.2.2.cmml" xref="S2.E1.2.2.2.2">𝑡</ci><ci id="S2.E1.2.2.2.3.cmml" xref="S2.E1.2.2.2.3">𝐶</ci></apply></apply></apply><apply id="S2.E1.4.4.4.1c.cmml" xref="S2.E1.4.4.4"><leq id="S2.E1.4.4.4.1.5.cmml" xref="S2.E1.4.4.4.1.5"></leq><share href="#S2.E1.4.4.4.1.4.cmml" id="S2.E1.4.4.4.1d.cmml" xref="S2.E1.4.4.4"></share><apply id="S2.E1.4.4.4.1.6.1.cmml" xref="S2.E1.4.4.4.1.6.2"><floor id="S2.E1.4.4.4.1.6.1.1.cmml" xref="S2.E1.4.4.4.1.6.2.1"></floor><apply id="S2.E1.3.3.3.cmml" xref="S2.E1.3.3.3"><divide id="S2.E1.3.3.3.1.cmml" xref="S2.E1.3.3.3"></divide><ci id="S2.E1.3.3.3.2.cmml" xref="S2.E1.3.3.3.2">𝑢</ci><ci id="S2.E1.3.3.3.3.cmml" xref="S2.E1.3.3.3.3">𝐶</ci></apply></apply></apply></apply></matrixrow><matrixrow id="S2.E3.m2.1.1b.cmml" xref="S2.E3.m2.1.1"><cn type="integer" id="S2.E2.1.1.cmml" xref="S2.E2.1.1">0</cn><ci id="S2.E2.2.1a.cmml" xref="S2.E2.2.1"><mtext id="S2.E2.2.1.cmml" xref="S2.E2.2.1">otherwise.</mtext></ci></matrixrow></matrix></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m2.1c">\displaystyle=\left\{\begin{array}[]{ll}1&amp;\text{if~{}}\left\lfloor\frac{u}{C}\right\rfloor-L\leq\left\lfloor\frac{t}{C}\right\rfloor\leq\left\lfloor\frac{u}{C}\right\rfloor;\\
0&amp;\text{otherwise.}\end{array}\right.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p2.16" class="ltx_p">When <math id="S2.SS1.p2.11.m1.1" class="ltx_Math" alttext="C=T" display="inline"><semantics id="S2.SS1.p2.11.m1.1a"><mrow id="S2.SS1.p2.11.m1.1.1" xref="S2.SS1.p2.11.m1.1.1.cmml"><mi id="S2.SS1.p2.11.m1.1.1.2" xref="S2.SS1.p2.11.m1.1.1.2.cmml">C</mi><mo id="S2.SS1.p2.11.m1.1.1.1" xref="S2.SS1.p2.11.m1.1.1.1.cmml">=</mo><mi id="S2.SS1.p2.11.m1.1.1.3" xref="S2.SS1.p2.11.m1.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.11.m1.1b"><apply id="S2.SS1.p2.11.m1.1.1.cmml" xref="S2.SS1.p2.11.m1.1.1"><eq id="S2.SS1.p2.11.m1.1.1.1.cmml" xref="S2.SS1.p2.11.m1.1.1.1"></eq><ci id="S2.SS1.p2.11.m1.1.1.2.cmml" xref="S2.SS1.p2.11.m1.1.1.2">𝐶</ci><ci id="S2.SS1.p2.11.m1.1.1.3.cmml" xref="S2.SS1.p2.11.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.11.m1.1c">C=T</annotation></semantics></math>, the model can see the complete input, since then <math id="S2.SS1.p2.12.m2.2" class="ltx_Math" alttext="m_{t,u}=1" display="inline"><semantics id="S2.SS1.p2.12.m2.2a"><mrow id="S2.SS1.p2.12.m2.2.3" xref="S2.SS1.p2.12.m2.2.3.cmml"><msub id="S2.SS1.p2.12.m2.2.3.2" xref="S2.SS1.p2.12.m2.2.3.2.cmml"><mi id="S2.SS1.p2.12.m2.2.3.2.2" xref="S2.SS1.p2.12.m2.2.3.2.2.cmml">m</mi><mrow id="S2.SS1.p2.12.m2.2.2.2.4" xref="S2.SS1.p2.12.m2.2.2.2.3.cmml"><mi id="S2.SS1.p2.12.m2.1.1.1.1" xref="S2.SS1.p2.12.m2.1.1.1.1.cmml">t</mi><mo id="S2.SS1.p2.12.m2.2.2.2.4.1" xref="S2.SS1.p2.12.m2.2.2.2.3.cmml">,</mo><mi id="S2.SS1.p2.12.m2.2.2.2.2" xref="S2.SS1.p2.12.m2.2.2.2.2.cmml">u</mi></mrow></msub><mo id="S2.SS1.p2.12.m2.2.3.1" xref="S2.SS1.p2.12.m2.2.3.1.cmml">=</mo><mn id="S2.SS1.p2.12.m2.2.3.3" xref="S2.SS1.p2.12.m2.2.3.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.12.m2.2b"><apply id="S2.SS1.p2.12.m2.2.3.cmml" xref="S2.SS1.p2.12.m2.2.3"><eq id="S2.SS1.p2.12.m2.2.3.1.cmml" xref="S2.SS1.p2.12.m2.2.3.1"></eq><apply id="S2.SS1.p2.12.m2.2.3.2.cmml" xref="S2.SS1.p2.12.m2.2.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.12.m2.2.3.2.1.cmml" xref="S2.SS1.p2.12.m2.2.3.2">subscript</csymbol><ci id="S2.SS1.p2.12.m2.2.3.2.2.cmml" xref="S2.SS1.p2.12.m2.2.3.2.2">𝑚</ci><list id="S2.SS1.p2.12.m2.2.2.2.3.cmml" xref="S2.SS1.p2.12.m2.2.2.2.4"><ci id="S2.SS1.p2.12.m2.1.1.1.1.cmml" xref="S2.SS1.p2.12.m2.1.1.1.1">𝑡</ci><ci id="S2.SS1.p2.12.m2.2.2.2.2.cmml" xref="S2.SS1.p2.12.m2.2.2.2.2">𝑢</ci></list></apply><cn type="integer" id="S2.SS1.p2.12.m2.2.3.3.cmml" xref="S2.SS1.p2.12.m2.2.3.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.12.m2.2c">m_{t,u}=1</annotation></semantics></math> for all <math id="S2.SS1.p2.13.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p2.13.m3.1a"><mi id="S2.SS1.p2.13.m3.1.1" xref="S2.SS1.p2.13.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.13.m3.1b"><ci id="S2.SS1.p2.13.m3.1.1.cmml" xref="S2.SS1.p2.13.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.13.m3.1c">t</annotation></semantics></math> and <math id="S2.SS1.p2.14.m4.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S2.SS1.p2.14.m4.1a"><mi id="S2.SS1.p2.14.m4.1.1" xref="S2.SS1.p2.14.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.14.m4.1b"><ci id="S2.SS1.p2.14.m4.1.1.cmml" xref="S2.SS1.p2.14.m4.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.14.m4.1c">u</annotation></semantics></math>.
Otherwise, setting <math id="S2.SS1.p2.15.m5.1" class="ltx_Math" alttext="L=\lfloor T/C\rfloor" display="inline"><semantics id="S2.SS1.p2.15.m5.1a"><mrow id="S2.SS1.p2.15.m5.1.1" xref="S2.SS1.p2.15.m5.1.1.cmml"><mi id="S2.SS1.p2.15.m5.1.1.3" xref="S2.SS1.p2.15.m5.1.1.3.cmml">L</mi><mo id="S2.SS1.p2.15.m5.1.1.2" xref="S2.SS1.p2.15.m5.1.1.2.cmml">=</mo><mrow id="S2.SS1.p2.15.m5.1.1.1.1" xref="S2.SS1.p2.15.m5.1.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p2.15.m5.1.1.1.1.2" xref="S2.SS1.p2.15.m5.1.1.1.2.1.cmml">⌊</mo><mrow id="S2.SS1.p2.15.m5.1.1.1.1.1" xref="S2.SS1.p2.15.m5.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.15.m5.1.1.1.1.1.2" xref="S2.SS1.p2.15.m5.1.1.1.1.1.2.cmml">T</mi><mo id="S2.SS1.p2.15.m5.1.1.1.1.1.1" xref="S2.SS1.p2.15.m5.1.1.1.1.1.1.cmml">/</mo><mi id="S2.SS1.p2.15.m5.1.1.1.1.1.3" xref="S2.SS1.p2.15.m5.1.1.1.1.1.3.cmml">C</mi></mrow><mo stretchy="false" id="S2.SS1.p2.15.m5.1.1.1.1.3" xref="S2.SS1.p2.15.m5.1.1.1.2.1.cmml">⌋</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.15.m5.1b"><apply id="S2.SS1.p2.15.m5.1.1.cmml" xref="S2.SS1.p2.15.m5.1.1"><eq id="S2.SS1.p2.15.m5.1.1.2.cmml" xref="S2.SS1.p2.15.m5.1.1.2"></eq><ci id="S2.SS1.p2.15.m5.1.1.3.cmml" xref="S2.SS1.p2.15.m5.1.1.3">𝐿</ci><apply id="S2.SS1.p2.15.m5.1.1.1.2.cmml" xref="S2.SS1.p2.15.m5.1.1.1.1"><floor id="S2.SS1.p2.15.m5.1.1.1.2.1.cmml" xref="S2.SS1.p2.15.m5.1.1.1.1.2"></floor><apply id="S2.SS1.p2.15.m5.1.1.1.1.1.cmml" xref="S2.SS1.p2.15.m5.1.1.1.1.1"><divide id="S2.SS1.p2.15.m5.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.15.m5.1.1.1.1.1.1"></divide><ci id="S2.SS1.p2.15.m5.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.15.m5.1.1.1.1.1.2">𝑇</ci><ci id="S2.SS1.p2.15.m5.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.15.m5.1.1.1.1.1.3">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.15.m5.1c">L=\lfloor T/C\rfloor</annotation></semantics></math> results in infinite left context.
If the left context is infinite, then the mask only grows as time proceeds: <math id="S2.SS1.p2.16.m6.4" class="ltx_Math" alttext="m_{t,u}\leq m_{t+1,u}" display="inline"><semantics id="S2.SS1.p2.16.m6.4a"><mrow id="S2.SS1.p2.16.m6.4.5" xref="S2.SS1.p2.16.m6.4.5.cmml"><msub id="S2.SS1.p2.16.m6.4.5.2" xref="S2.SS1.p2.16.m6.4.5.2.cmml"><mi id="S2.SS1.p2.16.m6.4.5.2.2" xref="S2.SS1.p2.16.m6.4.5.2.2.cmml">m</mi><mrow id="S2.SS1.p2.16.m6.2.2.2.4" xref="S2.SS1.p2.16.m6.2.2.2.3.cmml"><mi id="S2.SS1.p2.16.m6.1.1.1.1" xref="S2.SS1.p2.16.m6.1.1.1.1.cmml">t</mi><mo id="S2.SS1.p2.16.m6.2.2.2.4.1" xref="S2.SS1.p2.16.m6.2.2.2.3.cmml">,</mo><mi id="S2.SS1.p2.16.m6.2.2.2.2" xref="S2.SS1.p2.16.m6.2.2.2.2.cmml">u</mi></mrow></msub><mo id="S2.SS1.p2.16.m6.4.5.1" xref="S2.SS1.p2.16.m6.4.5.1.cmml">≤</mo><msub id="S2.SS1.p2.16.m6.4.5.3" xref="S2.SS1.p2.16.m6.4.5.3.cmml"><mi id="S2.SS1.p2.16.m6.4.5.3.2" xref="S2.SS1.p2.16.m6.4.5.3.2.cmml">m</mi><mrow id="S2.SS1.p2.16.m6.4.4.2.2" xref="S2.SS1.p2.16.m6.4.4.2.3.cmml"><mrow id="S2.SS1.p2.16.m6.4.4.2.2.1" xref="S2.SS1.p2.16.m6.4.4.2.2.1.cmml"><mi id="S2.SS1.p2.16.m6.4.4.2.2.1.2" xref="S2.SS1.p2.16.m6.4.4.2.2.1.2.cmml">t</mi><mo id="S2.SS1.p2.16.m6.4.4.2.2.1.1" xref="S2.SS1.p2.16.m6.4.4.2.2.1.1.cmml">+</mo><mn id="S2.SS1.p2.16.m6.4.4.2.2.1.3" xref="S2.SS1.p2.16.m6.4.4.2.2.1.3.cmml">1</mn></mrow><mo id="S2.SS1.p2.16.m6.4.4.2.2.2" xref="S2.SS1.p2.16.m6.4.4.2.3.cmml">,</mo><mi id="S2.SS1.p2.16.m6.3.3.1.1" xref="S2.SS1.p2.16.m6.3.3.1.1.cmml">u</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.16.m6.4b"><apply id="S2.SS1.p2.16.m6.4.5.cmml" xref="S2.SS1.p2.16.m6.4.5"><leq id="S2.SS1.p2.16.m6.4.5.1.cmml" xref="S2.SS1.p2.16.m6.4.5.1"></leq><apply id="S2.SS1.p2.16.m6.4.5.2.cmml" xref="S2.SS1.p2.16.m6.4.5.2"><csymbol cd="ambiguous" id="S2.SS1.p2.16.m6.4.5.2.1.cmml" xref="S2.SS1.p2.16.m6.4.5.2">subscript</csymbol><ci id="S2.SS1.p2.16.m6.4.5.2.2.cmml" xref="S2.SS1.p2.16.m6.4.5.2.2">𝑚</ci><list id="S2.SS1.p2.16.m6.2.2.2.3.cmml" xref="S2.SS1.p2.16.m6.2.2.2.4"><ci id="S2.SS1.p2.16.m6.1.1.1.1.cmml" xref="S2.SS1.p2.16.m6.1.1.1.1">𝑡</ci><ci id="S2.SS1.p2.16.m6.2.2.2.2.cmml" xref="S2.SS1.p2.16.m6.2.2.2.2">𝑢</ci></list></apply><apply id="S2.SS1.p2.16.m6.4.5.3.cmml" xref="S2.SS1.p2.16.m6.4.5.3"><csymbol cd="ambiguous" id="S2.SS1.p2.16.m6.4.5.3.1.cmml" xref="S2.SS1.p2.16.m6.4.5.3">subscript</csymbol><ci id="S2.SS1.p2.16.m6.4.5.3.2.cmml" xref="S2.SS1.p2.16.m6.4.5.3.2">𝑚</ci><list id="S2.SS1.p2.16.m6.4.4.2.3.cmml" xref="S2.SS1.p2.16.m6.4.4.2.2"><apply id="S2.SS1.p2.16.m6.4.4.2.2.1.cmml" xref="S2.SS1.p2.16.m6.4.4.2.2.1"><plus id="S2.SS1.p2.16.m6.4.4.2.2.1.1.cmml" xref="S2.SS1.p2.16.m6.4.4.2.2.1.1"></plus><ci id="S2.SS1.p2.16.m6.4.4.2.2.1.2.cmml" xref="S2.SS1.p2.16.m6.4.4.2.2.1.2">𝑡</ci><cn type="integer" id="S2.SS1.p2.16.m6.4.4.2.2.1.3.cmml" xref="S2.SS1.p2.16.m6.4.4.2.2.1.3">1</cn></apply><ci id="S2.SS1.p2.16.m6.3.3.1.1.cmml" xref="S2.SS1.p2.16.m6.3.3.1.1">𝑢</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.16.m6.4c">m_{t,u}\leq m_{t+1,u}</annotation></semantics></math>. The implementation implications of this chunking depend on the type of neural network.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Convolutional layers require a specific design to avoid data leakage from future frames. If using standard convolutional layers, kernels will be trained to see a few frames after the chunk boundaries, and therefore performance will degrade significantly at inference time as these frames are not available. Causal convolutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> address this issue by shifting to the left of the convolutional kernels with the current frame being the rightmost element. However, in the case of DCT, it also means that every frame computed with causal convolution does not integrate information from the future within the chunk boundaries, resulting in performance degradation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Dynamic chunk convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> (DCCONV) addresses all these issues by keeping standard convolutional kernels centered on the current frame, hence allowing within-chunk future information, but with masking according to the boundaries of the chunk. Hence, convolutional kernels will see different levels of masking as they progress on the rightmost frames.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">For self-attention layers, things are much simpler as the attention score is masked according to the chunk boundaries. Hence, no frames from outside of the chunk or the left context are being attended by the attention mechanism.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">ASR systems trained with DCT and DCCONV are capable of both streaming and non-streaming ASR without architectural change or fine-tuning as shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. We rely on the DCT available in SpeechBrain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Streaming SummaryMixing</span>
</h3>

<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F1.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.07165/assets/x1.png" id="S2.F1.1.g1" class="ltx_graphics ltx_img_portrait" width="80" height="191" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F1.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.07165/assets/x2.png" id="S2.F1.2.g1" class="ltx_graphics ltx_img_portrait" width="88" height="191" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.4.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.5.2" class="ltx_text" style="font-size:90%;">The Conformer with non-streaming (left) and streaming (right) SummaryMixing.</span></figcaption>
</figure>
<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">SummaryMixing was introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> as a drop-in replacement for self-attention in offline ASR that reduces the time complexity from quadratic to linear. In the following, we recall its basics, extend it to the streaming ASR scenario, and introduce it to the conformer transducer.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.5" class="ltx_p">Much like self-attention, SummaryMixing takes an input sequence <math id="S2.SS2.p2.1.m1.3" class="ltx_Math" alttext="\mathbf{X}\in\mathbb{R}^{T\times D}=\{\mathbf{x}_{0},\ldots,\mathbf{x}_{T}\}" display="inline"><semantics id="S2.SS2.p2.1.m1.3a"><mrow id="S2.SS2.p2.1.m1.3.3" xref="S2.SS2.p2.1.m1.3.3.cmml"><mi id="S2.SS2.p2.1.m1.3.3.4" xref="S2.SS2.p2.1.m1.3.3.4.cmml">𝐗</mi><mo id="S2.SS2.p2.1.m1.3.3.5" xref="S2.SS2.p2.1.m1.3.3.5.cmml">∈</mo><msup id="S2.SS2.p2.1.m1.3.3.6" xref="S2.SS2.p2.1.m1.3.3.6.cmml"><mi id="S2.SS2.p2.1.m1.3.3.6.2" xref="S2.SS2.p2.1.m1.3.3.6.2.cmml">ℝ</mi><mrow id="S2.SS2.p2.1.m1.3.3.6.3" xref="S2.SS2.p2.1.m1.3.3.6.3.cmml"><mi id="S2.SS2.p2.1.m1.3.3.6.3.2" xref="S2.SS2.p2.1.m1.3.3.6.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS2.p2.1.m1.3.3.6.3.1" xref="S2.SS2.p2.1.m1.3.3.6.3.1.cmml">×</mo><mi id="S2.SS2.p2.1.m1.3.3.6.3.3" xref="S2.SS2.p2.1.m1.3.3.6.3.3.cmml">D</mi></mrow></msup><mo id="S2.SS2.p2.1.m1.3.3.7" xref="S2.SS2.p2.1.m1.3.3.7.cmml">=</mo><mrow id="S2.SS2.p2.1.m1.3.3.2.2" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S2.SS2.p2.1.m1.3.3.2.2.3" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml">{</mo><msub id="S2.SS2.p2.1.m1.2.2.1.1.1" xref="S2.SS2.p2.1.m1.2.2.1.1.1.cmml"><mi id="S2.SS2.p2.1.m1.2.2.1.1.1.2" xref="S2.SS2.p2.1.m1.2.2.1.1.1.2.cmml">𝐱</mi><mn id="S2.SS2.p2.1.m1.2.2.1.1.1.3" xref="S2.SS2.p2.1.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S2.SS2.p2.1.m1.3.3.2.2.4" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">…</mi><mo id="S2.SS2.p2.1.m1.3.3.2.2.5" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml">,</mo><msub id="S2.SS2.p2.1.m1.3.3.2.2.2" xref="S2.SS2.p2.1.m1.3.3.2.2.2.cmml"><mi id="S2.SS2.p2.1.m1.3.3.2.2.2.2" xref="S2.SS2.p2.1.m1.3.3.2.2.2.2.cmml">𝐱</mi><mi id="S2.SS2.p2.1.m1.3.3.2.2.2.3" xref="S2.SS2.p2.1.m1.3.3.2.2.2.3.cmml">T</mi></msub><mo stretchy="false" id="S2.SS2.p2.1.m1.3.3.2.2.6" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.3b"><apply id="S2.SS2.p2.1.m1.3.3.cmml" xref="S2.SS2.p2.1.m1.3.3"><and id="S2.SS2.p2.1.m1.3.3a.cmml" xref="S2.SS2.p2.1.m1.3.3"></and><apply id="S2.SS2.p2.1.m1.3.3b.cmml" xref="S2.SS2.p2.1.m1.3.3"><in id="S2.SS2.p2.1.m1.3.3.5.cmml" xref="S2.SS2.p2.1.m1.3.3.5"></in><ci id="S2.SS2.p2.1.m1.3.3.4.cmml" xref="S2.SS2.p2.1.m1.3.3.4">𝐗</ci><apply id="S2.SS2.p2.1.m1.3.3.6.cmml" xref="S2.SS2.p2.1.m1.3.3.6"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.3.3.6.1.cmml" xref="S2.SS2.p2.1.m1.3.3.6">superscript</csymbol><ci id="S2.SS2.p2.1.m1.3.3.6.2.cmml" xref="S2.SS2.p2.1.m1.3.3.6.2">ℝ</ci><apply id="S2.SS2.p2.1.m1.3.3.6.3.cmml" xref="S2.SS2.p2.1.m1.3.3.6.3"><times id="S2.SS2.p2.1.m1.3.3.6.3.1.cmml" xref="S2.SS2.p2.1.m1.3.3.6.3.1"></times><ci id="S2.SS2.p2.1.m1.3.3.6.3.2.cmml" xref="S2.SS2.p2.1.m1.3.3.6.3.2">𝑇</ci><ci id="S2.SS2.p2.1.m1.3.3.6.3.3.cmml" xref="S2.SS2.p2.1.m1.3.3.6.3.3">𝐷</ci></apply></apply></apply><apply id="S2.SS2.p2.1.m1.3.3c.cmml" xref="S2.SS2.p2.1.m1.3.3"><eq id="S2.SS2.p2.1.m1.3.3.7.cmml" xref="S2.SS2.p2.1.m1.3.3.7"></eq><share href="#S2.SS2.p2.1.m1.3.3.6.cmml" id="S2.SS2.p2.1.m1.3.3d.cmml" xref="S2.SS2.p2.1.m1.3.3"></share><set id="S2.SS2.p2.1.m1.3.3.2.3.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2"><apply id="S2.SS2.p2.1.m1.2.2.1.1.1.cmml" xref="S2.SS2.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.2.2.1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.p2.1.m1.2.2.1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.2.2.1.1.1.2">𝐱</ci><cn type="integer" id="S2.SS2.p2.1.m1.2.2.1.1.1.3.cmml" xref="S2.SS2.p2.1.m1.2.2.1.1.1.3">0</cn></apply><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">…</ci><apply id="S2.SS2.p2.1.m1.3.3.2.2.2.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.3.3.2.2.2.1.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.p2.1.m1.3.3.2.2.2.2.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2.2.2">𝐱</ci><ci id="S2.SS2.p2.1.m1.3.3.2.2.2.3.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2.2.3">𝑇</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.3c">\mathbf{X}\in\mathbb{R}^{T\times D}=\{\mathbf{x}_{0},\ldots,\mathbf{x}_{T}\}</annotation></semantics></math> of <math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mi id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><ci id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">T</annotation></semantics></math> feature vectors <math id="S2.SS2.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{x}_{t}" display="inline"><semantics id="S2.SS2.p2.3.m3.1a"><msub id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml"><mi id="S2.SS2.p2.3.m3.1.1.2" xref="S2.SS2.p2.3.m3.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.p2.3.m3.1.1.3" xref="S2.SS2.p2.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><apply id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.3.m3.1.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p2.3.m3.1.1.2.cmml" xref="S2.SS2.p2.3.m3.1.1.2">𝐱</ci><ci id="S2.SS2.p2.3.m3.1.1.3.cmml" xref="S2.SS2.p2.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">\mathbf{x}_{t}</annotation></semantics></math> of length <math id="S2.SS2.p2.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.SS2.p2.4.m4.1a"><mi id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.1b"><ci id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.1c">D</annotation></semantics></math>, and transforms them into hidden representations <math id="S2.SS2.p2.5.m5.3" class="ltx_Math" alttext="\mathbf{H}\in\mathbb{R}^{T\times D^{\prime}}=\{\mathbf{h}_{0},\ldots,\mathbf{h}_{T}\}" display="inline"><semantics id="S2.SS2.p2.5.m5.3a"><mrow id="S2.SS2.p2.5.m5.3.3" xref="S2.SS2.p2.5.m5.3.3.cmml"><mi id="S2.SS2.p2.5.m5.3.3.4" xref="S2.SS2.p2.5.m5.3.3.4.cmml">𝐇</mi><mo id="S2.SS2.p2.5.m5.3.3.5" xref="S2.SS2.p2.5.m5.3.3.5.cmml">∈</mo><msup id="S2.SS2.p2.5.m5.3.3.6" xref="S2.SS2.p2.5.m5.3.3.6.cmml"><mi id="S2.SS2.p2.5.m5.3.3.6.2" xref="S2.SS2.p2.5.m5.3.3.6.2.cmml">ℝ</mi><mrow id="S2.SS2.p2.5.m5.3.3.6.3" xref="S2.SS2.p2.5.m5.3.3.6.3.cmml"><mi id="S2.SS2.p2.5.m5.3.3.6.3.2" xref="S2.SS2.p2.5.m5.3.3.6.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS2.p2.5.m5.3.3.6.3.1" xref="S2.SS2.p2.5.m5.3.3.6.3.1.cmml">×</mo><msup id="S2.SS2.p2.5.m5.3.3.6.3.3" xref="S2.SS2.p2.5.m5.3.3.6.3.3.cmml"><mi id="S2.SS2.p2.5.m5.3.3.6.3.3.2" xref="S2.SS2.p2.5.m5.3.3.6.3.3.2.cmml">D</mi><mo id="S2.SS2.p2.5.m5.3.3.6.3.3.3" xref="S2.SS2.p2.5.m5.3.3.6.3.3.3.cmml">′</mo></msup></mrow></msup><mo id="S2.SS2.p2.5.m5.3.3.7" xref="S2.SS2.p2.5.m5.3.3.7.cmml">=</mo><mrow id="S2.SS2.p2.5.m5.3.3.2.2" xref="S2.SS2.p2.5.m5.3.3.2.3.cmml"><mo stretchy="false" id="S2.SS2.p2.5.m5.3.3.2.2.3" xref="S2.SS2.p2.5.m5.3.3.2.3.cmml">{</mo><msub id="S2.SS2.p2.5.m5.2.2.1.1.1" xref="S2.SS2.p2.5.m5.2.2.1.1.1.cmml"><mi id="S2.SS2.p2.5.m5.2.2.1.1.1.2" xref="S2.SS2.p2.5.m5.2.2.1.1.1.2.cmml">𝐡</mi><mn id="S2.SS2.p2.5.m5.2.2.1.1.1.3" xref="S2.SS2.p2.5.m5.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S2.SS2.p2.5.m5.3.3.2.2.4" xref="S2.SS2.p2.5.m5.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS2.p2.5.m5.1.1" xref="S2.SS2.p2.5.m5.1.1.cmml">…</mi><mo id="S2.SS2.p2.5.m5.3.3.2.2.5" xref="S2.SS2.p2.5.m5.3.3.2.3.cmml">,</mo><msub id="S2.SS2.p2.5.m5.3.3.2.2.2" xref="S2.SS2.p2.5.m5.3.3.2.2.2.cmml"><mi id="S2.SS2.p2.5.m5.3.3.2.2.2.2" xref="S2.SS2.p2.5.m5.3.3.2.2.2.2.cmml">𝐡</mi><mi id="S2.SS2.p2.5.m5.3.3.2.2.2.3" xref="S2.SS2.p2.5.m5.3.3.2.2.2.3.cmml">T</mi></msub><mo stretchy="false" id="S2.SS2.p2.5.m5.3.3.2.2.6" xref="S2.SS2.p2.5.m5.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.5.m5.3b"><apply id="S2.SS2.p2.5.m5.3.3.cmml" xref="S2.SS2.p2.5.m5.3.3"><and id="S2.SS2.p2.5.m5.3.3a.cmml" xref="S2.SS2.p2.5.m5.3.3"></and><apply id="S2.SS2.p2.5.m5.3.3b.cmml" xref="S2.SS2.p2.5.m5.3.3"><in id="S2.SS2.p2.5.m5.3.3.5.cmml" xref="S2.SS2.p2.5.m5.3.3.5"></in><ci id="S2.SS2.p2.5.m5.3.3.4.cmml" xref="S2.SS2.p2.5.m5.3.3.4">𝐇</ci><apply id="S2.SS2.p2.5.m5.3.3.6.cmml" xref="S2.SS2.p2.5.m5.3.3.6"><csymbol cd="ambiguous" id="S2.SS2.p2.5.m5.3.3.6.1.cmml" xref="S2.SS2.p2.5.m5.3.3.6">superscript</csymbol><ci id="S2.SS2.p2.5.m5.3.3.6.2.cmml" xref="S2.SS2.p2.5.m5.3.3.6.2">ℝ</ci><apply id="S2.SS2.p2.5.m5.3.3.6.3.cmml" xref="S2.SS2.p2.5.m5.3.3.6.3"><times id="S2.SS2.p2.5.m5.3.3.6.3.1.cmml" xref="S2.SS2.p2.5.m5.3.3.6.3.1"></times><ci id="S2.SS2.p2.5.m5.3.3.6.3.2.cmml" xref="S2.SS2.p2.5.m5.3.3.6.3.2">𝑇</ci><apply id="S2.SS2.p2.5.m5.3.3.6.3.3.cmml" xref="S2.SS2.p2.5.m5.3.3.6.3.3"><csymbol cd="ambiguous" id="S2.SS2.p2.5.m5.3.3.6.3.3.1.cmml" xref="S2.SS2.p2.5.m5.3.3.6.3.3">superscript</csymbol><ci id="S2.SS2.p2.5.m5.3.3.6.3.3.2.cmml" xref="S2.SS2.p2.5.m5.3.3.6.3.3.2">𝐷</ci><ci id="S2.SS2.p2.5.m5.3.3.6.3.3.3.cmml" xref="S2.SS2.p2.5.m5.3.3.6.3.3.3">′</ci></apply></apply></apply></apply><apply id="S2.SS2.p2.5.m5.3.3c.cmml" xref="S2.SS2.p2.5.m5.3.3"><eq id="S2.SS2.p2.5.m5.3.3.7.cmml" xref="S2.SS2.p2.5.m5.3.3.7"></eq><share href="#S2.SS2.p2.5.m5.3.3.6.cmml" id="S2.SS2.p2.5.m5.3.3d.cmml" xref="S2.SS2.p2.5.m5.3.3"></share><set id="S2.SS2.p2.5.m5.3.3.2.3.cmml" xref="S2.SS2.p2.5.m5.3.3.2.2"><apply id="S2.SS2.p2.5.m5.2.2.1.1.1.cmml" xref="S2.SS2.p2.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.5.m5.2.2.1.1.1.1.cmml" xref="S2.SS2.p2.5.m5.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.p2.5.m5.2.2.1.1.1.2.cmml" xref="S2.SS2.p2.5.m5.2.2.1.1.1.2">𝐡</ci><cn type="integer" id="S2.SS2.p2.5.m5.2.2.1.1.1.3.cmml" xref="S2.SS2.p2.5.m5.2.2.1.1.1.3">0</cn></apply><ci id="S2.SS2.p2.5.m5.1.1.cmml" xref="S2.SS2.p2.5.m5.1.1">…</ci><apply id="S2.SS2.p2.5.m5.3.3.2.2.2.cmml" xref="S2.SS2.p2.5.m5.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.5.m5.3.3.2.2.2.1.cmml" xref="S2.SS2.p2.5.m5.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.p2.5.m5.3.3.2.2.2.2.cmml" xref="S2.SS2.p2.5.m5.3.3.2.2.2.2">𝐡</ci><ci id="S2.SS2.p2.5.m5.3.3.2.2.2.3.cmml" xref="S2.SS2.p2.5.m5.3.3.2.2.2.3">𝑇</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.5.m5.3c">\mathbf{H}\in\mathbb{R}^{T\times D^{\prime}}=\{\mathbf{h}_{0},\ldots,\mathbf{h}_{T}\}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.9" class="ltx_p">In particular, SummaryMixing summarises a whole utterance in a single vector with a linear-time complexity summary function. This single vector is then passed back to every time step of the sequence. First, the input <math id="S2.SS2.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{x}_{t}" display="inline"><semantics id="S2.SS2.p3.1.m1.1a"><msub id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml"><mi id="S2.SS2.p3.1.m1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.p3.1.m1.1.1.3" xref="S2.SS2.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.1.m1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p3.1.m1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.2">𝐱</ci><ci id="S2.SS2.p3.1.m1.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">\mathbf{x}_{t}</annotation></semantics></math> is transformed by two non-linear functions e.g. two dense layers with activation functions. One is the local transformation function <math id="S2.SS2.p3.2.m2.1" class="ltx_Math" alttext="f:\mathbb{R}^{D}\rightarrow\mathbb{R}^{D^{\prime\prime}}" display="inline"><semantics id="S2.SS2.p3.2.m2.1a"><mrow id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml"><mi id="S2.SS2.p3.2.m2.1.1.2" xref="S2.SS2.p3.2.m2.1.1.2.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.p3.2.m2.1.1.1" xref="S2.SS2.p3.2.m2.1.1.1.cmml">:</mo><mrow id="S2.SS2.p3.2.m2.1.1.3" xref="S2.SS2.p3.2.m2.1.1.3.cmml"><msup id="S2.SS2.p3.2.m2.1.1.3.2" xref="S2.SS2.p3.2.m2.1.1.3.2.cmml"><mi id="S2.SS2.p3.2.m2.1.1.3.2.2" xref="S2.SS2.p3.2.m2.1.1.3.2.2.cmml">ℝ</mi><mi id="S2.SS2.p3.2.m2.1.1.3.2.3" xref="S2.SS2.p3.2.m2.1.1.3.2.3.cmml">D</mi></msup><mo stretchy="false" id="S2.SS2.p3.2.m2.1.1.3.1" xref="S2.SS2.p3.2.m2.1.1.3.1.cmml">→</mo><msup id="S2.SS2.p3.2.m2.1.1.3.3" xref="S2.SS2.p3.2.m2.1.1.3.3.cmml"><mi id="S2.SS2.p3.2.m2.1.1.3.3.2" xref="S2.SS2.p3.2.m2.1.1.3.3.2.cmml">ℝ</mi><msup id="S2.SS2.p3.2.m2.1.1.3.3.3" xref="S2.SS2.p3.2.m2.1.1.3.3.3.cmml"><mi id="S2.SS2.p3.2.m2.1.1.3.3.3.2" xref="S2.SS2.p3.2.m2.1.1.3.3.3.2.cmml">D</mi><mo id="S2.SS2.p3.2.m2.1.1.3.3.3.3" xref="S2.SS2.p3.2.m2.1.1.3.3.3.3.cmml">′′</mo></msup></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><apply id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1"><ci id="S2.SS2.p3.2.m2.1.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1.1">:</ci><ci id="S2.SS2.p3.2.m2.1.1.2.cmml" xref="S2.SS2.p3.2.m2.1.1.2">𝑓</ci><apply id="S2.SS2.p3.2.m2.1.1.3.cmml" xref="S2.SS2.p3.2.m2.1.1.3"><ci id="S2.SS2.p3.2.m2.1.1.3.1.cmml" xref="S2.SS2.p3.2.m2.1.1.3.1">→</ci><apply id="S2.SS2.p3.2.m2.1.1.3.2.cmml" xref="S2.SS2.p3.2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS2.p3.2.m2.1.1.3.2.1.cmml" xref="S2.SS2.p3.2.m2.1.1.3.2">superscript</csymbol><ci id="S2.SS2.p3.2.m2.1.1.3.2.2.cmml" xref="S2.SS2.p3.2.m2.1.1.3.2.2">ℝ</ci><ci id="S2.SS2.p3.2.m2.1.1.3.2.3.cmml" xref="S2.SS2.p3.2.m2.1.1.3.2.3">𝐷</ci></apply><apply id="S2.SS2.p3.2.m2.1.1.3.3.cmml" xref="S2.SS2.p3.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.2.m2.1.1.3.3.1.cmml" xref="S2.SS2.p3.2.m2.1.1.3.3">superscript</csymbol><ci id="S2.SS2.p3.2.m2.1.1.3.3.2.cmml" xref="S2.SS2.p3.2.m2.1.1.3.3.2">ℝ</ci><apply id="S2.SS2.p3.2.m2.1.1.3.3.3.cmml" xref="S2.SS2.p3.2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.2.m2.1.1.3.3.3.1.cmml" xref="S2.SS2.p3.2.m2.1.1.3.3.3">superscript</csymbol><ci id="S2.SS2.p3.2.m2.1.1.3.3.3.2.cmml" xref="S2.SS2.p3.2.m2.1.1.3.3.3.2">𝐷</ci><ci id="S2.SS2.p3.2.m2.1.1.3.3.3.3.cmml" xref="S2.SS2.p3.2.m2.1.1.3.3.3.3">′′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">f:\mathbb{R}^{D}\rightarrow\mathbb{R}^{D^{\prime\prime}}</annotation></semantics></math> while the second is the summary function <math id="S2.SS2.p3.3.m3.1" class="ltx_Math" alttext="s:\mathbb{R}^{D}\rightarrow\mathbb{R}^{D^{\prime\prime\prime}}" display="inline"><semantics id="S2.SS2.p3.3.m3.1a"><mrow id="S2.SS2.p3.3.m3.1.1" xref="S2.SS2.p3.3.m3.1.1.cmml"><mi id="S2.SS2.p3.3.m3.1.1.2" xref="S2.SS2.p3.3.m3.1.1.2.cmml">s</mi><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.p3.3.m3.1.1.1" xref="S2.SS2.p3.3.m3.1.1.1.cmml">:</mo><mrow id="S2.SS2.p3.3.m3.1.1.3" xref="S2.SS2.p3.3.m3.1.1.3.cmml"><msup id="S2.SS2.p3.3.m3.1.1.3.2" xref="S2.SS2.p3.3.m3.1.1.3.2.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.2.2" xref="S2.SS2.p3.3.m3.1.1.3.2.2.cmml">ℝ</mi><mi id="S2.SS2.p3.3.m3.1.1.3.2.3" xref="S2.SS2.p3.3.m3.1.1.3.2.3.cmml">D</mi></msup><mo stretchy="false" id="S2.SS2.p3.3.m3.1.1.3.1" xref="S2.SS2.p3.3.m3.1.1.3.1.cmml">→</mo><msup id="S2.SS2.p3.3.m3.1.1.3.3" xref="S2.SS2.p3.3.m3.1.1.3.3.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.3.2" xref="S2.SS2.p3.3.m3.1.1.3.3.2.cmml">ℝ</mi><msup id="S2.SS2.p3.3.m3.1.1.3.3.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.cmml"><mi id="S2.SS2.p3.3.m3.1.1.3.3.3.2" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2.cmml">D</mi><mo id="S2.SS2.p3.3.m3.1.1.3.3.3.3" xref="S2.SS2.p3.3.m3.1.1.3.3.3.3.cmml">′′′</mo></msup></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.1b"><apply id="S2.SS2.p3.3.m3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1"><ci id="S2.SS2.p3.3.m3.1.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1.1">:</ci><ci id="S2.SS2.p3.3.m3.1.1.2.cmml" xref="S2.SS2.p3.3.m3.1.1.2">𝑠</ci><apply id="S2.SS2.p3.3.m3.1.1.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3"><ci id="S2.SS2.p3.3.m3.1.1.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.1">→</ci><apply id="S2.SS2.p3.3.m3.1.1.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.2.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2">superscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.3.2.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2.2">ℝ</ci><ci id="S2.SS2.p3.3.m3.1.1.3.2.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.2.3">𝐷</ci></apply><apply id="S2.SS2.p3.3.m3.1.1.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3">superscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.3.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.2">ℝ</ci><apply id="S2.SS2.p3.3.m3.1.1.3.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.3.3.3.1.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3">superscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.2.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.2">𝐷</ci><ci id="S2.SS2.p3.3.m3.1.1.3.3.3.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3.3.3.3">′′′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.1c">s:\mathbb{R}^{D}\rightarrow\mathbb{R}^{D^{\prime\prime\prime}}</annotation></semantics></math>. The output of the latter function is then averaged over time (<math id="S2.SS2.p3.4.m4.1" class="ltx_Math" alttext="\frac{1}{T}\!\sum" display="inline"><semantics id="S2.SS2.p3.4.m4.1a"><mrow id="S2.SS2.p3.4.m4.1.1" xref="S2.SS2.p3.4.m4.1.1.cmml"><mfrac id="S2.SS2.p3.4.m4.1.1.2" xref="S2.SS2.p3.4.m4.1.1.2.cmml"><mn id="S2.SS2.p3.4.m4.1.1.2.2" xref="S2.SS2.p3.4.m4.1.1.2.2.cmml">1</mn><mi id="S2.SS2.p3.4.m4.1.1.2.3" xref="S2.SS2.p3.4.m4.1.1.2.3.cmml">T</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS2.p3.4.m4.1.1.1" xref="S2.SS2.p3.4.m4.1.1.1.cmml">​</mo><mo id="S2.SS2.p3.4.m4.1.1.3" xref="S2.SS2.p3.4.m4.1.1.3.cmml">∑</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m4.1b"><apply id="S2.SS2.p3.4.m4.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1"><times id="S2.SS2.p3.4.m4.1.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1.1"></times><apply id="S2.SS2.p3.4.m4.1.1.2.cmml" xref="S2.SS2.p3.4.m4.1.1.2"><divide id="S2.SS2.p3.4.m4.1.1.2.1.cmml" xref="S2.SS2.p3.4.m4.1.1.2"></divide><cn type="integer" id="S2.SS2.p3.4.m4.1.1.2.2.cmml" xref="S2.SS2.p3.4.m4.1.1.2.2">1</cn><ci id="S2.SS2.p3.4.m4.1.1.2.3.cmml" xref="S2.SS2.p3.4.m4.1.1.2.3">𝑇</ci></apply><sum id="S2.SS2.p3.4.m4.1.1.3.cmml" xref="S2.SS2.p3.4.m4.1.1.3"></sum></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m4.1c">\frac{1}{T}\!\sum</annotation></semantics></math>) to obtain the mean vector <math id="S2.SS2.p3.5.m5.1" class="ltx_Math" alttext="\bar{\mathbf{s}}" display="inline"><semantics id="S2.SS2.p3.5.m5.1a"><mover accent="true" id="S2.SS2.p3.5.m5.1.1" xref="S2.SS2.p3.5.m5.1.1.cmml"><mi id="S2.SS2.p3.5.m5.1.1.2" xref="S2.SS2.p3.5.m5.1.1.2.cmml">𝐬</mi><mo id="S2.SS2.p3.5.m5.1.1.1" xref="S2.SS2.p3.5.m5.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.5.m5.1b"><apply id="S2.SS2.p3.5.m5.1.1.cmml" xref="S2.SS2.p3.5.m5.1.1"><ci id="S2.SS2.p3.5.m5.1.1.1.cmml" xref="S2.SS2.p3.5.m5.1.1.1">¯</ci><ci id="S2.SS2.p3.5.m5.1.1.2.cmml" xref="S2.SS2.p3.5.m5.1.1.2">𝐬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.5.m5.1c">\bar{\mathbf{s}}</annotation></semantics></math>. This single vector is concatenated back to each time step of the output of the local transformation (<math id="S2.SS2.p3.6.m6.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S2.SS2.p3.6.m6.1a"><mi id="S2.SS2.p3.6.m6.1.1" xref="S2.SS2.p3.6.m6.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.6.m6.1b"><ci id="S2.SS2.p3.6.m6.1.1.cmml" xref="S2.SS2.p3.6.m6.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.6.m6.1c">f</annotation></semantics></math>). This concatenation is processed by the non-linear combiner function <math id="S2.SS2.p3.7.m7.1" class="ltx_Math" alttext="c:\mathbb{R}^{D^{\prime\prime}+D^{\prime\prime\prime}}\rightarrow\mathbb{R}^{D^{\prime}}" display="inline"><semantics id="S2.SS2.p3.7.m7.1a"><mrow id="S2.SS2.p3.7.m7.1.1" xref="S2.SS2.p3.7.m7.1.1.cmml"><mi id="S2.SS2.p3.7.m7.1.1.2" xref="S2.SS2.p3.7.m7.1.1.2.cmml">c</mi><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.p3.7.m7.1.1.1" xref="S2.SS2.p3.7.m7.1.1.1.cmml">:</mo><mrow id="S2.SS2.p3.7.m7.1.1.3" xref="S2.SS2.p3.7.m7.1.1.3.cmml"><msup id="S2.SS2.p3.7.m7.1.1.3.2" xref="S2.SS2.p3.7.m7.1.1.3.2.cmml"><mi id="S2.SS2.p3.7.m7.1.1.3.2.2" xref="S2.SS2.p3.7.m7.1.1.3.2.2.cmml">ℝ</mi><mrow id="S2.SS2.p3.7.m7.1.1.3.2.3" xref="S2.SS2.p3.7.m7.1.1.3.2.3.cmml"><msup id="S2.SS2.p3.7.m7.1.1.3.2.3.2" xref="S2.SS2.p3.7.m7.1.1.3.2.3.2.cmml"><mi id="S2.SS2.p3.7.m7.1.1.3.2.3.2.2" xref="S2.SS2.p3.7.m7.1.1.3.2.3.2.2.cmml">D</mi><mo id="S2.SS2.p3.7.m7.1.1.3.2.3.2.3" xref="S2.SS2.p3.7.m7.1.1.3.2.3.2.3.cmml">′′</mo></msup><mo id="S2.SS2.p3.7.m7.1.1.3.2.3.1" xref="S2.SS2.p3.7.m7.1.1.3.2.3.1.cmml">+</mo><msup id="S2.SS2.p3.7.m7.1.1.3.2.3.3" xref="S2.SS2.p3.7.m7.1.1.3.2.3.3.cmml"><mi id="S2.SS2.p3.7.m7.1.1.3.2.3.3.2" xref="S2.SS2.p3.7.m7.1.1.3.2.3.3.2.cmml">D</mi><mo id="S2.SS2.p3.7.m7.1.1.3.2.3.3.3" xref="S2.SS2.p3.7.m7.1.1.3.2.3.3.3.cmml">′′′</mo></msup></mrow></msup><mo stretchy="false" id="S2.SS2.p3.7.m7.1.1.3.1" xref="S2.SS2.p3.7.m7.1.1.3.1.cmml">→</mo><msup id="S2.SS2.p3.7.m7.1.1.3.3" xref="S2.SS2.p3.7.m7.1.1.3.3.cmml"><mi id="S2.SS2.p3.7.m7.1.1.3.3.2" xref="S2.SS2.p3.7.m7.1.1.3.3.2.cmml">ℝ</mi><msup id="S2.SS2.p3.7.m7.1.1.3.3.3" xref="S2.SS2.p3.7.m7.1.1.3.3.3.cmml"><mi id="S2.SS2.p3.7.m7.1.1.3.3.3.2" xref="S2.SS2.p3.7.m7.1.1.3.3.3.2.cmml">D</mi><mo id="S2.SS2.p3.7.m7.1.1.3.3.3.3" xref="S2.SS2.p3.7.m7.1.1.3.3.3.3.cmml">′</mo></msup></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.7.m7.1b"><apply id="S2.SS2.p3.7.m7.1.1.cmml" xref="S2.SS2.p3.7.m7.1.1"><ci id="S2.SS2.p3.7.m7.1.1.1.cmml" xref="S2.SS2.p3.7.m7.1.1.1">:</ci><ci id="S2.SS2.p3.7.m7.1.1.2.cmml" xref="S2.SS2.p3.7.m7.1.1.2">𝑐</ci><apply id="S2.SS2.p3.7.m7.1.1.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3"><ci id="S2.SS2.p3.7.m7.1.1.3.1.cmml" xref="S2.SS2.p3.7.m7.1.1.3.1">→</ci><apply id="S2.SS2.p3.7.m7.1.1.3.2.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m7.1.1.3.2.1.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2">superscript</csymbol><ci id="S2.SS2.p3.7.m7.1.1.3.2.2.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.2">ℝ</ci><apply id="S2.SS2.p3.7.m7.1.1.3.2.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3"><plus id="S2.SS2.p3.7.m7.1.1.3.2.3.1.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.1"></plus><apply id="S2.SS2.p3.7.m7.1.1.3.2.3.2.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m7.1.1.3.2.3.2.1.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.2">superscript</csymbol><ci id="S2.SS2.p3.7.m7.1.1.3.2.3.2.2.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.2.2">𝐷</ci><ci id="S2.SS2.p3.7.m7.1.1.3.2.3.2.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.2.3">′′</ci></apply><apply id="S2.SS2.p3.7.m7.1.1.3.2.3.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m7.1.1.3.2.3.3.1.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.3">superscript</csymbol><ci id="S2.SS2.p3.7.m7.1.1.3.2.3.3.2.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.3.2">𝐷</ci><ci id="S2.SS2.p3.7.m7.1.1.3.2.3.3.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3.2.3.3.3">′′′</ci></apply></apply></apply><apply id="S2.SS2.p3.7.m7.1.1.3.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m7.1.1.3.3.1.cmml" xref="S2.SS2.p3.7.m7.1.1.3.3">superscript</csymbol><ci id="S2.SS2.p3.7.m7.1.1.3.3.2.cmml" xref="S2.SS2.p3.7.m7.1.1.3.3.2">ℝ</ci><apply id="S2.SS2.p3.7.m7.1.1.3.3.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p3.7.m7.1.1.3.3.3.1.cmml" xref="S2.SS2.p3.7.m7.1.1.3.3.3">superscript</csymbol><ci id="S2.SS2.p3.7.m7.1.1.3.3.3.2.cmml" xref="S2.SS2.p3.7.m7.1.1.3.3.3.2">𝐷</ci><ci id="S2.SS2.p3.7.m7.1.1.3.3.3.3.cmml" xref="S2.SS2.p3.7.m7.1.1.3.3.3.3">′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.7.m7.1c">c:\mathbb{R}^{D^{\prime\prime}+D^{\prime\prime\prime}}\rightarrow\mathbb{R}^{D^{\prime}}</annotation></semantics></math>. Computing the mean from <math id="S2.SS2.p3.8.m8.1" class="ltx_Math" alttext="\bar{\mathbf{s}}" display="inline"><semantics id="S2.SS2.p3.8.m8.1a"><mover accent="true" id="S2.SS2.p3.8.m8.1.1" xref="S2.SS2.p3.8.m8.1.1.cmml"><mi id="S2.SS2.p3.8.m8.1.1.2" xref="S2.SS2.p3.8.m8.1.1.2.cmml">𝐬</mi><mo id="S2.SS2.p3.8.m8.1.1.1" xref="S2.SS2.p3.8.m8.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.8.m8.1b"><apply id="S2.SS2.p3.8.m8.1.1.cmml" xref="S2.SS2.p3.8.m8.1.1"><ci id="S2.SS2.p3.8.m8.1.1.1.cmml" xref="S2.SS2.p3.8.m8.1.1.1">¯</ci><ci id="S2.SS2.p3.8.m8.1.1.2.cmml" xref="S2.SS2.p3.8.m8.1.1.2">𝐬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.8.m8.1c">\bar{\mathbf{s}}</annotation></semantics></math> takes <math id="S2.SS2.p3.9.m9.1" class="ltx_Math" alttext="\mathcal{O}(T)" display="inline"><semantics id="S2.SS2.p3.9.m9.1a"><mrow id="S2.SS2.p3.9.m9.1.2" xref="S2.SS2.p3.9.m9.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p3.9.m9.1.2.2" xref="S2.SS2.p3.9.m9.1.2.2.cmml">𝒪</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p3.9.m9.1.2.1" xref="S2.SS2.p3.9.m9.1.2.1.cmml">​</mo><mrow id="S2.SS2.p3.9.m9.1.2.3.2" xref="S2.SS2.p3.9.m9.1.2.cmml"><mo stretchy="false" id="S2.SS2.p3.9.m9.1.2.3.2.1" xref="S2.SS2.p3.9.m9.1.2.cmml">(</mo><mi id="S2.SS2.p3.9.m9.1.1" xref="S2.SS2.p3.9.m9.1.1.cmml">T</mi><mo stretchy="false" id="S2.SS2.p3.9.m9.1.2.3.2.2" xref="S2.SS2.p3.9.m9.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.9.m9.1b"><apply id="S2.SS2.p3.9.m9.1.2.cmml" xref="S2.SS2.p3.9.m9.1.2"><times id="S2.SS2.p3.9.m9.1.2.1.cmml" xref="S2.SS2.p3.9.m9.1.2.1"></times><ci id="S2.SS2.p3.9.m9.1.2.2.cmml" xref="S2.SS2.p3.9.m9.1.2.2">𝒪</ci><ci id="S2.SS2.p3.9.m9.1.1.cmml" xref="S2.SS2.p3.9.m9.1.1">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.9.m9.1c">\mathcal{O}(T)</annotation></semantics></math> time, compared to the usual quadratic cost of MHSA. SummaryMixing can be formally summarised as:</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<table id="S4.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E4.m1.1" class="ltx_Math" alttext="\displaystyle\bar{\mathbf{s}}" display="inline"><semantics id="S2.E4.m1.1a"><mover accent="true" id="S2.E4.m1.1.1" xref="S2.E4.m1.1.1.cmml"><mi id="S2.E4.m1.1.1.2" xref="S2.E4.m1.1.1.2.cmml">𝐬</mi><mo id="S2.E4.m1.1.1.1" xref="S2.E4.m1.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S2.E4.m1.1b"><apply id="S2.E4.m1.1.1.cmml" xref="S2.E4.m1.1.1"><ci id="S2.E4.m1.1.1.1.cmml" xref="S2.E4.m1.1.1.1">¯</ci><ci id="S2.E4.m1.1.1.2.cmml" xref="S2.E4.m1.1.1.2">𝐬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.1c">\displaystyle\bar{\mathbf{s}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E4.m2.1" class="ltx_Math" alttext="\displaystyle=\frac{1}{T}\sum_{t=1}^{T}s(\mathbf{x}_{t});" display="inline"><semantics id="S2.E4.m2.1a"><mrow id="S2.E4.m2.1.1.1" xref="S2.E4.m2.1.1.1.1.cmml"><mrow id="S2.E4.m2.1.1.1.1" xref="S2.E4.m2.1.1.1.1.cmml"><mi id="S2.E4.m2.1.1.1.1.3" xref="S2.E4.m2.1.1.1.1.3.cmml"></mi><mo id="S2.E4.m2.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.2.cmml">=</mo><mrow id="S2.E4.m2.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E4.m2.1.1.1.1.1.3" xref="S2.E4.m2.1.1.1.1.1.3.cmml"><mfrac id="S2.E4.m2.1.1.1.1.1.3a" xref="S2.E4.m2.1.1.1.1.1.3.cmml"><mn id="S2.E4.m2.1.1.1.1.1.3.2" xref="S2.E4.m2.1.1.1.1.1.3.2.cmml">1</mn><mi id="S2.E4.m2.1.1.1.1.1.3.3" xref="S2.E4.m2.1.1.1.1.1.3.3.cmml">T</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S2.E4.m2.1.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E4.m2.1.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E4.m2.1.1.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.1.1.2.cmml"><munderover id="S2.E4.m2.1.1.1.1.1.1.2a" xref="S2.E4.m2.1.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.E4.m2.1.1.1.1.1.1.2.2.2" xref="S2.E4.m2.1.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S2.E4.m2.1.1.1.1.1.1.2.2.3" xref="S2.E4.m2.1.1.1.1.1.1.2.2.3.cmml"><mi id="S2.E4.m2.1.1.1.1.1.1.2.2.3.2" xref="S2.E4.m2.1.1.1.1.1.1.2.2.3.2.cmml">t</mi><mo id="S2.E4.m2.1.1.1.1.1.1.2.2.3.1" xref="S2.E4.m2.1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.E4.m2.1.1.1.1.1.1.2.2.3.3" xref="S2.E4.m2.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E4.m2.1.1.1.1.1.1.2.3" xref="S2.E4.m2.1.1.1.1.1.1.2.3.cmml">T</mi></munderover></mstyle><mrow id="S2.E4.m2.1.1.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m2.1.1.1.1.1.1.1.3" xref="S2.E4.m2.1.1.1.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E4.m2.1.1.1.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E4.m2.1.1.1.1.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E4.m2.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E4.m2.1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.E4.m2.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S2.E4.m2.1.1.1.2" xref="S2.E4.m2.1.1.1.1.cmml">;</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m2.1b"><apply id="S2.E4.m2.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1"><eq id="S2.E4.m2.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.2"></eq><csymbol cd="latexml" id="S2.E4.m2.1.1.1.1.3.cmml" xref="S2.E4.m2.1.1.1.1.3">absent</csymbol><apply id="S2.E4.m2.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1"><times id="S2.E4.m2.1.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.1.2"></times><apply id="S2.E4.m2.1.1.1.1.1.3.cmml" xref="S2.E4.m2.1.1.1.1.1.3"><divide id="S2.E4.m2.1.1.1.1.1.3.1.cmml" xref="S2.E4.m2.1.1.1.1.1.3"></divide><cn type="integer" id="S2.E4.m2.1.1.1.1.1.3.2.cmml" xref="S2.E4.m2.1.1.1.1.1.3.2">1</cn><ci id="S2.E4.m2.1.1.1.1.1.3.3.cmml" xref="S2.E4.m2.1.1.1.1.1.3.3">𝑇</ci></apply><apply id="S2.E4.m2.1.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1"><apply id="S2.E4.m2.1.1.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m2.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2">superscript</csymbol><apply id="S2.E4.m2.1.1.1.1.1.1.2.2.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m2.1.1.1.1.1.1.2.2.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E4.m2.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2.2.2"></sum><apply id="S2.E4.m2.1.1.1.1.1.1.2.2.3.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2.2.3"><eq id="S2.E4.m2.1.1.1.1.1.1.2.2.3.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2.2.3.1"></eq><ci id="S2.E4.m2.1.1.1.1.1.1.2.2.3.2.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2.2.3.2">𝑡</ci><cn type="integer" id="S2.E4.m2.1.1.1.1.1.1.2.2.3.3.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E4.m2.1.1.1.1.1.1.2.3.cmml" xref="S2.E4.m2.1.1.1.1.1.1.2.3">𝑇</ci></apply><apply id="S2.E4.m2.1.1.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1"><times id="S2.E4.m2.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.2"></times><ci id="S2.E4.m2.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.3">𝑠</ci><apply id="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m2.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m2.1c">\displaystyle=\frac{1}{T}\sum_{t=1}^{T}s(\mathbf{x}_{t});</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E4.m3.1" class="ltx_Math" alttext="\displaystyle\mathbf{h}_{t}" display="inline"><semantics id="S2.E4.m3.1a"><msub id="S2.E4.m3.1.1" xref="S2.E4.m3.1.1.cmml"><mi id="S2.E4.m3.1.1.2" xref="S2.E4.m3.1.1.2.cmml">𝐡</mi><mi id="S2.E4.m3.1.1.3" xref="S2.E4.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E4.m3.1b"><apply id="S2.E4.m3.1.1.cmml" xref="S2.E4.m3.1.1"><csymbol cd="ambiguous" id="S2.E4.m3.1.1.1.cmml" xref="S2.E4.m3.1.1">subscript</csymbol><ci id="S2.E4.m3.1.1.2.cmml" xref="S2.E4.m3.1.1.2">𝐡</ci><ci id="S2.E4.m3.1.1.3.cmml" xref="S2.E4.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m3.1c">\displaystyle\mathbf{h}_{t}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E4.m4.2" class="ltx_Math" alttext="\displaystyle=c(f(\mathbf{x}_{t}),\bar{\mathbf{s}})." display="inline"><semantics id="S2.E4.m4.2a"><mrow id="S2.E4.m4.2.2.1" xref="S2.E4.m4.2.2.1.1.cmml"><mrow id="S2.E4.m4.2.2.1.1" xref="S2.E4.m4.2.2.1.1.cmml"><mi id="S2.E4.m4.2.2.1.1.3" xref="S2.E4.m4.2.2.1.1.3.cmml"></mi><mo id="S2.E4.m4.2.2.1.1.2" xref="S2.E4.m4.2.2.1.1.2.cmml">=</mo><mrow id="S2.E4.m4.2.2.1.1.1" xref="S2.E4.m4.2.2.1.1.1.cmml"><mi id="S2.E4.m4.2.2.1.1.1.3" xref="S2.E4.m4.2.2.1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E4.m4.2.2.1.1.1.2" xref="S2.E4.m4.2.2.1.1.1.2.cmml">​</mo><mrow id="S2.E4.m4.2.2.1.1.1.1.1" xref="S2.E4.m4.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m4.2.2.1.1.1.1.1.2" xref="S2.E4.m4.2.2.1.1.1.1.2.cmml">(</mo><mrow id="S2.E4.m4.2.2.1.1.1.1.1.1" xref="S2.E4.m4.2.2.1.1.1.1.1.1.cmml"><mi id="S2.E4.m4.2.2.1.1.1.1.1.1.3" xref="S2.E4.m4.2.2.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E4.m4.2.2.1.1.1.1.1.1.2" xref="S2.E4.m4.2.2.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E4.m4.2.2.1.1.1.1.1.3" xref="S2.E4.m4.2.2.1.1.1.1.2.cmml">,</mo><mover accent="true" id="S2.E4.m4.1.1" xref="S2.E4.m4.1.1.cmml"><mi id="S2.E4.m4.1.1.2" xref="S2.E4.m4.1.1.2.cmml">𝐬</mi><mo id="S2.E4.m4.1.1.1" xref="S2.E4.m4.1.1.1.cmml">¯</mo></mover><mo stretchy="false" id="S2.E4.m4.2.2.1.1.1.1.1.4" xref="S2.E4.m4.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E4.m4.2.2.1.2" xref="S2.E4.m4.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m4.2b"><apply id="S2.E4.m4.2.2.1.1.cmml" xref="S2.E4.m4.2.2.1"><eq id="S2.E4.m4.2.2.1.1.2.cmml" xref="S2.E4.m4.2.2.1.1.2"></eq><csymbol cd="latexml" id="S2.E4.m4.2.2.1.1.3.cmml" xref="S2.E4.m4.2.2.1.1.3">absent</csymbol><apply id="S2.E4.m4.2.2.1.1.1.cmml" xref="S2.E4.m4.2.2.1.1.1"><times id="S2.E4.m4.2.2.1.1.1.2.cmml" xref="S2.E4.m4.2.2.1.1.1.2"></times><ci id="S2.E4.m4.2.2.1.1.1.3.cmml" xref="S2.E4.m4.2.2.1.1.1.3">𝑐</ci><interval closure="open" id="S2.E4.m4.2.2.1.1.1.1.2.cmml" xref="S2.E4.m4.2.2.1.1.1.1.1"><apply id="S2.E4.m4.2.2.1.1.1.1.1.1.cmml" xref="S2.E4.m4.2.2.1.1.1.1.1.1"><times id="S2.E4.m4.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E4.m4.2.2.1.1.1.1.1.1.2"></times><ci id="S2.E4.m4.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E4.m4.2.2.1.1.1.1.1.1.3">𝑓</ci><apply id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m4.2.2.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply><apply id="S2.E4.m4.1.1.cmml" xref="S2.E4.m4.1.1"><ci id="S2.E4.m4.1.1.1.cmml" xref="S2.E4.m4.1.1.1">¯</ci><ci id="S2.E4.m4.1.1.2.cmml" xref="S2.E4.m4.1.1.2">𝐬</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m4.2c">\displaystyle=c(f(\mathbf{x}_{t}),\bar{\mathbf{s}}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.3" class="ltx_p">Extending SummaryMixing from (<a href="#S2.E4" title="In II-B Streaming SummaryMixing ‣ II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) to streaming ASR means that the whole sentence will not be summarised into a single vector anymore.
Instead, as Figure <a href="#S2.F1" title="Figure 1 ‣ II-B Streaming SummaryMixing ‣ II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates, the average should be computed over only the frames that are visible to the model.
The summary vector, written <math id="S2.SS2.p5.1.m1.1" class="ltx_Math" alttext="\bar{\mathbf{s}}_{t}" display="inline"><semantics id="S2.SS2.p5.1.m1.1a"><msub id="S2.SS2.p5.1.m1.1.1" xref="S2.SS2.p5.1.m1.1.1.cmml"><mover accent="true" id="S2.SS2.p5.1.m1.1.1.2" xref="S2.SS2.p5.1.m1.1.1.2.cmml"><mi id="S2.SS2.p5.1.m1.1.1.2.2" xref="S2.SS2.p5.1.m1.1.1.2.2.cmml">𝐬</mi><mo id="S2.SS2.p5.1.m1.1.1.2.1" xref="S2.SS2.p5.1.m1.1.1.2.1.cmml">¯</mo></mover><mi id="S2.SS2.p5.1.m1.1.1.3" xref="S2.SS2.p5.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.1.m1.1b"><apply id="S2.SS2.p5.1.m1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p5.1.m1.1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1">subscript</csymbol><apply id="S2.SS2.p5.1.m1.1.1.2.cmml" xref="S2.SS2.p5.1.m1.1.1.2"><ci id="S2.SS2.p5.1.m1.1.1.2.1.cmml" xref="S2.SS2.p5.1.m1.1.1.2.1">¯</ci><ci id="S2.SS2.p5.1.m1.1.1.2.2.cmml" xref="S2.SS2.p5.1.m1.1.1.2.2">𝐬</ci></apply><ci id="S2.SS2.p5.1.m1.1.1.3.cmml" xref="S2.SS2.p5.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.1.m1.1c">\bar{\mathbf{s}}_{t}</annotation></semantics></math>, is specific to the time step.
The number of visible frames at time <math id="S2.SS2.p5.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS2.p5.2.m2.1a"><mi id="S2.SS2.p5.2.m2.1.1" xref="S2.SS2.p5.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.2.m2.1b"><ci id="S2.SS2.p5.2.m2.1.1.cmml" xref="S2.SS2.p5.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.2.m2.1c">t</annotation></semantics></math> can be computed as <math id="S2.SS2.p5.3.m3.2" class="ltx_Math" alttext="\bar{T}_{t}=\sum_{u=1}^{T}m_{t,u}" display="inline"><semantics id="S2.SS2.p5.3.m3.2a"><mrow id="S2.SS2.p5.3.m3.2.3" xref="S2.SS2.p5.3.m3.2.3.cmml"><msub id="S2.SS2.p5.3.m3.2.3.2" xref="S2.SS2.p5.3.m3.2.3.2.cmml"><mover accent="true" id="S2.SS2.p5.3.m3.2.3.2.2" xref="S2.SS2.p5.3.m3.2.3.2.2.cmml"><mi id="S2.SS2.p5.3.m3.2.3.2.2.2" xref="S2.SS2.p5.3.m3.2.3.2.2.2.cmml">T</mi><mo id="S2.SS2.p5.3.m3.2.3.2.2.1" xref="S2.SS2.p5.3.m3.2.3.2.2.1.cmml">¯</mo></mover><mi id="S2.SS2.p5.3.m3.2.3.2.3" xref="S2.SS2.p5.3.m3.2.3.2.3.cmml">t</mi></msub><mo rspace="0.111em" id="S2.SS2.p5.3.m3.2.3.1" xref="S2.SS2.p5.3.m3.2.3.1.cmml">=</mo><mrow id="S2.SS2.p5.3.m3.2.3.3" xref="S2.SS2.p5.3.m3.2.3.3.cmml"><msubsup id="S2.SS2.p5.3.m3.2.3.3.1" xref="S2.SS2.p5.3.m3.2.3.3.1.cmml"><mo id="S2.SS2.p5.3.m3.2.3.3.1.2.2" xref="S2.SS2.p5.3.m3.2.3.3.1.2.2.cmml">∑</mo><mrow id="S2.SS2.p5.3.m3.2.3.3.1.2.3" xref="S2.SS2.p5.3.m3.2.3.3.1.2.3.cmml"><mi id="S2.SS2.p5.3.m3.2.3.3.1.2.3.2" xref="S2.SS2.p5.3.m3.2.3.3.1.2.3.2.cmml">u</mi><mo id="S2.SS2.p5.3.m3.2.3.3.1.2.3.1" xref="S2.SS2.p5.3.m3.2.3.3.1.2.3.1.cmml">=</mo><mn id="S2.SS2.p5.3.m3.2.3.3.1.2.3.3" xref="S2.SS2.p5.3.m3.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p5.3.m3.2.3.3.1.3" xref="S2.SS2.p5.3.m3.2.3.3.1.3.cmml">T</mi></msubsup><msub id="S2.SS2.p5.3.m3.2.3.3.2" xref="S2.SS2.p5.3.m3.2.3.3.2.cmml"><mi id="S2.SS2.p5.3.m3.2.3.3.2.2" xref="S2.SS2.p5.3.m3.2.3.3.2.2.cmml">m</mi><mrow id="S2.SS2.p5.3.m3.2.2.2.4" xref="S2.SS2.p5.3.m3.2.2.2.3.cmml"><mi id="S2.SS2.p5.3.m3.1.1.1.1" xref="S2.SS2.p5.3.m3.1.1.1.1.cmml">t</mi><mo id="S2.SS2.p5.3.m3.2.2.2.4.1" xref="S2.SS2.p5.3.m3.2.2.2.3.cmml">,</mo><mi id="S2.SS2.p5.3.m3.2.2.2.2" xref="S2.SS2.p5.3.m3.2.2.2.2.cmml">u</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.3.m3.2b"><apply id="S2.SS2.p5.3.m3.2.3.cmml" xref="S2.SS2.p5.3.m3.2.3"><eq id="S2.SS2.p5.3.m3.2.3.1.cmml" xref="S2.SS2.p5.3.m3.2.3.1"></eq><apply id="S2.SS2.p5.3.m3.2.3.2.cmml" xref="S2.SS2.p5.3.m3.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.p5.3.m3.2.3.2.1.cmml" xref="S2.SS2.p5.3.m3.2.3.2">subscript</csymbol><apply id="S2.SS2.p5.3.m3.2.3.2.2.cmml" xref="S2.SS2.p5.3.m3.2.3.2.2"><ci id="S2.SS2.p5.3.m3.2.3.2.2.1.cmml" xref="S2.SS2.p5.3.m3.2.3.2.2.1">¯</ci><ci id="S2.SS2.p5.3.m3.2.3.2.2.2.cmml" xref="S2.SS2.p5.3.m3.2.3.2.2.2">𝑇</ci></apply><ci id="S2.SS2.p5.3.m3.2.3.2.3.cmml" xref="S2.SS2.p5.3.m3.2.3.2.3">𝑡</ci></apply><apply id="S2.SS2.p5.3.m3.2.3.3.cmml" xref="S2.SS2.p5.3.m3.2.3.3"><apply id="S2.SS2.p5.3.m3.2.3.3.1.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p5.3.m3.2.3.3.1.1.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1">superscript</csymbol><apply id="S2.SS2.p5.3.m3.2.3.3.1.2.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p5.3.m3.2.3.3.1.2.1.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1">subscript</csymbol><sum id="S2.SS2.p5.3.m3.2.3.3.1.2.2.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1.2.2"></sum><apply id="S2.SS2.p5.3.m3.2.3.3.1.2.3.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1.2.3"><eq id="S2.SS2.p5.3.m3.2.3.3.1.2.3.1.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1.2.3.1"></eq><ci id="S2.SS2.p5.3.m3.2.3.3.1.2.3.2.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1.2.3.2">𝑢</ci><cn type="integer" id="S2.SS2.p5.3.m3.2.3.3.1.2.3.3.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS2.p5.3.m3.2.3.3.1.3.cmml" xref="S2.SS2.p5.3.m3.2.3.3.1.3">𝑇</ci></apply><apply id="S2.SS2.p5.3.m3.2.3.3.2.cmml" xref="S2.SS2.p5.3.m3.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS2.p5.3.m3.2.3.3.2.1.cmml" xref="S2.SS2.p5.3.m3.2.3.3.2">subscript</csymbol><ci id="S2.SS2.p5.3.m3.2.3.3.2.2.cmml" xref="S2.SS2.p5.3.m3.2.3.3.2.2">𝑚</ci><list id="S2.SS2.p5.3.m3.2.2.2.3.cmml" xref="S2.SS2.p5.3.m3.2.2.2.4"><ci id="S2.SS2.p5.3.m3.1.1.1.1.cmml" xref="S2.SS2.p5.3.m3.1.1.1.1">𝑡</ci><ci id="S2.SS2.p5.3.m3.2.2.2.2.cmml" xref="S2.SS2.p5.3.m3.2.2.2.2">𝑢</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.3.m3.2c">\bar{T}_{t}=\sum_{u=1}^{T}m_{t,u}</annotation></semantics></math>.
Streaming SummaryMixing can then be described by changing (<a href="#S2.E4" title="In II-B Streaming SummaryMixing ‣ II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) to:</p>
<table id="S4.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E5.m1.1" class="ltx_Math" alttext="\displaystyle\bar{\mathbf{s}}_{t}" display="inline"><semantics id="S2.E5.m1.1a"><msub id="S2.E5.m1.1.1" xref="S2.E5.m1.1.1.cmml"><mover accent="true" id="S2.E5.m1.1.1.2" xref="S2.E5.m1.1.1.2.cmml"><mi id="S2.E5.m1.1.1.2.2" xref="S2.E5.m1.1.1.2.2.cmml">𝐬</mi><mo id="S2.E5.m1.1.1.2.1" xref="S2.E5.m1.1.1.2.1.cmml">¯</mo></mover><mi id="S2.E5.m1.1.1.3" xref="S2.E5.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E5.m1.1b"><apply id="S2.E5.m1.1.1.cmml" xref="S2.E5.m1.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.cmml" xref="S2.E5.m1.1.1">subscript</csymbol><apply id="S2.E5.m1.1.1.2.cmml" xref="S2.E5.m1.1.1.2"><ci id="S2.E5.m1.1.1.2.1.cmml" xref="S2.E5.m1.1.1.2.1">¯</ci><ci id="S2.E5.m1.1.1.2.2.cmml" xref="S2.E5.m1.1.1.2.2">𝐬</ci></apply><ci id="S2.E5.m1.1.1.3.cmml" xref="S2.E5.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.1c">\displaystyle\bar{\mathbf{s}}_{t}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E5.m2.3" class="ltx_Math" alttext="\displaystyle=\frac{1}{\bar{T}_{t}}\sum_{u=1}^{T}m_{t,u}\cdot s(\mathbf{x}_{u});" display="inline"><semantics id="S2.E5.m2.3a"><mrow id="S2.E5.m2.3.3.1" xref="S2.E5.m2.3.3.1.1.cmml"><mrow id="S2.E5.m2.3.3.1.1" xref="S2.E5.m2.3.3.1.1.cmml"><mi id="S2.E5.m2.3.3.1.1.3" xref="S2.E5.m2.3.3.1.1.3.cmml"></mi><mo id="S2.E5.m2.3.3.1.1.2" xref="S2.E5.m2.3.3.1.1.2.cmml">=</mo><mrow id="S2.E5.m2.3.3.1.1.1" xref="S2.E5.m2.3.3.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E5.m2.3.3.1.1.1.3" xref="S2.E5.m2.3.3.1.1.1.3.cmml"><mfrac id="S2.E5.m2.3.3.1.1.1.3a" xref="S2.E5.m2.3.3.1.1.1.3.cmml"><mn id="S2.E5.m2.3.3.1.1.1.3.2" xref="S2.E5.m2.3.3.1.1.1.3.2.cmml">1</mn><msub id="S2.E5.m2.3.3.1.1.1.3.3" xref="S2.E5.m2.3.3.1.1.1.3.3.cmml"><mover accent="true" id="S2.E5.m2.3.3.1.1.1.3.3.2" xref="S2.E5.m2.3.3.1.1.1.3.3.2.cmml"><mi id="S2.E5.m2.3.3.1.1.1.3.3.2.2" xref="S2.E5.m2.3.3.1.1.1.3.3.2.2.cmml">T</mi><mo id="S2.E5.m2.3.3.1.1.1.3.3.2.1" xref="S2.E5.m2.3.3.1.1.1.3.3.2.1.cmml">¯</mo></mover><mi id="S2.E5.m2.3.3.1.1.1.3.3.3" xref="S2.E5.m2.3.3.1.1.1.3.3.3.cmml">t</mi></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S2.E5.m2.3.3.1.1.1.2" xref="S2.E5.m2.3.3.1.1.1.2.cmml">​</mo><mrow id="S2.E5.m2.3.3.1.1.1.1" xref="S2.E5.m2.3.3.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E5.m2.3.3.1.1.1.1.2" xref="S2.E5.m2.3.3.1.1.1.1.2.cmml"><munderover id="S2.E5.m2.3.3.1.1.1.1.2a" xref="S2.E5.m2.3.3.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.E5.m2.3.3.1.1.1.1.2.2.2" xref="S2.E5.m2.3.3.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S2.E5.m2.3.3.1.1.1.1.2.2.3" xref="S2.E5.m2.3.3.1.1.1.1.2.2.3.cmml"><mi id="S2.E5.m2.3.3.1.1.1.1.2.2.3.2" xref="S2.E5.m2.3.3.1.1.1.1.2.2.3.2.cmml">u</mi><mo id="S2.E5.m2.3.3.1.1.1.1.2.2.3.1" xref="S2.E5.m2.3.3.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.E5.m2.3.3.1.1.1.1.2.2.3.3" xref="S2.E5.m2.3.3.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E5.m2.3.3.1.1.1.1.2.3" xref="S2.E5.m2.3.3.1.1.1.1.2.3.cmml">T</mi></munderover></mstyle><mrow id="S2.E5.m2.3.3.1.1.1.1.1" xref="S2.E5.m2.3.3.1.1.1.1.1.cmml"><mrow id="S2.E5.m2.3.3.1.1.1.1.1.3" xref="S2.E5.m2.3.3.1.1.1.1.1.3.cmml"><msub id="S2.E5.m2.3.3.1.1.1.1.1.3.2" xref="S2.E5.m2.3.3.1.1.1.1.1.3.2.cmml"><mi id="S2.E5.m2.3.3.1.1.1.1.1.3.2.2" xref="S2.E5.m2.3.3.1.1.1.1.1.3.2.2.cmml">m</mi><mrow id="S2.E5.m2.2.2.2.4" xref="S2.E5.m2.2.2.2.3.cmml"><mi id="S2.E5.m2.1.1.1.1" xref="S2.E5.m2.1.1.1.1.cmml">t</mi><mo id="S2.E5.m2.2.2.2.4.1" xref="S2.E5.m2.2.2.2.3.cmml">,</mo><mi id="S2.E5.m2.2.2.2.2" xref="S2.E5.m2.2.2.2.2.cmml">u</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em" id="S2.E5.m2.3.3.1.1.1.1.1.3.1" xref="S2.E5.m2.3.3.1.1.1.1.1.3.1.cmml">⋅</mo><mi id="S2.E5.m2.3.3.1.1.1.1.1.3.3" xref="S2.E5.m2.3.3.1.1.1.1.1.3.3.cmml">s</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E5.m2.3.3.1.1.1.1.1.2" xref="S2.E5.m2.3.3.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E5.m2.3.3.1.1.1.1.1.1.1" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E5.m2.3.3.1.1.1.1.1.1.1.2" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E5.m2.3.3.1.1.1.1.1.1.1.1" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.2" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.3" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.3.cmml">u</mi></msub><mo stretchy="false" id="S2.E5.m2.3.3.1.1.1.1.1.1.1.3" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S2.E5.m2.3.3.1.2" xref="S2.E5.m2.3.3.1.1.cmml">;</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m2.3b"><apply id="S2.E5.m2.3.3.1.1.cmml" xref="S2.E5.m2.3.3.1"><eq id="S2.E5.m2.3.3.1.1.2.cmml" xref="S2.E5.m2.3.3.1.1.2"></eq><csymbol cd="latexml" id="S2.E5.m2.3.3.1.1.3.cmml" xref="S2.E5.m2.3.3.1.1.3">absent</csymbol><apply id="S2.E5.m2.3.3.1.1.1.cmml" xref="S2.E5.m2.3.3.1.1.1"><times id="S2.E5.m2.3.3.1.1.1.2.cmml" xref="S2.E5.m2.3.3.1.1.1.2"></times><apply id="S2.E5.m2.3.3.1.1.1.3.cmml" xref="S2.E5.m2.3.3.1.1.1.3"><divide id="S2.E5.m2.3.3.1.1.1.3.1.cmml" xref="S2.E5.m2.3.3.1.1.1.3"></divide><cn type="integer" id="S2.E5.m2.3.3.1.1.1.3.2.cmml" xref="S2.E5.m2.3.3.1.1.1.3.2">1</cn><apply id="S2.E5.m2.3.3.1.1.1.3.3.cmml" xref="S2.E5.m2.3.3.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E5.m2.3.3.1.1.1.3.3.1.cmml" xref="S2.E5.m2.3.3.1.1.1.3.3">subscript</csymbol><apply id="S2.E5.m2.3.3.1.1.1.3.3.2.cmml" xref="S2.E5.m2.3.3.1.1.1.3.3.2"><ci id="S2.E5.m2.3.3.1.1.1.3.3.2.1.cmml" xref="S2.E5.m2.3.3.1.1.1.3.3.2.1">¯</ci><ci id="S2.E5.m2.3.3.1.1.1.3.3.2.2.cmml" xref="S2.E5.m2.3.3.1.1.1.3.3.2.2">𝑇</ci></apply><ci id="S2.E5.m2.3.3.1.1.1.3.3.3.cmml" xref="S2.E5.m2.3.3.1.1.1.3.3.3">𝑡</ci></apply></apply><apply id="S2.E5.m2.3.3.1.1.1.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1"><apply id="S2.E5.m2.3.3.1.1.1.1.2.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E5.m2.3.3.1.1.1.1.2.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2">superscript</csymbol><apply id="S2.E5.m2.3.3.1.1.1.1.2.2.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E5.m2.3.3.1.1.1.1.2.2.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2">subscript</csymbol><sum id="S2.E5.m2.3.3.1.1.1.1.2.2.2.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2.2.2"></sum><apply id="S2.E5.m2.3.3.1.1.1.1.2.2.3.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2.2.3"><eq id="S2.E5.m2.3.3.1.1.1.1.2.2.3.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2.2.3.1"></eq><ci id="S2.E5.m2.3.3.1.1.1.1.2.2.3.2.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2.2.3.2">𝑢</ci><cn type="integer" id="S2.E5.m2.3.3.1.1.1.1.2.2.3.3.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E5.m2.3.3.1.1.1.1.2.3.cmml" xref="S2.E5.m2.3.3.1.1.1.1.2.3">𝑇</ci></apply><apply id="S2.E5.m2.3.3.1.1.1.1.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1"><times id="S2.E5.m2.3.3.1.1.1.1.1.2.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.2"></times><apply id="S2.E5.m2.3.3.1.1.1.1.1.3.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.3"><ci id="S2.E5.m2.3.3.1.1.1.1.1.3.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.3.1">⋅</ci><apply id="S2.E5.m2.3.3.1.1.1.1.1.3.2.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E5.m2.3.3.1.1.1.1.1.3.2.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E5.m2.3.3.1.1.1.1.1.3.2.2.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.3.2.2">𝑚</ci><list id="S2.E5.m2.2.2.2.3.cmml" xref="S2.E5.m2.2.2.2.4"><ci id="S2.E5.m2.1.1.1.1.cmml" xref="S2.E5.m2.1.1.1.1">𝑡</ci><ci id="S2.E5.m2.2.2.2.2.cmml" xref="S2.E5.m2.2.2.2.2">𝑢</ci></list></apply><ci id="S2.E5.m2.3.3.1.1.1.1.1.3.3.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.3.3">𝑠</ci></apply><apply id="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E5.m2.3.3.1.1.1.1.1.1.1.1.3">𝑢</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m2.3c">\displaystyle=\frac{1}{\bar{T}_{t}}\sum_{u=1}^{T}m_{t,u}\cdot s(\mathbf{x}_{u});</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E5.m3.1" class="ltx_Math" alttext="\displaystyle\mathbf{h}_{t}" display="inline"><semantics id="S2.E5.m3.1a"><msub id="S2.E5.m3.1.1" xref="S2.E5.m3.1.1.cmml"><mi id="S2.E5.m3.1.1.2" xref="S2.E5.m3.1.1.2.cmml">𝐡</mi><mi id="S2.E5.m3.1.1.3" xref="S2.E5.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E5.m3.1b"><apply id="S2.E5.m3.1.1.cmml" xref="S2.E5.m3.1.1"><csymbol cd="ambiguous" id="S2.E5.m3.1.1.1.cmml" xref="S2.E5.m3.1.1">subscript</csymbol><ci id="S2.E5.m3.1.1.2.cmml" xref="S2.E5.m3.1.1.2">𝐡</ci><ci id="S2.E5.m3.1.1.3.cmml" xref="S2.E5.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m3.1c">\displaystyle\mathbf{h}_{t}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E5.m4.1" class="ltx_Math" alttext="\displaystyle=c(f(\mathbf{x}_{t}),\bar{\mathbf{s}}_{t})." display="inline"><semantics id="S2.E5.m4.1a"><mrow id="S2.E5.m4.1.1.1" xref="S2.E5.m4.1.1.1.1.cmml"><mrow id="S2.E5.m4.1.1.1.1" xref="S2.E5.m4.1.1.1.1.cmml"><mi id="S2.E5.m4.1.1.1.1.4" xref="S2.E5.m4.1.1.1.1.4.cmml"></mi><mo id="S2.E5.m4.1.1.1.1.3" xref="S2.E5.m4.1.1.1.1.3.cmml">=</mo><mrow id="S2.E5.m4.1.1.1.1.2" xref="S2.E5.m4.1.1.1.1.2.cmml"><mi id="S2.E5.m4.1.1.1.1.2.4" xref="S2.E5.m4.1.1.1.1.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E5.m4.1.1.1.1.2.3" xref="S2.E5.m4.1.1.1.1.2.3.cmml">​</mo><mrow id="S2.E5.m4.1.1.1.1.2.2.2" xref="S2.E5.m4.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S2.E5.m4.1.1.1.1.2.2.2.3" xref="S2.E5.m4.1.1.1.1.2.2.3.cmml">(</mo><mrow id="S2.E5.m4.1.1.1.1.1.1.1.1" xref="S2.E5.m4.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E5.m4.1.1.1.1.1.1.1.1.3" xref="S2.E5.m4.1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E5.m4.1.1.1.1.1.1.1.1.2" xref="S2.E5.m4.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E5.m4.1.1.1.1.2.2.2.4" xref="S2.E5.m4.1.1.1.1.2.2.3.cmml">,</mo><msub id="S2.E5.m4.1.1.1.1.2.2.2.2" xref="S2.E5.m4.1.1.1.1.2.2.2.2.cmml"><mover accent="true" id="S2.E5.m4.1.1.1.1.2.2.2.2.2" xref="S2.E5.m4.1.1.1.1.2.2.2.2.2.cmml"><mi id="S2.E5.m4.1.1.1.1.2.2.2.2.2.2" xref="S2.E5.m4.1.1.1.1.2.2.2.2.2.2.cmml">𝐬</mi><mo id="S2.E5.m4.1.1.1.1.2.2.2.2.2.1" xref="S2.E5.m4.1.1.1.1.2.2.2.2.2.1.cmml">¯</mo></mover><mi id="S2.E5.m4.1.1.1.1.2.2.2.2.3" xref="S2.E5.m4.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="S2.E5.m4.1.1.1.1.2.2.2.5" xref="S2.E5.m4.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E5.m4.1.1.1.2" xref="S2.E5.m4.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m4.1b"><apply id="S2.E5.m4.1.1.1.1.cmml" xref="S2.E5.m4.1.1.1"><eq id="S2.E5.m4.1.1.1.1.3.cmml" xref="S2.E5.m4.1.1.1.1.3"></eq><csymbol cd="latexml" id="S2.E5.m4.1.1.1.1.4.cmml" xref="S2.E5.m4.1.1.1.1.4">absent</csymbol><apply id="S2.E5.m4.1.1.1.1.2.cmml" xref="S2.E5.m4.1.1.1.1.2"><times id="S2.E5.m4.1.1.1.1.2.3.cmml" xref="S2.E5.m4.1.1.1.1.2.3"></times><ci id="S2.E5.m4.1.1.1.1.2.4.cmml" xref="S2.E5.m4.1.1.1.1.2.4">𝑐</ci><interval closure="open" id="S2.E5.m4.1.1.1.1.2.2.3.cmml" xref="S2.E5.m4.1.1.1.1.2.2.2"><apply id="S2.E5.m4.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m4.1.1.1.1.1.1.1.1"><times id="S2.E5.m4.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m4.1.1.1.1.1.1.1.1.2"></times><ci id="S2.E5.m4.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E5.m4.1.1.1.1.1.1.1.1.3">𝑓</ci><apply id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E5.m4.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply><apply id="S2.E5.m4.1.1.1.1.2.2.2.2.cmml" xref="S2.E5.m4.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E5.m4.1.1.1.1.2.2.2.2.1.cmml" xref="S2.E5.m4.1.1.1.1.2.2.2.2">subscript</csymbol><apply id="S2.E5.m4.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E5.m4.1.1.1.1.2.2.2.2.2"><ci id="S2.E5.m4.1.1.1.1.2.2.2.2.2.1.cmml" xref="S2.E5.m4.1.1.1.1.2.2.2.2.2.1">¯</ci><ci id="S2.E5.m4.1.1.1.1.2.2.2.2.2.2.cmml" xref="S2.E5.m4.1.1.1.1.2.2.2.2.2.2">𝐬</ci></apply><ci id="S2.E5.m4.1.1.1.1.2.2.2.2.3.cmml" xref="S2.E5.m4.1.1.1.1.2.2.2.2.3">𝑡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m4.1c">\displaystyle=c(f(\mathbf{x}_{t}),\bar{\mathbf{s}}_{t}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p5.4" class="ltx_p">When the left context is infinite, the mask only grows, and the sum <math id="S2.SS2.p5.4.m1.1" class="ltx_math_unparsed" alttext="\sum_{u=1}^{T}\cdot" display="inline"><semantics id="S2.SS2.p5.4.m1.1a"><mrow id="S2.SS2.p5.4.m1.1b"><msubsup id="S2.SS2.p5.4.m1.1.1"><mo id="S2.SS2.p5.4.m1.1.1.2.2">∑</mo><mrow id="S2.SS2.p5.4.m1.1.1.2.3"><mi id="S2.SS2.p5.4.m1.1.1.2.3.2">u</mi><mo id="S2.SS2.p5.4.m1.1.1.2.3.1">=</mo><mn id="S2.SS2.p5.4.m1.1.1.2.3.3">1</mn></mrow><mi id="S2.SS2.p5.4.m1.1.1.3">T</mi></msubsup><mo lspace="0em" id="S2.SS2.p5.4.m1.1.2">⋅</mo></mrow><annotation encoding="application/x-tex" id="S2.SS2.p5.4.m1.1c">\sum_{u=1}^{T}\cdot</annotation></semantics></math> can be computed incrementally, keeping time complexity linear compared to quadratic for MHSA. SummaryMixing therefore makes the use of an infinite left context, i.e. better recognition accuracies, more practical than MHSA. For DCT, the sum takes on a new value only when a new chunk comes in. Conversely to MHSA, SummaryMixing can easily use an infinite left context.
<br class="ltx_break"></p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.2.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S2.T1.3.2" class="ltx_text" style="font-size:90%;">Speech recognition word error rates (WER) with a non-streaming and streaming conformer transducer with chunks of 1280ms, 640ms and 320ms trained with and without dynamic chunk training. The left context is infinite. </span></figcaption>
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.4.1.1" class="ltx_tr">
<td id="S2.T1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_border_tt"></td>
<td id="S2.T1.4.1.1.2" class="ltx_td ltx_nopad_l ltx_border_r ltx_border_tt"></td>
<td id="S2.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S2.T1.4.1.1.3.1" class="ltx_text ltx_font_bold">Non-streaming</span></td>
<td id="S2.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S2.T1.4.1.1.4.1" class="ltx_text ltx_font_bold">1280ms</span></td>
<td id="S2.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S2.T1.4.1.1.5.1" class="ltx_text ltx_font_bold">640ms</span></td>
<td id="S2.T1.4.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S2.T1.4.1.1.6.1" class="ltx_text ltx_font_bold">320ms</span></td>
<td id="S2.T1.4.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S2.T1.4.1.1.7.1" class="ltx_text ltx_font_bold">Training</span></td>
</tr>
<tr id="S2.T1.4.2.2" class="ltx_tr">
<td id="S2.T1.4.2.2.1" class="ltx_td ltx_nopad_r"></td>
<td id="S2.T1.4.2.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.2.2.2.1" class="ltx_text ltx_font_bold">Dynamic</span></td>
<td id="S2.T1.4.2.2.3" class="ltx_td ltx_align_center ltx_border_r" colspan="3"><span id="S2.T1.4.2.2.3.1" class="ltx_text ltx_font_italic">WER %</span></td>
<td id="S2.T1.4.2.2.4" class="ltx_td ltx_align_center ltx_border_r" colspan="3"><span id="S2.T1.4.2.2.4.1" class="ltx_text ltx_font_italic">WER %</span></td>
<td id="S2.T1.4.2.2.5" class="ltx_td ltx_align_center ltx_border_r" colspan="3"><span id="S2.T1.4.2.2.5.1" class="ltx_text ltx_font_italic">WER %</span></td>
<td id="S2.T1.4.2.2.6" class="ltx_td ltx_align_center ltx_border_r" colspan="3"><span id="S2.T1.4.2.2.6.1" class="ltx_text ltx_font_italic">WER %</span></td>
<td id="S2.T1.4.2.2.7" class="ltx_td ltx_align_center ltx_border_r" colspan="2"><span id="S2.T1.4.2.2.7.1" class="ltx_text ltx_font_bold">GPU</span></td>
<td id="S2.T1.4.2.2.8" class="ltx_td ltx_align_center" colspan="2"><span id="S2.T1.4.2.2.8.1" class="ltx_text ltx_font_bold">VRAM</span></td>
</tr>
<tr id="S2.T1.4.3.3" class="ltx_tr">
<td id="S2.T1.4.3.3.1" class="ltx_td ltx_nopad_r"></td>
<td id="S2.T1.4.3.3.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.3.3.2.1" class="ltx_text ltx_font_bold">chunk</span></td>
<td id="S2.T1.4.3.3.3" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.3.3.3.1" class="ltx_text ltx_font_italic">dev-</span></td>
<td id="S2.T1.4.3.3.4" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.3.3.4.1" class="ltx_text ltx_font_italic">test-</span></td>
<td id="S2.T1.4.3.3.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.3.3.5.1" class="ltx_text ltx_font_italic">test-</span></td>
<td id="S2.T1.4.3.3.6" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.3.3.6.1" class="ltx_text ltx_font_italic">dev-</span></td>
<td id="S2.T1.4.3.3.7" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.3.3.7.1" class="ltx_text ltx_font_italic">test-</span></td>
<td id="S2.T1.4.3.3.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.3.3.8.1" class="ltx_text ltx_font_italic">test-</span></td>
<td id="S2.T1.4.3.3.9" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.3.3.9.1" class="ltx_text ltx_font_italic">dev-</span></td>
<td id="S2.T1.4.3.3.10" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.3.3.10.1" class="ltx_text ltx_font_italic">test-</span></td>
<td id="S2.T1.4.3.3.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.3.3.11.1" class="ltx_text ltx_font_italic">test-</span></td>
<td id="S2.T1.4.3.3.12" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.3.3.12.1" class="ltx_text ltx_font_italic">dev-</span></td>
<td id="S2.T1.4.3.3.13" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.3.3.13.1" class="ltx_text ltx_font_italic">test-</span></td>
<td id="S2.T1.4.3.3.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.3.3.14.1" class="ltx_text ltx_font_italic">test-</span></td>
<td id="S2.T1.4.3.3.15" class="ltx_td ltx_align_center ltx_border_r" colspan="2"><span id="S2.T1.4.3.3.15.1" class="ltx_text ltx_font_italic">hours</span></td>
<td id="S2.T1.4.3.3.16" class="ltx_td ltx_align_center" colspan="2"><span id="S2.T1.4.3.3.16.1" class="ltx_text ltx_font_italic">GB</span></td>
</tr>
<tr id="S2.T1.4.4.4" class="ltx_tr">
<td id="S2.T1.4.4.4.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T1.4.4.4.1.1" class="ltx_text ltx_font_bold">Librispeech</span></td>
<td id="S2.T1.4.4.4.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.4.4.2.1" class="ltx_text ltx_font_bold">training</span></td>
<td id="S2.T1.4.4.4.3" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.3.1" class="ltx_text ltx_font_italic">clean</span></td>
<td id="S2.T1.4.4.4.4" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.4.1" class="ltx_text ltx_font_italic">clean</span></td>
<td id="S2.T1.4.4.4.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.4.4.5.1" class="ltx_text ltx_font_italic">other</span></td>
<td id="S2.T1.4.4.4.6" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.6.1" class="ltx_text ltx_font_italic">clean</span></td>
<td id="S2.T1.4.4.4.7" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.7.1" class="ltx_text ltx_font_italic">clean</span></td>
<td id="S2.T1.4.4.4.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.4.4.8.1" class="ltx_text ltx_font_italic">other</span></td>
<td id="S2.T1.4.4.4.9" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.9.1" class="ltx_text ltx_font_italic">clean</span></td>
<td id="S2.T1.4.4.4.10" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.10.1" class="ltx_text ltx_font_italic">clean</span></td>
<td id="S2.T1.4.4.4.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.4.4.11.1" class="ltx_text ltx_font_italic">other</span></td>
<td id="S2.T1.4.4.4.12" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.12.1" class="ltx_text ltx_font_italic">clean</span></td>
<td id="S2.T1.4.4.4.13" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.13.1" class="ltx_text ltx_font_italic">clean</span></td>
<td id="S2.T1.4.4.4.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.4.4.14.1" class="ltx_text ltx_font_italic">other</span></td>
<td id="S2.T1.4.4.4.15" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.15.1" class="ltx_text ltx_font_italic">fp16</span></td>
<td id="S2.T1.4.4.4.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.4.4.4.16.1" class="ltx_text ltx_font_italic">fp32</span></td>
<td id="S2.T1.4.4.4.17" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.17.1" class="ltx_text ltx_font_italic">fp16</span></td>
<td id="S2.T1.4.4.4.18" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.4.4.4.18.1" class="ltx_text ltx_font_italic">fp32</span></td>
</tr>
<tr id="S2.T1.4.5.5" class="ltx_tr">
<td id="S2.T1.4.5.5.1" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Self-attention</td>
<td id="S2.T1.4.5.5.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">—</td>
<td id="S2.T1.4.5.5.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">2.7</td>
<td id="S2.T1.4.5.5.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">3.0</td>
<td id="S2.T1.4.5.5.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">7.0</td>
<td id="S2.T1.4.5.5.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">—</td>
<td id="S2.T1.4.5.5.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">—</td>
<td id="S2.T1.4.5.5.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">—</td>
<td id="S2.T1.4.5.5.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">—</td>
<td id="S2.T1.4.5.5.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">—</td>
<td id="S2.T1.4.5.5.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">—</td>
<td id="S2.T1.4.5.5.12" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">—</td>
<td id="S2.T1.4.5.5.13" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">—</td>
<td id="S2.T1.4.5.5.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">—</td>
<td id="S2.T1.4.5.5.15" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">29.0</td>
<td id="S2.T1.4.5.5.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">39.5</td>
<td id="S2.T1.4.5.5.17" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">20.1</td>
<td id="S2.T1.4.5.5.18" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">40.2</td>
</tr>
<tr id="S2.T1.4.6.6" class="ltx_tr">
<td id="S2.T1.4.6.6.1" class="ltx_td ltx_nopad_r ltx_align_left">SummaryMixing</td>
<td id="S2.T1.4.6.6.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">—</td>
<td id="S2.T1.4.6.6.3" class="ltx_td ltx_nopad_l ltx_align_center">2.7</td>
<td id="S2.T1.4.6.6.4" class="ltx_td ltx_nopad_l ltx_align_center">2.9</td>
<td id="S2.T1.4.6.6.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">7.0</td>
<td id="S2.T1.4.6.6.6" class="ltx_td ltx_nopad_l ltx_align_center">—</td>
<td id="S2.T1.4.6.6.7" class="ltx_td ltx_nopad_l ltx_align_center">—</td>
<td id="S2.T1.4.6.6.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">—</td>
<td id="S2.T1.4.6.6.9" class="ltx_td ltx_nopad_l ltx_align_center">—</td>
<td id="S2.T1.4.6.6.10" class="ltx_td ltx_nopad_l ltx_align_center">—</td>
<td id="S2.T1.4.6.6.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">—</td>
<td id="S2.T1.4.6.6.12" class="ltx_td ltx_nopad_l ltx_align_center">—</td>
<td id="S2.T1.4.6.6.13" class="ltx_td ltx_nopad_l ltx_align_center">—</td>
<td id="S2.T1.4.6.6.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">—</td>
<td id="S2.T1.4.6.6.15" class="ltx_td ltx_nopad_l ltx_align_center">24.5</td>
<td id="S2.T1.4.6.6.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">34.7</td>
<td id="S2.T1.4.6.6.17" class="ltx_td ltx_nopad_l ltx_align_center">16.9</td>
<td id="S2.T1.4.6.6.18" class="ltx_td ltx_nopad_l ltx_align_center">32.9</td>
</tr>
<tr id="S2.T1.4.7.7" class="ltx_tr">
<td id="S2.T1.4.7.7.1" class="ltx_td ltx_nopad_r ltx_align_left">Self-attention</td>
<td id="S2.T1.4.7.7.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">✓</td>
<td id="S2.T1.4.7.7.3" class="ltx_td ltx_nopad_l ltx_align_center">3.0</td>
<td id="S2.T1.4.7.7.4" class="ltx_td ltx_nopad_l ltx_align_center">2.9</td>
<td id="S2.T1.4.7.7.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">7.0</td>
<td id="S2.T1.4.7.7.6" class="ltx_td ltx_nopad_l ltx_align_center">3.1</td>
<td id="S2.T1.4.7.7.7" class="ltx_td ltx_nopad_l ltx_align_center">3.2</td>
<td id="S2.T1.4.7.7.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">8.0</td>
<td id="S2.T1.4.7.7.9" class="ltx_td ltx_nopad_l ltx_align_center">3.2</td>
<td id="S2.T1.4.7.7.10" class="ltx_td ltx_nopad_l ltx_align_center">3.4</td>
<td id="S2.T1.4.7.7.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">8.6</td>
<td id="S2.T1.4.7.7.12" class="ltx_td ltx_nopad_l ltx_align_center">3.4</td>
<td id="S2.T1.4.7.7.13" class="ltx_td ltx_nopad_l ltx_align_center">3.7</td>
<td id="S2.T1.4.7.7.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">9.6</td>
<td id="S2.T1.4.7.7.15" class="ltx_td ltx_nopad_l ltx_align_center">29.7</td>
<td id="S2.T1.4.7.7.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">40.1</td>
<td id="S2.T1.4.7.7.17" class="ltx_td ltx_nopad_l ltx_align_center">20.2</td>
<td id="S2.T1.4.7.7.18" class="ltx_td ltx_nopad_l ltx_align_center">40.2</td>
</tr>
<tr id="S2.T1.4.8.8" class="ltx_tr">
<td id="S2.T1.4.8.8.1" class="ltx_td ltx_nopad_r ltx_align_left">SummaryMixing</td>
<td id="S2.T1.4.8.8.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">✓</td>
<td id="S2.T1.4.8.8.3" class="ltx_td ltx_nopad_l ltx_align_center">2.9</td>
<td id="S2.T1.4.8.8.4" class="ltx_td ltx_nopad_l ltx_align_center">2.9</td>
<td id="S2.T1.4.8.8.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">7.0</td>
<td id="S2.T1.4.8.8.6" class="ltx_td ltx_nopad_l ltx_align_center">2.9</td>
<td id="S2.T1.4.8.8.7" class="ltx_td ltx_nopad_l ltx_align_center">3.2</td>
<td id="S2.T1.4.8.8.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">8.1</td>
<td id="S2.T1.4.8.8.9" class="ltx_td ltx_nopad_l ltx_align_center">3.1</td>
<td id="S2.T1.4.8.8.10" class="ltx_td ltx_nopad_l ltx_align_center">3.4</td>
<td id="S2.T1.4.8.8.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">8.6</td>
<td id="S2.T1.4.8.8.12" class="ltx_td ltx_nopad_l ltx_align_center">3.3</td>
<td id="S2.T1.4.8.8.13" class="ltx_td ltx_nopad_l ltx_align_center">3.7</td>
<td id="S2.T1.4.8.8.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">9.6</td>
<td id="S2.T1.4.8.8.15" class="ltx_td ltx_nopad_l ltx_align_center">25.0</td>
<td id="S2.T1.4.8.8.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">35.1</td>
<td id="S2.T1.4.8.8.17" class="ltx_td ltx_nopad_l ltx_align_center">16.9</td>
<td id="S2.T1.4.8.8.18" class="ltx_td ltx_nopad_l ltx_align_center">33.0</td>
</tr>
<tr id="S2.T1.4.9.9" class="ltx_tr">
<td id="S2.T1.4.9.9.1" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S2.T1.4.9.9.1.1" class="ltx_text ltx_font_bold">Voxpopuli</span></td>
<td id="S2.T1.4.9.9.2" class="ltx_td ltx_nopad_l ltx_border_r ltx_border_tt"></td>
<td id="S2.T1.4.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S2.T1.4.9.9.3.1" class="ltx_text ltx_font_italic">Dev. Test</span></td>
<td id="S2.T1.4.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S2.T1.4.9.9.4.1" class="ltx_text ltx_font_italic">Dev. Test</span></td>
<td id="S2.T1.4.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S2.T1.4.9.9.5.1" class="ltx_text ltx_font_italic">Dev. Test</span></td>
<td id="S2.T1.4.9.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S2.T1.4.9.9.6.1" class="ltx_text ltx_font_italic">Dev. Test</span></td>
<td id="S2.T1.4.9.9.7" class="ltx_td ltx_nopad_l ltx_border_tt"></td>
<td id="S2.T1.4.9.9.8" class="ltx_td ltx_nopad_l ltx_border_r ltx_border_tt"></td>
<td id="S2.T1.4.9.9.9" class="ltx_td ltx_border_tt"></td>
<td id="S2.T1.4.9.9.10" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S2.T1.4.10.10" class="ltx_tr">
<td id="S2.T1.4.10.10.1" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Self-attention</td>
<td id="S2.T1.4.10.10.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">—</td>
<td id="S2.T1.4.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">11.5  11.7</td>
<td id="S2.T1.4.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">—     —</td>
<td id="S2.T1.4.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">—     —</td>
<td id="S2.T1.4.10.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">—     —</td>
<td id="S2.T1.4.10.10.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">8.0</td>
<td id="S2.T1.4.10.10.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">12.9</td>
<td id="S2.T1.4.10.10.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">36.0</td>
<td id="S2.T1.4.10.10.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">71.1</td>
</tr>
<tr id="S2.T1.4.11.11" class="ltx_tr">
<td id="S2.T1.4.11.11.1" class="ltx_td ltx_nopad_r ltx_align_left">SummaryMixing</td>
<td id="S2.T1.4.11.11.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">—</td>
<td id="S2.T1.4.11.11.3" class="ltx_td ltx_align_center ltx_border_r" colspan="3">11.0  11.2</td>
<td id="S2.T1.4.11.11.4" class="ltx_td ltx_align_center ltx_border_r" colspan="3">—     —</td>
<td id="S2.T1.4.11.11.5" class="ltx_td ltx_align_center ltx_border_r" colspan="3">—     —</td>
<td id="S2.T1.4.11.11.6" class="ltx_td ltx_align_center ltx_border_r" colspan="3">—     —</td>
<td id="S2.T1.4.11.11.7" class="ltx_td ltx_nopad_l ltx_align_center">7.1</td>
<td id="S2.T1.4.11.11.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">10.0</td>
<td id="S2.T1.4.11.11.9" class="ltx_td ltx_nopad_l ltx_align_center">29.1</td>
<td id="S2.T1.4.11.11.10" class="ltx_td ltx_nopad_l ltx_align_center">61.3</td>
</tr>
<tr id="S2.T1.4.12.12" class="ltx_tr">
<td id="S2.T1.4.12.12.1" class="ltx_td ltx_nopad_r ltx_align_left">Self-attention</td>
<td id="S2.T1.4.12.12.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">✓</td>
<td id="S2.T1.4.12.12.3" class="ltx_td ltx_align_center ltx_border_r" colspan="3">11.6  11.7</td>
<td id="S2.T1.4.12.12.4" class="ltx_td ltx_align_center ltx_border_r" colspan="3">12.3  12.6</td>
<td id="S2.T1.4.12.12.5" class="ltx_td ltx_align_center ltx_border_r" colspan="3">13.0  13.4</td>
<td id="S2.T1.4.12.12.6" class="ltx_td ltx_align_center ltx_border_r" colspan="3">14.6  14.6</td>
<td id="S2.T1.4.12.12.7" class="ltx_td ltx_nopad_l ltx_align_center">8.4</td>
<td id="S2.T1.4.12.12.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">13.3</td>
<td id="S2.T1.4.12.12.9" class="ltx_td ltx_nopad_l ltx_align_center">36.1</td>
<td id="S2.T1.4.12.12.10" class="ltx_td ltx_nopad_l ltx_align_center">71.1</td>
</tr>
<tr id="S2.T1.4.13.13" class="ltx_tr">
<td id="S2.T1.4.13.13.1" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">SummaryMixing</td>
<td id="S2.T1.4.13.13.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r">✓</td>
<td id="S2.T1.4.13.13.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" colspan="3">11.2  11.3</td>
<td id="S2.T1.4.13.13.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" colspan="3">12.1  12.4</td>
<td id="S2.T1.4.13.13.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" colspan="3">12.8  13.0</td>
<td id="S2.T1.4.13.13.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" colspan="3">14.1  14.2</td>
<td id="S2.T1.4.13.13.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">7.3</td>
<td id="S2.T1.4.13.13.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r">10.4</td>
<td id="S2.T1.4.13.13.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">29.2</td>
<td id="S2.T1.4.13.13.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">61.3</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.SS2.p6" class="ltx_para ltx_noindent">
<p id="S2.SS2.p6.1" class="ltx_p"><span id="S2.SS2.p6.1.1" class="ltx_text ltx_font_bold">Conformer Transducers with SummaryMixing.</span> The conformer-based transducer is a popular architecture for streaming ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> mainly due to its capability to generate partial hypotheses without processing the whole input sequence. Making the conformer transducer compatible with SummaryMixing is straightforward, as only the acoustic encoder i.e. the conformer part, needs to be updated. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, and based on the fact that self-attention and SummaryMixing are expected to fulfill the same role within the encoder, we replace every MHSA cell in the conformer with a SummaryMixing one, hence leading to an ASR architecture without any attention. Convolutional layers are also changed to dynamic chunck convolutions to allow DCT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. The integration of SummaryMixing to the conformer encoder is depicted in Figure <a href="#S2.F1" title="Figure 1 ‣ II-B Streaming SummaryMixing ‣ II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. 
<br class="ltx_break"></p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The effectiveness of SummaryMixing for streaming and non-streaming ASR is first evaluated on two datasets (section <a href="#S3.SS2" title="III-B Speech recognition results ‣ III Experiments ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>). Then, we provide an analysis of the efficiency gains in terms of real-time factor and peak memory consumption as well as on the impact of the audio duration on the word error rate (section <a href="#S3.SS3" title="III-C Extended analysis of streaming SummaryMixing ‣ III Experiments ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>).</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Experimental protocol</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">SummaryMixing has already been shown to outperform many baselines for non-streaming ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Hence, we decided to compare it to the fastest available implementation of a conformer-transducer for streaming and offline ASR with MHSA on SpeechBrain<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>SpeechBrain version 1.0.0 is used for all experiments.</span></span></span>.
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Speech recognition datasets.</span> Librispeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and the English set of Voxpopuli <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> are considered as benchmark datasets. On Librispeech, the tokenizer and the recurrent neural language model (RNNLM) are pre-trained and originate from the official SpeechBrain recipe. The full 960 hours are used for training while results are reported on the standard validation and test sets. Voxpopuli is a multilingual dataset containing recordings from the European Parliament. The acoustic conditions including recording hardware, background noises, and speech accents are more challenging than Librispeech. In practice, we removed all sentences over 100 seconds to fit the memory budget with MHSA while training. The training set contains 522 hours of speech while the validation and test sets are made of 5 hours. No language model is used for Voxpopuli. 
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.2" class="ltx_p"><span id="S3.SS1.p3.2.1" class="ltx_text ltx_font_bold">Architecture and training details.</span> Hyperparameters are almost identical to the DCT recipe from SpeechBrain<sup id="S3.SS1.p3.2.2" class="ltx_sup">2</sup> and are open-sourced in our repository<sup id="S3.SS1.p3.2.3" class="ltx_sup">1</sup>. In brief, the Transducer architecture is made of a 12-block conformer acoustic encoder equipped either with MHSA or SummaryMixing and DCCONV, a one-layered LSTM predictor network, and a joiner with a single hidden layer. The joiner performs a sum before the projection. The total number of trainable parameters for the models is 80M. Multi-task learning is performed for the first 10 epochs with the CTC loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Models are trained for 90,000 and 50,000 steps on Librispeech and Voxpopuli respectively with a warmup (25,000 steps) and exponential decay learning rate scheduler. The learning rate peaks at 0.0008. Dynamic chunk training parameters are strictly identical to the original recipe with a streaming probability of 0.6 and chunks ranging from 320ms to 1280ms. The left context also randomly varies from 320ms to 1280ms. Full context training is performed 40% of the time enabling the model to behave properly when an infinite left context is given. The output vocabulary size is 1,000 for both datasets. Batches are created via dynamic batching and a total batch duration of 900 seconds. Models were trained on three A40 46GB. Each GPU was able to process 150 seconds of speech, hence a gradient accumulation of two was applied to reach the 900 seconds per batch.
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Half-precision and transducers.</span> Most existing toolkits including SpeechBrain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, ESPnet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> or k2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> integrate half-precision training for the neural network parts of transducer systems greatly boosting the training speed. In ESPnet or SpeechBrain, however, the memory footprint remains unchanged due to a large bottleneck when instantiating the four-dimensional tensor merging time-steps and tokens of the transducer. Indeed, the loss computation is computed in single precision and the large tensor must be cast back to this type, creating a spike in memory requirement. To avoid this casting operation, and to divide by a factor of two the memory consumption, we contributed to SpeechBrain a fully half-precision transducer loss computation using Numba <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Speech recognition results</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The effectiveness of SummaryMixing for streaming ASR is first evaluated on Librispeech and Voxpopuli. Table <a href="#S2.T1" title="TABLE I ‣ II-B Streaming SummaryMixing ‣ II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> reports the WER for SummaryMixing and MHSA models once trained with and without DCT and evaluated on a non-streaming scenario or with streaming chunks of length 1280 ms, 640 ms, and 320 ms. In the streaming setting, the left-context is infinite. It also reports the peak VRAM for the full training as well as the total number of GPU hours needed.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2409.07165/assets/x3.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="113" height="88" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2409.07165/assets/x4.png" id="S3.F2.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="122" height="92" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2409.07165/assets/x5.png" id="S3.F2.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="111" height="91" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Word error rate variations of the MHSA- and SummaryMixing- equipped models trained on VoxPopuli depending on the utterance length (left curve). Sentences are obtained from the test set of VoxPopuli. The middle curve shows the inference real-time factor observed with CPU and GPU for the two models. The right-most curve gives the peak VRAM from both models when decoding. The left context is infinite for all experiments.</span></figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">SummaryMixing either outperforms or matches the WER of MHSA with both datasets and on all scenarios. If decoding is performed without streaming, SummaryMixing WER is lower than MHSA by 0.1% absolute on the “dev-clean” set and identical on the two others. When streaming with chunks of length 640 ms and 320 ms the same 0.1% absolute WER improvement over MHSA is observed on “dev-clean” for SummaryMixing. At 1280 ms, however, SummaryMixing improves by 0.2% absolute on “dev-clean” but degrades by 0.1% absolute on “test-clean”. This is the only degradation observed with SummaryMixing on both datasets and across all scenarios. In particular, with VoxPopuli, SummaryMixing always outperforms MHSA. The average absolute WER reduction obtained by SummaryMixing is 0.34%. This difference increases with the reduction of latency as the streaming scenario with a 320 ms chunk size sees SummaryMixing performing at a WER of 14.1% against 14.6% for MHSA on the validation subset.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">On average, SummaryMixing-equipped conformer transducers are 15.5% faster to train than MHSA ones. Memory-wise, and despite the rather short sentences contained in Librispeech, the peak VRAM using mixed precision goes from 20.2 GB for MHSA to 16.9 GB, hence a 16% decrease in memory budget. On VoxPopuli, with longer utterances, this increases to 19%. SummaryMixing therefore offers better or similar performance for non-streaming and streaming ASR, but at a significantly lower training cost. Finally, our half-precision Transducer loss divides by more than two the required VRAM.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Extended analysis of streaming SummaryMixing</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">An extended analysis of the characteristics of SummaryMixing is conducted along three axes: encoder inference real-time factor (RTF) analysis on CPU and GPU, peak memory usage, and WER variations given the sequence length. Indeed, and due to its averaging mechanism, it sounds plausible that SummaryMixing is more impacted than MHSA when the available context increases. It is critical to note that the left-context is infinite for all measurements. Indeed, an infinite left context leads to higher recognition accuracies. In that scenario, SummaryMixing has a linear-time complexity while self-attention time complexity is quadratic. MHSA could also exhibit a linear-time complexity by reducing the left context to a fixed number of chunks, but the WER would then be negatively impacted. However, our goal is to maximize the accuracy and minimize the latency and compute requirements. Figure <a href="#S3.F2" title="Figure 2 ‣ III-B Speech recognition results ‣ III Experiments ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows this analysis.
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">WER given utterance length.</span> The 5 hours of speech contained in the test set of VoxPopuli are grouped into 10 buckets of increasing length. We then compute the WER of all the sentences in each bucket and report their value on the left-most curves of Figure <a href="#S3.F2" title="Figure 2 ‣ III-B Speech recognition results ‣ III Experiments ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> for MHSA and SummaryMixing. Streaming decoding from models trained with VoxPopuli is performed with a chunk size of 640 ms, hence corresponding to the middle column of Table <a href="#S2.T1" title="TABLE I ‣ II-B Streaming SummaryMixing ‣ II Streaming and Non-Streaming SummaryMixing ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. While the WER increases slightly with the utterance length for both MHSA and SummaryMixing, the rate of increase is not higher for SummaryMixing. Therefore, the averaging mechanism of SummaryMixing does not seem to impact adversaly the WER with longer sequences compared to MHSA in this setting.
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold">Encoder RTF analysis.</span> The RTF is obtained at the acoustic encoder level, i.e. the conformer, as all the other blocks are the same both for MHSA and SummaryMixing. The decoding algorithm also is excluded as it does not affect the comparison and is usually an order of magnitude slower than the inference. Instead, we wish to focus on the impact of SummaryMixing over MHSA on the encoder when inferring. We generate five sets of 100 random input sequences sampled at 16 kHz of length <math id="S3.SS3.p3.1.m1.6" class="ltx_Math" alttext="[5,10,20,30,60,120]" display="inline"><semantics id="S3.SS3.p3.1.m1.6a"><mrow id="S3.SS3.p3.1.m1.6.7.2" xref="S3.SS3.p3.1.m1.6.7.1.cmml"><mo stretchy="false" id="S3.SS3.p3.1.m1.6.7.2.1" xref="S3.SS3.p3.1.m1.6.7.1.cmml">[</mo><mn id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">5</mn><mo id="S3.SS3.p3.1.m1.6.7.2.2" xref="S3.SS3.p3.1.m1.6.7.1.cmml">,</mo><mn id="S3.SS3.p3.1.m1.2.2" xref="S3.SS3.p3.1.m1.2.2.cmml">10</mn><mo id="S3.SS3.p3.1.m1.6.7.2.3" xref="S3.SS3.p3.1.m1.6.7.1.cmml">,</mo><mn id="S3.SS3.p3.1.m1.3.3" xref="S3.SS3.p3.1.m1.3.3.cmml">20</mn><mo id="S3.SS3.p3.1.m1.6.7.2.4" xref="S3.SS3.p3.1.m1.6.7.1.cmml">,</mo><mn id="S3.SS3.p3.1.m1.4.4" xref="S3.SS3.p3.1.m1.4.4.cmml">30</mn><mo id="S3.SS3.p3.1.m1.6.7.2.5" xref="S3.SS3.p3.1.m1.6.7.1.cmml">,</mo><mn id="S3.SS3.p3.1.m1.5.5" xref="S3.SS3.p3.1.m1.5.5.cmml">60</mn><mo id="S3.SS3.p3.1.m1.6.7.2.6" xref="S3.SS3.p3.1.m1.6.7.1.cmml">,</mo><mn id="S3.SS3.p3.1.m1.6.6" xref="S3.SS3.p3.1.m1.6.6.cmml">120</mn><mo stretchy="false" id="S3.SS3.p3.1.m1.6.7.2.7" xref="S3.SS3.p3.1.m1.6.7.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.6b"><list id="S3.SS3.p3.1.m1.6.7.1.cmml" xref="S3.SS3.p3.1.m1.6.7.2"><cn type="integer" id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">5</cn><cn type="integer" id="S3.SS3.p3.1.m1.2.2.cmml" xref="S3.SS3.p3.1.m1.2.2">10</cn><cn type="integer" id="S3.SS3.p3.1.m1.3.3.cmml" xref="S3.SS3.p3.1.m1.3.3">20</cn><cn type="integer" id="S3.SS3.p3.1.m1.4.4.cmml" xref="S3.SS3.p3.1.m1.4.4">30</cn><cn type="integer" id="S3.SS3.p3.1.m1.5.5.cmml" xref="S3.SS3.p3.1.m1.5.5">60</cn><cn type="integer" id="S3.SS3.p3.1.m1.6.6.cmml" xref="S3.SS3.p3.1.m1.6.6">120</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.6c">[5,10,20,30,60,120]</annotation></semantics></math> seconds and pass them throughout the acoustic encoder. The random nature of the input does not affect the measured RTF as no autoregressive behavior is included in the measurements. RTF are measurements either on an isolated Nvidia A40 46GB GPU or on four cores of an Intel Xeon 5218 CPU. The middle curve of Figure <a href="#S3.F2" title="Figure 2 ‣ III-B Speech recognition results ‣ III Experiments ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the outcomes of that experiment. It clearly appears that the RTF, both on CPU and GPU, of the MHSA-equipped encoder degrades with the increase of the utterance length. This is not true for SummaryMixing as the RTF remains constant due to its linear-time complexity. SummaryMixing always is faster to infer compared to MHSA.
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.1" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold">Memory consumption.</span> We also store the peak VRAM usage during the GPU RTF analysis experiments to generate curves of memory requirements over the ten different sets of utterance lengths. The right-most curve of Figure <a href="#S3.F2" title="Figure 2 ‣ III-B Speech recognition results ‣ III Experiments ‣ Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> reports the results. MHSA suffers from a much faster increase in memory consumption than SummaryMixing given the sentence length as peak VRAMs of 0.51 GB and 0.48 GB are reported for MHSA and SummaryMixing with 10-second long sentences compared to 1.9 GB and 0.8 GB at 120 seconds. Hence the delta increases from 6.25% to 137% demonstrating that SummaryMixing is much more efficient than MHSA with longer sentences enabling the use of infinite left-context.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This article extended SummaryMixing, a linear-time complexity alternative to self-attention, to streaming speech recognition with a streaming and non-streaming conformer transducer. The conducted experiments and analysis show that compared to self-attention, SummaryMixing leads to faster training, halves the required on-board memory for transcribing long utterances while keeping an infinite left context, and exhibits a constant real-time factor at decoding time both on CPU and GPU while reaching lower error rates on the selected streaming and non-streaming tasks.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever, “Robust speech recognition via large-scale weak supervision,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.04356</em>, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. B. Nassif, I. Shahin, I. Attili, M. Azzeh, and K. Shaalan, “Speech recognition using deep neural networks: A systematic review,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE access</em>, vol. 7, pp. 19 143–19 165, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
H. Arasteh, V. Hosseinnezhad, V. Loia, A. Tommasetti, O. Troisi, M. Shafie-khah, and P. Siano, “Iot-based smart cities: A survey,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">2016 IEEE 16th international conference on environment and electrical engineering (EEEIC)</em>.   IEEE, 2016, pp. 1–6.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol. 30, 2017.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
K. Kim, F. Wu, Y. Peng, J. Pan, P. Sridhar, K. J. Han, and S. Watanabe, “E-branchformer: Branchformer with enhanced merging for speech recognition,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2022 IEEE Spoken Language Technology Workshop (SLT)</em>.   IEEE, 2023, pp. 84–91.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
B. Li, A. Gulati, J. Yu, T. N. Sainath, C.-C. Chiu, A. Narayanan, S.-Y. Chang, R. Pang, Y. He, J. Qin <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A better and faster end-to-end model for streaming asr,” in <em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2021, pp. 5634–5638.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
X. Li, G. Huybrechts, S. Ronanki, J. Farris, and S. Bodapati, “Dynamic chunk convolution for unified streaming and non-streaming conformer asr,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2023, pp. 1–5.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Tay, M. Dehghani, D. Bahri, and D. Metzler, “Efficient transformers: A survey,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, vol. 55, no. 6, pp. 1–28, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Wang, B. Z. Li, M. Khabsa, H. Fang, and H. Ma, “Linformer: Self-attention with linear complexity,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.04768</em>, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
R. Child, S. Gray, A. Radford, and I. Sutskever, “Generating long sequences with sparse transformers,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.10509</em>, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. Kim, A. Gholami, A. Shaw, N. Lee, K. Mangalam, J. Malik, M. W. Mahoney, and K. Keutzer, “Squeezeformer: An efficient transformer for automatic speech recognition,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol. 35, pp. 9361–9373, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. Burchi and V. Vielzeuf, “Efficient conformer: Progressive downsampling and grouped attention for automatic speech recognition,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>.   IEEE, 2021, pp. 8–15.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y. Shi, Y. Wang, C. Wu, C.-F. Yeh, J. Chan, F. Zhang, D. Le, and M. Seltzer, “Emformer: Efficient memory transformer based acoustic model for low latency streaming speech recognition,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2021, pp. 6783–6787.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
C. Wu, F. Wu, T. Qi, Y. Huang, and X. Xie, “Fastformer: Additive attention can be all you need,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.09084</em>, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. Peng, S. Dalmia, I. Lane, and S. Watanabe, “Branchformer: Parallel MLP-attention architectures to capture local and global context for speech recognition and understanding,” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.   PMLR, 2022, pp. 17 627–17 643.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
S. Zhang, E. Loweimi, P. Bell, and S. Renals, “On the usefulness of self-attention for automatic speech recognition with transformers,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Spoken Language Technology Workshop (SLT)</em>.   IEEE, 2021, pp. 89–96.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
K. Shim, J. Choi, and W. Sung, “Understanding the role of self attention for efficient speech recognition,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
T. Parcollet, R. van Dalen, S. Zhang, and S. Bhattacharya, “Summarymixing: A linear-complexity alternative to self-attention for speech recognition and understanding,” 2024.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
A. Gulati, J. Qin, C.-C. Chiu, N. Parmar, Y. Zhang, J. Yu, W. Han, S. Wang, Z. Zhang, Y. Wu <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Conformer: Convolution-augmented transformer for speech recognition,” 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S. Zhang, T. Parcollet, R. van Dalen, and S. Bhattacharya, “Linear-complexity self-supervised learning for speech processing,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2407.13377</em>, 2024.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Z. Yao, D. Wu, X. Wang, B. Zhang, F. Yu, C. Yang, Z. Peng, X. Chen, L. Xie, and X. Lei, “WeNet: Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2021</em>, 2021, pp. 4054–4058.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M. Ravanelli, T. Parcollet, P. Plantinga, A. Rouhe, S. Cornell, L. Lugosch, C. Subakan, N. Dawalatabad, A. Heba, J. Zhong <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Speechbrain: A general-purpose speech toolkit,” <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.04624</em>, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “Librispeech: an asr corpus based on public domain audio books,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>.   IEEE, 2015, pp. 5206–5210.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
C. Wang, M. Riviere, A. Lee, A. Wu, C. Talnikar, D. Haziza, M. Williamson, J. Pino, and E. Dupoux, “VoxPopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>.   Online: Association for Computational Linguistics, Aug. 2021, pp. 993–1003. [Online]. Available: <a target="_blank" href="https://aclanthology.org/2021.acl-long.80" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2021.acl-long.80</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
A. Graves and A. Graves, “Connectionist temporal classification,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Supervised sequence labelling with recurrent neural networks</em>, pp. 61–93, 2012.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
S. Watanabe, T. Hori, S. Karita, T. Hayashi, J. Nishitoba, Y. Unno, N. E. Y. Soplin, J. Heymann, M. Wiesner, N. Chen <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Espnet: End-to-end speech processing toolkit,” <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">Interspeech 2018</em>, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Z. Yao, L. Guo, X. Yang, W. Kang, F. Kuang, Y. Yang, Z. Jin, L. Lin, and D. Povey, “Zipformer: A faster and better encoder for automatic speech recognition,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.11230</em>, 2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
S. K. Lam, A. Pitrou, and S. Seibert, “Numba: A llvm-based python jit compiler,” in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC</em>, 2015, pp. 1–6.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.07164" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.07165" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.07165">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.07165" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.07166" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 01:39:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
