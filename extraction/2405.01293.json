{
    "S3.T1": {
        "caption": "Table 1:  Speech corpora",
        "table": "<figure id=\"S3.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Speech corpora</figcaption>\n<table id=\"S3.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S3.T1.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Type</span></th>\n<th id=\"S3.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T1.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Duration (h)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.3.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S3.T1.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Audiobooks</span></th>\n<td id=\"S3.T1.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.3.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">33.6</span></td>\n</tr>\n<tr id=\"S3.T1.3.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span id=\"S3.T1.3.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Synthesis</span></th>\n<td id=\"S3.T1.3.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T1.3.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">25.6</span></td>\n</tr>\n<tr id=\"S3.T1.3.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span id=\"S3.T1.3.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">M\u00edleGl\u00f3r</span></th>\n<td id=\"S3.T1.3.4.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T1.3.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">45.7</span></td>\n</tr>\n<tr id=\"S3.T1.3.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.3.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span id=\"S3.T1.3.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Corpas na Cainte Beo</span></th>\n<td id=\"S3.T1.3.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T1.3.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">200.8</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The data used in these experiments has either been recorded by the ABAIR project or drawn from external sources and are summarised in Table 1. The recordings made in-house are divided into two corpora: M\u00edleGl\u00f3r and Synthesis. The M\u00edleGl\u00f3r (A thousand voices) data collection platform was created with speech recognition development in mind. Dialect-appropriate textual prompts were selected or crafted for recording. The dataset of 45.7h and 369 speakers includes crowdsourced recordings where participants recorded utterances using their own devices in varied recording environments as well as live recordings where the authors had control over the microphones used and the acoustic environment. The meta-data pertaining to the linguistc background of speakers is also collected, enabling selection of L1 vs L2 speakers. The Synthesis corpus of 25.6h is comprised of recordings of 5 L1 speakers used to create the ABAIR synthetic voices."
        ]
    },
    "S3.T2": {
        "caption": "Table 2:  Breakdown of validation and test sets with number of speakers and duration",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Breakdown of validation and test sets with number of speakers and duration</figcaption>\n<table id=\"S3.T2.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S3.T2.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"2\"><span id=\"S3.T2.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Validation set</span></th>\n<th id=\"S3.T2.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"2\"><span id=\"S3.T2.3.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">Test set</span></th>\n</tr>\n<tr id=\"S3.T2.3.2.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.2.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r\"><span id=\"S3.T2.3.2.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Dialect</span></th>\n<th id=\"S3.T2.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T2.3.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">#spks</span></th>\n<th id=\"S3.T2.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S3.T2.3.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">dur (h)</span></th>\n<th id=\"S3.T2.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T2.3.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">#spks</span></th>\n<th id=\"S3.T2.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S3.T2.3.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">dur (h)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.3.3.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S3.T2.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ul</span></th>\n<td id=\"S3.T2.3.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.3.3.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">9</span></td>\n<td id=\"S3.T2.3.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T2.3.3.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.55h</span></td>\n<td id=\"S3.T2.3.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.3.3.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">17</span></td>\n<td id=\"S3.T2.3.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.3.3.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.03h</span></td>\n</tr>\n<tr id=\"S3.T2.3.4.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span id=\"S3.T2.3.4.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Co</span></th>\n<td id=\"S3.T2.3.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.3.4.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4</span></td>\n<td id=\"S3.T2.3.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S3.T2.3.4.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.55h</span></td>\n<td id=\"S3.T2.3.4.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.3.4.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">12</span></td>\n<td id=\"S3.T2.3.4.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.3.4.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.29h</span></td>\n</tr>\n<tr id=\"S3.T2.3.5.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span id=\"S3.T2.3.5.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Mu</span></th>\n<td id=\"S3.T2.3.5.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.3.5.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">5</span></td>\n<td id=\"S3.T2.3.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S3.T2.3.5.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.55h</span></td>\n<td id=\"S3.T2.3.5.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.3.5.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">20</span></td>\n<td id=\"S3.T2.3.5.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.3.5.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.15h</span></td>\n</tr>\n<tr id=\"S3.T2.3.6.4\" class=\"ltx_tr\">\n<th id=\"S3.T2.3.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S3.T2.3.6.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Total</span></th>\n<td id=\"S3.T2.3.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T2.3.6.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">18</span></td>\n<td id=\"S3.T2.3.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t\"><span id=\"S3.T2.3.6.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.66h</span></td>\n<td id=\"S3.T2.3.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T2.3.6.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">49</span></td>\n<td id=\"S3.T2.3.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T2.3.6.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.47h</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The train set contains 290h in total, and the validation and test sets contain 1.7h and 3.5h respectively. These were constructed such that there was no overlap of speakers or utterance texts between the sets. As this paper is focusing on ASR and dialect identification of L1 speakers of Irish, the M\u00edleGl\u00f3r corpus is the most appropriate set to use to construct the validation and test sets. As noted, specific meta-data relating to the linguistic background of each speaker was collected and therefore, including only L1 speakers of Irish in the test sets can be done easily. Also, the authors had control over the text prompts used when recording and could ensure their dialect appropriateness. One issue with this corpus which pertains to Ulster speakers particularly, is that only a limited set of 3000 recording prompts were used for Ul recordings. Therefore, there is less variability of utterance texts in the Ul portion of this corpus, compared to Co and Mu. Avoiding overlap of texts would necessitate a large portion of Ul data to be discarded from any set. To avoid this, a portion 0.2h of Ul data from the Audiobook collection was added to the test set. Details of the validation and test sets are presented in Table 2."
        ]
    },
    "S3.T3": {
        "caption": "Table 3:  Text corpora used for LM training and multi-task fine-tuning",
        "table": "<figure id=\"S3.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Text corpora used for LM training and multi-task fine-tuning</figcaption>\n<table id=\"S3.T3.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T3.3.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"></th>\n<th id=\"S3.T3.3.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T3.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Corpus</span></th>\n<th id=\"S3.T3.3.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T3.3.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">#words</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.3.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S3.T3.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Training</span></th>\n<td id=\"S3.T3.3.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T3.3.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Paracrawl</span></td>\n<td id=\"S3.T3.3.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T3.3.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">63.1m</span></td>\n</tr>\n<tr id=\"S3.T3.3.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.3.3.2.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T3.3.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ConLL17</span></td>\n<td id=\"S3.T3.3.3.2.2\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T3.3.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">49.4m</span></td>\n</tr>\n<tr id=\"S3.T3.3.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S3.T3.3.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Fine-tuning</span></th>\n<td id=\"S3.T3.3.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T3.3.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Historical</span></td>\n<td id=\"S3.T3.3.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T3.3.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.5m</span></td>\n</tr>\n<tr id=\"S3.T3.3.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T3.3.5.4.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T3.3.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Spontaneous Speech</span></td>\n<td id=\"S3.T3.3.5.4.2\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T3.3.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.4m</span></td>\n</tr>\n<tr id=\"S3.T3.3.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T3.3.6.5.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_r\"></th>\n<td id=\"S3.T3.3.6.5.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S3.T3.3.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Training</span></td>\n<td id=\"S3.T3.3.6.5.3\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S3.T3.3.6.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.9m</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The second collection of texts that were used include dialect information at the sentence level, which is generally not available in Irish corpora. One useful source that is tagged with dialect is the Historical Irish Corpus of the Royal Irish Academy. This corpus consists of texts written between 1900-50, before the introduction of the standard written form, so morphosyntactic and lexical markers of dialect are salient in these texts (for more details, see [3]). Alongside this corpus, the transcripts from the entire Spontaneous Speech Corpus were used, as well as the transcripts from the training set. See for Table 3 for information regarding these corpora.",
            "Despite the advance of End-to-End ASR models, the hybrid TDNN-HMM is still a robust model for low-resource languages and was still the best performing model for Irish [31]. A TDNN-HMM model was trained as the baseline to compare with the CTC/Attention encoder-decoder architecture, following the same set-up as [31]. A 4-gram LM is trained using both the training and fine-tuning text corpora listed in Section 3.2 and Table 3.",
            "This experiment explores the usefulness of multi-task shallow fusion. A transformer language model was initially trained with a larger corpus of Irish text and fine-tuned on a smaller dialect-tagged corpus of Irish text for multi-task DID and ASR shallow fusion. For details of the corpora used, see Table 3. A grid-search found 0.3 to be the optimal weight for shallow fusion."
        ]
    },
    "S5.T4": {
        "caption": "Table 4:  Performance of ASR baselines.",
        "table": "<figure id=\"S5.T4\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Performance of ASR baselines.</figcaption>\n<table id=\"S5.T4.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.3.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></th>\n<th id=\"S5.T4.3.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Objective</span></th>\n<th id=\"S5.T4.3.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_rr ltx_border_tt\"><span id=\"S5.T4.3.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">InterCTC</span></th>\n<th id=\"S5.T4.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T4.3.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">WER</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.3.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S5.T4.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">TDNN-HMM</span></td>\n<td id=\"S5.T4.3.2.1.2\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S5.T4.3.2.1.3\" class=\"ltx_td ltx_border_rr ltx_border_t\"></td>\n<td id=\"S5.T4.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.3.2.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.2</span></td>\n</tr>\n<tr id=\"S5.T4.3.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.3.3.2.1\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T4.3.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Conformer</span></td>\n<td id=\"S5.T4.3.3.2.2\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T4.3.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">ASR</span></td>\n<td id=\"S5.T4.3.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_rr\"><span id=\"S5.T4.3.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">yes</span></td>\n<td id=\"S5.T4.3.3.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.3.3.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.8</span></td>\n</tr>\n<tr id=\"S5.T4.3.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.3.4.3.1\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T4.3.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Conformer</span></td>\n<td id=\"S5.T4.3.4.3.2\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T4.3.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">ASR + DID</span></td>\n<td id=\"S5.T4.3.4.3.3\" class=\"ltx_td ltx_align_left ltx_border_rr\"><span id=\"S5.T4.3.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">yes</span></td>\n<td id=\"S5.T4.3.4.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T4.3.4.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.1</span></td>\n</tr>\n<tr id=\"S5.T4.3.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.3.5.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S5.T4.3.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Conformer</span></td>\n<td id=\"S5.T4.3.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S5.T4.3.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">ASR + DID</span></td>\n<td id=\"S5.T4.3.5.4.3\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_rr\"><span id=\"S5.T4.3.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">no</span></td>\n<td id=\"S5.T4.3.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T4.3.5.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.9</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "To evaluate both the effectiveness of InterCTC on DID and ASR performance and the impact of multi-task learning on ASR performance, three Conformer-based models are trained and compared with the hybrid TDNN-HMM baseline. The first Conformer-based model, which will be referred to as Conformer (ASR) and is the second row in Table 4, is trained for ASR only with an ASR InterCTC objective in layers 3, 6 and 9. This model is designed to compare the capability of the model architecture on the ASR task with TDNN-HMM on the ASR task. The second Conformer model, which will be referred to as Conformer (multi-task) and is the third row in Table 4, is trained for multi-task ASR and DID with InterCTC DID and ASR objectives defined for encoder layers 3, 6 and 9.\nThe third model Conformer (no InterCTC), see the fourth row in Table 4, is trained for multi-task ASR and DID without InterCTC.",
            "Table 4 presents the ASR performance of these models. The TDNN-HMM baseline outperforms the best performing Conformer model, specifically Conformer (ASR), by 16.5% relative WER. Conformer (multi-task) performs worse than Conformer (ASR) by 13% relative, suggesting that jointly modelling DID and ASR leads to ASR performance degradation. Conformer (no InterCTC) performs less well, showing that the addition of InterCTC leads to WER improvements."
        ]
    },
    "S5.T5": {
        "caption": "Table 5:  Performance of DID baselines.",
        "table": "<figure id=\"S5.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Performance of DID baselines.</figcaption>\n<table id=\"S5.T5.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.3.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt\"><span id=\"S5.T5.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Model</span></th>\n<th id=\"S5.T5.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S5.T5.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">DID Acc.</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.3.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t\"><span id=\"S5.T5.3.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">ECAPA-TDNN</span></th>\n<td id=\"S5.T5.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T5.3.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">72.5</span></td>\n</tr>\n<tr id=\"S5.T5.3.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr\"><span id=\"S5.T5.3.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Conformer (multitask)</span></th>\n<td id=\"S5.T5.3.3.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.3.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">78.6</span></td>\n</tr>\n<tr id=\"S5.T5.3.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T5.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr\"><span id=\"S5.T5.3.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Conformer (no InterCTC)</span></th>\n<td id=\"S5.T5.3.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T5.3.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">79.7</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "In Table 5, the DID performance of the ECAPA-TDNN is compared with a Conformer (multi-task) and a Conformer (no InterCTC). Both Conformer models outperform the ECAPA-TDNN model by a wide margin. Interestingly, InterCTC with the multi-task objective assigned to layers 3, 6 and 9 does not lead to a gain in DID accuracy compared to the model trained without InterCTC."
        ]
    },
    "S5.T6": {
        "caption": "Table 6:  DID and ASR performance with varying InterCTC settings. Row 1 is Conformer (no InterCTC) and row 7 is Conformer (multi-task) from the baseline experiments",
        "table": "<figure id=\"S5.T6\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>DID and ASR performance with varying InterCTC settings. Row 1 is Conformer (no InterCTC) and row 7 is Conformer (multi-task) from the baseline experiments</figcaption>\n<table id=\"S5.T6.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T6.3.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T6.3.1.1.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt\"></th>\n<th id=\"S5.T6.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\" colspan=\"2\"><span id=\"S5.T6.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Inter-CTC</span></th>\n<th id=\"S5.T6.3.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt\"><span id=\"S5.T6.3.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">DID</span></th>\n<th id=\"S5.T6.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\"><span id=\"S5.T6.3.1.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">WER</span></th>\n</tr>\n<tr id=\"S5.T6.3.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T6.3.2.2.1\" class=\"ltx_td ltx_th ltx_th_column ltx_border_r\"></th>\n<th id=\"S5.T6.3.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\"><span id=\"S5.T6.3.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Multitask</span></th>\n<th id=\"S5.T6.3.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_r\"><span id=\"S5.T6.3.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">DID</span></th>\n<th id=\"S5.T6.3.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r\"><span id=\"S5.T6.3.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Acc</span></th>\n<th id=\"S5.T6.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T6.3.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">All</span></th>\n<th id=\"S5.T6.3.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T6.3.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ul</span></th>\n<th id=\"S5.T6.3.2.2.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T6.3.2.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">Co</span></th>\n<th id=\"S5.T6.3.2.2.8\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T6.3.2.2.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">Mu</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T6.3.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T6.3.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">1*</span></td>\n<td id=\"S5.T6.3.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S5.T6.3.3.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S5.T6.3.3.1.3\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T6.3.3.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">79.7</span></td>\n<td id=\"S5.T6.3.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.9</span></td>\n<td id=\"S5.T6.3.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.6</span></td>\n<td id=\"S5.T6.3.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">20.7</span></td>\n<td id=\"S5.T6.3.3.1.7\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\"><span id=\"S5.T6.3.3.1.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.2</span></td>\n</tr>\n<tr id=\"S5.T6.3.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.4.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">2</span></td>\n<td id=\"S5.T6.3.4.2.2\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T6.3.4.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S5.T6.3.4.2.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\"><span id=\"S5.T6.3.4.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">L 3, 6, 9</span></td>\n<td id=\"S5.T6.3.4.2.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.4.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">78.4</span></td>\n<td id=\"S5.T6.3.4.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.4.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.6</span></td>\n<td id=\"S5.T6.3.4.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.4.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.2</span></td>\n<td id=\"S5.T6.3.4.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.4.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.0</span></td>\n<td id=\"S5.T6.3.4.2.8\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T6.3.4.2.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.4</span></td>\n</tr>\n<tr id=\"S5.T6.3.5.3\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.5.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">3</span></td>\n<td id=\"S5.T6.3.5.3.2\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T6.3.5.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S5.T6.3.5.3.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\"><span id=\"S5.T6.3.5.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">L 3, 6</span></td>\n<td id=\"S5.T6.3.5.3.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.5.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">69.1</span></td>\n<td id=\"S5.T6.3.5.3.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.5.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.7</span></td>\n<td id=\"S5.T6.3.5.3.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.5.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.9</span></td>\n<td id=\"S5.T6.3.5.3.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.5.3.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">20.1</span></td>\n<td id=\"S5.T6.3.5.3.8\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T6.3.5.3.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.8</span></td>\n</tr>\n<tr id=\"S5.T6.3.6.4\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.6.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">4</span></td>\n<td id=\"S5.T6.3.6.4.2\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T6.3.6.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S5.T6.3.6.4.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\"><span id=\"S5.T6.3.6.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">L 3</span></td>\n<td id=\"S5.T6.3.6.4.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.6.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">75.3</span></td>\n<td id=\"S5.T6.3.6.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.6.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">19.4</span></td>\n<td id=\"S5.T6.3.6.4.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.6.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">19.3</span></td>\n<td id=\"S5.T6.3.6.4.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.6.4.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">20.0</span></td>\n<td id=\"S5.T6.3.6.4.8\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T6.3.6.4.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.4</span></td>\n</tr>\n<tr id=\"S5.T6.3.7.5\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.7.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.7.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">5</span></td>\n<td id=\"S5.T6.3.7.5.2\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T6.3.7.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">L 9</span></td>\n<td id=\"S5.T6.3.7.5.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\"><span id=\"S5.T6.3.7.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">L 3, 6</span></td>\n<td id=\"S5.T6.3.7.5.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.7.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">77.0</span></td>\n<td id=\"S5.T6.3.7.5.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.7.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.2</span></td>\n<td id=\"S5.T6.3.7.5.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.7.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.8</span></td>\n<td id=\"S5.T6.3.7.5.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.7.5.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">19.3</span></td>\n<td id=\"S5.T6.3.7.5.8\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T6.3.7.5.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.3</span></td>\n</tr>\n<tr id=\"S5.T6.3.8.6\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.8.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.8.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">6</span></td>\n<td id=\"S5.T6.3.8.6.2\" class=\"ltx_td ltx_align_left\"><span id=\"S5.T6.3.8.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">L 6, 9</span></td>\n<td id=\"S5.T6.3.8.6.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_r\"><span id=\"S5.T6.3.8.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">L 3</span></td>\n<td id=\"S5.T6.3.8.6.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_r\"><span id=\"S5.T6.3.8.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">80.3</span></td>\n<td id=\"S5.T6.3.8.6.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.8.6.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.7</span></td>\n<td id=\"S5.T6.3.8.6.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.8.6.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.4</span></td>\n<td id=\"S5.T6.3.8.6.7\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T6.3.8.6.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.2</span></td>\n<td id=\"S5.T6.3.8.6.8\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S5.T6.3.8.6.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.2</span></td>\n</tr>\n<tr id=\"S5.T6.3.9.7\" class=\"ltx_tr\">\n<td id=\"S5.T6.3.9.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T6.3.9.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">7*</span></td>\n<td id=\"S5.T6.3.9.7.2\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S5.T6.3.9.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">L 3, 6, 9</span></td>\n<td id=\"S5.T6.3.9.7.3\" class=\"ltx_td ltx_nopad_l ltx_align_left ltx_border_bb ltx_border_r\"><span id=\"S5.T6.3.9.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>\n<td id=\"S5.T6.3.9.7.4\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r\"><span id=\"S5.T6.3.9.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">78.6</span></td>\n<td id=\"S5.T6.3.9.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T6.3.9.7.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.1</span></td>\n<td id=\"S5.T6.3.9.7.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T6.3.9.7.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.8</span></td>\n<td id=\"S5.T6.3.9.7.7\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T6.3.9.7.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">19.3</span></td>\n<td id=\"S5.T6.3.9.7.8\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\"><span id=\"S5.T6.3.9.7.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.1</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 6 shows the results of the InterCTC configurations for DID accuracy and WER. Row 1 shows the performance of baseline Conformer (no InterCTC), and row 7 shows the performance for baseline Conformer (multi-task). As mentioned before, the Conformer (no InterCTC) model achieved a DID accuracy of 79.7%. However, in comparison with the models trained with InterCTC, its ASR performance is relatively poor at 18.9% WER, suggesting that InterCTC is most helpful for ASR performance as opposed to the speech classification task of DID. Surprisingly, the models trained with DID InterCTC objectives only, as in rows 2-4, performed worse in DID accuracy than the baseline on row 7, which was trained with multi-task CTC objectives. However, the ASR performance of the these models (rows 2-4) varies considerably: row 2 trained with DID InterCTC objective in layers 3, 6 and 9 garnered the best WER (16.6%) in this experiment; row 4, where the only InterCTC objective was assigned to layer 3, achieved the worst WER in the experiment (19.4%). The best performing system (row 6) is trained with the DID objective in layer 3 and the multi-task objective in layers 6 and 9. This model achieved the highest DID accuracy in this experiment, a boost of 10.8% relative to the ECAPA-TDNN baseline. The same model also achieved the second lowest WER among the models trained for both ASR and DID, with 16.7% WER. This model is chosen as the best configuration of InterCTC objectives for joint DID and ASR modelling for Experiments 2 and 3.",
            "The best configuration (row 6 in Table 6) of Experiment 1 is selected to compare the performance of Conformer and E-branchformer encoders in this experiment. Results are presented in Table 7. E-branchformer Small is the best performing model in terms of DID, with an accuracy of 81.4%, an improvement of 1.1% absolute. The model\u2019s WER performance however is worse, suggesting that the smaller number of trainable parameters more strongly affects WER performance than it does DID performance. E-branchformer Large performs slightly worse than the Conformer model in terms of DID, but it has a relative WER performance gain of 6%.",
            "The present DID results are promising in that they surpass the previous best model trained (ECAPA-TDNN). The best DID accuracy obtained here is 81.5% compared to 73% obtained in [3]. The overall contribution of InterCTC to DID accuracy is slight, as can be seen by comparing row 1 in Table 6 with the other rows. Only in one case (row 6) does the inclusion of InterCTC yield a DID improvement. This differs from what was found in [6] and [20], where InterCTC improved the speech classification accuracy more considerably."
        ]
    },
    "S5.T7": {
        "caption": "Table 7:  DID & ASR performance for Conformer and E-branchformer encoders and multi-task LM shallow fusion.",
        "table": "<figure id=\"S5.T7\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\" style=\"font-size:90%;\"><span class=\"ltx_tag ltx_tag_table\">Table 7: </span>DID &amp; ASR performance for Conformer and E-branchformer encoders and multi-task LM shallow fusion.</figcaption>\n<table id=\"S5.T7.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T7.3.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S5.T7.3.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Encoder</span></th>\n<th id=\"S5.T7.3.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\"><span id=\"S5.T7.3.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">DID</span></th>\n<th id=\"S5.T7.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" colspan=\"4\"><span id=\"S5.T7.3.1.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">WER</span></th>\n</tr>\n<tr id=\"S5.T7.3.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.2.2.1\" class=\"ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r\"></th>\n<th id=\"S5.T7.3.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r\"><span id=\"S5.T7.3.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Acc</span></th>\n<th id=\"S5.T7.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T7.3.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">All</span></th>\n<th id=\"S5.T7.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T7.3.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ul</span></th>\n<th id=\"S5.T7.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T7.3.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">Co</span></th>\n<th id=\"S5.T7.3.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S5.T7.3.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">Mu</span></th>\n</tr>\n<tr id=\"S5.T7.3.3.3\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T7.3.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Conformer</span></th>\n<th id=\"S5.T7.3.3.3.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T7.3.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">80.3</span></th>\n<th id=\"S5.T7.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T7.3.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.7</span></th>\n<th id=\"S5.T7.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T7.3.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.4</span></th>\n<th id=\"S5.T7.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T7.3.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">18.2</span></th>\n<th id=\"S5.T7.3.3.3.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T7.3.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.2</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T7.3.4.1\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.4.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T7.3.4.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">E-Branchformer Small</span></th>\n<th id=\"S5.T7.3.4.1.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T7.3.4.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">81.5</span></th>\n<td id=\"S5.T7.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.3.4.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.7</span></td>\n<td id=\"S5.T7.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.3.4.1.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">17.6</span></td>\n<td id=\"S5.T7.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.3.4.1.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">19.1</span></td>\n<td id=\"S5.T7.3.4.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T7.3.4.1.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">16.3</span></td>\n</tr>\n<tr id=\"S5.T7.3.5.2\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.5.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T7.3.5.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">E-Branchformer Large</span></th>\n<th id=\"S5.T7.3.5.2.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S5.T7.3.5.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">80.0</span></th>\n<td id=\"S5.T7.3.5.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.3.5.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">15.7</span></td>\n<td id=\"S5.T7.3.5.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.3.5.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">15.5</span></td>\n<td id=\"S5.T7.3.5.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.3.5.2.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">17.0</span></td>\n<td id=\"S5.T7.3.5.2.6\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T7.3.5.2.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">14.5</span></td>\n</tr>\n<tr id=\"S5.T7.3.6.3\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.6.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span id=\"S5.T7.3.6.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 + LM</span></th>\n<th id=\"S5.T7.3.6.3.2\" class=\"ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r\"><span id=\"S5.T7.3.6.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">80.8</span></th>\n<td id=\"S5.T7.3.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.3.6.3.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">13.5</span></td>\n<td id=\"S5.T7.3.6.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.3.6.3.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">13.0</span></td>\n<td id=\"S5.T7.3.6.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.3.6.3.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">14.9</span></td>\n<td id=\"S5.T7.3.6.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S5.T7.3.6.3.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">12.3</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The best configuration (row 6 in Table 6) of Experiment 1 is selected to compare the performance of Conformer and E-branchformer encoders in this experiment. Results are presented in Table 7. E-branchformer Small is the best performing model in terms of DID, with an accuracy of 81.4%, an improvement of 1.1% absolute. The model\u2019s WER performance however is worse, suggesting that the smaller number of trainable parameters more strongly affects WER performance than it does DID performance. E-branchformer Large performs slightly worse than the Conformer model in terms of DID, but it has a relative WER performance gain of 6%.",
            "The results for LM shallow fusion can also be seen in Table 7. A slight improvement in DID classification accuracy of 0.8% was gained through shallow fusion, but its most significant contribution is, unsurprisingly, a reduction of WER by 2.2%."
        ]
    }
}