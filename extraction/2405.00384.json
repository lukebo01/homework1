{
    "S3.T1": {
        "caption": "Table 1.  Class-wise Distribution of Unmodifiedand Manipulated Samples in the VADD dataset",
        "table": "<figure id=\"S3.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1. </span>Class-wise Distribution of Unmodifiedand Manipulated Samples in the VADD dataset</figcaption>\n<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\">Class</th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\">Total</th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Unmodified(%)</th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Manipulated (%)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">airport</th>\n<th id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">281</th>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">141 (50.18%)</td>\n<td id=\"S3.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">140 (49.82%)</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">bus</th>\n<th id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">327</th>\n<td id=\"S3.T1.1.3.2.3\" class=\"ltx_td ltx_align_center\">164 (50.15%)</td>\n<td id=\"S3.T1.1.3.2.4\" class=\"ltx_td ltx_align_center\">163 (49.85%)</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">metro</th>\n<th id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">360</th>\n<td id=\"S3.T1.1.4.3.3\" class=\"ltx_td ltx_align_center\">180 (50.00%)</td>\n<td id=\"S3.T1.1.4.3.4\" class=\"ltx_td ltx_align_center\">180 (50.00%)</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">metro station</th>\n<th id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">386</th>\n<td id=\"S3.T1.1.5.4.3\" class=\"ltx_td ltx_align_center\">193 (50.00%)</td>\n<td id=\"S3.T1.1.5.4.4\" class=\"ltx_td ltx_align_center\">193 (50.00%)</td>\n</tr>\n<tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">park</th>\n<th id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">386</th>\n<td id=\"S3.T1.1.6.5.3\" class=\"ltx_td ltx_align_center\">193 (50.00%)</td>\n<td id=\"S3.T1.1.6.5.4\" class=\"ltx_td ltx_align_center\">193 (50.00%)</td>\n</tr>\n<tr id=\"S3.T1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">public square</th>\n<th id=\"S3.T1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">387</th>\n<td id=\"S3.T1.1.7.6.3\" class=\"ltx_td ltx_align_center\">194 (50.13%)</td>\n<td id=\"S3.T1.1.7.6.4\" class=\"ltx_td ltx_align_center\">193 (49.87%)</td>\n</tr>\n<tr id=\"S3.T1.1.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">shopping mall</th>\n<th id=\"S3.T1.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">387</th>\n<td id=\"S3.T1.1.8.7.3\" class=\"ltx_td ltx_align_center\">194 (50.13%)</td>\n<td id=\"S3.T1.1.8.7.4\" class=\"ltx_td ltx_align_center\">193 (49.87%)</td>\n</tr>\n<tr id=\"S3.T1.1.9.8\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">street pedestrian</th>\n<th id=\"S3.T1.1.9.8.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">421</th>\n<td id=\"S3.T1.1.9.8.3\" class=\"ltx_td ltx_align_center\">211 (50.12%)</td>\n<td id=\"S3.T1.1.9.8.4\" class=\"ltx_td ltx_align_center\">210 (49.88%)</td>\n</tr>\n<tr id=\"S3.T1.1.10.9\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">street traffic</th>\n<th id=\"S3.T1.1.10.9.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">402</th>\n<td id=\"S3.T1.1.10.9.3\" class=\"ltx_td ltx_align_center\">201 (50.00%)</td>\n<td id=\"S3.T1.1.10.9.4\" class=\"ltx_td ltx_align_center\">201 (50.00%)</td>\n</tr>\n<tr id=\"S3.T1.1.11.10\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">tram</th>\n<th id=\"S3.T1.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">308</th>\n<td id=\"S3.T1.1.11.10.3\" class=\"ltx_td ltx_align_center\">154 (50.00%)</td>\n<td id=\"S3.T1.1.11.10.4\" class=\"ltx_td ltx_align_center\">154 (50.00%)</td>\n</tr>\n<tr id=\"S3.T1.1.12.11\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.12.11.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_t\"></th>\n<th id=\"S3.T1.1.12.11.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_t\">3645</th>\n<td id=\"S3.T1.1.12.11.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">1825 (50.07%)</td>\n<td id=\"S3.T1.1.12.11.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">1820 (49.93%)</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We introduce the Visual-Audio Discrepancy Detection (VADD) experimental protocol, curated to facilitate research in detecting discrepancies between visual and audio streams in videos. The dataset includes a subset of videos in which the visual content portrays one class (e.g., an outdoor scenery), while the accompanying audio track is sourced from a different class (e.g., the sound of an indoor environment). Aiming to leverage the wealth of visual and auditory data already available in the already existing TAU dataset, additionally expediting the data collection process, our VADD experimental protocol and dataset is created by re-purposing data and providing annotations for the TAU dataset. Specifically, we swap the audio and video streams for half of the videos in the TAU dataset, to create \"manipulated\" samples while keeping the rest of the videos unchanged to have \"unmodified\" samples. We ensured balanced sets of unmodifiedand manipulated samples through the following process (see Table 1 for the resulting distribution of samples across classes):"
        ]
    },
    "S5.T2": {
        "caption": "Table 2.  Evaluation of the proposed visual-audio (VASC), visual (VSC), and audio (ASC) scene classifiers on the TAU dataset, for the 3-class and 10-class variants.",
        "table": "<figure id=\"S5.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2. </span>Evaluation of the proposed visual-audio (VASC), visual (VSC), and audio (ASC) scene classifiers on the TAU dataset, for the 3-class and 10-class variants.</figcaption>\n<table id=\"S5.T2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:50.0pt;\">\n<span id=\"S5.T2.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.1.1.1.1.1\" class=\"ltx_p\">Approach</span>\n</span>\n</td>\n<td id=\"S5.T2.1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T2.1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.1.1.2.1.1\" class=\"ltx_p\">Accuracy (%) on TAU using the 3-class variant</span>\n</span>\n</td>\n<td id=\"S5.T2.1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T2.1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.1.1.3.1.1\" class=\"ltx_p\">Accuracy (%) on TAU using the 10-class variant</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.2.2.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:50.0pt;\">\n<span id=\"S5.T2.1.2.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.2.2.1.1.1\" class=\"ltx_p\">VASC</span>\n</span>\n</td>\n<td id=\"S5.T2.1.2.2.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T2.1.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.2.2.2.1.1\" class=\"ltx_p\">99.95</span>\n</span>\n</td>\n<td id=\"S5.T2.1.2.2.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T2.1.2.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.2.2.3.1.1\" class=\"ltx_p\">97.24</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.3.3.1\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:50.0pt;\">\n<span id=\"S5.T2.1.3.3.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.3.3.1.1.1\" class=\"ltx_p\">ASC</span>\n</span>\n</td>\n<td id=\"S5.T2.1.3.3.2\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:70.0pt;\">\n<span id=\"S5.T2.1.3.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.3.3.2.1.1\" class=\"ltx_p\">99.84</span>\n</span>\n</td>\n<td id=\"S5.T2.1.3.3.3\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:70.0pt;\">\n<span id=\"S5.T2.1.3.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.3.3.3.1.1\" class=\"ltx_p\">78.84</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T2.1.4.4.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b\" style=\"width:50.0pt;\">\n<span id=\"S5.T2.1.4.4.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.4.4.1.1.1\" class=\"ltx_p\">VSC</span>\n</span>\n</td>\n<td id=\"S5.T2.1.4.4.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b\" style=\"width:70.0pt;\">\n<span id=\"S5.T2.1.4.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.4.4.2.1.1\" class=\"ltx_p\">99.93</span>\n</span>\n</td>\n<td id=\"S5.T2.1.4.4.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b\" style=\"width:70.0pt;\">\n<span id=\"S5.T2.1.4.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T2.1.4.4.3.1.1\" class=\"ltx_p\">94.32</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "After confirming the effectiveness of our multimodal model in scene classification using the TAU dataset, we proceed to apply separate visual and audio classifiers to detect discrepancies in the VADD dataset. We train distinct classifiers for each modality and use them to detect the manipulated videos of the VADD dataset. The evaluation of the separate classifiers on the VADD dataset, both for the 3-class and 10-class variants, is included in Table 2. We observe that the audio scene and visual scene classifiers achieve near-perfect performance in the 3-class variant of VADD dataset. This high accuracy suggests that our classifiers can effectively discern the intended scenes within the multimedia content. Consequently, when our model detects a discrepancy between the audio and visual scenes, it indicates a high likelihood of actual inconsistencies in the analyzed media item, minimizing the risk of false positives."
        ]
    },
    "S5.T3": {
        "caption": "Table 3.  Comparison of the proposed baseline method on the VADD dataset.",
        "table": "<figure id=\"S5.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 3. </span>Comparison of the proposed baseline method on the VADD dataset.</figcaption>\n<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:80.0pt;\">\n<span id=\"S5.T3.1.1.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.1.1.1.1.1.1\" class=\"ltx_p\">VADD dataset variant used</span>\n</span>\n</th>\n<th id=\"S5.T3.1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:60.0pt;\">\n<span id=\"S5.T3.1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.1.1.1.2.1.1\" class=\"ltx_p\">F1-score (%) of the proposed method</span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.2.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:80.0pt;\">\n<span id=\"S5.T3.1.2.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.1.2.1.1.1.1\" class=\"ltx_p\">3-class VADD</span>\n</span>\n</td>\n<td id=\"S5.T3.1.2.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:60.0pt;\">\n<span id=\"S5.T3.1.2.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.1.2.1.2.1.1\" class=\"ltx_p\">95.54</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T3.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T3.1.3.2.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b\" style=\"width:80.0pt;\">\n<span id=\"S5.T3.1.3.2.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.1.3.2.1.1.1\" class=\"ltx_p\">10-class VADD</span>\n</span>\n</td>\n<td id=\"S5.T3.1.3.2.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b\" style=\"width:60.0pt;\">\n<span id=\"S5.T3.1.3.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T3.1.3.2.2.1.1\" class=\"ltx_p\">79.16</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We evaluate the effectiveness of the proposed baseline method for detecting visual-audio discrepancies on the VADD dataset, with the findings being reported in Table 3. Our assessment reveals notable differences between the 3-class and 10-class variants. The 3-class variant demonstrates higher accuracy, achieving an F1-score of 95.54%. This outcome is expected due to the reduced class complexity. However, it\u2019s crucial to include the 10-class variant for a more realistic and challenging evaluation, reflecting the complexities of real-world multimedia content. When applied to the 10-class variant, the baseline method achieves a lower F1-score of 79.16%. Figure 3 displays the confusion matrix for our visual-audio scene classifier on the 10-class variant of the VADD dataset, where the x-axis represents the predicted labels and the y-axis represents the true labels. A brief analysis of the results using confusion matrices showed that our classifier exhibited confusion between \"tram\" and \"bus\", \"public square\" and \"street pedestrian\", as well as \"airports\" and \"metro station\" class tuples, contributing to the lower performance of our method in the 10-class variant of the problem. Researchers can leverage both variants to evaluate their detection methods across different complexity levels."
        ]
    },
    "S5.T4": {
        "caption": "Table 4.  Comparison of different design options for the proposed classifier",
        "table": "<figure id=\"S5.T4\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 4. </span>Comparison of different design options for the proposed classifier</figcaption>\n<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:50.0pt;\"></th>\n<th id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.1.1.2.1.1\" class=\"ltx_p\">Approach</span>\n</span>\n</th>\n<th id=\"S5.T4.1.1.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.1.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.1.1.3.1.1\" class=\"ltx_p\">Accuracy (%) on TAU dataset</span>\n</span>\n</th>\n</tr>\n<tr id=\"S5.T4.1.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.1.2.2.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:50.0pt;\"></th>\n<th id=\"S5.T4.1.2.2.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.2.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.2.2.2.1.1\" class=\"ltx_p\">Proposed (LS + DA + + Double FC)</span>\n</span>\n</th>\n<th id=\"S5.T4.1.2.2.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.2.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.2.2.3.1.1\" class=\"ltx_p\"><span id=\"S5.T4.1.2.2.3.1.1.1\" class=\"ltx_text ltx_font_bold\">97.24</span></span>\n</span>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.3.1.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:50.0pt;\">\n<span id=\"S5.T4.1.3.1.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.3.1.1.1.1\" class=\"ltx_p\">\n<span id=\"S5.T4.1.3.1.1.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<span id=\"S5.T4.1.3.1.1.1.1.1.1\" class=\"ltx_tr\">\n<span id=\"S5.T4.1.3.1.1.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Scenario #1:</span></span>\n<span id=\"S5.T4.1.3.1.1.1.1.1.2\" class=\"ltx_tr\">\n<span id=\"S5.T4.1.3.1.1.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Self-attention</span></span>\n<span id=\"S5.T4.1.3.1.1.1.1.1.3\" class=\"ltx_tr\">\n<span id=\"S5.T4.1.3.1.1.1.1.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">variants</span></span>\n<span id=\"S5.T4.1.3.1.1.1.1.1.4\" class=\"ltx_tr\">\n<span id=\"S5.T4.1.3.1.1.1.1.1.4.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">(all using DA)</span></span>\n</span></span>\n</span>\n</td>\n<td id=\"S5.T4.1.3.1.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.3.1.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.3.1.2.1.1\" class=\"ltx_p\">ES</span>\n</span>\n</td>\n<td id=\"S5.T4.1.3.1.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.3.1.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.3.1.3.1.1\" class=\"ltx_p\">91.73</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T4.1.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.4.2.1\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:50.0pt;\"></td>\n<td id=\"S5.T4.1.4.2.2\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.4.2.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.4.2.2.1.1\" class=\"ltx_p\">MS</span>\n</span>\n</td>\n<td id=\"S5.T4.1.4.2.3\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.4.2.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.4.2.3.1.1\" class=\"ltx_p\">96.98</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T4.1.5.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.5.3.1\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:50.0pt;\"></td>\n<td id=\"S5.T4.1.5.3.2\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.5.3.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.5.3.2.1.1\" class=\"ltx_p\">NS</span>\n</span>\n</td>\n<td id=\"S5.T4.1.5.3.3\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.5.3.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.5.3.3.1.1\" class=\"ltx_p\">94.16</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T4.1.6.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.6.4.1\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:50.0pt;\"></td>\n<td id=\"S5.T4.1.6.4.2\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.6.4.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.6.4.2.1.1\" class=\"ltx_p\">ES + LS</span>\n</span>\n</td>\n<td id=\"S5.T4.1.6.4.3\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.6.4.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.6.4.3.1.1\" class=\"ltx_p\">93.75</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T4.1.7.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.7.5.1\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:50.0pt;\"></td>\n<td id=\"S5.T4.1.7.5.2\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.7.5.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.7.5.2.1.1\" class=\"ltx_p\">MS + LS</span>\n</span>\n</td>\n<td id=\"S5.T4.1.7.5.3\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.7.5.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.7.5.3.1.1\" class=\"ltx_p\">97.02</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T4.1.8.6\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.8.6.1\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:50.0pt;\"></td>\n<td id=\"S5.T4.1.8.6.2\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.8.6.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.8.6.2.1.1\" class=\"ltx_p\">ES + MS</span>\n</span>\n</td>\n<td id=\"S5.T4.1.8.6.3\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.8.6.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.8.6.3.1.1\" class=\"ltx_p\">92.65</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T4.1.9.7\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.9.7.1\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:50.0pt;\"></td>\n<td id=\"S5.T4.1.9.7.2\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.9.7.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.9.7.2.1.1\" class=\"ltx_p\">ES + MS + LS</span>\n</span>\n</td>\n<td id=\"S5.T4.1.9.7.3\" class=\"ltx_td ltx_align_justify ltx_align_middle\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.9.7.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.9.7.3.1.1\" class=\"ltx_p\">94.05</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T4.1.10.8\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.10.8.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:50.0pt;\">\n<span id=\"S5.T4.1.10.8.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.10.8.1.1.1\" class=\"ltx_p\">Scenario #2</span>\n</span>\n</td>\n<td id=\"S5.T4.1.10.8.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.10.8.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.10.8.2.1.1\" class=\"ltx_p\">Proposed without DA</span>\n</span>\n</td>\n<td id=\"S5.T4.1.10.8.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.10.8.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.10.8.3.1.1\" class=\"ltx_p\">96.98</span>\n</span>\n</td>\n</tr>\n<tr id=\"S5.T4.1.11.9\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.11.9.1\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_t\" style=\"width:50.0pt;\">\n<span id=\"S5.T4.1.11.9.1.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.11.9.1.1.1\" class=\"ltx_p\">Scenario #3</span>\n</span>\n</td>\n<td id=\"S5.T4.1.11.9.2\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_t\" style=\"width:80.0pt;\">\n<span id=\"S5.T4.1.11.9.2.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.11.9.2.1.1\" class=\"ltx_p\">Single FC layer</span>\n</span>\n</td>\n<td id=\"S5.T4.1.11.9.3\" class=\"ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_t\" style=\"width:70.0pt;\">\n<span id=\"S5.T4.1.11.9.3.1\" class=\"ltx_inline-block ltx_align_top\">\n<span id=\"S5.T4.1.11.9.3.1.1\" class=\"ltx_p\">97.18</span>\n</span>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The outcome of the ablation study is reported in Table 4. Regarding the position of a self-attention mechanism in the model, its placement can significantly influence the model\u2019s ability to capture relevant information and dependencies within the input data. Placing self-attention early in the model allows the network to attend to fine-grained features at lower levels of abstraction, potentially enhancing feature learning. On the other hand, positioning self-attention later in the model enables the network to integrate contextual information and global dependencies, facilitating better aggregation of information from multiple input sources. In our case, positioning the self-attention late in the network works best for the embedding aggregation scheme (LS &gt;&gt; [ES, MS]). Furthermore, overloading the network with more than one self-attention layer seems to \"short-circuit\" the model, leading to significantly reduced accuracy (LS, ES, MS &gt;&gt; [ES+LS, MS+LS, ES+MS, ES+MS+LS]). Data augmentation schemes benefit training by increasing the diversity and richness of the training data, thereby improving the model\u2019s ability to generalize to unseen examples. Employing a data augmentation scheme increases accuracy on the specific task. Finally, the performance improvement observed when using two fully connected (FC) layers instead of one can be attributed to the increased capacity and expressiveness of the deeper network architecture. Our experiments across all scenarios consistently demonstrate that the chosen model architecture, data augmentation strategies, and the number of FC layers used, are well-suited for the task at hand."
        ]
    }
}