{
    "S3.T1": {
        "caption": "Table 1:  Examples of our transcription, IPA, and corresponding translation.",
        "table": "<figure id=\"S3.T1\" class=\"ltx_table\">\n<div id=\"S3.T1.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:368.6pt;height:206pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(103.8pt,-58.0pt) scale(2.2885213226435,2.2885213226435) ;\">\n<table id=\"S3.T1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Transcription</span></th>\n<th id=\"S3.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T1.1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">IPA</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">mi\u014b nj bitk sw.</td>\n<td id=\"S3.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">mi\u014b ni pitk sw.</td>\n</tr>\n<tr id=\"S3.T1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_center\" colspan=\"2\">(Translation: My mother is a teacher.)</td>\n</tr>\n<tr id=\"S3.T1.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">do\u0161n \u01f0o.</td>\n<td id=\"S3.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">to\u2005zn d\u2005zo.</td>\n</tr>\n<tr id=\"S3.T1.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_b\" colspan=\"2\">(Translation: Come on in.)</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Examples of our transcription, IPA, and corresponding translation.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The phoneme transcription system in this study is based on Kim et al. (2008). While it shares similarities with the International Phonetic Alphabet (IPA), our system incorporates some distinctions. Specifically, /b, d, g/ represent voiceless unaspirated stops, and /p, t, k/ denote voiceless aspirated stops. Notably, Colloquial Manchu lacks voiced stops, making this transcription system more practical than using diacritic /h/ to indicate aspiration. Next, /\u01f0, \u010d, \u0161/ denote voiceless palatal sounds. In IPA system, corresponding sound symbols are [, \u00e7, ]. But /\u01f0/ is not voiced unlike [], and /\u010d/ is the aspirated sound, [\u010dh]. Some examples can be found in Table 1."
        ]
    },
    "S3.T2": {
        "caption": "Table 2:  The duration of audio files(.wav) in minutes before and after augmentation.",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Before Augmentation</span></th>\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S3.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Duration</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">train</td>\n<td id=\"S3.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">81 min</td>\n</tr>\n<tr id=\"S3.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.3.2.1\" class=\"ltx_td ltx_align_center\">test</td>\n<td id=\"S3.T2.1.3.2.2\" class=\"ltx_td ltx_align_center\">9.5 min</td>\n</tr>\n<tr id=\"S3.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.4.3.1.1\" class=\"ltx_text ltx_font_bold\">After Augmentation</span></td>\n<td id=\"S3.T2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.4.3.2.1\" class=\"ltx_text ltx_font_bold\">Duration</span></td>\n</tr>\n<tr id=\"S3.T2.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">train</td>\n<td id=\"S3.T2.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">326.5 min</td>\n</tr>\n<tr id=\"S3.T2.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_b\">test</td>\n<td id=\"S3.T2.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_b\">9.5 min</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>The duration of audio files(.wav) in minutes before and after augmentation.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "By implementing the above techniques through WavAugment111https://github.com/facebookresearch/WavAugment provided by Kharitonov et al. (2020), we expand the dataset by 100% respectively, to a total of 400%, significantly enriching the available train data. Notable is the fact that data augmentation is implemented after the separation of train and test data, ensuring more reliable test results by preventing overlap between the train and test sets. The size of data before and after augmentation is described in Table 2."
        ]
    },
    "S5.T3": {
        "caption": "Table 3:  The performance of Wav2Vec2-XLSR-53 each trained with data before and after augmentation.",
        "table": "<figure id=\"S5.T3\" class=\"ltx_table\">\n<table id=\"S5.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Data Augmentation</span></th>\n<th id=\"S5.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">CER</span></th>\n<th id=\"S5.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">WER</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T3.1.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">before</span></th>\n<td id=\"S5.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">0.13</td>\n<td id=\"S5.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.44</td>\n</tr>\n<tr id=\"S5.T3.1.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T3.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S5.T3.1.3.2.1.1\" class=\"ltx_text ltx_font_bold\">after</span></th>\n<td id=\"S5.T3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.1.3.2.2.1\" class=\"ltx_text ltx_font_bold\">0.11</span></td>\n<td id=\"S5.T3.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S5.T3.1.3.2.3.1\" class=\"ltx_text ltx_font_bold\">0.31</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>The performance of Wav2Vec2-XLSR-53 each trained with data before and after augmentation.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The experimental results prove the significance of data augmentation in fine-tuning the base model. As depicted in Table 3, using augmented data at the training stage clearly improves the performance, specifically dropping CER by 0.02 and WER by 0.13, indicating the effectiveness using augmented data described in Section 3.3."
        ]
    },
    "S5.T4": {
        "caption": "Table 4:  Examples of inference results from  ManWav . Wrong predictions are marked red and the corresponding answers are marked blue.",
        "table": "<figure id=\"S5.T4\" class=\"ltx_table\">\n<table id=\"S5.T4.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model Prediction</span></td>\n<td id=\"S5.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S5.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Actual Transcription</span></td>\n</tr>\n<tr id=\"S5.T4.1.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">si jawu\u010di bi gl jaam si jawu\u010di bi gl jaam</td>\n<td id=\"S5.T4.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">si jawu\u010di bi gl jaam si jawu\u010di bi gl jaam</td>\n</tr>\n<tr id=\"S5.T4.1.3.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">tl <span id=\"S5.T4.1.3.3.1.1\" class=\"ltx_text\" style=\"color:#FF0000;\">am</span> <span id=\"S5.T4.1.3.3.1.2\" class=\"ltx_text\" style=\"color:#FF0000;\">dulk</span> ani mk i\u010di bo alx</td>\n<td id=\"S5.T4.1.3.3.2\" class=\"ltx_td ltx_align_center\">tl <span id=\"S5.T4.1.3.3.2.1\" class=\"ltx_text\" style=\"color:#0000FF;\">am</span> <span id=\"S5.T4.1.3.3.2.2\" class=\"ltx_text\" style=\"color:#0000FF;\">dulk</span> ani mk i\u010di bo alx</td>\n</tr>\n<tr id=\"S5.T4.1.4.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">bi sajw wak bi sajw wak</td>\n<td id=\"S5.T4.1.4.4.2\" class=\"ltx_td ltx_align_center\">bi sajw wak bi sajw wak</td>\n</tr>\n<tr id=\"S5.T4.1.5.5\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">bi sisk bitk xolal ba d jom mutulko</td>\n<td id=\"S5.T4.1.5.5.2\" class=\"ltx_td ltx_align_center\">bi sisk bitk xolal ba d jom mutulko</td>\n</tr>\n<tr id=\"S5.T4.1.6.6\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.6.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\">min do bitk xolal ba joxo</td>\n<td id=\"S5.T4.1.6.6.2\" class=\"ltx_td ltx_align_center\">min do bitk xolal ba joxo</td>\n</tr>\n<tr id=\"S5.T4.1.7.7\" class=\"ltx_tr\">\n<td id=\"S5.T4.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">odun gjak <span id=\"S5.T4.1.7.7.1.1\" class=\"ltx_text\" style=\"color:#FF0000;\">\u0161axulo</span> odun gjak <span id=\"S5.T4.1.7.7.1.2\" class=\"ltx_text\" style=\"color:#FF0000;\">\u0161axulo</span>\n</td>\n<td id=\"S5.T4.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\">odun gjak <span id=\"S5.T4.1.7.7.2.1\" class=\"ltx_text\" style=\"color:#0000FF;\">\u0161awulo</span> odun gjak <span id=\"S5.T4.1.7.7.2.2\" class=\"ltx_text\" style=\"color:#0000FF;\">\u0161awulo</span>\n</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Examples of inference results from <span id=\"S5.T4.3.1\" class=\"ltx_text ltx_font_italic\">ManWav</span>. Wrong predictions are marked red and the corresponding answers are marked blue.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Moreover, Table 4 shows the promising capabilities of ManWav in the Manchu speech recognition task. The achieved accuracy is particularly noteworthy given the limited availability of Manchu speech data and considering that Wav2Vec2-XLSR-53 is not initially pre-trained on Manchu.",
            "First, there are some uncaptured or mismatched // sounds in the inference results, particularly in word-final or between sonorants (e.g., /l/) and stops. This occurs because // can be neutralized with other vowels or even deleted, posing challenges in accurate transcription. As shown in table 4, the locative marker de and am \u2018dad\u2019 are sometimes captured as d and am, indicating apocope of //. The loss of // is also evident in dulke, which originally included // between the sonorant /l/ and the stop /k/."
        ]
    },
    "S5.T5": {
        "caption": "Table 5:  Observed mismatch examples from the inference results written in phonological notations. R refers to sonorants, C consonants, and V vowels. # means boundary of words; __# means word-final position.",
        "table": "<figure id=\"S5.T5\" class=\"ltx_table\">\n<table id=\"S5.T5.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Mismatch Types</span></th>\n<th id=\"S5.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S5.T5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Examples</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.1.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">(1)  / __#, R__C</td>\n<td id=\"S5.T5.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">d : d, am : am, dulk : dulk</td>\n</tr>\n<tr id=\"S5.T5.1.3.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.3.2.1\" class=\"ltx_td ltx_align_center\">(2) n, m / __#</td>\n<td id=\"S5.T5.1.3.2.2\" class=\"ltx_td ltx_align_center\">gunin : gunim, ilan : ila</td>\n</tr>\n<tr id=\"S5.T5.1.4.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.4.3.1\" class=\"ltx_td ltx_align_center\">(3) assimilation</td>\n<td id=\"S5.T5.1.4.3.2\" class=\"ltx_td ltx_align_center\">damgu : daNgu</td>\n</tr>\n<tr id=\"S5.T5.1.5.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_b\">(4) w : x / V__V</td>\n<td id=\"S5.T5.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\">\u0161axulo : \u0161awulo</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Observed mismatch examples from the inference results written in phonological notations. R refers to sonorants, C consonants, and V vowels. # means boundary of words; __# means word-final position.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The above four types of mismatch and corresponding examples are elaborated in Table 5."
        ]
    }
}