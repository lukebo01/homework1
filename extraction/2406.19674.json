{
    "S3.T1": {
        "caption": "Table 1:  Training data statistics with breakdown per language and availability of punctuation and capitalization (PnC).",
        "table": "<figure id=\"S3.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Training data statistics with breakdown per language and availability of punctuation and capitalization (PnC).</figcaption>\n<div id=\"S3.T1.1\" class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:433.6pt;height:173.3pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(29.9pt,-12.0pt) scale(1.1600131865139,1.1600131865139) ;\">\n<table id=\"S3.T1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Language</span></td>\n<td id=\"S3.T1.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S3.T1.1.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.1.1.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.1.1.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Public</span></td>\n</tr>\n<tr id=\"S3.T1.1.1.1.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.1.1.1.2.1.2.1.1\" class=\"ltx_text ltx_font_bold\">+ In-house [K hours]</span></td>\n</tr>\n</table>\n</td>\n<td id=\"S3.T1.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S3.T1.1.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.1.1.1.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.1.1.1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">PnC</span></td>\n</tr>\n<tr id=\"S3.T1.1.1.1.1.3.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.1.1.1.3.1.2.1.1\" class=\"ltx_text ltx_font_bold\">[K hours]</span></td>\n</tr>\n</table>\n</td>\n<td id=\"S3.T1.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\n<table id=\"S3.T1.1.1.1.1.4.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.1.1.1.4.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.1.1.1.4.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Dur. [s]</span></td>\n</tr>\n<tr id=\"S3.T1.1.1.1.1.4.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.1.1.1.4.1.2.1.1\" class=\"ltx_text ltx_font_bold\">[Min, Max]</span></td>\n</tr>\n</table>\n</td>\n<td id=\"S3.T1.1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">\n<table id=\"S3.T1.1.1.1.1.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T1.1.1.1.1.5.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.5.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.1.1.1.5.1.1.1.1\" class=\"ltx_text ltx_font_bold\"># Utterances</span></td>\n</tr>\n<tr id=\"S3.T1.1.1.1.1.5.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.1.5.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\"><span id=\"S3.T1.1.1.1.1.5.1.2.1.1\" class=\"ltx_text ltx_font_bold\">[M]</span></td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"S3.T1.1.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">English</td>\n<td id=\"S3.T1.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">25.5 + 37.9</td>\n<td id=\"S3.T1.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">38.5</td>\n<td id=\"S3.T1.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">[1, 40]</td>\n<td id=\"S3.T1.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">24</td>\n</tr>\n<tr id=\"S3.T1.1.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">German</td>\n<td id=\"S3.T1.1.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2.5 + 3.6</td>\n<td id=\"S3.T1.1.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">6.1</td>\n<td id=\"S3.T1.1.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">[1, 20]</td>\n<td id=\"S3.T1.1.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">2.4</td>\n</tr>\n<tr id=\"S3.T1.1.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Spanish</td>\n<td id=\"S3.T1.1.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.4 + 5.2</td>\n<td id=\"S3.T1.1.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.4</td>\n<td id=\"S3.T1.1.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">[1, 20]</td>\n<td id=\"S3.T1.1.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">3.8</td>\n</tr>\n<tr id=\"S3.T1.1.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">French</td>\n<td id=\"S3.T1.1.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.8 + 3.3</td>\n<td id=\"S3.T1.1.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.8</td>\n<td id=\"S3.T1.1.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">[0.5, 40]</td>\n<td id=\"S3.T1.1.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">2.5</td>\n</tr>\n<tr id=\"S3.T1.1.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">Non-speech</td>\n<td id=\"S3.T1.1.1.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.3 + 0.0</td>\n<td id=\"S3.T1.1.1.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NA</td>\n<td id=\"S3.T1.1.1.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">[0.47, 10]</td>\n<td id=\"S3.T1.1.1.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1</td>\n</tr>\n<tr id=\"S3.T1.1.1.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt\">Total</td>\n<td id=\"S3.T1.1.1.7.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">31.5 + 50</td>\n<td id=\"S3.T1.1.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">47.8</td>\n<td id=\"S3.T1.1.1.7.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">NA</td>\n<td id=\"S3.T1.1.1.7.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_tt\">32.8</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Training data. Canary was trained on a mixture of public and in-house datasets. Table 1 shows the composition of training data for the ASR task (81.5K hours in total).\nThe public portion of English is composed of LibriSpeech, Fisher Corpus, Switchboard-1, WSJ-0 &amp; WSJ-1, National Speech Corpus (Part 1, Part 6), VCTK, VoxPopuli (EN), Europarl-ASR (EN), Multilingual LibriSpeech (MLS)-EN (2k hour subset), Mozilla Common Voice (MCV)-7.0, People's Speech (12K hour subset), MCV-11.0 (1.5k hour subset).\n800 hour subset of MCV-12.0, 1.5K hour subset of MLS and 200 hour subset of VoxPopuli were gathered from public sources for German.\nFor Spanish, 395 hours from MCV-12.0, 780 hours from MLS, 108 hours from VoxPopuli and 141 hours from Fisher were collected from public domain.\nSimilarly for French, 708 hour subset from MCV-12.0, 926 hours from MLS and 165 hours from VoxPopuli were used from public domain. Table 1 also shows number of hours with punctuation and capitalization (PnC) for each language. PnC was obtained from respective dataset metadata when available (e.g. LibriSpeech). Alternatively, PnC was restored using neural models for some datasets. PnC data was further processed to remove all punctuation marks except five (',?.!). Text normalization was applied to ground truth. 300 hours of non-Speech data (AudioSet strongly-labelled subset portion of [13]) is used to improve model robustness. Data for AST was solely obtained by generating synthetic labels using Neural Machine Translation models [14, 15] without using additional datasets. 43K hours of English ASR data from Table 1 was used to generate training data for English\u2192\u2192\\rightarrowX (X: German, Spanish, French). All available data from Table 1 for German, Spanish, French languages was used to prepare X \u2192\u2192\\rightarrow English direction of translation data. Further, a 4.8K hour English \u2192\u2192\\rightarrow German translation dataset from [16] was also used, which in-itself was also pseudo-labeled, bringing the total size to 86.3K hours.",
            "Training settings. Canary uses FastConformer encoder of XL size from  [7]. Along with convolution sub-sampling block, it has 24 conformer layers with model dimension 1024, projection dimension 4096, convolution kernel size 9 and 8 attention heads, with a total parameter count of 0.6B. The decoder is a regular transformer decoder [2], with 24 layers of dimension 1024, projection dimension 4096, and 8 attention heads, with a total parameter count of 0.4B. The decoder uses fixed-positional encoding.\nThe encoder consumes audio in the form of 128-dim log-mel features extracted every 10 msec over a window of 25 msec (preliminary experiments didn't show significant difference between 80-dim and 128-dim log-mel features for ASR, but 128-dim features showed consistent improvement for AST).\nLhotse [19] was used for dataloading with a batch duration of 360 sec per GPU, quadratic_duration of 20 sec, buffer_size of 20000, shuffle_buffer_size of 10000 and num_buckets as 31. To balance multiple languages and datasets, training examples were sampled based on the probability distribution ps\u223c(nsN)\u03b1similar-tosubscript\ud835\udc5d\ud835\udc60superscriptsubscript\ud835\udc5b\ud835\udc60\ud835\udc41\ud835\udefcp_{s}\\sim\\left(\\frac{n_{s}}{N}\\right)^{\\alpha}, where s\ud835\udc60s represents a stratum (e.g., a language or a dataset), nssubscript\ud835\udc5b\ud835\udc60n_{s} is the number of hours for stratum s\ud835\udc60s, N\ud835\udc41N is the total number of hours, and \u03b1\ud835\udefc\\alpha is the up-sampling factor [20]. We implemented a two-level hierarchical stratification of the training corpus: initially at the language level and subsequently within each language by dataset. The final weight assigned to a dataset is the product of these two probabilities. In both stratification levels, we set \u03b1=0.5\ud835\udefc0.5\\alpha=0.5. Non-speech audio has been treated as a separate language for the purposes of sampling.\nThe model was trained in 2 stages using NVIDIA NeMo [21] framework. In stage-1, the model was trained for 150K updates. We used AdamW with a peak learning rate (LR) of 3e-4 and weight decay of 1e-3. The learning rate was warmed up over 2.5K steps and annealed as per Noam scheduling. The encoder was initialized from an XL version of [22], whose training data was a subset of Table 1. Encoder initialization helped model converge faster and achieve better metrics overall. The decoder was random initialized. Stage-2 was trained for 75K updates with a peak LR of 2e-5, with remaining hyperparameters being same as stage-1. The main difference between both stages is the inclusion of Non-speech dataset from Table 1 in stage-2 (Note that this 2 stage training is merely practical convenience to allow for faster experimentation wrt to robustness and is not a necessity). In both stages, 128 A100 (80GB) GPUs were used.",
            "Training settings. Canary uses FastConformer encoder of XL size from  [7]. Along with convolution sub-sampling block, it has 24 conformer layers with model dimension 1024, projection dimension 4096, convolution kernel size 9 and 8 attention heads, with a total parameter count of 0.6B. The decoder is a regular transformer decoder [2], with 24 layers of dimension 1024, projection dimension 4096, and 8 attention heads, with a total parameter count of 0.4B. The decoder uses fixed-positional encoding.\nThe encoder consumes audio in the form of 128-dim log-mel features extracted every 10 msec over a window of 25 msec (preliminary experiments didn't show significant difference between 80-dim and 128-dim log-mel features for ASR, but 128-dim features showed consistent improvement for AST).\nLhotse [19] was used for dataloading with a batch duration of 360 sec per GPU, quadratic_duration of 20 sec, buffer_size of 20000, shuffle_buffer_size of 10000 and num_buckets as 31. To balance multiple languages and datasets, training examples were sampled based on the probability distribution ps\u223c(nsN)\u03b1similar-tosubscript\ud835\udc5d\ud835\udc60superscriptsubscript\ud835\udc5b\ud835\udc60\ud835\udc41\ud835\udefcp_{s}\\sim\\left(\\frac{n_{s}}{N}\\right)^{\\alpha}, where s\ud835\udc60s represents a stratum (e.g., a language or a dataset), nssubscript\ud835\udc5b\ud835\udc60n_{s} is the number of hours for stratum s\ud835\udc60s, N\ud835\udc41N is the total number of hours, and \u03b1\ud835\udefc\\alpha is the up-sampling factor [20]. We implemented a two-level hierarchical stratification of the training corpus: initially at the language level and subsequently within each language by dataset. The final weight assigned to a dataset is the product of these two probabilities. In both stratification levels, we set \u03b1=0.5\ud835\udefc0.5\\alpha=0.5. Non-speech audio has been treated as a separate language for the purposes of sampling.\nThe model was trained in 2 stages using NVIDIA NeMo [21] framework. In stage-1, the model was trained for 150K updates. We used AdamW with a peak learning rate (LR) of 3e-4 and weight decay of 1e-3. The learning rate was warmed up over 2.5K steps and annealed as per Noam scheduling. The encoder was initialized from an XL version of [22], whose training data was a subset of Table 1. Encoder initialization helped model converge faster and achieve better metrics overall. The decoder was random initialized. Stage-2 was trained for 75K updates with a peak LR of 2e-5, with remaining hyperparameters being same as stage-1. The main difference between both stages is the inclusion of Non-speech dataset from Table 1 in stage-2 (Note that this 2 stage training is merely practical convenience to allow for faster experimentation wrt to robustness and is not a necessity). In both stages, 128 A100 (80GB) GPUs were used."
        ]
    },
    "S3.T2": {
        "caption": "Table 2:  WER (%) results on ASR benchmarks. Baseline model predictions are generated using respective public checkpoints. Ground-truth and predictions are normalized using WhisperNormalizer [ 1 ] . Canary achieves lowest WER in 10 out of 12 test sets across all languages.",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>WER (%) results on ASR benchmarks. Baseline model predictions are generated using respective public checkpoints. Ground-truth and predictions are normalized using WhisperNormalizer<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib1\" title=\"\" class=\"ltx_ref\">1</a>]</cite>. Canary achieves lowest WER in 10 out of 12 test sets across all languages.</figcaption>\n<div id=\"S3.T2.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:74pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-152.6pt,26.0pt) scale(0.586963417761087,0.586963417761087) ;\">\n<table id=\"S3.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text\">Model (WER <math id=\"S3.T2.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T2.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T2.1.1.1.1.1.m1.1.1\" xref=\"S3.T2.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.1.1.1.1.1.m1.1b\"><ci id=\"S3.T2.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T2.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</span></th>\n<td id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\">En</td>\n<td id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\">De</td>\n<td id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\">Es</td>\n<td id=\"S3.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"3\">Fr</td>\n</tr>\n<tr id=\"S3.T2.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_r\">MCV-16.1</td>\n<td id=\"S3.T2.1.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_r\">MLS</td>\n<td id=\"S3.T2.1.1.2.1.3\" class=\"ltx_td ltx_align_left ltx_border_r\">VoxPopuli</td>\n<td id=\"S3.T2.1.1.2.1.4\" class=\"ltx_td ltx_align_left ltx_border_r\">MCV-16.1</td>\n<td id=\"S3.T2.1.1.2.1.5\" class=\"ltx_td ltx_align_left ltx_border_r\">MLS</td>\n<td id=\"S3.T2.1.1.2.1.6\" class=\"ltx_td ltx_align_left ltx_border_r\">VoxPopuli</td>\n<td id=\"S3.T2.1.1.2.1.7\" class=\"ltx_td ltx_align_left ltx_border_r\">MCV-16.1</td>\n<td id=\"S3.T2.1.1.2.1.8\" class=\"ltx_td ltx_align_left ltx_border_r\">MLS</td>\n<td id=\"S3.T2.1.1.2.1.9\" class=\"ltx_td ltx_align_left ltx_border_r\">VoxPopuli</td>\n<td id=\"S3.T2.1.1.2.1.10\" class=\"ltx_td ltx_align_left ltx_border_r\">MCV-16.1</td>\n<td id=\"S3.T2.1.1.2.1.11\" class=\"ltx_td ltx_align_left ltx_border_r\">MLS</td>\n<td id=\"S3.T2.1.1.2.1.12\" class=\"ltx_td ltx_align_left\">VoxPopuli</td>\n</tr>\n<tr id=\"S3.T2.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">OWSM-v3.1 (1.02B)</th>\n<td id=\"S3.T2.1.1.3.2.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">11.87</td>\n<td id=\"S3.T2.1.1.3.2.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">5.37</td>\n<td id=\"S3.T2.1.1.3.2.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">7.04</td>\n<td id=\"S3.T2.1.1.3.2.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">9.24</td>\n<td id=\"S3.T2.1.1.3.2.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">10.49</td>\n<td id=\"S3.T2.1.1.3.2.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">16.25</td>\n<td id=\"S3.T2.1.1.3.2.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">9.59</td>\n<td id=\"S3.T2.1.1.3.2.9\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">8.84</td>\n<td id=\"S3.T2.1.1.3.2.10\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">10.17</td>\n<td id=\"S3.T2.1.1.3.2.11\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">13.69</td>\n<td id=\"S3.T2.1.1.3.2.12\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">11.75</td>\n<td id=\"S3.T2.1.1.3.2.13\" class=\"ltx_td ltx_align_right ltx_border_tt\">12.61</td>\n</tr>\n<tr id=\"S3.T2.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">SeamlessM4T-medium (1.2B)</th>\n<td id=\"S3.T2.1.1.4.3.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">10.25</td>\n<td id=\"S3.T2.1.1.4.3.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">7.05</td>\n<td id=\"S3.T2.1.1.4.3.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">6.06</td>\n<td id=\"S3.T2.1.1.4.3.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">9.32</td>\n<td id=\"S3.T2.1.1.4.3.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">8.12</td>\n<td id=\"S3.T2.1.1.4.3.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">12.95</td>\n<td id=\"S3.T2.1.1.4.3.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">7.25</td>\n<td id=\"S3.T2.1.1.4.3.9\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">5.25</td>\n<td id=\"S3.T2.1.1.4.3.10\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">7.31</td>\n<td id=\"S3.T2.1.1.4.3.11\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">11.07</td>\n<td id=\"S3.T2.1.1.4.3.12\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">7.32</td>\n<td id=\"S3.T2.1.1.4.3.13\" class=\"ltx_td ltx_align_right ltx_border_t\">8.77</td>\n</tr>\n<tr id=\"S3.T2.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">SeamlessM4T-large-v2 (2.3B)</th>\n<td id=\"S3.T2.1.1.5.4.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">7.47</span></td>\n<td id=\"S3.T2.1.1.5.4.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">4.14</td>\n<td id=\"S3.T2.1.1.5.4.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">4.68</td>\n<td id=\"S3.T2.1.1.5.4.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">5.82</td>\n<td id=\"S3.T2.1.1.5.4.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">6.08</td>\n<td id=\"S3.T2.1.1.5.4.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.5.4.7.1\" class=\"ltx_text ltx_font_bold\">10.68</span></td>\n<td id=\"S3.T2.1.1.5.4.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">4.82</td>\n<td id=\"S3.T2.1.1.5.4.9\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">4.14</td>\n<td id=\"S3.T2.1.1.5.4.10\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">6.76</td>\n<td id=\"S3.T2.1.1.5.4.11\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">7.75</td>\n<td id=\"S3.T2.1.1.5.4.12\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">5.38</td>\n<td id=\"S3.T2.1.1.5.4.13\" class=\"ltx_td ltx_align_right ltx_border_t\">6.82</td>\n</tr>\n<tr id=\"S3.T2.1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Whisper-large-v3 (1.5B)</th>\n<td id=\"S3.T2.1.1.6.5.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">9.92</td>\n<td id=\"S3.T2.1.1.6.5.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">3.53</td>\n<td id=\"S3.T2.1.1.6.5.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">6.23</td>\n<td id=\"S3.T2.1.1.6.5.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">6.17</td>\n<td id=\"S3.T2.1.1.6.5.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">5.83</td>\n<td id=\"S3.T2.1.1.6.5.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">16.50</td>\n<td id=\"S3.T2.1.1.6.5.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">4.94</td>\n<td id=\"S3.T2.1.1.6.5.9\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">4.42</td>\n<td id=\"S3.T2.1.1.6.5.10\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">8.01</td>\n<td id=\"S3.T2.1.1.6.5.11\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">11.18</td>\n<td id=\"S3.T2.1.1.6.5.12\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">5.38</td>\n<td id=\"S3.T2.1.1.6.5.13\" class=\"ltx_td ltx_align_right ltx_border_t\">7.52</td>\n</tr>\n<tr id=\"S3.T2.1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_tt\">Canary (1B)</th>\n<td id=\"S3.T2.1.1.7.6.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">7.83</td>\n<td id=\"S3.T2.1.1.7.6.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.3.1\" class=\"ltx_text ltx_font_bold\">3.03</span></td>\n<td id=\"S3.T2.1.1.7.6.4\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.4.1\" class=\"ltx_text ltx_font_bold\">4.42</span></td>\n<td id=\"S3.T2.1.1.7.6.5\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.5.1\" class=\"ltx_text ltx_font_bold\">4.49</span></td>\n<td id=\"S3.T2.1.1.7.6.6\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.6.1\" class=\"ltx_text ltx_font_bold\">4.09</span></td>\n<td id=\"S3.T2.1.1.7.6.7\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">10.70</td>\n<td id=\"S3.T2.1.1.7.6.8\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.8.1\" class=\"ltx_text ltx_font_bold\">3.88</span></td>\n<td id=\"S3.T2.1.1.7.6.9\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.9.1\" class=\"ltx_text ltx_font_bold\">3.12</span></td>\n<td id=\"S3.T2.1.1.7.6.10\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.10.1\" class=\"ltx_text ltx_font_bold\">5.02</span></td>\n<td id=\"S3.T2.1.1.7.6.11\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.11.1\" class=\"ltx_text ltx_font_bold\">6.37</span></td>\n<td id=\"S3.T2.1.1.7.6.12\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.12.1\" class=\"ltx_text ltx_font_bold\">4.06</span></td>\n<td id=\"S3.T2.1.1.7.6.13\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_tt\"><span id=\"S3.T2.1.1.7.6.13.1\" class=\"ltx_text ltx_font_bold\">5.48</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 2 shows that the Canary model achieves the lowest WER in 10 out of 12 test sets across all languages.\nOn average, Canary model achieves 6.20% WER on English, 6.27% WER on German, 4.09% WER on Spanish and 5.39% WER on French. In comparison, the second best model, SeamlessM4T-large-v2, with twice as many parameters as ours, achieves 5.42% WER on English, 7.53% WER on German, 5.24% WER on Spanish and 6.65% WER on French. Figure 1 shows that the 95% confidence intervals do not overlap for most test sets and systems, indicating that the WER improvements observed for Canary in Table 2 are statistically significant."
        ]
    },
    "S4.T3": {
        "caption": "Table 3:  Comparing Canary with SOTA models across different domains for English ASR\u00a0 [ 23 ] . Canary achieves best average WER exhibiting generalizability across domains. ",
        "table": "<figure id=\"S4.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Comparing Canary with SOTA models across different domains for English ASR\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>. Canary achieves best average WER exhibiting generalizability across domains. </figcaption>\n<div id=\"S4.T3.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:346.9pt;height:57.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-98.1pt,16.3pt) scale(0.638688854934879,0.638688854934879) ;\">\n<table id=\"S4.T3.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Model (WER <math id=\"S4.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T3.1.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.1.m1.1b\"><ci id=\"S4.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</th>\n<td id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">AMI</td>\n<td id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Earnings22</td>\n<td id=\"S4.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GigaSpeech</td>\n<td id=\"S4.T3.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LS Clean</td>\n<td id=\"S4.T3.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">LS Other</td>\n<td id=\"S4.T3.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SPGISpeech</td>\n<td id=\"S4.T3.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Tedlium</td>\n<td id=\"S4.T3.1.1.1.9\" class=\"ltx_td ltx_align_center ltx_border_t\">Avg. WER</td>\n</tr>\n<tr id=\"S4.T3.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">Whisper-large-v3</th>\n<td id=\"S4.T3.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">16.01</td>\n<td id=\"S4.T3.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T3.1.1.2.1.3.1\" class=\"ltx_text ltx_font_bold\">11.3</span></td>\n<td id=\"S4.T3.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">10.02</td>\n<td id=\"S4.T3.1.1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">2.03</td>\n<td id=\"S4.T3.1.1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">3.91</td>\n<td id=\"S4.T3.1.1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">2.95</td>\n<td id=\"S4.T3.1.1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">3.9</td>\n<td id=\"S4.T3.1.1.2.1.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">7.16</td>\n</tr>\n<tr id=\"S4.T3.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Parakeet-RNNT-1.1B</th>\n<td id=\"S4.T3.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">17.1</td>\n<td id=\"S4.T3.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">15.15</td>\n<td id=\"S4.T3.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">9.96</td>\n<td id=\"S4.T3.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.46</td>\n<td id=\"S4.T3.1.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.1.3.2.6.1\" class=\"ltx_text ltx_font_bold\">2.48</span></td>\n<td id=\"S4.T3.1.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.11</td>\n<td id=\"S4.T3.1.1.3.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.92</td>\n<td id=\"S4.T3.1.1.3.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\">7.60</td>\n</tr>\n<tr id=\"S4.T3.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Parakeet-TDT-1.1B</th>\n<td id=\"S4.T3.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">15.9</td>\n<td id=\"S4.T3.1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">14.65</td>\n<td id=\"S4.T3.1.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">9.55</span></td>\n<td id=\"S4.T3.1.1.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T3.1.1.4.3.5.1\" class=\"ltx_text ltx_font_bold\">1.39</span></td>\n<td id=\"S4.T3.1.1.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2.62</td>\n<td id=\"S4.T3.1.1.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.42</td>\n<td id=\"S4.T3.1.1.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.56</td>\n<td id=\"S4.T3.1.1.4.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\">7.30</td>\n</tr>\n<tr id=\"S4.T3.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.1.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_tt\">Canary (1B)</th>\n<td id=\"S4.T3.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S4.T3.1.1.5.4.2.1\" class=\"ltx_text ltx_font_bold\">13.53</span></td>\n<td id=\"S4.T3.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">12.05</td>\n<td id=\"S4.T3.1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">10.07</td>\n<td id=\"S4.T3.1.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">1.47</td>\n<td id=\"S4.T3.1.1.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\">2.86</td>\n<td id=\"S4.T3.1.1.5.4.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S4.T3.1.1.5.4.7.1\" class=\"ltx_text ltx_font_bold\">2.02</span></td>\n<td id=\"S4.T3.1.1.5.4.8\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S4.T3.1.1.5.4.8.1\" class=\"ltx_text ltx_font_bold\">3.53</span></td>\n<td id=\"S4.T3.1.1.5.4.9\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_tt\"><span id=\"S4.T3.1.1.5.4.9.1\" class=\"ltx_text ltx_font_bold\">6.50</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Further, Canary achieves the best average WER of 6.5% across different test sets, highlighting its superior generalization capabilities in English ASR (Table 3)."
        ]
    },
    "S4.T4": {
        "caption": "Table 4:  BLEU scores on speech translation (AST) benchmarks. Annotations from the corresponding datasets come with native punctuation and capitalization and are used without further processing/normalization. SeamlessM4T-large-v2 (2.3B) achieves the best overall BLEU scores. Canary (1B) matches or outperforms models of comparable size.",
        "table": "<figure id=\"S4.T4\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>BLEU scores on speech translation (AST) benchmarks. Annotations from the corresponding datasets come with native punctuation and capitalization and are used without further processing/normalization. SeamlessM4T-large-v2 (2.3B) achieves the best overall BLEU scores. Canary (1B) matches or outperforms models of comparable size.</figcaption>\n<div id=\"S4.T4.17\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:77pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-138.1pt,24.5pt) scale(0.610803299152686,0.610803299152686) ;\">\n<table id=\"S4.T4.17.17\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.5.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S4.T4.1.1.1.1.1\" class=\"ltx_text\">Model (BLEU <math id=\"S4.T4.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T4.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.1.1.1.1.1.m1.1.1\" xref=\"S4.T4.1.1.1.1.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.1.1.1.1.1.m1.1b\"><ci id=\"S4.T4.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T4.1.1.1.1.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.1.1.1.1.1.m1.1c\">\\uparrow</annotation></semantics></math>)</span></th>\n<td id=\"S4.T4.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\">FLEURS (En <math id=\"S4.T4.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.2.2.2.2.m1.1.1\" xref=\"S4.T4.2.2.2.2.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.2.2.2.2.m1.1b\"><ci id=\"S4.T4.2.2.2.2.m1.1.1.cmml\" xref=\"S4.T4.2.2.2.2.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.2.2.2.2.m1.1c\">\\rightarrow</annotation></semantics></math> X)</td>\n<td id=\"S4.T4.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\">mExpresso (En <math id=\"S4.T4.3.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.3.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.3.3.3.3.m1.1.1\" xref=\"S4.T4.3.3.3.3.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.3.3.3.3.m1.1b\"><ci id=\"S4.T4.3.3.3.3.m1.1.1.cmml\" xref=\"S4.T4.3.3.3.3.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.3.3.3.3.m1.1c\">\\rightarrow</annotation></semantics></math> X)</td>\n<td id=\"S4.T4.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" colspan=\"3\">FLEURS (X <math id=\"S4.T4.4.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.4.4.4.4.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.4.4.4.4.m1.1.1\" xref=\"S4.T4.4.4.4.4.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.4.4.4.4.m1.1b\"><ci id=\"S4.T4.4.4.4.4.m1.1.1.cmml\" xref=\"S4.T4.4.4.4.4.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.4.4.4.4.m1.1c\">\\rightarrow</annotation></semantics></math> En)</td>\n<td id=\"S4.T4.5.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"3\">COVOST-v2 (X <math id=\"S4.T4.5.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.5.5.5.5.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.5.5.5.5.m1.1.1\" xref=\"S4.T4.5.5.5.5.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.5.5.5.5.m1.1b\"><ci id=\"S4.T4.5.5.5.5.m1.1.1.cmml\" xref=\"S4.T4.5.5.5.5.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.5.5.5.5.m1.1c\">\\rightarrow</annotation></semantics></math> En)</td>\n</tr>\n<tr id=\"S4.T4.17.17.17\" class=\"ltx_tr\">\n<td id=\"S4.T4.6.6.6.1\" class=\"ltx_td ltx_align_left ltx_border_r\">En <math id=\"S4.T4.6.6.6.1.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.6.6.6.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.6.6.6.1.m1.1.1\" xref=\"S4.T4.6.6.6.1.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.6.6.6.1.m1.1b\"><ci id=\"S4.T4.6.6.6.1.m1.1.1.cmml\" xref=\"S4.T4.6.6.6.1.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.6.6.6.1.m1.1c\">\\rightarrow</annotation></semantics></math> De</td>\n<td id=\"S4.T4.7.7.7.2\" class=\"ltx_td ltx_align_left ltx_border_r\">En <math id=\"S4.T4.7.7.7.2.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.7.7.7.2.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.7.7.7.2.m1.1.1\" xref=\"S4.T4.7.7.7.2.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.7.7.7.2.m1.1b\"><ci id=\"S4.T4.7.7.7.2.m1.1.1.cmml\" xref=\"S4.T4.7.7.7.2.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.7.7.7.2.m1.1c\">\\rightarrow</annotation></semantics></math> Es</td>\n<td id=\"S4.T4.8.8.8.3\" class=\"ltx_td ltx_align_left ltx_border_r\">En <math id=\"S4.T4.8.8.8.3.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.8.8.8.3.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.8.8.8.3.m1.1.1\" xref=\"S4.T4.8.8.8.3.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.8.8.8.3.m1.1b\"><ci id=\"S4.T4.8.8.8.3.m1.1.1.cmml\" xref=\"S4.T4.8.8.8.3.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.8.8.8.3.m1.1c\">\\rightarrow</annotation></semantics></math> Fr</td>\n<td id=\"S4.T4.9.9.9.4\" class=\"ltx_td ltx_align_left ltx_border_r\">En <math id=\"S4.T4.9.9.9.4.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.9.9.9.4.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.9.9.9.4.m1.1.1\" xref=\"S4.T4.9.9.9.4.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.9.9.9.4.m1.1b\"><ci id=\"S4.T4.9.9.9.4.m1.1.1.cmml\" xref=\"S4.T4.9.9.9.4.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.9.9.9.4.m1.1c\">\\rightarrow</annotation></semantics></math> De</td>\n<td id=\"S4.T4.10.10.10.5\" class=\"ltx_td ltx_align_left ltx_border_r\">En <math id=\"S4.T4.10.10.10.5.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.10.10.10.5.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.10.10.10.5.m1.1.1\" xref=\"S4.T4.10.10.10.5.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.10.10.10.5.m1.1b\"><ci id=\"S4.T4.10.10.10.5.m1.1.1.cmml\" xref=\"S4.T4.10.10.10.5.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.10.10.10.5.m1.1c\">\\rightarrow</annotation></semantics></math> Es</td>\n<td id=\"S4.T4.11.11.11.6\" class=\"ltx_td ltx_align_left ltx_border_r\">En <math id=\"S4.T4.11.11.11.6.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.11.11.11.6.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.11.11.11.6.m1.1.1\" xref=\"S4.T4.11.11.11.6.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.11.11.11.6.m1.1b\"><ci id=\"S4.T4.11.11.11.6.m1.1.1.cmml\" xref=\"S4.T4.11.11.11.6.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.11.11.11.6.m1.1c\">\\rightarrow</annotation></semantics></math> Fr</td>\n<td id=\"S4.T4.12.12.12.7\" class=\"ltx_td ltx_align_left ltx_border_r\">De <math id=\"S4.T4.12.12.12.7.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.12.12.12.7.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.12.12.12.7.m1.1.1\" xref=\"S4.T4.12.12.12.7.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.12.12.12.7.m1.1b\"><ci id=\"S4.T4.12.12.12.7.m1.1.1.cmml\" xref=\"S4.T4.12.12.12.7.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.12.12.12.7.m1.1c\">\\rightarrow</annotation></semantics></math> En</td>\n<td id=\"S4.T4.13.13.13.8\" class=\"ltx_td ltx_align_left ltx_border_r\">Es <math id=\"S4.T4.13.13.13.8.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.13.13.13.8.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.13.13.13.8.m1.1.1\" xref=\"S4.T4.13.13.13.8.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.13.13.13.8.m1.1b\"><ci id=\"S4.T4.13.13.13.8.m1.1.1.cmml\" xref=\"S4.T4.13.13.13.8.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.13.13.13.8.m1.1c\">\\rightarrow</annotation></semantics></math> En</td>\n<td id=\"S4.T4.14.14.14.9\" class=\"ltx_td ltx_align_left ltx_border_r\">Fr <math id=\"S4.T4.14.14.14.9.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.14.14.14.9.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.14.14.14.9.m1.1.1\" xref=\"S4.T4.14.14.14.9.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.14.14.14.9.m1.1b\"><ci id=\"S4.T4.14.14.14.9.m1.1.1.cmml\" xref=\"S4.T4.14.14.14.9.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.14.14.14.9.m1.1c\">\\rightarrow</annotation></semantics></math> En</td>\n<td id=\"S4.T4.15.15.15.10\" class=\"ltx_td ltx_align_left ltx_border_r\">De <math id=\"S4.T4.15.15.15.10.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.15.15.15.10.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.15.15.15.10.m1.1.1\" xref=\"S4.T4.15.15.15.10.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.15.15.15.10.m1.1b\"><ci id=\"S4.T4.15.15.15.10.m1.1.1.cmml\" xref=\"S4.T4.15.15.15.10.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.15.15.15.10.m1.1c\">\\rightarrow</annotation></semantics></math> En</td>\n<td id=\"S4.T4.16.16.16.11\" class=\"ltx_td ltx_align_left ltx_border_r\">Es <math id=\"S4.T4.16.16.16.11.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.16.16.16.11.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.16.16.16.11.m1.1.1\" xref=\"S4.T4.16.16.16.11.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.16.16.16.11.m1.1b\"><ci id=\"S4.T4.16.16.16.11.m1.1.1.cmml\" xref=\"S4.T4.16.16.16.11.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.16.16.16.11.m1.1c\">\\rightarrow</annotation></semantics></math> En</td>\n<td id=\"S4.T4.17.17.17.12\" class=\"ltx_td ltx_align_left\">Fr <math id=\"S4.T4.17.17.17.12.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S4.T4.17.17.17.12.m1.1a\"><mo stretchy=\"false\" id=\"S4.T4.17.17.17.12.m1.1.1\" xref=\"S4.T4.17.17.17.12.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T4.17.17.17.12.m1.1b\"><ci id=\"S4.T4.17.17.17.12.m1.1.1.cmml\" xref=\"S4.T4.17.17.17.12.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T4.17.17.17.12.m1.1c\">\\rightarrow</annotation></semantics></math> En</td>\n</tr>\n<tr id=\"S4.T4.17.17.18.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.17.17.18.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">OWSM-v3.1 (1.02B)</th>\n<td id=\"S4.T4.17.17.18.1.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">24.37</td>\n<td id=\"S4.T4.17.17.18.1.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">11.39</td>\n<td id=\"S4.T4.17.17.18.1.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">16.39</td>\n<td id=\"S4.T4.17.17.18.1.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">19.29</td>\n<td id=\"S4.T4.17.17.18.1.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">10.98</td>\n<td id=\"S4.T4.17.17.18.1.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">8.59</td>\n<td id=\"S4.T4.17.17.18.1.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">13.22</td>\n<td id=\"S4.T4.17.17.18.1.9\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">9.35</td>\n<td id=\"S4.T4.17.17.18.1.10\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">12.38</td>\n<td id=\"S4.T4.17.17.18.1.11\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">18.05</td>\n<td id=\"S4.T4.17.17.18.1.12\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">23.90</td>\n<td id=\"S4.T4.17.17.18.1.13\" class=\"ltx_td ltx_align_right ltx_border_tt\">24.47</td>\n</tr>\n<tr id=\"S4.T4.17.17.19.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.17.17.19.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">SeamlessM4T-medium (1.2B)</th>\n<td id=\"S4.T4.17.17.19.2.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">28.30</td>\n<td id=\"S4.T4.17.17.19.2.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">21.05</td>\n<td id=\"S4.T4.17.17.19.2.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">37.36</td>\n<td id=\"S4.T4.17.17.19.2.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">9.65</td>\n<td id=\"S4.T4.17.17.19.2.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">16.23</td>\n<td id=\"S4.T4.17.17.19.2.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">8.64</td>\n<td id=\"S4.T4.17.17.19.2.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">33.39</td>\n<td id=\"S4.T4.17.17.19.2.9\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">21.68</td>\n<td id=\"S4.T4.17.17.19.2.10\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">30.94</td>\n<td id=\"S4.T4.17.17.19.2.11\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">35.60</td>\n<td id=\"S4.T4.17.17.19.2.12\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">39.18</td>\n<td id=\"S4.T4.17.17.19.2.13\" class=\"ltx_td ltx_align_right ltx_border_t\">39.27</td>\n</tr>\n<tr id=\"S4.T4.17.17.20.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.17.17.20.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">SeamlessM4T-large-v2 (2.3B)</th>\n<td id=\"S4.T4.17.17.20.3.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T4.17.17.20.3.2.1\" class=\"ltx_text ltx_font_bold\">33.17</span></td>\n<td id=\"S4.T4.17.17.20.3.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T4.17.17.20.3.3.1\" class=\"ltx_text ltx_font_bold\">23.72</span></td>\n<td id=\"S4.T4.17.17.20.3.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T4.17.17.20.3.4.1\" class=\"ltx_text ltx_font_bold\">43.05</span></td>\n<td id=\"S4.T4.17.17.20.3.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">21.48</td>\n<td id=\"S4.T4.17.17.20.3.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">34.89</td>\n<td id=\"S4.T4.17.17.20.3.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">26.04</td>\n<td id=\"S4.T4.17.17.20.3.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T4.17.17.20.3.8.1\" class=\"ltx_text ltx_font_bold\">37.06</span></td>\n<td id=\"S4.T4.17.17.20.3.9\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T4.17.17.20.3.9.1\" class=\"ltx_text ltx_font_bold\">25.41</span></td>\n<td id=\"S4.T4.17.17.20.3.10\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T4.17.17.20.3.10.1\" class=\"ltx_text ltx_font_bold\">33.70</span></td>\n<td id=\"S4.T4.17.17.20.3.11\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T4.17.17.20.3.11.1\" class=\"ltx_text ltx_font_bold\">39.96</span></td>\n<td id=\"S4.T4.17.17.20.3.12\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\"><span id=\"S4.T4.17.17.20.3.12.1\" class=\"ltx_text ltx_font_bold\">42.91</span></td>\n<td id=\"S4.T4.17.17.20.3.13\" class=\"ltx_td ltx_align_right ltx_border_t\"><span id=\"S4.T4.17.17.20.3.13.1\" class=\"ltx_text ltx_font_bold\">42.12</span></td>\n</tr>\n<tr id=\"S4.T4.17.17.21.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.17.17.21.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">Whisper-large-v3 (1.5B)</th>\n<td id=\"S4.T4.17.17.21.4.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S4.T4.17.17.21.4.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S4.T4.17.17.21.4.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S4.T4.17.17.21.4.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S4.T4.17.17.21.4.6\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S4.T4.17.17.21.4.7\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">N/A</td>\n<td id=\"S4.T4.17.17.21.4.8\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">33.40</td>\n<td id=\"S4.T4.17.17.21.4.9\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">22.70</td>\n<td id=\"S4.T4.17.17.21.4.10\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">31.02</td>\n<td id=\"S4.T4.17.17.21.4.11\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">34.22</td>\n<td id=\"S4.T4.17.17.21.4.12\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">39.20</td>\n<td id=\"S4.T4.17.17.21.4.13\" class=\"ltx_td ltx_align_right ltx_border_t\">35.49</td>\n</tr>\n<tr id=\"S4.T4.17.17.22.5\" class=\"ltx_tr\">\n<th id=\"S4.T4.17.17.22.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_tt\">Canary (1B)</th>\n<td id=\"S4.T4.17.17.22.5.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">32.13</td>\n<td id=\"S4.T4.17.17.22.5.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">22.06</td>\n<td id=\"S4.T4.17.17.22.5.4\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">39.50</td>\n<td id=\"S4.T4.17.17.22.5.5\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S4.T4.17.17.22.5.5.1\" class=\"ltx_text ltx_font_bold\">24.42</span></td>\n<td id=\"S4.T4.17.17.22.5.6\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S4.T4.17.17.22.5.6.1\" class=\"ltx_text ltx_font_bold\">35.76</span></td>\n<td id=\"S4.T4.17.17.22.5.7\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S4.T4.17.17.22.5.7.1\" class=\"ltx_text ltx_font_bold\">27.96</span></td>\n<td id=\"S4.T4.17.17.22.5.8\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">33.70</td>\n<td id=\"S4.T4.17.17.22.5.9\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">22.06</td>\n<td id=\"S4.T4.17.17.22.5.10\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">31.57</td>\n<td id=\"S4.T4.17.17.22.5.11\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">37.92</td>\n<td id=\"S4.T4.17.17.22.5.12\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\">40.79</td>\n<td id=\"S4.T4.17.17.22.5.13\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_tt\">40.58</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We evaluate the Canary model on speech recognition (ASR) and speech-to-text translation (AST), and show the results in Table 2\nand Table 4 respectively. We use Whisper, OWSM-v3.1, and SeamlessM4T as baselines by using their official checkpoints and re-running the models on the same test sets. All models use beam search decoding with beam width 5.",
            "From Table 4, we notice that SeamlessM4T-large-v2 achieves the highest BLEU scores on all except mExpresso, which is expected given it has the highest number of parameters and the largest size of training data. Meanwhile, Canary model outperforms the SeamlessM4T-medium baseline, which shares similar parameter count but trained on more data, on all test sets. Compared with Whisper-large-v3, Canary achieves better results on CoVoST-2 and comparable performance on FLEURS. In addition, Canary is able to translate English audios into other languages, while Whisper-large-v3 cannot. From these results, we can see that, despite being the smallest model in its class, the Canary model achieves competitive performance on speech-to-text translation."
        ]
    },
    "S4.T5": {
        "caption": "Table 5:  WER(%) on long-form ASR inference, both ground-truth and predictions were processed by WhisperNormalizer\u00a0 [ 1 ] . All models use greedy decoding. The FastConformer baseline uses a streaming mechanism, while the Canary model uses simple chunking without overlap. Canary achieves lowest WER.",
        "table": "<figure id=\"S4.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>WER(%) on long-form ASR inference, both ground-truth and predictions were processed by WhisperNormalizer\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib1\" title=\"\" class=\"ltx_ref\">1</a>]</cite>. All models use greedy decoding. The FastConformer baseline uses a streaming mechanism, while the Canary model uses simple chunking without overlap. Canary achieves lowest WER.</figcaption>\n<div id=\"S4.T5.1\" class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:433.6pt;height:62.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-34.3pt,4.9pt) scale(0.863239708761717,0.863239708761717) ;\">\n<table id=\"S4.T5.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T5.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Model (WER <math id=\"S4.T5.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T5.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T5.1.1.1.1.m1.1.1\" xref=\"S4.T5.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T5.1.1.1.1.m1.1b\"><ci id=\"S4.T5.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T5.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T5.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</th>\n<th id=\"S4.T5.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Tedlium3</th>\n<th id=\"S4.T5.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t\">Earnings21</th>\n<th id=\"S4.T5.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\">Earnings22</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">FastConformer-CTC (FT+LCA+GT)\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib29\" title=\"\" class=\"ltx_ref\">29</a>]</cite>\n</th>\n<td id=\"S4.T5.1.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">5.53</td>\n<td id=\"S4.T5.1.1.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">15.61</td>\n<td id=\"S4.T5.1.1.2.1.4\" class=\"ltx_td ltx_align_right ltx_border_tt\">22.37</td>\n</tr>\n<tr id=\"S4.T5.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">FastConformer-RNNT (FT+LCA+GT)\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib29\" title=\"\" class=\"ltx_ref\">29</a>]</cite>\n</th>\n<td id=\"S4.T5.1.1.3.2.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">4.98</td>\n<td id=\"S4.T5.1.1.3.2.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">13.84</td>\n<td id=\"S4.T5.1.1.3.2.4\" class=\"ltx_td ltx_align_right ltx_border_t\">19.49</td>\n</tr>\n<tr id=\"S4.T5.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T5.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_tt\">Canary (1B)</th>\n<td id=\"S4.T5.1.1.4.3.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S4.T5.1.1.4.3.2.1\" class=\"ltx_text ltx_font_bold\">4.68</span></td>\n<td id=\"S4.T5.1.1.4.3.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_tt\"><span id=\"S4.T5.1.1.4.3.3.1\" class=\"ltx_text ltx_font_bold\">11.34</span></td>\n<td id=\"S4.T5.1.1.4.3.4\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_tt\"><span id=\"S4.T5.1.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">14.34</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We investigate the performance of the Canary model on long-form audio by chunking long audios into non-overlapping 30-second segments, performing inference on each segment, and then stitching the transcripts together. We use the FastConformer [29] as our baseline, and show the results on Tedlium3 [30], Earnings21 [31] and Earnings22 [32] in Table 5. WER's for baselines are copied from the original paper [29]. We can see that, although chunking is a naive method, Canary is achieves lowest WER in transcribing long-form audios. Meanwhile, adding streaming capability to Canary remains a direction for future research."
        ]
    },
    "S4.T6": {
        "caption": "Table 6:  Number of hallucinated characters per min, measured using 48-hour non-speech audio subset from MUSAN\u00a0 [ 17 ] . Canary hallucinates the least. (Note that there is some vocals in MUSAN audios, so the actual number of hallucinated characters may be smaller.)",
        "table": "<figure id=\"S4.T6\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Number of hallucinated characters per min, measured using 48-hour non-speech audio subset from MUSAN\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib17\" title=\"\" class=\"ltx_ref\">17</a>]</cite>. Canary hallucinates the least. (Note that there is some vocals in MUSAN audios, so the actual number of hallucinated characters may be smaller.)</figcaption>\n<div id=\"S4.T6.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:346.9pt;height:120.6pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(36.2pt,-12.6pt) scale(1.26386815806653,1.26386815806653) ;\">\n<table id=\"S4.T6.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T6.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Model</th>\n<th id=\"S4.T6.1.1.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t\"># Hallucinated Chars / min (<math id=\"S4.T6.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T6.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T6.1.1.1.1.m1.1.1\" xref=\"S4.T6.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T6.1.1.1.1.m1.1b\"><ci id=\"S4.T6.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T6.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T6.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>)</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T6.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\">Whisper-large-v3</th>\n<td id=\"S4.T6.1.1.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_tt\">114.8</td>\n</tr>\n<tr id=\"S4.T6.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t\">\n<table id=\"S4.T6.1.1.3.2.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T6.1.1.3.2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.1.3.2.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">Canary (1B) w/o noise</td>\n</tr>\n<tr id=\"S4.T6.1.1.3.2.1.1.2\" class=\"ltx_tr\">\n<td id=\"S4.T6.1.1.3.2.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">robust training</td>\n</tr>\n</table>\n</th>\n<td id=\"S4.T6.1.1.3.2.2\" class=\"ltx_td ltx_align_right ltx_border_t\">95.61</td>\n</tr>\n<tr id=\"S4.T6.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T6.1.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_tt\">Canary (1B)</th>\n<td id=\"S4.T6.1.1.4.3.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_tt\"><span id=\"S4.T6.1.1.4.3.2.1\" class=\"ltx_text ltx_font_bold\">70.75</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 6 compares the number of hallucinated characters per minute produced by Canary with and without noise-robust training (utilizing the strongly-labeled subset of AudioSet from [13]). We also include Whisper-large-v3 as an additional baseline. As shown in the table, Canary generates 16.7% fewer hallucinated characters than Whisper-large-v3, even without noise-robust training. With noise-robust training, Canary further reduces its hallucinated characters by another 26."
        ]
    }
}