{
    "S4.T1": {
        "caption": "TABLE I:  ADHD detection performance with different neural networks.  Bold  indicates the best results. \n",
        "table": "<figure id=\"S4.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">TABLE I: </span><span id=\"S4.T1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">ADHD detection performance with different neural networks. <span id=\"S4.T1.2.1.1\" class=\"ltx_text ltx_font_bold\">Bold</span> indicates the best results. \n<br class=\"ltx_break\"></span></figcaption>\n<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Audio</span></th>\n<th id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Video</span></th>\n<th id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Precision</span></th>\n<th id=\"S4.T1.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n<th id=\"S4.T1.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T1.3.1.1.5.1\" class=\"ltx_text ltx_font_bold\">AUC</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.3.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">LSTM</th>\n<th id=\"S4.T1.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">3D CNN</th>\n<td id=\"S4.T1.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">75.58</td>\n<td id=\"S4.T1.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">59.60</td>\n<td id=\"S4.T1.3.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">64.84</td>\n</tr>\n<tr id=\"S4.T1.3.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">LSTM</th>\n<th id=\"S4.T1.3.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">LSTM</th>\n<td id=\"S4.T1.3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">65.67</td>\n<td id=\"S4.T1.3.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">47.98</td>\n<td id=\"S4.T1.3.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">53.13</td>\n</tr>\n<tr id=\"S4.T1.3.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Attention CNN</th>\n<th id=\"S4.T1.3.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">3D CNN</th>\n<td id=\"S4.T1.3.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.19</td>\n<td id=\"S4.T1.3.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">65.16</td>\n<td id=\"S4.T1.3.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">68.38</td>\n</tr>\n<tr id=\"S4.T1.3.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Attention CNN</th>\n<th id=\"S4.T1.3.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">LSTM</th>\n<td id=\"S4.T1.3.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">71.71</td>\n<td id=\"S4.T1.3.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">70.57</td>\n<td id=\"S4.T1.3.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">67.20</td>\n</tr>\n<tr id=\"S4.T1.3.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.3.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.6.5.1.1\" class=\"ltx_text ltx_font_bold\">Attention CNN</span></th>\n<th id=\"S4.T1.3.6.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.6.5.2.1\" class=\"ltx_text ltx_font_bold\">Cov-Attention</span></th>\n<td id=\"S4.T1.3.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T1.3.6.5.3.1\" class=\"ltx_text ltx_font_bold\">81.08</span></td>\n<td id=\"S4.T1.3.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T1.3.6.5.4.1\" class=\"ltx_text ltx_font_bold\">82.22</span></td>\n<td id=\"S4.T1.3.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T1.3.6.5.5.1\" class=\"ltx_text ltx_font_bold\">77.35</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Our proposed system\u2019s performance is evaluated by comparing it with LSTM and 3D-CNN networks on this real multimodal ADHD dataset with precision, accuracy, and Area Under the Curve (AUC) to evaluate the classification performance of the system.\nFor the results of the AVEC 2014 dataset for depression, we utilize Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).\nThe experimental results are summarized in Table I and Table II.",
            "From Table I, the proposed system shows good classification ability on the real multimodal ADHD dataset. At the same time, the results from Table II show that the proposed audio-visual attention network is significantly higher than the other fusion networks in MAE and RMSE."
        ]
    },
    "S4.T2": {
        "caption": "TABLE II:  Depression detection performance with different neural networks.  Bold  indicates the best results. \n",
        "table": "<figure id=\"S4.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">TABLE II: </span><span id=\"S4.T2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Depression detection performance with different neural networks. <span id=\"S4.T2.2.1.1\" class=\"ltx_text ltx_font_bold\">Bold</span> indicates the best results. \n<br class=\"ltx_break\"></span></figcaption>\n<table id=\"S4.T2.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T2.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Audio</span></th>\n<th id=\"S4.T2.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T2.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Video</span></th>\n<th id=\"S4.T2.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">MAE</span></th>\n<th id=\"S4.T2.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S4.T2.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\">RMSE</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.3.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">LSTM</th>\n<th id=\"S4.T2.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">3D-CNN</th>\n<td id=\"S4.T2.3.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">8.81</td>\n<td id=\"S4.T2.3.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">10.04</td>\n</tr>\n<tr id=\"S4.T2.3.3.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">LSTM</th>\n<th id=\"S4.T2.3.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">LSTM</th>\n<td id=\"S4.T2.3.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">10.43</td>\n<td id=\"S4.T2.3.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">12.11</td>\n</tr>\n<tr id=\"S4.T2.3.4.3\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Attention CNN</th>\n<th id=\"S4.T2.3.4.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">3D CNN</th>\n<td id=\"S4.T2.3.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7.67</td>\n<td id=\"S4.T2.3.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">9.24</td>\n</tr>\n<tr id=\"S4.T2.3.5.4\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Attention CNN</th>\n<th id=\"S4.T2.3.5.4.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">LSTM</th>\n<td id=\"S4.T2.3.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">8.52</td>\n<td id=\"S4.T2.3.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">10.20</td>\n</tr>\n<tr id=\"S4.T2.3.6.5\" class=\"ltx_tr\">\n<th id=\"S4.T2.3.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.3.6.5.1.1\" class=\"ltx_text ltx_font_bold\">Attention CNN</span></th>\n<th id=\"S4.T2.3.6.5.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T2.3.6.5.2.1\" class=\"ltx_text ltx_font_bold\">Cov-Attention</span></th>\n<td id=\"S4.T2.3.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T2.3.6.5.3.1\" class=\"ltx_text ltx_font_bold\">7.23</span></td>\n<td id=\"S4.T2.3.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T2.3.6.5.4.1\" class=\"ltx_text ltx_font_bold\">9.36</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Our proposed system\u2019s performance is evaluated by comparing it with LSTM and 3D-CNN networks on this real multimodal ADHD dataset with precision, accuracy, and Area Under the Curve (AUC) to evaluate the classification performance of the system.\nFor the results of the AVEC 2014 dataset for depression, we utilize Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).\nThe experimental results are summarized in Table I and Table II.",
            "From Table I, the proposed system shows good classification ability on the real multimodal ADHD dataset. At the same time, the results from Table II show that the proposed audio-visual attention network is significantly higher than the other fusion networks in MAE and RMSE."
        ]
    },
    "S4.T3": {
        "caption": "TABLE III:  Comparison with STATE-OF-THE-ART METHODS for ADHD Detection.\n",
        "table": "<figure id=\"S4.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">TABLE III: </span><span id=\"S4.T3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Comparison with STATE-OF-THE-ART METHODS for ADHD Detection.\n<br class=\"ltx_break\"></span></figcaption>\n<table id=\"S4.T3.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Author</span></th>\n<td id=\"S4.T3.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Data Input</span></td>\n<td id=\"S4.T3.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Classifier</span></td>\n<td id=\"S4.T3.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Accuracy</span></td>\n<td id=\"S4.T3.3.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.1.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">Equipment Price ($)</span></td>\n</tr>\n<tr id=\"S4.T3.3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><em id=\"S4.T3.3.2.2.1.1\" class=\"ltx_emph ltx_font_italic\" style=\"font-size:70%;\">Luo et al.<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">28</a>]</cite></em></th>\n<td id=\"S4.T3.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.2.2.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">MRI &amp; DTI</span></td>\n<td id=\"S4.T3.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.2.2.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">CNN</span></td>\n<td id=\"S4.T3.3.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.2.2.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">76.6%</span></td>\n<td id=\"S4.T3.3.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.2.2.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">150,000-1,000,000</span></td>\n</tr>\n<tr id=\"S4.T3.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><em id=\"S4.T3.3.3.3.1.1\" class=\"ltx_emph ltx_font_italic\" style=\"font-size:70%;\">Peng et al.<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib29\" title=\"\" class=\"ltx_ref\">29</a>]</cite></em></th>\n<td id=\"S4.T3.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.3.3.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">fMRI</span></td>\n<td id=\"S4.T3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.3.3.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">CNN</span></td>\n<td id=\"S4.T3.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.3.3.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">72.9%</span></td>\n<td id=\"S4.T3.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.3.3.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">150,000-1,000,000</span></td>\n</tr>\n<tr id=\"S4.T3.3.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><em id=\"S4.T3.3.4.4.1.1\" class=\"ltx_emph ltx_font_italic\" style=\"font-size:70%;\">Vahid et al.<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib30\" title=\"\" class=\"ltx_ref\">30</a>]</cite></em></th>\n<td id=\"S4.T3.3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.4.4.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">EEG</span></td>\n<td id=\"S4.T3.3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.4.4.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">CNN</span></td>\n<td id=\"S4.T3.3.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.4.4.4.1\" class=\"ltx_text\" style=\"font-size:70%;\">80.3%</span></td>\n<td id=\"S4.T3.3.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.4.4.5.1\" class=\"ltx_text\" style=\"font-size:70%;\">1,000-25,000</span></td>\n</tr>\n<tr id=\"S4.T3.3.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.3.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><em id=\"S4.T3.3.5.5.1.1\" class=\"ltx_emph ltx_font_bold ltx_font_italic\" style=\"font-size:70%;\">Proposed method</em></th>\n<td id=\"S4.T3.3.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.5.5.2.1\" class=\"ltx_text\" style=\"font-size:70%;\">Audio-Visual</span></td>\n<td id=\"S4.T3.3.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.5.5.3.1\" class=\"ltx_text\" style=\"font-size:70%;\">Cov-attention</span></td>\n<td id=\"S4.T3.3.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.5.5.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">82.22%</span></td>\n<td id=\"S4.T3.3.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span id=\"S4.T3.3.5.5.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:70%;\">450</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We also provided part of state-of-the-art results compared to our proposed method in Table III and Table IV. It should be emphasized that, due to medical confidentiality requirements, there is no publicly available ADHD multimodal dataset. Therefore, we evaluated the performance of state-of-the-art ADHD detection systems on various datasets containing EEG and daily activities videos."
        ]
    },
    "S4.T4": {
        "caption": "TABLE IV:  Comparison with state-of-the-art methods for Depression Assessment. \n",
        "table": "<figure id=\"S4.T4\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">TABLE IV: </span><span id=\"S4.T4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Comparison with state-of-the-art methods for Depression Assessment. \n<br class=\"ltx_break\"></span></figcaption>\n<table id=\"S4.T4.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T4.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><span id=\"S4.T4.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Author</span></th>\n<td id=\"S4.T4.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T4.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Features</span></td>\n<td id=\"S4.T4.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">MAE</span></td>\n</tr>\n<tr id=\"S4.T4.3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><em id=\"S4.T4.3.2.2.1.1\" class=\"ltx_emph ltx_font_italic\">Valstar et al.<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib31\" title=\"\" class=\"ltx_ref\">31</a>]</cite></em></th>\n<td id=\"S4.T4.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Hand-craft features</td>\n<td id=\"S4.T4.3.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">10.03</td>\n</tr>\n<tr id=\"S4.T4.3.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><em id=\"S4.T4.3.3.3.1.1\" class=\"ltx_emph ltx_font_italic\">Niu et al.<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\">32</a>]</cite></em></th>\n<td id=\"S4.T4.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Fourier\nspectrogram</td>\n<td id=\"S4.T4.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7.65</td>\n</tr>\n<tr id=\"S4.T4.3.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.4.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><em id=\"S4.T4.3.4.4.1.1\" class=\"ltx_emph ltx_font_italic\">Niu et al.<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">33</a>]</cite></em></th>\n<td id=\"S4.T4.3.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Mel spectrogram</td>\n<td id=\"S4.T4.3.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7.67</td>\n</tr>\n<tr id=\"S4.T4.3.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.5.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><em id=\"S4.T4.3.5.5.1.1\" class=\"ltx_emph ltx_font_italic\">Du et al.<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib34\" title=\"\" class=\"ltx_ref\">34</a>]</cite></em></th>\n<td id=\"S4.T4.3.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Video</td>\n<td id=\"S4.T4.3.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">7.28</td>\n</tr>\n<tr id=\"S4.T4.3.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T4.3.6.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T4.3.6.6.1.1\" class=\"ltx_text ltx_font_bold\">Proposed method</span></th>\n<td id=\"S4.T4.3.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S4.T4.3.6.6.2.1\" class=\"ltx_text ltx_font_bold\">Audio-Visual Information</span></td>\n<td id=\"S4.T4.3.6.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T4.3.6.6.3.1\" class=\"ltx_text ltx_font_bold\">7.23</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We also provided part of state-of-the-art results compared to our proposed method in Table III and Table IV. It should be emphasized that, due to medical confidentiality requirements, there is no publicly available ADHD multimodal dataset. Therefore, we evaluated the performance of state-of-the-art ADHD detection systems on various datasets containing EEG and daily activities videos."
        ]
    },
    "S4.T5": {
        "caption": "TABLE V:  Ablation study of four contributions in the proposed method.  Bold  indicates the best results.",
        "table": "<figure id=\"S4.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">TABLE V: </span>Ablation study of four contributions in the proposed method. <span id=\"S4.T5.2.1\" class=\"ltx_text ltx_font_bold\">Bold</span> indicates the best results.</figcaption>\n<table id=\"S4.T5.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T5.3.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T5.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\">Ablation Settings</th>\n<th id=\"S4.T5.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span id=\"S4.T5.3.1.1.2.1\" class=\"ltx_text\">Backbone</span></th>\n<th id=\"S4.T5.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span id=\"S4.T5.3.1.1.3.1\" class=\"ltx_text\">MAE</span></th>\n</tr>\n<tr id=\"S4.T5.3.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T5.3.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Audio</th>\n<th id=\"S4.T5.3.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Video</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T5.3.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T5.3.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">\u2713</td>\n<td id=\"S4.T5.3.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">\u2717</td>\n<td id=\"S4.T5.3.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Attention-CNN</td>\n<td id=\"S4.T5.3.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">7.64</td>\n</tr>\n<tr id=\"S4.T5.3.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T5.3.4.2.1\" class=\"ltx_td ltx_align_center\">\u2717</td>\n<td id=\"S4.T5.3.4.2.2\" class=\"ltx_td ltx_align_center\">\u2713</td>\n<td id=\"S4.T5.3.4.2.3\" class=\"ltx_td ltx_align_center\">Cov-Attention</td>\n<td id=\"S4.T5.3.4.2.4\" class=\"ltx_td ltx_align_center\">7.58</td>\n</tr>\n<tr id=\"S4.T5.3.5.3\" class=\"ltx_tr\">\n<td id=\"S4.T5.3.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">\u2713</td>\n<td id=\"S4.T5.3.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">\u2713</td>\n<td id=\"S4.T5.3.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T5.3.5.3.3.1\" class=\"ltx_text ltx_font_bold\">Attention+Cov-Attention</span></td>\n<td id=\"S4.T5.3.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">7.23</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We conduct ablation studies to assess the diagnostic performance of each module within our proposed system on the same AVEC 2014 dataset and multimodal ADHD dataset. The corresponding results are presented in Table V and Fig. 6, respectively."
        ]
    }
}