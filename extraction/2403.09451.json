{
    "S4.T1": {
        "caption": "Table 1:  The parameter details of audio-visual augmentations.",
        "table": "<figure id=\"S4.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>The parameter details of audio-visual augmentations.</figcaption>\n<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S4.T1.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\">Audio Augmentation</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Volume Jitter</td>\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">range=<math id=\"S4.T1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\pm\" display=\"inline\"><semantics id=\"S4.T1.1.1.1.m1.1a\"><mo id=\"S4.T1.1.1.1.m1.1.1\" xref=\"S4.T1.1.1.1.m1.1.1.cmml\">\u00b1</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T1.1.1.1.m1.1.1.cmml\" xref=\"S4.T1.1.1.1.m1.1.1\">plus-or-minus</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T1.1.1.1.m1.1c\">\\pm</annotation></semantics></math>0.2</td>\n</tr>\n<tr id=\"S4.T1.1.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Time Mask</td>\n<td id=\"S4.T1.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_r\">max size=50, num=2</td>\n</tr>\n<tr id=\"S4.T1.1.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Frequency Mask</td>\n<td id=\"S4.T1.1.4.2.2\" class=\"ltx_td ltx_align_left ltx_border_r\">max size=50, num=2</td>\n</tr>\n<tr id=\"S4.T1.1.5.3\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Random Crop</td>\n<td id=\"S4.T1.1.5.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\">range=[0.6,1.5],</td>\n</tr>\n<tr id=\"S4.T1.1.6.4\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.6.4.1\" class=\"ltx_td ltx_border_l ltx_border_r\"></td>\n<td id=\"S4.T1.1.6.4.2\" class=\"ltx_td ltx_align_left ltx_border_r\">crop scale=[1.0,1.5]</td>\n</tr>\n<tr id=\"S4.T1.1.7.5\" class=\"ltx_tr\">\n<th id=\"S4.T1.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"2\"><span id=\"S4.T1.1.7.5.1.1\" class=\"ltx_text ltx_font_bold\">Visual Augmentation</span></th>\n</tr>\n<tr id=\"S4.T1.1.8.6\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.8.6.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t\">Multi-scale Crop</td>\n<td id=\"S4.T1.1.8.6.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\">min area=0.2</td>\n</tr>\n<tr id=\"S4.T1.1.9.7\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.9.7.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Horizontal Flip</td>\n<td id=\"S4.T1.1.9.7.2\" class=\"ltx_td ltx_align_left ltx_border_r\">p=0.5</td>\n</tr>\n<tr id=\"S4.T1.1.10.8\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.10.8.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Color Jitter</td>\n<td id=\"S4.T1.1.10.8.2\" class=\"ltx_td ltx_align_left ltx_border_r\">b=1.0, c=1.0, s=1.0, h=0.5</td>\n</tr>\n<tr id=\"S4.T1.1.11.9\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.11.9.1\" class=\"ltx_td ltx_align_left ltx_border_l ltx_border_r\">Gray Scale</td>\n<td id=\"S4.T1.1.11.9.2\" class=\"ltx_td ltx_align_left ltx_border_r\">p=0.2</td>\n</tr>\n<tr id=\"S4.T1.1.12.10\" class=\"ltx_tr\">\n<td id=\"S4.T1.1.12.10.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r\">Cutout</td>\n<td id=\"S4.T1.1.12.10.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_r\">max size=50, num=1</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The AVCAffe dataset [Sarkar et al., 2022] offers rich audio-visual data to study cognitive load in remote work, with 108 hours of footage from a globally diverse participant group. It explores the cognitive impact of remote collaboration through task-oriented video conferencing, employing NASA-TLX for multidimensional cognitive load measurement. Challenges in detailed classification led to the adoption of a binary approach. For model validation and to avoid data leakage, we ensured representative splits and attempted to emulate the authors\u2019 data augmentation methods as detailed in Table 1, despite the lack of public implementations."
        ]
    },
    "S4.T2": {
        "caption": "Table 2:  CLA results (F1-Score) on AVCAffe validation set (Binary Classification)",
        "table": "<figure id=\"S4.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>CLA results (F1-Score) on AVCAffe validation set (Binary Classification)</figcaption>\n<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Modalities</span></th>\n<th id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Architecture</span></th>\n<th id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Global F1 score</span></th>\n<th id=\"S4.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Mental Demand</span></th>\n<th id=\"S4.T2.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.5.1\" class=\"ltx_text ltx_font_bold\">Effort</span></th>\n<th id=\"S4.T2.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.1.1.1.6.1\" class=\"ltx_text ltx_font_bold\">Temporal Demand</span></th>\n</tr>\n<tr id=\"S4.T2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\" colspan=\"6\"><cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bibx32\" title=\"\" class=\"ltx_ref\">Sarkar et\u00a0al., 2022</a>]</cite></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.1.3.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Audio</td>\n<td id=\"S4.T2.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ResNet+MLP</td>\n<td id=\"S4.T2.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\u2013</td>\n<td id=\"S4.T2.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.61</td>\n<td id=\"S4.T2.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.55</td>\n<td id=\"S4.T2.1.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.55</td>\n</tr>\n<tr id=\"S4.T2.1.4.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">Video</td>\n<td id=\"S4.T2.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">R(2+1)D+MLP</td>\n<td id=\"S4.T2.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">\u2013</td>\n<td id=\"S4.T2.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">0.59</td>\n<td id=\"S4.T2.1.4.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0.55</td>\n<td id=\"S4.T2.1.4.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0.55</td>\n</tr>\n<tr id=\"S4.T2.1.5.3\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Audio-Video</td>\n<td id=\"S4.T2.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Multimodal-Single Task</td>\n<td id=\"S4.T2.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">\u2013</td>\n<td id=\"S4.T2.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.62</td>\n<td id=\"S4.T2.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.61</td>\n<td id=\"S4.T2.1.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.59</td>\n</tr>\n<tr id=\"S4.T2.1.6.4\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"6\">Ours</td>\n</tr>\n<tr id=\"S4.T2.1.7.5\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Audio</td>\n<td id=\"S4.T2.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CNN+MLP+Multitask</td>\n<td id=\"S4.T2.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.58</td>\n<td id=\"S4.T2.1.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.56</td>\n<td id=\"S4.T2.1.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.58</td>\n<td id=\"S4.T2.1.7.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.56</td>\n</tr>\n<tr id=\"S4.T2.1.8.6\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">Video</td>\n<td id=\"S4.T2.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">I3D+MLP+Multitask</td>\n<td id=\"S4.T2.1.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">0.48</td>\n<td id=\"S4.T2.1.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">0.44</td>\n<td id=\"S4.T2.1.8.6.5\" class=\"ltx_td ltx_align_center ltx_border_r\">0.49</td>\n<td id=\"S4.T2.1.8.6.6\" class=\"ltx_td ltx_align_center ltx_border_r\">0.48</td>\n</tr>\n<tr id=\"S4.T2.1.9.7\" class=\"ltx_tr\">\n<td id=\"S4.T2.1.9.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Audio-Video</td>\n<td id=\"S4.T2.1.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">Multimodal-Multitask (M&amp;M)</td>\n<td id=\"S4.T2.1.9.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.59</td>\n<td id=\"S4.T2.1.9.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.60</td>\n<td id=\"S4.T2.1.9.7.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.61</td>\n<td id=\"S4.T2.1.9.7.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.54</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We report the experimental results in Table 2 which outlines a comparative analysis of different architectures applied to the AVCAffe dataset for binary classification of cognitive load, indicated by F1-Score metrics across three task domains: Mental Demand, Effort, and Temporal Demand. It compares results from [Sarkar et al., 2022] with those obtained from our proposed M&amp;M model."
        ]
    }
}