{
    "S1.T1": {
        "caption": "Table 1:  Advantages and disadvantages of different modalities for speaker diarization.",
        "table": "<figure id=\"S1.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Advantages and disadvantages of different modalities for speaker diarization.</figcaption>\n<table id=\"S1.T1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S1.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Modality</th>\n<th id=\"S1.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Advantages</th>\n<th id=\"S1.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Disadvantages</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S1.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\" rowspan=\"2\"><span id=\"S1.T1.1.2.1.1.1\" class=\"ltx_text\">Audio</span></td>\n<td id=\"S1.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Conveys direct voice characteristics.</td>\n<td id=\"S1.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Vulnerable to environmental interference.</td>\n</tr>\n<tr id=\"S1.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.3.2.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Tracks speaker activity seamlessly.</td>\n<td id=\"S1.T1.1.3.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Fails in handling simultaneous speech.</td>\n</tr>\n<tr id=\"S1.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\" rowspan=\"2\"><span id=\"S1.T1.1.4.3.1.1\" class=\"ltx_text\">Vision</span></td>\n<td id=\"S1.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Offers distinctive visual cues.</td>\n<td id=\"S1.T1.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Cannot handle off-screen voices.</td>\n</tr>\n<tr id=\"S1.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.5.4.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Robust to complicated acoustic conditions.</td>\n<td id=\"S1.T1.1.5.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Sensitive to camera quality, angle, and distance.</td>\n</tr>\n<tr id=\"S1.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\" rowspan=\"2\"><span id=\"S1.T1.1.6.5.1.1\" class=\"ltx_text\">Text</span></td>\n<td id=\"S1.T1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Identifies speaker-turn with semantic breaks.</td>\n<td id=\"S1.T1.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Sensitive to transcription errors.</td>\n</tr>\n<tr id=\"S1.T1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S1.T1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Provides semantic context.</td>\n<td id=\"S1.T1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:12.0pt;padding-right:12.0pt;\">Often presents ambiguity regarding speaker identity.</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "While there are some known attempts to jointly model audio-visual or audio-textual information for speaker diarization, there is an obvious absence in addressing the comprehensive utilization of all three modalities, audio, visual, and textual information, in a unified framework.\nAs summarized in Table 1, each modality offers distinct and complementary strengths. Audio signals, being the primary source of speech content, provide direct access to vocal characteristics such as pitch, timbre, and speaking rate, which are essential for speaker identification.\nVisual cues can assist in distinguishing speakers by capturing unique facial features and tracking lip movements over time in low-quality acoustic environment.\nTextual data, transcribed from ASR modules, provide rich contextual and semantic content, which can reveal clear linguistic patterns and identify speaker-turns based on semantic breaks.\nConcurrently, the inherent limitations of each individual modality also constrain the efficacy of unimodal speaker diarization.\nWe believe that the complementary natures of all three modalities, when carefully combined, can potentially yield a performance leap beyond the sum of their individual contributions.\nTo successfully integrate them under one unified framework, we introduce a clustering method based on constrained optimization. By carefully constructing visual and semantic constraints, we effectively incorporate multimodal information in the joint constraint propagation."
        ]
    },
    "S3.T2": {
        "caption": "Table 2:  The results of speaker diarization with multimodal constraints",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>The results of speaker diarization with multimodal constraints</figcaption>\n<table id=\"S3.T2.6\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.6.7.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.6.7.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span id=\"S3.T2.6.7.1.1.1\" class=\"ltx_text\">Cluster Algorithm</span></th>\n<th id=\"S3.T2.6.7.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span id=\"S3.T2.6.7.1.2.1\" class=\"ltx_text\">Constraints</span></th>\n<th id=\"S3.T2.6.7.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\">Cluster Metrics</th>\n<th id=\"S3.T2.6.7.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"4\">Speaker Metrics(%)</th>\n</tr>\n<tr id=\"S3.T2.6.6\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">ARI<math id=\"S3.T2.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T2.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T2.1.1.1.m1.1.1\" xref=\"S3.T2.1.1.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.1.1.1.m1.1b\"><ci id=\"S3.T2.1.1.1.m1.1.1.cmml\" xref=\"S3.T2.1.1.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.1.1.1.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"S3.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">NMI<math id=\"S3.T2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S3.T2.2.2.2.m1.1.1\" xref=\"S3.T2.2.2.2.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.2.2.2.m1.1b\"><ci id=\"S3.T2.2.2.2.m1.1.1.cmml\" xref=\"S3.T2.2.2.2.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.2.2.2.m1.1c\">\\uparrow</annotation></semantics></math>\n</th>\n<th id=\"S3.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">DER<math id=\"S3.T2.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T2.3.3.3.m1.1a\"><mo stretchy=\"false\" id=\"S3.T2.3.3.3.m1.1.1\" xref=\"S3.T2.3.3.3.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.3.3.3.m1.1b\"><ci id=\"S3.T2.3.3.3.m1.1.1.cmml\" xref=\"S3.T2.3.3.3.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.3.3.3.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S3.T2.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">JER<math id=\"S3.T2.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T2.4.4.4.m1.1a\"><mo stretchy=\"false\" id=\"S3.T2.4.4.4.m1.1.1\" xref=\"S3.T2.4.4.4.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.4.4.4.m1.1b\"><ci id=\"S3.T2.4.4.4.m1.1.1.cmml\" xref=\"S3.T2.4.4.4.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.4.4.4.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S3.T2.5.5.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">TextDER<math id=\"S3.T2.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T2.5.5.5.m1.1a\"><mo stretchy=\"false\" id=\"S3.T2.5.5.5.m1.1.1\" xref=\"S3.T2.5.5.5.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.5.5.5.m1.1b\"><ci id=\"S3.T2.5.5.5.m1.1.1.cmml\" xref=\"S3.T2.5.5.5.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.5.5.5.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S3.T2.6.6.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">CpWER<math id=\"S3.T2.6.6.6.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T2.6.6.6.m1.1a\"><mo stretchy=\"false\" id=\"S3.T2.6.6.6.m1.1.1\" xref=\"S3.T2.6.6.6.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.6.6.6.m1.1b\"><ci id=\"S3.T2.6.6.6.m1.1.1.cmml\" xref=\"S3.T2.6.6.6.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.6.6.6.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.6.8.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.6.8.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">VBx</td>\n<td id=\"S3.T2.6.8.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">No Constraints</td>\n<td id=\"S3.T2.6.8.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.903</td>\n<td id=\"S3.T2.6.8.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">0.893</td>\n<td id=\"S3.T2.6.8.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">10.31</td>\n<td id=\"S3.T2.6.8.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">29.28</td>\n<td id=\"S3.T2.6.8.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">4.23</td>\n<td id=\"S3.T2.6.8.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">18.03</td>\n</tr>\n<tr id=\"S3.T2.6.9.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.6.9.2.1\" class=\"ltx_td ltx_align_center\">SC</td>\n<td id=\"S3.T2.6.9.2.2\" class=\"ltx_td ltx_align_center\">No Constraints</td>\n<td id=\"S3.T2.6.9.2.3\" class=\"ltx_td ltx_align_center\">0.918</td>\n<td id=\"S3.T2.6.9.2.4\" class=\"ltx_td ltx_align_center\">0.899</td>\n<td id=\"S3.T2.6.9.2.5\" class=\"ltx_td ltx_align_center\">9.37</td>\n<td id=\"S3.T2.6.9.2.6\" class=\"ltx_td ltx_align_center\">27.21</td>\n<td id=\"S3.T2.6.9.2.7\" class=\"ltx_td ltx_align_center\">3.25</td>\n<td id=\"S3.T2.6.9.2.8\" class=\"ltx_td ltx_align_center\">17.04</td>\n</tr>\n<tr id=\"S3.T2.6.10.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.6.10.3.1\" class=\"ltx_td ltx_align_center\">E2CP + SC</td>\n<td id=\"S3.T2.6.10.3.2\" class=\"ltx_td ltx_align_center\">Semantic Constraints</td>\n<td id=\"S3.T2.6.10.3.3\" class=\"ltx_td ltx_align_center\">0.924</td>\n<td id=\"S3.T2.6.10.3.4\" class=\"ltx_td ltx_align_center\">0.904</td>\n<td id=\"S3.T2.6.10.3.5\" class=\"ltx_td ltx_align_center\">9.12</td>\n<td id=\"S3.T2.6.10.3.6\" class=\"ltx_td ltx_align_center\">25.98</td>\n<td id=\"S3.T2.6.10.3.7\" class=\"ltx_td ltx_align_center\">3.02</td>\n<td id=\"S3.T2.6.10.3.8\" class=\"ltx_td ltx_align_center\">16.86</td>\n</tr>\n<tr id=\"S3.T2.6.11.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.6.11.4.1\" class=\"ltx_td ltx_align_center\">E2CP + SC</td>\n<td id=\"S3.T2.6.11.4.2\" class=\"ltx_td ltx_align_center\">Visual Constraints</td>\n<td id=\"S3.T2.6.11.4.3\" class=\"ltx_td ltx_align_center\">0.924</td>\n<td id=\"S3.T2.6.11.4.4\" class=\"ltx_td ltx_align_center\">0.905</td>\n<td id=\"S3.T2.6.11.4.5\" class=\"ltx_td ltx_align_center\">9.13</td>\n<td id=\"S3.T2.6.11.4.6\" class=\"ltx_td ltx_align_center\">26.02</td>\n<td id=\"S3.T2.6.11.4.7\" class=\"ltx_td ltx_align_center\">3.02</td>\n<td id=\"S3.T2.6.11.4.8\" class=\"ltx_td ltx_align_center\">16.83</td>\n</tr>\n<tr id=\"S3.T2.6.12.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.6.12.5.1\" class=\"ltx_td ltx_align_center ltx_border_b\">E2CP + SC</td>\n<td id=\"S3.T2.6.12.5.2\" class=\"ltx_td ltx_align_center ltx_border_b\">Semantic + Visual Constraints</td>\n<td id=\"S3.T2.6.12.5.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T2.6.12.5.3.1\" class=\"ltx_text ltx_font_bold\">0.925</span></td>\n<td id=\"S3.T2.6.12.5.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T2.6.12.5.4.1\" class=\"ltx_text ltx_font_bold\">0.908</span></td>\n<td id=\"S3.T2.6.12.5.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T2.6.12.5.5.1\" class=\"ltx_text ltx_font_bold\">9.01</span></td>\n<td id=\"S3.T2.6.12.5.6\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T2.6.12.5.6.1\" class=\"ltx_text ltx_font_bold\">22.57</span></td>\n<td id=\"S3.T2.6.12.5.7\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T2.6.12.5.7.1\" class=\"ltx_text ltx_font_bold\">2.89</span></td>\n<td id=\"S3.T2.6.12.5.8\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T2.6.12.5.8.1\" class=\"ltx_text ltx_font_bold\">16.36</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The results of speaker diarization in Table 2 show that adding either semantic or visual constraints individually in E2CP + SC system can lead to improvements in cluster and diarization metrics. With semantic constraints, the JER metric decreases from 27.21% to 25.98%, and the DER metric also shows a reduction from 9.37% to 9.12%, compared to the baseline SC\u2019s DER. The integration of visual constraints improves cluster precision, as reflected by an improved NMI of 0.905."
        ]
    },
    "S3.T3": {
        "caption": "Table 3:  Constraints derived from various modalities. We separately evaluated the accuracy and coverage of these constraints.",
        "table": "<figure id=\"S3.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Constraints derived from various modalities. We separately evaluated the accuracy and coverage of these constraints.</figcaption>\n<table id=\"S3.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span id=\"S3.T3.1.1.1.1.1\" class=\"ltx_text\">Constraints</span></th>\n<th id=\"S3.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"3\">Accuracy(%)</th>\n<th id=\"S3.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"3\">Coverage(%)</th>\n</tr>\n<tr id=\"S3.T3.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Must-Link</td>\n<td id=\"S3.T3.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Cannot-Link</td>\n<td id=\"S3.T3.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">Total</td>\n<td id=\"S3.T3.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Must-Link</td>\n<td id=\"S3.T3.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">Cannot-Link</td>\n<td id=\"S3.T3.1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">Total</td>\n</tr>\n<tr id=\"S3.T3.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Semantic Constraints</td>\n<td id=\"S3.T3.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">99.75</td>\n<td id=\"S3.T3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">84.80</td>\n<td id=\"S3.T3.1.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">99.40</td>\n<td id=\"S3.T3.1.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1.23</td>\n<td id=\"S3.T3.1.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.08</td>\n<td id=\"S3.T3.1.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.49</td>\n</tr>\n<tr id=\"S3.T3.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Visual Constraints</td>\n<td id=\"S3.T3.1.4.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">99.07</td>\n<td id=\"S3.T3.1.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">97.87</td>\n<td id=\"S3.T3.1.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">99.32</td>\n<td id=\"S3.T3.1.4.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">22.81</td>\n<td id=\"S3.T3.1.4.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">21.78</td>\n<td id=\"S3.T3.1.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_t\">22.53</td>\n</tr>\n<tr id=\"S3.T3.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">Semantic + Visual Constraints</td>\n<td id=\"S3.T3.1.5.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">99.11</td>\n<td id=\"S3.T3.1.5.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">97.83</td>\n<td id=\"S3.T3.1.5.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">99.34</td>\n<td id=\"S3.T3.1.5.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">23.65</td>\n<td id=\"S3.T3.1.5.5.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">21.84</td>\n<td id=\"S3.T3.1.5.5.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">22.87</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "It is important to note that both visual and semantic decoding methods introduce some level of error, and the constraints constructed from these modalities may cover different sets of embedding pairs, so we need to examine the impact of these factors on the outcome. Table 3 presents the accuracy and coverage rates of constraints generated from both visual and semantic modalities."
        ]
    },
    "S5.T4": {
        "caption": "Table 4:  The results of audio-visual speaker diarization experiments on AVA-AVD datasets.",
        "table": "<figure id=\"S5.T4\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>The results of audio-visual speaker diarization experiments on AVA-AVD datasets.</figcaption>\n<div id=\"S5.T4.2\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:110.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(40.2pt,-10.2pt) scale(1.22770698167265,1.22770698167265) ;\">\n<table id=\"S5.T4.2.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.2.2.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.2.2.3\" class=\"ltx_td ltx_border_t\"></td>\n<th id=\"S5.T4.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Modality</th>\n<th id=\"S5.T4.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Methods</th>\n<th id=\"S5.T4.2.2.2.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">VAD</th>\n<th id=\"S5.T4.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">SPKE(%)<math id=\"S5.T4.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T4.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S5.T4.1.1.1.1.m1.1.1\" xref=\"S5.T4.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.1.1.1.1.m1.1b\"><ci id=\"S5.T4.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T4.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S5.T4.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">DER(%)<math id=\"S5.T4.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T4.2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S5.T4.2.2.2.2.m1.1.1\" xref=\"S5.T4.2.2.2.2.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T4.2.2.2.2.m1.1b\"><ci id=\"S5.T4.2.2.2.2.m1.1.1.cmml\" xref=\"S5.T4.2.2.2.2.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T4.2.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n<tr id=\"S5.T4.2.2.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.2.2.3.1.1.1\" class=\"ltx_text\">AVR-Net</span></td>\n<td id=\"S5.T4.2.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Audio</td>\n<td id=\"S5.T4.2.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">VBx</td>\n<td id=\"S5.T4.2.2.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Oracle</td>\n<td id=\"S5.T4.2.2.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">18.45</td>\n<td id=\"S5.T4.2.2.3.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\">21.37</td>\n</tr>\n<tr id=\"S5.T4.2.2.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.2.4.2.1\" class=\"ltx_td ltx_align_center\">Audio + Visual</td>\n<td id=\"S5.T4.2.2.4.2.2\" class=\"ltx_td ltx_align_center\">AVA-AVD</td>\n<td id=\"S5.T4.2.2.4.2.3\" class=\"ltx_td ltx_align_center\">Oracle</td>\n<td id=\"S5.T4.2.2.4.2.4\" class=\"ltx_td ltx_align_center\">17.65</td>\n<td id=\"S5.T4.2.2.4.2.5\" class=\"ltx_td ltx_align_center\">20.57</td>\n</tr>\n<tr id=\"S5.T4.2.2.5.3\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.2.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" rowspan=\"2\"><span id=\"S5.T4.2.2.5.3.1.1\" class=\"ltx_text\">Ours</span></td>\n<td id=\"S5.T4.2.2.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Audio</td>\n<td id=\"S5.T4.2.2.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">SC</td>\n<td id=\"S5.T4.2.2.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Oracle</td>\n<td id=\"S5.T4.2.2.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">18.39</td>\n<td id=\"S5.T4.2.2.5.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">21.31</td>\n</tr>\n<tr id=\"S5.T4.2.2.6.4\" class=\"ltx_tr\">\n<td id=\"S5.T4.2.2.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_b\">Audio + Visual</td>\n<td id=\"S5.T4.2.2.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_b\">E2CP + SC</td>\n<td id=\"S5.T4.2.2.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_b\">Oracle</td>\n<td id=\"S5.T4.2.2.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T4.2.2.6.4.4.1\" class=\"ltx_text ltx_font_bold\">17.40</span></td>\n<td id=\"S5.T4.2.2.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T4.2.2.6.4.5.1\" class=\"ltx_text ltx_font_bold\">20.32</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The method proposed in (Xu et al. 2022) involves training an audio-visual relation network (AVR-Net) to simultaneously model audio and visual information. This approach requires a substantial amount of aligned audio-visual paired data for training. In contrast, our method utilizes a pretrained visual model to directly construct visual constraints that refine the affinity matrix from acoustic embeddings. Table 4 presents a comparison conducted on AVA-AVD, revealing the competitive performance of our method when utilizing only visual constraints. This demonstrates strong generalizability of our approach."
        ]
    },
    "S5.T5": {
        "caption": "Table 5:  The results of audio-text speaker diarization experiments on AIShell-4 and Alimeeting Datasets.",
        "table": "<figure id=\"S5.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>The results of audio-text speaker diarization experiments on AIShell-4 and Alimeeting Datasets.</figcaption>\n<div id=\"S5.T5.2\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:157pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(42.8pt,-15.5pt) scale(1.24613167196008,1.24613167196008) ;\">\n<table id=\"S5.T5.2.2\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.2.2.2\" class=\"ltx_tr\">\n<th id=\"S5.T5.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Dataset</th>\n<th id=\"S5.T5.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Modality</th>\n<th id=\"S5.T5.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Methods</th>\n<th id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">CpWER(%)<math id=\"S5.T5.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T5.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S5.T5.1.1.1.1.m1.1.1\" xref=\"S5.T5.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.1.1.1.1.m1.1b\"><ci id=\"S5.T5.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T5.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n<th id=\"S5.T5.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">TextDER(%)<math id=\"S5.T5.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S5.T5.2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S5.T5.2.2.2.2.m1.1.1\" xref=\"S5.T5.2.2.2.2.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T5.2.2.2.2.m1.1b\"><ci id=\"S5.T5.2.2.2.2.m1.1.1.cmml\" xref=\"S5.T5.2.2.2.2.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T5.2.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.2.2.3.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.2.2.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"3\"><span id=\"S5.T5.2.2.3.1.1.1\" class=\"ltx_text\">AIShell-4</span></td>\n<td id=\"S5.T5.2.2.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Audio</td>\n<td id=\"S5.T5.2.2.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">SC</td>\n<td id=\"S5.T5.2.2.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">17.31</td>\n<td id=\"S5.T5.2.2.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">5.97</td>\n</tr>\n<tr id=\"S5.T5.2.2.4.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.2.2.4.2.1\" class=\"ltx_td ltx_align_center\">Audio + Semantic</td>\n<td id=\"S5.T5.2.2.4.2.2\" class=\"ltx_td ltx_align_center\">Fusion</td>\n<td id=\"S5.T5.2.2.4.2.3\" class=\"ltx_td ltx_align_center\">15.23</td>\n<td id=\"S5.T5.2.2.4.2.4\" class=\"ltx_td ltx_align_center\">6.28</td>\n</tr>\n<tr id=\"S5.T5.2.2.5.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.2.2.5.3.1\" class=\"ltx_td ltx_align_center\">Audio + Semantic</td>\n<td id=\"S5.T5.2.2.5.3.2\" class=\"ltx_td ltx_align_center\">Ours</td>\n<td id=\"S5.T5.2.2.5.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.2.2.5.3.3.1\" class=\"ltx_text ltx_font_bold\">14.95</span></td>\n<td id=\"S5.T5.2.2.5.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S5.T5.2.2.5.3.4.1\" class=\"ltx_text ltx_font_bold\">4.98</span></td>\n</tr>\n<tr id=\"S5.T5.2.2.6.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.2.2.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" rowspan=\"3\"><span id=\"S5.T5.2.2.6.4.1.1\" class=\"ltx_text\">Alimeeting</span></td>\n<td id=\"S5.T5.2.2.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">Audio</td>\n<td id=\"S5.T5.2.2.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">SC</td>\n<td id=\"S5.T5.2.2.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">41.67</td>\n<td id=\"S5.T5.2.2.6.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">18.89</td>\n</tr>\n<tr id=\"S5.T5.2.2.7.5\" class=\"ltx_tr\">\n<td id=\"S5.T5.2.2.7.5.1\" class=\"ltx_td ltx_align_center\">Audio + Semantic</td>\n<td id=\"S5.T5.2.2.7.5.2\" class=\"ltx_td ltx_align_center\">Fusion</td>\n<td id=\"S5.T5.2.2.7.5.3\" class=\"ltx_td ltx_align_center\">36.15</td>\n<td id=\"S5.T5.2.2.7.5.4\" class=\"ltx_td ltx_align_center\">14.50</td>\n</tr>\n<tr id=\"S5.T5.2.2.8.6\" class=\"ltx_tr\">\n<td id=\"S5.T5.2.2.8.6.1\" class=\"ltx_td ltx_align_center ltx_border_b\">Audio + Semantic</td>\n<td id=\"S5.T5.2.2.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\">Ours</td>\n<td id=\"S5.T5.2.2.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T5.2.2.8.6.3.1\" class=\"ltx_text ltx_font_bold\">31.11</span></td>\n<td id=\"S5.T5.2.2.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S5.T5.2.2.8.6.4.1\" class=\"ltx_text ltx_font_bold\">10.76</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The method presented in (Cheng et al. 2023b) integrates acoustic and semantic information to address boundary issues in acoustic-only systems. In contrast, our approach uses semantic information to create pairwise constraints that directly impact spectral clustering. Table 5 presents the experimental results of our audio-text speaker diarization method, showing significant performance improvements on both the AIShell-4 and AliMeeting datasets. Specifically, the CpWER on the AIShell-4 dataset decreased from 15.23% to 14.95%, and on the AliMeeting dataset, it reduced from 36.15% to 31.11%. These results indicate that our method effectively utilizes semantic information compared to the approach in (Cheng et al. 2023b)."
        ]
    }
}