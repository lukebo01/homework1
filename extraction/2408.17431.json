{
    "S3.T1": {
        "caption": "Table 1 :  Overall performance comparison of various approaches on LibriMix.  Sys. {1-3} are the experimental results from ESPnet \\footref espnet, Sys. {4-5} are the results of AED-based models, and Sys. {6-8} are the results of the LLM-based models.",
        "table": "<figure id=\"S3.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T1.4.1.1\" class=\"ltx_text ltx_font_bold\">Table 1</span>: </span>Overall performance comparison of various approaches on LibriMix. <span id=\"S3.T1.5.2\" class=\"ltx_text\" style=\"color:#000000;\">Sys. {1-3} are the experimental results from ESPnet<span id=\"S3.T1.5.2.1\" class=\"ltx_ERROR undefined\">\\footref</span>espnet, Sys. {4-5} are the results of AED-based models, and Sys. {6-8} are the results of the LLM-based models.</span></figcaption>\n<div id=\"S3.T1.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:246.8pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(58.7pt,-33.4pt) scale(1.37093634553146,1.37093634553146) ;\">\n<table id=\"S3.T1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T1.1.1.1.2.1\" class=\"ltx_text\">Sys.</span></td>\n<td id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T1.1.1.1.3.1\" class=\"ltx_text\">type</span></td>\n<td id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T1.1.1.1.4.1\" class=\"ltx_text\">Speech Encoder</span></td>\n<td id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" colspan=\"2\">WER\u00a0(%) <math id=\"S3.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T1.1.1.1.1.m1.1.1\" xref=\"S3.T1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T1.1.1.1.1.m1.1b\"><ci id=\"S3.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S3.T1.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.2.1.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">dev</td>\n<td id=\"S3.T1.1.1.2.1.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">test</td>\n</tr>\n<tr id=\"S3.T1.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">1</td>\n<td id=\"S3.T1.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"3\"><span id=\"S3.T1.1.1.3.2.2.1\" class=\"ltx_text\">\n<span id=\"S3.T1.1.1.3.2.2.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T1.1.1.3.2.2.1.1.1\" class=\"ltx_p\">ESPnet<span id=\"S3.T1.1.1.3.2.2.1.1.1.1\" class=\"ltx_ERROR undefined\">\\footref</span>espnet</span>\n<span id=\"S3.T1.1.1.3.2.2.1.1.2\" class=\"ltx_p\">Baseline</span>\n</span></span></td>\n<td id=\"S3.T1.1.1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Whisper small</td>\n<td id=\"S3.T1.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">26.0</td>\n<td id=\"S3.T1.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">25.0</td>\n</tr>\n<tr id=\"S3.T1.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">2</td>\n<td id=\"S3.T1.1.1.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Conformer</td>\n<td id=\"S3.T1.1.1.4.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">24.7</td>\n<td id=\"S3.T1.1.1.4.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">23.3</td>\n</tr>\n<tr id=\"S3.T1.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">3</td>\n<td id=\"S3.T1.1.1.5.4.2\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">\u00a0\u00a0\u2003+ WavLM Large upstream</td>\n<td id=\"S3.T1.1.1.5.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">19.4</td>\n<td id=\"S3.T1.1.1.5.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">17.1</td>\n</tr>\n<tr id=\"S3.T1.1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">4</td>\n<td id=\"S3.T1.1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T1.1.1.6.5.2.1\" class=\"ltx_text\">AED</span></td>\n<td id=\"S3.T1.1.1.6.5.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">WavLM Base+</td>\n<td id=\"S3.T1.1.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">18.9</td>\n<td id=\"S3.T1.1.1.6.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">17.7</td>\n</tr>\n<tr id=\"S3.T1.1.1.7.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">5</td>\n<td id=\"S3.T1.1.1.7.6.2\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">WavLM Large</td>\n<td id=\"S3.T1.1.1.7.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T1.1.1.7.6.3.1\" class=\"ltx_text\" style=\"color:#000000;\">10.6</span></td>\n<td id=\"S3.T1.1.1.7.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T1.1.1.7.6.4.1\" class=\"ltx_text\" style=\"color:#000000;\">9.2</span></td>\n</tr>\n<tr id=\"S3.T1.1.1.8.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">6</td>\n<td id=\"S3.T1.1.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"3\"><span id=\"S3.T1.1.1.8.7.2.1\" class=\"ltx_text\">LLM</span></td>\n<td id=\"S3.T1.1.1.8.7.3\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">WavLM Base+</td>\n<td id=\"S3.T1.1.1.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">17.6</td>\n<td id=\"S3.T1.1.1.8.7.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">15.9</td>\n</tr>\n<tr id=\"S3.T1.1.1.9.8\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.9.8.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">7</td>\n<td id=\"S3.T1.1.1.9.8.2\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">WavLM Large</td>\n<td id=\"S3.T1.1.1.9.8.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">11.4</td>\n<td id=\"S3.T1.1.1.9.8.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">10.2</td>\n</tr>\n<tr id=\"S3.T1.1.1.10.9\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.10.9.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">8</td>\n<td id=\"S3.T1.1.1.10.9.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">\u00a0\u00a0\u2003+ LibriMix Fine-tuning</td>\n<td id=\"S3.T1.1.1.10.9.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T1.1.1.10.9.3.1\" class=\"ltx_text ltx_font_bold\">10.3</span></td>\n<td id=\"S3.T1.1.1.10.9.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T1.1.1.10.9.4.1\" class=\"ltx_text ltx_font_bold\">9.0</span></td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 1 shows our results comparing various approaches on LibriMix. Sys. {1-3} are the results from ESPnet. Among these, using a conformer as the encoder and the WavLM Large model as upstream achieves better results because the WavLM model has been self-supervised pre-trained on large-scale overlapped speech, making it more suitable for multi-talker scenarios. Sys. {4-5} in Table 1 are the results of fine-tuning the WavLM model using AED approach. The performance of the WavLM Large model is significantly better than that in ESPnet, since the WavLM in the latter is frozen. Sys. {6-8} in Table 1 are the results of the LLM-based approach proposed in this work.\nWhen using WavLM Base+ as the speech encoder, the LLM-based method (Sys. 6, Tab. 1) outperforms the AED-based method (Sys. 4, Tab. 1). However, when WavLM Large is used as the encoder, the AED-based method shows a significant performance boost (Sys. 5, Tab. 1), even surpassing the LLM-based method (Sys. 7, Tab. 1), which indicates that AED-based systems are more dependent on encoder performance. Initializing the LLM-based system with the speech encoder fine-tuned on LibriMix using AED method results in the best performance (Sys. 8, Tab. 1). Therefore, in the performance on LibriMix test set, the advantage of the LLM-based system over the AED-based system is not very pronounced (9.0% WER in Sys. 8 vs. 9.2% WER in Sys. 5). This is similar to conclusions drawn from single-speaker ASR studies [18, 21], as LibriMix is simulated data and contains only two speakers per utterance, making it less challenging compared to real conversational scenarios."
        ]
    },
    "S3.T2": {
        "caption": "Table 2 :  Performance comparison with and without LoRA fine-tuning in the case of different speech encoders.",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T2.4.1.1\" class=\"ltx_text ltx_font_bold\">Table 2</span>: </span><span id=\"S3.T2.5.2\" class=\"ltx_text\" style=\"color:#000000;\">Performance comparison with and without LoRA fine-tuning in the case of different speech encoders.</span></figcaption>\n<div id=\"S3.T2.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:222.1pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(76.3pt,-39.1pt) scale(1.54262226764451,1.54262226764451) ;\">\n<table id=\"S3.T2.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\" rowspan=\"2\"><span id=\"S3.T2.1.1.1.2.1\" class=\"ltx_text\">Sys.</span></th>\n<th id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\" rowspan=\"2\"><span id=\"S3.T2.1.1.1.3.1\" class=\"ltx_text\">Speech Encoder</span></th>\n<th id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\" rowspan=\"2\"><span id=\"S3.T2.1.1.1.4.1\" class=\"ltx_text\">LoRA</span></th>\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\" colspan=\"2\">WER\u00a0(%) <math id=\"S3.T2.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T2.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T2.1.1.1.1.m1.1.1\" xref=\"S3.T2.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.1.1.1.1.m1.1b\"><ci id=\"S3.T2.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T2.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</th>\n</tr>\n<tr id=\"S3.T2.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">dev</th>\n<th id=\"S3.T2.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">test</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.3.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">-</td>\n<td id=\"S3.T2.1.1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\" rowspan=\"2\"><span id=\"S3.T2.1.1.3.1.2.1\" class=\"ltx_text\">WavLM Base+</span></td>\n<td id=\"S3.T2.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">\u2717</td>\n<td id=\"S3.T2.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">19.4</td>\n<td id=\"S3.T2.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">17.3</td>\n</tr>\n<tr id=\"S3.T2.1.1.4.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">Tab.\u00a0<a href=\"#S3.T1\" title=\"Table 1 \u2023 3.1.4 Experimental results \u2023 3.1 Experiment with LibriMix \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, Sys. 6</td>\n<td id=\"S3.T2.1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">\u2713</td>\n<td id=\"S3.T2.1.1.4.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">17.6</td>\n<td id=\"S3.T2.1.1.4.2.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">15.9</td>\n</tr>\n<tr id=\"S3.T2.1.1.5.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">-</td>\n<td id=\"S3.T2.1.1.5.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\" rowspan=\"2\"><span id=\"S3.T2.1.1.5.3.2.1\" class=\"ltx_text\">WavLM Large</span></td>\n<td id=\"S3.T2.1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">\u2717</td>\n<td id=\"S3.T2.1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">12.6</td>\n<td id=\"S3.T2.1.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">11.3</td>\n</tr>\n<tr id=\"S3.T2.1.1.6.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">Tab.\u00a0<a href=\"#S3.T1\" title=\"Table 1 \u2023 3.1.4 Experimental results \u2023 3.1 Experiment with LibriMix \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, Sys. 7</td>\n<td id=\"S3.T2.1.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">\u2713</td>\n<td id=\"S3.T2.1.1.6.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">11.4</td>\n<td id=\"S3.T2.1.1.6.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">10.2</td>\n</tr>\n<tr id=\"S3.T2.1.1.7.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">-</td>\n<td id=\"S3.T2.1.1.7.5.2\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\" rowspan=\"2\"><span id=\"S3.T2.1.1.7.5.2.1\" class=\"ltx_text\">\u2003+ LibriMix Fine-tuning</span></td>\n<td id=\"S3.T2.1.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">\u2717</td>\n<td id=\"S3.T2.1.1.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">10.8</td>\n<td id=\"S3.T2.1.1.7.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">9.5</td>\n</tr>\n<tr id=\"S3.T2.1.1.8.6\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">Tab.\u00a0<a href=\"#S3.T1\" title=\"Table 1 \u2023 3.1.4 Experimental results \u2023 3.1 Experiment with LibriMix \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, Sys. 8</td>\n<td id=\"S3.T2.1.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">\u2713</td>\n<td id=\"S3.T2.1.1.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">10.3</td>\n<td id=\"S3.T2.1.1.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:4.3pt;padding-right:4.3pt;\">9.0</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 2 shows the performance comparison of different speech encoders with and without LoRA fine-tuning. Similar to the conclusions in [18] and [22], introducing LoRA fine-tuning into the LLM consistently improves performance regardless of the speech encoder used. This indicates that LoRA fine-tuning can adapt the LLM output to the style of SOT-based multi-talker transcription. In [21], promising performance can be achieved even without introducing the LoRA adaptor, possibly because the transcription style of the single-talker Librispeech used in [21] is similar to the output of the original LLM."
        ]
    },
    "S3.T3": {
        "caption": "Table 3 :  Performance comparison of freezing and jointly training the speech encoder with and without fine-tuning on LibriMix using AED method.",
        "table": "<figure id=\"S3.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T3.4.1.1\" class=\"ltx_text ltx_font_bold\">Table 3</span>: </span><span id=\"S3.T3.5.2\" class=\"ltx_text\" style=\"color:#000000;\">Performance comparison of freezing and jointly training the speech encoder with and without fine-tuning on LibriMix using AED method.</span></figcaption>\n<div id=\"S3.T3.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:164.4pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(74.3pt,-28.2pt) scale(1.5217799335022,1.5217799335022) ;\">\n<table id=\"S3.T3.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S3.T3.1.1.1.2.1\" class=\"ltx_text\">Sys.</span></td>\n<td id=\"S3.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S3.T3.1.1.1.3.1\" class=\"ltx_text\">\n<span id=\"S3.T3.1.1.1.3.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T3.1.1.1.3.1.1.1\" class=\"ltx_p\">LibriMix</span>\n<span id=\"S3.T3.1.1.1.3.1.1.2\" class=\"ltx_p\">Fine-tuning</span>\n</span></span></td>\n<td id=\"S3.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S3.T3.1.1.1.4.1\" class=\"ltx_text\">\n<span id=\"S3.T3.1.1.1.4.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T3.1.1.1.4.1.1.1\" class=\"ltx_p\">Freeze</span>\n<span id=\"S3.T3.1.1.1.4.1.1.2\" class=\"ltx_p\">Encoder</span>\n</span></span></td>\n<td id=\"S3.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" colspan=\"2\">WER\u00a0(%) <math id=\"S3.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T3.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T3.1.1.1.1.m1.1.1\" xref=\"S3.T3.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.1.1.1.1.m1.1b\"><ci id=\"S3.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T3.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S3.T3.1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.2.1.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">dev</td>\n<td id=\"S3.T3.1.1.2.1.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">test</td>\n</tr>\n<tr id=\"S3.T3.1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">Tab.\u00a0<a href=\"#S3.T1\" title=\"Table 1 \u2023 3.1.4 Experimental results \u2023 3.1 Experiment with LibriMix \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, Sys. 7</td>\n<td id=\"S3.T3.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S3.T3.1.1.3.2.2.1\" class=\"ltx_text\">\u2717</span></td>\n<td id=\"S3.T3.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\u2717</td>\n<td id=\"S3.T3.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">11.4</td>\n<td id=\"S3.T3.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">10.2</td>\n</tr>\n<tr id=\"S3.T3.1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">-</td>\n<td id=\"S3.T3.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\u2713</td>\n<td id=\"S3.T3.1.1.4.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">47.8</td>\n<td id=\"S3.T3.1.1.4.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">46.7</td>\n</tr>\n<tr id=\"S3.T3.1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">-</td>\n<td id=\"S3.T3.1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\" rowspan=\"2\"><span id=\"S3.T3.1.1.5.4.2.1\" class=\"ltx_text\">\u2713</span></td>\n<td id=\"S3.T3.1.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\u2717</td>\n<td id=\"S3.T3.1.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">11.4</td>\n<td id=\"S3.T3.1.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">10.1</td>\n</tr>\n<tr id=\"S3.T3.1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T3.1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">Tab.\u00a0<a href=\"#S3.T1\" title=\"Table 1 \u2023 3.1.4 Experimental results \u2023 3.1 Experiment with LibriMix \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, Sys. 8</td>\n<td id=\"S3.T3.1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">\u2713</td>\n<td id=\"S3.T3.1.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">10.3</td>\n<td id=\"S3.T3.1.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:10.0pt;padding-right:10.0pt;\">9.0</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 3 presents the impact of freezing the speech encoder during training. When the initialized speech encoder is not fine-tuned on LibriMix using the AED method, freezing the encoder results in poor performance because the encoder has not adapted to the LibriMix dataset. However, when using the encoder fine-tuned with LibriMix (Sys. 5, Tab. 1), freezing the encoder during training results in better performance. This is likely because the fine-tuned encoder already has excellent representation extraction capabilities on LibriMix and does not require further adjustment.",
            "Fig. 3 shows the comparison of training curves in the first training stage, where only the projector module is trained, using either a fine-tuned encoder or a non-fine-tuned encoder. When using the fine-tuned encoder, the model quickly converges to a very high accuracy. In contrast, using the original WavLM model results in slower and less complete convergence. This indicates that if we have a high-quality encoder, simply aligning the modality of speech representations with the LLM can directly achieve a relatively good performance. Conversely, for an unadapted encoder, merely training the projector to perform alignment is insufficient, which is similar to the conclusion in Table 3."
        ]
    },
    "S3.T4": {
        "caption": "Table 4 :  Performance comparison of single-stage training and multi-stage training strategy.  Multi-stage training refers to sequentially unfreezing and jointly training in the order of projector  \u2192 \u2192 \\rightarrow  speech encoder  \u2192 \u2192 \\rightarrow  LoRA. When the \u201cFreeze Encoder\u201d option in the table is set to True, the second stage is skipped. Single-stage training refers to jointly training all these modules from the beginning.",
        "table": "<figure id=\"S3.T4\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T4.7.3.1\" class=\"ltx_text ltx_font_bold\">Table 4</span>: </span>Performance comparison of single-stage training and multi-stage training strategy. <span id=\"S3.T4.4.2\" class=\"ltx_text\" style=\"color:#000000;\">Multi-stage training refers to sequentially unfreezing and jointly training in the order of projector <math id=\"S3.T4.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S3.T4.3.1.m1.1b\"><mo mathcolor=\"#000000\" stretchy=\"false\" id=\"S3.T4.3.1.m1.1.1\" xref=\"S3.T4.3.1.m1.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.3.1.m1.1c\"><ci id=\"S3.T4.3.1.m1.1.1.cmml\" xref=\"S3.T4.3.1.m1.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.3.1.m1.1d\">\\rightarrow</annotation></semantics></math> speech encoder <math id=\"S3.T4.4.2.m2.1\" class=\"ltx_Math\" alttext=\"\\rightarrow\" display=\"inline\"><semantics id=\"S3.T4.4.2.m2.1b\"><mo mathcolor=\"#000000\" stretchy=\"false\" id=\"S3.T4.4.2.m2.1.1\" xref=\"S3.T4.4.2.m2.1.1.cmml\">\u2192</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.4.2.m2.1c\"><ci id=\"S3.T4.4.2.m2.1.1.cmml\" xref=\"S3.T4.4.2.m2.1.1\">\u2192</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.4.2.m2.1d\">\\rightarrow</annotation></semantics></math> LoRA. When the \u201cFreeze Encoder\u201d option in the table is set to True, the second stage is skipped. Single-stage training refers to jointly training all these modules from the beginning.</span></figcaption>\n<div id=\"S3.T4.5\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:173.5pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(81.9pt,-32.8pt) scale(1.60686231624773,1.60686231624773) ;\">\n<table id=\"S3.T4.5.1\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T4.5.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T4.5.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"2\"><span id=\"S3.T4.5.1.1.2.1\" class=\"ltx_text\">Sys.</span></td>\n<td id=\"S3.T4.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"2\"><span id=\"S3.T4.5.1.1.3.1\" class=\"ltx_text\">\n<span id=\"S3.T4.5.1.1.3.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T4.5.1.1.3.1.1.1\" class=\"ltx_p\">Freeze</span>\n<span id=\"S3.T4.5.1.1.3.1.1.2\" class=\"ltx_p\">Encoder</span>\n</span></span></td>\n<td id=\"S3.T4.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"2\"><span id=\"S3.T4.5.1.1.4.1\" class=\"ltx_text\">\n<span id=\"S3.T4.5.1.1.4.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T4.5.1.1.4.1.1.1\" class=\"ltx_p\">Training</span>\n<span id=\"S3.T4.5.1.1.4.1.1.2\" class=\"ltx_p\">Strategy</span>\n</span></span></td>\n<td id=\"S3.T4.5.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" colspan=\"2\">WER\u00a0(%) <math id=\"S3.T4.5.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T4.5.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T4.5.1.1.1.m1.1.1\" xref=\"S3.T4.5.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T4.5.1.1.1.m1.1b\"><ci id=\"S3.T4.5.1.1.1.m1.1.1.cmml\" xref=\"S3.T4.5.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T4.5.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S3.T4.5.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T4.5.1.2.1.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">dev</td>\n<td id=\"S3.T4.5.1.2.1.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">test</td>\n</tr>\n<tr id=\"S3.T4.5.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T4.5.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">-</td>\n<td id=\"S3.T4.5.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"2\"><span id=\"S3.T4.5.1.3.2.2.1\" class=\"ltx_text\">\u2717</span></td>\n<td id=\"S3.T4.5.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">single-stage</td>\n<td id=\"S3.T4.5.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">11.7</td>\n<td id=\"S3.T4.5.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">10.4</td>\n</tr>\n<tr id=\"S3.T4.5.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T4.5.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">-</td>\n<td id=\"S3.T4.5.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">multi-stage</td>\n<td id=\"S3.T4.5.1.4.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">11.4</td>\n<td id=\"S3.T4.5.1.4.3.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">10.1</td>\n</tr>\n<tr id=\"S3.T4.5.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T4.5.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">-</td>\n<td id=\"S3.T4.5.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\" rowspan=\"2\"><span id=\"S3.T4.5.1.5.4.2.1\" class=\"ltx_text\">\u2713</span></td>\n<td id=\"S3.T4.5.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">single-stage</td>\n<td id=\"S3.T4.5.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">10.5</td>\n<td id=\"S3.T4.5.1.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">9.2</td>\n</tr>\n<tr id=\"S3.T4.5.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T4.5.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">Tab.\u00a0<a href=\"#S3.T1\" title=\"Table 1 \u2023 3.1.4 Experimental results \u2023 3.1 Experiment with LibriMix \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>, Sys. 8</td>\n<td id=\"S3.T4.5.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">multi-stage</td>\n<td id=\"S3.T4.5.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">10.3</td>\n<td id=\"S3.T4.5.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:8.5pt;padding-right:8.5pt;\">9.0</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 4 presents the comparison between single-stage and multi-stage training strategies. The results show that, regardless of whether the speech encoder is frozen, multi-stage training outperforms single-stage training. This indicates that multi-stage training helps the model better align auditory and textual information."
        ]
    },
    "S3.T5": {
        "caption": "Table 5 :  Overall performance comparison of various approaches on AMI-SDM evaluation set.  Sys. {1-3} are previous works that use large-scale supervised data for pre-training. Sys. {4-6} display the results of models pre-trained with only 0.83k hours of LibriMix and then fine-tuned on AMI, where Sys. 4 uses the AED-based architecture, and Sys. {5-6} use the LLM-based architecture. The WER (%) and cpWER (%) metrics are reported for the  utterance groups  with different numbers of speakers, as well as overall (average) results.",
        "table": "<figure id=\"S3.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T5.6.1.1\" class=\"ltx_text ltx_font_bold\">Table 5</span>: </span>Overall performance comparison of various approaches on AMI-SDM evaluation set. <span id=\"S3.T5.7.2\" class=\"ltx_text\" style=\"color:#000000;\">Sys. {1-3} are previous works that use large-scale supervised data for pre-training. Sys. {4-6} display the results of models pre-trained with only 0.83k hours of LibriMix and then fine-tuned on AMI, where Sys. 4 uses the AED-based architecture, and Sys. {5-6} use the LLM-based architecture. The WER (%) and cpWER (%) metrics are reported for the <span id=\"S3.T5.7.2.1\" class=\"ltx_text ltx_font_italic\">utterance groups</span> with different numbers of speakers, as well as overall (average) results.</span></figcaption>\n<div id=\"S3.T5.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:506.5pt;height:107.4pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-86.4pt,18.3pt) scale(0.74556982867391,0.74556982867391) ;\">\n<table id=\"S3.T5.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T5.2.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T5.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T5.2.2.2.3.1\" class=\"ltx_text\">Sys.</span></td>\n<td id=\"S3.T5.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T5.2.2.2.4.1\" class=\"ltx_text\">Architecture</span></td>\n<td id=\"S3.T5.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T5.2.2.2.5.1\" class=\"ltx_text\">\n<span id=\"S3.T5.2.2.2.5.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T5.2.2.2.5.1.1.1\" class=\"ltx_p\">Supervised</span>\n<span id=\"S3.T5.2.2.2.5.1.1.2\" class=\"ltx_p\">Pre-training data</span>\n</span></span></td>\n<td id=\"S3.T5.2.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T5.2.2.2.6.1\" class=\"ltx_text\">\n<span id=\"S3.T5.2.2.2.6.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T5.2.2.2.6.1.1.1\" class=\"ltx_p\">Fine-tuning</span>\n<span id=\"S3.T5.2.2.2.6.1.1.2\" class=\"ltx_p\">data</span>\n</span></span></td>\n<td id=\"S3.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" colspan=\"5\">WER (w.r.t. # of talkers) (%) <math id=\"S3.T5.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T5.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T5.1.1.1.1.m1.1.1\" xref=\"S3.T5.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T5.1.1.1.1.m1.1b\"><ci id=\"S3.T5.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T5.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T5.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n<td id=\"S3.T5.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" colspan=\"5\">cpWER (w.r.t. # of talkers) (%) <math id=\"S3.T5.2.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T5.2.2.2.2.m1.1a\"><mo stretchy=\"false\" id=\"S3.T5.2.2.2.2.m1.1.1\" xref=\"S3.T5.2.2.2.2.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T5.2.2.2.2.m1.1b\"><ci id=\"S3.T5.2.2.2.2.m1.1.1.cmml\" xref=\"S3.T5.2.2.2.2.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T5.2.2.2.2.m1.1c\">\\downarrow</annotation></semantics></math>\n</td>\n</tr>\n<tr id=\"S3.T5.3.3.4.1\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.4.1.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">avg.</td>\n<td id=\"S3.T5.3.3.4.1.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">1</td>\n<td id=\"S3.T5.3.3.4.1.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">2</td>\n<td id=\"S3.T5.3.3.4.1.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">3</td>\n<td id=\"S3.T5.3.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">4</td>\n<td id=\"S3.T5.3.3.4.1.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">avg.</td>\n<td id=\"S3.T5.3.3.4.1.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">1</td>\n<td id=\"S3.T5.3.3.4.1.8\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">2</td>\n<td id=\"S3.T5.3.3.4.1.9\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">3</td>\n<td id=\"S3.T5.3.3.4.1.10\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">4</td>\n</tr>\n<tr id=\"S3.T5.3.3.5.2\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.5.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">1</td>\n<td id=\"S3.T5.3.3.5.2.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Conformer AED\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">11</a>]</cite>\n</td>\n<td id=\"S3.T5.3.3.5.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">900k hrs</td>\n<td id=\"S3.T5.3.3.5.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"6\"><span id=\"S3.T5.3.3.5.2.4.1\" class=\"ltx_text\">AMI</span></td>\n<td id=\"S3.T5.3.3.5.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.5.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.5.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.5.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.5.2.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.5.2.10\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">21.2</td>\n<td id=\"S3.T5.3.3.5.2.11\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">14.7</td>\n<td id=\"S3.T5.3.3.5.2.12\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">19.6</td>\n<td id=\"S3.T5.3.3.5.2.13\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.5.2.13.1\" class=\"ltx_text ltx_font_bold\">25.7</span></td>\n<td id=\"S3.T5.3.3.5.2.14\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.5.2.14.1\" class=\"ltx_text ltx_font_bold\">35.5</span></td>\n</tr>\n<tr id=\"S3.T5.3.3.6.3\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.6.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">2</td>\n<td id=\"S3.T5.3.3.6.3.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Whisper medium\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">36</a>]</cite>\n</td>\n<td id=\"S3.T5.3.3.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"2\"><span id=\"S3.T5.3.3.6.3.3.1\" class=\"ltx_text\">680k hrs</span></td>\n<td id=\"S3.T5.3.3.6.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.6.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.6.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.6.3.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.6.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.6.3.9\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">23.6</td>\n<td id=\"S3.T5.3.3.6.3.10\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">12.8</td>\n<td id=\"S3.T5.3.3.6.3.11\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">21.8</td>\n<td id=\"S3.T5.3.3.6.3.12\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">32.5</td>\n<td id=\"S3.T5.3.3.6.3.13\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">45.9</td>\n</tr>\n<tr id=\"S3.T5.3.3.7.4\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.7.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">3</td>\n<td id=\"S3.T5.3.3.7.4.2\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">Whisper large\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">36</a>]</cite>\n</td>\n<td id=\"S3.T5.3.3.7.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.7.4.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.7.4.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.7.4.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.7.4.7\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">-</td>\n<td id=\"S3.T5.3.3.7.4.8\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">21.4</td>\n<td id=\"S3.T5.3.3.7.4.9\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">12.0</td>\n<td id=\"S3.T5.3.3.7.4.10\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">20.0</td>\n<td id=\"S3.T5.3.3.7.4.11\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">29.3</td>\n<td id=\"S3.T5.3.3.7.4.12\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">40.6</td>\n</tr>\n<tr id=\"S3.T5.3.3.8.5\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.8.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">4</td>\n<td id=\"S3.T5.3.3.8.5.2\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">WavLM Large AED</td>\n<td id=\"S3.T5.3.3.8.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\" rowspan=\"3\"><span id=\"S3.T5.3.3.8.5.3.1\" class=\"ltx_text ltx_font_bold\">0.83k hrs</span></td>\n<td id=\"S3.T5.3.3.8.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">30.5</td>\n<td id=\"S3.T5.3.3.8.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">16.7</td>\n<td id=\"S3.T5.3.3.8.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">26.2</td>\n<td id=\"S3.T5.3.3.8.5.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">45.8</td>\n<td id=\"S3.T5.3.3.8.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">54.8</td>\n<td id=\"S3.T5.3.3.8.5.9\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">24.1</td>\n<td id=\"S3.T5.3.3.8.5.10\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">10.8</td>\n<td id=\"S3.T5.3.3.8.5.11\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">20.4</td>\n<td id=\"S3.T5.3.3.8.5.12\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">37.9</td>\n<td id=\"S3.T5.3.3.8.5.13\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">48.6</td>\n</tr>\n<tr id=\"S3.T5.3.3.9.6\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.9.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">5</td>\n<td id=\"S3.T5.3.3.9.6.2\" class=\"ltx_td ltx_align_left ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">WavLM Large LLM</td>\n<td id=\"S3.T5.3.3.9.6.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">27.6</td>\n<td id=\"S3.T5.3.3.9.6.4\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">14.9</td>\n<td id=\"S3.T5.3.3.9.6.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">25.3</td>\n<td id=\"S3.T5.3.3.9.6.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">38.4</td>\n<td id=\"S3.T5.3.3.9.6.7\" class=\"ltx_td ltx_align_center ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">52.6</td>\n<td id=\"S3.T5.3.3.9.6.8\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">21.0</td>\n<td id=\"S3.T5.3.3.9.6.9\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">9.3</td>\n<td id=\"S3.T5.3.3.9.6.10\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">18.8</td>\n<td id=\"S3.T5.3.3.9.6.11\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">31.1</td>\n<td id=\"S3.T5.3.3.9.6.12\" class=\"ltx_td ltx_align_center\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">44.1</td>\n</tr>\n<tr id=\"S3.T5.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">6</td>\n<td id=\"S3.T5.3.3.3.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">\u00a0\u00a0\u00a0 + beam search (beam=4)</td>\n<td id=\"S3.T5.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">26.8</span></td>\n<td id=\"S3.T5.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">14.8</span></td>\n<td id=\"S3.T5.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.3.5.1\" class=\"ltx_text ltx_font_bold\">24.4</span></td>\n<td id=\"S3.T5.3.3.3.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.3.6.1\" class=\"ltx_text ltx_font_bold\">37.5</span></td>\n<td id=\"S3.T5.3.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.3.7.1\" class=\"ltx_text ltx_font_bold\">49.4</span></td>\n<td id=\"S3.T5.3.3.3.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.3.8.1\" class=\"ltx_text ltx_font_bold\">20.4</span></td>\n<td id=\"S3.T5.3.3.3.9\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.3.9.1\" class=\"ltx_text ltx_font_bold\">9.3</span></td>\n<td id=\"S3.T5.3.3.3.10\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\"><span id=\"S3.T5.3.3.3.10.1\" class=\"ltx_text ltx_font_bold\">18.1</span></td>\n<td id=\"S3.T5.3.3.3.11\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">30.3</td>\n<td id=\"S3.T5.3.3.3.12\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\" style=\"padding-left:5.7pt;padding-right:5.7pt;\">42.2</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The overall experimental results on the AMI-SDM evaluation set are presented in Table 5. Sys. {1-3} are from previous work, all relying on large-scale supervised data for pre-training. As shown by the experimental results, in terms of the average cpWER metric, the LLM-based approach (Sys. 5, Tab. 5) not only outperforms the AED-based method using the same amount of data (Sys. 4, Tab. 5) but also remarkably surpasses the models in Sys. {1-3} that were trained with large-scale supervised data. It is worth mentioning that Sys. 1 in Table 5 was trained using 900k hours of supervised data, which is 1000 times more than what we used.\nThis demonstrates that for SOT-based multi-talker ASR task, having a robust, large-scale pre-trained decoder is more important, as it provides strong capabilities in long-context awareness and cross-utterance modeling. This is precisely the advantage of LLM-based architectures over traditional AED-based systems in a such complex scenarios involving multi-talker conversations.\nAdditionally, the performance advancement of the LLM-based model over the AED-based method is further highlighted on the AMI evaluation set with an absolute WER reduction of 2.9% and cpWER reduction of 3.1% (Sys. 5 vs. 4, Tab. 5, column \"avg.\") comparing with the comparable systems evaluated on the LibriMix test set (Sys. 8 vs. 5, Tab. 1).\nThis indicates that the more realistic and complex the scenario, the greater the advantage of the LLM-based method, confirming our conjecture. Using beam search for decoding yields even better results (Sys. 6, Tab. 5).",
            "The overall experimental results on the AMI-SDM evaluation set are presented in Table 5. Sys. {1-3} are from previous work, all relying on large-scale supervised data for pre-training. As shown by the experimental results, in terms of the average cpWER metric, the LLM-based approach (Sys. 5, Tab. 5) not only outperforms the AED-based method using the same amount of data (Sys. 4, Tab. 5) but also remarkably surpasses the models in Sys. {1-3} that were trained with large-scale supervised data. It is worth mentioning that Sys. 1 in Table 5 was trained using 900k hours of supervised data, which is 1000 times more than what we used.\nThis demonstrates that for SOT-based multi-talker ASR task, having a robust, large-scale pre-trained decoder is more important, as it provides strong capabilities in long-context awareness and cross-utterance modeling. This is precisely the advantage of LLM-based architectures over traditional AED-based systems in a such complex scenarios involving multi-talker conversations.\nAdditionally, the performance advancement of the LLM-based model over the AED-based method is further highlighted on the AMI evaluation set with an absolute WER reduction of 2.9% and cpWER reduction of 3.1% (Sys. 5 vs. 4, Tab. 5, column \"avg.\") comparing with the comparable systems evaluated on the LibriMix test set (Sys. 8 vs. 5, Tab. 1).\nThis indicates that the more realistic and complex the scenario, the greater the advantage of the LLM-based method, confirming our conjecture. Using beam search for decoding yields even better results (Sys. 6, Tab. 5)."
        ]
    },
    "S3.T6": {
        "caption": "Table 6 :  Speaker counting accuracy (%) for each  utterance group  of AMI-SDM evaluation set. The number of talkers can be estimated by counting the segments obtained by separating SOT-style transcriptions with the speaker change symbol \u201c$\u201d. SOT follows speaker-wise FIFO, as shown in Fig.\u00a0 1 .",
        "table": "<figure id=\"S3.T6\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T6.4.1.1\" class=\"ltx_text ltx_font_bold\">Table 6</span>: </span><span id=\"S3.T6.5.2\" class=\"ltx_text\" style=\"color:#000000;\">Speaker counting accuracy (%) for each <span id=\"S3.T6.5.2.1\" class=\"ltx_text ltx_font_italic\">utterance group</span> of AMI-SDM evaluation set. The number of talkers can be estimated by counting the segments obtained by separating SOT-style transcriptions with the speaker change symbol \u201c$\u201d. SOT follows speaker-wise FIFO, as shown in Fig.\u00a0<a href=\"#S2.F1\" title=\"Figure 1 \u2023 2.1 Serialized Output Training \u2023 2 Method \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">1</span></a>.</span></figcaption>\n<div id=\"S3.T6.1\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:360.6pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(65.3pt,-54.3pt) scale(1.43110285796847,1.43110285796847) ;\">\n<table id=\"S3.T6.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T6.1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt ltx_border_t\" rowspan=\"2\"><span id=\"S3.T6.1.1.2.1.1.1\" class=\"ltx_text\">Sys.</span></th>\n<th id=\"S3.T6.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt ltx_border_t\" rowspan=\"2\"><span id=\"S3.T6.1.1.2.1.2.1\" class=\"ltx_text\">\n<span id=\"S3.T6.1.1.2.1.2.1.1\" class=\"ltx_inline-block\">\n<span id=\"S3.T6.1.1.2.1.2.1.1.1\" class=\"ltx_p\">Actual #</span>\n<span id=\"S3.T6.1.1.2.1.2.1.1.2\" class=\"ltx_p\">of talkers</span>\n</span></span></th>\n<td id=\"S3.T6.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt ltx_border_t\" colspan=\"6\">Estimated # of talkers</td>\n</tr>\n<tr id=\"S3.T6.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T6.1.1.1.2\" class=\"ltx_td ltx_align_center\">0</td>\n<td id=\"S3.T6.1.1.1.3\" class=\"ltx_td ltx_align_center\">1</td>\n<td id=\"S3.T6.1.1.1.4\" class=\"ltx_td ltx_align_center\">2</td>\n<td id=\"S3.T6.1.1.1.5\" class=\"ltx_td ltx_align_center\">3</td>\n<td id=\"S3.T6.1.1.1.6\" class=\"ltx_td ltx_align_center\">4</td>\n<td id=\"S3.T6.1.1.1.1\" class=\"ltx_td ltx_align_center\">\n<math id=\"S3.T6.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\geq\" display=\"inline\"><semantics id=\"S3.T6.1.1.1.1.m1.1a\"><mo id=\"S3.T6.1.1.1.1.m1.1.1\" xref=\"S3.T6.1.1.1.1.m1.1.1.cmml\">\u2265</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T6.1.1.1.1.m1.1b\"><geq id=\"S3.T6.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T6.1.1.1.1.m1.1.1\"></geq></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T6.1.1.1.1.m1.1c\">\\geq</annotation></semantics></math> 5</td>\n</tr>\n<tr id=\"S3.T6.1.1.3.2\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S3.T6.1.1.3.2.1.1\" class=\"ltx_text\">Tab.\u00a0<a href=\"#S3.T5\" title=\"Table 5 \u2023 3.2.1 Experimental settings \u2023 3.2 Experiment with AMI \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, Sys. 1</span></th>\n<th id=\"S3.T6.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">1</th>\n<td id=\"S3.T6.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.2</td>\n<td id=\"S3.T6.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.1.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">97.2</span></td>\n<td id=\"S3.T6.1.1.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">2.5</td>\n<td id=\"S3.T6.1.1.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1</td>\n<td id=\"S3.T6.1.1.3.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n<td id=\"S3.T6.1.1.3.2.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.4.3\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">2</th>\n<td id=\"S3.T6.1.1.4.3.2\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.4.3.3\" class=\"ltx_td ltx_align_center\">13.7</td>\n<td id=\"S3.T6.1.1.4.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T6.1.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">80.5</span></td>\n<td id=\"S3.T6.1.1.4.3.5\" class=\"ltx_td ltx_align_center\">5.9</td>\n<td id=\"S3.T6.1.1.4.3.6\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.4.3.7\" class=\"ltx_td ltx_align_center\">0.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.5.4\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">3</th>\n<td id=\"S3.T6.1.1.5.4.2\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.5.4.3\" class=\"ltx_td ltx_align_center\">2.4</td>\n<td id=\"S3.T6.1.1.5.4.4\" class=\"ltx_td ltx_align_center\">32.6</td>\n<td id=\"S3.T6.1.1.5.4.5\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T6.1.1.5.4.5.1\" class=\"ltx_text ltx_font_bold\">60.2</span></td>\n<td id=\"S3.T6.1.1.5.4.6\" class=\"ltx_td ltx_align_center\">4.8</td>\n<td id=\"S3.T6.1.1.5.4.7\" class=\"ltx_td ltx_align_center\">0.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.6.5\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">4</th>\n<td id=\"S3.T6.1.1.6.5.2\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.6.5.3\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.6.5.4\" class=\"ltx_td ltx_align_center\">9.9</td>\n<td id=\"S3.T6.1.1.6.5.5\" class=\"ltx_td ltx_align_center\">51.2</td>\n<td id=\"S3.T6.1.1.6.5.6\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T6.1.1.6.5.6.1\" class=\"ltx_text ltx_font_bold\">38.9</span></td>\n<td id=\"S3.T6.1.1.6.5.7\" class=\"ltx_td ltx_align_center\">0.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.7.6\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S3.T6.1.1.7.6.1.1\" class=\"ltx_text\">Tab.\u00a0<a href=\"#S3.T5\" title=\"Table 5 \u2023 3.2.1 Experimental settings \u2023 3.2 Experiment with AMI \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, Sys. 4</span></th>\n<th id=\"S3.T6.1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">1</th>\n<td id=\"S3.T6.1.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n<td id=\"S3.T6.1.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.1.1.7.6.4.1\" class=\"ltx_text ltx_font_bold\">92.1</span></td>\n<td id=\"S3.T6.1.1.7.6.5\" class=\"ltx_td ltx_align_center ltx_border_t\">7.6</td>\n<td id=\"S3.T6.1.1.7.6.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.3</td>\n<td id=\"S3.T6.1.1.7.6.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n<td id=\"S3.T6.1.1.7.6.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.8.7\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">2</th>\n<td id=\"S3.T6.1.1.8.7.2\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.8.7.3\" class=\"ltx_td ltx_align_center\">10.0</td>\n<td id=\"S3.T6.1.1.8.7.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T6.1.1.8.7.4.1\" class=\"ltx_text ltx_font_bold\">73.0</span></td>\n<td id=\"S3.T6.1.1.8.7.5\" class=\"ltx_td ltx_align_center\">16.4</td>\n<td id=\"S3.T6.1.1.8.7.6\" class=\"ltx_td ltx_align_center\">0.6</td>\n<td id=\"S3.T6.1.1.8.7.7\" class=\"ltx_td ltx_align_center\">0.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.9.8\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.9.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">3</th>\n<td id=\"S3.T6.1.1.9.8.2\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.9.8.3\" class=\"ltx_td ltx_align_center\">0.8</td>\n<td id=\"S3.T6.1.1.9.8.4\" class=\"ltx_td ltx_align_center\">30.2</td>\n<td id=\"S3.T6.1.1.9.8.5\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T6.1.1.9.8.5.1\" class=\"ltx_text ltx_font_bold\">58.0</span></td>\n<td id=\"S3.T6.1.1.9.8.6\" class=\"ltx_td ltx_align_center\">10.1</td>\n<td id=\"S3.T6.1.1.9.8.7\" class=\"ltx_td ltx_align_center\">0.9</td>\n</tr>\n<tr id=\"S3.T6.1.1.10.9\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.10.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">4</th>\n<td id=\"S3.T6.1.1.10.9.2\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.10.9.3\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.10.9.4\" class=\"ltx_td ltx_align_center\">5.5</td>\n<td id=\"S3.T6.1.1.10.9.5\" class=\"ltx_td ltx_align_center\">52.0</td>\n<td id=\"S3.T6.1.1.10.9.6\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T6.1.1.10.9.6.1\" class=\"ltx_text ltx_font_bold\">33.5</span></td>\n<td id=\"S3.T6.1.1.10.9.7\" class=\"ltx_td ltx_align_center\">9.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.11.10\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.11.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S3.T6.1.1.11.10.1.1\" class=\"ltx_text\">Tab.\u00a0<a href=\"#S3.T5\" title=\"Table 5 \u2023 3.2.1 Experimental settings \u2023 3.2 Experiment with AMI \u2023 3 Experiments \u2023 Advancing Multi-talker ASR Performance with Large Language Models\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>, Sys. 5</span></th>\n<th id=\"S3.T6.1.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">1</th>\n<td id=\"S3.T6.1.1.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n<td id=\"S3.T6.1.1.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.1.1.11.10.4.1\" class=\"ltx_text ltx_font_bold\">96.7</span></td>\n<td id=\"S3.T6.1.1.11.10.5\" class=\"ltx_td ltx_align_center ltx_border_t\">3.2</td>\n<td id=\"S3.T6.1.1.11.10.6\" class=\"ltx_td ltx_align_center ltx_border_t\">0.1</td>\n<td id=\"S3.T6.1.1.11.10.7\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n<td id=\"S3.T6.1.1.11.10.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.12.11\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.12.11.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">2</th>\n<td id=\"S3.T6.1.1.12.11.2\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.12.11.3\" class=\"ltx_td ltx_align_center\">11.7</td>\n<td id=\"S3.T6.1.1.12.11.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T6.1.1.12.11.4.1\" class=\"ltx_text ltx_font_bold\">76.9</span></td>\n<td id=\"S3.T6.1.1.12.11.5\" class=\"ltx_td ltx_align_center\">11.0</td>\n<td id=\"S3.T6.1.1.12.11.6\" class=\"ltx_td ltx_align_center\">0.4</td>\n<td id=\"S3.T6.1.1.12.11.7\" class=\"ltx_td ltx_align_center\">0.0</td>\n</tr>\n<tr id=\"S3.T6.1.1.13.12\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.13.12.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">3</th>\n<td id=\"S3.T6.1.1.13.12.2\" class=\"ltx_td ltx_align_center\">0.0</td>\n<td id=\"S3.T6.1.1.13.12.3\" class=\"ltx_td ltx_align_center\">1.3</td>\n<td id=\"S3.T6.1.1.13.12.4\" class=\"ltx_td ltx_align_center\">39.3</td>\n<td id=\"S3.T6.1.1.13.12.5\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T6.1.1.13.12.5.1\" class=\"ltx_text ltx_font_bold\">48.4</span></td>\n<td id=\"S3.T6.1.1.13.12.6\" class=\"ltx_td ltx_align_center\">10.8</td>\n<td id=\"S3.T6.1.1.13.12.7\" class=\"ltx_td ltx_align_center\">0.2</td>\n</tr>\n<tr id=\"S3.T6.1.1.14.13\" class=\"ltx_tr\">\n<th id=\"S3.T6.1.1.14.13.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r\">4</th>\n<td id=\"S3.T6.1.1.14.13.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\">0.0</td>\n<td id=\"S3.T6.1.1.14.13.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\">0.0</td>\n<td id=\"S3.T6.1.1.14.13.4\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\">10.5</td>\n<td id=\"S3.T6.1.1.14.13.5\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\">53.0</td>\n<td id=\"S3.T6.1.1.14.13.6\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\"><span id=\"S3.T6.1.1.14.13.6.1\" class=\"ltx_text ltx_font_bold\">35.0</span></td>\n<td id=\"S3.T6.1.1.14.13.7\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_b\">1.5</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We calculated the speaker counting accuracy and presented it in Table 6. From the results, it can be observed that the LLM-based method (Tab. 5, Sys. 5) is less accurate in estimating the number of speakers compared to the AED model trained with large-scale supervised data (Tab. 5, Sys. 1). Additionally, in the cases of 3 and 4 speakers, it also shows no significant advantage over the AED model using the same amount of data (Tab. 5, Sys. 4). Despite the lower accuracy in speaker counting, the LLM-based method achieves the best performance in the cpWER metric, indicating that it has a very high accuracy in recognizing the content of transcriptions in complex scenarios involving multi-talker conversations with noise and reverberation."
        ]
    }
}