{
    "S1.T1": {
        "caption": "Table 1 :  Examples of different diarization errors (errors are underlined and marked in pink color).",
        "table": "<figure id=\"S1.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S1.T1.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 1</span>: </span>Examples of different diarization errors (errors are underlined and marked in pink color).</figcaption>\n<table id=\"S1.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S1.T1.3.1.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r\">Error Type</th>\n<th id=\"S1.T1.3.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column\">Example</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S1.T1.3.2.1\" class=\"ltx_tr\">\n<th id=\"S1.T1.3.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Type a</th>\n<td id=\"S1.T1.3.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<table id=\"S1.T1.3.2.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S1.T1.3.2.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.2.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S1.T1.3.2.1.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Speaker A:</span></td>\n</tr>\n<tr id=\"S1.T1.3.2.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.2.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">right that\u2019s going exactly going back to facebook\u2019s optimizer algorithm that\u2019s not optimizing for truth right</td>\n</tr>\n<tr id=\"S1.T1.3.2.1.2.1.3\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.2.1.2.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">it\u2019s optimizing for profit and they they claim to be neutral but of course nothing\u2019s neutral <span id=\"S1.T1.3.2.1.2.1.3.1.1\" class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"background-color:#FFBFBF;\">right</span> and we have</td>\n</tr>\n<tr id=\"S1.T1.3.2.1.2.1.4\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.2.1.2.1.4.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">seen the results we\u2019ve seen what it\u2019s actually optimized for and it\u2019s not pretty</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"S1.T1.3.3.2\" class=\"ltx_tr\">\n<th id=\"S1.T1.3.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Type b</th>\n<td id=\"S1.T1.3.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<table id=\"S1.T1.3.3.2.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S1.T1.3.3.2.2.1.1\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.3.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S1.T1.3.3.2.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Speaker A:</span></td>\n</tr>\n<tr id=\"S1.T1.3.3.2.2.1.2\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.3.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">and presumably you could take all that biased input data and say this high chance recidivism means that we</td>\n</tr>\n<tr id=\"S1.T1.3.3.2.2.1.3\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.3.2.2.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">should rehabilitate more i mean like you could take all that same stuff and choose to do a completely different</td>\n</tr>\n<tr id=\"S1.T1.3.3.2.2.1.4\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.3.2.2.1.4.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">thing with the result of</td>\n</tr>\n<tr id=\"S1.T1.3.3.2.2.1.5\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.3.2.2.1.5.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S1.T1.3.3.2.2.1.5.1.1\" class=\"ltx_text ltx_font_bold\">Speaker B:</span></td>\n</tr>\n<tr id=\"S1.T1.3.3.2.2.1.6\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.3.2.2.1.6.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">\n<span id=\"S1.T1.3.3.2.2.1.6.1.1\" class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"background-color:#FFBFBF;\">the algorithm</span> total that\u2019s exactly my point exactly my point you know we could say oh i wonder why people</td>\n</tr>\n<tr id=\"S1.T1.3.3.2.2.1.7\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.3.2.2.1.7.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">who have this characteristic have so much worse recidivism well let\u2019s try to help them find a job maybe that\u2019ll</td>\n</tr>\n<tr id=\"S1.T1.3.3.2.2.1.8\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.3.2.2.1.8.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">help we could use those algorithms those risk scores to try to account for our society</td>\n</tr>\n</table>\n</td>\n</tr>\n<tr id=\"S1.T1.3.4.3\" class=\"ltx_tr\">\n<th id=\"S1.T1.3.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Type c</th>\n<td id=\"S1.T1.3.4.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">\n<table id=\"S1.T1.3.4.3.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S1.T1.3.4.3.2.1.1\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.4.3.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S1.T1.3.4.3.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Speaker A:</span></td>\n</tr>\n<tr id=\"S1.T1.3.4.3.2.1.2\" class=\"ltx_tr\">\n<td id=\"S1.T1.3.4.3.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\"><span id=\"S1.T1.3.4.3.2.1.2.1.1\" class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"background-color:#FFBFBF;\">is this a good or bad thing that social media has been able to infiltrate politics</span></td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The main cause of errors of type (a) and (b) is the use of uniform audio segmentation with a high temporal resolution. Inaccurate word timestamps can also lead to type (b) errors. Type (c) errors typically occur due to inaccurate estimation of the number of speakers and incorrect clustering. Background noise, music and reverberation also contribute to all types of errors. Examples of each type of error are illustrated in Table 1."
        ]
    },
    "S4.T2": {
        "caption": "Table 2 :  Example of ambiguous sample.",
        "table": "<figure id=\"S4.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T2.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 2</span>: </span>Example of ambiguous sample.</figcaption>\n<table id=\"S4.T2.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T2.3.1.1\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">Reference Tags</td>\n<td id=\"S4.T2.3.1.1.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_tt\">spk1 spk1 spk1 spk1 spk1 spk1 spk1</td>\n</tr>\n<tr id=\"S4.T2.3.2.2\" class=\"ltx_tr\">\n<td id=\"S4.T2.3.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t\">Simulated Tags</td>\n<td id=\"S4.T2.3.2.2.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t\">spk1 spk1 spk2 spk2 spk2 spk2 spk2</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Our goal is to accurately predict speaker segmentation, even though the concept of speaker ID can sometimes be ambiguous. Consider the motivating example illustrated in Table 2. The model can either correct the first two tags or the last five tags. To handle such cases, we use permutation invariant cross-entropy loss for speaker tag classification, which selects a permutation of speakers that results in the minimum loss."
        ]
    },
    "S4.T3": {
        "caption": "Table 3 :  Top three alternates generated by the ASP model.",
        "table": "<figure id=\"S4.T3\" class=\"ltx_table\">\n<div id=\"S4.T3.2\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:227.9pt;height:155.1pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-18.3pt,12.4pt) scale(0.861824197011297,0.861824197011297) ;\">\n<table id=\"S4.T3.2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S4.T3.2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt\"><span id=\"S4.T3.2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Word</span></th>\n<td id=\"S4.T3.2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T3.2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Top1</span></td>\n<td id=\"S4.T3.2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S4.T3.2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Top2</span></td>\n<td id=\"S4.T3.2.1.1.1.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_tt\"><span id=\"S4.T3.2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">Top3</span></td>\n</tr>\n<tr id=\"S4.T3.2.1.2.2\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"4\"><span id=\"S4.T3.2.1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Words seen during training</span></th>\n</tr>\n<tr id=\"S4.T3.2.1.3.3\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.3.3.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t\">hashimoto</th>\n<td id=\"S4.T3.2.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">hashamoto</td>\n<td id=\"S4.T3.2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">hashimoto</td>\n<td id=\"S4.T3.2.1.3.3.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">hashamato</td>\n</tr>\n<tr id=\"S4.T3.2.1.4.4\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.4.4.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\">jupyter</th>\n<td id=\"S4.T3.2.1.4.4.2\" class=\"ltx_td ltx_align_center\">jupiter</td>\n<td id=\"S4.T3.2.1.4.4.3\" class=\"ltx_td ltx_align_center\">jupitor</td>\n<td id=\"S4.T3.2.1.4.4.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">jupitter</td>\n</tr>\n<tr id=\"S4.T3.2.1.5.5\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.5.5.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\">kotlin</th>\n<td id=\"S4.T3.2.1.5.5.2\" class=\"ltx_td ltx_align_center\">cotlin</td>\n<td id=\"S4.T3.2.1.5.5.3\" class=\"ltx_td ltx_align_center\">cotlan</td>\n<td id=\"S4.T3.2.1.5.5.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">codlin</td>\n</tr>\n<tr id=\"S4.T3.2.1.6.6\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.6.6.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\">pulumi</th>\n<td id=\"S4.T3.2.1.6.6.2\" class=\"ltx_td ltx_align_center\">pulumi</td>\n<td id=\"S4.T3.2.1.6.6.3\" class=\"ltx_td ltx_align_center\">polumi</td>\n<td id=\"S4.T3.2.1.6.6.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">poulumi</td>\n</tr>\n<tr id=\"S4.T3.2.1.7.7\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\" colspan=\"4\"><span id=\"S4.T3.2.1.7.7.1.1\" class=\"ltx_text ltx_font_bold\">Words unseen during training</span></th>\n</tr>\n<tr id=\"S4.T3.2.1.8.8\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.8.8.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t\">farnoosh</th>\n<td id=\"S4.T3.2.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">farnosh</td>\n<td id=\"S4.T3.2.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">farnush</td>\n<td id=\"S4.T3.2.1.8.8.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">farnash</td>\n</tr>\n<tr id=\"S4.T3.2.1.9.9\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.9.9.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\">doernenburg</th>\n<td id=\"S4.T3.2.1.9.9.2\" class=\"ltx_td ltx_align_center\">dornenburg</td>\n<td id=\"S4.T3.2.1.9.9.3\" class=\"ltx_td ltx_align_center\">doernenberg</td>\n<td id=\"S4.T3.2.1.9.9.4\" class=\"ltx_td ltx_nopad_r ltx_align_center\">doernenburg</td>\n</tr>\n<tr id=\"S4.T3.2.1.10.10\" class=\"ltx_tr\">\n<th id=\"S4.T3.2.1.10.10.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r\">odersky</th>\n<td id=\"S4.T3.2.1.10.10.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">oderski</td>\n<td id=\"S4.T3.2.1.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">odersky</td>\n<td id=\"S4.T3.2.1.10.10.4\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">odderski</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T3.3.1.1\" class=\"ltx_text ltx_font_bold\">Table 3</span>: </span>Top three alternates generated by the ASP model.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "To test the accuracy of the ASP model, we measure the BLEU score [19] between the word pieces of the reference and predicted alternates. Table 4 shows the results of the ASP model on the test set. For comparison, we present the baseline score for an identity system that keeps the input word unchanged. In addition, we report the score obtained by a refined ASP model using beam search. Table 3 illustrates examples of alternates that the ASP model produces."
        ]
    },
    "S5.T4": {
        "caption": "Table 4 :  Performance of the ASP model with and without beam search in comparison to the identity baseline.",
        "table": "<figure id=\"S5.T4\" class=\"ltx_table\">\n<table id=\"S5.T4.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T4.2.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.2.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row\" style=\"padding-bottom:0.86108pt;\"><span id=\"S5.T4.2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th id=\"S5.T4.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\" style=\"padding-bottom:0.86108pt;\"><span id=\"S5.T4.2.1.1.2.1\" class=\"ltx_text ltx_font_bold\">BLEU</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T4.2.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T4.2.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-bottom:0.86108pt;\">Identity</th>\n<td id=\"S5.T4.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-bottom:0.86108pt;\">0.48</td>\n</tr>\n<tr id=\"S5.T4.2.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T4.2.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\" style=\"padding-bottom:0.86108pt;\">ASP with greedy decoding</th>\n<td id=\"S5.T4.2.3.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:0.86108pt;\">0.6</td>\n</tr>\n<tr id=\"S5.T4.2.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T4.2.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\">ASP with beam search</th>\n<td id=\"S5.T4.2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\">0.605</td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S5.T4.3.1.1\" class=\"ltx_text ltx_font_bold\">Table 4</span>: </span>Performance of the ASP model with and without beam search in comparison to the identity baseline.</figcaption>\n</figure>\n",
        "footnotes": [],
        "references": [
            "To test the accuracy of the ASP model, we measure the BLEU score [19] between the word pieces of the reference and predicted alternates. Table 4 shows the results of the ASP model on the test set. For comparison, we present the baseline score for an identity system that keeps the input word unchanged. In addition, we report the score obtained by a refined ASP model using beam search. Table 3 illustrates examples of alternates that the ASP model produces."
        ]
    },
    "S5.T5": {
        "caption": "Table 5 :  Example case from the TAL testing set (errors are underlined and marked in pink color).",
        "table": "<figure id=\"S5.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S5.T5.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 5</span>: </span>Example case from the TAL testing set (errors are underlined and marked in pink color).</figcaption>\n<table id=\"S5.T5.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T5.3.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T5.3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Before Correction</th>\n<th id=\"S5.T5.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">After Correction</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T5.3.2.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_t\">\n<table id=\"S5.T5.3.2.1.1.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T5.3.2.1.1.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.1.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">[spk2]: three percent to five percent you mean of all</td>\n</tr>\n<tr id=\"S5.T5.3.2.1.1.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.1.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">healthcare</td>\n</tr>\n<tr id=\"S5.T5.3.2.1.1.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.1.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">[spk5]: <span id=\"S5.T5.3.2.1.1.1.3.1.1\" class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"background-color:#FFBFBF;\">professionals</span> all across the profession <span id=\"S5.T5.3.2.1.1.1.3.1.2\" class=\"ltx_text ltx_framed ltx_framed_underline\" style=\"background-color:#FFBFBF;\">wow</span>\n</td>\n</tr>\n<tr id=\"S5.T5.3.2.1.1.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.1.1.4.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">[spk2]: which drugs</td>\n</tr>\n</table>\n</td>\n<td id=\"S5.T5.3.2.1.2\" class=\"ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t\">\n<table id=\"S5.T5.3.2.1.2.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S5.T5.3.2.1.2.1.1\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">[spk2]: three percent to five percent you mean of all</td>\n</tr>\n<tr id=\"S5.T5.3.2.1.2.1.2\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">healthcare professionals</td>\n</tr>\n<tr id=\"S5.T5.3.2.1.2.1.3\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.2.1.3.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">[spk5]: all across the profession</td>\n</tr>\n<tr id=\"S5.T5.3.2.1.2.1.4\" class=\"ltx_tr\">\n<td id=\"S5.T5.3.2.1.2.1.4.1\" class=\"ltx_td ltx_nopad_r ltx_align_left\">[spk2]: wow which drugs</td>\n</tr>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "From Table 6 and Table 7 we can see that the SEC model consistently outperforms the \"No Correction\" baseline across different datasets. For instance, on the Fisher dataset, the SEC model reduces the WDER from 2.8% to 2.42%. Similarly, on the TAL dataset, the WDER decreases from 4.25% to 4.11%. This improvement is also evident in the cpWER metric for the SLT GenSEC Challenge Track-2 datasets, where the SEC model achieves lower error rates on both the dev and eval sets compared to the baseline [4]. Table 5 presents an example case from the TAL testing set, where we see improvements after applying the speaker error correction model."
        ]
    },
    "S5.T6": {
        "caption": "Table 6 :  The performance of the SEC model on the Fisher and TAL datasets. The results are reported in WDER. The x/y notation signifies the number of incorrectly assigned words (x) out of the total words analyzed (y).",
        "table": "<figure id=\"S5.T6\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S5.T6.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 6</span>: </span>The performance of the SEC model on the Fisher and TAL datasets. The results are reported in WDER. The x/y notation signifies the number of incorrectly assigned words (x) out of the total words analyzed (y).</figcaption>\n<table id=\"S5.T6.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T6.3.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T6.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Model Type</th>\n<th id=\"S5.T6.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">Fisher</th>\n<th id=\"S5.T6.3.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\">TAL</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T6.3.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T6.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">No Correction</th>\n<td id=\"S5.T6.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">2.8 (7673/274398)</td>\n<td id=\"S5.T6.3.2.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">4.25 (14487/340991)</td>\n</tr>\n<tr id=\"S5.T6.3.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T6.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">SEC</th>\n<td id=\"S5.T6.3.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">2.42 (6653/274398)</td>\n<td id=\"S5.T6.3.3.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">4.11 (14012/340991)</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "From Table 6 and Table 7 we can see that the SEC model consistently outperforms the \"No Correction\" baseline across different datasets. For instance, on the Fisher dataset, the SEC model reduces the WDER from 2.8% to 2.42%. Similarly, on the TAL dataset, the WDER decreases from 4.25% to 4.11%. This improvement is also evident in the cpWER metric for the SLT GenSEC Challenge Track-2 datasets, where the SEC model achieves lower error rates on both the dev and eval sets compared to the baseline [4]. Table 5 presents an example case from the TAL testing set, where we see improvements after applying the speaker error correction model."
        ]
    },
    "S5.T7": {
        "caption": "Table 7 :  The performance of the SEC model on the SLT GenSEC Challenge Track-2 dev and eval datasets. The results are reported in cpWER.",
        "table": "<figure id=\"S5.T7\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S5.T7.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 7</span>: </span>The performance of the SEC model on the SLT GenSEC Challenge Track-2 dev and eval datasets. The results are reported in cpWER.</figcaption>\n<table id=\"S5.T7.3\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S5.T7.3.1.1\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Model Type</th>\n<th id=\"S5.T7.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">dev</th>\n<th id=\"S5.T7.3.1.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt\">eval</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S5.T7.3.2.1\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">No Correction</th>\n<td id=\"S5.T7.3.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">24.64 (5998/24335)</td>\n<td id=\"S5.T7.3.2.1.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_t\">28.45 (5563/19552)</td>\n</tr>\n<tr id=\"S5.T7.3.3.2\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Baseline</th>\n<td id=\"S5.T7.3.3.2.2\" class=\"ltx_td ltx_align_center\">24.53 (5971/24335)</td>\n<td id=\"S5.T7.3.3.2.3\" class=\"ltx_td ltx_nopad_r ltx_align_center\">28.36 (5546/19552)</td>\n</tr>\n<tr id=\"S5.T7.3.4.3\" class=\"ltx_tr\">\n<th id=\"S5.T7.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">SEC</th>\n<td id=\"S5.T7.3.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">23.97 (5834/24335)</td>\n<td id=\"S5.T7.3.4.3.3\" class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_bb\">27.76 (5429/19552)</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "From Table 6 and Table 7 we can see that the SEC model consistently outperforms the \"No Correction\" baseline across different datasets. For instance, on the Fisher dataset, the SEC model reduces the WDER from 2.8% to 2.42%. Similarly, on the TAL dataset, the WDER decreases from 4.25% to 4.11%. This improvement is also evident in the cpWER metric for the SLT GenSEC Challenge Track-2 datasets, where the SEC model achieves lower error rates on both the dev and eval sets compared to the baseline [4]. Table 5 presents an example case from the TAL testing set, where we see improvements after applying the speaker error correction model."
        ]
    }
}