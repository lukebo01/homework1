{
    "S3.T1": {
        "caption": "Table 1:  Proposed models comparison with SOTA methods from literature.",
        "table": "<figure id=\"S3.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Proposed models comparison with SOTA methods from literature.</figcaption>\n<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Model</span></th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Accuracy</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">ViT<span id=\"footnotex3\" class=\"ltx_note ltx_role_footnote\"><sup class=\"ltx_note_mark\">7</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">7</sup><span class=\"ltx_tag ltx_tag_note\">7</span>The model has been reimplemented.</span></span></span>\n</td>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">91.79%</td>\n</tr>\n<tr id=\"S3.T1.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">RNNCA\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib21\" title=\"\" class=\"ltx_ref\">21</a>]</cite>\n</td>\n<td id=\"S3.T1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.1%</td>\n</tr>\n<tr id=\"S3.T1.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">1D-CNN with BiRNN and attention mechanism\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S3.T1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">91.99%</td>\n</tr>\n<tr id=\"S3.T1.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">SA-SLnO with optimization\u00a0<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S3.T1.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">85.63%</td>\n</tr>\n<tr id=\"S3.T1.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.6.5.1.1\" class=\"ltx_text ltx_font_bold\">EAViT (our)</span></td>\n<td id=\"S3.T1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><span id=\"S3.T1.1.6.5.2.1\" class=\"ltx_text ltx_font_bold\">93.99%</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "To demonstrate the robustness and efficacy of the proposed model in this study, we conducted a comparative analysis with state-of-the-art (SOTA) models from the literature, including ViT [15], Recurrent Neural Networks with Channel Attention Mechanism (RNNCA) [21], 1D-CNN with BiRNN and attention mechanism [22], and SA-SLnO with optimization [23]. Table 1 unequivocally shows that the results of our proposed method surpass the performance of these SOTA models. EAViT surpasses the ViT by 2.37%, RNNCA by 0.95%, and the 1D-CNN with BiRNN and attention mechanism by 2.15%. Furthermore, in comparison to SA-SLnO with optimization model, EAViT achieves a remarkable 9.31% increase in classification accuracy. Here, Table 2 presents the evaluation metrics, including Precision, Recall, and F1-score, for each class of the proposed EAViT model. These findings underscore the robustness of the proposed model as it demonstrates consistent performance across various classes."
        ]
    },
    "S3.T2": {
        "caption": "Table 2:  Evaluation of class-specific classification results of the proposed EAViT model",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Evaluation of class-specific classification results of the proposed EAViT model</figcaption>\n<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Class</span></th>\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Precision</span></th>\n<th id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Recall</span></th>\n<th id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S3.T2.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">F1-Score</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.2.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Blues</td>\n<td id=\"S3.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.94</td>\n<td id=\"S3.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.96</td>\n<td id=\"S3.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.95</td>\n</tr>\n<tr id=\"S3.T2.1.3.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Classical</td>\n<td id=\"S3.T2.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.99</td>\n<td id=\"S3.T2.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.97</td>\n<td id=\"S3.T2.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.98</td>\n</tr>\n<tr id=\"S3.T2.1.4.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Country</td>\n<td id=\"S3.T2.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.89</td>\n<td id=\"S3.T2.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.93</td>\n<td id=\"S3.T2.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.91</td>\n</tr>\n<tr id=\"S3.T2.1.5.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Disco</td>\n<td id=\"S3.T2.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.95</td>\n<td id=\"S3.T2.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.97</td>\n<td id=\"S3.T2.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.96</td>\n</tr>\n<tr id=\"S3.T2.1.6.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Hiphop</td>\n<td id=\"S3.T2.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.93</td>\n<td id=\"S3.T2.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.90</td>\n<td id=\"S3.T2.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.91</td>\n</tr>\n<tr id=\"S3.T2.1.7.6\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Jazz</td>\n<td id=\"S3.T2.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.92</td>\n<td id=\"S3.T2.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.94</td>\n<td id=\"S3.T2.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.93</td>\n</tr>\n<tr id=\"S3.T2.1.8.7\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Metal</td>\n<td id=\"S3.T2.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.96</td>\n<td id=\"S3.T2.1.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.93</td>\n<td id=\"S3.T2.1.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.95</td>\n</tr>\n<tr id=\"S3.T2.1.9.8\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.9.8.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Pop</td>\n<td id=\"S3.T2.1.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.99</td>\n<td id=\"S3.T2.1.9.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.92</td>\n<td id=\"S3.T2.1.9.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.96</td>\n</tr>\n<tr id=\"S3.T2.1.10.9\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.10.9.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Reggae</td>\n<td id=\"S3.T2.1.10.9.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.93</td>\n<td id=\"S3.T2.1.10.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.92</td>\n<td id=\"S3.T2.1.10.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.93</td>\n</tr>\n<tr id=\"S3.T2.1.11.10\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.11.10.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t\">Rock</td>\n<td id=\"S3.T2.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.90</td>\n<td id=\"S3.T2.1.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.94</td>\n<td id=\"S3.T2.1.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">0.92</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "To demonstrate the robustness and efficacy of the proposed model in this study, we conducted a comparative analysis with state-of-the-art (SOTA) models from the literature, including ViT [15], Recurrent Neural Networks with Channel Attention Mechanism (RNNCA) [21], 1D-CNN with BiRNN and attention mechanism [22], and SA-SLnO with optimization [23]. Table 1 unequivocally shows that the results of our proposed method surpass the performance of these SOTA models. EAViT surpasses the ViT by 2.37%, RNNCA by 0.95%, and the 1D-CNN with BiRNN and attention mechanism by 2.15%. Furthermore, in comparison to SA-SLnO with optimization model, EAViT achieves a remarkable 9.31% increase in classification accuracy. Here, Table 2 presents the evaluation metrics, including Precision, Recall, and F1-score, for each class of the proposed EAViT model. These findings underscore the robustness of the proposed model as it demonstrates consistent performance across various classes."
        ]
    }
}