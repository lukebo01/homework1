{
    "S3.T1": {
        "caption": "Table 1:  The sizes of training and testing datasets.",
        "table": "<figure id=\"S3.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>The sizes of training and testing datasets.</figcaption>\n<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\">Dataset</th>\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">D1</th>\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">D2</th>\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">D3</th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T1.1.2.1\" class=\"ltx_tr\">\n<th id=\"S3.T1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_t\">IEMOCAP</th>\n<td id=\"S3.T1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">1710</td>\n<td id=\"S3.T1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">3421</td>\n<td id=\"S3.T1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">400</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "As shown in Table 1, following the methodology proposed by [17], we partition the IEMOCAP dataset into three distinct subsets tailored for addressing ambiguous SER scenarios. Specifically, D1 encompasses precise labeled samples exhibiting minimal ambiguity in emotional classification. D2 comprises unlabeled samples with moderate ambiguity in emotion. D3, on the other hand, includes labeled samples characterized by the highest degree of ambiguity in emotion, serving as the evaluation set. The determination of emotion ambiguity is predicated on the level of consensus among experts during the annotation process. For each utterance in IEMOCAP, multiple experts contribute their assessments, and the consistency of their judgments dictates the attribution of the sample. A high level of agreement among annotators results in D1, whereas increased variability in assessments places a sample within D2. Samples demonstrating substantial disagreement among annotators are designated to D3."
        ]
    },
    "S3.T2": {
        "caption": "Table 2:  Performance comparison of our proposed methods with SOTA approaches on IEMOCAP.",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Performance comparison of our proposed methods with SOTA approaches on IEMOCAP.</figcaption>\n<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></td>\n<td id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Description</span></td>\n<td id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Acc(%)</span></td>\n</tr>\n<tr id=\"S3.T2.1.2.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Cummins et al.<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\">22</a>]</cite>\n</td>\n<td id=\"S3.T2.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">AlexNet</td>\n<td id=\"S3.T2.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">59.20</td>\n</tr>\n<tr id=\"S3.T2.1.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.3.3.1\" class=\"ltx_td ltx_align_center\">Li et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>\n</td>\n<td id=\"S3.T2.1.3.3.2\" class=\"ltx_td ltx_align_center\">CNN</td>\n<td id=\"S3.T2.1.3.3.3\" class=\"ltx_td ltx_align_center\">58.00</td>\n</tr>\n<tr id=\"S3.T2.1.4.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.4.4.1\" class=\"ltx_td ltx_align_center\">Ando et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib24\" title=\"\" class=\"ltx_ref\">24</a>]</cite>\n</td>\n<td id=\"S3.T2.1.4.4.2\" class=\"ltx_td ltx_align_center\">Multi-label</td>\n<td id=\"S3.T2.1.4.4.3\" class=\"ltx_td ltx_align_center\">57.80</td>\n</tr>\n<tr id=\"S3.T2.1.5.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.5.5.1\" class=\"ltx_td ltx_align_center\">Liu et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>\n</td>\n<td id=\"S3.T2.1.5.5.2\" class=\"ltx_td ltx_align_center\">CapsNet</td>\n<td id=\"S3.T2.1.5.5.3\" class=\"ltx_td ltx_align_center\">58.55</td>\n</tr>\n<tr id=\"S3.T2.1.6.6\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.6.6.1\" class=\"ltx_td ltx_align_center\">Zhou et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib17\" title=\"\" class=\"ltx_ref\">17</a>]</cite>\n</td>\n<td id=\"S3.T2.1.6.6.2\" class=\"ltx_td ltx_align_center\">Majority voting</td>\n<td id=\"S3.T2.1.6.6.3\" class=\"ltx_td ltx_align_center\">65.00</td>\n</tr>\n<tr id=\"S3.T2.1.7.7\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.7.7.1\" class=\"ltx_td ltx_align_center\">Zhou et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib17\" title=\"\" class=\"ltx_ref\">17</a>]</cite>\n</td>\n<td id=\"S3.T2.1.7.7.2\" class=\"ltx_td ltx_align_center\">MCIL</td>\n<td id=\"S3.T2.1.7.7.3\" class=\"ltx_td ltx_align_center\">67.00</td>\n</tr>\n<tr id=\"S3.T2.1.8.8\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.8.8.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Ghifary et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">26</a>]</cite>\n</td>\n<td id=\"S3.T2.1.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_t\">DaNN</td>\n<td id=\"S3.T2.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">65.00</td>\n</tr>\n<tr id=\"S3.T2.1.9.9\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.9.9.1\" class=\"ltx_td ltx_align_center\">Yu et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a>]</cite>\n</td>\n<td id=\"S3.T2.1.9.9.2\" class=\"ltx_td ltx_align_center\">DAAN</td>\n<td id=\"S3.T2.1.9.9.3\" class=\"ltx_td ltx_align_center\">65.75</td>\n</tr>\n<tr id=\"S3.T2.1.10.10\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.10.10.1\" class=\"ltx_td ltx_align_center\">Ganin et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">28</a>]</cite>\n</td>\n<td id=\"S3.T2.1.10.10.2\" class=\"ltx_td ltx_align_center\">DANN</td>\n<td id=\"S3.T2.1.10.10.3\" class=\"ltx_td ltx_align_center\">68.50</td>\n</tr>\n<tr id=\"S3.T2.1.11.11\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.11.11.1\" class=\"ltx_td ltx_align_center\">Cui et al. <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib29\" title=\"\" class=\"ltx_ref\">29</a>]</cite>\n</td>\n<td id=\"S3.T2.1.11.11.2\" class=\"ltx_td ltx_align_center\">BNM</td>\n<td id=\"S3.T2.1.11.11.3\" class=\"ltx_td ltx_align_center\">68.75</td>\n</tr>\n<tr id=\"S3.T2.1.12.12\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.12.12.1\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T2.1.12.12.1.1\" class=\"ltx_text ltx_font_bold\">IPR</span></td>\n<td id=\"S3.T2.1.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T2.1.12.12.2.1\" class=\"ltx_text ltx_font_bold\">Prototype learning</span></td>\n<td id=\"S3.T2.1.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_t\"><span id=\"S3.T2.1.12.12.3.1\" class=\"ltx_text ltx_font_bold\">70.75</span></td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "To demonstrate the effectiveness of IPR, we compare IPR with many state-of-the-art (SOTA) methods. Table 2 lists a brief description and accuracy results of these methods, where the first half is SER method, retrained following MCIL training algorithm, and the second half is the classical semi-supervised methods."
        ]
    },
    "S3.T3": {
        "caption": "Table 3:  Experimental results of different baseline systems on IEMOCAP dataset. The baseline +  represents training using model-generated pseudo labels.  \u22c6 \u22c6 \\star  indicates that p-value  < <  0.05 (compared with baseline).  \u2605 \u2605 \\bigstar  indicates that p-value  < <  0.05 (compared with baseline and baseline + ).",
        "table": "<figure id=\"S3.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Experimental results of different baseline systems on IEMOCAP dataset. The baseline<sup id=\"S3.T3.18.1\" class=\"ltx_sup\">+</sup> represents training using model-generated pseudo labels. <math id=\"S3.T3.8.m2.1\" class=\"ltx_Math\" alttext=\"\\star\" display=\"inline\"><semantics id=\"S3.T3.8.m2.1b\"><mo id=\"S3.T3.8.m2.1.1\" xref=\"S3.T3.8.m2.1.1.cmml\">\u22c6</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.8.m2.1c\"><ci id=\"S3.T3.8.m2.1.1.cmml\" xref=\"S3.T3.8.m2.1.1\">\u22c6</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.8.m2.1d\">\\star</annotation></semantics></math> indicates that p-value <math id=\"S3.T3.9.m3.1\" class=\"ltx_Math\" alttext=\"&lt;\" display=\"inline\"><semantics id=\"S3.T3.9.m3.1b\"><mo id=\"S3.T3.9.m3.1.1\" xref=\"S3.T3.9.m3.1.1.cmml\">&lt;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.9.m3.1c\"><lt id=\"S3.T3.9.m3.1.1.cmml\" xref=\"S3.T3.9.m3.1.1\"></lt></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.9.m3.1d\">&lt;</annotation></semantics></math> 0.05 (compared with baseline). <math id=\"S3.T3.10.m4.1\" class=\"ltx_Math\" alttext=\"\\bigstar\" display=\"inline\"><semantics id=\"S3.T3.10.m4.1b\"><mi mathvariant=\"normal\" id=\"S3.T3.10.m4.1.1\" xref=\"S3.T3.10.m4.1.1.cmml\">\u2605</mi><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.10.m4.1c\"><ci id=\"S3.T3.10.m4.1.1.cmml\" xref=\"S3.T3.10.m4.1.1\">\u2605</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.10.m4.1d\">\\bigstar</annotation></semantics></math> indicates that p-value <math id=\"S3.T3.11.m5.1\" class=\"ltx_Math\" alttext=\"&lt;\" display=\"inline\"><semantics id=\"S3.T3.11.m5.1b\"><mo id=\"S3.T3.11.m5.1.1\" xref=\"S3.T3.11.m5.1.1.cmml\">&lt;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.11.m5.1c\"><lt id=\"S3.T3.11.m5.1.1.cmml\" xref=\"S3.T3.11.m5.1.1\"></lt></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.11.m5.1d\">&lt;</annotation></semantics></math> 0.05 (compared with baseline and baseline<sup id=\"S3.T3.19.2\" class=\"ltx_sup\">+</sup>).</figcaption>\n<table id=\"S3.T3.15\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">\n<thead class=\"ltx_thead\">\n<tr id=\"S3.T3.15.4.1\" class=\"ltx_tr\">\n<th id=\"S3.T3.15.4.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T3.15.4.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>\n<th id=\"S3.T3.15.4.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T3.15.4.1.2.1\" class=\"ltx_text ltx_font_bold\">Train</span></th>\n<th id=\"S3.T3.15.4.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span id=\"S3.T3.15.4.1.3.1\" class=\"ltx_text ltx_font_bold\">Acc(%)</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr id=\"S3.T3.15.5.1\" class=\"ltx_tr\">\n<td id=\"S3.T3.15.5.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">baseline</td>\n<td id=\"S3.T3.15.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">D1</td>\n<td id=\"S3.T3.15.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">64.25</td>\n</tr>\n<tr id=\"S3.T3.14.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.13.1.1\" class=\"ltx_td ltx_align_center\">baseline<sup id=\"S3.T3.13.1.1.1\" class=\"ltx_sup\">+</sup>\n</td>\n<td id=\"S3.T3.14.2.3\" class=\"ltx_td ltx_align_center\">D1 and unlabeled D2</td>\n<td id=\"S3.T3.14.2.2\" class=\"ltx_td ltx_align_center\">66.85<sup id=\"S3.T3.14.2.2.1\" class=\"ltx_sup\"><span id=\"S3.T3.14.2.2.1.1\" class=\"ltx_text ltx_font_italic\">\u22c6</span></sup>\n</td>\n</tr>\n<tr id=\"S3.T3.15.3\" class=\"ltx_tr\">\n<td id=\"S3.T3.15.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T3.15.3.2.1\" class=\"ltx_text ltx_font_bold\">IPR</span></td>\n<td id=\"S3.T3.15.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T3.15.3.3.1\" class=\"ltx_text ltx_font_bold\">D1 and unlabeled D2</span></td>\n<td id=\"S3.T3.15.3.1\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T3.15.3.1.1\" class=\"ltx_text ltx_font_bold\">70.75<sup id=\"S3.T3.15.3.1.1.1\" class=\"ltx_sup\"><span id=\"S3.T3.15.3.1.1.1.1\" class=\"ltx_text ltx_font_medium ltx_font_italic\">\u2605</span></sup></span></td>\n</tr>\n<tr id=\"S3.T3.15.6.2\" class=\"ltx_tr\">\n<td id=\"S3.T3.15.6.2.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">supervised baseline</td>\n<td id=\"S3.T3.15.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">both labeled D1 and D2</td>\n<td id=\"S3.T3.15.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">72.30</td>\n</tr>\n</tbody>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We report the experimental results of IPR with different baseline systems as shown in Table 3. First, we observe that by integrating these unlabeled samples, the performance of IPR improves significantly, by 6.50% over baseline on Acc. This highlights the importance of using unlabeled ambiguous data to optimize model. Second, IPR outperforms baseline+. This proves that IPR, an iterative prototype refinement framework, outperforms model-generated soft labels in the generation of pseudo labels. Notably, the baseline+ also outperforms the majority voting method of MCIL in SOTA. Thus, when faced with a corpus without voting information, our method utilizes a small amount of data for training and could achieve a large number of data annotation, both single and ambiguous soft labels. Finally, by comparing IPR and supervised baseline, we could notice that on Acc, the proposed method reduces 1.55%, while MCIL reduces 5.30%. As a result, IPR is closer to the performance of supervised system, while it produces more precise and reliable pseudo labels when annotating unlabeled samples."
        ]
    }
}