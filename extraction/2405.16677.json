{
    "S2.T1": {
        "caption": "Table 1 :  WERs (%) of the ASR transcripts.",
        "table": "<figure id=\"S2.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S2.T1.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 1</span>: </span>WERs (%) of the ASR transcripts.</figcaption>\n<table id=\"S2.T1.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S2.T1.3.1\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S2.T1.3.1.1.1\" class=\"ltx_text ltx_font_bold\">ASR Model</span></td>\n<td id=\"S2.T1.3.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S2.T1.3.1.2.1\" class=\"ltx_text ltx_font_bold\">Corpus</span></td>\n<td id=\"S2.T1.3.1.3\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S2.T1.3.1.3.1\" class=\"ltx_text ltx_font_bold\">WER</span></td>\n</tr>\n<tr id=\"S2.T1.3.2\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\" rowspan=\"2\"><span id=\"S2.T1.3.2.1.1\" class=\"ltx_text ltx_font_italic\">Whisper</span></td>\n<td id=\"S2.T1.3.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">Common Voice</td>\n<td id=\"S2.T1.3.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">19.11</td>\n</tr>\n<tr id=\"S2.T1.3.3\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.3.1\" class=\"ltx_td ltx_align_left\">IEMOCAP</td>\n<td id=\"S2.T1.3.3.2\" class=\"ltx_td ltx_align_left\">17.18</td>\n</tr>\n<tr id=\"S2.T1.3.4\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.4.1\" class=\"ltx_td\"></td>\n<td id=\"S2.T1.3.4.2\" class=\"ltx_td ltx_align_left\">CMU-MOSI</td>\n<td id=\"S2.T1.3.4.3\" class=\"ltx_td ltx_align_left\">17.84</td>\n</tr>\n<tr id=\"S2.T1.3.5\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.5.1\" class=\"ltx_td\"></td>\n<td id=\"S2.T1.3.5.2\" class=\"ltx_td ltx_align_left\">MSP-Podcast</td>\n<td id=\"S2.T1.3.5.3\" class=\"ltx_td ltx_align_left\">17.65</td>\n</tr>\n<tr id=\"S2.T1.3.6\" class=\"ltx_tr\">\n<td id=\"S2.T1.3.6.1\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\"><span id=\"S2.T1.3.6.1.1\" class=\"ltx_text ltx_font_italic\">Random</span></td>\n<td id=\"S2.T1.3.6.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">IEMOCAP</td>\n<td id=\"S2.T1.3.6.3\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">17.12</td>\n</tr>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Whisper is run on all four corpora, yielding satisfactory WERs (see Table 1) for the following reasons: 1) the WERs indicate that the corpora fall outside the domain used for training Whisper, aligning with our goal to study the OOD problem; 2) the WER of Common Voice (for PT) is close to the others (for FT), ensuring the error ratios are consistent in PT and FT. Otherwise in PT, too many errors can result in a serious over-correction problem in subsequent FT and inference phases (which generally occurs in OOD scenarios, as we have observed in our experiments), while too few errors may lead to insufficient learning of error-gold pairs. This setting was usually ignored in the literature, where many studies trained the AEC model on Librispeech with less than 10% WER [27], thereby hindering their generalizability. Subsequently, to discover the ASR domain discrepancy problem, which is a new concept presented by this work, we create the transcript of IEMOCAP from the Random model for comparison, which has almost the same WER as that from Whisper. As said, we omit experimental details on CMU-MOSI and MSP-Podcast.",
            "Table 3 shows that without FT, a pre-trained model cannot perform well. The improvement is hardly noticeable on IEMOCAP, whereas the improvement is significant on the test set of Common Voice (Table 2), despite their original ASR transcripts being of similar quality (Table 1). This is likely due to the domain discrepancy between Common Voice and IEMOCAP, which results in the model pre-trained on the former being unable to recognize some erroneous OOD words in the latter. However, even without PT, the model can still improve transcript quality after FT222Technically, since there is no PT on Common Voice, it is not appropriate to use the term \"FT\" as the model is directly trained on IEMOCAP. However, we keep \"FT\" here for consistency. on LROOD data."
        ]
    },
    "S3.T2": {
        "caption": "Table 2 :  AEC Performance on the test set of Common Voice.",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T2.2.1.1\" class=\"ltx_text ltx_font_bold\">Table 2</span>: </span>AEC Performance on the test set of Common Voice.</figcaption>\n<div id=\"S3.T2.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:223.9pt;height:50.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-8.4pt,1.9pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T2.3.1\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T2.3.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.1.1.1\" class=\"ltx_td ltx_border_t\"></td>\n<td id=\"S3.T2.3.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">WER</span></td>\n<td id=\"S3.T2.3.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">BLEU</span></td>\n<td id=\"S3.T2.3.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\">GLEU</span></td>\n</tr>\n<tr id=\"S3.T2.3.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.1.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T2.3.1.2.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T2.3.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">19.30</td>\n<td id=\"S3.T2.3.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">70.56</td>\n<td id=\"S3.T2.3.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">71.24</td>\n</tr>\n<tr id=\"S3.T2.3.1.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.3.1.3.1\" class=\"ltx_td ltx_align_left ltx_border_b\">Best checkpoint</td>\n<td id=\"S3.T2.3.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\">18.19</td>\n<td id=\"S3.T2.3.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\">72.14</td>\n<td id=\"S3.T2.3.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\">72.45</td>\n</tr>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "To pre-train the AEC model, 166k samples from Common Voice were recognized by Whisper, with 1,000 random samples held out as the test set, and the rest for training and validation with an 80%-20% split. The training aims to recover the gold transcripts from the ASR output. With a batch size of 256, an initial learning rate of 1e-5, and the Adam optimizer, we train the model for 30 epochs using cross-entropy loss and select the best checkpoint based on WER as the evaluation metric. Decoding is performed using beam search with a size of 5. The S2S backbone model is adopted from [30]. Performance on the test set is shown in Table 2.",
            "Table 3 shows that without FT, a pre-trained model cannot perform well. The improvement is hardly noticeable on IEMOCAP, whereas the improvement is significant on the test set of Common Voice (Table 2), despite their original ASR transcripts being of similar quality (Table 1). This is likely due to the domain discrepancy between Common Voice and IEMOCAP, which results in the model pre-trained on the former being unable to recognize some erroneous OOD words in the latter. However, even without PT, the model can still improve transcript quality after FT222Technically, since there is no PT on Common Voice, it is not appropriate to use the term \"FT\" as the model is directly trained on IEMOCAP. However, we keep \"FT\" here for consistency. on LROOD data."
        ]
    },
    "S3.T3": {
        "caption": "Table 3 :  Comparison results on IEMOCAP of w/ and w/o pre-training or fine-tuning.",
        "table": "<figure id=\"S3.T3\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T3.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 3</span>: </span>Comparison results on IEMOCAP of w/ and w/o pre-training or fine-tuning.</figcaption>\n<div id=\"S3.T3.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:178.3pt;height:83.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-6.7pt,3.1pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T3.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T3.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T3.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">PT</span></td>\n<td id=\"S3.T3.3.3.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.3.3.5.1\" class=\"ltx_text ltx_font_bold\">FT</span></td>\n<td id=\"S3.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T3.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T3.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T3.1.1.1.1.1.m1.1.1\" xref=\"S3.T3.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.1.1.1.1.1.m1.1b\"><ci id=\"S3.T3.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T3.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T3.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T3.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T3.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T3.2.2.2.2.1.m1.1.1\" xref=\"S3.T3.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.2.2.2.2.1.m1.1b\"><ci id=\"S3.T3.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T3.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T3.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T3.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T3.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T3.3.3.3.3.1.m1.1.1\" xref=\"S3.T3.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T3.3.3.3.3.1.m1.1b\"><ci id=\"S3.T3.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T3.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T3.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T3.3.3.4.1\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S3.T3.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T3.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.18</td>\n<td id=\"S3.T3.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.56</td>\n<td id=\"S3.T3.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">75.29</td>\n</tr>\n<tr id=\"S3.T3.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T3.3.3.5.1\" class=\"ltx_td ltx_align_center\">\n<span id=\"S3.T3.3.3.5.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span>\u2713</td>\n<td id=\"S3.T3.3.3.5.2\" class=\"ltx_td ltx_align_center\">\u2717</td>\n<td id=\"S3.T3.3.3.5.3\" class=\"ltx_td ltx_align_center\">17.14</td>\n<td id=\"S3.T3.3.3.5.4\" class=\"ltx_td ltx_align_center\">76.61</td>\n<td id=\"S3.T3.3.3.5.5\" class=\"ltx_td ltx_align_center\">75.34</td>\n</tr>\n<tr id=\"S3.T3.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T3.3.3.6.1\" class=\"ltx_td ltx_align_center\">\u2717</td>\n<td id=\"S3.T3.3.3.6.2\" class=\"ltx_td ltx_align_center\">\u2713</td>\n<td id=\"S3.T3.3.3.6.3\" class=\"ltx_td ltx_align_center\">17.08</td>\n<td id=\"S3.T3.3.3.6.4\" class=\"ltx_td ltx_align_center\">77.01</td>\n<td id=\"S3.T3.3.3.6.5\" class=\"ltx_td ltx_align_center\">75.52</td>\n</tr>\n<tr id=\"S3.T3.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T3.3.3.7.1\" class=\"ltx_td ltx_align_center ltx_border_b\">\u2713</td>\n<td id=\"S3.T3.3.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\">\u2713</td>\n<td id=\"S3.T3.3.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T3.3.3.7.3.1\" class=\"ltx_text ltx_font_bold\">16.40</span></td>\n<td id=\"S3.T3.3.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T3.3.3.7.4.1\" class=\"ltx_text ltx_font_bold\">78.00</span></td>\n<td id=\"S3.T3.3.3.7.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T3.3.3.7.5.1\" class=\"ltx_text ltx_font_bold\">76.58</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Table 3 shows that without FT, a pre-trained model cannot perform well. The improvement is hardly noticeable on IEMOCAP, whereas the improvement is significant on the test set of Common Voice (Table 2), despite their original ASR transcripts being of similar quality (Table 1). This is likely due to the domain discrepancy between Common Voice and IEMOCAP, which results in the model pre-trained on the former being unable to recognize some erroneous OOD words in the latter. However, even without PT, the model can still improve transcript quality after FT222Technically, since there is no PT on Common Voice, it is not appropriate to use the term \"FT\" as the model is directly trained on IEMOCAP. However, we keep \"FT\" here for consistency. on LROOD data."
        ]
    },
    "S3.SS1.SSS2.3": {
        "caption": "Table 4 :  Comparison results on IEMOCAP of fine-tuning on transcript generated by different ASR models. Table 5 :  Result summary on IEMOCAP. Table 6 :  Result summary on CMU-MOSI. Table 7 :  Result summary on MSP-Podcast. Table 8 :  Performance comparison with generative AEC approaches. Fig.\u00a02 :  An illustration of the Alpaca prompt (upper) and Task-Activating prompt (below) used in this work. Table 9 :  Comparison results of SER performance.",
        "table": "<figure id=\"S3.SS1.SSS2.3\" class=\"ltx_table\">\n\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.SS1.SSS2.3.4.1.1\" class=\"ltx_text ltx_font_bold\">Table 4</span>: </span>Comparison results on IEMOCAP of fine-tuning on transcript generated by different ASR models.</figcaption><div class=\"ltx_flex_figure\">\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<div id=\"S3.SS1.SSS2.3.3\" class=\"ltx_inline-block ltx_figure_panel ltx_transformed_outer\" style=\"width:183.9pt;height:167.4pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-6.9pt,6.3pt) scale(0.93,0.93) ;\">\n<table id=\"S3.SS1.SSS2.3.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.SS1.SSS2.3.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.SS1.SSS2.3.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">ASR Model</span></td>\n<td id=\"S3.SS1.SSS2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.SS1.SSS2.1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.SS1.SSS2.1.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.SS1.SSS2.1.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.SS1.SSS2.1.1.1.1.1.1.m1.1.1\" xref=\"S3.SS1.SSS2.1.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS2.1.1.1.1.1.1.m1.1b\"><ci id=\"S3.SS1.SSS2.1.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.SS1.SSS2.1.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS2.1.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.SS1.SSS2.2.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.SS1.SSS2.2.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.SS1.SSS2.2.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.SS1.SSS2.2.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.SS1.SSS2.2.2.2.2.2.1.m1.1.1\" xref=\"S3.SS1.SSS2.2.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS2.2.2.2.2.2.1.m1.1b\"><ci id=\"S3.SS1.SSS2.2.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.SS1.SSS2.2.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS2.2.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.SS1.SSS2.3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.SS1.SSS2.3.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.SS1.SSS2.3.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.SS1.SSS2.3.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.SS1.SSS2.3.3.3.3.3.1.m1.1.1\" xref=\"S3.SS1.SSS2.3.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS2.3.3.3.3.3.1.m1.1b\"><ci id=\"S3.SS1.SSS2.3.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.SS1.SSS2.3.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS2.3.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\" colspan=\"4\">Original ASR transcript</td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.5.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.SS1.SSS2.3.3.3.5.1.1\" class=\"ltx_text ltx_font_italic\">Whisper</span></td>\n<td id=\"S3.SS1.SSS2.3.3.3.5.2\" class=\"ltx_td ltx_align_center\">17.18</td>\n<td id=\"S3.SS1.SSS2.3.3.3.5.3\" class=\"ltx_td ltx_align_center\">76.56</td>\n<td id=\"S3.SS1.SSS2.3.3.3.5.4\" class=\"ltx_td ltx_align_center\">75.29</td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.6.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.SS1.SSS2.3.3.3.6.1.1\" class=\"ltx_text ltx_font_italic\">Random</span></td>\n<td id=\"S3.SS1.SSS2.3.3.3.6.2\" class=\"ltx_td ltx_align_center\">17.12</td>\n<td id=\"S3.SS1.SSS2.3.3.3.6.3\" class=\"ltx_td ltx_align_center\">76.64</td>\n<td id=\"S3.SS1.SSS2.3.3.3.6.4\" class=\"ltx_td ltx_align_center\">75.38</td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.7.1\" class=\"ltx_td ltx_align_left\" colspan=\"4\">\n<span id=\"S3.SS1.SSS2.3.3.3.7.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span> \u00a0\u00a0\u00a0\u00a0\u2717pre-training</td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.8\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.8.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.SS1.SSS2.3.3.3.8.1.1\" class=\"ltx_text ltx_font_italic\">Whisper</span></td>\n<td id=\"S3.SS1.SSS2.3.3.3.8.2\" class=\"ltx_td ltx_align_center\">17.08</td>\n<td id=\"S3.SS1.SSS2.3.3.3.8.3\" class=\"ltx_td ltx_align_center\">77.01</td>\n<td id=\"S3.SS1.SSS2.3.3.3.8.4\" class=\"ltx_td ltx_align_center\">75.52</td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.9\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.9.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.SS1.SSS2.3.3.3.9.1.1\" class=\"ltx_text ltx_font_italic\">Random</span></td>\n<td id=\"S3.SS1.SSS2.3.3.3.9.2\" class=\"ltx_td ltx_align_center\">17.03</td>\n<td id=\"S3.SS1.SSS2.3.3.3.9.3\" class=\"ltx_td ltx_align_center\">77.08</td>\n<td id=\"S3.SS1.SSS2.3.3.3.9.4\" class=\"ltx_td ltx_align_center\">75.61</td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.10\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.10.1\" class=\"ltx_td ltx_align_left\" colspan=\"4\">\n<span id=\"S3.SS1.SSS2.3.3.3.10.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span> \u00a0\u00a0\u00a0\u00a0\u2713pre-training</td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.11\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.11.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.SS1.SSS2.3.3.3.11.1.1\" class=\"ltx_text ltx_font_italic\">Whisper</span></td>\n<td id=\"S3.SS1.SSS2.3.3.3.11.2\" class=\"ltx_td ltx_align_center\">16.40</td>\n<td id=\"S3.SS1.SSS2.3.3.3.11.3\" class=\"ltx_td ltx_align_center\">78.00</td>\n<td id=\"S3.SS1.SSS2.3.3.3.11.4\" class=\"ltx_td ltx_align_center\">76.58</td>\n</tr>\n<tr id=\"S3.SS1.SSS2.3.3.3.12\" class=\"ltx_tr\">\n<td id=\"S3.SS1.SSS2.3.3.3.12.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.SS1.SSS2.3.3.3.12.1.1\" class=\"ltx_text ltx_font_italic\">Random</span></td>\n<td id=\"S3.SS1.SSS2.3.3.3.12.2\" class=\"ltx_td ltx_align_center ltx_border_b\">16.54</td>\n<td id=\"S3.SS1.SSS2.3.3.3.12.3\" class=\"ltx_td ltx_align_center ltx_border_b\">77.57</td>\n<td id=\"S3.SS1.SSS2.3.3.3.12.4\" class=\"ltx_td ltx_align_center ltx_border_b\">76.42</td>\n</tr>\n</table>\n</span></div>\n</div>\n<div class=\"ltx_flex_cell ltx_flex_size_2\">\n<section id=\"S3.SS1.SSS3\" class=\"ltx_subsubsection ltx_figure_panel\">\n<h4 class=\"ltx_title ltx_title_subsubsection\">\n<span class=\"ltx_tag ltx_tag_subsubsection\">3.1.3 </span>Incorporation of Discrete Speech Units</h4>\n\n<div id=\"S3.SS1.SSS3.p1\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS3.p1.1\" class=\"ltx_p\">So far, we have investigated how PT and FT contribute to text-only S2S AEC. To further improve the quality of error correction, we study the incorporation of acoustic information. Previous studies usually incorporated acoustic information in all stages\u2014PT, FT, and testing\u2014and only utilized continuous features such as Mel-spectrogram or raw SSR <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>, <a href=\"#bib.bib16\" title=\"\" class=\"ltx_ref\">16</a>]</cite>. However, we argue that these practices do not apply to LROOD scenarios for the following reasons:</p>\n</div>\n<div id=\"S3.SS1.SSS3.p2\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS3.p2.1\" class=\"ltx_p\"><span id=\"S3.SS1.SSS3.p2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">1)</span> The audio source of large-scale PT data is not always accessible due to privacy or other ethical concerns. <span id=\"S3.SS1.SSS3.p2.1.2\" class=\"ltx_text ltx_font_bold ltx_font_italic\">2)</span> The high-WER OOD speech usually contains low-quality audio that can introduce acoustic distortions (e.g., prosody variation or noise) into crossmodal training. <span id=\"S3.SS1.SSS3.p2.1.3\" class=\"ltx_text ltx_font_bold ltx_font_italic\">3)</span> It is challenging to align discrete word embeddings with continuous audio features. To this end, we propose to discretize the audio features to create DSUs and avoid incorporating such acoustic information in PT, making it a resource-efficient and effort-saving approach.</p>\n</div>\n<div id=\"S3.SS1.SSS3.p3\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS3.p3.1\" class=\"ltx_p\">We utilize AWEs, which are fixed-dimensional vectors representing variable-length spoken word segments as DSUs. These vectors map acoustic features extracted from audio signals to vectors, where similar words or linguistic units have similar embeddings in the vector space <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\">32</a>, <a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">33</a>]</cite>. AWEs can capture information about phonetics and other acoustic aspects of speech, offering promising potential for word discrimination <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib34\" title=\"\" class=\"ltx_ref\">34</a>]</cite>.</p>\n</div>\n<div id=\"S3.SS1.SSS3.p4\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS3.p4.1\" class=\"ltx_p\">Following recent studies on the analysis of AWEs from self-supervised speech models, we use SSR from <span id=\"S3.SS1.SSS3.p4.1.1\" class=\"ltx_text ltx_font_italic\">HuBERT</span> with mean pooling followed by forced alignment to find the word boundary, as this practice has been shown to be competitive with the state-of-the-art on English AWEs <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib35\" title=\"\" class=\"ltx_ref\">35</a>, <a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">36</a>]</cite>. On the other hand, we also use Mel-spectrogram and continuous raw SSR for comparison. After a layer-wise analysis (omitted due to space), we use AWEs from <span id=\"S3.SS1.SSS3.p4.1.2\" class=\"ltx_text ltx_font_italic\">HuBERT</span> layer 7 and raw SSR from <span id=\"S3.SS1.SSS3.p4.1.3\" class=\"ltx_text ltx_font_italic\">HuBERT</span> layer 8 as they performed the best among all layers, respectively. This aligns with a previous finding that <span id=\"S3.SS1.SSS3.p4.1.4\" class=\"ltx_text ltx_font_italic\">HuBERT</span> encodes the most word information between the middle layer and the last layer <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib37\" title=\"\" class=\"ltx_ref\">37</a>]</cite>.</p>\n</div>\n<div id=\"S3.SS1.SSS3.p5\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS3.p5.10\" class=\"ltx_p\">To incorporate the DSUs, we set the maximum sequence length as that of corresponding word embeddings and 0-pad the short sequence. To incorporate continuous features for comparison, we first downsample them to the same sequence length as the word embeddings using a fast Fourier transform. Unlike <span id=\"S3.SS1.SSS3.p5.10.1\" class=\"ltx_text ltx_font_italic\">HuBERT</span>, which has the same feature dimension of 768 as <span id=\"S3.SS1.SSS3.p5.10.2\" class=\"ltx_text ltx_font_italic\">RoBERTa</span>, we use a feed-forward layer for Mel-spectrogram to expand its dimension to this size. After such pre-processing, we implement cross-attention to align acoustic features with word embeddings:</p>\n<table id=\"S5.EGx1\" class=\"ltx_equationgroup ltx_eqn_align ltx_eqn_table\">\n\n<tbody id=\"S3.E1\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_td ltx_align_right ltx_eqn_cell\"><math id=\"S3.E1.m1.4\" class=\"ltx_Math\" alttext=\"\\displaystyle A^{\\prime}=Attn(Q_{w},K_{a},V_{a})=softmax(\\frac{Q_{w}K_{a}^{T}}{\\sqrt{d_{k}}})V_{a}\" display=\"inline\"><semantics id=\"S3.E1.m1.4a\"><mrow id=\"S3.E1.m1.4.4\" xref=\"S3.E1.m1.4.4.cmml\"><msup id=\"S3.E1.m1.4.4.5\" xref=\"S3.E1.m1.4.4.5.cmml\"><mi id=\"S3.E1.m1.4.4.5.2\" xref=\"S3.E1.m1.4.4.5.2.cmml\">A</mi><mo id=\"S3.E1.m1.4.4.5.3\" xref=\"S3.E1.m1.4.4.5.3.cmml\">\u2032</mo></msup><mo id=\"S3.E1.m1.4.4.6\" xref=\"S3.E1.m1.4.4.6.cmml\">=</mo><mrow id=\"S3.E1.m1.4.4.3\" xref=\"S3.E1.m1.4.4.3.cmml\"><mi id=\"S3.E1.m1.4.4.3.5\" xref=\"S3.E1.m1.4.4.3.5.cmml\">A</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.3.4\" xref=\"S3.E1.m1.4.4.3.4.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.3.6\" xref=\"S3.E1.m1.4.4.3.6.cmml\">t</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.3.4a\" xref=\"S3.E1.m1.4.4.3.4.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.3.7\" xref=\"S3.E1.m1.4.4.3.7.cmml\">t</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.3.4b\" xref=\"S3.E1.m1.4.4.3.4.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.3.8\" xref=\"S3.E1.m1.4.4.3.8.cmml\">n</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.3.4c\" xref=\"S3.E1.m1.4.4.3.4.cmml\">\u200b</mo><mrow id=\"S3.E1.m1.4.4.3.3.3\" xref=\"S3.E1.m1.4.4.3.3.4.cmml\"><mo stretchy=\"false\" id=\"S3.E1.m1.4.4.3.3.3.4\" xref=\"S3.E1.m1.4.4.3.3.4.cmml\">(</mo><msub id=\"S3.E1.m1.2.2.1.1.1.1\" xref=\"S3.E1.m1.2.2.1.1.1.1.cmml\"><mi id=\"S3.E1.m1.2.2.1.1.1.1.2\" xref=\"S3.E1.m1.2.2.1.1.1.1.2.cmml\">Q</mi><mi id=\"S3.E1.m1.2.2.1.1.1.1.3\" xref=\"S3.E1.m1.2.2.1.1.1.1.3.cmml\">w</mi></msub><mo id=\"S3.E1.m1.4.4.3.3.3.5\" xref=\"S3.E1.m1.4.4.3.3.4.cmml\">,</mo><msub id=\"S3.E1.m1.3.3.2.2.2.2\" xref=\"S3.E1.m1.3.3.2.2.2.2.cmml\"><mi id=\"S3.E1.m1.3.3.2.2.2.2.2\" xref=\"S3.E1.m1.3.3.2.2.2.2.2.cmml\">K</mi><mi id=\"S3.E1.m1.3.3.2.2.2.2.3\" xref=\"S3.E1.m1.3.3.2.2.2.2.3.cmml\">a</mi></msub><mo id=\"S3.E1.m1.4.4.3.3.3.6\" xref=\"S3.E1.m1.4.4.3.3.4.cmml\">,</mo><msub id=\"S3.E1.m1.4.4.3.3.3.3\" xref=\"S3.E1.m1.4.4.3.3.3.3.cmml\"><mi id=\"S3.E1.m1.4.4.3.3.3.3.2\" xref=\"S3.E1.m1.4.4.3.3.3.3.2.cmml\">V</mi><mi id=\"S3.E1.m1.4.4.3.3.3.3.3\" xref=\"S3.E1.m1.4.4.3.3.3.3.3.cmml\">a</mi></msub><mo stretchy=\"false\" id=\"S3.E1.m1.4.4.3.3.3.7\" xref=\"S3.E1.m1.4.4.3.3.4.cmml\">)</mo></mrow></mrow><mo id=\"S3.E1.m1.4.4.7\" xref=\"S3.E1.m1.4.4.7.cmml\">=</mo><mrow id=\"S3.E1.m1.4.4.8\" xref=\"S3.E1.m1.4.4.8.cmml\"><mi id=\"S3.E1.m1.4.4.8.2\" xref=\"S3.E1.m1.4.4.8.2.cmml\">s</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.8.1\" xref=\"S3.E1.m1.4.4.8.1.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.8.3\" xref=\"S3.E1.m1.4.4.8.3.cmml\">o</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.8.1a\" xref=\"S3.E1.m1.4.4.8.1.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.8.4\" xref=\"S3.E1.m1.4.4.8.4.cmml\">f</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.8.1b\" xref=\"S3.E1.m1.4.4.8.1.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.8.5\" xref=\"S3.E1.m1.4.4.8.5.cmml\">t</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.8.1c\" xref=\"S3.E1.m1.4.4.8.1.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.8.6\" xref=\"S3.E1.m1.4.4.8.6.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.8.1d\" xref=\"S3.E1.m1.4.4.8.1.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.8.7\" xref=\"S3.E1.m1.4.4.8.7.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.8.1e\" xref=\"S3.E1.m1.4.4.8.1.cmml\">\u200b</mo><mi id=\"S3.E1.m1.4.4.8.8\" xref=\"S3.E1.m1.4.4.8.8.cmml\">x</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.8.1f\" xref=\"S3.E1.m1.4.4.8.1.cmml\">\u200b</mo><mrow id=\"S3.E1.m1.4.4.8.9.2\" xref=\"S3.E1.m1.1.1.cmml\"><mo stretchy=\"false\" id=\"S3.E1.m1.4.4.8.9.2.1\" xref=\"S3.E1.m1.1.1.cmml\">(</mo><mstyle displaystyle=\"true\" id=\"S3.E1.m1.1.1\" xref=\"S3.E1.m1.1.1.cmml\"><mfrac id=\"S3.E1.m1.1.1a\" xref=\"S3.E1.m1.1.1.cmml\"><mrow id=\"S3.E1.m1.1.1.2\" xref=\"S3.E1.m1.1.1.2.cmml\"><msub id=\"S3.E1.m1.1.1.2.2\" xref=\"S3.E1.m1.1.1.2.2.cmml\"><mi id=\"S3.E1.m1.1.1.2.2.2\" xref=\"S3.E1.m1.1.1.2.2.2.cmml\">Q</mi><mi id=\"S3.E1.m1.1.1.2.2.3\" xref=\"S3.E1.m1.1.1.2.2.3.cmml\">w</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.1.1.2.1\" xref=\"S3.E1.m1.1.1.2.1.cmml\">\u200b</mo><msubsup id=\"S3.E1.m1.1.1.2.3\" xref=\"S3.E1.m1.1.1.2.3.cmml\"><mi id=\"S3.E1.m1.1.1.2.3.2.2\" xref=\"S3.E1.m1.1.1.2.3.2.2.cmml\">K</mi><mi id=\"S3.E1.m1.1.1.2.3.2.3\" xref=\"S3.E1.m1.1.1.2.3.2.3.cmml\">a</mi><mi id=\"S3.E1.m1.1.1.2.3.3\" xref=\"S3.E1.m1.1.1.2.3.3.cmml\">T</mi></msubsup></mrow><msqrt id=\"S3.E1.m1.1.1.3\" xref=\"S3.E1.m1.1.1.3.cmml\"><msub id=\"S3.E1.m1.1.1.3.2\" xref=\"S3.E1.m1.1.1.3.2.cmml\"><mi id=\"S3.E1.m1.1.1.3.2.2\" xref=\"S3.E1.m1.1.1.3.2.2.cmml\">d</mi><mi id=\"S3.E1.m1.1.1.3.2.3\" xref=\"S3.E1.m1.1.1.3.2.3.cmml\">k</mi></msub></msqrt></mfrac></mstyle><mo stretchy=\"false\" id=\"S3.E1.m1.4.4.8.9.2.2\" xref=\"S3.E1.m1.1.1.cmml\">)</mo></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E1.m1.4.4.8.1g\" xref=\"S3.E1.m1.4.4.8.1.cmml\">\u200b</mo><msub id=\"S3.E1.m1.4.4.8.10\" xref=\"S3.E1.m1.4.4.8.10.cmml\"><mi id=\"S3.E1.m1.4.4.8.10.2\" xref=\"S3.E1.m1.4.4.8.10.2.cmml\">V</mi><mi id=\"S3.E1.m1.4.4.8.10.3\" xref=\"S3.E1.m1.4.4.8.10.3.cmml\">a</mi></msub></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.E1.m1.4b\"><apply id=\"S3.E1.m1.4.4.cmml\" xref=\"S3.E1.m1.4.4\"><and id=\"S3.E1.m1.4.4a.cmml\" xref=\"S3.E1.m1.4.4\"></and><apply id=\"S3.E1.m1.4.4b.cmml\" xref=\"S3.E1.m1.4.4\"><eq id=\"S3.E1.m1.4.4.6.cmml\" xref=\"S3.E1.m1.4.4.6\"></eq><apply id=\"S3.E1.m1.4.4.5.cmml\" xref=\"S3.E1.m1.4.4.5\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.4.4.5.1.cmml\" xref=\"S3.E1.m1.4.4.5\">superscript</csymbol><ci id=\"S3.E1.m1.4.4.5.2.cmml\" xref=\"S3.E1.m1.4.4.5.2\">\ud835\udc34</ci><ci id=\"S3.E1.m1.4.4.5.3.cmml\" xref=\"S3.E1.m1.4.4.5.3\">\u2032</ci></apply><apply id=\"S3.E1.m1.4.4.3.cmml\" xref=\"S3.E1.m1.4.4.3\"><times id=\"S3.E1.m1.4.4.3.4.cmml\" xref=\"S3.E1.m1.4.4.3.4\"></times><ci id=\"S3.E1.m1.4.4.3.5.cmml\" xref=\"S3.E1.m1.4.4.3.5\">\ud835\udc34</ci><ci id=\"S3.E1.m1.4.4.3.6.cmml\" xref=\"S3.E1.m1.4.4.3.6\">\ud835\udc61</ci><ci id=\"S3.E1.m1.4.4.3.7.cmml\" xref=\"S3.E1.m1.4.4.3.7\">\ud835\udc61</ci><ci id=\"S3.E1.m1.4.4.3.8.cmml\" xref=\"S3.E1.m1.4.4.3.8\">\ud835\udc5b</ci><vector id=\"S3.E1.m1.4.4.3.3.4.cmml\" xref=\"S3.E1.m1.4.4.3.3.3\"><apply id=\"S3.E1.m1.2.2.1.1.1.1.cmml\" xref=\"S3.E1.m1.2.2.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.2.2.1.1.1.1.1.cmml\" xref=\"S3.E1.m1.2.2.1.1.1.1\">subscript</csymbol><ci id=\"S3.E1.m1.2.2.1.1.1.1.2.cmml\" xref=\"S3.E1.m1.2.2.1.1.1.1.2\">\ud835\udc44</ci><ci id=\"S3.E1.m1.2.2.1.1.1.1.3.cmml\" xref=\"S3.E1.m1.2.2.1.1.1.1.3\">\ud835\udc64</ci></apply><apply id=\"S3.E1.m1.3.3.2.2.2.2.cmml\" xref=\"S3.E1.m1.3.3.2.2.2.2\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.3.3.2.2.2.2.1.cmml\" xref=\"S3.E1.m1.3.3.2.2.2.2\">subscript</csymbol><ci id=\"S3.E1.m1.3.3.2.2.2.2.2.cmml\" xref=\"S3.E1.m1.3.3.2.2.2.2.2\">\ud835\udc3e</ci><ci id=\"S3.E1.m1.3.3.2.2.2.2.3.cmml\" xref=\"S3.E1.m1.3.3.2.2.2.2.3\">\ud835\udc4e</ci></apply><apply id=\"S3.E1.m1.4.4.3.3.3.3.cmml\" xref=\"S3.E1.m1.4.4.3.3.3.3\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.4.4.3.3.3.3.1.cmml\" xref=\"S3.E1.m1.4.4.3.3.3.3\">subscript</csymbol><ci id=\"S3.E1.m1.4.4.3.3.3.3.2.cmml\" xref=\"S3.E1.m1.4.4.3.3.3.3.2\">\ud835\udc49</ci><ci id=\"S3.E1.m1.4.4.3.3.3.3.3.cmml\" xref=\"S3.E1.m1.4.4.3.3.3.3.3\">\ud835\udc4e</ci></apply></vector></apply></apply><apply id=\"S3.E1.m1.4.4c.cmml\" xref=\"S3.E1.m1.4.4\"><eq id=\"S3.E1.m1.4.4.7.cmml\" xref=\"S3.E1.m1.4.4.7\"></eq><share href=\"#S3.E1.m1.4.4.3.cmml\" id=\"S3.E1.m1.4.4d.cmml\" xref=\"S3.E1.m1.4.4\"></share><apply id=\"S3.E1.m1.4.4.8.cmml\" xref=\"S3.E1.m1.4.4.8\"><times id=\"S3.E1.m1.4.4.8.1.cmml\" xref=\"S3.E1.m1.4.4.8.1\"></times><ci id=\"S3.E1.m1.4.4.8.2.cmml\" xref=\"S3.E1.m1.4.4.8.2\">\ud835\udc60</ci><ci id=\"S3.E1.m1.4.4.8.3.cmml\" xref=\"S3.E1.m1.4.4.8.3\">\ud835\udc5c</ci><ci id=\"S3.E1.m1.4.4.8.4.cmml\" xref=\"S3.E1.m1.4.4.8.4\">\ud835\udc53</ci><ci id=\"S3.E1.m1.4.4.8.5.cmml\" xref=\"S3.E1.m1.4.4.8.5\">\ud835\udc61</ci><ci id=\"S3.E1.m1.4.4.8.6.cmml\" xref=\"S3.E1.m1.4.4.8.6\">\ud835\udc5a</ci><ci id=\"S3.E1.m1.4.4.8.7.cmml\" xref=\"S3.E1.m1.4.4.8.7\">\ud835\udc4e</ci><ci id=\"S3.E1.m1.4.4.8.8.cmml\" xref=\"S3.E1.m1.4.4.8.8\">\ud835\udc65</ci><apply id=\"S3.E1.m1.1.1.cmml\" xref=\"S3.E1.m1.4.4.8.9.2\"><divide id=\"S3.E1.m1.1.1.1.cmml\" xref=\"S3.E1.m1.4.4.8.9.2\"></divide><apply id=\"S3.E1.m1.1.1.2.cmml\" xref=\"S3.E1.m1.1.1.2\"><times id=\"S3.E1.m1.1.1.2.1.cmml\" xref=\"S3.E1.m1.1.1.2.1\"></times><apply id=\"S3.E1.m1.1.1.2.2.cmml\" xref=\"S3.E1.m1.1.1.2.2\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.2.2.1.cmml\" xref=\"S3.E1.m1.1.1.2.2\">subscript</csymbol><ci id=\"S3.E1.m1.1.1.2.2.2.cmml\" xref=\"S3.E1.m1.1.1.2.2.2\">\ud835\udc44</ci><ci id=\"S3.E1.m1.1.1.2.2.3.cmml\" xref=\"S3.E1.m1.1.1.2.2.3\">\ud835\udc64</ci></apply><apply id=\"S3.E1.m1.1.1.2.3.cmml\" xref=\"S3.E1.m1.1.1.2.3\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.2.3.1.cmml\" xref=\"S3.E1.m1.1.1.2.3\">superscript</csymbol><apply id=\"S3.E1.m1.1.1.2.3.2.cmml\" xref=\"S3.E1.m1.1.1.2.3\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.2.3.2.1.cmml\" xref=\"S3.E1.m1.1.1.2.3\">subscript</csymbol><ci id=\"S3.E1.m1.1.1.2.3.2.2.cmml\" xref=\"S3.E1.m1.1.1.2.3.2.2\">\ud835\udc3e</ci><ci id=\"S3.E1.m1.1.1.2.3.2.3.cmml\" xref=\"S3.E1.m1.1.1.2.3.2.3\">\ud835\udc4e</ci></apply><ci id=\"S3.E1.m1.1.1.2.3.3.cmml\" xref=\"S3.E1.m1.1.1.2.3.3\">\ud835\udc47</ci></apply></apply><apply id=\"S3.E1.m1.1.1.3.cmml\" xref=\"S3.E1.m1.1.1.3\"><root id=\"S3.E1.m1.1.1.3a.cmml\" xref=\"S3.E1.m1.1.1.3\"></root><apply id=\"S3.E1.m1.1.1.3.2.cmml\" xref=\"S3.E1.m1.1.1.3.2\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.1.1.3.2.1.cmml\" xref=\"S3.E1.m1.1.1.3.2\">subscript</csymbol><ci id=\"S3.E1.m1.1.1.3.2.2.cmml\" xref=\"S3.E1.m1.1.1.3.2.2\">\ud835\udc51</ci><ci id=\"S3.E1.m1.1.1.3.2.3.cmml\" xref=\"S3.E1.m1.1.1.3.2.3\">\ud835\udc58</ci></apply></apply></apply><apply id=\"S3.E1.m1.4.4.8.10.cmml\" xref=\"S3.E1.m1.4.4.8.10\"><csymbol cd=\"ambiguous\" id=\"S3.E1.m1.4.4.8.10.1.cmml\" xref=\"S3.E1.m1.4.4.8.10\">subscript</csymbol><ci id=\"S3.E1.m1.4.4.8.10.2.cmml\" xref=\"S3.E1.m1.4.4.8.10.2\">\ud835\udc49</ci><ci id=\"S3.E1.m1.4.4.8.10.3.cmml\" xref=\"S3.E1.m1.4.4.8.10.3\">\ud835\udc4e</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.E1.m1.4c\">\\displaystyle A^{\\prime}=Attn(Q_{w},K_{a},V_{a})=softmax(\\frac{Q_{w}K_{a}^{T}}{\\sqrt{d_{k}}})V_{a}</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td rowspan=\"1\" class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(1)</span></td>\n</tr></tbody>\n</table>\n<p id=\"S3.SS1.SSS3.p5.9\" class=\"ltx_p\">where <math id=\"S3.SS1.SSS3.p5.1.m1.1\" class=\"ltx_Math\" alttext=\"Q_{t}\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.1.m1.1a\"><msub id=\"S3.SS1.SSS3.p5.1.m1.1.1\" xref=\"S3.SS1.SSS3.p5.1.m1.1.1.cmml\"><mi id=\"S3.SS1.SSS3.p5.1.m1.1.1.2\" xref=\"S3.SS1.SSS3.p5.1.m1.1.1.2.cmml\">Q</mi><mi id=\"S3.SS1.SSS3.p5.1.m1.1.1.3\" xref=\"S3.SS1.SSS3.p5.1.m1.1.1.3.cmml\">t</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.1.m1.1b\"><apply id=\"S3.SS1.SSS3.p5.1.m1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.SS1.SSS3.p5.1.m1.1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.1.m1.1.1\">subscript</csymbol><ci id=\"S3.SS1.SSS3.p5.1.m1.1.1.2.cmml\" xref=\"S3.SS1.SSS3.p5.1.m1.1.1.2\">\ud835\udc44</ci><ci id=\"S3.SS1.SSS3.p5.1.m1.1.1.3.cmml\" xref=\"S3.SS1.SSS3.p5.1.m1.1.1.3\">\ud835\udc61</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.1.m1.1c\">Q_{t}</annotation></semantics></math>, <math id=\"S3.SS1.SSS3.p5.2.m2.1\" class=\"ltx_Math\" alttext=\"K_{a}\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.2.m2.1a\"><msub id=\"S3.SS1.SSS3.p5.2.m2.1.1\" xref=\"S3.SS1.SSS3.p5.2.m2.1.1.cmml\"><mi id=\"S3.SS1.SSS3.p5.2.m2.1.1.2\" xref=\"S3.SS1.SSS3.p5.2.m2.1.1.2.cmml\">K</mi><mi id=\"S3.SS1.SSS3.p5.2.m2.1.1.3\" xref=\"S3.SS1.SSS3.p5.2.m2.1.1.3.cmml\">a</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.2.m2.1b\"><apply id=\"S3.SS1.SSS3.p5.2.m2.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.2.m2.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.SS1.SSS3.p5.2.m2.1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.2.m2.1.1\">subscript</csymbol><ci id=\"S3.SS1.SSS3.p5.2.m2.1.1.2.cmml\" xref=\"S3.SS1.SSS3.p5.2.m2.1.1.2\">\ud835\udc3e</ci><ci id=\"S3.SS1.SSS3.p5.2.m2.1.1.3.cmml\" xref=\"S3.SS1.SSS3.p5.2.m2.1.1.3\">\ud835\udc4e</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.2.m2.1c\">K_{a}</annotation></semantics></math>, and <math id=\"S3.SS1.SSS3.p5.3.m3.1\" class=\"ltx_Math\" alttext=\"V_{a}\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.3.m3.1a\"><msub id=\"S3.SS1.SSS3.p5.3.m3.1.1\" xref=\"S3.SS1.SSS3.p5.3.m3.1.1.cmml\"><mi id=\"S3.SS1.SSS3.p5.3.m3.1.1.2\" xref=\"S3.SS1.SSS3.p5.3.m3.1.1.2.cmml\">V</mi><mi id=\"S3.SS1.SSS3.p5.3.m3.1.1.3\" xref=\"S3.SS1.SSS3.p5.3.m3.1.1.3.cmml\">a</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.3.m3.1b\"><apply id=\"S3.SS1.SSS3.p5.3.m3.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.3.m3.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.SS1.SSS3.p5.3.m3.1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.3.m3.1.1\">subscript</csymbol><ci id=\"S3.SS1.SSS3.p5.3.m3.1.1.2.cmml\" xref=\"S3.SS1.SSS3.p5.3.m3.1.1.2\">\ud835\udc49</ci><ci id=\"S3.SS1.SSS3.p5.3.m3.1.1.3.cmml\" xref=\"S3.SS1.SSS3.p5.3.m3.1.1.3\">\ud835\udc4e</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.3.m3.1c\">V_{a}</annotation></semantics></math> represent the respective matrix for query (word embeddings), key (acoustic features), and value (acoustic features), <math id=\"S3.SS1.SSS3.p5.4.m4.1\" class=\"ltx_Math\" alttext=\"d_{k}\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.4.m4.1a\"><msub id=\"S3.SS1.SSS3.p5.4.m4.1.1\" xref=\"S3.SS1.SSS3.p5.4.m4.1.1.cmml\"><mi id=\"S3.SS1.SSS3.p5.4.m4.1.1.2\" xref=\"S3.SS1.SSS3.p5.4.m4.1.1.2.cmml\">d</mi><mi id=\"S3.SS1.SSS3.p5.4.m4.1.1.3\" xref=\"S3.SS1.SSS3.p5.4.m4.1.1.3.cmml\">k</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.4.m4.1b\"><apply id=\"S3.SS1.SSS3.p5.4.m4.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.4.m4.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.SS1.SSS3.p5.4.m4.1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.4.m4.1.1\">subscript</csymbol><ci id=\"S3.SS1.SSS3.p5.4.m4.1.1.2.cmml\" xref=\"S3.SS1.SSS3.p5.4.m4.1.1.2\">\ud835\udc51</ci><ci id=\"S3.SS1.SSS3.p5.4.m4.1.1.3.cmml\" xref=\"S3.SS1.SSS3.p5.4.m4.1.1.3\">\ud835\udc58</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.4.m4.1c\">d_{k}</annotation></semantics></math> is the size of a key vector, and <math id=\"S3.SS1.SSS3.p5.5.m5.1\" class=\"ltx_Math\" alttext=\"A^{\\prime}\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.5.m5.1a\"><msup id=\"S3.SS1.SSS3.p5.5.m5.1.1\" xref=\"S3.SS1.SSS3.p5.5.m5.1.1.cmml\"><mi id=\"S3.SS1.SSS3.p5.5.m5.1.1.2\" xref=\"S3.SS1.SSS3.p5.5.m5.1.1.2.cmml\">A</mi><mo id=\"S3.SS1.SSS3.p5.5.m5.1.1.3\" xref=\"S3.SS1.SSS3.p5.5.m5.1.1.3.cmml\">\u2032</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.5.m5.1b\"><apply id=\"S3.SS1.SSS3.p5.5.m5.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.5.m5.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.SS1.SSS3.p5.5.m5.1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.5.m5.1.1\">superscript</csymbol><ci id=\"S3.SS1.SSS3.p5.5.m5.1.1.2.cmml\" xref=\"S3.SS1.SSS3.p5.5.m5.1.1.2\">\ud835\udc34</ci><ci id=\"S3.SS1.SSS3.p5.5.m5.1.1.3.cmml\" xref=\"S3.SS1.SSS3.p5.5.m5.1.1.3\">\u2032</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.5.m5.1c\">A^{\\prime}</annotation></semantics></math> is the word-aligned acoustic features. Next, we add <math id=\"S3.SS1.SSS3.p5.6.m6.1\" class=\"ltx_Math\" alttext=\"A^{\\prime}\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.6.m6.1a\"><msup id=\"S3.SS1.SSS3.p5.6.m6.1.1\" xref=\"S3.SS1.SSS3.p5.6.m6.1.1.cmml\"><mi id=\"S3.SS1.SSS3.p5.6.m6.1.1.2\" xref=\"S3.SS1.SSS3.p5.6.m6.1.1.2.cmml\">A</mi><mo id=\"S3.SS1.SSS3.p5.6.m6.1.1.3\" xref=\"S3.SS1.SSS3.p5.6.m6.1.1.3.cmml\">\u2032</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.6.m6.1b\"><apply id=\"S3.SS1.SSS3.p5.6.m6.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.6.m6.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.SS1.SSS3.p5.6.m6.1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.6.m6.1.1\">superscript</csymbol><ci id=\"S3.SS1.SSS3.p5.6.m6.1.1.2.cmml\" xref=\"S3.SS1.SSS3.p5.6.m6.1.1.2\">\ud835\udc34</ci><ci id=\"S3.SS1.SSS3.p5.6.m6.1.1.3.cmml\" xref=\"S3.SS1.SSS3.p5.6.m6.1.1.3\">\u2032</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.6.m6.1c\">A^{\\prime}</annotation></semantics></math> and <math id=\"S3.SS1.SSS3.p5.7.m7.1\" class=\"ltx_Math\" alttext=\"W\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.7.m7.1a\"><mi id=\"S3.SS1.SSS3.p5.7.m7.1.1\" xref=\"S3.SS1.SSS3.p5.7.m7.1.1.cmml\">W</mi><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.7.m7.1b\"><ci id=\"S3.SS1.SSS3.p5.7.m7.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.7.m7.1.1\">\ud835\udc4a</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.7.m7.1c\">W</annotation></semantics></math> for the Transformer decoder with optimizable parameters <math id=\"S3.SS1.SSS3.p5.8.m8.1\" class=\"ltx_Math\" alttext=\"\\theta_{T}\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.8.m8.1a\"><msub id=\"S3.SS1.SSS3.p5.8.m8.1.1\" xref=\"S3.SS1.SSS3.p5.8.m8.1.1.cmml\"><mi id=\"S3.SS1.SSS3.p5.8.m8.1.1.2\" xref=\"S3.SS1.SSS3.p5.8.m8.1.1.2.cmml\">\u03b8</mi><mi id=\"S3.SS1.SSS3.p5.8.m8.1.1.3\" xref=\"S3.SS1.SSS3.p5.8.m8.1.1.3.cmml\">T</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.8.m8.1b\"><apply id=\"S3.SS1.SSS3.p5.8.m8.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.8.m8.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.SS1.SSS3.p5.8.m8.1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.8.m8.1.1\">subscript</csymbol><ci id=\"S3.SS1.SSS3.p5.8.m8.1.1.2.cmml\" xref=\"S3.SS1.SSS3.p5.8.m8.1.1.2\">\ud835\udf03</ci><ci id=\"S3.SS1.SSS3.p5.8.m8.1.1.3.cmml\" xref=\"S3.SS1.SSS3.p5.8.m8.1.1.3\">\ud835\udc47</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.8.m8.1c\">\\theta_{T}</annotation></semantics></math> to generate a corrected version <math id=\"S3.SS1.SSS3.p5.9.m9.1\" class=\"ltx_Math\" alttext=\"W^{\\prime}\" display=\"inline\"><semantics id=\"S3.SS1.SSS3.p5.9.m9.1a\"><msup id=\"S3.SS1.SSS3.p5.9.m9.1.1\" xref=\"S3.SS1.SSS3.p5.9.m9.1.1.cmml\"><mi id=\"S3.SS1.SSS3.p5.9.m9.1.1.2\" xref=\"S3.SS1.SSS3.p5.9.m9.1.1.2.cmml\">W</mi><mo id=\"S3.SS1.SSS3.p5.9.m9.1.1.3\" xref=\"S3.SS1.SSS3.p5.9.m9.1.1.3.cmml\">\u2032</mo></msup><annotation-xml encoding=\"MathML-Content\" id=\"S3.SS1.SSS3.p5.9.m9.1b\"><apply id=\"S3.SS1.SSS3.p5.9.m9.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.9.m9.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.SS1.SSS3.p5.9.m9.1.1.1.cmml\" xref=\"S3.SS1.SSS3.p5.9.m9.1.1\">superscript</csymbol><ci id=\"S3.SS1.SSS3.p5.9.m9.1.1.2.cmml\" xref=\"S3.SS1.SSS3.p5.9.m9.1.1.2\">\ud835\udc4a</ci><ci id=\"S3.SS1.SSS3.p5.9.m9.1.1.3.cmml\" xref=\"S3.SS1.SSS3.p5.9.m9.1.1.3\">\u2032</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.SS1.SSS3.p5.9.m9.1c\">W^{\\prime}</annotation></semantics></math>:</p>\n<table id=\"S5.EGx2\" class=\"ltx_equationgroup ltx_eqn_align ltx_eqn_table\">\n\n<tbody id=\"S3.E2\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_td ltx_align_right ltx_eqn_cell\"><math id=\"S3.E2.m1.2\" class=\"ltx_Math\" alttext=\"\\displaystyle W^{\\prime}=\\arg\\!\\max_{W}P(W|addition(A^{\\prime},W);\\theta_{T})\" display=\"inline\"><semantics id=\"S3.E2.m1.2a\"><mrow id=\"S3.E2.m1.2.2\" xref=\"S3.E2.m1.2.2.cmml\"><msup id=\"S3.E2.m1.2.2.3\" xref=\"S3.E2.m1.2.2.3.cmml\"><mi id=\"S3.E2.m1.2.2.3.2\" xref=\"S3.E2.m1.2.2.3.2.cmml\">W</mi><mo id=\"S3.E2.m1.2.2.3.3\" xref=\"S3.E2.m1.2.2.3.3.cmml\">\u2032</mo></msup><mo id=\"S3.E2.m1.2.2.2\" xref=\"S3.E2.m1.2.2.2.cmml\">=</mo><mrow id=\"S3.E2.m1.2.2.1\" xref=\"S3.E2.m1.2.2.1.cmml\"><mrow id=\"S3.E2.m1.2.2.1.3\" xref=\"S3.E2.m1.2.2.1.3.cmml\"><mi id=\"S3.E2.m1.2.2.1.3.1\" xref=\"S3.E2.m1.2.2.1.3.1.cmml\">arg</mi><mo id=\"S3.E2.m1.2.2.1.3a\" xref=\"S3.E2.m1.2.2.1.3.cmml\">\u2061</mo><mrow id=\"S3.E2.m1.2.2.1.3.2\" xref=\"S3.E2.m1.2.2.1.3.2.cmml\"><munder id=\"S3.E2.m1.2.2.1.3.2.1\" xref=\"S3.E2.m1.2.2.1.3.2.1.cmml\"><mi id=\"S3.E2.m1.2.2.1.3.2.1.2\" xref=\"S3.E2.m1.2.2.1.3.2.1.2.cmml\">max</mi><mi id=\"S3.E2.m1.2.2.1.3.2.1.3\" xref=\"S3.E2.m1.2.2.1.3.2.1.3.cmml\">W</mi></munder><mo lspace=\"0.167em\" id=\"S3.E2.m1.2.2.1.3.2a\" xref=\"S3.E2.m1.2.2.1.3.2.cmml\">\u2061</mo><mi id=\"S3.E2.m1.2.2.1.3.2.2\" xref=\"S3.E2.m1.2.2.1.3.2.2.cmml\">P</mi></mrow></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.2\" xref=\"S3.E2.m1.2.2.1.2.cmml\">\u200b</mo><mrow id=\"S3.E2.m1.2.2.1.1.1\" xref=\"S3.E2.m1.2.2.1.1.1.1.cmml\"><mo stretchy=\"false\" id=\"S3.E2.m1.2.2.1.1.1.2\" xref=\"S3.E2.m1.2.2.1.1.1.1.cmml\">(</mo><mrow id=\"S3.E2.m1.2.2.1.1.1.1\" xref=\"S3.E2.m1.2.2.1.1.1.1.cmml\"><mi id=\"S3.E2.m1.2.2.1.1.1.1.4\" xref=\"S3.E2.m1.2.2.1.1.1.1.4.cmml\">W</mi><mo fence=\"false\" id=\"S3.E2.m1.2.2.1.1.1.1.3\" xref=\"S3.E2.m1.2.2.1.1.1.1.3.cmml\">|</mo><mrow id=\"S3.E2.m1.2.2.1.1.1.1.2.2\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.3.cmml\"><mrow id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml\"><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.3\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml\">a</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\">\u200b</mo><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.4\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.4.cmml\">d</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2a\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\">\u200b</mo><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.5\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.5.cmml\">d</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2b\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\">\u200b</mo><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.6\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.6.cmml\">i</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2c\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\">\u200b</mo><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.7\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.7.cmml\">t</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2d\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\">\u200b</mo><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.8\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.8.cmml\">i</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2e\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\">\u200b</mo><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.9\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.9.cmml\">o</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2f\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\">\u200b</mo><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.10\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.10.cmml\">n</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2g\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\">\u200b</mo><mrow id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml\"><mo stretchy=\"false\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml\">(</mo><msup id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml\">A</mi><mo id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml\">\u2032</mo></msup><mo id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml\">,</mo><mi id=\"S3.E2.m1.1.1\" xref=\"S3.E2.m1.1.1.cmml\">W</mi><mo stretchy=\"false\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.4\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml\">)</mo></mrow></mrow><mo id=\"S3.E2.m1.2.2.1.1.1.1.2.2.3\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.3.cmml\">;</mo><msub id=\"S3.E2.m1.2.2.1.1.1.1.2.2.2\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.cmml\"><mi id=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.2\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.2.cmml\">\u03b8</mi><mi id=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.3\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.3.cmml\">T</mi></msub></mrow></mrow><mo stretchy=\"false\" id=\"S3.E2.m1.2.2.1.1.1.3\" xref=\"S3.E2.m1.2.2.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S3.E2.m1.2b\"><apply id=\"S3.E2.m1.2.2.cmml\" xref=\"S3.E2.m1.2.2\"><eq id=\"S3.E2.m1.2.2.2.cmml\" xref=\"S3.E2.m1.2.2.2\"></eq><apply id=\"S3.E2.m1.2.2.3.cmml\" xref=\"S3.E2.m1.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S3.E2.m1.2.2.3.1.cmml\" xref=\"S3.E2.m1.2.2.3\">superscript</csymbol><ci id=\"S3.E2.m1.2.2.3.2.cmml\" xref=\"S3.E2.m1.2.2.3.2\">\ud835\udc4a</ci><ci id=\"S3.E2.m1.2.2.3.3.cmml\" xref=\"S3.E2.m1.2.2.3.3\">\u2032</ci></apply><apply id=\"S3.E2.m1.2.2.1.cmml\" xref=\"S3.E2.m1.2.2.1\"><times id=\"S3.E2.m1.2.2.1.2.cmml\" xref=\"S3.E2.m1.2.2.1.2\"></times><apply id=\"S3.E2.m1.2.2.1.3.cmml\" xref=\"S3.E2.m1.2.2.1.3\"><arg id=\"S3.E2.m1.2.2.1.3.1.cmml\" xref=\"S3.E2.m1.2.2.1.3.1\"></arg><apply id=\"S3.E2.m1.2.2.1.3.2.cmml\" xref=\"S3.E2.m1.2.2.1.3.2\"><apply id=\"S3.E2.m1.2.2.1.3.2.1.cmml\" xref=\"S3.E2.m1.2.2.1.3.2.1\"><csymbol cd=\"ambiguous\" id=\"S3.E2.m1.2.2.1.3.2.1.1.cmml\" xref=\"S3.E2.m1.2.2.1.3.2.1\">subscript</csymbol><max id=\"S3.E2.m1.2.2.1.3.2.1.2.cmml\" xref=\"S3.E2.m1.2.2.1.3.2.1.2\"></max><ci id=\"S3.E2.m1.2.2.1.3.2.1.3.cmml\" xref=\"S3.E2.m1.2.2.1.3.2.1.3\">\ud835\udc4a</ci></apply><ci id=\"S3.E2.m1.2.2.1.3.2.2.cmml\" xref=\"S3.E2.m1.2.2.1.3.2.2\">\ud835\udc43</ci></apply></apply><apply id=\"S3.E2.m1.2.2.1.1.1.1.cmml\" xref=\"S3.E2.m1.2.2.1.1.1\"><csymbol cd=\"latexml\" id=\"S3.E2.m1.2.2.1.1.1.1.3.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.3\">conditional</csymbol><ci id=\"S3.E2.m1.2.2.1.1.1.1.4.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.4\">\ud835\udc4a</ci><list id=\"S3.E2.m1.2.2.1.1.1.1.2.3.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.2\"><apply id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1\"><times id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.2\"></times><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.3\">\ud835\udc4e</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.4.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.4\">\ud835\udc51</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.5.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.5\">\ud835\udc51</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.6.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.6\">\ud835\udc56</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.7.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.7\">\ud835\udc61</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.8.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.8\">\ud835\udc56</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.9.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.9\">\ud835\udc5c</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.10.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.10\">\ud835\udc5b</ci><interval closure=\"open\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1\"><apply id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1\">superscript</csymbol><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2\">\ud835\udc34</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3\">\u2032</ci></apply><ci id=\"S3.E2.m1.1.1.cmml\" xref=\"S3.E2.m1.1.1\">\ud835\udc4a</ci></interval></apply><apply id=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.2.2\"><csymbol cd=\"ambiguous\" id=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.1.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.2.2\">subscript</csymbol><ci id=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.2.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.2\">\ud835\udf03</ci><ci id=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.3.cmml\" xref=\"S3.E2.m1.2.2.1.1.1.1.2.2.2.3\">\ud835\udc47</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.E2.m1.2c\">\\displaystyle W^{\\prime}=\\arg\\!\\max_{W}P(W|addition(A^{\\prime},W);\\theta_{T})</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td rowspan=\"1\" class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(2)</span></td>\n</tr></tbody>\n</table>\n<p id=\"S3.SS1.SSS3.p5.11\" class=\"ltx_p\">The results of fusing acoustic features are shown in Table\u00a0<a href=\"#S3.T5\" title=\"Table 5 \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> with previous experimental results included for comparison.</p>\n</div>\n<figure id=\"S3.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T5.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 5</span>: </span>Result summary on IEMOCAP.</figcaption>\n<div id=\"S3.T5.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:246.4pt;height:133.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-9.3pt,5.0pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T5.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T5.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T5.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S3.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T5.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T5.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T5.1.1.1.1.1.m1.1.1\" xref=\"S3.T5.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T5.1.1.1.1.1.m1.1b\"><ci id=\"S3.T5.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T5.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T5.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T5.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T5.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T5.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T5.2.2.2.2.1.m1.1.1\" xref=\"S3.T5.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T5.2.2.2.2.1.m1.1b\"><ci id=\"S3.T5.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T5.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T5.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T5.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T5.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T5.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T5.3.3.3.3.1.m1.1.1\" xref=\"S3.T5.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T5.3.3.3.3.1.m1.1b\"><ci id=\"S3.T5.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T5.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T5.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T5.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T5.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T5.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.18</td>\n<td id=\"S3.T5.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.56</td>\n<td id=\"S3.T5.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">75.29</td>\n</tr>\n<tr id=\"S3.T5.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.5.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S3.T5.3.3.5.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span><span id=\"S3.T5.3.3.5.1.2\" class=\"ltx_text ltx_font_italic\">PT</span>\n</td>\n<td id=\"S3.T5.3.3.5.2\" class=\"ltx_td ltx_align_center\">17.14</td>\n<td id=\"S3.T5.3.3.5.3\" class=\"ltx_td ltx_align_center\">76.61</td>\n<td id=\"S3.T5.3.3.5.4\" class=\"ltx_td ltx_align_center\">75.34</td>\n</tr>\n<tr id=\"S3.T5.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.6.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T5.3.3.6.1.1\" class=\"ltx_text ltx_font_italic\">FT</span></td>\n<td id=\"S3.T5.3.3.6.2\" class=\"ltx_td ltx_align_center\">17.08</td>\n<td id=\"S3.T5.3.3.6.3\" class=\"ltx_td ltx_align_center\">77.01</td>\n<td id=\"S3.T5.3.3.6.4\" class=\"ltx_td ltx_align_center\">75.52</td>\n</tr>\n<tr id=\"S3.T5.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.7.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T5.3.3.7.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT</span></td>\n<td id=\"S3.T5.3.3.7.2\" class=\"ltx_td ltx_align_center\">16.40</td>\n<td id=\"S3.T5.3.3.7.3\" class=\"ltx_td ltx_align_center\">78.00</td>\n<td id=\"S3.T5.3.3.7.4\" class=\"ltx_td ltx_align_center\">76.58</td>\n</tr>\n<tr id=\"S3.T5.3.3.8\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.8.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T5.3.3.8.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+Mel-spec</span></td>\n<td id=\"S3.T5.3.3.8.2\" class=\"ltx_td ltx_align_center\">17.36</td>\n<td id=\"S3.T5.3.3.8.3\" class=\"ltx_td ltx_align_center\">76.82</td>\n<td id=\"S3.T5.3.3.8.4\" class=\"ltx_td ltx_align_center\">75.48</td>\n</tr>\n<tr id=\"S3.T5.3.3.9\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.9.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T5.3.3.9.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+HuBERT SSR</span></td>\n<td id=\"S3.T5.3.3.9.2\" class=\"ltx_td ltx_align_center\">16.20</td>\n<td id=\"S3.T5.3.3.9.3\" class=\"ltx_td ltx_align_center\">78.01</td>\n<td id=\"S3.T5.3.3.9.4\" class=\"ltx_td ltx_align_center\">76.71</td>\n</tr>\n<tr id=\"S3.T5.3.3.10\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.10.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.T5.3.3.10.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+HuBERT AWEs</span></td>\n<td id=\"S3.T5.3.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T5.3.3.10.2.1\" class=\"ltx_text ltx_font_bold\">16.07</span></td>\n<td id=\"S3.T5.3.3.10.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T5.3.3.10.3.1\" class=\"ltx_text ltx_font_bold\">78.22</span></td>\n<td id=\"S3.T5.3.3.10.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T5.3.3.10.4.1\" class=\"ltx_text ltx_font_bold\">76.96</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n<div id=\"S3.SS1.SSS3.p6\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS3.p6.1\" class=\"ltx_p\">We note that <span id=\"S3.SS1.SSS3.p6.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">1)</span> compared with other acoustic features, <span id=\"S3.SS1.SSS3.p6.1.2\" class=\"ltx_text ltx_font_italic\">HuBERT</span> AWEs provide the best results across all metrics. This verifies our hypothesis that <span id=\"S3.SS1.SSS3.p6.1.3\" class=\"ltx_text ltx_font_italic\">DSUs align more easily with word embeddings than continuous acoustic features</span>. <span id=\"S3.SS1.SSS3.p6.1.4\" class=\"ltx_text ltx_font_bold ltx_font_italic\">2)</span> The inclusion of Mel-spec worsens WER rather than improves it, which contrasts with findings in <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>, <a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a>, <a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">20</a>]</cite>. This phenomenon is reasonable and consistent with discussions in Sec.\u00a0<a href=\"#S3.SS1.SSS3\" title=\"3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">3.1.3</span></a>: <span id=\"S3.SS1.SSS3.p6.1.5\" class=\"ltx_text ltx_font_italic\">i)</span> IEMOCAP being emotional speech, contains intense prosody variation, making it challenging to encode phonetic information from Mel-spec; <span id=\"S3.SS1.SSS3.p6.1.6\" class=\"ltx_text ltx_font_italic\">ii)</span> the small-size data for FT (4.4k samples with an average duration of 5 seconds) hinders the model from sufficiently learning linguistic information from Mel-spec, representing a low-resource scenario; <span id=\"S3.SS1.SSS3.p6.1.7\" class=\"ltx_text ltx_font_italic\">iii)</span> our incorporation of audio features only happens during FT and testing, causing Mel-spec to struggle to provide sufficient information to word embeddings. In contrast, <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>, <a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a>, <a href=\"#bib.bib20\" title=\"\" class=\"ltx_ref\">20</a>]</cite> conducted all training phases using the same large corpus, making their findings inapplicable to LROOD scenarios. <span id=\"S3.SS1.SSS3.p6.1.8\" class=\"ltx_text ltx_font_bold ltx_font_italic\">3)</span> Interestingly, despite that Mel-spec worsens WER compared to the original ASR transcript and PT, BLEU and GLEU record improvement. This is likely because the corrected texts are more fluent and structurally correct with respect to the reference (favourable for BLEU and GLEU), while still containing word-level mistakes captured by WER. This demonstrates the contribution of audio to high-level linguistic information, which corroborates our later finding in SER (Sec.\u00a0<a href=\"#S4\" title=\"4 AEC for Downstream Use \u2013 SER \u2023 3.1.5 Performance Comparison with Literature \u2023 3.1.4 Evaluation on Additional Corpora \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">4</span></a>).</p>\n</div>\n<section id=\"S3.SS1.SSS4\" class=\"ltx_subsubsection\">\n<h4 class=\"ltx_title ltx_title_subsubsection\">\n<span class=\"ltx_tag ltx_tag_subsubsection\">3.1.4 </span>Evaluation on Additional Corpora</h4>\n\n<div id=\"S3.SS1.SSS4.p1\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS4.p1.1\" class=\"ltx_p\">As mentioned before, we test the performance of our proposed approach on two more corpora: CMU-MOSI and MSP-Podcast, to verify its generalizability. The results are shown in Table\u00a0<a href=\"#S3.T6\" title=\"Table 6 \u2023 3.1.4 Evaluation on Additional Corpora \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">6</span></a> and <a href=\"#S3.T7\" title=\"Table 7 \u2023 3.1.4 Evaluation on Additional Corpora \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">7</span></a>. All experimental settings remain the same, while several non-optimal models are omitted for brevity.</p>\n</div>\n<div id=\"S3.SS1.SSS4.p2\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS4.p2.1\" class=\"ltx_p\">It can be noted that <span id=\"S3.SS1.SSS4.p2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">1)</span> PT fails to provide better results than the original ASR transcript on CMU-MOSI, whereas the performance improvement is significant on MSP-Podcast. This phenomenon is plausible due to the OOD problem: CMU-MOSI consists of monologue speech with opinions on specific topics (mainly about movies), containing a high proportion of OOD words, making the PT model trained on Common Voice less effective. In contrast, MSP-Podcast consists of natural, real-life speech recorded in podcast settings, sharing more linguistic similarities with Common Voice. <span id=\"S3.SS1.SSS4.p2.1.2\" class=\"ltx_text ltx_font_bold ltx_font_italic\">2)</span> Both FT and the incorporation of DSUs bring performance improvements on CMU-MOSI, despite PT not being effective and the FT data being extremely limited at only 1,800 samples. Since the data size and domain similarity of IEMOCAP are between those of CMU-MOSI and MSP-Podcast, its performance improvement also falls in between (Table\u00a0<a href=\"#S3.T5\" title=\"Table 5 \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">5</span></a>). Furthermore, the performance improvement is even more significant on MSP-Podcast, indicating that the more data available for FT, the better the performance. These findings demonstrate the efficacy of our approach in LROOD scenarios and also highlight its generalizability and potential across various scenarios.</p>\n</div>\n<figure id=\"S3.T6\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T6.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 6</span>: </span>Result summary on CMU-MOSI.</figcaption>\n<div id=\"S3.T6.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:246.4pt;height:83.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-9.3pt,3.1pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T6.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T6.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T6.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S3.T6.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T6.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T6.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T6.1.1.1.1.1.m1.1.1\" xref=\"S3.T6.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T6.1.1.1.1.1.m1.1b\"><ci id=\"S3.T6.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T6.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T6.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T6.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T6.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T6.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T6.2.2.2.2.1.m1.1.1\" xref=\"S3.T6.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T6.2.2.2.2.1.m1.1b\"><ci id=\"S3.T6.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T6.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T6.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T6.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T6.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T6.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T6.3.3.3.3.1.m1.1.1\" xref=\"S3.T6.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T6.3.3.3.3.1.m1.1b\"><ci id=\"S3.T6.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T6.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T6.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T6.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T6.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T6.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.84</td>\n<td id=\"S3.T6.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">72.82</td>\n<td id=\"S3.T6.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">72.17</td>\n</tr>\n<tr id=\"S3.T6.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.5.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S3.T6.3.3.5.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span><span id=\"S3.T6.3.3.5.1.2\" class=\"ltx_text ltx_font_italic\">PT</span>\n</td>\n<td id=\"S3.T6.3.3.5.2\" class=\"ltx_td ltx_align_center\">17.88</td>\n<td id=\"S3.T6.3.3.5.3\" class=\"ltx_td ltx_align_center\">72.80</td>\n<td id=\"S3.T6.3.3.5.4\" class=\"ltx_td ltx_align_center\">72.16</td>\n</tr>\n<tr id=\"S3.T6.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.6.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T6.3.3.6.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT</span></td>\n<td id=\"S3.T6.3.3.6.2\" class=\"ltx_td ltx_align_center\">17.65</td>\n<td id=\"S3.T6.3.3.6.3\" class=\"ltx_td ltx_align_center\">73.31</td>\n<td id=\"S3.T6.3.3.6.4\" class=\"ltx_td ltx_align_center\">72.63</td>\n</tr>\n<tr id=\"S3.T6.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.T6.3.3.7.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+HuBERT AWEs</span></td>\n<td id=\"S3.T6.3.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T6.3.3.7.2.1\" class=\"ltx_text ltx_font_bold\">17.22</span></td>\n<td id=\"S3.T6.3.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T6.3.3.7.3.1\" class=\"ltx_text ltx_font_bold\">73.98</span></td>\n<td id=\"S3.T6.3.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T6.3.3.7.4.1\" class=\"ltx_text ltx_font_bold\">73.01</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n<figure id=\"S3.T7\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T7.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 7</span>: </span>Result summary on MSP-Podcast.</figcaption>\n<div id=\"S3.T7.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:246.4pt;height:83.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-9.3pt,3.1pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T7.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T7.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T7.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S3.T7.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T7.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T7.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T7.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T7.1.1.1.1.1.m1.1.1\" xref=\"S3.T7.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T7.1.1.1.1.1.m1.1b\"><ci id=\"S3.T7.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T7.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T7.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T7.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T7.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T7.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T7.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T7.2.2.2.2.1.m1.1.1\" xref=\"S3.T7.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T7.2.2.2.2.1.m1.1b\"><ci id=\"S3.T7.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T7.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T7.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T7.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T7.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T7.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T7.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T7.3.3.3.3.1.m1.1.1\" xref=\"S3.T7.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T7.3.3.3.3.1.m1.1b\"><ci id=\"S3.T7.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T7.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T7.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T7.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T7.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T7.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.65</td>\n<td id=\"S3.T7.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">81.32</td>\n<td id=\"S3.T7.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">78.02</td>\n</tr>\n<tr id=\"S3.T7.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.5.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S3.T7.3.3.5.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span><span id=\"S3.T7.3.3.5.1.2\" class=\"ltx_text ltx_font_italic\">PT</span>\n</td>\n<td id=\"S3.T7.3.3.5.2\" class=\"ltx_td ltx_align_center\">16.23</td>\n<td id=\"S3.T7.3.3.5.3\" class=\"ltx_td ltx_align_center\">82.59</td>\n<td id=\"S3.T7.3.3.5.4\" class=\"ltx_td ltx_align_center\">79.14</td>\n</tr>\n<tr id=\"S3.T7.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.6.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T7.3.3.6.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT</span></td>\n<td id=\"S3.T7.3.3.6.2\" class=\"ltx_td ltx_align_center\">14.73</td>\n<td id=\"S3.T7.3.3.6.3\" class=\"ltx_td ltx_align_center\">83.16</td>\n<td id=\"S3.T7.3.3.6.4\" class=\"ltx_td ltx_align_center\">80.84</td>\n</tr>\n<tr id=\"S3.T7.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.T7.3.3.7.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+HuBERT AWEs</span></td>\n<td id=\"S3.T7.3.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T7.3.3.7.2.1\" class=\"ltx_text ltx_font_bold\">13.89</span></td>\n<td id=\"S3.T7.3.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T7.3.3.7.3.1\" class=\"ltx_text ltx_font_bold\">83.64</span></td>\n<td id=\"S3.T7.3.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T7.3.3.7.4.1\" class=\"ltx_text ltx_font_bold\">81.80</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n<section id=\"S3.SS1.SSS5\" class=\"ltx_subsubsection\">\n<h4 class=\"ltx_title ltx_title_subsubsection\">\n<span class=\"ltx_tag ltx_tag_subsubsection\">3.1.5 </span>Performance Comparison with Literature</h4>\n\n<div id=\"S3.SS1.SSS5.p1\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p1.1\" class=\"ltx_p\">To confirm the effectiveness of our approach, we compare it with the literature by adopting the following baselines:</p>\n</div>\n<div id=\"S3.SS1.SSS5.p2\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p2.1\" class=\"ltx_p\"><span id=\"S3.SS1.SSS5.p2.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">1)</span> Crossmodal AEC using continuous acoustic information: Mel-spectrogram <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a>]</cite></p>\n</div>\n<div id=\"S3.SS1.SSS5.p3\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p3.1\" class=\"ltx_p\"><span id=\"S3.SS1.SSS5.p3.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">2)</span> Crossmodal AEC using continuous acoustic information: raw self-supervised representations <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib15\" title=\"\" class=\"ltx_ref\">15</a>]</cite>.</p>\n</div>\n<div id=\"S3.SS1.SSS5.p4\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p4.1\" class=\"ltx_p\"><span id=\"S3.SS1.SSS5.p4.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">3)</span> Generative AEC using an LLM with 1-best ASR hypothesis and Alpaca prompt <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib17\" title=\"\" class=\"ltx_ref\">17</a>]</cite>.</p>\n</div>\n<div id=\"S3.SS1.SSS5.p5\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p5.1\" class=\"ltx_p\"><span id=\"S3.SS1.SSS5.p5.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">4)</span> Generative AEC using an LLM with N-best ASR hypothesis and Alpaca prompt <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib17\" title=\"\" class=\"ltx_ref\">17</a>]</cite>.</p>\n</div>\n<div id=\"S3.SS1.SSS5.p6\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p6.1\" class=\"ltx_p\"><span id=\"S3.SS1.SSS5.p6.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">5)</span> Generative AEC using an LLM with 1-best ASR hypothesis and Task-Activating prompt <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite>.</p>\n</div>\n<div id=\"S3.SS1.SSS5.p7\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p7.1\" class=\"ltx_p\"><span id=\"S3.SS1.SSS5.p7.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">6)</span> Generative AEC using an LLM with N-best ASR hypothesis and Task-Activating prompt <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite>.</p>\n</div>\n<div id=\"S3.SS1.SSS5.p8\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p8.1\" class=\"ltx_p\">Since the comparisons with <span id=\"S3.SS1.SSS5.p8.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">1)</span> and <span id=\"S3.SS1.SSS5.p8.1.2\" class=\"ltx_text ltx_font_bold ltx_font_italic\">2)</span> have already been presented in Table\u00a0<a href=\"#S3.T5\" title=\"Table 5 \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">5</span></a> and discussed, we omit them here. For the remaining comparisons, we attempt the Alpaca prompt <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite> and Task-Activating (TA) prompt <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite> using <span id=\"S3.SS1.SSS5.p8.1.3\" class=\"ltx_text ltx_font_italic\">InstructGPT</span> on both 1-best and 5-best hypotheses. Figure\u00a0<a href=\"#S3.F2\" title=\"Figure 2 \u2023 3.1.5 Performance Comparison with Literature \u2023 3.1.4 Evaluation on Additional Corpora \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">2</span></a> illustrates how the Alpaca prompt and TA prompt are used. The results are presented in Table\u00a0<a href=\"#S3.T8\" title=\"Table 8 \u2023 3.1.5 Performance Comparison with Literature \u2023 3.1.4 Evaluation on Additional Corpora \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">8</span></a>.</p>\n</div>\n<figure id=\"S3.T8\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T8.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 8</span>: </span>Performance comparison with generative AEC approaches.</figcaption>\n<div id=\"S3.T8.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:243.8pt;height:117.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-9.2pt,4.4pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T8.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T8.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T8.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S3.T8.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T8.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T8.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T8.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T8.1.1.1.1.1.m1.1.1\" xref=\"S3.T8.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T8.1.1.1.1.1.m1.1b\"><ci id=\"S3.T8.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T8.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T8.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T8.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T8.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T8.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T8.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T8.2.2.2.2.1.m1.1.1\" xref=\"S3.T8.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T8.2.2.2.2.1.m1.1b\"><ci id=\"S3.T8.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T8.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T8.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T8.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T8.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T8.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T8.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T8.3.3.3.3.1.m1.1.1\" xref=\"S3.T8.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T8.3.3.3.3.1.m1.1b\"><ci id=\"S3.T8.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T8.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T8.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T8.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T8.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T8.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.18</td>\n<td id=\"S3.T8.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.56</td>\n<td id=\"S3.T8.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">75.29</td>\n</tr>\n<tr id=\"S3.T8.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.5.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T8.3.3.5.1.1\" class=\"ltx_text ltx_font_italic\">Our full model</span></td>\n<td id=\"S3.T8.3.3.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T8.3.3.5.2.1\" class=\"ltx_text ltx_font_bold\">16.07</span></td>\n<td id=\"S3.T8.3.3.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T8.3.3.5.3.1\" class=\"ltx_text ltx_font_bold\">78.22</span></td>\n<td id=\"S3.T8.3.3.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T8.3.3.5.4.1\" class=\"ltx_text ltx_font_bold\">76.96</span></td>\n</tr>\n<tr id=\"S3.T8.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.6.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S3.T8.3.3.6.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span><span id=\"S3.T8.3.3.6.1.2\" class=\"ltx_text ltx_font_bold ltx_font_italic\">3)<span id=\"S3.T8.3.3.6.1.2.1\" class=\"ltx_text ltx_font_medium\"> Alpaca prompt<sub id=\"S3.T8.3.3.6.1.2.1.1\" class=\"ltx_sub\">1-best</sub></span></span>\n</td>\n<td id=\"S3.T8.3.3.6.2\" class=\"ltx_td ltx_align_center\">17.18</td>\n<td id=\"S3.T8.3.3.6.3\" class=\"ltx_td ltx_align_center\">76.56</td>\n<td id=\"S3.T8.3.3.6.4\" class=\"ltx_td ltx_align_center\">75.29</td>\n</tr>\n<tr id=\"S3.T8.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.7.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T8.3.3.7.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">4)<span id=\"S3.T8.3.3.7.1.1.1\" class=\"ltx_text ltx_font_medium\"> Alpaca prompt<sub id=\"S3.T8.3.3.7.1.1.1.1\" class=\"ltx_sub\">5-best</sub></span></span></td>\n<td id=\"S3.T8.3.3.7.2\" class=\"ltx_td ltx_align_center\">17.01</td>\n<td id=\"S3.T8.3.3.7.3\" class=\"ltx_td ltx_align_center\">76.97</td>\n<td id=\"S3.T8.3.3.7.4\" class=\"ltx_td ltx_align_center\">75.44</td>\n</tr>\n<tr id=\"S3.T8.3.3.8\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.8.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T8.3.3.8.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">5)<span id=\"S3.T8.3.3.8.1.1.1\" class=\"ltx_text ltx_font_medium\"> TA prompt<sub id=\"S3.T8.3.3.8.1.1.1.1\" class=\"ltx_sub\">1-best</sub></span></span></td>\n<td id=\"S3.T8.3.3.8.2\" class=\"ltx_td ltx_align_center\">17.18</td>\n<td id=\"S3.T8.3.3.8.3\" class=\"ltx_td ltx_align_center\">76.57</td>\n<td id=\"S3.T8.3.3.8.4\" class=\"ltx_td ltx_align_center\">75.30</td>\n</tr>\n<tr id=\"S3.T8.3.3.9\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.9.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.T8.3.3.9.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">6)<span id=\"S3.T8.3.3.9.1.1.1\" class=\"ltx_text ltx_font_medium\"> TA prompt<sub id=\"S3.T8.3.3.9.1.1.1.1\" class=\"ltx_sub\">5-best</sub></span></span></td>\n<td id=\"S3.T8.3.3.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\">16.62</td>\n<td id=\"S3.T8.3.3.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\">77.99</td>\n<td id=\"S3.T8.3.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_b\">75.98</td>\n</tr>\n</table>\n</span></div>\n</figure>\n<figure id=\"S3.F2\" class=\"ltx_figure\">\n<div class=\"ltx_flex_figure\">\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img src=\"/html/2405.16677/assets/x2.png\" id=\"S3.F2.g1\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape\" width=\"277\" height=\"156\" alt=\"Refer to caption\"></div>\n<div class=\"ltx_flex_break\"></div>\n<div class=\"ltx_flex_cell ltx_flex_size_1\"><img src=\"/html/2405.16677/assets/x3.png\" id=\"S3.F2.g2\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape\" width=\"280\" height=\"157\" alt=\"Refer to caption\"></div>\n</div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\"><span id=\"S3.F2.2.1.1\" class=\"ltx_text ltx_font_bold\">Fig.\u00a02</span>: </span>An illustration of the Alpaca prompt (upper) and Task-Activating prompt (below) used in this work.</figcaption>\n</figure>\n<div id=\"S3.SS1.SSS5.p9\" class=\"ltx_para\">\n<p id=\"S3.SS1.SSS5.p9.1\" class=\"ltx_p\">From the comparison results, it can be observed that: the generative AEC approaches underperform our S2S crossmodal AEC approach, particularly as the 1-best hypothesis shows hardly any difference compared to the original ASR transcript, confirming our effectiveness for scenarios where only the 1-best hypothesis is available.</p>\n</div>\n<section id=\"S4\" class=\"ltx_section\">\n<h2 class=\"ltx_title ltx_title_section\">\n<span class=\"ltx_tag ltx_tag_section\">4 </span>AEC for Downstream Use \u2013 SER</h2>\n\n<div id=\"S4.p1\" class=\"ltx_para\">\n<p id=\"S4.p1.1\" class=\"ltx_p\">To verify the quality and usability of our AEC approaches in downstream applications, we compare SER performances using the corrected transcript and the original ASR transcript.</p>\n</div>\n<div id=\"S4.p2\" class=\"ltx_para\">\n<p id=\"S4.p2.1\" class=\"ltx_p\">Following the same training scheme as <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">7</a>]</cite>, we train the SER model on the ground-truth transcript of the IEMOCAP training set and evaluate its performance on the ASR transcript of the test set, employing five-fold cross-validation. Textual features are extracted using <span id=\"S4.p2.1.1\" class=\"ltx_text ltx_font_italic\">BERT</span>. The SER model consists of two bidirectional LSTM layers (hidden state: 32), a self-attention layer (hidden state: 64, heads: 16), a dense layer (hidden state: 64) with ReLU activation, and an output layer with Softmax activation. We use the AdamW optimizer with a learning rate of 1e-4 and weight decay of 1e-5 and a batch size of 64. Training is performed for 150 epochs, and the reported results are the best Unweighted Accuracy (UA) achieved. The only difference from <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">7</a>]</cite> is that they used the pooler output from <span id=\"S4.p2.1.2\" class=\"ltx_text ltx_font_italic\">BERT</span>, while we use hidden states.</p>\n</div>\n<figure id=\"S4.T9\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T9.6.1.1\" class=\"ltx_text ltx_font_bold\">Table 9</span>: </span>Comparison results of SER performance.</figcaption>\n<div id=\"S4.T9.4\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:214.2pt;height:50.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-8.1pt,1.9pt) scale(0.93,0.93) ;\">\n<table id=\"S4.T9.4.4\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T9.4.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T9.4.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T9.4.4.4.5.1\" class=\"ltx_text ltx_font_bold\">Transcript</span></td>\n<td id=\"S4.T9.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T9.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S4.T9.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T9.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.1.1.1.1.1.m1.1.1\" xref=\"S4.T9.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.1.1.1.1.1.m1.1b\"><ci id=\"S4.T9.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T9.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S4.T9.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T9.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S4.T9.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T9.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.2.2.2.2.1.m1.1.1\" xref=\"S4.T9.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.2.2.2.2.1.m1.1b\"><ci id=\"S4.T9.2.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T9.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S4.T9.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T9.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S4.T9.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T9.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.3.3.3.3.1.m1.1.1\" xref=\"S4.T9.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.3.3.3.3.1.m1.1b\"><ci id=\"S4.T9.3.3.3.3.1.m1.1.1.cmml\" xref=\"S4.T9.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S4.T9.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T9.4.4.4.4.1\" class=\"ltx_text ltx_font_bold\">UA<math id=\"S4.T9.4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T9.4.4.4.4.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.4.4.4.4.1.m1.1.1\" xref=\"S4.T9.4.4.4.4.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.4.4.4.4.1.m1.1b\"><ci id=\"S4.T9.4.4.4.4.1.m1.1.1.cmml\" xref=\"S4.T9.4.4.4.4.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.4.4.4.4.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S4.T9.4.4.5\" class=\"ltx_tr\">\n<td id=\"S4.T9.4.4.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T9.4.4.5.1.1\" class=\"ltx_text ltx_font_italic\">Original</span></td>\n<td id=\"S4.T9.4.4.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.18</td>\n<td id=\"S4.T9.4.4.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.56</td>\n<td id=\"S4.T9.4.4.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">75.29</td>\n<td id=\"S4.T9.4.4.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">60.92</td>\n</tr>\n<tr id=\"S4.T9.4.4.6\" class=\"ltx_tr\">\n<td id=\"S4.T9.4.4.6.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S4.T9.4.4.6.1.1\" class=\"ltx_text ltx_font_italic\">Corrected</span></td>\n<td id=\"S4.T9.4.4.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\">16.07</td>\n<td id=\"S4.T9.4.4.6.3\" class=\"ltx_td ltx_align_center ltx_border_b\">78.22</td>\n<td id=\"S4.T9.4.4.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">76.96</td>\n<td id=\"S4.T9.4.4.6.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T9.4.4.6.5.1\" class=\"ltx_text ltx_font_bold\">61.82</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n<div id=\"S4.p3\" class=\"ltx_para\">\n<p id=\"S4.p3.1\" class=\"ltx_p\">As expected, SER performance can be improved by using the corrected transcript. In <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">7</a>]</cite>, UA increased from 55.4 to 57.1 (<span id=\"S4.p3.1.1\" class=\"ltx_text ltx_font_italic\">+1.70</span>) with WER decreasing from 20 to 15 (<span id=\"S4.p3.1.2\" class=\"ltx_text ltx_font_italic\">-5.00</span>). In our case, UA increased from 60.92 to 61.82 (<span id=\"S4.p3.1.3\" class=\"ltx_text ltx_font_italic\">+0.90</span>) with WER decreasing from 17.18 to 16.07 (<span id=\"S4.p3.1.4\" class=\"ltx_text ltx_font_italic\">-1.11</span>), which represents a more significant improvement. This observation can be attributed to the fact that AEC with DSUs not only reduces WER but potentially does so via preserving syntax and semantics better, leading to higher usability in downstream tasks (resonates with the last finding in Sec.\u00a0<a href=\"#S3.SS1.SSS3\" title=\"3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">3.1.3</span></a>). However, further analysis is needed to understand the nature of ASR errors: where they occur and how they are corrected.</p>\n</div>\n<section id=\"S5\" class=\"ltx_section\">\n<h2 class=\"ltx_title ltx_title_section\">\n<span class=\"ltx_tag ltx_tag_section\">5 </span>Discussion and Conclusion</h2>\n\n<div id=\"S5.p1\" class=\"ltx_para\">\n<p id=\"S5.p1.1\" class=\"ltx_p\">In this paper, we pre-train an S2S AEC model on large corpora and fine-tune it on an LROOD corpus with the assistance of DSUs. The results indicate that for AEC on LROOD data, PT, FT, and DSUs are all important. Moreover, the ASR domain discrepancy problem requires attention and should be alleviated by using the same ASR model to generate transcripts in all phases of AEC applications. We compare different acoustic features and demonstrate the superiority of DSUs over continuous features in aligning with word embeddings. A downstream task of SER further demonstrates the improved quality of the corrected transcript, highlighting the applicability of our approach. Additionally, as demonstrated by the experiment in Sec.\u00a0<a href=\"#S3.SS1.SSS4\" title=\"3.1.4 Evaluation on Additional Corpora \u2023 3.1.3 Incorporation of Discrete Speech Units \u2023 3.1.2 ASR Domain Discrepancy Problem \u2023 3.1 Crossmodal AEC on LROOD Data \u2023 3 Approach, Experiments, and Results \u2023 Crossmodal ASR Error Correction with Discrete Speech Units\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">3.1.4</span></a>, our approach is expected to perform better on larger downstream data.</p>\n</div>\n<section id=\"bib\" class=\"ltx_bibliography\">\n<h2 class=\"ltx_title ltx_title_bibliography\">References</h2>\n\n<ul class=\"ltx_biblist\">\n<li id=\"bib.bib1\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[1]</span>\n<span class=\"ltx_bibblock\">\nAlexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cwav2vec 2.0: A framework for self-supervised learning of speech representations,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib1.1.1\" class=\"ltx_text ltx_font_italic\">Advances in neural information processing systems</span>, vol. 33, pp. 12449\u201312460, 2020.\n\n</span>\n</li>\n<li id=\"bib.bib2\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[2]</span>\n<span class=\"ltx_bibblock\">\nWei-Ning Hsu, Benjamin Bolte, Yao-Hung\u00a0Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cHubert: Self-supervised speech representation learning by masked prediction of hidden units,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib2.1.1\" class=\"ltx_text ltx_font_italic\">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, vol. 29, pp. 3451\u20133460, 2021.\n\n</span>\n</li>\n<li id=\"bib.bib3\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[3]</span>\n<span class=\"ltx_bibblock\">\nAlec Radford, Jong\u00a0Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cRobust speech recognition via large-scale weak supervision,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib3.1.1\" class=\"ltx_text ltx_font_italic\">International Conference on Machine Learning</span>. PMLR, 2023, pp. 28492\u201328518.\n\n</span>\n</li>\n<li id=\"bib.bib4\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[4]</span>\n<span class=\"ltx_bibblock\">\nYuanchao Li, Yumnah Mohamied, Peter Bell, and Catherine Lai,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cExploration of a self-supervised speech model: A study on emotional corpora,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib4.1.1\" class=\"ltx_text ltx_font_italic\">2022 IEEE Spoken Language Technology Workshop (SLT)</span>. IEEE, 2023, pp. 868\u2013875.\n\n</span>\n</li>\n<li id=\"bib.bib5\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[5]</span>\n<span class=\"ltx_bibblock\">\nGene-Ping Yang, Yue Gu, Qingming Tang, Dongsu Du, and Yuzong Liu,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cOn-device constrained self-supervised speech representation learning for keyword spotting via knowledge distillation,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib5.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech</span>, 2023.\n\n</span>\n</li>\n<li id=\"bib.bib6\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[6]</span>\n<span class=\"ltx_bibblock\">\nYuan Gong, Sameer Khurana, Leonid Karlinsky, and James Glass,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cWhisper-at: Noise-robust automatic speech recognizers are also strong general audio event taggers,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib6.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech</span>, 2023.\n\n</span>\n</li>\n<li id=\"bib.bib7\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[7]</span>\n<span class=\"ltx_bibblock\">\nYuanchao Li, Zeyu Zhao, Ondrej Klejch, Peter Bell, and Catherine Lai,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cASR and emotional speech: A word-level investigation of the mutual impact of speech and emotion recognition,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib7.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech 2023</span>, 2023.\n\n</span>\n</li>\n<li id=\"bib.bib8\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[8]</span>\n<span class=\"ltx_bibblock\">\nWen Wu, Chao Zhang, and Philip\u00a0C Woodland,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cSelf-supervised representations in speech-based depression detection,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib8.1.1\" class=\"ltx_text ltx_font_italic\">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2023, pp. 1\u20135.\n\n</span>\n</li>\n<li id=\"bib.bib9\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[9]</span>\n<span class=\"ltx_bibblock\">\nSatwik Dutta, Sarah\u00a0A. Tao, Jacob\u00a0C. Reyna, Rebecca\u00a0E. Hacker, Dwight\u00a0W. Irvin, Jay Buzhardt, and John H.\u00a0L. Hansen,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cChallenges remain in building asr for spontaneous preschool children speech in naturalistic educational environments,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib9.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech</span>, 2022.\n\n</span>\n</li>\n<li id=\"bib.bib10\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[10]</span>\n<span class=\"ltx_bibblock\">\nYuanchao Li, Peter Bell, and Catherine Lai,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cFusing ASR outputs in joint training for speech emotion recognition,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib10.1.1\" class=\"ltx_text ltx_font_italic\">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2022, pp. 7362\u20137366.\n\n</span>\n</li>\n<li id=\"bib.bib11\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[11]</span>\n<span class=\"ltx_bibblock\">\nTomohiro Tanaka, Ryo Masumura, Hirokazu Masataki, and Yushi Aono,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cNeural error corrective language models for automatic speech recognition.,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib11.1.1\" class=\"ltx_text ltx_font_italic\">INTERSPEECH</span>, 2018, pp. 401\u2013405.\n\n</span>\n</li>\n<li id=\"bib.bib12\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[12]</span>\n<span class=\"ltx_bibblock\">\nChao-Han\u00a0Huck Yang, Yile Gu, Yi-Chieh Liu, Shalini Ghosh, Ivan Bulyko, and Andreas Stolcke,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cGenerative speech recognition error correction with large language models,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib12.1.1\" class=\"ltx_text ltx_font_italic\">arXiv preprint arXiv:2309.15649</span>, 2023.\n\n</span>\n</li>\n<li id=\"bib.bib13\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[13]</span>\n<span class=\"ltx_bibblock\">\nAnirudh Mani, Shruti Palaskar, Nimshi\u00a0Venkat Meripo, Sandeep Konam, and Florian Metze,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cASR error correction and domain adaptation using machine translation,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib13.1.1\" class=\"ltx_text ltx_font_italic\">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2020, pp. 6344\u20136348.\n\n</span>\n</li>\n<li id=\"bib.bib14\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[14]</span>\n<span class=\"ltx_bibblock\">\nJunwei Liao, Sefik Eskimez, Liyang Lu, Yu\u00a0Shi, Ming Gong, Linjun Shou, Hong Qu, and Michael Zeng,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cImproving readability for automatic speech recognition transcription,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib14.1.1\" class=\"ltx_text ltx_font_italic\">ACM Transactions on Asian and Low-Resource Language Information Processing</span>, vol. 22, no. 5, pp. 1\u201323, 2023.\n\n</span>\n</li>\n<li id=\"bib.bib15\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[15]</span>\n<span class=\"ltx_bibblock\">\nBinghuai Lin and Liyuan Wang,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cMulti-modal ASR error correction with joint ASR error detection,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib15.1.1\" class=\"ltx_text ltx_font_italic\">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2023, pp. 1\u20135.\n\n</span>\n</li>\n<li id=\"bib.bib16\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[16]</span>\n<span class=\"ltx_bibblock\">\nJing Du, Shiliang Pu, Qinbo Dong, Chao Jin, Xin Qi, Dian Gu, Ru\u00a0Wu, and Hongwei Zhou,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cCross-modal ASR post-processing system for error correction and utterance rejection,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib16.1.1\" class=\"ltx_text ltx_font_italic\">arXiv preprint arXiv:2201.03313</span>, 2022.\n\n</span>\n</li>\n<li id=\"bib.bib17\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[17]</span>\n<span class=\"ltx_bibblock\">\nSrijith Radhakrishnan, Chao-Han\u00a0Huck Yang, Sumeer\u00a0Ahmad Khan, Rohit Kumar, Narsis\u00a0A Kiani, David Gomez-Cabrero, and Jesper Tegn\u00e9r,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cWhispering llama: A cross-modal generative error correction framework for speech recognition,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib17.1.1\" class=\"ltx_text ltx_font_italic\">The 2023 Conference on Empirical Methods in Natural Language Processing</span>, 2023.\n\n</span>\n</li>\n<li id=\"bib.bib18\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[18]</span>\n<span class=\"ltx_bibblock\">\nChen Chen, Ruizhe Li, Yuchen Hu, Sabato\u00a0Marco Siniscalchi, Pin-Yu Chen, Ensiong Chng, and Chao-Han\u00a0Huck Yang,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cIt\u2019s never too late: Fusing acoustic information into large language models for automatic speech recognition,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib18.1.1\" class=\"ltx_text ltx_font_italic\">arXiv preprint arXiv:2402.05457</span>, 2024.\n\n</span>\n</li>\n<li id=\"bib.bib19\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[19]</span>\n<span class=\"ltx_bibblock\">\nShuai Zhang, Jiangyan Yi, Zhengkun Tian, Ye\u00a0Bai, Jianhua Tao, and Xuefei Liu,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cEnd-to-end spelling correction conditioned on acoustic feature for code-switching speech recognition.,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib19.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech</span>, 2021.\n\n</span>\n</li>\n<li id=\"bib.bib20\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[20]</span>\n<span class=\"ltx_bibblock\">\nTomohiro Tanaka, Ryo Masumura, Mana Ihori, Akihiko Takashima, Takafumi Moriya, Takanori Ashihara, Shota Orihashi, and Naoki Makishima,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cCross-modal transformer-based neural correction models for automatic speech recognition,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib20.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech</span>, 2021.\n\n</span>\n</li>\n<li id=\"bib.bib21\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[21]</span>\n<span class=\"ltx_bibblock\">\nRosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis\u00a0M Tyers, and Gregor Weber,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cCommon voice: A massively-multilingual speech corpus,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib21.1.1\" class=\"ltx_text ltx_font_italic\">Proceedings of the Twelfth Language Resources and Evaluation Conference (LREC)</span>, 2020.\n\n</span>\n</li>\n<li id=\"bib.bib22\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[22]</span>\n<span class=\"ltx_bibblock\">\nCarlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim, Jeannette\u00a0N Chang, Sungbok Lee, and Shrikanth\u00a0S Narayanan,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cIEMOCAP: Interactive emotional dyadic motion capture database,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib22.1.1\" class=\"ltx_text ltx_font_italic\">Language resources and evaluation</span>, vol. 42, pp. 335\u2013359, 2008.\n\n</span>\n</li>\n<li id=\"bib.bib23\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[23]</span>\n<span class=\"ltx_bibblock\">\nAmir Zadeh, Rowan Zellers, Eli Pincus, and Louis-Philippe Morency,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cMultimodal sentiment intensity analysis in videos: Facial gestures and verbal messages,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib23.1.1\" class=\"ltx_text ltx_font_italic\">IEEE Intelligent Systems</span>, vol. 31, no. 6, pp. 82\u201388, 2016.\n\n</span>\n</li>\n<li id=\"bib.bib24\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[24]</span>\n<span class=\"ltx_bibblock\">\nReza Lotfian and Carlos Busso,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cBuilding naturalistic emotionally balanced speech corpus by retrieving emotional speech from existing podcast recordings,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib24.1.1\" class=\"ltx_text ltx_font_italic\">IEEE Transactions on Affective Computing</span>, vol. 10, no. 4, pp. 471\u2013483, 2017.\n\n</span>\n</li>\n<li id=\"bib.bib25\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[25]</span>\n<span class=\"ltx_bibblock\">\nAnmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu\u00a0Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, et\u00a0al.,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cConformer: Convolution-augmented transformer for speech recognition,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib25.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech</span>, 2020.\n\n</span>\n</li>\n<li id=\"bib.bib26\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[26]</span>\n<span class=\"ltx_bibblock\">\nShinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro Nishitoba, Yuya Unno, Nelson Enrique\u00a0Yalta Soplin, Jahn Heymann, Matthew Wiesner, Nanxin Chen, et\u00a0al.,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cEspnet: End-to-end speech processing toolkit,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib26.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech</span>, 2018.\n\n</span>\n</li>\n<li id=\"bib.bib27\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[27]</span>\n<span class=\"ltx_bibblock\">\nJinxi Guo, Tara\u00a0N Sainath, and Ron\u00a0J Weiss,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cA spelling correction model for end-to-end speech recognition,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib27.1.1\" class=\"ltx_text ltx_font_italic\">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2019, pp. 5651\u20135655.\n\n</span>\n</li>\n<li id=\"bib.bib28\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[28]</span>\n<span class=\"ltx_bibblock\">\nYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc\u00a0V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et\u00a0al.,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cGoogle\u2019s neural machine translation system: Bridging the gap between human and machine translation,\u201d\n\n</span>\n<span class=\"ltx_bibblock\"><span id=\"bib.bib28.1.1\" class=\"ltx_text ltx_font_italic\">arXiv preprint arXiv:1609.08144</span>, 2016.\n\n</span>\n</li>\n<li id=\"bib.bib29\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[29]</span>\n<span class=\"ltx_bibblock\">\nMichael McAuliffe, Michaela Socolof, Sarah Mihuc, Michael Wagner, and Morgan Sonderegger,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cMontreal forced aligner: Trainable text-speech alignment using kaldi.,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib29.1.1\" class=\"ltx_text ltx_font_italic\">Interspeech</span>, 2017, vol. 2017, pp. 498\u2013502.\n\n</span>\n</li>\n<li id=\"bib.bib30\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[30]</span>\n<span class=\"ltx_bibblock\">\nPinzhen Chen and Gerasimos Lampouras,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cExploring data augmentation for code generation tasks,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib30.1.1\" class=\"ltx_text ltx_font_italic\">Findings of the Association for Computational Linguistics: EACL 2023</span>, 2023, pp. 1497\u20131505.\n\n</span>\n</li>\n<li id=\"bib.bib31\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[31]</span>\n<span class=\"ltx_bibblock\">\nMauro Cettolo, Christian Girardi, and Marcello Federico,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cWIT3: Web inventory of transcribed and translated talks,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib31.1.1\" class=\"ltx_text ltx_font_italic\">Proceedings of the 16th Annual Conference of the European Association for Machine Translation</span>, Trento, Italy, 2012, pp. 261\u2013268, European Association for Machine Translation.\n\n</span>\n</li>\n<li id=\"bib.bib32\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[32]</span>\n<span class=\"ltx_bibblock\">\nAndrew\u00a0L Maas, Stephen\u00a0D Miller, Tyler\u00a0M O\u2019neil, Andrew\u00a0Y Ng, and Patrick Nguyen,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cWord-level acoustic modeling with convolutional vector regression,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib32.1.1\" class=\"ltx_text ltx_font_italic\">Proc. ICML Workshop Representation Learn</span>, 2012.\n\n</span>\n</li>\n<li id=\"bib.bib33\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[33]</span>\n<span class=\"ltx_bibblock\">\nKeith Levin, Katharine Henry, Aren Jansen, and Karen Livescu,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cFixed-dimensional acoustic embeddings of variable-length segments in low-resource settings,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib33.1.1\" class=\"ltx_text ltx_font_italic\">2013 IEEE workshop on automatic speech recognition and understanding</span>. IEEE, 2013, pp. 410\u2013415.\n\n</span>\n</li>\n<li id=\"bib.bib34\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[34]</span>\n<span class=\"ltx_bibblock\">\nYevgen Matusevych, Herman Kamper, and Sharon Goldwater,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cAnalyzing autoencoder-based acoustic word embeddings,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib34.1.1\" class=\"ltx_text ltx_font_italic\">ICLR Workshop on Bridging AI and Cognitive Science</span>, 2020.\n\n</span>\n</li>\n<li id=\"bib.bib35\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[35]</span>\n<span class=\"ltx_bibblock\">\nRamon Sanabria, Hao Tang, and Sharon Goldwater,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cAnalyzing acoustic word embeddings from pre-trained self-supervised speech models,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib35.1.1\" class=\"ltx_text ltx_font_italic\">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2023, pp. 1\u20135.\n\n</span>\n</li>\n<li id=\"bib.bib36\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[36]</span>\n<span class=\"ltx_bibblock\">\nAlexandra Saliba, Yuanchao Li, Ramon Sanabria, and Catherine Lai,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cLayer-wise analysis of self-supervised acoustic word embeddings: A study on speech emotion recognition,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib36.1.1\" class=\"ltx_text ltx_font_italic\">2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)</span>. IEEE, 2024.\n\n</span>\n</li>\n<li id=\"bib.bib37\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[37]</span>\n<span class=\"ltx_bibblock\">\nAnkita Pasad, Bowen Shi, and Karen Livescu,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cComparative layer-wise analysis of self-supervised speech models,\u201d\n\n</span>\n<span class=\"ltx_bibblock\">in <span id=\"bib.bib37.1.1\" class=\"ltx_text ltx_font_italic\">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2023, pp. 1\u20135.\n\n</span>\n</li>\n<li id=\"bib.bib38\" class=\"ltx_bibitem\">\n<span class=\"ltx_tag ltx_tag_bibitem\">[38]</span>\n<span class=\"ltx_bibblock\">\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori\u00a0B Hashimoto,\n\n</span>\n<span class=\"ltx_bibblock\">\u201cStanford alpaca: An instruction-following llama model,\u201d 2023.\n\n</span>\n</li>\n</ul>\n</section>\n</section>\n</section>\n</section>\n</section>\n</section>\n</div>\n</div>\n</figure>\n",
        "footnotes": [],
        "references": []
    },
    "S3.T5": {
        "caption": "Table 5 :  Result summary on IEMOCAP.",
        "table": "<figure id=\"S3.T5\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T5.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 5</span>: </span>Result summary on IEMOCAP.</figcaption>\n<div id=\"S3.T5.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:246.4pt;height:133.9pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-9.3pt,5.0pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T5.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T5.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T5.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S3.T5.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T5.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T5.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T5.1.1.1.1.1.m1.1.1\" xref=\"S3.T5.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T5.1.1.1.1.1.m1.1b\"><ci id=\"S3.T5.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T5.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T5.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T5.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T5.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T5.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T5.2.2.2.2.1.m1.1.1\" xref=\"S3.T5.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T5.2.2.2.2.1.m1.1b\"><ci id=\"S3.T5.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T5.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T5.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T5.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T5.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T5.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T5.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T5.3.3.3.3.1.m1.1.1\" xref=\"S3.T5.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T5.3.3.3.3.1.m1.1b\"><ci id=\"S3.T5.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T5.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T5.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T5.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T5.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T5.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.18</td>\n<td id=\"S3.T5.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.56</td>\n<td id=\"S3.T5.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">75.29</td>\n</tr>\n<tr id=\"S3.T5.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.5.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S3.T5.3.3.5.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span><span id=\"S3.T5.3.3.5.1.2\" class=\"ltx_text ltx_font_italic\">PT</span>\n</td>\n<td id=\"S3.T5.3.3.5.2\" class=\"ltx_td ltx_align_center\">17.14</td>\n<td id=\"S3.T5.3.3.5.3\" class=\"ltx_td ltx_align_center\">76.61</td>\n<td id=\"S3.T5.3.3.5.4\" class=\"ltx_td ltx_align_center\">75.34</td>\n</tr>\n<tr id=\"S3.T5.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.6.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T5.3.3.6.1.1\" class=\"ltx_text ltx_font_italic\">FT</span></td>\n<td id=\"S3.T5.3.3.6.2\" class=\"ltx_td ltx_align_center\">17.08</td>\n<td id=\"S3.T5.3.3.6.3\" class=\"ltx_td ltx_align_center\">77.01</td>\n<td id=\"S3.T5.3.3.6.4\" class=\"ltx_td ltx_align_center\">75.52</td>\n</tr>\n<tr id=\"S3.T5.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.7.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T5.3.3.7.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT</span></td>\n<td id=\"S3.T5.3.3.7.2\" class=\"ltx_td ltx_align_center\">16.40</td>\n<td id=\"S3.T5.3.3.7.3\" class=\"ltx_td ltx_align_center\">78.00</td>\n<td id=\"S3.T5.3.3.7.4\" class=\"ltx_td ltx_align_center\">76.58</td>\n</tr>\n<tr id=\"S3.T5.3.3.8\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.8.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T5.3.3.8.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+Mel-spec</span></td>\n<td id=\"S3.T5.3.3.8.2\" class=\"ltx_td ltx_align_center\">17.36</td>\n<td id=\"S3.T5.3.3.8.3\" class=\"ltx_td ltx_align_center\">76.82</td>\n<td id=\"S3.T5.3.3.8.4\" class=\"ltx_td ltx_align_center\">75.48</td>\n</tr>\n<tr id=\"S3.T5.3.3.9\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.9.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T5.3.3.9.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+HuBERT SSR</span></td>\n<td id=\"S3.T5.3.3.9.2\" class=\"ltx_td ltx_align_center\">16.20</td>\n<td id=\"S3.T5.3.3.9.3\" class=\"ltx_td ltx_align_center\">78.01</td>\n<td id=\"S3.T5.3.3.9.4\" class=\"ltx_td ltx_align_center\">76.71</td>\n</tr>\n<tr id=\"S3.T5.3.3.10\" class=\"ltx_tr\">\n<td id=\"S3.T5.3.3.10.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.T5.3.3.10.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+HuBERT AWEs</span></td>\n<td id=\"S3.T5.3.3.10.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T5.3.3.10.2.1\" class=\"ltx_text ltx_font_bold\">16.07</span></td>\n<td id=\"S3.T5.3.3.10.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T5.3.3.10.3.1\" class=\"ltx_text ltx_font_bold\">78.22</span></td>\n<td id=\"S3.T5.3.3.10.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T5.3.3.10.4.1\" class=\"ltx_text ltx_font_bold\">76.96</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "The results of fusing acoustic features are shown in Table 5 with previous experimental results included for comparison.",
            "It can be noted that 1) PT fails to provide better results than the original ASR transcript on CMU-MOSI, whereas the performance improvement is significant on MSP-Podcast. This phenomenon is plausible due to the OOD problem: CMU-MOSI consists of monologue speech with opinions on specific topics (mainly about movies), containing a high proportion of OOD words, making the PT model trained on Common Voice less effective. In contrast, MSP-Podcast consists of natural, real-life speech recorded in podcast settings, sharing more linguistic similarities with Common Voice. 2) Both FT and the incorporation of DSUs bring performance improvements on CMU-MOSI, despite PT not being effective and the FT data being extremely limited at only 1,800 samples. Since the data size and domain similarity of IEMOCAP are between those of CMU-MOSI and MSP-Podcast, its performance improvement also falls in between (Table 5). Furthermore, the performance improvement is even more significant on MSP-Podcast, indicating that the more data available for FT, the better the performance. These findings demonstrate the efficacy of our approach in LROOD scenarios and also highlight its generalizability and potential across various scenarios.",
            "Since the comparisons with 1) and 2) have already been presented in Table 5 and discussed, we omit them here. For the remaining comparisons, we attempt the Alpaca prompt [38] and Task-Activating (TA) prompt [12] using InstructGPT on both 1-best and 5-best hypotheses. Figure 2 illustrates how the Alpaca prompt and TA prompt are used. The results are presented in Table 8."
        ]
    },
    "S3.T6": {
        "caption": "Table 6 :  Result summary on CMU-MOSI.",
        "table": "<figure id=\"S3.T6\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T6.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 6</span>: </span>Result summary on CMU-MOSI.</figcaption>\n<div id=\"S3.T6.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:246.4pt;height:83.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-9.3pt,3.1pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T6.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T6.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T6.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S3.T6.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T6.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T6.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T6.1.1.1.1.1.m1.1.1\" xref=\"S3.T6.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T6.1.1.1.1.1.m1.1b\"><ci id=\"S3.T6.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T6.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T6.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T6.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T6.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T6.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T6.2.2.2.2.1.m1.1.1\" xref=\"S3.T6.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T6.2.2.2.2.1.m1.1b\"><ci id=\"S3.T6.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T6.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T6.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T6.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T6.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T6.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T6.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T6.3.3.3.3.1.m1.1.1\" xref=\"S3.T6.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T6.3.3.3.3.1.m1.1b\"><ci id=\"S3.T6.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T6.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T6.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T6.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T6.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T6.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.84</td>\n<td id=\"S3.T6.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">72.82</td>\n<td id=\"S3.T6.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">72.17</td>\n</tr>\n<tr id=\"S3.T6.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.5.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S3.T6.3.3.5.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span><span id=\"S3.T6.3.3.5.1.2\" class=\"ltx_text ltx_font_italic\">PT</span>\n</td>\n<td id=\"S3.T6.3.3.5.2\" class=\"ltx_td ltx_align_center\">17.88</td>\n<td id=\"S3.T6.3.3.5.3\" class=\"ltx_td ltx_align_center\">72.80</td>\n<td id=\"S3.T6.3.3.5.4\" class=\"ltx_td ltx_align_center\">72.16</td>\n</tr>\n<tr id=\"S3.T6.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.6.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T6.3.3.6.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT</span></td>\n<td id=\"S3.T6.3.3.6.2\" class=\"ltx_td ltx_align_center\">17.65</td>\n<td id=\"S3.T6.3.3.6.3\" class=\"ltx_td ltx_align_center\">73.31</td>\n<td id=\"S3.T6.3.3.6.4\" class=\"ltx_td ltx_align_center\">72.63</td>\n</tr>\n<tr id=\"S3.T6.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T6.3.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.T6.3.3.7.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+HuBERT AWEs</span></td>\n<td id=\"S3.T6.3.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T6.3.3.7.2.1\" class=\"ltx_text ltx_font_bold\">17.22</span></td>\n<td id=\"S3.T6.3.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T6.3.3.7.3.1\" class=\"ltx_text ltx_font_bold\">73.98</span></td>\n<td id=\"S3.T6.3.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T6.3.3.7.4.1\" class=\"ltx_text ltx_font_bold\">73.01</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "As mentioned before, we test the performance of our proposed approach on two more corpora: CMU-MOSI and MSP-Podcast, to verify its generalizability. The results are shown in Table 6 and 7. All experimental settings remain the same, while several non-optimal models are omitted for brevity."
        ]
    },
    "S3.T7": {
        "caption": "Table 7 :  Result summary on MSP-Podcast.",
        "table": "<figure id=\"S3.T7\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T7.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 7</span>: </span>Result summary on MSP-Podcast.</figcaption>\n<div id=\"S3.T7.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:246.4pt;height:83.7pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-9.3pt,3.1pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T7.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T7.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T7.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S3.T7.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T7.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T7.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T7.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T7.1.1.1.1.1.m1.1.1\" xref=\"S3.T7.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T7.1.1.1.1.1.m1.1b\"><ci id=\"S3.T7.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T7.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T7.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T7.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T7.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T7.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T7.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T7.2.2.2.2.1.m1.1.1\" xref=\"S3.T7.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T7.2.2.2.2.1.m1.1b\"><ci id=\"S3.T7.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T7.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T7.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T7.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T7.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T7.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T7.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T7.3.3.3.3.1.m1.1.1\" xref=\"S3.T7.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T7.3.3.3.3.1.m1.1b\"><ci id=\"S3.T7.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T7.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T7.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T7.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T7.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T7.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.65</td>\n<td id=\"S3.T7.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">81.32</td>\n<td id=\"S3.T7.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">78.02</td>\n</tr>\n<tr id=\"S3.T7.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.5.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S3.T7.3.3.5.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span><span id=\"S3.T7.3.3.5.1.2\" class=\"ltx_text ltx_font_italic\">PT</span>\n</td>\n<td id=\"S3.T7.3.3.5.2\" class=\"ltx_td ltx_align_center\">16.23</td>\n<td id=\"S3.T7.3.3.5.3\" class=\"ltx_td ltx_align_center\">82.59</td>\n<td id=\"S3.T7.3.3.5.4\" class=\"ltx_td ltx_align_center\">79.14</td>\n</tr>\n<tr id=\"S3.T7.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.6.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T7.3.3.6.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT</span></td>\n<td id=\"S3.T7.3.3.6.2\" class=\"ltx_td ltx_align_center\">14.73</td>\n<td id=\"S3.T7.3.3.6.3\" class=\"ltx_td ltx_align_center\">83.16</td>\n<td id=\"S3.T7.3.3.6.4\" class=\"ltx_td ltx_align_center\">80.84</td>\n</tr>\n<tr id=\"S3.T7.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T7.3.3.7.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.T7.3.3.7.1.1\" class=\"ltx_text ltx_font_italic\">PT+FT+HuBERT AWEs</span></td>\n<td id=\"S3.T7.3.3.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T7.3.3.7.2.1\" class=\"ltx_text ltx_font_bold\">13.89</span></td>\n<td id=\"S3.T7.3.3.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T7.3.3.7.3.1\" class=\"ltx_text ltx_font_bold\">83.64</span></td>\n<td id=\"S3.T7.3.3.7.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T7.3.3.7.4.1\" class=\"ltx_text ltx_font_bold\">81.80</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": []
    },
    "S3.T8": {
        "caption": "Table 8 :  Performance comparison with generative AEC approaches.",
        "table": "<figure id=\"S3.T8\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S3.T8.5.1.1\" class=\"ltx_text ltx_font_bold\">Table 8</span>: </span>Performance comparison with generative AEC approaches.</figcaption>\n<div id=\"S3.T8.3\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:243.8pt;height:117.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-9.2pt,4.4pt) scale(0.93,0.93) ;\">\n<table id=\"S3.T8.3.3\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S3.T8.3.3.3\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.3.4\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T8.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">Model</span></td>\n<td id=\"S3.T8.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T8.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S3.T8.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S3.T8.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T8.1.1.1.1.1.m1.1.1\" xref=\"S3.T8.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T8.1.1.1.1.1.m1.1b\"><ci id=\"S3.T8.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T8.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T8.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S3.T8.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T8.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S3.T8.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T8.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T8.2.2.2.2.1.m1.1.1\" xref=\"S3.T8.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T8.2.2.2.2.1.m1.1b\"><ci id=\"S3.T8.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T8.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T8.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S3.T8.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T8.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S3.T8.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S3.T8.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S3.T8.3.3.3.3.1.m1.1.1\" xref=\"S3.T8.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T8.3.3.3.3.1.m1.1b\"><ci id=\"S3.T8.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T8.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T8.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S3.T8.3.3.4\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.4.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S3.T8.3.3.4.1.1\" class=\"ltx_text ltx_font_italic\">Original ASR transcript</span></td>\n<td id=\"S3.T8.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.18</td>\n<td id=\"S3.T8.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.56</td>\n<td id=\"S3.T8.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">75.29</td>\n</tr>\n<tr id=\"S3.T8.3.3.5\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.5.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T8.3.3.5.1.1\" class=\"ltx_text ltx_font_italic\">Our full model</span></td>\n<td id=\"S3.T8.3.3.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T8.3.3.5.2.1\" class=\"ltx_text ltx_font_bold\">16.07</span></td>\n<td id=\"S3.T8.3.3.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T8.3.3.5.3.1\" class=\"ltx_text ltx_font_bold\">78.22</span></td>\n<td id=\"S3.T8.3.3.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T8.3.3.5.4.1\" class=\"ltx_text ltx_font_bold\">76.96</span></td>\n</tr>\n<tr id=\"S3.T8.3.3.6\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.6.1\" class=\"ltx_td ltx_align_left\">\n<span id=\"S3.T8.3.3.6.1.1\" class=\"ltx_ERROR undefined\">\\hdashline</span><span id=\"S3.T8.3.3.6.1.2\" class=\"ltx_text ltx_font_bold ltx_font_italic\">3)<span id=\"S3.T8.3.3.6.1.2.1\" class=\"ltx_text ltx_font_medium\"> Alpaca prompt<sub id=\"S3.T8.3.3.6.1.2.1.1\" class=\"ltx_sub\">1-best</sub></span></span>\n</td>\n<td id=\"S3.T8.3.3.6.2\" class=\"ltx_td ltx_align_center\">17.18</td>\n<td id=\"S3.T8.3.3.6.3\" class=\"ltx_td ltx_align_center\">76.56</td>\n<td id=\"S3.T8.3.3.6.4\" class=\"ltx_td ltx_align_center\">75.29</td>\n</tr>\n<tr id=\"S3.T8.3.3.7\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.7.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T8.3.3.7.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">4)<span id=\"S3.T8.3.3.7.1.1.1\" class=\"ltx_text ltx_font_medium\"> Alpaca prompt<sub id=\"S3.T8.3.3.7.1.1.1.1\" class=\"ltx_sub\">5-best</sub></span></span></td>\n<td id=\"S3.T8.3.3.7.2\" class=\"ltx_td ltx_align_center\">17.01</td>\n<td id=\"S3.T8.3.3.7.3\" class=\"ltx_td ltx_align_center\">76.97</td>\n<td id=\"S3.T8.3.3.7.4\" class=\"ltx_td ltx_align_center\">75.44</td>\n</tr>\n<tr id=\"S3.T8.3.3.8\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.8.1\" class=\"ltx_td ltx_align_left\"><span id=\"S3.T8.3.3.8.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">5)<span id=\"S3.T8.3.3.8.1.1.1\" class=\"ltx_text ltx_font_medium\"> TA prompt<sub id=\"S3.T8.3.3.8.1.1.1.1\" class=\"ltx_sub\">1-best</sub></span></span></td>\n<td id=\"S3.T8.3.3.8.2\" class=\"ltx_td ltx_align_center\">17.18</td>\n<td id=\"S3.T8.3.3.8.3\" class=\"ltx_td ltx_align_center\">76.57</td>\n<td id=\"S3.T8.3.3.8.4\" class=\"ltx_td ltx_align_center\">75.30</td>\n</tr>\n<tr id=\"S3.T8.3.3.9\" class=\"ltx_tr\">\n<td id=\"S3.T8.3.3.9.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S3.T8.3.3.9.1.1\" class=\"ltx_text ltx_font_bold ltx_font_italic\">6)<span id=\"S3.T8.3.3.9.1.1.1\" class=\"ltx_text ltx_font_medium\"> TA prompt<sub id=\"S3.T8.3.3.9.1.1.1.1\" class=\"ltx_sub\">5-best</sub></span></span></td>\n<td id=\"S3.T8.3.3.9.2\" class=\"ltx_td ltx_align_center ltx_border_b\">16.62</td>\n<td id=\"S3.T8.3.3.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\">77.99</td>\n<td id=\"S3.T8.3.3.9.4\" class=\"ltx_td ltx_align_center ltx_border_b\">75.98</td>\n</tr>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": [
            "Since the comparisons with 1) and 2) have already been presented in Table 5 and discussed, we omit them here. For the remaining comparisons, we attempt the Alpaca prompt [38] and Task-Activating (TA) prompt [12] using InstructGPT on both 1-best and 5-best hypotheses. Figure 2 illustrates how the Alpaca prompt and TA prompt are used. The results are presented in Table 8."
        ]
    },
    "S4.T9": {
        "caption": "Table 9 :  Comparison results of SER performance.",
        "table": "<figure id=\"S4.T9\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span id=\"S4.T9.6.1.1\" class=\"ltx_text ltx_font_bold\">Table 9</span>: </span>Comparison results of SER performance.</figcaption>\n<div id=\"S4.T9.4\" class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:214.2pt;height:50.2pt;vertical-align:-0.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-8.1pt,1.9pt) scale(0.93,0.93) ;\">\n<table id=\"S4.T9.4.4\" class=\"ltx_tabular ltx_align_middle\">\n<tr id=\"S4.T9.4.4.4\" class=\"ltx_tr\">\n<td id=\"S4.T9.4.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T9.4.4.4.5.1\" class=\"ltx_text ltx_font_bold\">Transcript</span></td>\n<td id=\"S4.T9.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T9.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">WER<math id=\"S4.T9.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T9.1.1.1.1.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.1.1.1.1.1.m1.1.1\" xref=\"S4.T9.1.1.1.1.1.m1.1.1.cmml\">\u2193</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.1.1.1.1.1.m1.1b\"><ci id=\"S4.T9.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T9.1.1.1.1.1.m1.1.1\">\u2193</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math></span></td>\n<td id=\"S4.T9.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T9.2.2.2.2.1\" class=\"ltx_text ltx_font_bold\">BLEU<math id=\"S4.T9.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T9.2.2.2.2.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.2.2.2.2.1.m1.1.1\" xref=\"S4.T9.2.2.2.2.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.2.2.2.2.1.m1.1b\"><ci id=\"S4.T9.2.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T9.2.2.2.2.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.2.2.2.2.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S4.T9.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S4.T9.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">GLEU<math id=\"S4.T9.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T9.3.3.3.3.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.3.3.3.3.1.m1.1.1\" xref=\"S4.T9.3.3.3.3.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.3.3.3.3.1.m1.1b\"><ci id=\"S4.T9.3.3.3.3.1.m1.1.1.cmml\" xref=\"S4.T9.3.3.3.3.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.3.3.3.3.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n<td id=\"S4.T9.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T9.4.4.4.4.1\" class=\"ltx_text ltx_font_bold\">UA<math id=\"S4.T9.4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\uparrow\" display=\"inline\"><semantics id=\"S4.T9.4.4.4.4.1.m1.1a\"><mo stretchy=\"false\" id=\"S4.T9.4.4.4.4.1.m1.1.1\" xref=\"S4.T9.4.4.4.4.1.m1.1.1.cmml\">\u2191</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T9.4.4.4.4.1.m1.1b\"><ci id=\"S4.T9.4.4.4.4.1.m1.1.1.cmml\" xref=\"S4.T9.4.4.4.4.1.m1.1.1\">\u2191</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T9.4.4.4.4.1.m1.1c\">\\uparrow</annotation></semantics></math></span></td>\n</tr>\n<tr id=\"S4.T9.4.4.5\" class=\"ltx_tr\">\n<td id=\"S4.T9.4.4.5.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T9.4.4.5.1.1\" class=\"ltx_text ltx_font_italic\">Original</span></td>\n<td id=\"S4.T9.4.4.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\">17.18</td>\n<td id=\"S4.T9.4.4.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\">76.56</td>\n<td id=\"S4.T9.4.4.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">75.29</td>\n<td id=\"S4.T9.4.4.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">60.92</td>\n</tr>\n<tr id=\"S4.T9.4.4.6\" class=\"ltx_tr\">\n<td id=\"S4.T9.4.4.6.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S4.T9.4.4.6.1.1\" class=\"ltx_text ltx_font_italic\">Corrected</span></td>\n<td id=\"S4.T9.4.4.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\">16.07</td>\n<td id=\"S4.T9.4.4.6.3\" class=\"ltx_td ltx_align_center ltx_border_b\">78.22</td>\n<td id=\"S4.T9.4.4.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">76.96</td>\n<td id=\"S4.T9.4.4.6.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T9.4.4.6.5.1\" class=\"ltx_text ltx_font_bold\">61.82</span></td>\n</tr>\n</table>\n</span></div>\n</figure>\n",
        "footnotes": [],
        "references": []
    }
}