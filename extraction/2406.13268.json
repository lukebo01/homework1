{
    "S3.T1": {
        "caption": "Table 1:  The comparison of EER (%) results for speaker recognition performance on the VoxCeleb2 dataset.",
        "table": "<figure id=\"S3.T1\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>The comparison of EER (%) results for speaker recognition performance on the VoxCeleb2 dataset.</figcaption>\n<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S3.T1.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T1.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Methods</span></td>\n<td id=\"S3.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T1.1.1.2.1\" class=\"ltx_text ltx_font_bold\">vox1-O</span></td>\n<td id=\"S3.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T1.1.1.3.1\" class=\"ltx_text ltx_font_bold\">vox1-E</span></td>\n<td id=\"S3.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\"><span id=\"S3.T1.1.1.4.1\" class=\"ltx_text ltx_font_bold\">vox1-H</span></td>\n</tr>\n<tr id=\"S3.T1.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Baseline</td>\n<td id=\"S3.T1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">1.069</td>\n<td id=\"S3.T1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">1.209</td>\n<td id=\"S3.T1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">2.310</td>\n</tr>\n<tr id=\"S3.T1.1.3\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.3.1\" class=\"ltx_td ltx_align_center\">Co-teaching</td>\n<td id=\"S3.T1.1.3.2\" class=\"ltx_td ltx_align_center\">1.016</td>\n<td id=\"S3.T1.1.3.3\" class=\"ltx_td ltx_align_center\">1.239</td>\n<td id=\"S3.T1.1.3.4\" class=\"ltx_td ltx_align_center\">2.275</td>\n</tr>\n<tr id=\"S3.T1.1.4\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.4.1\" class=\"ltx_td ltx_align_center\">Co-teaching+</td>\n<td id=\"S3.T1.1.4.2\" class=\"ltx_td ltx_align_center\">1.180</td>\n<td id=\"S3.T1.1.4.3\" class=\"ltx_td ltx_align_center\">1.426</td>\n<td id=\"S3.T1.1.4.4\" class=\"ltx_td ltx_align_center\">2.600</td>\n</tr>\n<tr id=\"S3.T1.1.5\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.5.1\" class=\"ltx_td ltx_align_center\">O2U-Net</td>\n<td id=\"S3.T1.1.5.2\" class=\"ltx_td ltx_align_center\">1.067</td>\n<td id=\"S3.T1.1.5.3\" class=\"ltx_td ltx_align_center\">1.341</td>\n<td id=\"S3.T1.1.5.4\" class=\"ltx_td ltx_align_center\">2.457</td>\n</tr>\n<tr id=\"S3.T1.1.6\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.6.1\" class=\"ltx_td ltx_align_center\">OR-Gate</td>\n<td id=\"S3.T1.1.6.2\" class=\"ltx_td ltx_align_center\">1.080</td>\n<td id=\"S3.T1.1.6.3\" class=\"ltx_td ltx_align_center\">1.256</td>\n<td id=\"S3.T1.1.6.4\" class=\"ltx_td ltx_align_center\">2.346</td>\n</tr>\n<tr id=\"S3.T1.1.7\" class=\"ltx_tr\">\n<td id=\"S3.T1.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">CEC</td>\n<td id=\"S3.T1.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T1.1.7.2.1\" class=\"ltx_text ltx_font_bold\">1.010</span></td>\n<td id=\"S3.T1.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T1.1.7.3.1\" class=\"ltx_text ltx_font_bold\">1.199</span></td>\n<td id=\"S3.T1.1.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T1.1.7.4.1\" class=\"ltx_text ltx_font_bold\">2.233</span></td>\n</tr>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "As shown in Table 1, Co-teaching and our algorithm achieved good performance in speaker recognition on the VoxCeleb2 dataset. However, since VoxCeleb2 itself contains only a small number of noisy labels, the improvement for both methods is not significant. Qin et al. [16] obtained that VoxCeleb2 contains about 2.6% noisy labels through clustering, which is consistent with our results. The poor performance of Co-teaching+ may be attributed to its ``Update by Disagreement\" approach, where a large proportion of disagreements between the two networks are noisy labels. OR-Gate also did not achieve satisfactory results, possibly because the optimal hyperparameters mentioned in the paper were determined without extensive data augmentation. O2U-Net did not demonstrate its advantage because it requires multi-round of training, while all our training was limited to 150 epochs, which is not sufficient for O2U-Net."
        ]
    },
    "S3.T2": {
        "caption": "Table 2:  The results of the ablation experiments on the simulated dataset with an NCR of 5%.",
        "table": "<figure id=\"S3.T2\" class=\"ltx_table\">\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>The results of the ablation experiments on the simulated dataset with an NCR of 5%.</figcaption>\n<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">\n<tr id=\"S3.T2.1.1\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T2.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Methods</span></td>\n<td id=\"S3.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\" colspan=\"3\"><span id=\"S3.T2.1.1.2.1\" class=\"ltx_text ltx_font_bold\">EER(%)</span></td>\n<td id=\"S3.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\" rowspan=\"2\"><span id=\"S3.T2.1.1.3.1\" class=\"ltx_text ltx_font_bold\">Recall</span></td>\n</tr>\n<tr id=\"S3.T2.1.2\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.1.1\" class=\"ltx_text ltx_font_bold\">vox1-O</span></td>\n<td id=\"S3.T2.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.2.1\" class=\"ltx_text ltx_font_bold\">vox1-E</span></td>\n<td id=\"S3.T2.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.3.1\" class=\"ltx_text ltx_font_bold\">vox1-H</span></td>\n</tr>\n<tr id=\"S3.T2.1.3\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\">Baseline</td>\n<td id=\"S3.T2.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">3.112</td>\n<td id=\"S3.T2.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">3.060</td>\n<td id=\"S3.T2.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">5.198</td>\n<td id=\"S3.T2.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">-</td>\n</tr>\n<tr id=\"S3.T2.1.4\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.4.1\" class=\"ltx_td ltx_align_center\">w/o CIC</td>\n<td id=\"S3.T2.1.4.2\" class=\"ltx_td ltx_align_center\">2.619</td>\n<td id=\"S3.T2.1.4.3\" class=\"ltx_td ltx_align_center\">2.683</td>\n<td id=\"S3.T2.1.4.4\" class=\"ltx_td ltx_align_center\">4.521</td>\n<td id=\"S3.T2.1.4.5\" class=\"ltx_td ltx_align_center\">0.934</td>\n</tr>\n<tr id=\"S3.T2.1.5\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.5.1\" class=\"ltx_td ltx_align_center\">w/o TIC</td>\n<td id=\"S3.T2.1.5.2\" class=\"ltx_td ltx_align_center\">2.597</td>\n<td id=\"S3.T2.1.5.3\" class=\"ltx_td ltx_align_center\">2.685</td>\n<td id=\"S3.T2.1.5.4\" class=\"ltx_td ltx_align_center\">4.538</td>\n<td id=\"S3.T2.1.5.5\" class=\"ltx_td ltx_align_center\">0.992</td>\n</tr>\n<tr id=\"S3.T2.1.6\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.6.1\" class=\"ltx_td ltx_align_center\">w/o CIC/TIC</td>\n<td id=\"S3.T2.1.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.1.6.2.1\" class=\"ltx_text ltx_font_bold\">2.532</span></td>\n<td id=\"S3.T2.1.6.3\" class=\"ltx_td ltx_align_center\">2.714</td>\n<td id=\"S3.T2.1.6.4\" class=\"ltx_td ltx_align_center\">4.552</td>\n<td id=\"S3.T2.1.6.5\" class=\"ltx_td ltx_align_center\">-</td>\n</tr>\n<tr id=\"S3.T2.1.7\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.7.1\" class=\"ltx_td ltx_align_center\">w/o CL</td>\n<td id=\"S3.T2.1.7.2\" class=\"ltx_td ltx_align_center\">2.763</td>\n<td id=\"S3.T2.1.7.3\" class=\"ltx_td ltx_align_center\">2.767</td>\n<td id=\"S3.T2.1.7.4\" class=\"ltx_td ltx_align_center\">4.650</td>\n<td id=\"S3.T2.1.7.5\" class=\"ltx_td ltx_align_center\">0.936</td>\n</tr>\n<tr id=\"S3.T2.1.8\" class=\"ltx_tr\">\n<td id=\"S3.T2.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_bb\">CEC</td>\n<td id=\"S3.T2.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">2.580</td>\n<td id=\"S3.T2.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.8.3.1\" class=\"ltx_text ltx_font_bold\">2.650</span></td>\n<td id=\"S3.T2.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.8.4.1\" class=\"ltx_text ltx_font_bold\">4.499</span></td>\n<td id=\"S3.T2.1.8.5\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.8.5.1\" class=\"ltx_text ltx_font_bold\">0.995</span></td>\n</tr>\n</table>\n</figure>\n",
        "footnotes": [],
        "references": [
            "We further conducted ablation experiments to validate the effectiveness of each component in the proposed approach. To simulate datasets with fewer noisy labels similar to those encountered in real-world applications, we conducted ablation experiments on a 5% NCR dataset. Table 2 displays the experimental results. The baseline represents not using any optimization schemes, while CL represents curriculum learning. Our proposed method shows an EER improvement of over 13% compared to the baseline. Among them, curriculum learning has a greater impact on the model's speaker recognition performance, while CIC has a greater impact on noisy label detection performance. CIC can screen out more than 90% of noisy labels in the early stages of training, while TIC has better recall performance (over 99%), enabling it to screen out noisy labels missed by CIC in the later stages of training. Recall is used here because it more accurately reflects the performance of noisy label detection on low NCR data, as mentioned before, Recall is not affected by the presence of outlier data in the clean dataset."
        ]
    }
}